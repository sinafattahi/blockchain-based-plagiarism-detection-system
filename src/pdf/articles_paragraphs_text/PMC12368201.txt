The ICH E9(R1)Addendum on Estimands and Sensitivity Analysisprovides a framework for defining the treatment effect a trial intends to estimate—the estimand. The addendum is widely adopted in pharmaceutical research. However, it remains underutilized in trials investigating internet-based interventions (IBIs). This manuscript introduces the addendum to IBI researchers. It concludes that estimands are essential to improve the interpretability, relevance, and validity of effect estimates derived in IBI trials.

To ensure that randomized controlled trials of (non-) digital (mental) health interventions yield informative results, researchers need to define the intended substantive meaning of the treatment effect they intend to estimate: theestimand1–4. An estimand forms the basis for designing trials that allow collecting data needed to answer the clinical question. An estimator (i.e., a statistical procedure) that is aligned with the estimand is used to summarize the data and derive an estimate that accurately quantifies the estimand1,3,4.

Define the estimand attributes: population, endpoint, treatment, and statistical summary measure1.

Identify possible intercurrent events (ICEs): events that occur after treatment initiation and affect either the interpretation or availability of measurements relevant to answering the clinical question (e.g., treatment discontinuation)1.

Choose strategies for dealing with ICEs that ensure that the estimate remains aligned with the estimand1.

Pharmacology researchers have adopted the addendum; numerous publications explained, refined, and illustrated its application3–19. However, the addendum is underutilized in Internet-based interventions (IBIs: interventions that provide individuals access to evidence-based psychotherapeutic techniques in a digital format) research, despite its potential to (1) enhance the interpretability of IBI studies4,20and (2) its recognition in the European Medicines Agency (EMA) guidelines on depression trials21and the updated CONSORT guidelines22. This manuscript provides an overview of the estimand framework for IBI researchers, particularly clinical psychologists, psychiatrists, and non-statistical professionals who play a key role in trial design and implementation. We outline key assumptions and provide resources for statistical details.

Two trials evaluate the same IBI for depression. They use the same inclusion criteria, recruit from routine care, employ a waitlist control, and use self-reported depressive symptoms 8 weeks after randomization as the endpoint.

Trial Aassessed depressive symptoms weekly, but only while patients used the IBI. Thus, the endpoint is missing for individuals who discontinued treatment. Trial A replaces missing endpoints using multiple imputations with depression scores collected while individuals used the IBI as auxiliary information.Trial Bcollects the endpoint fromallpatients, even if they discontinued the IBI. Thus, Trial B has no missing values.

Since neither study defines what treatment effect they intend to estimate or describes the assumptions underlying their approaches, the reader must infer the meaning of the estimated treatment effect from how the data were collected and analyzed4. It becomes evident that the two trials answerdifferentclinical questions.

Since the imputation model in Trial A only knows how the symptoms develop while individuals are on treatment, it imputes the missing values of discontinuers as if they continued the treatment23,24. Trial A estimates a treatment effect for ahypothetical scenarioin which one has found a “magical” measure to get all non-adherers to adhere24,25. However, the assumption that individuals who discontinued IBI have similar symptom trajectories to those who completed it, especially if discontinuation is related to the intervention, worsening of symptoms, or other characteristics that distinguish discontinuers from those who adhere, is unrealistic. Trial A appears to be valid. However, not collecting endpoints from discontinuers can be a trial-related flaw that may lead to overestimated treatment effects that do not generalize to clinically relevant contexts.

Trial B collects the endpoint from all patients, regardless of adherence. It targets the symptom change in areal-world scenarioin which treatment discontinuation occurs.

The estimand is the central concept of the ICH E9(R1) addendum. Anestimandis a systematic description of the effect researchers want to quantify1,3. The addendum recommends defining the estimand along five attributes1,3.

Treatment:A complete description of the treatment regimen for all study arms is required, including all digital (e.g., number of modules, intended dosage) and non-digital components (e.g., whether concurrent antidepressant use is permitted, emergency procedures). It is incorrect to equate the treatment with the IBI; the IBI is typically just the major ingredient of a comprehensive treatment regimen.

Population:The eligibility criteria define the target population1. Baseline characteristics inform how well the sample represents it. The addendum highlights the possibility of focusing on principal strata (see section onprincipal strata)1,3.

Endpoint:The endpoint is the variable collected to quantify the treatment effect, including the assessment time and modality1. Endpoints may be questionnaire scores, diagnostic classifications, or composite variables1.

Population-level summary:The population-level summary is a statistical measure calculated to quantify the treatment effect1,3. IBI trials are typically interested in differences in mean symptom scores or responder rates.

Table1summarizes some considerations for defining these attributes in IBI trials. These aspects are not IBI-specific, but important due to the nature of IBIs.

►Describe all components of the IBI. IBIs are treatment packages that differ in several dimensions, such as (a) the theoretical foundation, (b) the number of modules, (c) the psychotherapeutic techniques used, (d) the sequence and/or the timing of treatment modules, (e) the rules for how clients access new content, (f) the amount and type of guidance, or (g) the type of personalization. Trial protocols should describe all components. This description should also include aspects of technical implementation, such as (i) the type of platform, (ii) the form of the application (mobile vs. web-based), and (iii) the nudging mechanisms used (e.g., gamification, reminders).

►Define what “being treated” means. In principle, various meaningful definitions exist, such as (a) gaining access to the treatment material or (b) completing all or a certain proportion of the modules. However, IBI participants often choose the dose and intensity of the IBI treatment for themselves. This IBI characteristic makes some estimands more plausible (e.g., the treatment effect of individuals gaining access to an IBI with a non-standardized and self-selected dose;treatment policy strategy) than others (e.g., the effect that would have been observed with perfect adherence). Moreover, protocol deviations are difficult to define and assess. This also concerns treatment discontinuation. For example, in an IBI trial where participants enter modules sequentially, a treatment could be considered discontinued if individuals stop logging in to the modules. However, in other IBIs, individuals decide for themselves how many and which modules they use; defining discontinuation and handling it appropriately can become much more challenging. Consequently, many IBI trials likely focus on the effect of making an IBI accessible.

►Define if the treatment regimen under investigation accepts treatments in parallel. IBIs are low-threshold interventions that are not regularly accompanied by visits to study centers. Therefore, there is little control over what individuals do in parallel. In the eligibility criteria, IBI often limits the parallel treatments with which participants are allowed to enter the trial. However, the use of parallel treatments initiatedafterrandomization is usually not restricted. Consequently, it should be explicitly stated which parallel treatments are allowed. In most instances, especially in clinical samples, all parallel treatments are allowed and atreatment policy strategy(e.g., collect data even if individuals use treatments in parallel) will be employed. However, this should be stated explicitly, and the frequency and intensity of parallel treatments should be assessed and reported.

►Consider the time-point of assessment as an endpoint attribute. Describe when the endpoint will be assessed. If possible, define a time frame that is considered acceptable and how observations collected outside this time frame are handled.

►Discuss whether linking measurement to progress in the IBI is sensible. IBI trials may align assessments with specific events, such as the start of a new module or completion of all modules. However, this creates a correlation between adherence and endpoint availability, which raises methodological challenges. First, assessment times can vary widely when participants complete the program at their own pace, making it difficult to control for time effects. Second, if the assessment of the outcome is linked to the completion of the intervention, participants control when the endpoint is assessed; for example, participants may complete the endpoint assessment when they feel ready rather than at the intended point in time55. If the missing assessments at the time of interest depend on the endpoint itself, the estimate could be biased55,56.

►Assessing endpoints outside the IBI could be useful. While conventional clinical trials often involve on-site assessments conducted in study centers, this is less common in IBI trials. IBIs may assess the endpoint within the application. However, this can result in a correlation between endpoint availability and adherence. Especially if no information is available about how endpoints developed among individuals who discontinued the IBI, problems can arise. Researchers must rely on a hypothetical strategy that imposes assumptions about the post-ICE symptom development. Therefore, alternative assessment modalities (e.g., telephone interviews) for the primary endpoint should be considered. This method allows for standardization of the assessment time-point for all participants, reduces reliance on IBI participation patterns, and could increase the sense of commitment to the evaluations.

►Apply the same principles to endpoints different from symptom change. In some studies, other variables, such as treatment discontinuation, could be the endpoints. To derive meaningful treatment effects, the same principles discussed for defining appropriate estimands should be applied.

►Select an effect size measure that is aligned with the estimand. If a trial is concerned with the mean difference, the statistical summary measure should reflect this mean difference. Therefore, specifying effect sizes that reflect the proportion of variance explained is not informative (e.g., R2).

►State your standardizer. Many IBI studies report between-group effects in standardized mean differences. If standardization is required, the standardizer should be specified. For a given mean difference, different standardizers lead to differences in the size of the effect sizes57and, more importantly, represent different estimands58. Standardizing a mean difference by the standard deviation of an untreated reference population has a different meaning than standardizing by the standard deviation of endpoint among all randomized individuals at the endpoint assessment59. It may be useful to report effects in units of the scale, as raw, unstandardized scale values do not depend on the standardizer and are often informative to clinicians.

The first four attributes help to identify relevantintercurrent events(ICEs), defined as “events occurring after treatment initiation that affect either [1] the interpretation or [2] the existence of the measurements associated with the clinical question of interest”1. Researchers should anticipate ICEs and discuss how they relate to the four attributes1,3. ICEs that result in measurements that misalign with one of the attributes are relevant.

Consider a trial that intends to estimate the effect of a scenario in which all individuals use IBI as intended versus no treatment (treatment) among adults with depression (population) in terms of mean differences (population level summary) in PHQ-9 scores 8 weeks after randomization (endpoint). Some patients are expected to discontinue the treatment (ICE). Treatment discontinuation fulfills both criteria of an ICE. First, it affects the interpretation of measurements collected after discontinuation. These measurements reflect the effects of the IBI and everything that happened after discontinuation. Second, measurements necessary to answer the clinical question do not exist for individuals who discontinued the treatment because they did not complete it. To keep the estimate aligned with the estimand, measurements affected by the ICE must be handled properly. This leads to the fifth attribute:the strategies for handling ICE.

Handling ICEs:Researchers should handle ICEs in a manner that keeps the estimate aligned with the estimand1,3. The addendum outlines five strategies, which can be combined: (1) treatment policy strategy, (2) hypothetical strategy, (3) while-on-treatment strategy, (4) composite strategy, and (5) principal strata strategy1,3.

The addendum highlights the difference between data affected by an ICE and missing data1,3. Missing data refers to information that was available but has not been collected. In our example, missing data results when individuals who complete the treatment are not assessed. This is different from data affected by an ICE. In our discontinuation example, the data cannot be collected because the individuals have not completed the IBI.

The addendum introduces a fundamental principle:whenever an ICE occurs, the post-ICE data, whether observed or missing, must be handled in a way that aligns with the estimand1. This section provides a conceptual overview of the five strategies for handling ICEs suggested in the addendum. There is no one-size-fits-all approach. Each strategy entails trade-offs. The appropriate (combined) strategy depends on the clinical question3,8. How to handle ICEs should be decided in a comprehensive discussion among all stakeholders1. All strategies and statistical methods employed to implement the strategies rely on assumptions. These assumptions should be stated4,7. Sensitivity analyses are necessary to assess the robustness of conclusions against violations of these assumptions1,3.

We focus on treatment discontinuation (ICE) in a simplified treatment regimen that comprises an IBI as the main treatment ingredient. Participants work with eight modules (one per week) in sequential order. We consider the treatment “discontinued” if the person no longer logs in in spite of not yet having completed all available treatment modules. We use this simplified example to illustrate how different strategies alter the interpretation of the treatment effects. Table2illustrates the application of the strategies to other ICEs. Table3relates the strategies to concepts widely used in IBI research: (a) the intention-to-treat principle, (b) per-protocol analysis, and (c) efficacy vs. effectiveness trials.

The treatment policy strategy considers the ICE part of the treatment1,3. Measurements remain informative even after an ICE has occurred, making it essential to collect post-ICE measurements1,3. Figure1A illustrates the treatment policy strategy.

The black solid lines indicate behavior until the ICE occurs or until the assessment of the endpoint.ATreatment policy strategy: Case 1 (C1) completed treatment and the assessment of the endpoint. C2 and C4 discontinued treatment but completed the endpoint assessment; their measurements are retained because discontinuation is considered part of the treatment regimen. C3 and C5 did not complete the endpoint assessment; therefore, endpoints must be modeled. The model must account for the fact that C3 and C5 discontinued the treatment and that C5 started antidepressants after discontinuation.BHypothetical strategy: C1 completed the treatment and the endpoint assessment. C2 and C3 discontinued the treatment, with C3 completing the endpoint assessment. Given that the trial’s interest in a scenario where discontinuation did not occur, this assessment is non-informative and must be discarded. For both cases, the missing outcomes are modeled to mimic a scenario in which they completed treatment (indicated by gray dashed line). C4 completed treatment but not the assessment. This is “pure” missing data, as it is unrelated to an intercurrent-event (ICE), but still requires modeling.CWhile-on-treatment strategy: C1 completed treatment; therefore, the endpoint assessment is used. C2 and C3 discontinued treatment; thus, only measurements collected before discontinuation are used for analysis.DComposite strategy: treatment failure is defined as (A) treatment discontinuation or (B) less than 50% symptom improvement (composite measure). C1 completed treatment and endpoint assessments; coded as treatment failure if symptom improvement is under 50%. C2 and C3 discontinued treatment. Hence, they are coded as treatment failures.EPrincipal stratum strategy: this analysis focuses on the principal stratum of individuals whowouldcomplete both treatments, regardless of assignment (TX1: an IBI focusing on cognitive restructuring; TX2: an IBI focusing on behavioral activation). Solid black lines represent behavior under the assigned treatment; dotted black lines represent non-observable behavior under the non-assigned treatment. C1 completed TX1, butwouldhave discontinued TX2. C2 discontinued TX1, butwouldhave completed TX2. In both C1 and C2, the ICE depends on the assigned treatment. C3wouldcomplete both treatments and is thus part of the target stratum. Since statum membership is not observable, it must be estimated.

By including all endpoints, even those affected by an ICE, in the analysis, the interpretation shifts toward the effect ofproviding access to the IBI, rather than the IBI itself. It quantifies the treatment effect under imperfect adherence.

The EMA recommends this strategy for handling treatment discontinuation in pharmacological trials21. This likely extends to IBI trials. Typically, IBI participants decide for themselves how and with what dose they use the treatment material. Therefore, collecting all endpoints at a pre-defined time point, irrespective of the level of engagement, seems to be the natural approach to consider the self-selected heterogeneity in dosage. This strategy bears challenges. Consider a trial that employs this strategy for parallel treatments. Group differences in the endpoint could emerge (or vanish) because the groups initiate parallel treatments with different likelihoods. However, one must assume that the estimate remains informative. High rates of parallel treatments can mask the ineffectiveness of the main treatment component.

The treatment policy strategy aims to minimize the need for assumptions by collecting data from all participants. Participants in IBI trials typically do not attend study centers. This increases the risk of missing endpoints after treatment discontinuation, especially if completing an assessment is tied to the use of the IBI. Without personal contact, individuals may feel less obligated to complete the online assessments. If measurements affected by an ICE are missing, the missing endpoints must be modeled in a way that accounts for the fact that the ICE has occurred25,26. Without any information about the post-ICE symptom course, researchers must rely solely on assumptions, such as that the post-discontinuation symptom course parallels that of patients in the control group17,23,24,27,28. These assumptions can typically not be verified. Researchers should therefore collect data that is as complete as possible. Thus, strategies to reduce missing values are needed29,30. Resources on the treatment policy strategy are available3,18,23,24,27,31,32.

The hypothetical strategy estimates the treatment effect for a well-definedwhat-ifscenario, assuming that the ICE did (or did not) occur1,3. Thus, it is impossible to derive a meaningful estimate using observed measurements affected by an ICE. Instead, the endpoints affected by an ICE are modeled in a manner that attempts to mimic the endpoints that would have occurred in the hypothetical scenario1,3,33.

Figure1B illustrates this strategy. The hypothetical strategy shifts the interpretation of the estimate towards an effect thatwould have been observed if discontinuation had not occurred. The strategy relies on two key assumptions:First, the hypothetical scenario is clinically meaningful1,3.Second, given all available data, the symptom course in the hypothetical scenario can be predicted1,3. Both are often questionable, especially when the rates with which ICEs occur are large (e.g., discontinuation in IBI trials); therefore, caution is needed. If used, the underlying assumptions must be reported1,21.

The following example illustrates possible challenges. A study aims to estimate the effect of a scenario in which all participants complete the IBI (i.e., work with all modules in the intended timeframe). To achieve this goal, one must assume that data from individuals who completed IBI is sufficient to estimate the symptom trajectories of those who discontinued treatment as if they had continued treatment (i.e., themissing-at-random assumption, MAR). However, individuals may discontinue the IBI due to dissatisfaction or deteriorating symptoms, and may differ in other characteristics from completers. Therefore, the available information might be insufficient (i.e., we did not collect all relevant covariates) to recover symptom trajectories with continued treatment. The MAR estimates will be biased and may not generalize to real-world settings, particularly when attrition rates are high.

The hypothetical strategy typically relies on some variant of multiple imputations; however, other approaches exist. Several resources are available3,7,18,31,33.

Thewhile-on-treatmentstrategy assumes that measurements collected before the ICE occurred contain all relevant information. Measurements after the ICE are irrelevant1,3.

Figure1C illustrates this strategy. The strategy yields an estimate that reflects the treatment effects up to the point at which an ICE occurs.

It is typically less relevant for evaluating the effects of IBI treatment. However, it can be used to assess safety-related aspects, such as the rate of suicides, while following the assigned treatment. However, some aspects warrant attention. First, the strategy may provide an incomplete picture of all adverse events that occur in the context of the treatment3,34. In particular, the strategy fails to detect adverse events occurring immediately after discontinuation, such as hospitalization or suicide, which could be a consequence of an ineffective treatment. Second, if people in one treatment arm tend to discontinue the treatment earlier, and the risk of adverse events increases over time, event rates may appear lower due to the lower time on treatment. The interpretability of the between-group differences in rates of adverse events becomes misleading. Therefore, a safety assessment of an IBI should combine the while-on-treatment strategy with assessments collected after discontinuation34. Interested readers will find more information elsewhere3,18,35.

A composite measure is a single outcome variable that combines two or more endpoints1,3. The composite strategy considers the ICE part of the endpoint.

Figure1D illustrates the strategy. The composite strategy shifts the interpretation towards an effect that is a mixture of different components. Consequently, the strategy assumes that the composite measure offers a meaningful interpretation. In particular, it assumes that the components have similar clinical relevance (a limitation that applies to all composite endpoints)3,36.

The following example illustrates the interpretative challenges that can emerge when this assumption is violated. Consider two trials that classify a treatment as a failure if (a) there was no reduction in suicidal ideation or (b) hospitalization was required due to suicidal ideation (e.g., rate of treatment failures is the endpoint). Both studies report treatment failure rates of 15%. In study A, 95% of failures were due to no reduction in suicidal ideation, and 5% were due to hospitalization. Study B reports reversed rates. Claiming that both IBIs are equally effective is misleading. Thus, it is essential to report the rate of individual components or to apply appropriate weighting36,37. Further problems arise when the likelihood of certain components differs across treatment arms. Consider a trial that compares antidepressants against an IBI. In the antidepressant arm, treatment discontinuation may result from physiological adverse events that can’t occur in IBIs. Thus, the reasons why the ICE occurred must be considered. Composite strategies may fall short of meeting regulatory expectations. Therefore, even when employing a composite strategy, collecting post-ICE data is advisable. More information is provided elsewhere3,18,36,37.

The principal stratum strategy aims to quantify the treatment effect within the latent stratum of individuals who would (or would not) experience an ICE, regardless of the assigned treatment1,3. For instance, in a two-arm trial, one could be interested in the effect among individuals whowouldcomplete both treatments, irrespective of which treatment arm they are assigned (see ref.38for further examples)38,39. Alternatively, one may focus on individuals who would complete the IBI if assigned to the IBI. Thus, the stratum is defined based on how individualswouldbehave under different treatments38,39.

Figure1E illustrates the strategy. This interpretation of the treatment effects shifts towards the latent population of individuals defined by the (non-)occurrence of the ICE. The estimate no longer quantifies the effect among all randomized individuals1,5.

In theory, this strategy can address clinically relevant questions, such as which treatment yields longer-lasting effects among individuals whowouldcomplete both treatments. Beyond the fact that it can be challenging to define what completion means in IBI trials (see Table1), it is impossible to observe if an individual will experience the ICE under both treatments. Untestable assumptions are necessary when determining whether an individual belongs to the stratum of interest3,38,39. One may attempt to model stratum membership using baseline variables39. However, it is impossible to identify stratum membership without error; the statistical analysis must take this into account3,38,39.

Kahan et al. discuss rare instances in which strata appear naturally40. Consider a study comparing guided versus unguided IBI. Some individuals discontinue the treatment before learning their assigned trial arm. Since discontinuation is unrelated to the treatment, excluding them from the analysis won’t introduce bias40. The interpretation shifts toward the subset of individualswho would always start the assigned treatment(=the principal stratum)40. Guidance on appropriate statistical approaches is provided elsewhere3,7,18,38,39.

Several applications of the framework to pharmacological treatments have been published11–14,41–44. Supplementary Tables1and2present two fictitious examples of IBI trials. They are not intended as best-practice examples, but rather to illustrate the principles of the addendum. The example follows the template to describe trials provided by Ratitch et al.8,9.

This manuscript introduced the ICH E9(R1) addendum to IBI researchers. The addendum prompts prioritizing the collection of measurements vital for answering the clinical question and anticipating how ICEs impair the availability of needed measurements1. When ICEs are anticipated, trial design and statistical approach can be aligned to derive informative estimates. Trial protocols should report the targeted estimand1,22,45. Reports of completed trials should provide sufficient detail to derive the estimand20,46. This includes describing estimated effects with precise language. Instead of claiming that the “IBI was effective,” one might report that “group differences reflect the effect thatcouldbe achieved if all individualswould becompliant” when the hypothetical strategy was employed18.

Standardized reporting of estimands will facilitate the synthesis of findings in meta-analyses6. Currently, the lack of clarity in reporting estimands hampers systematic evaluations of how estimands explain between-study heterogeneity20,46. To increase understanding of estimands, helpful teaching materials have been published16,26,47.

While this manuscript focuses on parallel group trials, the framework extends to factorial designs48, cluster randomized trials49, and non-inferiority and equivalence trials42,50–52. It should also be considered in face-to-face psychotherapy trials.

Open access funding provided by Freie Universität Berlin.