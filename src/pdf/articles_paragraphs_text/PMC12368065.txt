Student performance prediction (SPP) constitutes one of the pivotal tasks in educational data analysis. Outcomes from the prediction enables educators to implement targeted interventions for students. Therefore, developing an effective SPP model is of critical importance. The belief rule base (BRB) is a rule-based modeling approach that integrates expert knowledge and effectively manages uncertain information. Nevertheless, when employing traditional BRB to construct a prediction model, excessive input attributes and reference points may result in a combination explosion. Furthermore, in practical scenarios, the configuration of the model’s parameters may be restricted by the limitations of expert knowledge. To overcome these challenges, an SPP model using an interval BRB structure based on the random forest (RF) attribute selection method (IBRB-C) is proposed. The parameters of the IBRB-C model are determined by combining the expert knowledge and the Kmeans++ algorithm. Subsequently, the P-CMA-ES algorithm is applied to optimize the initial model. Ablation experiment is conducted to validate the rationality of the IBRB-C. Finally, case studies on graduate applications and GPA of students demonstrate that the mean squared error (MSE) of the IBRB-C is 0.0024 and 0.1014, respectively. The results of comparative experiments confirm the superiority of the IBRB-C model in predicting student performance.

Focusing on students’ academic performance is essential in the educational process. This focus aids in students’ personal growth and provides an important framework for educators to evaluate the effectiveness of their teaching methods. The prediction of student performance entails forecasting future academic outcomes by examining past data on student learning1,2. Education serves as a crucial foundation for national revitalization and societal advancement, and SPP holds considerable importance3–6. Educators are accessible to offer individualized, focused assistance and prompt intervention for students7,8. As society places greater importance on fostering an ideal educational environment, the SPP holds significant promise for steering and overseeing the teaching process9. Therefore, an efficient SPP model is crucial to stay aligned with the swift advancements in educational information technology10,11.

Currently, researchers in related fields have proposed a series of student performance prediction methods. These methods can be broadly classified into three categories: data-driven, physical-driven, and hybrid-driven models12. Data-driven models analyze data samples to identify patterns or correlations. Mi proposed a model to predict student performance based on the neural network of the radial basis function (RBF) neural network13.The model accurately predicted performance by analyzing the learning situation of students, demonstrating the potential of machine learning in the field of education. In recent years, with significant progress in deep learning (DL), SPP methods based on DL have made further breakthroughs14. Sun used the adaptive federated deep learning algorithm to predict college students’ sports performance, studied the influencing factors, and presented improvement suggestions15. Dien et al. combined deep learning, data transformation, and factor analysis methods. They proposed several data pre-processing techniques to predict student performance combined with models16. However,It should be noted that the training of data-driven models relies on a large number of data samples. In addiction, prediction results lack interpretability because they are black-box models.

Physical-driven models are developed upon theoretical foundations and empirical guidelines. These models rely on a comprehensive understanding and mathematical depiction of the system’s physical process. Ouyang et al.17used an artificial intelligence prediction model combined with the learning analysis method to improve the effect of students in a collaborative learning environment. Based on self-regulation and prediction of learning analysis, Cogliano et al. monitored students with difficulties learning biology and provided support18. Physical-driven models have some advantages due to their theoretical integrity and interpretability. However, it can be difficult for these models to understand the interaction of various influencing factors and to deal with complex problems.

Hybrid-driven models integrate the advantages of data-driven and physical-driven models. Hao et al.19used Bayesian networks to predict student MOOC performance and suggested improvement measures. Chiu et al.20used a hidden Markov model to predict student performance. Raes et al.21proposed the concept of a blended learning environment to combine elements of on-site and distance learning to adapt to educational needs during the COVID-19 pandemic. These hybrid-driven SPP models combine the experience of educational experts with sample data from relevant cases. Therefore, their results have great advantages in accuracy and interpretability. Educators are encouraged to prioritize the student-centered principles. When developing the prediction model, it is essential to comprehensively utilize the expertise accumulated by educational professionals. Nevertheless, pertinent data in the educational domain frequently exhibit a degree of subjectivity and uncertainty, thereby influencing the outcomes of the model22. Therefore, prediction models must be able to handle uncertain information.

In this study, belief rule base (BRB) is selected to build the model. BRB is a hybrid-driven model proposed by Yang et al.23, which is based on IF-THEN rules and evidential reasoning (ER)24. BRB effectively solves uncertainty and ambiguity in the data collection process by using the belief distribution to describe qualitative or quantitative data25,26. Regarding education issues, BRB has good interpretability, which enables educators to understand the process of achieving the results. Liang et al.27constructed the HBRB-I model to predict student performance. Gong et al.28also proposed a hierarchical BRB model to predict global educational inequality. Liu et al.29used data mining technology to analyze educational data, and adjusted the balance between precision and complexity of the prediction model with AIC. In addition to interpretability, researchers are increasingly focusing on the robustness of BRB models30,31. Therefore, BRB has demonstrated increasingly broader application prospects in fault detection and health assessment of complex systems32–34. Yin et al. further considered the attribute reliability and reverse causal inference based on interpretable BRB modeling, successfully applied to the health state assessment of aeronautical relay and diesel engines35,36. Lian et al. proposed the linguistic Z-Number belief rule base considering the reliability of knowledge, which demonstrated excellent performance while retaining a high transparency in modeling process37–39.

However, the combination explosion will be caused by too many input attributes or reference points in traditional BRB models. Rule reduction and hierarchical structure are used to reduce the complexity of the BRB. Zhou et al. conducted a rule evaluation using a statistical utility threshold40,41. Kalia et al. introduced dimensionality reduction methods such as multidimensional scaling (MDS), principal component analysis (PCA), Isomap, and gray objective (GT)42–45. Zhang et al.46used the BRB model to predict tunnel squeezing and avoided the combination explosion by building the hierarchical structure. However, rule reduction methods will lose model accuracy and have limitations in filtering important attributes. The initial hierarchical BRB model is unable to train the intermediate layers, increasing the uncertainty of the model. Therefore, Sun et al. proposed an interval BRB model (IBRB), which can better cope with uncertainty and diversity by dividing input attributes into reference intervals47. In the field of education, student performance often presents a normal distribution. IBRB model can make full use of data samples, effectively integrate multidimensional data, and improve the accuracy of the prediction results.

The following two problems need to be solved when construct the SPP model based on IBRB. (1) A series of factors affect students’ academic performance. The question of how to select the appropriate input attributes must be considered. (2) Setting the reference intervals is vital for model construction, and the inefficient expert knowledge will affect the process. To solve these problems, in this paper, an interval BRB student performance prediction model based on random forest (RF) attribute selection is proposed. First, features with the highest importance are chosen as input attributes. Expert knowledge is combined with the Kmeans++ algorithm to divide reference intervals. Then, ER rule is used as the inference mechanism. Finally, optimization of the initial parameters is performed by the P-CMA-ES algorithm to improve the accuracy.

The main contributions of this paper are as follows.

This paper proposes the IBRB-C student performance prediction model.

An interval BRB structure based on RF attribute selection is constructed to solve the combination explosion, and the reliability of each belief rule is considered in the model inference process.

Expert knowledge and the Kmeans++ algorithm are combined to determine the reference intervals of the model. This method can compensate for the lack of expert knowledge and improve the accuracy of the IBRB-C model.

The main structure of this paper is as follows. In section “Problem formulation”, three problems are elaborated to build the IBRB-C model. Section “IBRB-C student performance prediction model” describes the construction, inference, and optimization process of the IBRB-C model. In section “Case study”, two experimental cases are combined to verify the effectiveness of the IBRB-C model. Section “Conclusions” concludes the paper and discusses future work.

Problem 1: When designing the structure of IBRB-C model, it is indispensable to determine the input attributes and reference intervals. Therefore, the first question is how to choose input attributes. The process can be expressed as follows.

wheredenote all available attributes.denotes the attribute selection function.denote the selected input attributes of the model.

The setting of the reference intervals is generally based on expert knowledge. However, if expert knowledge is insufficient, it is difficult to ensure the precision and integrity of the model. Therefore, a reference interval determination method combined with expert knowledge is needed. The process can be described as follows.

whereanddenote the set of reference points to be determined and the data samples of theinput attribute, respectively.denotes the determination algorithm.denotes the adjustments made by experts.

Problem 2: How to properly design the inference process of the model. The inference process of IBRB is different from that of traditional BRB. The process can be described as follows.

wherexrepresents the evaluation levels of the model.represents the set of parameters in the inference process.urepresents the prediction result.represents the inference function.

Problem 3: How to design the optimization process of the model. As a hybrid-driven model, the initial model of BRB needs to be optimized. The process can be described as follows.

whereandrepresent inputs and outputs.represents the set of parameters used in the optimization process.represents the set of optimal model parameters.represents the optimization algorithm.

This section outlines the construction methodology of the IBRB-C model. The IBRB model substitutes the reference points of the input attributes with intervals. Upon encountering a data sample within a reference interval, the corresponding belief rule is activated. These activated rules are involved in the inference and optimization process of the model. Typically, the distribution of student scores is either scattered or displays a segmental concentration. By employing intervals to depict the data, the IBRB-C model more effectively captures the uncertainty information, making it more appropriate for practical application.

This section is structured as follows. Subsection “Construction process of the IBRB-C model” describes the construction process of the IBRB-C model. Subsection “Inference process of the IBRB-C model” explains the inference procedure of the model. Subsection “Optimization process of the IBRB-C model” presents the optimization procedure of the IBRB-C model.

The IBRB-C is modeled based on IF-THEN rules, which consist of a series of belief rules. Assuming that the input attributes are independent of each other, the relationship between the evaluation levels and the result of the model can be described as follows.

whereL,MandNdenote the number of belief rules, input attributes, and evaluation levels of the model, respectively.denotes the input attributes.denotes the reference intervals.denotes the evaluation levels.denotes the belief degree of each evaluation level under thebelief rule.anddenote the weight and reliability of thebelief rule, respectively.

It is worth noting that, unlike the traditional BRB, the input attributes of the proposed model are connected by the disjunctive notation. The main reason is that interval BRB uses interval addition to combine rules instead of Cartesian product. In this way, for the same number of input attributes and reference points, the number of rules in interval BRB models will be greatly reduced26.

The general construction process of the IBRB-C model is shown in Fig.1.

It is crucial to acknowledge that the integration way of rules in the IBRB model enables more input attributes compared to the traditional BRB26. However, in practical scenarios, the factors affecting student academic performance are multifaceted. Additionally, the gathered data samples often encompass various types. For instance, some features might include binary data, where 0 denotes “no” and 1 denotes “yes”. The selection of these features as input attributes is problematic. They complicate the definition of reference intervals and pose difficulties in assessing their significance. Meanwhile, the process of manually selecting features is easily influenced by subjectivity, which affects the persuasiveness and rationality of the modeling process. Therefore, this study integrates an attribute selection module within the IBRB-C model to achieve a balance between prediction accuracy and model simplicity.

The main difficulty in attribute selection is assessing the significance of each feature. To address this, this study employs the random forest (RF) approach. RF is an ensemble learning method that develops multiple decision trees and combines their output to generate the final prediction. Consider that the input feature matrix isand the target attribute is, wherenandpdenote the number of samples and features, respectively. The importance value for each feature can be calculated as follows.

Two features with the highest values are selected as input attributes of the IBRB-C model.

Reference points for the BRB are generally established using expert knowledge. However, in practical scenarios, such insights may prove insufficient. Zhang et al. have proposed a Kmeans++ algorithm with error constraints to generate reference points, which has been utilized to forecast the behavior of complex systems48. Building upon this algorithm, Liu et al. implemented it within a BRB-based SPP model29. Therefore, reference intervals for the IBRB-C model are determined by combining expert knowledge with the Kmeans++ algorithm in this study.

It is important to note that the point set generated by the Kmeans++ algorithm excludes endpoints. The lack of endpoints may undermine the comprehensiveness of the BRB model49. To remedy this deficiency, the Kmeans++ algorithm is initially employed to establish the set of interval boundary points, followed by adding endpoints with expert knowledge. The procedures are outlined as follows.

Select the initial center.Ccluster centers are preset based on the reality of the research. A sample point of the input attributeis randomly selected as the first cluster center.

Repeat the above steps until all cluster centers are selected.

Repeat Step 5 and 6 until all interval boundary points are established. Now, the initial set of interval boundary points is obtained. The endpoints are added with expert knowledge to ensure meaningfulness. For example, the Kmeans++ algorithm provides the initial points,,, and the endpoints selected by experts are,. Therefore, the final interval boundary points are,,,,. The reference intervals can then be set as [,], [,], [,]and [,].The process is repeated until each input attribute has suitable reference intervals.

The inference process of the traditional BRB uses ER parsing algorithm, without considering the reliability of each belief rule49. Cheng et al. designed a new inference algorithm for the IBRB, which improved the performance of the model26. The inference process of the IBRB-C model can be summarized as follows. After judging the activation rules based on the input information, the ER rule is used to fuse the belief rules. Finally, the expected utility is obtained by utility calculation as the model prediction results. The process can be described as follows.

When the BRB model demonstrates insufficient accuracy, this may result from rules that are not properly allocated within the belief distribution50. Therefore, the IBRB-C model focuses on optimizing the initial parameters to minimize the MSE.

Various algorithms have been employed in the optimization of models. A widely adopted optimization algorithm for BRB is the P-CMA-ES algorithm51. The P-CMA-ES algorithm is a parallel optimization method based on an adaptive evolution strategy of the projected covariance matrix. It mimics the principles of biological evolution and demonstrates strong robustness and rapid convergence. Therefore, the P-CMA-ES algorithm is utilized to optimize the IBRB-C model.

The objective function of the optimization algorithm can be formulated as follows.

whererepresents the prediction accuracy of the model, which is calculated as follows.

wherePrepresents the number of samples.represents the prediction result of the model.represents the actual value. The prediction result can be obtained as follows.

The constraints for parameter optimization are given as follows.The optimization process of the model is shown in Fig.3.

The steps to execute the P-CMA-ES algorithm can be summarized as follows.

Recursively perform steps 1 to step 5 until the best parameters are obtained.

In this section, two case studies were used to verify the validity and superiority of the IBRB-C student performance prediction model. In Subsection “IBRB-C model for prediction of graduate admission success rate”, a graduate application dataset containing 500 data sets was researched for the ablation and comparison experiments. In Subsection “IBRB-C model for prediction of students’GPA”, a dataset containing nearly 2,400 data sets was studied to predict students’ GPA, verifying the prediction performance of IBRB-C model on the large-scale dataset.

Data collected for this case study relates to a group of Indian students. The dataset can be publicly obtained fromhttps://www.kaggle.com/datasets/mukeshmanral/graduates-admission-prediction(accessed on 12 July 2022), which has 500 sets of data. This dataset consists of one target attribute and seven input features, including test scores, written materials, and learning experience. The information are detailed in Table1.

whereandrepresent the input attributes.represents the evaluation level as the prediction result of the model. In this case study, the evaluation levels are low (), medium (), high (), and very high ().

Random forest method was used to select the input attributes of the IBRB-C model. The importance values of each feature are shown in Table2. Two features with the highest values, GRE and CGPA, were taken as input attributes of the IBRB-C model. Though TOEFL has a comparable importance value to the GRE, its data distribution is too concentrated to obtain enough cluster centers by Kmeans++ algorithm, so it has not been considered as a input attribute. The data distribution of GRE and CGPA are shown in Fig.4. In this case study, 100 data are randomly selected for testing, and the remaining data are used for training. The experimental environment includes Windows 11 and aGen Intel (R) Core (TM) i7-9750H processor. The experiment is carried out using Matlab R2024a software.

The upper and lower bounds of the attributes are presented in Table3. When conducting the Kmeans++ algorithm, the number of cluster centersCneeds to be set in advance. By analyzing the data distribution, 18 reference intervals are decided for each attribute, which means 19 interval boundary points. Since the results of algorithm exclude endpoints, the value ofCin this case study is 19-2 = 17. As illustrated in Table4, 36 reference intervals are composed of points determined jointly by the Kmeans++ algorithm and expert knowledge. Each rule in IBRB inherently represent a belief distribution and can serve directly as evidence26, which means 36 belief rules are consequently generated.

From Table3, the value of predictive target is between 0.34 and 0.97, so boundary of the reference values can be set as 0.35 and 1, with a difference of 0.65. When determining the remaining values, the difference between adjacent ones should be similar. Table5presents three sets of reference values, with an approximate difference of 0.3, 0.2, and 0.15, respectively. Compared to the second group, data distribution of other groups are relatively more uneven. In addition, the number of values in the second group is also appropriate. Therefore, (0.35, 0.55, 0.75, 1) was chosen as the reference values set.

In this case study, the initial rule weight and the rule reliability were initialized to 1. If the inputs of attributesandare 295 and 7, the two activated rules correspond to the intervals (290, 296) and (6.8, 7.28). These two rules are fused using the ER rule, followed by utility calculation to yield the final evaluation level. In the IBRB model, although the expanded range of reference points mitigates the uncertainty of expert knowledge, the belief degree, rule weight, and rule reliability still rely on it. Therefore, the IBRB-C model requires an optimization algorithm to refine the parameters. The initial parameters of the model can be found as Supplementary TableS1online, while the optimized results are detailed in Supplementary TableS2.

whereVdenotes the total number of data in the dataset.denotes the predicted value of thedata.denotes the true value of this data.denotes the residual sum of squares.denotes the total sum of squares.var(error) denotes the error variance.var(actual) denotes the actual data variance.

The MSE, RMSE, MAE,and VAF of the optimized IBRB-C model are 0.0024, 0.0496, 0.0365, 87.12% and 87.88%, respectively. It can be seen that the optimized model has high accuracy. Experiments validate the selection of attributes of the IBRB-C model and the reference intervals divided by the Kmeans++ algorithm combined with expert knowledge are reasonable and effective.

To verify the effectiveness of each module in the IBRB-C model, the same training and testing datasets were utilized to conduct an ablation study. The basic interval BRB model was the baseline, an attribute selection module based on RF, and a reference interval determination module based on expert knowledge and K-means++ algorithm were incrementally incorporated. The traditional BRB model was also considered to prove the superiority of the interval structure.

In the attribute selection module, Random Forest (RF) is used to assess the importance of attributes and select the most valuable ones for the model. This process ensures the validity of input attributes while reducing the number of belief rules. The reference interval determination module generates the boundary points of each interval, leading to a significant improvement in the precision of the model.

The following four models are designed to verify the effectiveness of each module.

Model A: This one is the basic interval BRB model without any added module, using all six available features in the dataset as input attributes.

Model B: The attribute selection module is added to this model. After the attribute selection, Model B has 2 input attributes and 36 belief rules.

Model C: It incorporates the reference interval determination module, which is also the IBRB-C model proposed in this paper.

Model D: This is the traditional BRB model, which has 2 input attributes and 361 belief rules.

The predictive fitting plots for the models are shown in Fig.5.

Predictive fitting plots for four models. (a) Model A. (b) Model B. (c) Model C. (d) Model D.

Table6presents a comparative analysis of Model B and Model D, which correspond to the traditional BRB and the basic interval BRB model, respectively. It is apparently that due to the interval structure, the number of belief rules is reduced by 90% from 361 to 36, and the parameters reduce from 1807 to 216, a decrease of approximately 88%. Crucially, as illustrated in Table7, Model B shows a considerably enhanced capability for predicting student performance. The advantages of the interval structure are thoroughly demonstrated. Combining the information in Figure5and Table7, the inclusion of each module significantly improves the model’s performance. In comparison to Model A, Model B effectively decreases the number of input attributes and enhances accuracy by selecting proper features. The best performance is achieved by Model C through the incorporation of the reference interval determination module. In summary, each module refines the basic model while avoiding redundancy.

To prove the superiority of the proposed IBRB-C model, we compared it with models such as Random Forest(RF), Backpropagation Neural Network(BPNN), K-Nearest Neighbor(KNN), Decision Tree(DT) and Long Short-Term Memory Network(LSTM). Table8illustrates the MSE, RMSE, MAE,and VAF of the models. The results showed that the IBRB-C model exhibits good performance compared to other models: The MSE value is 17.24% and 14.29% lower than RF and BPNN, respectively. The fitting plots of the prediction results of the models are shown in Figs.6,7,8,9and10.

Comparison of accuracy of IBRB-C with other models.

To further validate the robustness of the IBRB-C model, ten cycles of experiments were conducted using the IBRB-C, RF,and BPNN, which were the three best performing models. Figures11,12and13illustrate the MSE, RMSE and MAE for each model across the testing cycles. The mean values of MSE, RMSE and MAE for IBRB-C model are 0.0025, 0.0499, and 0.0372, respectively. It is evident that BPNN exhibits greater volatility compared to the other models, while IBRB-C demonstrates relatively stability. On the basis of the overall results, IBRB-C outperforms both RF and BPNN.

To further validate the generalizability of the IBRB-C model, a large-scale dataset was selected to predict the GPA of students. This dataset is publicly accessible viahttps://www.kaggle.com/datasets/rabieelkharoua/students-performance-dataset(accessed on 13 July 2024), which comprises 2,392 instances. After executing random forest method to analyze attribute importance, Study Time and Absences were chosen as input attributes of the IBRB-C model. The details of attributes are shown in Table9. According to teaching conventions, five values with segmented significance 0, 1, 2, 3 and 4 were chosen as output levels. 15 reference intervals were defined for each input attribute, combining the Kmeans++ algorithm with expert knowledge. The initial IBRB-C model was constructed as follows.

whereandrepresent the Study Time and Absences, respectively.represents the evaluation level of GPA as the prediction result of the model.

In this case study, the same comparative models and evaluation indicators with the subsubsection 4.1.5 are introduced. After conducting ten rounds of experiments, the result and fluctuation range of each evaluation indicator are shown in Table10and Fig.14.

Comparison of MSE, RMSE, and MAE of IBRB-C with other models.

It is evident that the IBRB-C model still shows the best performance. However, as the sample size of the dataset increases, the advantages of the IBRB-C model have declined. Compared to RF and BPNN, the MSE of IBRB-C decreases by approximately 8.3% and 5.5%, respectively. The possible reason is that with the surge in data volume, the number of belief rules maybe not sufficient, and the initial belief degrees need to be further finely set. Enhancing the effectiveness of the model for large-scale datasets could be a focus of future work. From the fluctuation range of indicators, consistent with the first case study, the IBRB-C model still maintains relatively good robustness compared to RF and BPNN. Furthermore, the prediction results of the LSTM model are significantly superior to its performance in small-sample datasets, while DT exhibited poor performance, with the MSE reaching 0.1462.

In summary, the IBRB-C model exhibits an superior predictive capability across both case studies. In comparison to traditional BRB, IBRB-C not only significantly refines the model structure, reduces the complexity of the rule base, but also greatly improves the accuracy of the results. The five other models introduced in comparative experiments are all commonly used tools in SPP. Nevertheless, due to their reliance on data-driven methodologies, these models are not well-suited for problems involving small sample sizes. Although BPNN and RF show good predictive ability, their results are not interpretable because of the nature of black-box models. The IBRB-C model is constructed through a lucid and transparent process, which is integrated with expert knowledge, enabling educators to easily comprehend how results are derived.

In this paper, an IBRB-C student performance prediction model is proposed. The model efficiently manages the combination explosion by employing an RF attribute selection method and segmenting reference intervals. Furthermore, the Kmeans++ algorithm is incorporated to address the constraints of expert experience in practical scenarios, while further research is still needed on how to reasonably select the parameters of the algorithm. By utilizing both expert knowledge and the clustering algorithm, interval boundary points are identified, facilitating a more reasonable construction of reference intervals and improving the model’s accuracy. The superiority of the IBRB-C model is validated through comparisons with other models. Owing to the integration of expert knowledge and quantitative information, the model achieves reliable results, particularly on small-scale datasets.

Future work will focus on achieving a balance between the interpretability and precision of the model. Furthermore, we intend to investigate the possible application of the model across other domains. As the number of input attributes increases, how to continue ensuring the prediction accuracy is worth to be studied. We are trying to compare more approaches for establishing reference intervals and develop methods for the dynamic adjustment of interval boundary points, with the objective of augmenting the model’s predictive capability.

This research was funded in part by Harbin Normal University Ph.D. Research Start-Up Gold Project under Grant XKB201906, in part by Heilongjiang Province Higher Education Teaching Reform Project under Grant SJGZ20210033, in part by the General Research Project on Higher Education Teaching Reform at Harbin Normal University under Grant XJGYFW2022006, and in part by the General Project of Graduate Education Reform and Research in Higher Education at Harbin Normal University in 2024 under Grant XJGYJSY202413.