With the aim of providing new tools for the design and assessment of synthetic routes, we describe an approach that mimics human interpretation whilst being highly amenable to machine implementation. The representation of molecular structures as 2D-coordinates derived from molecular similarity and complexity allows individual transformations to be viewed as vectors (reactant to product) where the magnitude and direction of travel can be used to assess and quantify efficiency. Using a dataset comprising 640k literature syntheses and 2.4m reactions taken from six journals between 2000 and 2020, we show that vectors derived in this way follow logical patterns when grouped by reaction type. Similarly, complete synthetic routes can be visualised as sequences of head-to-tail vectors traversing the range between starting material and target, allowing the efficiency with which this range is covered to be quantified. Three applications of the methodology are demonstrated: a comparison of CASP performance between two versions of AiZynthFinder for generating synthetic routes to 100k ChEMBL targets, analysis of predicted routes to a specific target molecule and, finally, a perspective on how the efficiency of published synthetic routes has changed over the last two decades.

Represenation of molecular structures using coordinates derived from similarity and complexity provides new approaches for vector-based assessment of synthetic transformations and routes.

The assessment and comparison of synthetic routes in organic chemistry can, after suitable training and experience, be readily accomplished by humans. Regardless of the criteria we are assessing against (cost, time, waste,etc.), someone “skilled in the art” can make a judgement as to whether the route represents a logical and efficient series of chemical transformations. This is typically achieved by considering the structural complexity of the target and assessing the number and type of transformations present, the order in which they are carried out and any reliance on protecting groups, auxiliaries,etc.

To do the same assessment on hundreds or thousands of synthetic routes, our suitably trained chemist quickly becomes the rate-limiting step. If empirical information (e.g., yield or waste) is available, then automation is trivial. If such information is either unavailable or unreliable, for example at the route design stage, the task becomes significantly more challenging due to the sparsity of meaningful or generally accepted metrics.

Step count – either longest linear sequence (LLS) or total – is by far the most common gauge against which synthetic routes are assessed. It is easy to conceptualise, machine-interpretable and a reasonable predictor of the quantitative metrics we are ultimately interested in. If defined and counted consistently, it is a reliable tool for comparing synthetic routes to a specified target – with fewer steps usually being better. Unfortunately, step counting is subject to major inconsistencies within the synthetic-organic community. It is clear that step-counting should stop when the desired target structure is reached, but there is no accepted convention for when to begin. Typically, step-counting begins at the first material (working backwards) that can be purchased, regardless of cost or availability. Alternatively, counting begins at the first material whose synthesis has been reported and deemed “simple”. These approaches are practical, since exhaustively step-counting back to hydrocarbons and biomass feedstock is unrealistic. The result is a high degree of inconsistency, however, with unspecified steps upstream of the starting materials being unaccounted for.

Assessment of a synthetic route based on its constituent reaction types is often informative and can be automated using commercial software such as NameRxn1or InfoChem.2Certain reaction types, for example redox manipulations or functional group interconversions (FGI), can be penalised in favour of “constructive” steps where bonds present in the target skeleton are formed. This strategy remains challenging since the classification of reactions is prone to failure, particularly when considering novel or tandem/cascade transformations. Furthermore, the binary assignment of transformations as productive or non-productive is somewhat limiting for the purposes of comparison or ranking.

With the above in mind, we have an interest in novel, automatable strategies for the assessment of synthetic routes, primarily at the route design stage, that are less reliant on step count and do not require empirical data (yield,etc.), atom mapping or reaction class assignment.

We described the use of similarity (structural commonality between two molecules) to gauge the progress of a synthetic route in 2024.20We would generally expect the starting material (sm) to be least similar to the route target and, as we move along the synthetic route, the reaction products (intermediates) should become increasingly similar to the route target; the final reaction in the route will necessarily deliver a product that is (identical to) the route target.

For comparison, we used an alternative measure of similarity: Maximum Common Edge Subgraph (MCES),24which can also be generated using SMILES strings.22This approach, summarised inFig. 2, compares two molecular structures (graphs) and finds the largest fragment, or MCES, that is present in both. Tanimoto similarity was again used, this time to compare the number of atoms and bonds in the MCES with those in the two comparator molecules. This metric also yields values (SMCES) between 0 (no similarity) and 1 (identical).

For a given synthetic route, similarity measures (SFP,SMCES) between the target and all preceding intermediates can be generated, as shown inFig. 3, for the synthesis of cell division cycle 25B (CDC25B) phosphatase inhibitor 6.25The starting fingerprint similarity value (SFP0.35) for naphthalene 1 is lower than the corresponding MCES similarity (SMCES0.50). In step (a) (Boc-protection), there is a drop in both similarity metrics (ΔSFP, ΔSMCES= −0.07). This is logical since six heavy atoms (COC[CH3]3) have been introduced in an arrangement that does not feature in the target structure 6. In step (b) (C–N coupling), aniline 3 is added to give compound 4 which has significant positive impact on target similarity (ΔSFP= +0.12, ΔSMCES= +0.28). In the following Boc-deprotection step (c), positive changes are again observed (ΔSFP= +0.25, ΔSMCES= +0.21) since the previously added COC(CH3)3fragment, which does not feature in target 6, is now being removed. The final transformation (d, ester hydrolysis/deprotection) shows a much lower change in MCES similarity (ΔSMCES= +0.08) compared to fingerprint similarity (ΔSFP= +0.36).

As synthetic chemists, we would identify only one of the four transformations as being “productive” (step b); the other three protecting group manipulations would be considered non-ideal.8The two similarity metrics both yield negative values (−ΔS) for the first step (a) and we would interpret this as non-productive since structurally, we are moving further away from our desired target. By this interpretation, however, both similarity metrics suggest steps (c and d), two deprotection operations, to be productive (+ΔS). In the case ofSFP, both deprotections have a larger, positive ΔSvalue than the C–N coupling reaction (b).

We can obtain a more logical interpretation by adding a second descriptor to describe the magnitude of structural change taking place in each transformation. The changes in molecular weight for each step along the route might suffice here but, for our purposes of route assessment, we are interested in more than mass variation. Ideally, we are aiming to generate some measure of route efficiency related to cost, waste, time,etc.and, since this information is seldom available directly, we will use a molecular complexity metric as a surrogate. There is an important assumption to recognise here: we are assuming the “complexity” of a molecule is proportional to how easily it is obtained or synthesised, and therefore the implicit cost, time and waste. For the most part this seems reasonable in that “complex” molecules, where there is a variety of atom types, bond orders and ring systems are generally more challenging to obtain than “less complex” molecules. We must be mindful, however, that this assumption does not hold for complex molecules that are readily available (e.g., steroids, carbohydrates).

There are numerous molecular complexity metrics that might be used here.26–32We will demonstrate our approach using a path-based complexity metric,CM*,33that we have recently shown to be useful as a predictor of process mass intensity (PMI).34This metric, which can be easily generated from a SMILES string,22does not make any special consideration of symmetry or chirality. For comparison, some of the analyses described below were repeated using spacial scores35in place ofCM*, leading to the same overall conclusions (see SI).

• The starting material must necessarily be to the left of the route target, since it must be less similar to the target than the target itself.

• The starting material is of lower complexity than the target (routes that do not satisfy this criterion were removed) and so the overall direction of travel from starting material to target will be in the direction +S(right) and +C(up).

• Transformations that are “productive” should therefore travel in the direction +S(right) and +C(up).

This 2D-coordinate system gives more information about the individual transformations than similarity alone. Step (a) (Boc-protection) is non-productive since complexity is added without an increase in target similarity, giving a vector that moves up and left. Step (b) (C–N coupling) is productive since it increases complexity and similarity toward that of the target (the vectors move up and right). The final deprotection operations (c and d) increase target similarity, as demonstrated inFig. 3, but are associated with a decrease in complexity. The vectors move down and right which signifies “wasted” complexity (molecular structure that was not needed) and can be viewed as non-productive. Compared to similarity alone, the use of similarity and complexity gives a more logical assessment of the individual transformations in the route.

Our next objective was to determine whether the basic trends identified above were consistent throughout the entire dataset, and whether certain reaction types result in vectors of a particular direction or magnitude. InFig. 5, a general synthetic route is depicted leading from starting materialAto targetT,viaintermediateB. Each individual step (AB,BT) is a vector with an associated change in similarity (ΔS) and complexity (ΔC), each of which can be positive or negative. The vectorvminrepresents the “ideal” route (if such a transformation could be achieved in a single step) leading directly fromAtoT. The magnitude of this line ‖vmin‖ represents the total amount of structural change or “work” that is required across the route. The “efficiency” (ηT), or contribution of each step to the overall route, is calculated as the scalar projection of its vector ontovmin.36Efficiency values can be negative (which effectively lengthensvmin) leaving more work for the remaining steps in the route to achieve.

Analysis of dataset reactions is shown inFig. 6. The distributions of values for ΔSFP, ΔSMCES, ΔnCandηT(derived fromSMCESvalues) are grouped by ten main reaction super-classes,37which do indeed display characteristic patterns.

• Carbon–carbon bond forming reactions are predominantly associated with +ΔSand +ΔCchanges, which indicates a productive reaction. The efficiencyηTvalues are the highest of all ten reaction super-classes.

• Heteroatom alkylation/arylation, heteroatom acylation and heterocycle formation show the same +ΔSand +ΔCmean values although the efficiencyηTvalues are slightly lower.

• Deprotection reactions yield −ΔnCvalues in conjunction with +ΔSvalues. The mean efficiency valueηTis positive but significantly less than for the four super-classes mentioned above.

• Redox, functional group interconversion (FGI) and addition (FGA) reactions show very low (close to zero) mean values for ΔS, ΔCandηT.

• Protection reactions are unique (and in keeping with our earlier observations) in that they are associated with −ΔSand +ΔCvalues. This is the only reaction super-class with a negative meanηTvalue.

Crucially, this definition of transformation efficiencyηTis not binary, in that reaction super-classes are not wholly designated as productive or non-productive. An acylation reaction, for example, can have low or negativeηTif the fragment being introduced represents a small proportion of the target structure (e.g., a methyl ester) or is not present at all in the target structure (e.g., a methyl ester that is functioning as a protecting group).

The distribution of ΔSMCESvalues is generally narrower than that of ΔSFP, particularly so for redox, FGI and FGA reactions. This is due to subtleties in the way that the fingerprint and MCES similarity algorithms operate. The fingerprint similarity approach is more sensitive to changes in bond order and can be significantly impacted by relatively small, single atom changes.38This can be illustrated by examining how mean ΔSvalues change depending on proximity (in terms of step count) to the route target, as shownFig. 7. The fingerprint based metricSFPis much more sensitive to the final changes taking place in the synthetic route (i.e., in the final step) than the alternativeSMCESmetric. It is possible to tune the way atom and bond types are distinguished in the fingerprint algorithm (or use a different fingerprint type), which would likely alleviate this problem, but we would suggest theSMCESmetric to be more suitable and will use it from hereon.

We can apply the various measures described above to whole synthetic routes. The synthetic range (‖vmin‖) is useful for comparing routes that begin at differing starting materials but end at the same target. Step count is by far the most common metric for comparing routes but there are no specific rules for what designates an acceptable starting material; this frequently leads to unfair or inaccurate comparisons. The use of ‖vmin‖ allows us to quantify how different a starting material is from a route target in terms of similarity and complexity.

Further to this, if we accept that (i)vminrepresents the shortest possible route (a single transformation) from starting material to route target and (ii) productive transformations should move towards the route target when plotted on similarity, complexity axes, then we might assess the efficiency of a route using simple path comparison, as shown inFig. 8.

Pyridol 12 is synthesised in four steps from 7.39The synthetic range of the route ‖vmin‖ is relatively large since the starting material is of lower complexity than the route target and bears limited similarity to it. The actual path of the route (a–d) is very close to the “ideal” pathvmin(note they-axis scale) and, as shown, a simple ratio of the magnitudes (lengths) of the ideal to actual path gives a measure of the efficiencyηR, where values can range from 0 (low efficiency) to 1 (perfect efficiency). This measure is both easy to conceptualise and there is no inherent need to examine or chemically interpret the actual transformations taking place. Routes that feature significant detours (e.g., protecting group manipulations, auxiliaries, complex leaving groups) are immediately obvious both mathematically and visually, as demonstrated inFig. 9. ToO-methylate 13 chemo- and regioselectively,40global protection and deprotection was necessary, eventually yieldingO-GlcNAcase inhibitor 18. The synthetic range of the route is very small (‖vmin‖ = 0.06) since little overall structural change is taking place whilst the actual path length (∑‖v‖) is very large due to the significant “detours”; the result is a low efficiency value (μR= 0.05).

This definition of route efficiency is wholly agnostic towards step count:ηRis not influenced by the number of steps, only the direction in which they travel. Whilst this partially satisfies our original aim, it introduces a significant shortcoming: transformations with very small or zero magnitude (e.g., redox, FGI, FGA) or those which offer small, incremental progress in a direction similar tovminare not penalised. Whilst we are trying to develop a theoretical analysis that is not governed by step count, we cannot ignore the fact that fewer steps is generally better. As shown inFig. 10, it is possible for the real path of a route to be identical tovminbut also comprise low-efficiency transformations. Conversion of alcohol 19 to alkene 23 is achieved with very high stereoselectivity.41In terms of introducing the heavy atoms present in the target skeleton, the entirety of the work is achieved in step (b) where iodide 20 is reacted with 1-trimethylsilylpropyne. Regarding similarity (SMCES) and complexity, steps a (FGI), c (alkyne migration) and d (hydrogenation) effect no change and display zero efficiencyηTvalues. The resulting route efficiencyηRis perfect, however, since our analysis ignores zero-magnitude vectors and effectively treats this as a single step transformation (19–23).

This shortcoming can be remedied by using a penalised function for route efficiency (ηPR) where the minimum path length for any single step is set to 0.1. As shown inFig. 10, this significantly reduces the efficiency for the synthesis of 23 (ηR= 1,ηPR= 0.51) but would have much less impact on the route to 12 (Fig. 8,ηR= 0.94,ηPR= 0.84). The minimum value of 0.1 (a somewhat arbitrary value chosen by inspection of the data inFig. 6) can, of course, be tuned to vary the extent to which low efficiency transformations are penalised. This penalised efficiency metric might be considered as an amalgam of atom economy3and ideality8since wasted molecular structure and inefficient transformations are disfavoured.

Up to this point, we have only discussed linear routes with no parallel synthetic branches. The definition of a convergent route is again somewhat subjective since it depends on whether any fragment incoming to the LLS is designated as a starting materiali.e., its synthesis is not included. Basic inspection of the dataset shows that many routes reported (or retrieved from Reaxys) as linear have complex incoming fragments part-way through the LLS and should therefore probably be designated as branched or convergent.

Regardless of this inconsistency,Fig. 11(left) shows that for all route lengths, convergent routes show higher penalised route efficiency valuesμPRthan linear routes and (Fig. 11, right) coupling reactions occurring at branch points are significantly more efficient (ηT) than those occurring at non-branch points. This is logical since the branch point in a convergent route, where two significant skeletal fragments come together, is likely to feature a large increase in similarity and complexity. The same efficiency analysis we have described for the LLS could also be carried out for any parallel synthetic branches, between its starting material and the branch point, to give a second efficiency measure for the route. As a final, expected observation,Fig. 11shows a steady decrease in route efficiency with route length.

To demonstrate the utility of our methodology with CASP output, we took a set of 100 000 molecules from ChEMBL42and generated predicted synthetic routes using two versions of the AiZynthFinder software.§43,44There was a slight difference in the success rate of each version: routes leading back to available starting materials (eMolecules)45were found for 69% and 71% of the targets for AiZynthFinder versions v1 and v4 respectively. For 64% of the targets, routes were found using both software versions. The total number of routes identified for these 64 400 common targets was 650 000 for v1 and 867 000 for v4.

As shown inFig. 12(top), if we consider only the best routes (one per target) by step count, there is negligible difference in the output of the two software versions. The output from the two software versions becomes distinguishable, however, using both synthetic range ‖vmin‖ (Fig. 12, middle) and penalised route efficiencyηPR(Fig. 12, bottom). The later version predicts routes that are, on average, of wider synthetic range. Since the collection of route targets is the same for both software versions, we can deduce that the route starting materials identified by version v4 are generally simpler and less similar to the route targets compared to version v1. The later version also predicts routes with slightly higher penalised route efficiency, which indicates a reduced reliance on non-productive transformations (redox, FGI, FGA,etc.) compared to version v1.

We can also use this methodology to assess and rank CASP routes, using androgen receptor antagonist 26 from the ChEMBL dataset as an example.46Construction of the central thiohydantoin unit is the main challenge and four predicted routes are shown inFig. 13. Route A is the joint shortest (two steps) and the strategy here is to purchase the thiohydantoin core. The starting material is therefore complex and of very high similarity to the route target, meaning the synthetic range ‖vmin‖ is very small (0.04, notice the difference in scale for the vector plot of route A). The two proposed transformations are both of low efficiency (oxidation and FGI) resulting in low route efficiency (ηR= 0.36) and even lower penalised route efficiency (ηPR= 0.19).

Route B is also two steps but, in comparison to route A, covers a much wider synthetic range since the starting material 27 is much less complex and less similar to 26. Both transformations are of high efficiency and the resulting route efficiency is almost perfect (ηR=ηPR= 0.99). We might speculate on the viability of the thiohydantoin-forming step (29 + 30) or whether the primary amide might interfere but, if successful, route B would be a highly efficient synthesis.

The remaining two routes are both longer (4 steps). Route C has wider synthetic range ‖vmin‖ but comprises two protecting group manipulations resulting in a lower route efficiency (ηPR= 0.77). Route D has narrower synthetic range but, with three construction reactions and one FGI, has a higher route efficiency (ηPR= 0.88).

We propose that the overall analysis is in keeping with human assessment: route B would be the most efficient (if viable), routes C and D are less efficient (but perhaps more viable) and route A is unlikely to be of use (the cost and availability of starting material 24 is unlikely to be significantly different to that of target 26).

As a final analysis,Fig. 14shows how synthetic range (‖vmin‖) and penalised route efficiency (ηPR) have changed between 2000 and 2020. The steady upward trend in both suggests that, based on our analysis, the synthetic-organic community is making increasingly complex route targets from simpler starting materials and doing so with less wasted complexity and reliance on low efficiency reactions.

The use of vectors comprising similarity and complexity components to describe synthetic transformations and routes has been shown to be useful for visualising and quantifying several qualities that we look for as organic chemists. Using a large dataset, we have demonstrated that the transformation efficiencies (ηT) associated with reaction super-classes follow logical trends. The specific similarity (Morgan fingerprint, MCES) and complexity metrics (CM*, SPS) we have used are easily interchangeable and alternative, or even custom-made fingerprints and/or complexity metrics, could be used, following the same principles. We have described how the synthetic range of a route can be represented as a vector and quantified using ‖vmin‖ to alleviate inconsistencies with step-counting and starting material designation. Penalised route efficiency (ηPR) has also been introduced to describe how effectively a given route traverses said range. This efficiency measure functions as an amalgam of atom economy and ideality.

To demonstrate the use of this methodology, we have shown how (i) large sets of CASP output from differing sources can be rapidly compared and contrasted and (ii) the automated assessment of individual CASP-derived routes to a given synthetic target can be achieved in a similar way to human interpretation.

Our mathematical approach to route analysis is highly amenable to further analysis. The impact of ordering in the sequence of transformations along a synthetic route ought to be of interest. We would instinctively suggest that similarity and complexity values should continually increase from starting material to target such that wasted complexity (due to yield losses) is minimised. Similarly, we might expect low-efficiency transformations to be better situated at the start of a route and high-efficiency transformations towards the end; these properties could be assessed using rank correlation metrics (e.g., Pearson,47Spearman48).

It should be stressed that the methodology described here, derived only from chemical structures and route topography is wholly theoretical and will always be inferior to real, empirical data such as cost, time and waste. Obtaining reliable empirical data for known transformations is problematic however and, in the case of unknown or theoretical transformations, Hendrickson's observation made in 1976 (ref.9) (“when planning an organic synthesis it is presently impossible to predict the yields of individual reactions, or indeed even whether they will succeed or fail”) remains pertinent today. Thus, we believe this methodology will be useful wherever assessment of synthetic transformations and routes is required.

This manuscript is an extension and rework of a previous submission (https://doi.org/10.26434/chemrxiv-2024-nbx35-v2);20some sections of text have been reused.