Portfolio optimization has long been a central topic in finance, dating back to the foundational work of Markowitz (1952) [1], who introduced the mean-variance (MV) model to balance expected return against risk. While this framework remains influential, its reliance on historical average returns and constant covariances limits its responsiveness in volatile or fast-changing markets [2]. In recent years, the integration of forecasting techniques, particularly those driven by machine learning, has emerged as a powerful enhancement to traditional portfolio theory [3–5].

Among various predictive techniques, deep learning models such as Long Short-Term Memory (LSTM) networks and One-Dimensional Convolutional Neural Networks (1D-CNN) have gained traction due to their ability to capture temporal patterns and non-linear dependencies in financial time series [6–8]. These models have demonstrated superior performance over traditional statistical methods such as ARIMA and Prophet in return prediction tasks, particularly in high-volatility and noisy market conditions. While newer architectures such as N‑BEATS offer strong performance and explicit interpretability through basis-expansion blocks [9], they are more computationally intensive and require careful tuning [10]. Similarly, attention‑based LSTM networks improve transparency in feature attribution but introduce additional complexity and parameter overhead compared to standard LSTM models [11]. In this study, we focus on LSTM and 1D-CNN due to their proven effectiveness in financial forecasting and their balance between predictive performance and model complexity, which has been validated in several prior works [5,8]. Building on this progress, recent studies have begun incorporating predicted returns into portfolio optimization frameworks, resulting in what is known as Mean-Variance with Forecasting (MVF) models [5,12]. These models extend the classical MV theory by replacing historical return estimates with model-based forecasts, and in some cases, by introducing prediction reliability as an additional optimization objective. Parallel to this development, risk-based strategies such as Risk Parity Portfolio (RPP) have emerged as viable alternatives for investors seeking balanced risk exposure without relying on potentially unstable return forecasts [13]. RPP focuses on equalizing the marginal contribution of each asset to total portfolio risk, offering a stable diversification method under volatile market conditions. For highly conservative investors, Maximum Drawdown Portfolio (MDP) models, originally proposed by Chekhlov et al. (2005) [14], provide direct control over downside risk by minimizing the worst-case loss over a specified horizon, a metric that resonates more intuitively with investor psychology than variance-based measures.

In recent years, deep learning has emerged as a powerful tool for financial forecasting, particularly in the context of stock return prediction. Unlike traditional time series models such as ARIMA or GARCH, deep learning methods are capable of capturing complex nonlinear patterns and long-term temporal dependencies in high-frequency and noisy financial data. These capabilities make them well-suited for predicting asset returns in dynamic and volatile markets.

Among the various deep learning architectures, LSTM networks have shown particular promise in modeling sequential financial data. As a variant of recurrent neural networks (RNNs), LSTM is designed to overcome the vanishing gradient problem by introducing memory cells that retain information over extended time intervals. This feature allows LSTM networks to learn both short- and long-term dependencies in time series data, which is essential for forecasting asset returns where past events may influence future movements. Studies such as Fischer et al. (2018) and Mehtab et al. (2020) [6,8] have demonstrated the effectiveness of LSTM in predicting stock prices and returns with greater accuracy than conventional machine learning methods. Another widely used architecture in financial prediction tasks is the 1D-CNN. Originally developed for pattern recognition in image and signal processing, 1D-CNN has been successfully adapted for time series applications due to its ability to detect local features through convolutional filters. In financial contexts, 1D-CNN models can identify short-term trends, abrupt changes, and repetitive patterns in return sequences, offering a complementary perspective to LSTM models. Empirical studies have confirmed the competitive performance of 1D-CNNs in financial forecasting, particularly when integrated into hybrid architectures or used for feature extraction [7,15].

Beyond these models, recent advances in deep learning have introduced architectures such as attention mechanisms and transformer-based models, which enable dynamic weighting of input sequences and improve the model’s ability to focus on relevant historical patterns. Transformer-based models, originally developed for natural language processing, have shown strong performance in financial forecasting tasks by capturing both long- and short-term dependencies more effectively than traditional RNN-based models. Studies such as Nayak et al. (2024) and Mozaffari et al. (2024) [16,17] reported promising results using transformer variants for volatility and return prediction in financial markets, as well as for general time series forecasting tasks. In addition, N-BEATS, a deep learning architecture specifically designed for time series forecasting, has gained attention for its interpretable structure and competitive forecasting accuracy without requiring extensive preprocessing or feature engineering. Oreshkin et al. (2019) [9] demonstrated that N-BEATS achieved state-of-the-art performance on several forecasting benchmarks, including financial time series. These models represent the latest developments in machine learning for stock market prediction and highlight the growing diversity of techniques available for financial forecasting.

The integration of financial forecasting models into portfolio optimization frameworks represents a key advancement in data-driven asset allocation. While traditional optimization approaches often rely on historical average returns, recent research emphasizes the value of incorporating predicted returns, particularly those generated by machine learning models, to create forward-looking portfolios that adapt to market dynamics [18]. The effectiveness of integrating forecasts into optimization depends not only on prediction accuracy but also on how the information is utilized. Empirical studies have shown that forecast-based strategies, when paired with appropriate optimization logic, can outperform purely historical models [19]. Moreover, the use of prediction uncertainty, such as confidence intervals or historical prediction error, can help mitigate the risks associated with model overfitting or unstable predictions.

This study aims to address these questions by conducting a comprehensive comparative analysis of three distinct portfolio optimization frameworks (MVF, RPP and MDP), each combined with forecasts generated by LSTM and 1D-CNN models. By evaluating these strategies using data from the VN-100 Index, the research offers insights into how forecasting accuracy and portfolio logic interact in practice, and how such integration supports different investor objectives in an emerging market setting.

This study utilizes a curated dataset based on the VN-100 Index, a widely recognized benchmark that captures the performance of the top 100 publicly traded companies across Vietnam’s principal stock exchanges. As one of the most comprehensive indicators of Vietnam’s equity market, the VN-100 offers valuable insights into both market sentiment and macroeconomic trends in an emerging Asian economy experiencing rapid financial development. Compared to other major Vietnamese indices, such as the VN-30 (which includes the 30 largest blue-chip firms) or the broader VN-Index (which includes all listed firms on HOSE), the VN-100 strikes a balance between breadth and investability. It captures over 80% of total market capitalization while maintaining sufficient liquidity for institutional relevance. While many previous studies on forecasting-based portfolio optimization have concentrated on developed markets such as the U.S., Europe, or China [5,19,20], research on emerging markets like Vietnam remains limited. The Vietnamese stock market, and particularly the VN-100 Index, presents distinct challenges, including high volatility, limited liquidity, and rapidly changing market dynamics [21,22]. These factors make it difficult for models to generalize and highlight the importance of flexible, data-driven methods in such environments. By anchoring the analysis to this index, we ensure that the models are evaluated on a broad and representative subset of the market. The initial data collection involved retrieving the daily closing prices of all VN-100 constituents over an eight-year span, from January 2017 through December 2024. To ensure the integrity and consistency of the dataset, we applied a set of eligibility filters: only those stocks with complete price histories throughout the observation period were retained. Firms that were delisted, newly listed mid-period, or exhibited significant gaps in trading records were excluded. This filtering process resulted in the exclusion of 41 stocks, leaving a final selection of 59 stocks. The final sample maintains representation across major sectors such as finance, real estate, consumer goods, and industrials, and includes mostly mid- to large-cap firms. This provided a robust and consistent dataset suitable for time series prediction and portfolio optimization.

wherexis the original value,μis the feature mean andσis the standard deviation. In our study, we employed z-score standardization because it is particularly suitable for models like LSTM and 1D-CNN that are sensitive to the scale of input features but benefit from data centered around zero [23]. This normalization ensures that input features are on a comparable scale, preventing those with larger numeric ranges from disproportionately influencing the learning process. We selected z-score standardization over min-max normalization because it is less sensitive to outliers and avoids compressing the range of the majority of data due to extreme values [15,24]. This consideration is particularly important in financial time series, where outliers may reflect genuine market behaviors rather than noise. Therefore, instead of excluding outliers, we retained them and applied z-score standardization to preserve the full distribution of observed data while maintaining numerical stability during model training.

The training set (2017–2021) was used to fit model parameters.

The validation set (2022) was used for hyperparameter tuning and model selection.

The test set (2023–2024) was reserved for final evaluation and performance reporting on unseen data.

This sequential approach preserves the temporal order of observations and safeguards against look-ahead bias, a common pitfall in financial modeling. The structure of this experimental design ensures that all models are assessed under realistic predictive conditions and that performance reflects genuine forecasting ability rather than overfitting or data leakage.

bf,bi,bo,bCare bias vectors corresponding to each gate and the candidate state and also are learnable parameters.

Together, these equations enable the LSTM unit to regulate which information is retained, forgotten, or output at each time step, allowing it to effectively capture long-term dependencies in sequential data. To optimize the forecasting performance of the LSTM model, a grid search strategy was employed to systematically evaluate different combinations of hyperparameters. This method ensures that the model achieves a suitable balance between underfitting and overfitting by selecting parameters that minimize validation loss.Table 1summarizes the hyperparameter values tested during grid search.

After extensive experimentation, the best configuration was found to consist of four hidden layers with four units per layer, a learning rate of 0.01, a batch size of 64, a dropout rate and recurrent dropout rate of 0.3, and the Adam optimizer. This configuration yielded the lowest average validation MAE and was therefore used to train the LSTM forecasting model across all stocks and generate return predictions.

This operation is applied repeatedly as the filter “slides” across the input sequence. Multiple filters can be used to capture different types of patterns in parallel. ReLU (Rectified Linear Unit) activation is typically applied after each convolution to introduce non-linearity. Pooling layers (e.g., max pooling) follow the convolution layers to reduce overfitting and computation by downsampling the feature maps. The resulting lower-dimensional representations are then flattened and passed through one or more dense layers to produce the final prediction. Similar to our approach with LSTM in this study, a grid search was conducted to tune the hyperparameters of the 1D-CNN.Table 2summarizes the range of hyperparameter values searched.

Through comprehensive experimentation, the most effective 1D-CNN architecture was identified as consisting of two convolutional layers with 32 filters each and a kernel size of 3, followed by a max pooling layer with a pooling size of 2, ReLU activation, and a dense layer with 64 units. The model used a dropout rate of 0.2, was trained with a batch size of 64 over 50 epochs, and optimized using the Adam optimizer with a learning rate of 0.01. This setup produced the lowest average validation MAE and was adopted to stock return prediction in this study.

ε―iis the average residual for asseti, representing abnormal returns based on forecast errors.

In this study, λ is set to 1 to match the original formulation and maintain balance. The MVF objective seeks to construct a portfolio that minimizes total risk while maximizing forecasted returns and potential abnormal returns. This model thus reflects a return-focused investment strategy informed by both predictive insights and risk control.

Overall, the RPP strategy offers a compelling alternative for moderate-risk investors. By eliminating dependence on unstable return forecasts and focusing on risk contributions, it provides a robust mechanism for constructing balanced portfolios that are resilient across various market conditions.

In this study, maximum drawdown is evaluated over historical return sequences informed by LSTM and 1D-CNN forecasts, allowing the optimization process to incorporate both forward-looking performance expectations and risk control. The MDP approach, by directly addressing the most adverse loss scenarios, aligns with the goals of conservative investors who prioritize capital preservation over short-term gains.

Accurate forecasting of stock returns is a critical component in the success of predictive portfolio optimization strategies. In this study, the performance of the return prediction models is evaluated using six evaluation metrics commonly employed in time series forecasting and financial prediction. These metrics are designed to evaluate both the magnitude and directional accuracy of the predicted returns. Specifically, we report the mean absolute error (MAE), mean squared error (MSE), and root mean squared error (RMSE) to assess prediction accuracy in terms of value deviation. Additionally, we include the total hit ratio (HR), positive-directional hit ratio (HR+), and negative-directional hit ratio (HR−) to measure the models’ ability to correctly predict the direction of returns. The definitions of these metrics are summarized inTable 3, whereyiis the actual observed return,y^iis the predicted return andnis the number of observations in the test set.

These metrics are computed for each stock across the test horizon and then averaged across the full set of assets. Lower values of MAE, MSE and RMSE indicate better predictive performance in terms of error magnitude, while higher values ofHR,HR+, andHR−reflect stronger directional accuracy. Note that this study designates MAE, MSE, and RMSE as the primary evaluation metrics, as they play a critical role in guiding portfolio construction based on return predictions.Table 4presents the performance comparison of the LSTM and 1D-CNN models based on such metrics.

In terms of average predictive accuracy, the LSTM model slightly outperforms the 1D-CNN model across all three magnitude-based error metrics. The mean MAE for LSTM is 1.56×10−2, compared to 1.60×10−2for 1D-CNN, indicating that LSTM generates marginally more precise predictions on average. Similarly, the MSE values suggest that LSTM better controls large forecast errors, with a lower mean MSE of 4.76×10−4relative to 5.03×10−4for 1D-CNN. This advantage is further reflected in the RMSE results, where LSTM achieves a value of 2.12×10−2, slightly lower than 2.18×10−2for 1D-CNN. Additionally, LSTM exhibits lower standard deviations in MAE, MSE, and RMSE, reflecting greater stability and reliability across different stocks and time periods. Beyond magnitude accuracy, directional prediction is another key consideration. The results show that both models perform similarly in directional forecasting. While the differences are marginal, they suggest that both models are similarly effective in capturing the direction of return movements under varying market conditions.

In summary, LSTM demonstrates better performance in minimizing forecast errors and exhibits more consistent behavior across evaluation metrics, making it a more robust choice for return prediction. Although directional metrics show only slight differences between the two models, LSTM’s superior performance in error-based evaluation and its lower prediction variability reinforce its suitability for integration into portfolio optimization frameworks.

To comprehensively assess the effectiveness of the proposed portfolio optimization frameworks, this section evaluates six strategy combinations that integrate two predictive models of LSTM and 1D-CNN with three optimization frameworks including MVF, RPP and MDP. The portfolio is rebalanced monthly (approximately every 20–22 trading days), in line with standard practice in empirical portfolio optimization studies [12]. For performance benchmarking, we assume no transaction costs and evaluate each strategy’s monthly excess return relative to the VN-100 Index over the test period from 2023 to 2024. The comparison includes the mean and standard deviation of monthly excess returns, information rate, total return as well as turnover rate, allowing for an in-depth assessment of how effectively each strategy balances risk and return. By referencing the VN-100, a representative index of the Vietnamese equity market, we contextualize the outcomes of each strategy against a relevant market benchmark, thereby enhancing interpretability of the results within a real-world investment setting. While transaction costs are excluded from this analysis for simplicity, it is important to recognize that frequent portfolio rebalancing may lead to substantial trading costs in practice. Such costs can reduce net returns and limit the real-world applicability of high-turnover strategies. To address this, we report the portfolio turnover rates alongside the performance metrics to provide additional insight into the trading intensity of each strategy. This enables a more comprehensive evaluation of the trade-offs between return potential and practical implementability.Table 5presents the performance comparison of the six portfolio strategies.

Among the strategies, LSTM+MDP achieves the highest total return of 52.459%, closely followed by LSTM+MVF with 50.775%. These results suggest that LSTM-based forecasts contribute more effectively to both capital preservation and growth compared to 1D-CNN. Notably, LSTM+MDP also yields a strong monthly excess return mean of 2.281% and an information ratio of 0.499, indicating its strength not only in raw performance but also in consistency relative to risk. Its turnover rate remains relatively high at 78.697%, which reflects more frequent rebalancing. The LSTM+MVF strategy shows a slightly lower return than LSTM+MDP but achieves the highest information ratio (0.526) among all strategies, suggesting strong risk-adjusted performance, with the highest turnover rate of 80.878%. To further examine the difference between these two top-performing strategies, we conducted a Mann-Whitney test on their monthly excess returns. The test results showed no statistically significant difference (p= 0.265), suggesting that the observed performance differences between LSTM+MDP and LSTM+MVF may not be statistically meaningful. Meanwhile, 1D-CNN+MVF trails its LSTM-based counterpart in both total return (45.499%) and information ratio (0.479), with a similarly high turnover rate of 80.236%, highlighting the advantage of LSTM in capturing time-series dynamics for return prediction. The RPP-based strategies, although more stable in terms of volatility, generate lower performance overall. LSTM+RPP and 1D-CNN+RPP report nearly identical results, with total returns of 34.034% and 33.824%, respectively, and information ratios of approximately 0.26, and moderate turnover rates of 54.137% and 60.224%, respectively. These findings align with the RPP framework’s objective of balanced risk allocation rather than aggressive return maximization. Interestingly, 1D-CNN+MDP, despite sharing the same conservative philosophy as its LSTM counterpart, underperforms significantly, yielding the lowest total return (33.877%) and the lowest information ratio (0.250), and a relatively moderate turnover rate of 55.454%. This suggests that MDP performance is highly sensitive to the accuracy and reliability of return forecasts, where LSTM consistently demonstrates superiority over 1D-CNN.

In addition, to rigorously assess whether the portfolio strategies achieved statistically significant outperformance relative to the VN-100 index, we conducted formal hypothesis tests on the excess returns of each portfolio. First, we applied the Shapiro-Wilk test to examine the normality of the excess return distributions. The results indicated that all portfolios exhibited non-normal return distributions. Consequently, we employed the non-parametric Wilcoxon signed-rank test to evaluate whether the median excess returns were significantly greater than zero. The test results revealed that all six portfolios achieved statistically significant outperformance with p-values below 0.05. These findings confirm that the returns of all strategies were not only higher than the benchmark on average but also statistically significant, reinforcing the robustness of the proposed predictive portfolio optimization frameworks.

To further illustrate the comparative performance of the six strategies,Fig 1plots the cumulative net value of each portfolio over the evaluation period. This visual representation captures the trajectory of wealth accumulation under each strategy, highlighting not only differences in final returns but also the evolution of gains and drawdowns over time.

Specifically, the LSTM+MDP strategy demonstrates superior performance in terms of consistent upward growth, achieving the highest final net value by the end of the test period. The LSTM+MVF strategy also shows strong performance, closely tracking MDP in the latter half of the period, albeit with more noticeable volatility. In contrast, the RPP-based strategies (both LSTM and 1D-CNN) exhibit relatively flat trajectories with smaller gains, aligning with their design goal of maintaining moderate risk exposure and balanced asset contributions. Notably, 1D-CNN-based strategies generally underperform their LSTM counterparts, with 1D-CNN+MDP showing significant drawdowns in the second half of 2024. This further supports the earlier observation that LSTM provides more stable and effective return forecasts, especially when integrated into optimization frameworks sensitive to extreme downside risk, such as MDP.

To complement the cumulative net value trajectories shown inFig 1,Figs 2and3provide a month-by-month breakdown of each strategy’s excess return during the years 2023 and 2024, respectively. These figures allow for a more granular examination of how each model-optimization combination performed across different market conditions.

From a practical perspective, the findings underscore the value of aligning forecasting models with portfolio construction techniques that reflect investor objectives. Incorporating model confidence (via prediction error) into the optimization process, as demonstrated in the MVF formulation, further enhances decision robustness. The study also affirms the viability of adopting deep learning frameworks in emerging markets such as Vietnam, where data quality and market dynamics present both challenges and opportunities. The results of this study offer practical guidance for investors seeking to align their portfolio strategies with both market conditions and personal risk profiles. For institutional investors with higher capital bases and greater tolerance for complexity and turnover, the LSTM+MVF strategy may be particularly attractive due to its superior risk-adjusted performance, despite its higher rebalancing intensity. In contrast, highly risk-averse individual investors may benefit more from the LSTM+MDP strategy, which provides stronger downside protection and capital preservation through maximum drawdown minimization. Meanwhile, moderate-risk investors, whether individuals or institutions, could consider RPP-based strategies for their stability, though they may trade off some return potential. Across all cases, our findings reinforce the importance of matching predictive modeling capabilities with optimization frameworks that reflect investor-specific goals and constraints. In practical settings, this may involve adjusting the frequency of rebalancing or incorporating simplified versions of the strategies for broader accessibility. It is important to note that this study focuses exclusively on forecasting expected returns, following common practice in prior portfolio optimization research. Although joint forecasting of both returns and covariances could potentially improve optimization outcomes, such an approach is beyond the scope of this study and is left for future research.

Future research may expand on this work by incorporating additional datasets from other markets to assess the robustness and generalizability of the proposed approach, and to determine whether the observed results are specific to Vietnam’s equity market or consistent across different financial environments. Extending the analysis to other asset classes (e.g., bonds or commodities) could further broaden the applicability of the framework. Introducing transaction cost modeling or extending the framework to multi-period and dynamic portfolio rebalancing, where portfolio decisions explicitly consider the path and long-term effects of rebalancing strategies, would help align the approach more closely with practical investment conditions. Moreover, incorporating traditional econometric models as benchmarks could offer valuable comparisons and help bridge the gap between deep learning-based methods and conventional approaches commonly used in financial research. In addition, future studies could address the interpretability of deep learning models by examining the underlying economic drivers of predictions, such as momentum, volatility, or other market-based factors. Applying explainable AI techniques (e.g., SHapley Additive exPlanations) could provide insights into feature importance and enhance the transparency of deep learning-driven portfolio decisions.