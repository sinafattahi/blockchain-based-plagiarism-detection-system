This paper presents a multi-person gait monitoring system designed for efficient operation in cluttered environments. The system demonstrates robust capabilities in tracking multiple closely spaced individuals and accurately extracting the walking speed, even in the presence of others. We address two significant challenges, including enhancing radar resolution and mitigating multipath effects in cluttered settings. Our method shows remarkable accuracy, with a maximum error of 0.33 m/s and a minimum of 0.005 m/s, as validated through 25 walking tests in a bedrest study. Its adaptability makes it a valuable clinical tool, offering insights for predicting underlying health issues in older adults.

Physical activity is an important lifestyle habit needed to achieve healthy aging, as it promotes autonomy and enhances quality of life1. Conversely, periods of severe inactivity, such as during bedrest (BR) for illnesses or hospitalization, induce dramatic changes to the human body that are often similar in magnitude to those seen over decades of normal aging2,3. Bedrest in otherwise healthy older individuals can lead to a reduction of muscle size and strength, changes in bone strength, and function of the heart and blood vessels1,4–6. All these factors combine to have a negative impact on the performance of activities of daily living, leading to physical function impairment and the development of frailty, a clinical condition associated with an increased risk for disease and death7,8. A simple indicator of health and function that can be easily utilized in everyday situations is walking speed, as it is a clear predictor of adverse health-related events9,10, and was reported to be slower following bedrest3,11,12.

To assess walking speed and extract other gait parameters, GaitRite mats13and Vicon motion capture systems14are widely used in clinical and research settings due to their high precision in gait analysis. GaitRite consists of pressure-sensitive mats that record footfall patterns, while Vicon employs marker-based optical tracking to capture body movements in 3D space with exceptional accuracy. However, both systems present significant challenges in practical deployment. GaitRite and Vicon are costly, requiring specialized hardware, which makes them less accessible for widespread clinical or in-home use. Vicon, in particular, involves an extensive setup with multiple cameras, controlled lighting conditions, and body markers, making it impractical for day-to-day gait assessments. Additionally, these systems require active user participation, which can alter natural gait patterns, and are confined to controlled lab settings, limiting their usability for continuous and real-world gait monitoring. Wearable devices could be potential easy-to-use solutions for gait assessments, but using them may cause feelings of burden and discomfort15. Additionally, while smartwatches and smartphones can provide gait features such as walking speed and stride length based on accelerometer and gyroscope data16, they rely on continuous user adherence, proper sensor placement, and frequent charging. These factors introduce inconsistencies in measurement and data loss due to non-compliance. In addition to wearable devices and optical motion capture systems, recent advancements in markerless gait analysis have leveraged Human Pose Estimation techniques, particularly Multiple Person Pose Estimation, for tracking gait parameters without the need for body markers17–19. One common drawback of all these systems is that these devices often cause people to (intentionally or unintentionally) change their gait patterns during assessments; existing methods are semi-subjective and require visiting the clinic. The problem for many patients, though, is that they cannot always get to a hospital or doctor’s office easily-whether it be because they live too far away or their illness prevents them from traveling easily.

To address these challenges, we use a contactless technology (i.e., a radar-based sensor) that operates passively in the background without requiring users to wear any devices or modify their behavior. Radar technology uses electromagnetic waves to detect and analyze motion, allowing for continuous gait monitoring in real-world environments such as homes, hospital hallways, conjugate living and long-term care facilities. Unlike traditional gait monitoring systems, radar does not require physical markers, direct user interaction, or controlled lighting conditions, making it well-suited for unobtrusive and long-term deployment. Compared to wearables and phone-based sensors, which rely on active user participation, proper placement, and battery maintenance, radar offers a fully passive solution that eliminates issues related to adherence and compliance. Additionally, wearable solutions monitor only the individual wearing the device, whereas radar-based monitoring can track multiple individuals simultaneously in a shared space. OpenPose-based gait tracking20, have also introduced markerless camera-based approaches for extracting gait parameters. These systems use body key-point estimation to calculate gait metrics, but they come with inherent limitations such as sensitivity to lighting conditions, occlusion issues, and privacy concerns. Unlike vision-based solutions, radar sensing is robust in various lighting conditions, operates effectively in cluttered environments, and preserves privacy by capturing motion data without recording identifiable visual information. Furthermore, real-time processing of high-resolution camera data requires substantial computational resources, whereas radar-based gait monitoring operates efficiently with lower data-processing overhead. By offering a non-intrusive, privacy-preserving, and continuous monitoring capability, our radar-based system presents a significant advancement in gait assessment, making it particularly valuable for in-home applications where long-term mobility tracking is essential.

Radar-based sensors have previously been used for gait assessment in many studies21–30. However, most radar systems for gait analysis applications have so far targeted only gait monitoring under ideal conditions, that is, on a single person who is walking in a low-clutter environment where no objects are present31–39. However, in real scenarios, such as at long-term care facilities or in clinical environments, there are many strong stationary clutter reflections, such as a hospital stretcher, a wheelchair, or other persons, which lead to difficulties in properly tracking moving targets40,41. To address the problems of tracking multiple people’s positions in a real-world setting (i.e., a multipath environment with heavy clutter), a novel iterative method based on unsupervised learning and advanced signal processing was developed to analyze the reflected signals and extracted walking speed through a hallway. We proposed advanced algorithms designed to address two significant challenges encountered in radar-based monitoring systems: low angular resolution and multipath effects. These challenges have traditionally hindered the system’s ability to distinguish between closely spaced walking subjects and to accurately interpret signals affected by ’ghosts’-artifacts resulting from interactions between the radar signals of moving individuals and stationary objects. Our algorithms enhance the radar’s capability to separate reflected signals from two individuals walking in close proximity, while also tracking their positions over time. This improvement enables more precise and reliable monitoring in dynamic environments. The system performance was evaluated on walking tests of 55-65-year-old adults who participated in a bedrest study2. Our system achieved remarkable accuracy, with a maximum and minimum error of 0.33 m/s and 0.005 m/s, respectively, compared to a stopwatch.

The results provided in this paper are the walking tests of a BR study, i.e., Microgravity Research Analogue (MRA): Understanding the Health Impact of Inactivity for the Benefit of Older Adults and Astronauts’ Initiative. The details of the study are provided in the method section. To validate and demonstrate the performance of our proposed system for gait extraction of participants with the coexistence of other people, Fig.1shows speed obtained by the radar empowered by our proposed algorithm compared to the stopwatch values. The results provided here are the outcome of 25 different tests performed before and after BR. As shown, there was a strong agreement between methods of calculating walking speed, demonstrating the high performance of the radar system in extracting walking speed of multiple people. It should be mentioned that we do not report the walking speeds of the second subject (the research assistant walking beside the participants) because the walking time of the second subject was not recorded by a stopwatch. To show more details, a repeated measures Bland-Altman plot of radar-stopwatch results is provided in Fig.2, which showcases the pairwise differences between simultaneous measures of radar and stopwatch measures while accounting for within participant variance42. Bias (i.e., mean difference) between methods was small with tight limits of agreement (bias:m/s, 95% limits of agreement:to 0.1261 m/s)). It should be mentioned that the difference here incorporates error inherent to the stopwatch method (a human pressed a button), and the important point is that there is no considerable difference between the two devices (0.0644 m/s difference with the radar is trivial). Radar data was not collected for all participants at all time points in this study; however, walking speed data derived from the stopwatch times were collected for all participants. A linear mixed model (R library: lmerTest43) with fixed effects of condition (i.e., control vs exercise) and time (i.e., PRE vs R + 1 vs R + 3 vs R − 4wk) and random effect of the participant was used to investigate the effects of bedrest and the exercise countermeasure on walking speed (Fig.3). A significant main effect of time () was observed, with pairwise comparisons of estimated marginal means (R library: emmeans44) and Bonferroni correction revealing that walking speed at R + 1 was slower than all other time points (PRE, R + 3, or R + 4wk). Critically, the exercise intervention had no effect on walking speed post-bedrest (interaction: p = 0.662).

Participants’ walking speed in the BR study obtained by radar empowered by the proposed STA algorithm (brown) and a stopwatch (blue).

Repeated measures Bland-Altman plot comparing the walking speed calculated from the stopwatch and radar data. A given colour represents a unique individual. The solid and dashed horizontal lines represent the bias and 95% limits of agreement.

Comparison of walking speed obtained by stopwatch before bedrest (PRE), the first day (R + 1), third day (R + 3) and 4 weeks (R + 4wk) after getting out of bed. A given colour represents a unique participant. *Different () from PRE.

In this study, we performed walking assessments of adults aged 55-65 years before and after 14 days of head-down bedrest to investigate the potential for radar technologies in clinical settings. Our approach is capable of tracking multiple people or extracting walking speed of a participant with the coexistence of other people. It can operate in a real-world setting and is robust in a cluttered environment. We showed that: (1) It is possible to differentiate between two individuals during a walk test (participant and assistant), (2) Such differentiation is possible during normal ambulation (i.e. without restricting path or gait during such assessments), (3) Radar technologies can accurately identify individuals and measure walking speed despite objects and clutter within the immediate environment.

We demonstrated that a radio sensor can facilitate passive, touchless, and meaningful assessment of gait with the coexistence of other people in a cluttered environment such as a hospital hallway. We presented evidence that the device can help in assessing the detection of walking decline over time. We note that our findings open up new possibilities that could improve clinical practice across all subjects in addition to older adults. Our study demonstrates the feasibility of continuously monitoring gait metrics at long-term care facilities, hospitals and individual homes in a passive manner. The monitoring device operates in the background, analyzing the reflection of radio signals. It tracks gait speed, with the potential to one day monitor daily fluctuations in speed and changes over time, which could be useful information for professional caregivers. Thus, without asking patients to leave their homes or actively measure themselves, doctors/caregivers could achieve safe and frequent health monitoring and deliver more personalized care. We believe that the main applications of our proposed multiple gait monitoring system are at long-term care facilities, retirement homes and hospitals, where radar systems could be utilized in hallways to passively measure walking speed in complex environments. Additionally, the system could be used as a tool to investigate behavioural symptoms and predict the risk of hospitalization. This technology might also have clinical utility for the assessment of individuals with Parkinson’s Disease who have traditionally been underserved, including those who live in rural areas and those with difficulty leaving home due to limited mobility or cognitive impairment.

To evaluate the proposed system, we conducted gait data collection in a hospital hallway environment, focusing on multi-person gait speed estimation under natural walking conditions. Unlike many publicly available gait datasets, such as the multimodal dataset18, which includes indoor and outdoor gait recordings from multiple sensors and cameras, our dataset specifically targets clinical settings, where gait monitoring is critical for patient mobility assessment and rehabilitation tracking. Additionally, large-scale datasets such as the multi-view gait dataset19, which is widely used for cross-view gait recognition, primarily focus on gait identification rather than real-time health monitoring applications. While existing datasets provide valuable benchmarks for pose-based gait analysis, they do not fully address real-world challenges of continuous, radar-based in-home gait monitoring in shared spaces.

Gait analysis has been widely applied in various domains beyond clinical and rehabilitation settings, including biometric identification, security, and sports science45,46. In biometric authentication, gait is considered a unique and unobtrusive characteristic for human identification and surveillance applications. Recent advancements in deep learning-based gait recognition leverage limb joint movement tracking and machine learning models to classify individuals based on their walking patterns19. These approaches have been explored for forensic investigations, access control, and anomaly detection, demonstrating the potential of gait as a non-contact biometric modality. Similarly, in sports biomechanics, gait analysis plays a crucial role in performance optimization, injury prevention, and rehabilitation. Early studies have explored the use of artificial intelligence in human gait analysis for assessing movement efficiency and athletic performance46. While the primary focus of this study was health-related gait monitoring, radar-based gait tracking has the potential to contribute to biometric security and sports science, particularly in motion tracking applications where privacy and non-intrusiveness are important considerations.

The study also has some limitations. Our previous work40successfully extracted various gait parameters, such as stride length, step length, and gait asymmetry, in single-person gait monitoring scenarios, both in hallway and in-home environments. However, for multi-person gait monitoring, we have not yet implemented these additional gait metrics. The primary challenge in this study stems from the fact that our previous gait detection methods relied on the increment and decrement of Doppler shifts during the swing and stance phases, which were extracted based on the torso’s position in the torso’s range cell. This approach works well when tracking a single individual, but in this study, where two individuals often occupy the same range bin, accurately isolating their respective range cells became significantly more complex. As a result, extracting fine-grained gait metrics for multiple people walking in close proximity requires further investigation and methodological refinements.

Second, the studied population is relatively small. Future studies with more participants are important to confirm the wide applicability of the results across diverse populations. Third, participants are monitored only in the hallway and only within the space covered by the radio device. Fourth, the evaluation of the system’s accuracy is limited by the precision of a stopwatch and the action of the research assistant walking and timing beside participants. Hence, a ground truth such as a GaitRite mat is needed to further validate the radar results. Fifth, gait speed is a general metric not specific to BR and could be affected by other factors. For example, the mode of participants, their interpretation of walking but not running, the hallway environment and the presence of our research assistant walking beside them; however, the instructions, research assistant acquiring the stopwatch times, and hallway environment were consistent for all data acquisition sessions. Lastly, the mechanisms underlying the decline in walking speed following BR and its recovery within 3 days of resuming ambulation after BR is beyond the scope of the current work, but is a topic for future work.

A key future direction is the integration of this radar-based gait monitoring system into existing clinical workflows. In healthcare environments such as hospitals, long-term care facilities, and rehabilitation centers, continuous gait assessment could provide early indicators of mobility decline and assist clinicians in monitoring post-hospitalization recovery. To facilitate this, future work will focus on validating the system across a broader range of clinical populations and developing an intuitive interface for seamless integration into electronic health records (EHRs) or remote patient monitoring platforms. Additionally, beyond gait speed estimation, this system has the potential to be expanded for fall detection and activity monitoring, which are critical for elderly care and independent living settings. While we have already implemented real-time fall detection in our system47, future research will focus on improving multi-person tracking in shared spaces and detecting subtle gait abnormalities that may indicate a high fall risk before an actual fall occurs.

Another important direction is the extraction of additional gait metrics, such as stride length, step length, gait variability, and asymmetry, particularly for multi-person environments where differentiating individuals’ gait parameters remains a challenge. From a technical standpoint, improving the system’s ability to function in complex and cluttered environments is another important area for exploration. This includes addressing challenges such as dynamic background noise and occlusions in highly populated settings. Furthermore, as the technology scales, optimizing processing efficiency to ensure low-latency real-time monitoring in large-scale deployments will be a priority. In terms of long-term use in healthcare, one of the main advantages of radar-based monitoring is its privacy-preserving nature, making it suitable for settings where camera-based solutions may not be acceptable. However, practical considerations such as deployment logistics, calibration across different environments, and integration with healthcare IT infrastructure will need to be addressed. Future studies will focus on evaluating long-term usability, clinician and patient acceptance, and system reliability in real-world deployments. By addressing these aspects, we aim to transition this technology from research to clinical practice, where it can enhance patient mobility assessment, improve fall prevention strategies, and contribute to long-term health monitoring.

Twenty-two healthy 55–65-year-old adults (11 women; age: 59 ± 3 years; mass: 70.1 ± 14.2 kg; height: 1.67 ± 0.09 m) participated in the 14-day BR study. All participants included in the study self-reported regularly performing at least 2.5 h of moderate-to-vigorous physical activity each week, and all female participants were post-menopausal. Half of the participants were inactive for the 14 days of BR, while the other half completed daily countermeasure exercises while in bed. This study was conducted according to the declaration of Helsinki, and all procedures were approved by the University of Waterloo’s Clinical Research Ethics Committee (ORE No. 40420) and McGill University Research Ethics Board (IRB00010120), as well as registered as a clinical trial (NCT04964999). All participants signed an informed consent form prior to participating in the study, and were made aware of their right to withdraw at any time.

This research study was carried out at the Center for Innovative Medicine (CIM) within the McGill University Health Centre Research Institute (RI-MUHC). Data collection for this research project spanned approximately six months from July 2021 to January 2022. Participants resided at the CIM for a consecutive period of 26 days, encompassing a 5-day adaptation period preceding bedrest (the term “PRE” is being used to show the walking speed for the adaptation period), followed by 14 days of continuous 6-degree head-down tilt bedrest, and concluding with a 7-day recovery phase. In the 7-day recovery phase, they underwent various measurements, including two walking tests called Recovery 1 and Recovery 3 for day 1 and day 3 after BR (shown as R + 1 and R + 3), respectively. Additionally, participants returned to the CIM for a single day of follow-up testing four weeks after completing the bed rest phase of the study. Walking tests were also conducted, called Recovery + 4 weeks (shown as R + 4 wk). Throughout the pre- and post-HDBR (head down bedrest) periods, participants retained the ability to stand, ambulate, and engage in their regular activities of daily living. However, during the 14 days of bedrest, all activities such as eating, toileting, reading, watching TV, and all personal hygiene procedures, including showering, teeth brushing, and shaving, were conducted while in bed.

Exercise Intervention (EX): The exercise intervention was carried out only during the 14-day BR period. All exercises were performed in bed. Participants performed 3 daily exercise sessions per day for a total of 1 h of exercise, which included high-intensity interval cycling, constant-load cycling, and upper- and lower-body resistive exercises, as previously described in detail2,48.

Control (CONT): Participants assigned to the control group underwent daily stretching and passive physiotherapy, as well as massages throughout the bedrest period.

Since this paper covers only the results of walking tests of the entire BR study, other tests performed on these participants within the CIM are reported elsewhere48–50. Walking tests were performed at 4 different timepoints: pre-bedrest (PRE), approximately 5 h after first finishing 14 days of bedrest (R + 1), 3 days after bedrest (R + 3), and during the 4-week follow-up visit (R + 4 wk). For the walking test, participants were instructed to walk as quickly as possible while maintaining safety, without running, and to complete four lengths of a 14-m hallway. Participants walked toward the radar, which started 15.5 m away from the radar. The schematic of the hallway walking test setup is provided in Fig.4.

Schematic of the multi-person hallway walking tests setup. The minimum and the maximum relative angle between the radar position and the hallway walls are1 and2, respectively.

The time to perform this test was recorded by a research assistant walking beside the participant using a stopwatch to compare the radar results. The research assistant walked beside participants to ensure their safety, as bedrest could alter their balance or gait. Figure5a shows the experimental setup for this study, while Fig.5b shows the corresponding detected clusters by DBSCAN (Density-Based Spatial Clustering of Applications with Noise)40. DBSCAN was chosen for clustering due to its effectiveness in detecting arbitrary-shaped clusters and filtering out noise in dense environments. While alternative methods such as HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise)51offer improved adaptability to varying densities, DBSCAN has demonstrated high accuracy in our previous work40and in this study, with predefined parameter values working reliably across different scenarios. Additionally, DBSCAN’s lower computational complexity makes it more suitable for real-time gait monitoring applications, ensuring efficiency and scalability for large-scale deployment without introducing significant processing delays.

Multi-person hallway walking tests (a) a snapshot of the video in the middle of walking and (b) corresponding detected subjects’ clusters and ghosts.

We used a commercially available mm-wave FMCW radar (AWR1443Boost, available from Texas Instruments) operating at 77–81 GHz52. It should be mentioned that our proposed algorithm in this paper could be paired with any other type of MIMO FMCW radar. Radar configuration along with a brief description of each parameter set for our experiment, are listed in Table1. Since our goal was to cover 14 m walking segments, the radar was configured for a maximum range of 16.4986 m.

Radar sensor and proposed gait extraction algorithm’s parameters.

Figure5illustrates the challenges associated with multipath effects in a cluttered environment. As depicted, the results shows not only the cluster of subjects but also several ghost clusters created by multipath reflections. This complexity underscores the need for an algorithm capable of removing ghost signals and distinguishing them from the direct signals reflected from the subjects. As demonstrated in our previous works53,54, one viable solution to mitigate multipath effects involves designing a lens antenna to sharpen the beam of the radiation patterns. However, implementing this solution in scenarios involving multiple people is not straightforward. Since the lens alters the phase of incoming waves, it is necessary to compensate for this phase change to accurately capture azimuth information and maintain the assumption that we have plane waves emanating from the subjects. In fact, all beamforming algorithms, including Capon, assume the incoming waves are plane waves, which is not the case when a lens is added. Therefore, phase compensation is essential to obtain an accurate range-azimuth heatmap. It is important to note that while the method we propose in this paper is radar-agnostic and can be paired with any radar type capable of generating range-azimuth heatmaps, the add-on lens was specifically designed for the AWR1443 radar operating at 79 GHz53. Consequently, we must repeat the simulations, measurements, and fabrication processes for the hyperbolic lens method for each new radar sensor. Although the same guidelines could be followed to determine the optimum lens parameters, the design process varies depending on the antenna type, number of antennas, radiation patterns, and frequency of operation. Moreover, this modification system requires significant design and fabrication effort, which is time-consuming and necessitates specialized equipment such as a Vector Network Analyzer (VNA) and a 3D printer, before deployment in real-life applications.

A block diagram of the proposed algorithm55for multi-person gait monitoring is illustrated in Fig.6. After performing range-FFT, mutual coupling reduction and the stationary clutter removal algorithm56,57, the remaining signals are direct signals from subjects and their multipath effects (i.e., time-varying clutter or ghosts)40. In received signals, there are two types of clutter effects: (1) stationary clutter and (2) time-varying clutter (ghosts)56. The direct reflection from stationary or unanimated objects is called stationary clutter. A stationary clutter removal algorithm is applied to the range profile to remove signals reflected from stationary clutter56. The average value of the signal is computed and subtracted from the aggregated signals; removing the average is equivalent to eliminating the stationary scatters. However, the interaction between a subject and stationary objects creates multipath or ghosting effects. Multipath occurs when a signal takes two or more paths from the transmitting antenna to the receiving antenna. The number and particular behavior of the multiple paths depends on the room structure and the presence of moving subjects. The multipath issue is more significant when the subjects, especially more than one subject, move in the space occupied by reflective objects since moving even a small object in such an environment causes changes in multipath reflections. Therefore, after performing the stationary clutter removal algorithm, the remaining signals in the range profile are direct signals from the subject, caused by chest motions (breathing) and other motions created by performing in-home activities, and multipath effects.

Proposed algorithm for multi-person gait monitoring.

Each target cluster (representing a subject) in a new frame is closest to its previous frame’s cluster, while ghost or other target clusters will be farther away due to the delay in electromagnetic waves.

The distance between the target cluster in two consecutive frames should not exceed a defined threshold, which is set based on the maximum expected walking speed of a person (= 4 m/s in this work).

Ghost clusters are not consistent throughout the entire frame and do not have the largest number of sub-clusters, even though they may appear consistently at several consecutive frames.

By utilizing these three principles, the STA algorithm aims to provide a more accurate and robust tracking method for subjects in real-world scenarios. The outcomes of each part of the diagram outlined in Fig.6are presented to provide a detailed understanding of the algorithm. As illustrated in Fig.7, after removing stationary clutter, a Capon beamformer algorithm57is applied to create a range-azimuth heatmap representing the density of reflected signals in the environment. Figure8a shows an example of a range-azimuth heatmap of the environment when two subjects just started to walk across the hallway. A screenshot of the video corresponding to frame #1 is provided in Fig.8b.

Representation of two walking subjects in a walking environment (a) range-azimuth heatmap of frame #1 obtained by the Capon beamformer, and (b) a snapshot of the video at the beginning of walking tests at frame #1.

The unsupervised machine learning algorithm (DBSCAN) is applied to cluster the output of 2D-CFAR (detect points) to find the exact positions of walking subjects over time (to track multiple subjects) and remove ghosts. Since sufficient information about the number of ghosting clusters was not known, the DBSCAN clustering algorithm was implemented to group the detected points after performing 2D-CFAR. Based on the performance of the different variables set for the DBSCAN parameters, epsilon neighbourhood,=2, and minpoints=8 were selected as optimized values. Figure9a shows the detected points after performing 2D-CFAR. Subjects’ direct signals are shown in a green rectangle, while other ghosts’ points are in red. Figure9b illustrates that the clusters were grouped into four after performing the DBSCAN. Even after examining a range of values to find the optimum values for the DBSCAN variables, the DBSCAN algorithm was unable to reliably group the detected points of multiple subjects walking at a very close distance into separate classes. The results were not satisfactory, as illustrated in Fig.9b where both subjects were clustered in one group (shown in purple). This is a particularly challenging scenario when subjects are walking at a very close distance, defined as a case where they are almost at the same range and azimuth. This is due to the radar angular resolution of 14°; at a range of 14 m away from the radar, subjects should be 3.3869 m away from each other to be distinguishable, which is impossible in a hallway or even in a room.

Representation of two walking subjects in the hallway environment (a) detected points by CFAR in frame #1 (b) clusters obtained by DBSCAN in frame #1.

As outlined in Fig.10, a 1D Azimuth Clustering Algorithm (1D-ACA) is proposed to address the radar low resolution and to provide a more effective solution for grouping the close subjects into separate clusters. The algorithm starts by taking the output from DBSCAN, which is an identified cluster and further divides it into multiple clusters. The division of the cluster is based on the detected points in the azimuth, and the grouping is performed if the epsilon neighbourhood of the detected points(= 10) contains more than a minimum number of neighbours in azimuth (minpoints = 10). The algorithm considers any detected points that do not satisfy the clustering algorithm’s conditions as noise points or “No-Cluster”, which are outliers that do not belong to any cluster. This 1D-ACA algorithm helps to effectively separate close subjects into distinct clusters, making it easier to analyze and process their gait information. A number of clusters are generated at each frame containing subjects’ and ghosts’ clusters. To show the outcome of the proposed 1D-ACA, the detected cluster of frame1 after performing the 1D-ACA is provided in Fig.10a. As shown, in addition to three ghost clusters that existed, four additional clusters were identified (Cluster 4 to Cluster 7). These clusters are associated with the two close subjects in frame1. The advanced STA algorithm is then required to track the objects over time and accurately obtain the subjects’ positions over time.

Representation of two walking subjects in a walking environment (a) seven detected clusters after performing the proposed 1D-Azimuth clustering in frame #1 (b) associated seven parents to the seven detected clusters in frame #1.

As shown in Fig.11, the STA algorithm takes the output of the 1D-ACA as input. The STA algorithm manages the identified clusters and organizes them into separate categories. The STA algorithm performs several tasks, including initialization of the detected clusters, confirming their existence, correcting any errors in classification, categorizing the clusters into different classes, and deleting any unnecessary clusters. Each detection is assigned to a specific class. If the detection cannot be assigned to an existing class, the STA algorithm creates a new class for it. This process helps keep track of each subject and organize the detected points into meaningful groups.

Details of the proposed STA algorithm (a) the procedure of allocating a new cluster that meets the criteria to previous classes and (b) the procedure of creating a new class for a new cluster that does not meet the condition to be allocated to the previous classes.

To initialize the process, as shown in Fig.11a, the STA algorithm divides allmnumber of detected clusters intomnumber of classes at frame1. All these clusters are the parent of their class,. In the next frame, for every newly identified cluster, the Euclidean distance matrix between this cluster andof all classes is calculated and sorted.

As detailed in Fig.11a, a new cluster will be associated with a previous class if their calculated Euclidean has the minimum values among other sorted distances, which should also be less than the defined threshold (based on the maximum defined). For the next frames, each newly added sub-cluster to a classis consideredof that class, and other old clusters are children of class. As detailed in Fig.11b, if a new cluster does not satisfy these conditions to be categorized to a previous class, it will be a parent of a new class. This process is iterated through the entire frame. In total,mnumber of classes withnumber of children/sub-clusters is created. Figure12shows all detected clusters throughout the entire walking lap. Two classes with the largest number of children are selected as walking subjects’ clusters (target classes). Target classes are constructed with the size of a total number of entire frames. Target classes might have several empty or missed sub-clusters. The tracking algorithm searches in other old classes and checks if any of its children is miscategorized in another class to fill in the missed children. This is done based on the estimated range-azimuth values of the corresponding sub-cluster and the expected speed. If any sub-cluster in other old classes satisfies its conditions, then the detected child from old classes will be identified as a child of the missed frame of the target class. Otherwise, it will remain as a missed child in the target cluster. The missed child is because a subject’s reflection is not detected in some frames or concealed under other stronger signals, such as ghosts or direct signals from another walking subject; a subject being tracked might not appear in every single frame. Finally, the target classes, includingnumber of children, represent all points detected from two walking subjects. Based on the detected points over the entire frames (Nnumber of frames) and the corresponding time, a trajectory of subjects is acquired (range and azimuth). Figure13shows the detected clusters of the two subjects walking in the hallway. The movement trajectory is analyzed with respect to time to calculate the participant’s gait speed. Having the subject’s position over time, the overall velocity of walking (i.e., the distance a walking subject travels over a second (velocity = position/time)) can be calculated.

All detected clusters throughout the entire walking lap.

Subjects’ clusters detected by the proposed STA algorithm.

In this paper, we introduce a multi-person gait monitoring system designed for operation in cluttered environments. The proposed method allows extraction of walking speed in multiple closely spaced subjects simultaneously, which is distinct from previous approaches in which speed of only one subject was obtained. The capabilities of the approach mean that it also has the potential to be used for other in-home applications, including people counting, fall detection, activity level and human gait monitoring and offers excellent long-term care benefits. Its robust performance in real-world, cluttered settings makes it a valuable tool, potentially serving as a clinical aid for predicting health issues in individuals undergoing testing. The system represents a noteworthy advancement in the development of autonomous and continuous human-monitoring systems. If possible, these technologies could be used as a clinical tool for the prediction of health problems in tested individuals.

We would like to thank the participants, members of the bedrest study staff, MUHC administrators, and technical research staff that made possible the achievement of this study.