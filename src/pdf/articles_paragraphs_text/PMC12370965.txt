Prostate cancer remains a significant public health concern, with a substantial proportion of patients experiencing biochemical recurrence (BCR) after radical prostatectomy (RP). Traditional risk models, such as CAPRA-S, have demonstrated moderate predictive performance, highlighting the need for more accurate tools. This study aimed to develop a machine learning (ML) model to predict BCR in patients undergoing robot-assisted laparoscopic RP (RALP). A retrospective cohort of 1024 (476 BCR+ and 548 BCR−) patients was analyzed, using a balanced dataset of 25 clinical and pathological variables. Five ML classifiers were evaluated, with XGBoost emerging as the best-performing model, achieving 84% accuracy and an AUC of 0.91. Model validation on an independent dataset of 96 patients confirmed its robustness, with an AUC of 0.89. Decision and calibration curves demonstrated the superior clinical applicability of XGBoost compared to CAPRA-S, indicating improved risk stratification and potential to optimize treatment decisions. The study underscores the value of ML in refining prognosis prediction and guiding therapeutic strategies in prostate cancer. While further validation in diverse clinical settings is necessary, these findings support the integration of ML-based models into clinical decision-making to enhance personalized patient management.

Prostate cancer (PCa) is a major public health issue in developed countries1. Radical prostatectomy (RP) is associated with a lower incidence of disease progression than active monitoring2,3. However, one-third of patients experience biochemical recurrence (BCR) after the procedure4,5. Previous studies have shown that the survival rate of patients with BCR is 20% lower after a ten-year follow-up, with a higher risk of metastasis and castration resistance5,6.

The European Association of Urology and European Society for Radiotherapy and Oncology recommend that physicians should discuss the possibility of administering radiotherapy to patients with adverse pathologic findings, as early treatment after RP may reduce the risk of mortality in these patients7. Nevertheless, not all patients will benefit from radiotherapy because some will never experience BCR8. As a result, various risk models have been developed to predict PCa prognosis in patients who undergo RP9,10.

D’Amico performed the first risk estimate using the Cox proportional hazards regression analysis, in which he noted differences between low-risk, intermediate-risk, and high-risk patients when estimating the PSA level 5 years after treatment9. Kattan developed a nomogram using Cox proportional hazard regression analysis to predict treatment failure after 5 years in patients with localized PCa after RP. He used preoperative PSA variables, cT stage, and biopsy Gleason scores and observed that there was only a 5% probability of patients not experiencing BCR 5 years after treatment when the total score was higher than 18011. Cooperberg presented the CAPRA score also using Cox proportional hazards regression analysis. He assigned points to PSA level, Gleason score, cT stage, age, and percentage of biopsy involvement. They found that the recurrence-free survival after 5 years of treatment was only 8% for a high CAPRA-S score12.

Although the accuracy of the previously mentioned models has been validated in different cohorts and exceeds manual decision-making capabilities, their performance is still subpar, with an area under the receiver operating characteristic (ROC) curve (AUC) 0.72–0.7513,14. Therefore, new, highly accurate tools are needed to detect PCa recurrence in patients at risk of BCR to provide effective treatment, maximize benefits, and reduce risks. The need to correctly classify patients living with cancer has led us to study the application of machine learning (ML) to predict disease progression and aid in the establishment of appropriate treatment regimens. The ability of ML tools to detect key features in complex datasets highlights the importance of this study15.

The main objective of this study was to build an ML model capable of predicting BCR in patients with PCa who underwent robot-assisted laparoscopic radical prostatectomy (RALP), with over 80% accuracy and an AUC higher than 85%. The secondary objectives were to identify the most important variables, preprocess and fine-tune the data, determine the appropriate training pattern, train and test different algorithms, compare their prediction performances, and complete the validation stage. Finally, we compared the best-performing ML model with the statistical model CAPRA-S used in urology because of the similarity in the variables analyzed and the temporality of the relapsed patients.

This analytical observational study was conducted in a retrospective cohort of male patients diagnosed with localized PCa who underwent RALP between January 2008 and December 2020. Patients were registered in the Italian de Buenos Aires Hospital database. The inclusion criteria were individuals who experienced BCR after RALP with or without lymphadenectomy and without hormone blockade and/or radiotherapy. BCR was defined as PSA ≥ 0.2 ng/ml after RP. The patients were followed-up for a minimum of 2 years to determine if there was no cancer recurrence. To develop an effective ML model, a class-balanced database was created to optimize its capability. A total of 476 patients with BCR were selected, and undersampling techniques were applied to a group of 1,827 patients without recurrence, resulting in 548 patients.

The following independent variables and attributes were analyzed: age; comorbidities: diabetes (DBT), hypertension, and total body mass index; postsurgical tumor histopathology report: Gleason score, pathological stage, percentage of tumor in prostate gland, and tumor volume in the region of interest (ROI); lymphovascular invasion; surgical margins; prostate capsule penetration; extraprostatic disease; positive lymph nodes; digital rectal exam; type of surgery: RALP with or without lymph node dissection; year of surgery; neurovascular bundle preservation; PSA before RP; PSA nadir; D’amico risk groups; and MRI before RP with the PI-RADS score. The class variable is BCR (Online Appendix1, Table S-I).

Data preprocessing and automatic attribute selection analyses were performed on the generated tabular database to obtain the optimal input pattern (Online Appendix1). Five classifiers were used to build the AI models: artificial neural networks (ANN), support vector machines (SVM), random forests (RF), deep neural networks (DNN), and extreme gradient boosting (XGBoost) (Online Appendix2, Table S-III). The attributes and input patterns used were the same for all classifiers. The cases were divided as follows: 70% and 30% in the training and testing stage, respectively. Additionally, tenfold cross-validation (CV) was applied to enhance the model’s robustness and ensure consistent performance across data subsets. Hyperparameters were tuned using grid search. In each model, the following metrics were assessed: percentage of accurately classified patients (accuracy), precision, sensitivity (recall), and AUC. Decision curve was created to assess the clinical net benefit of treating patients based on the models, comparing the “treat none” and “treat all” strategies. The calibration curve was used to measure the agreement between the model’s predicted probabilities and observed outcomes.

To assess the applicability of the model, a validation stage was conducted with 96 patients who were not included in the original model development. In addition, owing to the similarity in the analyzed variables and temporality of relapsed patients, the performance of the best AI model was compared with that of CAPRA-S12, a traditional prediction scoring tool commonly used in urology to estimate disease recurrence among patients with PCa.

Python (https://www.python.org/) and R (https://www.R-project.org/) were used for data pre-processing, exploratory statistical analysis, attribute selection, and classifier construction. The libraries used in R included dplyr, magrittr, caret, random forest, XGBoost, and pROC. The libraries used in Python include Pandas, NumPy, Matplotlib, Sklearn, TensorFlow, and Keras. From a statistical standpoint, the risk of each independent variable was evaluated against class. The odds ratio (OR) was assessed cross-sectionally, followed by risk variation over time using hazard ratio (HR). In both cases, the corresponding 95% confidence intervals were calculated. The level of statistical significance was set at α = 0.05. Patients enrolled in the study voluntarily signed an informed consent form regarding the use of their data in accordance with the principles of the Declaration of Helsinki, complying with the standards and protocols for conducting human research established by the Ethics Committee of the Italian Hospital of Buenos Aires. This study adhered to the TRIPOD-AI guidelines for transparent reporting and the PROBAST-AI tool for assessing risk of bias in diagnostic and prognostic prediction models based on artificial intelligence16,17.

We started with a tabular database containing 25 independent variables and one temporal variable (time in months until relapse). The mean age of the non-relapsed group was 60 ± 6.4 years, and that of the relapsed group was 61.1 ± 6.5 years. The median time to relapse was 12 months.

Of the 25 independent variables, those that showed neither clinically meaningful (expert knowledge) nor statistical significance were excluded, along with those that were irrelevant to automatic attribute selection. At this stage, variables related to penetration and the postoperative Gleason score consistently ranked the highest among the top attributes, as they provided the most information gain for the predictive models (Online Appendix1). Table1presents the risk analyses of the 16 variables used to build the model. The variables selected to train the predictive models could differentiate between cohorts with statistical significance.

Risk assessment between predictor variables and class.

Ref, Reference category; OR, Unadjusted Odds Ratio obtained by binary logistic regression; HR, Unadjusted Hazard Ratio obtained by Cox regression.

In the classification model building phase, the ANN yielded the following results on the training dataset: 91.6% sensitivity (recall), 91.6% precision, 91.5% accuracy, and an AUC of 0.96. The SVM algorithm delivered the following results on the training dataset: 82% sensitivity (recall), 83.1% precision, 82% accuracy, and an AUC of 0.82. The RF algorithm obtained the following results on the training dataset: 80.4% sensitivity (recall), 80.4% precision, 80.3% accuracy, and AUC of 0.88. The metrics of the algorithms for the test dataset are presented in Table2. The ANN model achieved an AUC of 0.96 on the training set, which dropped to 0.84 during testing, consistent with overfitting. This likely reflects the model’s high capacity relative to the size of the training folds, enabling it to learn noise despite regularization efforts such as early stopping.

Performance metrics from machine learning and deep learning models.

After observing the performance of RF and considering it a tree-based algorithm, we decided to use the XGBoost algorithm. The testing dataset showed an 84% sensitivity (recall), 84% precision, 84% accuracy, and an AUC of 0.91. (Online Appendix2). In addition, a deep learning algorithm was trained to compare its performance with the best ML model, which showed lower metrics than the best ML algorithm (Table2). The best ML algorithm was validated using a novel dataset comprising 96 patients. XGBoost correctly classified 82% of the cases, with an AUC of 0.89 (Fig.1a). Figure2illustrates the variable importance analysis of the XGBoost model. SHAP analysis confirmed model robustness and interpretability by highlighting postoperative Gleason score, prostate capsule infiltration, and surgical margins as the top predictors (Fig.3).

Validation of the model. (a) ROC curves illustrating discriminatory performance. (b) Calibration plot showing agreement between predicted and observed risks. (c) Decision-curve analysis comparing net clinical benefit of the XGBoost model with CAPRA-S and default strategies.

The decision curve demonstrates that the XGBoost model provides a higher clinical net benefit across a broad range of probability thresholds, suggesting that this model is more effective in determining when to intervene in patients. Finally, the calibration curve shows that the predictions from XGBoost are better calibrated compared to those of CAPRA, as the blue line is closer to the perfect calibration line. (Fig.1b,c).

Finally, CAPRA-S outputs were calculated for progression at 3 years, with a score of 6 as the cutoff point. This resulted in a dichotomous output for the score, where values 0–6 indicated a low probability of recurrence, and values 7–12 indicated a high probability of recurrence. The outputs were calculated for 307 cases by using the XGBoost test dataset with CV. By comparing the results with the actual recurrence outcomes, we obtained 77% sensitivity, 76% precision, 77.2% accuracy, and an AUC of 0.78 (Fig.1a).

The European Association of Urology recommends adjuvant radiation following RP for patients with adverse pathology7. Notwithstanding, a systematic review of risk stratification for patients with recurrence after RP did not provide evidence that the proposed risk factors should be used in clinical practice to tailor treatment. Furthermore, after RP, the only risk factors with moderate levels of evidence were pT3 stage, Gleason grade 4, surgical margins and pre-salvage PSA levels exceeding 0.5 ng/ml18.

There is little evidence on the use of ML tools to assess relapsing patients after RP19. Correctly classifying patients who experience BCR is extremely important, as adjuvant therapies carry adverse effects. Unfortunately, the recommended prognostic tools have low discriminative capacity20,21.

Wong analyzed 19 variables in 338 patients who underwent RALP, 25 of whom experienced BCR over a follow-up period of 12 months. This analysis resulted in AUCs of 0.903, 0.924, and 0.940 with the k-nearest neighbors (kNN), RF, and RL algorithms, respectively. However, the models were generated based on information captured from a small database. Therefore, it is unknown whether this assessment featured an overfitting of the ML algorithms used22. In a similar study, Eski analyzed 37 variables in 368 patients who underwent RALP, 73 of whom experienced BCR over a follow-up period of 35 months. The authors obtained better results with kNN, an AUC of 0.93, an AUC of 0.95 RF, and an AUC of 0.93. However, the study was poorly designed, and thus, the results were unreliable23.

Tan analyzed 18 variables in 1,130 patients who underwent RALP, 176 of whom experienced BCR over a follow-up period of 70 months. Three ML models were applied to predict BCR, including data validation and a 70/30 split strategy. The following results were obtained: 0.823 precision and an AUC of 0.894 using naïve Bayes, 0.838 precision and an AUC of 0.887 with RF, and 0.810 precision and an AUC of 0.852 with SVM 60 months after BCR. Tan also compared statistical risk models against ML models and found that the ML models were comparable to Kattan’s nomogram24.

Finally, Lee conducted an ML study assessing 13 variables in 5,114 patients who underwent RP, 1,207 of whom experienced BCR over a follow-up period of 60 months. They used an 80/20 split strategy for the data and obtained the following results: 0.719 precision and AUC of 0.805 with RF, 0.705 precision and AUC of 0.796 with ANN, and 0.740 precision and AUC of 0.803 with RL25.

The aforementioned studies have generally found that tree-based algorithms exhibit good prediction performance. In this study, the incorporation of RF as the initial model provided consistent results. Transitioning to the XGBoost ensemble method improved the performance metrics, thereby consolidating its position as the best model in this scenario. XGBoost outperformed DNN likely due to better regularization, early stopping, and superior handling of tabular structured data with moderate sample size.

The ability to visualize variable importance, as highlighted in the analysis of the XGBoost-based model, underscores the ability of these algorithms to identify key features for BCR prediction among patients with PCa. It is essential for healthcare professionals to understand and rely on the model’s decisions in a clinical setting. Moreover, the robustness of the XGBoost algorithm in the validation of a novel patient dataset supports its generalization capabilities, making it potentially applicable in dynamic clinical settings.

Previous oncology studies have highlighted the ability of tree-based algorithms with ensemble methods to handle complex datasets and extract nonlinear patterns, thus improving the prediction of clinically relevant events26–28. This may result in a more accurate assessment of the probability of recurrence in post-RALP patients with PCa.

In the present project, the analysis of the decision curves highlights the superiority of the AI model based on XGBoost over the CAPRA-S model in predicting BCR. While CAPRA-S offers moderate performance, the net clinical benefit of the XGBoost model, shown in the decision curve, suggests that using this model could avoid both overtreatment and undertreatment of patients. These findings align with previous studies that have demonstrated that ML models can outperform traditional models like CAPRA in complex clinical scenarios24. Model outputs were stratified into clinically actionable risk categories: > 80% as high risk (requiring intensified PSA monitoring and early salvage evaluation), < 20% as low risk (standard surveillance), and 20–80% as intermediate risk (individualized follow-up). These thresholds correspond to the net benefit range observed in the decision curve analysis (Fig.1), where the XGBoost model outperformed CAPRA-S, particularly among patients with recurrence probabilities between 30 and 70%. In this intermediate-risk group, where clinical decisions are often uncertain, the model offers refined stratification, supporting more selective intervention and potentially reducing overtreatment.

The main limitation of this study is its retrospective, single-centre design, which may reduce the generalisability of the findings to other populations and clinical settings. Further constraints include potential over-regularisation introduced by class sub-sampling during model training, reliance on the accuracy and completeness of electronic health-record coding, and the absence of both genomic variables and imaging data, elements that could provide additional information and enhance the model’s predictive power. However, these results reinforce the need to consider advanced ML-based approaches to assess and predict clinical outcomes in post-RALP patients with BCR, providing a personalized perspective for counseling and treatment. It is important to conduct additional research to optimize these models and understand their limitations in the clinical setting. Future steps will include external validation using public datasets such as TCGA-PRAD, and the application of transfer learning techniques to evaluate model adaptability when incorporating molecular or imaging biomarkers. Continuous collaboration between clinical experts and data scientists is key to achieve effective medical decision-making.

Although the model included patients aged 18 to 80 years, certain subgroups such as older adults may be underrepresented. This raises potential concerns regarding algorithmic bias, as an uneven distribution of demographic or clinical characteristics could affect prediction reliability across populations. Future studies should ensure diverse and representative samples to support equitable clinical applicability of AI-based models.

The clinical applicability of our model for predicting BCR after RP is strengthened by the use of postoperative Gleason score, lymphovascular invasion, and tumor percentage, which have demonstrated strong associations with prostate cancer prognosis. These predictors not only enhance the interpretability of the model but also align with existing clinical assessment protocols, making the model results directly actionable for healthcare providers. The XGBoost model provides an individualised probability of BCR during the first 24 months after surgery. In clinical practice this probability can stratify patients into higher and lower BCR risk groups. A higher predicted risk supports more intensive management, including earlier consideration of salvage radiotherapy before the prostate-specific antigen rises appreciably, PSA surveillance every three months instead of every six months, and shared-decision counselling about adjuvant androgen deprivation therapy or enrolment in clinical trials. In contrast, a lower predicted risk justifies a more conservative approach in which imaging and laboratory follow-up are scheduled less frequently, thereby reducing patient burden and avoiding unnecessary interventions. Because the score is calculated from clinicopathological variables already stored in the electronic health record, it can be generated automatically at discharge and displayed alongside established tools such as CAPRA-S, giving clinicians an additional data driven aid to personalise postoperative care.

To facilitate real-world integration, we developed a prototype web-based risk calculator using Python and Streamlit. (Online Appendix3, Fig. 1) It is currently used internally by the physicians in our Urology Department for prospective validation in new post-RARP patients. This pilot use enables real-time risk estimation at the point of care and allows comparison of model predictions with actual outcomes to iteratively assess clinical utility.

Further studies across diverse populations and clinical environments are essential to validate the model’s robustness and ensure its applicability in a wider range of clinical contexts.