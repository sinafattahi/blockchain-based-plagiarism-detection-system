With the growing variety of pharmacological compounds and the increasing need for polypharmacy, accurately predicting drug-drug interactions (DDIs) is essential to ensure both treatment efficacy and patient safety. Beneficial DDIs can enhance therapeutic outcomes. In contrast, adverse interactions may result in toxicity, reduced efficacy, or even fatality. Thus, the accurate prediction of DDIs is paramount. Building on recent advancements in graph neural network (GNN) architectures, this paper extends prior research, such as the SAGE GNN model, Graph Attention Network model, and Graph Diffusion Network model, by integrating advanced techniques such as skip connections, post-processing layers, and optimized training methods. It start from basic GNN to buld more advanced models such as based on Adaptive Graph Diffusion model. Our experimental results shows based on evaluation on 3 different drug-drug interaction dataset that on some evaluation metric basic models outperforms the advanced ones. We have found that GCN with skip connections, GCN with NGNN and SAGE with NGNN give competent accuracy with other baseline models. The corresponding code and datasets used in this study are available on GitHub for reproducibility at:https://github.com/khushnood/DrugDruginteractionPredictionBasedOnGNN.

When multiple drugs are taken simultaneously, the activity and effectiveness of one drug can be affected by another substance, usually another drug. Drug interactions are categorized into synergism and antagonism. Synergism refers to the combined use of different drugs that enhances their therapeutic effect, while antagonism occurs when two drugs interact, leading to side effects such as reduced efficacy and adverse reactions in patients. In fact, adverse reactions caused by drug interactions are quite common. For example, in recent years, many antiallergic drugs, such as loratadine and diphenhydramine, have been combined with macrolides. Serious adverse reactions can occur after the combined use of antibiotics (e.g., erythromycin). According to relevant studies, gastrointestinal reactions and skin allergies are the most common adverse effects of various macrolide antibiotics, with incidence rates as high as 48% and 26%, respectively1. Therefore, researchers are actively focusing on developing computational approaches to identify such interactions. The figure1depicts how the drug interaction prediction problem is converted to graph ML-based prediction problem.

The figure illustrates the process of converting a drug molecule into graph representations, followed by the application of a Graph Neural Network (GNN) to make predictions.

In recent years, the use of polypharmacy–administering multiple drugs simultaneously–has become a common approach for managing complex diseases such as cancer. This strategy is particularly advantageous for older adults with multiple comorbidities, as it utilizes the synergistic effects of drug combinations to enhance treatment efficacy. However, unintended drug-drug interactions (DDIs) remain a significant concern, posing risks such as adverse side effects and drug toxicity. With the growing demand for multidrug therapies, the need for reliable DDI detection methods has become increasingly urgent. Traditional in vitro and in vivo approaches for identifying DDIs are both expensive and time-consuming, particularly given the vast number of possible drug combinations. Consequently, developing effective strategies for DDI prediction has become a priority in pharmaceutical research. Proactively identifying potential DDIs not only minimizes the occurrence of adverse drug reactions (ADRs) but also streamlines the drug development process, ultimately improving patient safety and therapeutic outcomes.

Currently, the variety of drug interactions is vast, yet only a limited number of DDIs are identified through clinical trials and chemical experiments. As a result, some drug interactions remain unnoticed until they are widely used on the market. Often, only after patients experience adverse reactions and report them are these interactions discovered. Although this reactive approach does uncover harmful drug interactions, it comes at the cost of patient health and safety, making it an unsustainable solution. Therefore, there is an urgent need for more proactive approaches to predict drug interactions.

In recent years, the accumulation of biological and medical data has led to the widespread application of machine learning in the prediction of DDI. Machine learning algorithms are now being used to automatically extract features from datasets, converting them into biologically meaningful vectors or graph-based data. These features are then analyzed using machine learning models to predict potential drug interactions. Currently, advances in the analysis of graph data structures have led to the development of sophisticated techniques to study graph-based data. This has drawn significant attention to the use of machine learning in this field. One notable method is the calculation of the weighted average of neighboring node information using neural networks, a technique that forms the basis of graph neural networks (GNNs). GNNs have become a powerful tool for processing graph data structures, making them highly suitable for DDI prediction.

In June 2021, Zhu Jie, Wang Jingxiang, and colleagues introduced a drug efficacy prediction system (DLEPS) based on genetic fingerprinting and deep learning2. This study employed neural networks to establish connections between compound structures and gene expression profiles, successfully predicting drug interactions and validating these predictions using real clinical datasets. In early 2022, Wang Fei, Lei Xiujuan, Liao Bo, and Wu Fangxiang introduced a multi-kernel graph convolutional network (GCNMK) for drug interaction prediction3. The GCNMK model incorporates two distinct DDI kernels within the graph convolutional layer: one based on an “increasing” DDI graph that captures positive DDI correlations, and the other based on a “decreasing” DDI graph that captures negative DDI correlations. The model demonstrated higher prediction accuracy, with the learned drug features being fed into a block of three fully connected layers for DDI prediction. Gao et al.4introduced AutoDDI, an automated method for predicting drug-drug interactions (DDIs). This approach leverages a reinforcement learning-based search algorithm to design optimal GNN architectures without the need for manual intervention. AutoDDI explores a customized search space of handcrafted GNN models, ensuring efficient and accurate predictions. The method achieves state-of-the-art performance on real-world datasets, demonstrating its effectiveness. Additionally, AutoDDI improves interpretability by accurately identifying the drug substructures involved in DDIs. Geng et al.5came up with a graph neural network-based model that leverages a multiscale graph neural network (MGNN) and an attention-based substructure interaction learning module to predict adverse drug-drug interactions accurately. MGDDI addresses existing limitations by effectively capturing molecular substructure variations and detailed interactions between drug pairs, demonstrating superior predictive performance in experimental evaluations. Feng et al.6proposed a graph attention network-based model for drug-drug interaction (DDI) prediction, designed to handle both known drugs within the DDI network and novel drugs. By constructing a five-layer graph attention network that captures k-hop low-dimensional feature representations and employing an MLP predictor, GNN-DDI achieves superior predictive performance. Additionally, it enhances interpretability by identifying specific drug substructures involved in DDIs, providing insights into their underlying mechanisms. Similarly, Han et al.7introduced SmileGNN, a novel DDI prediction model that integrates structural features from SMILES data with topological features derived from knowledge graphs using graph neural networks. Experimental results show that SmileGNN outperforms existing models in DDI prediction accuracy, and its credibility is further validated by verifying five of the top ten predicted interactions with the latest database.

Liu et al.8developed DANN-DDI, a deep attention neural network-based framework for predicting missing drug-drug interactions (DDIs). This model integrates multiple drug feature networks and utilizes graph embedding to learn meaningful drug representations, while an attention mechanism is employed to enhance the learning of interactions between drug pairs. Experimental results indicate that DANN-DDI is capable of identifying novel DDIs and associated events, thus improving the robustness and applicability of DDI prediction. In a similar vein, Li et al.9introduced HetDDI, a pre-trained heterogeneous graph neural network model designed to enhance DDI prediction. HetDDI combines structural information from drug molecule graphs with rich semantic data from biomedical knowledge graphs, enabling it to effectively learn drug representations from diverse sources of heterogeneous information. Case studies further demonstrate HetDDI’s capacity to predict previously unknown DDIs, confirming its practical applicability in real-world scenarios. Sukanya et al.10proposed an innovative method for DDI prediction that leverages rich drug representations sourced from multiple knowledge domains, such as the Drug-Target Interaction Network and chemical structure data. This method, which incorporates techniques like metapath2vec and Graph Auto-Encoders, has been shown to outperform previous models across several benchmark datasets. Shtar et al.11introduced two novel methods, Adjacency Matrix Factorization (AMF) and Adjacency Matrix Factorization with Propagation (AMFP), for predicting DDIs. These methods frame the DDI prediction problem as link prediction and utilize artificial neural networks and factor propagation to uncover interactions. Lei et al.12presented the Neighborhood Relation-Aware Graph Neural Network (NRAGNN), which improves DDI prediction by incorporating both the topological structure of drug entities and the semantic significance of relationships within the drug knowledge graph. The NRAGNN model showed superior performance on the KEGG-DRUG dataset, achieving significant improvements in various evaluation metrics compared to existing models. Lastly, Feng et al.13introduced DPDDI, a method for predicting DDIs that uses a Graph Convolution Network (GCN) to extract network structure features from a DDI network, while a Deep Neural Network (DNN) is employed to perform the prediction. DPDDI outperformed four existing methods, demonstrating the effectiveness of GCN-derived features and the concatenation feature aggregation operator in capturing complex DDI information.

Khaled et al.14introduce a novel model called the Hypergraph Neural Network (HyGNN) that predicts Drug-Drug Interactions (DDIs) by leveraging only SMILES strings. This model captures the chemical structure similarities of drugs through hypergraph representations, highlighting the importance of structural relationships in drug interactions. Similarly, Junpeng et al.15present the Multi-layer Adaptive Soft Mask Graph Neural Network (MASMDDI) model, which enhances DDI prediction by capturing interaction information between chemical substructures. The effectiveness of MASMDDI was evaluated using the DrugBank dataset, where it demonstrated promising results in predicting DDIs for previously unknown drugs. In a different approach, Wang et al.16introduce AttenSyn, an attention-based deep graph neural network designed for predicting synergistic drug combinations. This model leverages molecular graphs along with an attention-based pooling module to refine the representations of drug pairs, significantly outperforming current methods for anticancer drug synergy prediction. Additionally, AttenSyn provides interpretability by identifying the key drug substructures contributing to synergy, and further validation on two cell lines demonstrates its ability to generalize across different biological contexts. Wu et al.17present MKG-FENN, a multimodal knowledge graph fused end-to-end neural network aimed at DDI prediction. MKG-FENN constructs a multimodal knowledge graph and extracts high-order semantic features through a graph neural network, which are then fused in an end-to-end manner, enabling more robust DDI predictions. Yu et al.18propose the Substructure-aware Tensor Neural Network (STNN-DDI), which improves the prediction of multiple types of DDIs by mapping drugs into a substructure-substructure interaction (SSI) space. This model not only enhances predictive performance but also offers interpretability by identifying the critical substructure pairs that drive interactions. Deepa et al.19introduce the SNF-HCNN framework, which leverages drug data from sources like DrugBank, PubChem, and SIDER. Using a similarity matrix derived from drug features, SNF-HCNN offers a novel approach to predicting DDIs. Similarly, Su et al.20introduce DDKG, an attention-based knowledge graph representation learning framework that integrates drug attributes and neighboring information to enhance DDI predictions. Feng et al.21present deepMDDI, a deep learning-based model for multi-label DDI prediction. By utilizing a relational graph convolutional network encoder and a tensor-like decoder, deepMDDI performs well in both transductive and inductive settings, successfully identifying new valid DDIs in case studies. Lastly, Wang et al.22propose MIRACLE, a multi-view graph contrastive representation learning method that captures both inter-view molecular structures and intra-view drug interaction relationships, significantly improving DDI prediction accuracy. Further DPSP framework23predicts drug-drug interactions by constructing novel drug feature vectors using multiple types of drug information and Jaccard similarity, followed by a deep neural network for classification. Researchers24proposed NNPS, a neural network-based method for predicting polypharmacy side effects using novel drug feature vectors derived from mono side effects and drug-protein interactions.

Further we have analysed the correlated work of drug target interaction prediction problems. How the researchers have solved the drug target interaction problem. Neural Matrix Factorization (ANMF), a novel model for computational drug repositioning that integrates drug-drug and disease-disease similarities, autoencoder-based hidden feature extraction, and Generalized Matrix Factorization is porposed25. GraphCL-DTA, a model for drug-target binding affinity prediction that leverages graph contrastive learning to improve drug representation quality. GraphCL-DTA performs semantic-preserving data augmentation in the embedding space, allowing for richer, unsupervised representation learning of molecular graphs. Additionally, a new loss function is introduced to directly optimize the uniformity of drug and target embeddings26. Hybrid Attentional Memory Network (HAMN), a deep learning model that combines neighborhood-based and latent factor-based collaborative filtering approaches to leverage both local and global information for drug repositioning. By incorporating a memory-attention mechanism and an autoencoder, along with auxiliary drug and disease information, HAMN addresses the cold start problem27. Further researchers28present a multi-task self-supervised learning framework for computational drug repositioning, designed to address the challenge of label sparsity by enhancing drug representation learning. By jointly training a main task for drug-disease association prediction and an auxiliary contrastive learning task using data augmentation. NMFDR29, a Neural Metric Factorization model for computational drug repositioning, to overcome the expressive limitations of traditional matrix factorization methods. By modeling drug-disease associations through a generalized Euclidean distance in a high-dimensional latent space. The authors30propose PUON, it leverages only validated (positive) and unvalidated (unlabeled) drug-disease associations without negative sampling and introduces an Outer Neighborhood-based classifier to capture cross-feature information from latent factors. These various approaches demonstrate the growing importance of graph-based and neural network-driven methodologies in the prediction and understanding of drug interactions, reflecting an ongoing trend toward more advanced, interpretable, and accurate models in computational drug discovery.

Although significant progress has been made in drug-drug interaction prediction, several challenges and methodological limitations remain.

Data Imbalance and Incompleteness:Drug interaction data usually come from medical experiments, patient records, literature reports, and departmental statistics. However, these data are often inconsistent. Furthermore, while the amount of drug-related data is vast, the subset available for analysis is relatively limited, leading to data imbalance. Many potential drug interactions remain undiscovered due to the scarcity of comprehensive datasets.

Complex Mechanisms of Interaction:In the human body, drugs can interact during various phases such as metabolism, absorption, distribution, and excretion. These mechanisms often involve multiple biological processes, making it challenging to develop predictive models that can accurately capture and interpret such complex interactions.

Non-Euclidian relationship:One of the primary obstacles is the vast complexity of interactions between drugs, which involves numerous factors such as chemical properties, pharmacodynamics, and pharmacokinetics. The large number of potential drug combinations further complicates the task, as traditional experimental methods for detecting DDIs through in vitro and in vivo testing are both time-consuming and costly. Additionally, many existing models rely heavily on structured data, such as chemical structures or biological pathways, but fail to fully capture the complex, unstructured relationships and nuances between drugs that can lead to interactions.

Data Fusion Challenges:Effective drug-drug interaction analysis requires integrating multiple data sources, including multi-modal data like molecular structures, protein interaction networks, and genomic information. Combining these diverse data types to generate meaningful and useful features remains a significant challenge.

Data Sharing and Cross-Field Collaboration:Predicting drug interactions often involves collaboration across diverse fields such as biology, chemistry, and medicine. However, issues related to data sharing, intellectual property rights, and the protection of sensitive information hinder cross-field cooperation, making it difficult to access and share crucial datasets.

Theoretical Significance:Traditional drug-drug interaction prediction methods primarily rely on the chemical properties of drugs and target protein sequences, among other factors. However, predicting drug interactions remains a complex challenge. The recent rise of graph neural network (GNN) models offers a promising solution by enabling the modeling of intricate graph data, including the three-dimensional structures of drug molecules, chemical bond information, and target proteins. This approach provides richer and more precise feature representations for drug interaction prediction. Moreover, GNN models can capture relationships between drugs and target proteins, offering researchers deeper insights into the mechanisms of drug interactions. Accurate drug interaction predictions can also support personalized medicine, improving treatment outcomes and enhancing medication safety.

Practical Significance:The application of graph neural network (GNN) models has introduced considerable advantages for researchers using machine learning to predict drug interactions. GNN models significantly improve the accuracy of these predictions, positively influencing drug development, the therapeutic effectiveness of drug combinations, and drug safety. Therefore, using GNN models for drug interaction prediction presents vast research potential and practical implications for the field.

The experiments are performed five times with different random seeds. Each model is trained for 100 epochs with learning rate=0.001, batch size, Hidden layer size=128,dropout rate=0.5.input-drop 0.0, edge-drop 0.0, attn-drop 0.0 and so on. We kept the default parameters given by the paper code itself for the baseline models.

The training loss curves (Figure2) across the three datasets–BIOSNAP, DrugBank, and OGBL-DDI–exhibit consistent downward trends, indicating that all models generally learn meaningful patterns over epochs. In the BIOSNAP dataset, the models display smooth and monotonic convergence, with some achieving noticeably lower final losses. This suggests that BIOSNAP is relatively easier to fit, and some models generalize better on it. In contrast, the DrugBank dataset reveals greater variance in convergence behavior. Certain models converge rapidly, while others exhibit a slower decline or maintain higher loss values throughout training, possibly due to the dataset’s increased complexity or noise. The OGBL-DDI dataset shows the most irregular loss trajectories, with several curves presenting mild fluctuations or delayed convergence. These patterns imply a more challenging optimization landscape, where model architecture significantly affects the training dynamics. Overall, the shape and rate of the loss curves reflect differences in model capacity, optimization stability, and dataset complexity.

The experimental results of loss value of each model during training for the three datasets. .

Overview for the results on validation datasetTable1reports the highest validation performance of various models during training across the three datasets:Biosnapddi,Drugbankddi, andOgbl-ddi, based on Hits@10 through Hits@50. The best three models per metric are color-coded, highlighting leading performance in ranking accuracy.

The validation results reveal distinct performance patterns across datasets. For Biosnapddi, models consistently achieve high Hits@n scores, indicating effective identification and ranking of true DDI pairs. Notably, ‘AGDN‘, ‘GCN‘, and ‘MEMAGDN‘ demonstrate strong performance on this dataset. In contrast, all models exhibit very low Hits@n values on the Drugbankddi dataset, typically ranging from 0.010 to 0.030. This suggests a significant challenge in the models’ ability to prioritize true DDI instances within their predictions for this specific dataset. ‘MAGCN‘ shows a marginal advantage at higher ’n’. On the Ogbl-ddi dataset, model performance is moderate, yet more discerning. ‘SAGE‘ and ‘SAGENGNN‘ generally lead in ‘Hits@n‘, with ‘MAGCN‘ and ‘AGDN‘ also performing competitively, achieving hit rates up to 0.630. In essence, while models effectively rank DDI pairs on Biosnapddi, they struggle considerably on Drugbankddi. The Ogbl-ddi dataset offers a more balanced evaluation ground, highlighting varying strengths among models in accurately retrieving relevant drug-drug interactions.

Overview from test data:Table2presents the final performance on test data of various models across three datasets:Biosnapddi,Drugbankddi, andOgbl-ddi. The evaluation includes five ranking-based metrics, Hits@10 through Hits@50, along with overall classification accuracy. There is a clear distinction between the performance on Accuracy and Hits@n metrics. While many models achieve very high accuracy (often above 0.900), their Hits@n scores, particularly at lower ’n’ values (e.g., @10, @20), are generally quite low, especially for the Biosnapddi and Drugbankddi datasets. This suggests that the models are highly accurate at classifying most DDI pairs (likely negative interactions, which are much more common), but struggle to rank true positive interactions highly within a set of predictions. In DDI prediction, a high Hits@n is often more crucial as it indicates the model’s ability to prioritize relevant interactions.

Model evaluation based on various metrics and datasets.

The Ogbl-ddi dataset appears to be significantly more challenging for DDI prediction in terms of absolute Hits@n scores, but also shows a greater range and higher maximum Hits@n values, indicating that models have more room for differentiation and improvement on this dataset compared to Biosnapddi and Drugbankddi. The accuracy for Ogbl-ddi is also generally high, but slightly lower than Biosnapddi. For Biosnapddi and Drugbankddi, the Hits@n values are consistently close to 0.000 for most models and ’n’ values. This indicates a substantial challenge in correctly ranking positive DDI instances among many negative ones.

On Biosnapddi dataset models are very good at classifying (leading to high accuracy). However, they struggle to correctly rank or identify the rare positive interactions (leading to very low Hits@n). For practical DDI prediction where identifyingtrueinteractions is paramount, the current models are not effectively addressing this challenge including our proposed models.

The Drugbankddi dataset also presents a challenge for ranking positive DDIs (evident from the consistently low Hits@n). While overall accuracy is respectable for some models, others perform poorly, suggesting a more balanced or diverse set of challenges compared to Biosnapddi in terms of classification. The significant drop in accuracy for certain models like GCNSKIPCONNECTION suggests it struggles with the underlying patterns in this specific dataset.

The Ogbl-ddi:dataset appears to be better suited for evaluating the ranking capabilities of DDI models. Models likeGCNNGNNGRAPHCONVandGCNSKIPCONNECTIONdemonstrate superior ability in retrieving actual DDI instances, indicating their potential for real-world DDI prediction where identifying relevant interactions is key. High accuracy is maintained by most models, suggesting a good overall classification ability.

Hits@n:Consistently low on Biosnapddi and Drugbankddi (0.000-0.010). Shows moderate performance on Ogbl-ddi (e.g., 0.230 at @50).

Accuracy:Excellent on Biosnapddi (0.992), decent on Drugbankddi (0.798), and strong on Ogbl-ddi (0.975).

Overall:A generally robust performer in terms of accuracy, but its Hits@n performance is only notable on Ogbl-ddi among the datasets tested.

Hits@n:Very poor on Biosnapddi and Drugbankddi (mostly 0.000-0.010). Moderate on Ogbl-ddi (e.g., 0.250 at @50).

Accuracy:Good on Biosnapddi (0.989), but significantly lower on Drugbankddi (0.614) and slightly lower on Ogbl-ddi (0.937) compared to top models.

Overall:Seems to struggle with Drugbankddi dataset in particular. Hits@n are not its strong suit.

Hits@n:Very low on Biosnapddi and Drugbankddi. Better on Ogbl-ddi (e.g., 0.350 at @50), performing reasonably well among the models.

Accuracy:High on Biosnapddi (0.987), moderate on Drugbankddi (0.736), and good on Ogbl-ddi (0.951).

Overall:A solid baseline GNN model, showing average to good performance, particularly for Hits@n on Ogbl-ddi.

Hits@n:Very low on Biosnapddi and Drugbankddi.Very strong onOgbl-ddi, particularly at lower ’n’ values (highest Hits@10 and @20).

Accuracy:Excellent on Biosnapddi (0.991), but remarkably poor on Drugbankddi (0.500), and decent on Ogbl-ddi (0.928).

Overall:A peculiar model. While it excels at retrieving relevant hits on Ogbl-ddi, its highly variable accuracy across datasets (especially the random performance on Drugbankddi) suggests it might be sensitive to specific dataset characteristics or require more fine-tuning.

Hits@n:Marginally better than GCN on Biosnapddi (0.010 at @30,@40,@50) and consistent with others on Drugbankddi (0.010). Moderate on Ogbl-ddi (e.g., 0.240 at @50).

Accuracy:Noticeably lower accuracy on Biosnapddi (0.891) and Drugbankddi (0.738) with higher variance, but high on Ogbl-ddi (0.973).

Overall:Its performance is quite inconsistent across datasets, suggesting it might not generalize as well as some other models.

Hits@n:Very low on Biosnapddi and Drugbankddi. Decent on Ogbl-ddi (e.g., 0.350 at @50).

Accuracy:Relatively low and variable accuracy on Biosnapddi (0.888) and Drugbankddi (0.699), but excellent on Ogbl-ddi (0.977).

Overall:Similar to MEMAGDN, its performance varies significantly, showing strong accuracy on Ogbl-ddi but struggling on the other two in terms of accuracy.

Hits@n:Very low on Biosnapddi and Drugbankddi. Lower end on Ogbl-ddi (0.220 at @50) compared to top models.

Accuracy:High on Biosnapddi (0.980), highest on Drugbankddi among models with 0.801, and highest on Ogbl-ddi (0.981).

Overall:SAGE is consistently among the top models for accuracy across all datasets, indicating its strong classification ability. However, its Hits@n performance is generally not as competitive as GCNNGNNGRAPHCONV or GCNSKIPCONNECTION on Ogbl-ddi.

Hits@n:Very low on Biosnapddi and Drugbankddi. Lower end on Ogbl-ddi (0.170 at @50).

Accuracy:High on Biosnapddi (0.991), highest on Drugbankddi (0.810), and high on Ogbl-ddi (0.972).

Overall:Similar to SAGE, it excels in overall classification accuracy across all datasets, but its ability to rank true positives highly (Hits@n) is not its strongest point.

Hits@n:Very low on Biosnapddi and Drugbankddi. Lower end on Ogbl-ddi (0.240 at @50).

Accuracy:Top accuracy on Biosnapddi (0.992) and strong on Drugbankddi (0.807) and Ogbl-ddi (0.964).

Overall:A very strong performer in terms of accuracy across all datasets, similar to SAGE and SAGENGNN. Its Hits@n performance on Ogbl-ddi is slightly better than SAGE/SAGENGNN but still not as good as GCNNGNNGRAPHCONV or GCNSKIPCONNECTION.

Use different models to conduct experiments on various datasets and leverage the characteristics of different models to combine them for discovering better drug interaction prediction models.

Actively collaborate with experts in biology and medicine to update and optimize models based on relevant clinical trial data and pharmacological knowledge.

Investigate methods to improve the interpretability and explainability of the model so that researchers in related fields can understand the model’s prediction results.

The Graph Attention Network (GAT) represents an advanced graph neural network model designed to leverage the attention mechanism for capturing intricate relationships among nodes within a graph, ultimately producing comprehensive node representations31. Unlike traditional methods, GAT introduces an innovative approach by assigning adaptive attention weights to neighboring nodes, allowing the model to focus on the most relevant connections. This mechanism enables efficient learning without relying on computationally intensive operations, such as matrix inversion, or requiring prior knowledge of the graph’s structure. By incorporating multiple stacked layers, GAT systematically aggregates domain-specific features from the local neighborhood of each node. The detailed architecture of the GAT model is depicted in Figure3(a).

Various graph neural networks used in our study are described in this figure.

The Graph Convolutional Network (GCN) is a deep learning model designed for processing graph-structured data. It is primarily utilized for tasks such as node classification and link prediction32. GCN represents graph data using two key components: an adjacency matrix and a node feature matrix. The adjacency matrix encodes the relationships between nodes, where entries typically indicate the presence (1) or absence (0) of connections, while the node feature matrix contains the feature vectors for each node. Through graph convolution operations, GCN propagates and aggregates node features from neighboring nodes, thereby generating enriched node representations. These representations are iteratively refined across multiple layers of graph convolutions, enabling the model to capture both local connectivity and complex relationships. GCN supports parameter sharing and is adaptable to graphs of various structures, providing strong generalization capabilities. Furthermore, GCNs can be integrated with other deep learning models to enhance performance across diverse tasks. The architecture of the GCN model is illustrated in Figure3(a).

The SAGE (Sample and Aggregation) model is a graph neural network model developed to learn low-dimensional representations of nodes in graph data. It effectively captures both local and global characteristics of nodes through multilayer neighbor sampling and information aggregation operations33. It is depicted in Figure3(a).

In this model, the GraphSAGE layer and the Nested Graph Neural Network (NGNN) layers are combined sequentially to enhance feature extraction, following a linear architecture inspired by34.

The Topology Adaptive Graph (TAG) method adapts the topology of graph neural networks to suit the structure of different graph data35. Traditional graph neural networks often assume a fixed topology, which may not be ideal for diverse graph structures. TAG dynamically adjusts the network’s topology to fit the input graph data better and capture local structural information better. It allows each node to adaptively select its neighboring nodes and learn convolutional kernels based on the relationships between nodes. This flexibility enables TAG to better capture local structural information, enhancing the performance of graph neural networks across different types of graph data.

To tackle the drug-drug interaction problem, we explored various combinations of these models, systematically evaluating their performance and comparing the results with those of other state-of-the-art approaches.

whereis a learned position embedding for thei-th hop.

The layer computes attention between nodes in a graph. The attention mechanism uses source () and destination () node features for computing attention scores.

wheredenotes the set of neighboring nodes of nodei.

whererepresents the edge feature vector between nodesiandj.

The model aggregates features over multiple hop steps. It updates node features and computes attention for each hop, allowing information to flow over longer distances.

Sun et al.37proposed Adaptive Graph Diffusion Networks (AGDNs) to address overfitting, over-smoothing, and inefficiency in deep Graph Neural Networks. AGDNs perform generalized multi-hop diffusion across different feature spaces using learnable hop-wise weighting mechanisms–Hop-wise Attention and Hop-wise Convolution–while maintaining moderate runtime and complexity. They have also given a variant MEMAGDN.

Skip Connection:Skip connection is a technique employed in neural networks to establish direct connections between different layers. It functions by adding the output of one layer directly to the input of another, enabling information to bypass intermediate layers and propagate more effectively through the network. This approach alleviates the vanishing gradient problem and facilitates the training of deeper networks. Moreover, skip connections allow lower-level features to be retained and utilized by higher layers. In our experiments, as illustrated in Figure3(b), we incorporated skip connections into the basic model. This enhancement enables the model to aggregate information from neighbors over multiple hops while mitigating the risk of over-smoothing in node embeddings.

Post-Processing Layers:While adding more convolutional layers can be challenging in GNNs, it is also possible to incorporate pre- and post-processing layers that do not perform message passing. Post-processing layers, such as multi-layer perceptrons (MLPs), are applied to node embeddings to convert and refine the nonlinear outputs of the model. MLPs consist of fully connected layers containing multiple neurons and using nonlinear activation functions such as ReLU or Sigmoid. Figure3(c) illustrates the model structure with these post-processing layers.

Enhanced Predictor:Building on the idea that passing embeddings through MLP layers can enhance performance, we incorporate this concept into a GNN model. Instead of integrating the LinkPredictor as part of the GNN, we define it as a small neural network (“NeuralLinkPredictor”) to perform post-processing independently. This setup optimizes the model’s predictive abilities, as depicted in Figure3(d).

The AGDN component is a specialized neural network designed for processing graph data by aggregating information from neighboring nodes through diffusion operations. By iteratively updating node representations based on their neighbors, the AGDN effectively captures the graph’s structural information, making it well-suited for understanding complex relationships in graph data.

Despite its strengths, the AGDN alone may face limitations in addressing the dynamic and intricate nature of graph topologies encountered in real-world applications. To address this, the TAG model introduces a topology-adaptive mechanism that dynamically adjusts to the graph’s structural variations based on the data’s characteristics. This enables the TAG model to better capture essential topological features, enhancing prediction accuracy.

In the MAGCN model, the AGDN, Attention based Neibhour aggregation, and TAGConv layer is applied to the node features, further refining the learned representations by adaptively accounting for the graph’s topology. The final component, the MLP, performs classification or regression tasks on the updated node features. As a robust nonlinear mapping tool, the Jumping Knowledge layer transforms these features into the target output space, enabling accurate and reliable predictions.

In summary, the MAGCN model effectively combines the complementary strengths of AGDN, Attention mechanism, TAG, and Jumping Knowledge layer to achieve efficient graph data processing and precise predictive performance. This integrated approach offers wide applicability and has demonstrated strong results in practical applications.

During the initial training phase, negative sampling is employed to address the imbalance between positive and negative edges in the graph. For each positive edge (i.e., an existing edge in the training graph), an equal number of negative edges (i.e., non-existent edges) is generated. This approach ensures that each training batch contains a balanced representation of positive and negative edges, facilitating effective learning.

The model then generates node embeddings by processing all training edges, transforming the graph data into feature representations that encapsulate the structural and relational information of the graph. These embeddings serve as the input for subsequent prediction tasks.

As a result, the problem is formulated as a binary classification task, where the objective is to distinguish between positive and negative edges based on their learned feature representations. This framing aligns with standard machine learning methodologies, allowing the model to leverage well-established classification techniques for edge prediction.

The experiment employs binary cross-entropy loss to evaluate model performance. This loss function is particularly suited for binary classification problems, where it measures the discrepancy between two probability distributions: one representing the true labels and the other representing the model’s predictions.

Among them,is the binary label 0 or 1, andis the predicted probability that the output belongs to thelabel.

The experiment employs the Adam optimizer for model training. Adam, which stands for Adaptive Moment Estimation, is an adaptive learning rate optimization algorithm that combines the benefits of momentum-based gradient descent with the advantages of adaptive learning rates39. It adjusts the learning rate of each parameter by calculating both the first-order moment estimate (the mean) and the second-order moment estimate (the uncentered variance) of the gradients. This adaptive mechanism allows Adam to effectively handle sparse gradients and noisy data.

Among them, it is assumed that there aresamples, of whichare positive samples andare negative samples. “Number of positive samples with RankK” refers to the number of positive samples with predicted score rankings less than or equal to. “Number of negative samples with RankK” refers to the number of negative samples with predicted score rankings greater than or equal to.

where “Number of Correct Predictions” represents the number of samples correctly classified by the model, andrepresents the total number of samples.

OGB-DDI:The Ogbl-ddi dataset is a homogeneous, unweighted, undirected graph where each node corresponds to an FDA-approved or experimental drug. Edges denote drug-drug interactions, capturing cases where the combined effect of two drugs differs significantly from their independent effects40,41. The dataset comprises 4,267 nodes and 1,067,911 edges, with an average node degree of 501. This structure enables the exploration of complex drug-drug interactions.

Drugbank-DDI:The DrugBank drug-drug interaction (DDI) dataset is manually curated from FDA and Health Canada drug labels, along with primary literature sources. It includes 191,808 drug-drug interaction pairs involving 1,706 unique drugs and spans 86 distinct interaction types. The associated task is formulated as a multi-class classification problem: given the SMILES representations of two drugs, the goal is to predict the type of interaction between them40,42.

Biosnap-DDI:The BIOSNAP dataset comprises 1,322 FDA-approved drugs with 41,520 labeled drug-drug interactions (DDIs). In contrast, the Zhang-DDI dataset includes 548 drugs and 48,584 pairwise DDIs. Both datasets are used for multi-DDI prediction tasks, where the objective is to identify specific interaction types between drug pairs43.

In Figure4we have shown ddi interaction adjacency plot for Ogbl-ddi dataset. In Figure5we have shown the label distribution for DrugBank ddi and Biosnap DDI. The figure shows these these are balanced class. For Ogbl-ddi dataset only interaction graph were present. To make it balanced we have done global sampling with equal number of true class for training the data. In this section we have anlysed various characteristics of our datasets. Although in the following analysis we have only considered two datasets because the have provided drug smiles in their datasets.

Whole (un-directed) graph adjacency matrix plot. Each node represents a drug. The dots show there is an interaction between two drugs.

This is label distribution of both the datasets. Which means both datasets are balanced.

is the number of bits (features) that are “on” (present) inbothfingerprint A and fingerprint B.

is the total number of “on” bits in fingerprint A.

is the total number of “on” bits in fingerprint B.

1 indicates perfect structural similarity (the fingerprints are identical).

0 indicates no shared features (the fingerprints have no “on” bits in common).

The core principle behind using Tanimoto similarity in these contexts is the“similarity principle”:structurally similar molecules are likely to have similar properties and biological activities.

In Figure6we have shown the Tonimoto similarity index for both the datasets.

Tonimoto similarity between drugs for both the datasets.

The Figure7shows molecular weight distribution for both the datasets. Molecular weight affects drug-drug and drug-target interactions by influencing absorption, distribution, binding affinity, and permeability. Generally, higher molecular weight can reduce membrane permeability, while also affecting how tightly or selectively a drug binds to its target or interacts with other drugs.

Molecular weight distribution for both the datasets.

Molecular hydrophobicity affects drug-drug and drug-target interactions by influencing binding affinity, membrane permeability, and solubility. Hydrophobic drugs often bind more strongly to hydrophobic pockets on targets but may have poor solubility and higher chances of off-target or nonspecific interactions. In Figure8we have shown the average hydrophobicity for two datasets.

The drug edges in the dataset are segmented based on the specific proteins they target in the body. As a result, the test set consists of drugs that primarily bind to proteins distinct from those in the training and validation sets. This segmentation ensures that the drugs in the test set exhibit different biological mechanisms of action and interact with distinct proteins compared to those in the training and validation sets. Protein-target segmentation, therefore, provides an opportunity to assess the model’s ability to make meaningful and generalizable predictions that are not limited to the specific proteins seen during training41.

The experimental task focuses on predicting drug-drug interactions (DDIs) by ranking each known positive interaction against approximately 100,000 randomly sampled negative interactions. The primary evaluation metrics are Hits@10, Hits@20, and Hits@50, which measure the proportion of true positive interactions ranked within the toppredictions. These metrics assess the model’s ability to correctly prioritize true interactions among a large set of candidates. In addition to Hits@K, we also report accuracy to provide a broader view of model performance across the entire prediction space. Prior studies have indicated that evaluating performance atis particularly meaningful in DDI prediction tasks, but we extend this analysis to smaller and largervalues for a more comprehensive evaluation.

The experimental code environment is based on Python version 3.10.8 and PyTorch version 2.1.2+cu118. The version of torch-scatter is 2.1.2+pt21cu118, torch-cluster is 1.6.3+pt21cu118, the version of torch-sparse is 0.6.18+pt21cu118, torch-geometric is 2.6.0, ogbl is 1.3.6, dgl is 2.4.0+cu118, and dgl-life is 0.3.2.

This work was supported by the Key Scientific and Technological Research Projects in Henan Province under Grant 202102210379 and also by Zhoukou Normal University super scientific project grantZKNUC2018019. We would also like to acknowledge the assistance of language models such as ChatGPT in enhancing the readability and clarity of our manuscript. The use of these tools has significantly contributed to refining the language and ensuring that our research is communicated effectively.