Artificial intelligence (AI) is increasingly shaping daily decision-making by enhancing efficiency and consistency. However, prolonged AI use may impose cognitive strain, attention depletion, information overload, and decision fatigue.

To investigate the relationships among AI anxiety, attitudes toward AI, cognitive performance, trust in AI, and decision fatigue, particularly emphasising long-term AI interaction.

A structured survey was administered both online and offline to a sample of 500 adults (290 males, 210 females) in the Delhi–NCR region, with a mean age of 24.2 ± 3.4 years. The survey assessed participant’s AI anxiety, AI attitude, cognitive skills, decision fatigue, and trust (encompassing reliability, productivity, and user control). Descriptive statistics and Pearson correlation analyses were conducted to explore the relationships between these variables.

Participants reported moderately high AI anxiety (mean = 4.62, SD = 1.14) and generally positive attitudes toward AI (mean = 5.01, SD = 1.06). A strong but marginally non-significant correlation (r= 0.81,p= .053) was found between favourable attitudes and technology usage frequency. High trust in AI—measured via reliability (r= 0.597), productivity (r= 0.985), and control (r= 0.829)—correlated with prior positive AI experience. Long-term AI use was significantly associated with mental exhaustion, attention strain, and information overload (r= 0.905), and inversely associated with decision-making self-confidence (r= −0.360).

The integration of AI in task performance resulted in improved efficiency and user confidence; however, prolonged utilisation may precipitate cognitive fatigue, diminished focus, and attenuated user agency. To mitigate these adverse effects, strategic design approaches prioritising user empowerment, transparency, and cognitive facilitation are essential for maximising benefits while upholding mental health and well-being.

Recent advancements in artificial intelligence (AI) have significantly impacted societal dynamics through the integration of large language models, programming assistants, and reinforcement learning, thereby underscoring the ubiquity of AI in contemporary daily life. The integration of AI technology into various aspects of life has rendered it an indispensable element, enabling expeditious access to information, fostering creativity, and promoting interconnectedness on a global scale.1The rising deployment of AI-driven technologies in vital sectors such as healthcare, energy infrastructure management, and transportation networks holds the potential to exacerbate existing problems in these domains.

The effects of digital technology on individuals vary significantly across diverse age groups. To promote a lifelong culture of healthy digital engagement, it is crucial to gain a profound understanding of its multifaceted role within distinct developmental stages. While digital tools, interactive applications, and media may confer benefits for children, such as educational enrichment, excessive or unregulated exposure can lead to undesirable consequences, including diminished attentional capacities, compromised academic achievement, and a heightened predisposition to decision fatigue.5The pervasive integration of digital technology and AI in contemporary life has significantly impacted cognitive processes, habits, and perceptual frameworks.

Attentional overload arises from the perpetual influx of sensory stimuli in contemporary digital environments, culminating in an individual’s diminished capacity for focused information processing.6,7Prolonged multifaceted distraction significantly impairs cognitive functionality and overall well-being, giving rise to deleterious outcomes such as diminished productivity, impaired memory retention, and heightened stress levels.

Multitasking can impair processing accuracy and efficiency and disrupt social relationships. The relentless requirement to respond to digital alerts and notifications can hamper deep engagement and diminish the quality of face-to-face interactions.8Research has demonstrated that recurrent interruptions can lead to diminished productivity, increased tension, and compromised job satisfaction.9Prolonged utilisation of digital technology is associated with compromised sustained attention, resulting in diminished performance on tasks that rely heavily on focused attention, as opposed to individuals with lower multitasking frequencies.

The increasing incorporation of AI in educational settings has profound implications for administrative and academic decision-making processes. Nevertheless, the implementation of AI in this context is beset by ethical considerations stemming from the pervasive nature of algorithmic bias, racial discriminatory outcomes, and the erosion of accountability mechanisms.26Excessive online information can result in decision paralysis, hindering critical evaluation due to information overload.27–29Automated recommendations can expedite decision-making processes; however, they may inadvertently reinforce confirmation bias by restricting access to diverse perspectives.

The proliferation of digital settings can impede cognitive functioning by overwhelming information assimilation capabilities, thereby leading to decision fatigue and compromised performance efficacy.35The proliferation of technology-driven platforms may intensify confirmation bias and groupthink phenomena, thereby hindering the development of critical thinking abilities and diminishing the quality of interpersonal interactions and collective decision-making processes.36,37Furthermore, excessive technology usage and addiction have been associated with a decline in critical thinking abilities.38In a digital era dominated by AI, prioritising cognitive health and well-informed decision-making necessitates the integration of digital literacy, defined boundaries on technological usage, and a deliberate cultivation of critical thinking and interpersonal connections.

The study analyses how AI anxiety and attitudes influence cognitive skills and decision fatigue in daily technology use.

To explore how positive or negative attitudes toward AI influence the adoption of AI-integrated technologies.

To assess the level of trust and confidence users have in AI systems and identify the key factors that influence their perceptions.

To investigate the impact of AI on users’ cognitive skills and levels of decision fatigue during decision-making tasks.

To investigate the strength and direction of the relationships between long-term interaction with AI systems and cognitive-psychological outcomes.

There is a relationship between an individual’s attitudes toward AI and their frequency of technology use.

Users with prior positive experiences and a basic understanding of how AI works are more likely to exhibit higher levels of trust and confidence in AI systems.

AI assistance will reduce decision fatigue by streamlining choices. Prolonged reliance on AI will more likely lead to a decline in users’ cognitive engagement and independent decision-making skills.

Long-term interaction with AI is positively associated with mental exhaustion, attention strain, and information overload, and negatively associated with self-assurance in decision-making.

Individuals aged between 18 and 30 years at the time of participation.

Regular users of digital technology (e.g., smartphones, computers) in daily activities.

Participants possessing a basic understanding or awareness of AI concepts.

Participants who voluntarily provide informed consent for participation.

Infrequent or non-users of digital technology who do not engage with technology regularly or do not have any knowledge about AI.

Surveys with incomplete data, inconsistent answers, or random responding, which could compromise data integrity.

This study employed a quantitative survey to examine how AI anxiety and attitudes toward AI influence users’ cognitive skills and levels of decision fatigue during daily technology use. The primary data collection method involved the use of a structured questionnaire administered to participants through online and offline means.

A convenience sampling technique was employed to recruit 500 participants between the ages of 18–30 years, from the Delhi-NCR region of India.

Data were collected using a self-administered survey questionnaire designed to measure key constructs such as AI anxiety, attitude toward AI, cognitive skills, and decision fatigue. The questionnaire consisted of Likert-type items, developed from pre-existing scales or previously verified, in order to quantitatively record participant attitudes and actions about AI and technology use. The participants were well informed about the goal of the study and were assured that their answers would remain anonymous and confidential. Informed consent was obtained from all respondents prior to participation.

Participation was voluntary, and no personally identifiable information was collected. The study adhered to ethical research guidelines and ensured that all participants were aware of their right to withdraw from the study at any point without any negative consequences.

The collected data were analysed using SPSS. Descriptive statistics, including mean, standard deviation, skewness, and kurtosis, were calculated to understand the distribution and central tendencies of the variables. Further inferential analyses were performed to explore the relationships among AI anxiety, attitudes toward AI, cognitive performance, and decision fatigue.

The result indicates how AI influences decision-making and cognitive skills, and how AI Anxiety and attitudes affect daily technology use.

Table 1shows the demographics of the sample comprising 500 participants (58% male, 42% female). In terms of education, 44% held undergraduate qualifications, 32% possessed postgraduate degrees, and 24% had completed matriculation or higher-secondary education. Most were aged 18–20 years (58%), followed by 21–25 years (20%) and 26–30 years (18%). Nearly half (48%) resided in urban areas, with 30% in rural and 22% in semi-urban settings. Daily digital technology usage was high, with 42% reporting >6 h/day, while 17% used digital devices for <2 h/day.

Table 2summarises the descriptive statistics for the key variables. AI Anxiety had a mean score of 4.62 (SD = 1.14) with skewness of −0.28 and kurtosis of −0.44, indicating a moderately high level of AI-related anxiety and a near-normal distribution. Attitudes Toward AI averaged 5.01 (SD = 1.06), suggesting generally favourable perceptions, with a skewness of −0.36 and kurtosis of −0.19. Cognitive Skills were rated relatively high (M = 3.72, SD = 0.78), with skewness (0.03) and kurtosis (−0.61) indicating a nearly symmetrical and slightly platykurtic distribution. Decision Fatigue had a mean of 3.94 (SD = 0.83), suggesting moderate cognitive strain, with skewness (−0.22) and kurtosis (−0.37) also indicating a roughly normal distribution.

The Pearson correlation between Attitudes Toward AI and Frequency of Technology Use, as shown inFigure 1, was strong (r= 0.806), suggesting a positive association (Table 3). However, thepvalue (.053) was slightly above the conventional significance threshold (p< .05), indicating that the result was marginally nonsignificant. Thus,H1(‘There is a relationship between an individual’s attitude toward AI and their frequency of technology use’) is partially accepted.

Notes:The shaded region shows 95% confidence interval.

The trendline shows the best fit linear connection.

The blue circles show the individual survey items.

The results highlight a strong, positive association between the two variables (r= 0.806,p= .053).

Notes:Pearson correlation coefficient (r) = 0.806,p= .053 (marginally significant).

The Pearson correlation coefficients between confidence and trust in AI-related variables are shown inTable 4. Notably, as depicted inFigure 2, there was a moderate correlation found between the impression of AI recommendations as reliable and both improved productivity (r= 0.597) and confidence in task completion (r= 0.486). These results suggest that greater levels of trust and confidence in the application of AI are linked to prior positive experience and comprehension of the technology. The results, therefore, supportH2.

The inter-item correlations (Table 5) revealed generally low or negligible associations across most AI cognitive variables. Notably, as illustrated inFigure 3, there was a moderate positive relationship between lower self-assurance in decision making and lower attention as a result of AI exposure (r= 0.32), indicating that lower attention is linked to lower confidence in decision making. Other associations, such as those pertaining to information overload and cognitive fatigue, were less strong than expected (|r| < 0.20). Thus,H3(‘AI may reduce decision fatigue in the short term, long-term reliance diminishes cognitive engagement and independent decision-making’) is partially supported.

Note:The bolded value (r= 0.32) indicates a moderate positive correlation between Lowered attention and Lower self-assurance in decision making. It is highlighted due to its interpretive significance in partially supporting hypothesis 3.

Table 6details the correlations between long-term AI interaction and various cognitive and psychological outcomes.Figure 4depicts strong, positive correlations were observed between long-term AI interaction and mental exhaustion (r= 0.671), attention strain (r= 0.874), information overload (r= 0.905), and having too many options (r= 0.671). Long-term AI interaction was found to be moderately negatively associated with decreased self-assurance (r= −0.360). These results supportH4, indicating that long-term AI exposure is associated with increased cognitive strain and reduced self-assurance.

The current research elucidates the complex interrelation between AI and human cognition, concurrently illuminating its advantageous and detrimental consequences. As AI increasingly permeates everyday existence, the psychological and cognitive effects necessitate rigorous examination. The discovered outcomes emphasise the dichotomous consequences of AI integration, wherein enhanced efficiency may be offset by cognitive burden and diminished user autonomy. A comprehensive comprehension of these interrelated dynamics is imperative for harmonising AI development with the innate requirements of human cognitive faculties, thus facilitating synergies between efficacious performance and individual well-being.

The demographic information of the chosen respondents, shown inTable 1, indicates that there are 210 female and 290 male respondents. The respondent’s region is classified into three categories. (a) Urban, (b) Rural and (c) Semi-urban. Of these respondents, 110 are from semi-urban areas, 150 are from rural areas, and 240 are from metropolitan areas.

The descriptive statistics (Table 2) for the key psychological variables assessed in the study: AI Anxiety, Attitude Toward AI, Cognitive Skills, and Decision Fatigue, based on a sample of 500 participants. The mean score for AI Anxiety was 4.62 (SD = 1.14), demonstrating a moderately high level of anxiety pertaining to the use of technologies for AI. The distribution was slightly negatively skewed (–0.28) with low kurtosis (–0.44), indicating a distribution that is comparatively normal but with a propensity for certain participants to express higher anxiety levels.

Attitude Toward AI had a mean of 5.01 (SD = 1.06), demonstrating mostly positive opinions towards AI among the participants. The data were also negatively skewed (–0.36), suggesting a slight inclination towards more positive attitudes.

The mean for Cognitive Skills was 3.72 (SD = 0.78), suggesting a comparatively high degree of self-perceived cognitive functioning on a 5-point scale. The skewness (0.03) and kurtosis (–0.61) values indicate a nearly symmetrical and slightly flat distribution.

Decision Fatigue yielded a mean of 3.94 (SD = 0.83), indicating that many participants, especially in AI-related contexts, experienced moderate to high levels of cognitive strain when making frequent decisions. The distribution was approximately normal, with slight negative skewness (–0.22) and mild platykurtosis (–0.37). Overall, the data is approximately normally distributed with only minor deviations in skewness and kurtosis; Since all skewness values are between –1 and +1, and all kurtosis values are between –1 and +1.

The findings of the study (Table 3) demonstrate a strong, positive association between participants’ attitude towards AI and their frequency of technology use (r= 0.806), suggesting that more favourable positive perceptions of AI are associated with increased engagement and adoption of AI-enabled technology. As shown inFigure 1, despite the strong correlation, the statistical significance was marginal (p= .053), marginally beyond the conventional threshold ofp< .05. However, this tendency offers significant evidence in support of the premise that attitudes towards AI have a significant impact on how AI-based tools are adopted and used.

The findings highlight that participants are more inclined to use AI more regularly if they believe it to be a useful, effective, and reliable technology. This is consistent with the expanding knowledge that a person’s attitudes, perceptions and level of comfort with AI might influence behavioural outcomes related to its use. The marginal significance suggests that more research with larger and more diverse samples may be necessary to fully confirm and clarify the strength of this relationship, as individual differences in digital literacy, exposure to AI technologies, and resource availability may also have an impact on the results.

These findings partially support the proposedH1on how user attitudes influence the adoption and usage trends of AI. Developers, researchers, and policymakers can create interventions that promote more positive views of AI by having a better understanding of this relationship. This will ultimately encourage the responsible and efficient use of AI in a variety of contexts.

The present study sought to examine (Table 4) whether users with prior positive experiences and a basic understanding of AI systems demonstrate greater trust and confidence in using AI. The results of the Pearson correlation analysis provide evidence in favour of this hypothesis and emphasise the important connections between different dimensions of trust in AI, including perceptions of reliability, task assurance, increased efficiency, preference for human judgment, and command over AI technologies.

As illustrated inFigure 2andTable 4, a moderately strong positive correlation was found between perceived reliability of AI recommendations and confidence in task performance (r= 0.486), implying that people are more likely to feel secure using AI tools to complete jobs if they believe these systems are trustworthy. Additionally, this is supported by a strong correlation between reliability and perceived improvement in productivity (r= 0.597), reinforcing the view that users’ earlier positive experiences with AI and their awareness of its usefulness contribute to their trust in the AI. These findings align with prior literature highlighting the significance of performance-based trust (Hoff & Bashir39; Schaefer et al.40), whereby consistent and dependable AI outcomes reinforce user confidence and acceptance.

Additionally, the observed strong correlation between perceived reliability and control over AI tools (r= 0.829) reveals that trust in AI systems is also deeply connected to a user’s perceived agency. This is consistent with the socio-technical perspective that highlights user autonomy as a central factor in human–AI interaction (Glikson & Woolley41). Users are more inclined to embrace and depend on AI systems—even in challenging or high-stakes situations—when they feel in charge of them.

Additionally, the findings showed that a preference for human judgment, despite being usually linked with scepticism toward AI, was positively correlated with trust-related dimensions such as confidence in tasks (r= 0.510) and control (r= 0.902). This suggests that having trust in AI is not always a prerequisite for appreciating human oversight; instead, it may reflect a desire for a hybrid decision-making approach in which AI augments rather than replaces human input (Dzindolet et al.42).

Notably, the strongest correlation was observed between confidence in tasks and improved productivity (r= 0.985), highlighting how consumers perceive AI’s benefits in terms of cognition and performance. However, weaker correlations between confidence and control (r= 0.423) and between automating decisions and reliability (r= 0.311) imply that worries about predictability, transparency, or lack of experience with algorithmic decision-making still influence some components of trust.

Taken together, these findings give empirical support for the hypothesis that users with prior positive experiences and a basic knowledge or understanding of AI are more likely to demonstrate higher levels of trust and confidence in AI systems. This has real-world ramifications for how AI tools are developed and implemented.

The present study inTable 5andFigure 3explored user perceptions of the influence of AI on cognitive engagement and decision fatigue, focusing on the hypothesis that AI may assist in reducing decision fatigue by streamlining choices. Prolonged reliance on AI is more likely to contribute to a decline in users’ cognitive engagement and independent decision-making skills. Results derived from descriptive analysis and Pearson correlation coefficients provide a nuanced grasp of the ways in which AI impacts different cognitive and psychological domains.

Despite the widespread assumption that AI always lessens decision fatigue, the findings of this study did not reveal strong positive correlations supporting this notion. Specifically, the relationship between the perception that AI offers too many choices and that it conserves mental energy was negligible (r= –0.05), implying that although participants recognise AI’s potential to reduce effort, choice overload could also cause complexity. This aligns with earlier research indicating that AI tools, despite being efficiency-oriented, can contribute to ‘choice paralysis’ or increased mental burden (Hadar et al.43). However, the hypothesis found partial support in relation to concerns over cognitive engagement. A moderate positive correlation was observed between perceived reduction in attention capacity due to prolonged AI exposure and lowered self-assurance in independent decision-making (r= 0.32). This correlation suggests that prolonged use of AI-enabled technologies may be associated with lower attentional resources and diminished confidence in cognitive autonomy. These findings echo earlier concerns raised in cognitive science literature, where overreliance on decision aids has been associated with underdevelopment of critical thinking and learned helplessness (Shariff et al.44).

Interestingly, while the participants overwhelmingly agreed that AI tools are used to conserve mental energy (100% agreement), correlations between this perception and indicators of cognitive fatigue or reduced self-assurance were weak (e.g.,r= –0.18 with cognitive exhaustion). This raises the possibility of a dissonance between perceived usefulness and experienced psychological outcomes.

Furthermore, the weak and sometimes inverse relationships between various dimensions of AI interaction and fatigue (e.g.,r= –0.25 between mental exhaustion and repeated interaction) indicate that the psychological experience of AI engagement is multifaceted. These correlations may be moderated by elements including task type, interface design, and user familiarity, all of which merit more empirical research.

Long-term dependence on AI may in fact, impair cognitive engagement and trust in one’s ability to make independent decisions, even though the predicted decrease in decision fatigue due to simplified choices was not statistically supported. This emphasises how crucial it is to create AI systems that maintain users’ cognitive agency and critical engagement while simultaneously enhancing human capabilities.

Table 6andFigure 4presents the study’s results, which indicate noteworthy correlations between long-term interaction with AI systems and a range of cognitive and psychological outcomes. Long-term use of AI technology was, as expected, strongly associated with information overload, mental exhaustion, and diminished attentional capacity. These results support prior literature suggesting that prolonged interaction with AI can lead to cognitive fatigue and mental depletion (Jones et al.45). Notably, long-term interaction (r= 0.996) and AI tools that reduce mental effort in decision-making (r= 0.915) both demonstrated strong, positive correlations with repeated interaction, reduced attention capacity, and an abundance of information. Collectively, these results demonstrate the cognitive cost of long-term AI use.

Similarly, AI’s propensity to overwhelm users by presenting too many choices was strongly associated with lower attention capacity (r= 0.908) and information overload (r= 0.920), indicating that decision architecture in AI settings can exacerbate mental stress and impede efficient information processing. These findings align with established theories of decision fatigue and cognitive load, wherein an abundance of options impedes attention and increases the risk of information fatigue (Schwartz46).

Perhaps most notably, lower self-assurance in individual decision-making was negatively associated with long-term interaction (r= −0.360), repeated interaction (r= −0.401), and AI’s prevention of mental effort (r= −0.287). This trend suggests that overreliance on AI for decision-making may erode trust in one’s own judgment, aligning with growing concerns about the psychological impacts of AI-mediated environments (Lee & See47). Notably, this degradation of self-assurance appeared largely unrelated to information overload (r= 0.014), suggesting that rather than being purely cognitive, its causes might be more directly related to autonomy and perceived effectiveness.

Overall, these results highlight the intricate relationship between long-term AI use and its effects on cognition and psychology. The data support the hypothesis that, although AI tools can reduce short-term cognitive load, their long-term and repeated use may result in cognitive fatigue, attention depletion, and diminished self-confidence in decision-making. This emphasises a crucial factor to take into account when designing and implementing AI: striking a balance between efficiency and convenience and maintaining user autonomy and cognitive well-being. We can create AI ecosystems that promote productivity and mental well-being.

The findings of the study provide insight into the intricate relationship among the usage of AI, user perceptions, and cognitive-psychological effects. The study reveals despite offering benefits like improved reliability and efficiency, AI also creates evolving problems. The data confirmed that more favourable attitudes toward AI relate positively to higher engagement levels, suggesting that trust and perceptions of efficacy play pivotal roles in the adoption of AI tools (Venkatesh et al.48; Zhang & Dafoe49). A marginally significant trend was found, suggesting the need for further research involving larger and more diverse sample groups to confirm this association.

Consistent with prior literature (Hoff & Bashir39; Schaefer et al.40), according to the current study, trust is largely dependent on user perceptions and AI reliability, particularly when AI is implemented in high-impact contexts. Strong correlations between reliability, productivity, and perceived control emphasise the significance of user autonomy as a determinant of trust and engagement (Glikson & Woolley41). Interestingly, a concurrent preference for human judgment emerged, suggesting that trust in AI does not imply its wholesale replacement of human decision-making but rather the establishment of a collaborative paradigm (Dzindolet et al.42).

Notably, this investigation reveals that the integration of AI may induce dichotomous consequences on cognitive load, wherein it simultaneously diminishes and amplifies mental exertion. While some users perceive AI as a means to reduce mental effort, long-term exposure and repeated interactions appear to hamper attention, diminish self-assurance, and foster information overload (Shariff et al.44; Jones et al.45; Schwartz46). These findings indicate a significant paradox whereby AI can concurrently function as an efficiency facilitator while also contributing to cognitive debilitation, thereby supporting hypotheses regarding learned powerlessness and the erosion of intrinsic decision-making autonomy.

This research affords substantial empirical validation for the requisite of a harmonious equilibrium between the psychological benefits and drawbacks of AI in fostering sustained engagement. Future investigations should adopt a longitudinal methodology to scrutinise the enduring behavioural and cerebral repercussions of AI utilisation as these technologies evolve and assume an increasing presence in both personal and professional settings. Design interventions prioritising cognitive scaffolding, user autonomy and transparency are likely to mitigate cognitive strain and facilitate trust. Such initiatives possess the potential to cultivate AI ecologies that not only exhibit efficacy and productivity but also sustain human autonomy and cognitive well-being.

Future research should adopt a multi-method approach to further elucidate the complex interplay between AI usage and cognitive-psychological outcomes. Longitudinal studies that track changes in cognitive load, decision-making behaviour, and trust across extended periods of AI interaction are vital for understanding the long-term consequences of human–AI collaboration. Such investigations would benefit from integrating behavioural metrics, psychometric assessments, and neurophysiological measures (e.g., EEG, fMRI) to deepen our understanding of how AI influences attention, cognitive strain, and self-assurance over time.

Furthermore, designing AI interfaces and interventions that maximise trust, strike a balance between autonomy and support, and lessen cognitive fatigue can be guided by these principles. In this situation, qualitative techniques, such as focus groups and interviews, might enhance quantitative methods by offering complex viewpoints on how users feel about AI tools.

Future studies should also investigate the efficacy of design interventions such as transparency-enhancing features, user-centric feedback loops, and adaptive complexity settings to mitigate the risk of cognitive strain and ‘choice paralysis’ associated with AI platforms. Such research has the potential to inform best practices for AI implementation across diverse domains, including clinical, educational, and organisational settings, ensuring that advances in AI technologies evolve in tandem with the psychological and neurocognitive well-being of their end-users.

I would like to express my sincere gratitude to my supervisor and corresponding author, Dr Nidhi Verma, for her invaluable guidance, continuous support, and encouragement throughout the course of this research and the preparation of this manuscript. Her insights and expertise were crucial to the success of this work. I also extend my appreciation to my co-authors, Kapil Dev, Dr Aradhana Balodi Bhardwaj and Dr Krishan Kumar, for their significant collaborative efforts, which greatly enhanced the quality of the manuscript.

Finally, we are thankful to all the participants who generously gave their time and shared their valuable insights for this study.

Funding:The authors received no financial support for the research, authorship and/or publication of this article.

Shalu: Conceptualisation, Methodology, Data collection & Curation, Formal Analysis, Writing: Original Draft.

Nidhi Verma: Conceptualisation, Supervision, Project Administration, Result, Writing: Review & Editing.

Kapil Dev: Investigation, Helped in Data Collection.

Aradhana Balodi Bhardwaj: Supervision, Validation, Writing: Review & Editing.

Krishan Kumar: Resources, Visualisation, Validation, Writing: Review & Editing.

All authors have read and approved the final version of the manuscript.

Informed consent was obtained from all individual participants included in the study. Participation was voluntary, and confidentiality of all participant data was maintained throughout the research process.

This manuscript does not involve any direct data collection from patients. No patient data (including identifiable information, medical records, or personal health details) were used, and therefore, patient consent was not required.