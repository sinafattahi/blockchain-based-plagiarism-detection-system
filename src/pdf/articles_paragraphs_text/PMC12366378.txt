Sepsis remains a leading cause of mortality worldwide, driven by its clinical complexity and delayed recognition. Artificial intelligence (AI) offers promising solutions to improve sepsis care through earlier detection, risk stratification, and personalized treatment strategies. Key applications include AI-driven early warning systems, subphenotyping based on clinical and biological data, and decision support tools that adapt to real-time patient information. The integration of diverse data types, such as structured clinical data, unstructured notes, waveform signals, and molecular biomarkers, enhances the precision and timeliness of interventions. However, challenges such as algorithmic bias, limited external validation, data quality issues, and ethical considerations continue to hinder clinical implementation. Future directions focus on real-time model adaptation, multi-omics integration, and the development of generalist medical AI capable of personalized recommendations. Successfully addressing these barriers is essential for AI to deliver on its potential to transform sepsis management and support the transition toward precision-driven critical care.

Sepsis is a dysregulated response to infection that can lead to life-threatening organ dysfunction [1], which affects nearly 50 million people worldwide annually [2]. Advances in critical care have increased in-hospital survival to 85% [3–5]. Sepsis survivors have excess long-term morbidity [5] and a 5-year survival rate of 60% [6]. Despite advancements in many other medical areas, sepsis remains a complex and elusive condition to recognize in its early stage and treat effectively. The host response to the infection involves complex interplays, such as the interaction between the immune response and the coagulation system. If systemic decompartmentization of inflammation from the original focus of infection occurs, patients may often suffer from arterial hypotension, distributive shock, and widespread coagulation impairment, such as disseminated intravascular coagulopathy, leading to multiple organ failure development [7,8]. Conversely, immune system hyperresponsiveness may occur in some patients, leading to overwhelming infection. This immunological imbalance is now considered a hallmark of sepsis pathogenesis and a target for precision medicine approaches [9].

Clinical studies have demonstrated higher survival rates of septic shock associated with earlier administration of antibiotics, this emphasizes the importance of rapid intervention to decrease mortality and morbidity [10]. Patient heterogeneity adds to this complexity, with individual responses to infection varying based on genetics and health status. For instance, patients with underlying diseases such as diabetes mellitus, immunodeficiency, autoimmune diseases, chronic lung, kidney, or liver diseases, and cancer, as well as individuals at the extremes of age including newborns and the elderly, are more susceptible to severe infections and the development of sepsis. Recent advances in sepsis research underscore the need for molecular stratification of these patients to tailor treatment strategies [11].

Antimicrobial resistance (AMR) is a growing concern globally that complicates sepsis treatment. In some countries, the emergence of resistant pathogens has severely limited treatment options, often leaving clinicians with few or no effective therapies. As a result, resistant infections significantly contribute to the mortality burden, accounting for an estimated 1.27 million deaths worldwide annually [12]. Early diagnosis and individualized treatment are essential for improving outcomes, yet current approaches often fail to address the heterogeneity of patient responses [13].

In 2021,Critical Care MedicineandIntensive Care Medicinepublished new guidelines for sepsis management, called The Surviving Sepsis Campaign [14], offering clinicians state-of-the-art instructions for treating patients with sepsis or septic shock. The guidelines stress the importance of early identification and appropriate management in the initial hours after sepsis development. As mentioned before, timely intervention in sepsis care is crucial, as for each hour delay of proper treatment, mortality increases by 7.6% from the onset of hypotension [15]. To this end, early administration of antimicrobials and adequate hemodynamic resuscitation using fluids and vasopressors depending on the patient’s needs, ideally within one hour of recognition, is essential for patients with hypotension and sepsis. The sepsis management guidelines recommend early elimination of the infection focus, including empiric administration of a combination of broad-spectrum antibiotics and, when necessary, surgical intervention such as incision and drainage of abscesses. It is important to note that samples for microbial analysis should be taken prior to antibiotic administration to increase the diagnostic yield [16]. Additional treatment strategies addressing vascular leakage and endothelial dysfunction are also under investigation to stabilize circulatory collapse in sepsis [17]. Sepsis-induced coagulopathy further complicates management and has been linked to poor outcomes in multiple studies [18].

Advances in AI have opened new opportunities for precision medicine in sepsis care, offering tools to address the unique diagnostic and treatment challenges posed by this highly heterogeneous and time-sensitive condition. AI-driven models show promise in enhancing early detection, risk stratification, and treatment personalization [19]. By analyzing large datasets from clinical and molecular sources, AI holds potential for enabling more tailored interventions in sepsis. However, clinical implementation and evidence for improved outcomes remain limited at present [20].

This narrative review outlines three potential use cases for AI in sepsis care, followed by a discussion of key challenges that must be addressed to improve AI applications in this field. It then explores promising future directions before concluding with final remarks. The focus is on adult sepsis management, reflecting the current clinical definitions (including Sepsis-3) and the predominant application of AI technologies in adult patient populations.

While several reviews have explored the promise of AI in sepsis management, focus mainly either on early detection models [21,22] or on specific algorithmic techniques [23,24], but to a less extend aspects such as clinical translation, regulatory evaluation, and real-world implementation. This review aims to address that gap by providing a structured synthesis of AI applications across the sepsis care continuum, from early prediction and phenotyping to therapeutic guidance and deployment in clinical settings, while also explicitly addressing associated challenges and promising directions for future research.

AI technologies show promise for enabling earlier interventions, more precise patient categorization, and personalized treatment strategies. However, these applications remain largely investigational and require further validation before widespread clinical adoption. Three critical use cases of AI in sepsis care include early detection, sepsis subphenotyping for risk stratification, and targeted treatment.

One of the most promising applications of AI in sepsis management is its ability to detect the condition at an early stage. This may enable earlier identification of patients at risk and demonstrates strong predictive performance; however, evidence for improved clinical outcomes resulting from the use of such models remains limited [25].

Numerous AI-driven early warning algorithms for sepsis detection have been developed and evaluated in diverse clinical settings. One of the more extensively studied sepsis prediction tools is the InSight algorithm, which was initially developed and internally validated using retrospective data [26]. While that study demonstrated promising performance metrics, it did not compare InSight to traditional scoring systems. A subsequent prospective clinical trial showed that InSight implementation was associated with earlier sepsis detection and reduced ICU length of stay compared to usual care [27]. In addition to early detection of sepsis, AI-driven warning algorithms have been explored as tools to guide the timing of critical interventions, such as renal replacement therapy in patients with acute kidney injury related to sepsis. Retrospective analyses suggest potential associations between earlier AI-triggered intervention and improved outcomes, but prospective evidence remains limited and inconclusive [28]. The validation and implementation of these systems remain challenging. Diagnostic suspicion bias and a lack of rigorous validation can undermine the generalizability and real-world effectiveness of machine learning-based sepsis detection tools [29].

Other AI models, such as the Sepsis Early Risk Assessment (SERA) algorithm and the Targeted Real-Time Early Warning System (TREWS), process large datasets in real-time to enhance early sepsis detection. SERA combines structured data (e.g., vital signs) and unstructured clinical notes using Natural Language Processing (NLP) to predict sepsis up to 12 h before onset [30]. TREWS continuously monitors patient data, flagging potential sepsis cases before they become clinically apparent. A prospective evaluation suggested that early alert confirmation (within 3 h) was associated with faster treatment initiation, though the absence of a non-TREWS control group and potential confounders limit causal interpretation [31]. Subsequent analyses have raised additional concerns, including exclusion of false detections and cases where antibiotics were administered prior to the alert [32]. Both SERA and TREWS have demonstrated strong predictive accuracy, with reported AUC values of 0.94 and 0.97, respectively. The SERA algorithm’s performance is based on single-center internal validation [33]. TREWS has undergone prospective, multi-center evaluation, but its reported AUC value was derived from internal validation datasets [34].

Despite promising results, concerns regarding external validation and clinical implementation remain [35]. The clinical benefits of automated sepsis early warning systems extend beyond individual studies. A recent systematic review and meta-analysis demonstrated that these systems significantly reduced hospital mortality, ICU admissions, and length of stay [36]. These AI systems streamline clinical workflows by automating the detection process, allowing healthcare professionals to focus on decision-making and patient care.

AI models such as the previously mentioned TREWS and SERA, and the Epic Sepsis Model, differ markedly in their core features, validation methods, and clinical applicability, reflecting substantial heterogeneity in both performance and methodological rigor. As summarized in Table1, these tools vary widely in input data requirements, reported AUC values, positive predictive performance, and degree of prospective evaluation. Although AUC is a frequently used performance metric, it does neither reflect clinical utility at decision-relevant thresholds nor provide insights into the calibration of the model [37]. Models such as TREWS report high AUCs but relatively low PPV, which may limit their actionability in real-world settings and contribute to alert fatigue. While TREWS demonstrated mortality benefit in a large multi-center prospective study [34], models like SERA [33] and the AI Clinician [38] remain confined to retrospective evaluation. Conversely, the Epic Sepsis Model showed markedly lower performance in independent validation (AUC ~ 0.63), despite wide adoption [39]. More recently, COMPOSER has shown promising prospective precision using language model-enhanced inputs [40]. These findings underscore that metrics like AUC alone may obscure critical limitations such as poor calibration or excessive alert volume.

To summarize, early warning systems represents the most commonly addressed use case for AI in sepsis care with models that show a seemingly promising performance, however, often lacking external validation and with still largely uncertain clinical impact.

The capacity of AI to manage the complexities of sepsis extends beyond early detection, offering a powerful tool for subphenotyping, which categorizes patients into subtypes based on clinical and biological characteristics. These subphenotypes are associated with differing risks of clinical outcomes and may require tailored therapeutic approaches that could alter the disease trajectory. This shift from standardized treatments to personalized strategies utilizes unsupervised learning algorithms to process large patient datasets, identifying clinically relevant patterns and suggesting adaptive treatment approaches tailored to subphenotypes, which may inform future improvements in clinical management and outcomes [41]. In this context, “phenotype” refers to observable clinical characteristics, while “subphenotype” denotes data-driven groupings identified through unsupervised learning techniques. To maintain terminological clarity, the term “endotype” is not used and molecularly defined variants are referred to as “subtypes”.

A notable example of AI-driven phenotyping is the identification of four distinct sepsis phenotypes, α (alpha), β (beta), γ (gamma), and δ (delta), through machine learning algorithms [42]. Factors like inflammatory markers, organ dysfunction, and mortality risk differentiate these phenotypes. For instance, the δ phenotype, characterized by severe organ dysfunction and high inflammation, is associated with the highest mortality rate. In contrast, the α phenotype, with less severe organ impairment, has better outcomes. Recognizing these phenotypes early may enable clinicians in the future to tailor treatments such as fluids, vasopressors, and antibiotics based on the specific needs of each patient group.

In addition to unsupervised clustering approaches for identifying sepsis phenotypes, trajectory-based methods have also been used to define subphenotypes based on longitudinal patterns of vital signs. These approaches have identified distinct temperature trajectory-based sepsis subphenotypes associated with differing host inflammatory responses and clinical outcomes [43]. Causal inference frameworks offer a complementary strategy aimed at discovering subgroups that respond differently to specific treatments. Recent work using causal inference techniques has demonstrated the potential to identify distinct sepsis phenotypes that exhibit differential responses to interventions, such as fluid resuscitation strategies [44].

Despite their promise, most AI-driven phenotypes remain observational and have not yet been incorporated into prospective interventional trials or decision-support systems [42]. Translational barriers include limited real-time identifiability, unclear therapeutic implications, and the lack of validated protocols linking phenotype classification to bedside interventions [43,44].

To summarize, the attempt to identify sepsis (sub)phenotypes is a promising use case for AI in sepsis care to address the inherent heterogeneity of sepsis. However, the clear differentiation of phenotypes their connection to different therapy response and/or differences in hard outcomes remains challenging.

AI plays a critical role in personalizing treatment by predicting how individual patients will respond to therapies. By analyzing historical data, real-time patient information (vital signs, lab results, clinical history), and outcomes, AI models help clinicians tailor interventions to maximize efficacy while minimizing risks. For example, predictive models can guide antibiotic selection or vasopressor timing and dosage based on the patient’s unique physiological state [45].

Systems like the AI Clinician use reinforcement learning to adjust fluid and vasopressor recommendations based on real-time data dynamically, optimizing treatment strategies in rapidly changing critical care settings [46]. The AI Clinician, first described in a seminal study applying reinforcement learning to sepsis treatment strategies, demonstrated the potential of AI systems to recommend optimal fluid and vasopressor dosing based on retrospective ICU data [47]. A recent prospective validation study, the OVISS trial, extended this approach by evaluating reinforcement learning–based treatment recommendations for vasopressors and fluids in real-world ICU settings. The study demonstrated clinical feasibility and higher adherence to AI-suggested regimens, with trends toward improved patient outcomes compared to clinician-administered care [48]. Tree Augmented Bayesian Networks (TAN) and Dynamic Treatment Regimes (DTRs) similarly help clinicians manage sepsis risks by providing real-time updates to treatment plans and adapting to short-term changes in patient conditions [49,50].

Incorporating sepsis subphenotypes (such as α, β, γ, or δ) alongside real-time data further enhances personalized care by categorizing patients based on their clinical and biological characteristics. This ensures more aggressive care for severe phenotypes and conservative management for milder cases. Subphenotype-based treatment plans continuously adapt to evolving patient conditions, improving outcomes through timely interventions.

Looking forward, AI tools will increasingly integrate omics data, such as genomics, epigenomics, transcriptomics, proteomics, lipidomics, and metabolomics, to provide even more personalized treatment recommendations tailored to each patient’s molecular profile. To summarize, AI-supported clinical decision support holds the promise to provide individualized treatment recommendations supported by data. This requires counterfactual reasoning skills, which are challenging to implement. It is therefore the least developed use case for AI in sepsis care.

AI in sepsis care faces many challenges, which we broadly categorize as foundational, methodological and deployment-related and discuss in detail the following paragraphs.

Machine learning models for sepsis recognition often face challenges due to the inherent complexity of the condition and the variability in its presentation. The absence of a single “gold standard” definition for sepsis complicates model comparisons, though the Sepsis-3 criteria, based on SOFA score changes and organ dysfunction, are increasingly accepted. This variability is further compounded by different clinical settings (e.g., ED, general ward, ICU) and the specific endpoints used, such as sepsis versus septic shock [51]. Large clinical care datasets are often used to train models, but they frequently lack the specific parameters needed to calculate the SOFA score, hindering accurate case labeling. The electronic SOFA (eSOFA), which relies on more commonly available parameters, may enable more reliable labeling of sepsis cases within such datasets [52]. Awareness of these seemingly subtle differences is essential, particularly when comparing models across different publications.

A comparative evaluation of early detection models for sepsis represents a major challenge. Prediction scores are normally obtained from retrospective analyses, typically measured at the encounter level using data collected within a pre-specified window prior to sepsis onset [13,14]. Dataset characteristics, including balancing, sepsis prevalence, and case definition criteria, strongly influence these performance metrics [33,34]. The AUC is often used as a measure of overall predictive performance; however, clinical implementation requires additional metrics, such as sensitivity and positive predictive value (PPV), evaluated at alert thresholds relevant to clinical practice. These metrics are essential to assess the potential impact of false positives and false negatives on workflows and decision-making.

Although many AI models demonstrate impressive accuracy in controlled research environments, their real-world performance can be inconsistent. Differences in patient populations, healthcare practices, and data quality between hospitals limit generalizability​ [53,54]. External validation of AI models across diverse settings is essential to build confidence in their reliability and ensure they can handle the complexity of real-world medical environments. Without rigorous validation, clinicians cannot rely on AI-driven tools to support clinical decision-making, further limiting their integration into clinical practice​ [55]. External and prospective validation across diverse settings is therefore critical to establish reliability before clinical integration. Several recently published multi-site studies have addressed this gap, and prospective implementation studies have reported promising outcomes [56–58], including reductions in mortality. Nevertheless, randomized controlled trials remain the gold standard and are still pending [59].

The risks of deploying models without rigorous validation are illustrated by the Epic Sepsis Model (ESM). Despite widespread adoption through Epic’s electronic health record, an external evaluation at the University of Michigan revealed that ESM missed 67% of sepsis cases, showing low sensitivity and raising serious concerns about its clinical utility. This case underscores the need for thorough external validation and prospective evaluation before integrating AI-driven prediction tools into clinical workflows [60].

As the clinical use of AI-based decision support systems in sepsis management expands, it raises a critical question: should these tools be held to the same standards of clinical validation as pharmacologic agents, diagnostic biomarkers, or medical devices? While most AI models are currently deployed after retrospective validation and occasionally external testing, few undergo the kind of prospective, real-world evaluation required for other clinical interventions.

Recent systematic evaluations of FDA-approved AI/ML-enabled medical devices show that fewer than 10% are supported by prospective clinical trials, and even fewer provide transparent reporting on model performance across patient subgroups or settings [61]. This stands in contrast to the standards expected for traditional interventions such as drugs or invasive monitoring devices, which require evidence from randomized controlled trials (RCTs) demonstrating clinical benefit, not just predictive accuracy.

Yet designing RCTs for AI interventions, especially those operating in the background or “silently”, raises unique challenges. In silent deployment, AI models may process data and generate risk predictions without alerting clinicians, allowing for unobtrusive evaluation of model performance. However, this setup complicates the application of clinical equipoise and informed consent, since patients may be randomized to arms where potentially actionable insights are withheld. These challenges raise profound ethical concerns, particularly around transparency, patient autonomy, and fairness, as silent deployment may undermine informed patient choice and institutional accountability. Moreover, silent trials blur the boundaries between observational and interventional research, complicating regulatory classification and challenging the oversight mechanisms typically used for clinical investigations. A robust ethical framework is needed to guide the design of such studies, including mechanisms to safeguard patient rights even when disclosure is limited. In light of these difficulties, alternative approaches rooted in causal inference have been proposed, in which emulated target trials using real-world data, such as EHRs, can approximate RCT conditions. For example, it has been reported that replicates RCT results using observational data, highlighting how carefully designed causal models can offer valid treatment effect estimates when traditional RCTs are infeasible or ethically constrained [62]. Such frameworks may be especially valuable in the context of AI systems deployed silently, where prospective experimentation is hindered by regulatory ambiguity and consent challenges.

From a methodological standpoint, these trials often rely on complex causal inference frameworks to compare outcomes across AI-assisted and standard care arms, yet such comparisons are sensitive to unmeasured confounding, patient heterogeneity, and context-specific clinical workflows [63]. However, these causal inference findings remain hypothesis-generating, are limited by unmeasured confounders and the static nature of current phenotyping approaches in this dynamic disease, and are not yet validated bedside strategies; prospective randomized trials are essential to confirm their clinical utility. Moreover, if clinician behavior is influenced, even unconsciously, by the presence of AI tools in the system, true isolation of effects becomes elusive. As such, while RCTs remain the gold standard for clinical validation, alternative designs, such as stepped-wedge trials or quasi-experimental models with robust sensitivity analyses, may offer pragmatic pathways for evaluating AI in dynamic and ethically sensitive settings.

A growing body of literature calls for more rigorous and standardized frameworks for evaluating AI in healthcare. These frameworks advocate for adaptive, risk-based regulatory approaches but emphasize the need for prospective evidence of clinical utility prior to deployment [64–66]. This perspective is especially relevant in sepsis care, where real-time decisions about fluids, antibiotics, and vasopressors can have immediate consequences for patient outcomes.

A limited but growing number of AI-based systems for sepsis have undergone prospective evaluation. For example, the NAVOY®Sepsis algorithm was recently assessed in a randomized controlled trial using Sepsis-3 criteria and demonstrated a statistically significant improvement in early sepsis identification and timely treatment initiation [67]. A multimodal large language model–driven system was prospectively evaluated in ICU settings, demonstrating robust real-time performance and workflow integration [68]. Another example, the Sepsis Watch model, has undergone multisite external validation, illustrating both its potential and the challenges of reproducibility in diverse clinical environments [69].

Moving forward, AI systems intended for high-stakes decisions in critical care should undergo clinical validation standards similar to those applied to devices or diagnostics. This includes not only technical performance and fairness evaluations but also prospective trials to determine their actual impact on patient outcomes.

The field of AI in sepsis care is subject to significant publication and reporting bias. Studies highlighting successful or high-performing models are more likely to be published, while those that fail to generalize or show limited clinical benefit often remain underreported. The failure of the widely deployed Epic Sepsis Model (ESM), which was only publicly scrutinized after an external evaluation revealed it missed 67% of sepsis cases, illustrates how such biases can distort perceptions of progress and delay critical scientific learning [70]. Learning from models that fail in external validation or real-world deployment is essential, as these cases often reveal hidden biases, fragile assumptions, or context-specific limitations that are crucial for developing more robust and equitable AI systems [71]. Failed models should therefore be systematically audited through post-hoc performance analyses, recalibration efforts, and transparent reporting practices to inform future model development and deployment strategies.

The“black box”nature of many AI models, particularly deep learning systems, poses significant challenges for clinicians in trusting AI-generated recommendations. Various Explainable AI (XAI) techniques have been developed, often applied as post-hoc analyses to trained models. These methods identify the most influential input features and offer approximate insights into why a model made a specific prediction. However, they do not provide true transparency into the model’s internal logic or how it generalizes across different contexts.

Shapley-value-based methods are widely used for tabular data, and post-hoc attribution techniques have been adapted for physiologically relevant domains, such as time series data [24]. While these techniques highlight important input features, they offer only limited and sometimes incomplete insights into the model’s overall behavior. Thus, their direct benefit to end-users in clinical decision-making remains unproven, though XAI provides a promising foundation for model auditing and knowledge discovery [72]. To address current limitations, rigorous validation protocols similar to those used for drug approval have been proposed to evaluate model performance across diverse patient subgroups [73].

Explainable techniques that provide clear insights into AI recommendations can contribute to building trust and ensuring safe clinical use. However, achieving transparency and accountability will require broader approaches, including interpretability by design, clinical oversight, and governance frameworks [74–76]. This challenge is not unique to sepsis detection but also applies to AI-driven phenotyping, where classifications must be both actionable and understandable to clinicians. Opaque or overly complex phenotypes risk eroding trust and limiting adoption​ [77].

AI models are only as good as the data on which they are trained, posing the risk of algorithmic bias. If training datasets do not adequately represent the diversity of patient populations, models may underperform in specific demographic groups, potentially leading to inequities in sepsis care where early detection is critical [55]. For example, an AI model trained primarily on data from one demographic might struggle to detect sepsis in patients from other ethnic or socioeconomic backgrounds, potentially leading to delayed or inappropriate treatment. AI systems must also mitigate biases in data, as these can lead to unfair treatment or discrimination [78]. Recent studies have shown that racial disparities in pulse oximetry accuracy, which lead to systematically underestimated hypoxemia in certain patient groups, can propagate through sepsis prediction models and amplify inequities in early detection [79].

Differences in the use of life-sustaining interventions such as mechanical ventilation, vasopressors, and renal replacement therapy across racial and ethnic groups, often associated with underlying socioeconomic disparities, have been documented in ICU patients with sepsis and may introduce confounding patterns into AI models trained on real-world critical care data [80]. Mitigation strategies, including subgroup-specific validation, bias-aware training, and continuous post-deployment auditing, are essential to ensure equitable sepsis care.

Critical care data often contain missing values or inconsistent entries, which can significantly affect model predictions [81]. In high-stakes environments, even minor gaps can lead to unreliable AI-driven decisions. For example, predictive models in neonatal care have been shown to suffer from inconsistencies in patient records, skewing results and reducing reliability [82]. Incomplete or inaccurate data not only undermine AI-generated recommendations but also erode clinicians’ trust in these systems.

The predictive performance of AI models is directly linked to the completeness and accuracy of their training datasets. Limited data coverage and poor standardization remain major obstacles, particularly when integrating heterogeneous sources [83]. Improving data quality through standardized documentation, robust preprocessing, and advanced imputation techniques will be crucial to ensure reliable and clinically acceptable predictions.

Integrating AI into existing healthcare systems poses both logistical and technical challenges. AI tools must be compatible with current EHR systems, which are often not optimized for advanced AI functionalities. AI algorithms not only demand sufficient computing power but also depend on the timely availability of input data in the appropriate format and resolution to function effectively. This requires substantial investment in infrastructure upgrades and coordination across departments [54]. Ensuring that AI systems enhance rather than complicate clinical workflows is key to fostering widespread adoption [54].

A further major barrier to real-world deployment is the clinical burden created by excessive alerts, which can strain healthcare resources and may even cause harm through unnecessary treatments. Even highly accurate models like TREWS can generate false alarms. This strains healthcare resources and may cause harm through unnecessary treatments​ [31]. False positives not only contribute to unnecessary interventions but can also lead to desensitization among healthcare providers, reducing their responsiveness to real alarms. This phenomenon, commonly known as alarm fatigue, has been widely documented in sepsis detection systems, where the balance between sensitivity and specificity must be carefully managed to minimize unnecessary alerts [84]. Efforts to improve sepsis detection models focus on reducing false positives by optimizing the timeliness of predictions and adjusting algorithms to weigh false alarms more heavily in the model’s training process. These improvements help ensure that alerts are triggered at the most clinically relevant times, thereby reducing alarm fatigue while maintaining early detection benefits [85]. In addition to these efforts, new models like COMPOSER are being developed to tackle alarm fatigue more effectively. The COMPOSER model leverages the formalism of conformal prediction, a technique that provides statistically robust out-of-distribution detection. This allows the model to identify samples that deviate significantly from the training data and refrain from making predictions in those cases, thus reducing the likelihood of false positives and improving overall prediction quality [86]. We would like to increase the readers’ awareness for not neglecting false positives compared to false negatives, which goes in hand with being transparent about the choice of the algorithm’s decision threshold. Approaches such as conformal prediction represent a promising innovative path to address this long-standing problem.

Finally, real-world implementation presents a significant hurdle. Models that perform well in controlled research environments may struggle in diverse healthcare settings. Healthcare institutions must invest in the necessary infrastructure and training to integrate these tools into daily practice [20]. Currently, no regulations exist regarding reimbursement for the use of AI models in clinical practice, despite the potential substantial costs incurred by manufacturers for their development, validation, and certification. Additionally, the economic burden of sepsis adds complexity, with hospital-related costs varying across healthcare systems [87]. Optimizing resource use and improving treatment efficiency through these advanced technologies could alleviate some of the financial strain.

In addition to economic and technical considerations, the successful deployment of AI systems must also address key principles from human factors engineering. Recent studies have highlighted how clinician perceptions of alert utility are shaped by cognitive load and prior experience, with less experienced providers often finding alerts more actionable and beneficial [88]. Moreover, effective implementation requires co-design with clinicians to reduce alert fatigue, support hypothesis generation, and ensure seamless workflow integration, features that have been shown to improve usability and clinical trust [89].

While the clinical promise of AI in sepsis care continues to grow, its real-world impact hinges on addressing critical economic and system-level barriers. Implementing AI tools requires more than technical validation, it also demands sustainable financing models, clear reimbursement pathways, and evidence of cost-effectiveness. Recent work has demonstrated the economic potential of AI-based sepsis prediction. For example, one study estimated that optimizing sepsis alert thresholds across diagnostic categories could result in nearly $4.6 billion in cost savings annually for the U.S. Medicare system, primarily by reducing unnecessary utilization and improving compliance at clinically relevant decision points [90]. Yet, cost-effectiveness analyses remain the exception rather than the norm. Few models undergo economic evaluation in parallel with validation studies, limiting stakeholders’ ability to weigh financial benefit against implementation cost and workforce burden.

Beyond quantifying potential savings, the adoption of AI systems in critical care is often limited by the lack of early health-economic analyses, limited evidence on cost-effectiveness, and uncertainty regarding real-world financial impact, factors that hinder informed investment and implementation decisions [91]. These systemic issues become particularly acute in under-resourced settings, where equity concerns compound the difficulty of deploying advanced AI infrastructure.

Another recent perspective argues that traditional evaluation metrics are insufficient for guiding AI deployment at scale. Instead, it proposes sociotechnical frameworks that integrate cost-benefit analysis with organizational readiness, data infrastructure maturity, and clinician acceptance [92]. From this viewpoint, demonstrating return on investment involves not only direct savings but also alignment with broader institutional goals, including quality improvement and staff efficiency.

Together, these findings suggest that the successful integration of AI in sepsis care will require a holistic approach that incorporates financial modeling, policy coordination, and system-level readiness, in addition to technical performance. Without attention to these economic dimensions, even well-validated tools may fail to deliver meaningful impact in clinical practice.

AI systems require access to vast amounts of data, often involving sensitive patient information sourced from electronic health records (EHRs), lab results, and physiological monitoring. However, concerns about data privacy and security are paramount, particularly in the context of compliance with regulations such as the General Data Protection Regulation (GDPR) and the Health Insurance Portability and Accountability Act (HIPAA). The challenge lies in balancing the utility of this data for AI models with the need to protect it from breaches or unauthorized access [93]. HIPAA mandates strict safeguards to protect personal health information (PHI) in both storage and transmission [94]. To address these concerns, advanced security measures such as encryption and access protocols are essential. Moreover, privacy-preserving techniques like federated learning, where models are trained on decentralized data without sharing raw information, offer a way to harness data for AI while maintaining strict privacy standards [95,96]. Another promising approach is data synthesis, which involves generating artificial datasets that mimic the statistical properties of real patient data without exposing individual identities; this allows AI models to be trained and validated while mitigating privacy risks. Even when data is de-identified, re-identification risks persist, particularly when dealing with large and complex datasets [97]. Therefore, continuous vigilance and evolving strategies are necessary to ensure patient data remains secure. Transparency also plays a key role: patients must be informed about how their data is used and protected, fostering trust in AI-driven healthcare systems [95]. As AI technologies advance, the need for strong privacy frameworks becomes even more pressing. Balancing innovation with robust data protection will ensure that the promise of AI in healthcare does not come at the cost of patient privacy [94].

Ethical and legal considerations, including compliance with GDPR and HIPAA, are essential for the safe implementation of AI in healthcare [93]. Beyond regulatory compliance, ethical challenges such as transparency, fairness, and clear accountability remain critical. The “black box” nature of many AI algorithms raises concerns about explainability, particularly when AI-driven decisions affect patient outcomes [93]. To foster trust, healthcare professionals and patients must understand how AI systems generate recommendations [98]. Equally important is defining responsibility and liability in the event of adverse outcomes, whether for developers, healthcare providers, or institutions [50]. The lack of clarity around accountability is a significant barrier to integrating AI into high-risk clinical settings like sepsis care [74,99]. Regulatory frameworks also play a decisive role. In the European Union, the Medical Device Regulation (MDR) requires CE certification for AI systems classified as Software as a Medical Device (SaMD), ensuring compliance with strict safety, performance, and risk management standards. In the United States, the Food and Drug Administration (FDA) regulates AI-based medical devices through pathways such as De Novo and 510(k), which assess safety, efficacy, and equivalence to existing technologies. Although these requirements add complexity and cost, they are crucial to ensuring patient safety and public trust. A multi-faceted approach addressing ethical, legal, and regulatory dimensions is essential for the safe integration of AI into healthcare systems.

AI is already transforming sepsis management, offering advancements in detection, diagnosis, and treatment. As AI tools and multimodal data integration evolve, they will enable more personalized, real-time interventions to address the complexities of sepsis care.

Most sepsis prediction algorithms rely on routine clinical data such as patient demographics, vital signs, and laboratory values [100]. For instance, a recent meta-analysis has identified several critical factors that contribute positively to sepsis prediction scores [101]. These factors include heart rate, respiratory rate, temperature, and various laboratory and blood gas values, all closely in line with clinical expectations. Moreover, neural network-based predictors have emerged as the predominant model category for sepsis prediction [102]. However, direct model comparisons across different publications remain difficult due to the heterogeneity of clinical endpoints and clinical settings. This urges for the creation of benchmark datasets as indicators for measurable performance improvements in the field, along the lines of standardized benchmarks for performance evaluation [103].

To improve the predictive accuracy, the inclusion of additional input variables is essential, as recent studies have shown. These include unstructured text such as progress notes, nursing notes, chief complaints, diagnostic reports, or discharge summaries, which may play a potential role in sepsis prediction [104]. Most approaches rely on traditional features from natural language processing such as n-grams, Latent Dirichlet Allocation topic modeling, or, more recently, word vectors or pre-trained text encoders of the BERT (Bidirectional Encoder Representations from Transformers) era. In particular, recent works indicate that the contextual information from unstructured clinical notes benefits in particular longer-term sepsis prediction tasks [30]. It is worth stressing that the models mentioned above date back to the pre-Large-Language-Model (LLM) era. LLMs, such as GPT-4 and Med-PaLM, have emerged as powerful tools in healthcare, capable of processing and synthesizing complex clinical data. In the context of sepsis care, LLMs have the potential to enhance clinical decision support by rapidly analyzing unstructured data from electronic health records (EHRs), such as clinical notes, laboratory reports, and imaging findings, to assist in early detection and risk stratification [105]. By providing real-time summaries of patient status and highlighting critical findings, LLMs can support clinicians in timely decision-making, potentially improving early recognition and management of sepsis. Additionally, integration of LLMs into clinical workflows may streamline documentation and reduce cognitive load, allowing healthcare professionals to focus more on patient care [106]. These bright prospects should be contrasted with severe shortcomings of a direct application of LLMs as highlighted in a recent study in a critical care context [107] namely in part significantly worse performance levels compared to physicians, failure to following guidelines or to interpret certain kinds of clinical information such as lab values.

The integration of omics diagnostics represents another approach, which could enhance sepsis prediction when combined with ML methods [108]. Omics technologies, such as genomics, proteomics, metabolomics, and transcriptomics, can revolutionize sepsis management by offering, more profound insights into the molecular basis of the disease and potentially revealing novel therapeutic targets. Through the analysis of patients’ omics data, clinicians can identify specific biomarkers associated with different sepsis phenotypes, guiding more targeted interventions. Figure1highlights the role of AI models in advancing biomarker validation and supporting personalized sepsis care through the integration of omics data. For example, genomics can reveal genetic predispositions to sepsis, while proteomics and metabolomics can identify biomarkers indicative of specific organ dysfunctions [109]. These advancements enable a more stratified treatment approach, with therapeutic decisions informed by each patient’s unique molecular profile [110,111]. So far, the majority of omics diagnostics represent non-routine measurements and have rarely undergone prospective validation. With the emergence of omics markers, one can expect an expansion of this field, potentially leading to further breakthroughs in sepsis diagnosis and treatment.

As AI models continue to evolve, the integration of omics data and enhanced real-time reclassification capabilities offer the potential to deliver precision medicine strategies tailored to the dynamic and heterogeneous nature of sepsis. Real-time data integration will be vital in enhancing the precision of care. As patients’ conditions change, these models can dynamically update phenotypic classifications, ensuring that treatments remain responsive and aligned with the current clinical picture [112]. Such adaptability will allow clinicians to make more effective, timely decisions. The ability to detect complex patterns in large datasets makes advanced systems particularly valuable for personalized treatment. Incorporating molecular data will enable even more precise classifications, further advancing personalized medicine [20]. Moreover, dynamic reclassification of patients based on continuously updated data ensures that treatment strategies remain relevant as patients’ conditions evolve [113]. This minimizes the risks of overtreatment or undertreatment.

While AI models show promise in integrating multi-modal data, including omics, into sepsis management, the real-time clinical application of omics data remains limited. Current omics assays, such as genomics, proteomics, and metabolomics, typically require complex laboratory workflows and extended processing times, making them impractical for point-of-care use in acute settings. There is a lack of validated point-of-care testing (POCT) platforms capable of delivering real-time omics-based diagnostics in sepsis. However, advances in rapid diagnostic technologies, such as biosensors and POCT devices, have demonstrated potential for near real-time detection of sepsis-relevant biomarkers. For example, novel nanotechnology-based biosensors have achieved rapid detection of pathogens in serum samples within seconds [114], and POCT systems for biomarkers like C-reactive protein, procalcitonin, and interleukin-6 are increasingly used in neonatal sepsis management [115]. Additionally, the integration of POCT for basic biomarkers, such as lactate and full blood count parameters, has been successfully implemented in remote clinical settings to improve timely sepsis detection and triage [116]. While full multi-omics integration into real-time clinical workflows remains an area for future development, these advancements in rapid biomarker testing are important steps toward more responsive sepsis diagnostics.

Another category of promising input modalities comprises waveform data, which encompasses ECG, photoplethysmogram (PPG), and arterial blood pressure captured at high sampling frequencies. Waveform analysis approaches can be broadly categorized into feature-based and raw-time-series-based approaches. As of feature-based approaches, a limited set of expert features extracted from the waveform data, such as HRV in the case of ECG, are known to be very predictive and widely considered in predictive models. Recent work further demonstrates that brief segments of waveform data, often just five minutes, can yield interpretable features such as heart rate variability (HRV), pulse arrival time (PAT), and mean arterial pressure variability (MAPV), which are predictive of septic shock onset well before clinical recognition [117]. HRV features commonly include time-domain indices (e.g., SDNN, RMSSD), frequency-domain metrics (e.g., LF/HF ratio), and nonlinear measures (e.g., entropy, Poincaré plots), all of which reflect autonomic regulation and perfusion dynamics [118]. To extract such features and prepare data for AI models, preprocessing methods such as noise filtering, artifact removal, and peak detection are required. More advanced methods, such as tensor decomposition (e.g., Canonical Polyadic Decomposition), have been successfully applied to retain spatiotemporal structure in multivariate waveform streams, improving predictive performance while reducing data dimensionality [119].

In contrast to handcrafted features, raw waveforms capture a wide range of conditions that do not necessarily pertain to a single organ system. In AI-enhanced ECG studies, for example, deep learning models have demonstrated the ability to infer numerous cardiac and non-cardiac conditions, such as diabetes and cirrhosis, from a single ECG, even within a single unified model [120]. Notably, initial exploratory studies on sepsis prediction suggest that using the complete waveform data offers a more comprehensive source of information [121], in line with a recent study highlighting the added value of raw waveforms for general diagnostic tasks and patient deterioration tasks in the ED [122] widely across all considered tasks. A wide variety of deep learning architectures including convolutional neural networks (CNNs) and hybrid CNN–LSTM models have been successfully applied to capture spatiotemporal patterns in waveform dynamics. More recent works explore the use transformer models [123] or structured state-space models [122] to extract waveform representations that are informative for prediction tasks in a critical care context. Therefore, it seems very likely that including raw waveform data will also enhance predictive accuracy for sepsis and enable more nuanced patient stratification.

Multimodality, which refers to the integration of diverse data types such as clinical, imaging, genomic, and sensor data, is an emerging paradigm in clinical prediction models [86]. A central challenge remains the necessity to circumvent the need for large training datasets covering several or in the worst case all modalities across for all samples, which would be indispensable for training a monolithic multimodal prediction model from scratch. Two solution components have recently emerged to address this challenge, the use of modular approaches with modality-specific encoder models combined with modality-specific pretraining. The resulting output representations of the different encoder models can then be combined using relatively shallow prediction models, as demonstrated in ICU/ED contexts [124,125]. Pretraining encoder models on EHR data enable to build for example multimodal models that combine EHR data with OMICS data [126] while requiring only a few hundred samples with paired data from both modalities. In the context of sepsis, integrating multimodal data streams, including clinical observations, laboratory values, molecular biomarkers, and patient-generated health data, may enable real-time patient stratification and dynamic phenotyping. By integrating data sources such as genomics, proteomics, and wearable devices, advanced systems can continuously assess a patient’s condition, providing personalized treatment strategies that evolve with the patient’s health status [20]. Leveraging AI-supported systems biology to analyze dynamic interactions among genes, proteins, and metabolites has the potential to facilitate continuous assessment and guide personalized interventions in sepsis care in real-time [127].

At present, the capabilities of sepsis prediction models remain quite limited. Nonetheless, there are undoubtedly promising prospects on the horizon for a generalist medical artificial intelligence [128]. Such a model, drawing upon medical expertise, can be constructed upon a foundational model meticulously pre-trained on extensive and diverse datasets equipped with both multimodal input and output capabilities. It could possess the capacity to address specific inquiries pertaining to individual patients. Not only would it retrieve similar cases, but it would also furnish therapeutic recommendations grounded in current guidelines and research literature. For instance, such systems could consolidate tasks currently handled by separate algorithms, such as optimizing antibiotic selection, de-escalation, and resistance prediction, central pillars of effective antibiotic stewardship in sepsis [129]. Early prototypes for such integrated systems, including reinforcement learning models and real-time decision support tools, have already demonstrated feasibility in clinical or simulated settings. To realize this vision, AI might need to acquire counterfactual reasoning skills, enabling it to evaluate the potential efficacy of particular therapeutic interventions. Moreover, generalist AI could leverage continuous waveform and hemodynamic data to improve fluid management decisions by predicting fluid responsiveness in real time, a challenge that remains poorly addressed in current sepsis care [130].

Artificial intelligence holds substantial promise for transforming sepsis management across three critical domains: early detection, patient phenotyping, and clinical decision support. While each of these applications addresses a distinct aspect of the clinical workflow, timeliness of intervention, understanding of biological heterogeneity, and optimization of therapeutic decisions, they are interdependent and must evolve in concert. Integrating insights across these domains is essential to fully leverage AI’s potential for improving sepsis outcomes (Fig.2). To accelerate the safe and effective translation of AI into real-world practice, several priorities emerge. First, models must be rigorously validated in prospective clinical studies designed to reflect real-world complexity and meet regulatory expectations. Second, successful integration will require human-centered design strategies that involve clinicians and patients from the outset, ensuring usability, interpretability, and alignment with clinical workflows. Finally, adoption depends on economic feasibility and institutional readiness, issues that demand supportive reimbursement models and evidence of cost-effectiveness. Ultimately, the promise of AI in sepsis lies not in replacing clinical expertise, but in augmenting it with timely, data-driven insights. As the field matures, it will be critical to move beyond technical benchmarks and toward patient-centered outcomes, drawing on interdisciplinary collaboration and iterative learning. A deliberate focus on validation, usability, and equity will determine whether AI becomes a routine component of high-quality sepsis care.

ChatGPT (OpenAI) and LanguageTool were used solely for language editing and spellchecking. No content was generated by AI, and the authors reviewed and take full responsibility for the final manuscript.

AI holds great promise in improving sepsis care by enabling earlier detection and personalized treatments. To fully harness its potential, addressing challenges like data quality and model interpretability will be crucial for its effective clinical application.