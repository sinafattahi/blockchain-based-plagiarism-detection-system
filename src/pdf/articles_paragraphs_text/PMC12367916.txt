The detection ofGW170817, together with its electromagnetic counterparts, has proven that binary neutron star mergers are of central importance to the field of nuclear astrophysics, e.g., through a better understanding of the formation of elements and novel constraints on the supranuclear dense equation of state governing the matter inside neutron stars. Essential for understanding the binary coalescence are numerical-relativity simulations, which typically come with high computational costs requiring high-performance computing facilities. In this work, we build on recent studies to investigate whether novel techniques, such as neural networks, can be employed in the conversion of conservative variables to primitive hydrodynamical variables, such as pressure and density. In this regard, we perform – to the best of our knowledge – the first binary neutron star merger simulations in which such methods are employed. We show that this method results in stable simulations, reaching accuracies similar to traditional methods with an overall comparable computational cost. These simulations serve as a proof of principle that, in the future, deep learning techniques could be used within numerical-relativity simulations. However, further improvements are necessary to offer a computational advantage compared to traditional methods.

The multi-messenger detection ofGW170817[1], GRB170817A [2], and AT2017gfo [3] has been a breakthrough in the field of multi-messenger astronomy by incorporating gravitational waves as an observational window. This groundbreaking event, associated with the merger of two neutron stars, has already provided significant insights into the evolution of the Universe [4–8], the properties of matter at supranuclear densities [1,8–21], and the processes responsible for the formation of heavy elements [22–28].

To extract information from such high-energetic astrophysical observations, one has to compare the measured data with predictions of the binary evolution. Regarding gravitational-wave (GW) astronomy, this can be done by correlating the measured strain signal with existing GW models, maximizing their agreement [29]. For an interpretation of possible electromagnetic (EM) counterparts, one needs to relate the properties of the observed signals with the predicted light curves and spectra caused by the material outflow from two neutron stars during the coalescence [30,31]. Because of the complexity of the merger process, an accurate description of the system’s dynamics requires us to solve Einstein’s field equations together with the equations of general relativistic hydrodynamics. For this reason, we have to perform numerical-relativity (NR) simulations to understand the binary neutron star (BNS) merger dynamics. In general, such simulations also allow us to extract the emitted GW signal and to validate/calibrate existing GW approximants, e.g., [32–36]. In addition, they also allow us to understand the properties of the outflowing material [30,37,38]. Regarding the latter, one requires a proper description of microphysical processes. This implies that one has to use a nuclear-physics motivated equation of state (EOS) for the description of the supranuclear dense material, incorporate a description of neutrino radiation and of magnetic fields; cf. e.g.,  [39–53] for such efforts.

Unfortunately, even by employing approximations for the microphysical description, NR simulations come with high computational costs, and single simulations require between tens of thousands to several millions of CPU hours, depending on the incorporated physical descriptions and the employed resolution. Hence, we can typically only investigate the last few orbits and the first tens to hundreds of milliseconds after the merger; cf. [54,55] for recent state-of-the-art simulations covering up to one second.

This large computational footprint motivates the continuous effort within the NR community to increase the efficiency of NR simulations. While there has been progress, e.g., through the application of new discretization schemes, e.g., [56–59], or the usage of GPUs, e.g., [60,61], some works also investigated possibilities to speed up individual routines such as the conservative-to-primitive recovery [44,62,63]. The conversion from the evolved conservative variables to the primitive variables is a critical ingredient within the often employed Valencia formulation of general-relativistic hydrodynamics [64,65]. In this article, we want to build on the previous works of Refs. [63,66,67] and present, to our knowledge, the first general-relativistic simulations in which deep-learning techniques are employed to speed up the conservative-to-primitive recovery during BNS simulations.

The article is structured as follows. In Sect.2we will review the basic methods and also discuss the constructed neural networks (NNs). In Sect.3we perform validation tests of our new method and in Sect.4we present results of BNS simulations. Throughout this article, we will use geometric unitsG=c=M⊙=1for all our calculations, which means that one code unit for lengths refers to≃1.48km, for times refer to≃5μs, and for masses refer to1M⊙.

corresponding to the rest-mass densityD, the momentum densitySj, and internal energyτas seen by Eulerian observers. Here,γis the determinant of the induced three-metricγij,Wis the Lorentz factor, andh=1+ϵ+p/ρis the fluid’s specific enthalpy. Note that the total mass-energy density as measured by an observer comoving with the fluid isρ∗=ρ(1+ϵ).

Here, we introducedv~i=vi-βi/α, withαthe lapse function andβithe shift vector [68],Tμνthe stress-energy tensor, and the Christoffel symbolsΓμνλ.

To finally close the system of equations, considering the existence of five conservative variables for which evolution equations exist and the presence of six primitive variables, one requires an EOS that relates, for example, the pressure to other hydrodynamical variables. In this article, we are employing two different EOSs: (i) an ideal gas EOS in which the pressure is given byp=(Γ-1)ρϵand (ii) a tabulated EOS representing a microphysical EOS for which the pressure depends on the temperatureT, the baryon number densitynB, and the electron fractionYe. For simplicity, we restrict our studies to the relativistic mean-field EOS SFHo [69], but certainly similar results can be obtained for other EOSs.

Although the conservative variables are used as evolved variables, knowledge about the primitive variables is necessary to compute the fluxes, Eq. (7). Unfortunately, in contrast to transforming the primitive variables to the conservative variables through a simple analytical transformation, there is no closed analytical description to compute the primitive variables from the conservative ones. While there are numerous different possibilities for recovering the primitive variables, we will follow the discussion of Ref. [70] for ideal gas EOS and of Refs. [44,62] for the employed tabulated EOS.

whereχ=∂p∂ρ=(Γ-1)ϵ,κ=∂p∂ϵ=(Γ-1)ρin case of an ideal gas EOS, andS=SiSi.

holds. With the new variables introduced, the EOS is described bya(ρ,ϵ,p). In the following, we will describe only the necessary steps to recover the primitives here and refer readers to [44] for details, e.g., the constraints that the EOS should satisfy, the bounds for the conserved variables, and the existence of a (unique) solution within the bounds.

Equation (33) can then be solved using bracketing root-finding methods. In our numerical-relativity code BAM [53,70,71], the Illinois method [72] is used, which is a hybrid root-solver combining bisection, secant, and inverse quadratic interpolation methods.

In this work, we employ a supervised machine learning technique [73,74] to predict the primitive variables from conservative ones. In particular, we use feedforward NNs [75], which form a computational circuit consisting of several layers of single units, referred to as neurons, that together define a function. We restrict ourselves to fully connected NNs, where all neurons of adjacent layers are connected with tunable weights. Feedforward NNs often have several so-called hidden layers between the input and output layer. As such, this class of machine learning methods is also known as deep learning [76–78]. Once the NN receives an input, the value of a neuron in a subsequent layer is computed as a weighted sum of the previous layers’ neurons, which is then passed to a non-linear activation function. The activation function outputs only when the weighted sum is greater than a certain threshold defined by the choice of activation function. The network can be trained (i.e., adapting the connection weights) by providing example input–output pairs of the ground truth and minimizing a loss function that quantifies the difference between the NN prediction and the true output value. The minimization procedure relies on backpropagation [79], where gradients of the loss function are accumulated and used to adapt the weights with a certain step size, also referred to as the learning rate.

Since NNs are universal function approximators [80], our goal is to train NNs to approximate a map from the conservative variables to the primitive ones. The input of our NNs then consists of the conservatives(D,|S|,τ), while the output will be either the pressurepor velocity-based quantityz. From this output, we can recover the other primitive variables following Eqs. (10)–(14).

The precise details of our architectures and the mechanism to construct training data vary for the two EOSs considered in this work. In the following, we describe the NN architectures and training procedures for each EOS in more detail.

To construct the training data for the ideal gas EOS, we draw values forρandϵfrom a log-uniform distribution withρ∈(10-14,10-2),ϵ∈(10-12,102). The velocity |v| is sampled uniformly between 0.001 and 0.8. From these samples, the pressure is computed using Eq. (9), after which the corresponding conservative variables(D,|S|,τ)are computed with Eqs. (3)–(5). This gives us the conserved variables within the range(1.0×10-14,0.02)forD,(1.3×10-17,2.6)for |S|, and(2.83×10-20,2.79)forτ. Because of such large input data ranges, we have further preprocessed the data. We convert the data intologscale to minimize the ranges. To further reduce the range, we scale the data into a [0, 1] range using theMinMaxScalerfrom scikit-learn [86]. When implemented in BAM, we have to do the above scaling of conservative variables before they are given as input to the NN, and when the prediction is received from the NN, we have to invert back to the normal scale that we have started with.

The NN architecture has one input layer with 3 neurons for the values(D,|S|,τ), followed by 3 hidden layers with 20, 20, and 15 neurons, respectively. The output layer has one neuron, with the pressurepbeing the output variable. The learning rate is set to 0.7, and the validation error of3×10-5is achieved at the end of the training.

In the following, we will see that the constructed NN will be sufficiently accurate for special-relativistic shocktube tests (Sect.3.1) but will not be sufficient for general-relativistic simulations. In such cases, as we will discuss later, the network will provide initial guesses for the root solver; cf. Sect.3.2.

For the tabulated SFHo EOS, the training dataset has been constructed as follows. First, we construct a 4-dimensional parameter space(ρ,T,Ye,|v|), whereρ,T, andYeare taken from the EOS table by sampling them log-uniformly within the provided EOS ranges.2Then computing the conserved variables with the distributed primitives, we end up with the ranges(2.68×10-15,0.14)forD,(4.81×10-19,19.12)for |S|, and(3.19×10-17,18.98)forτ. The velocity |v| is sampled independently from a uniform distribution between 0 and 0.99. For each set of primitive variables, we computez=W|v|and the conservative variables(D,|S|,τ)(Eqs. (3)–(5)). Regarding the preprocessing of the data, we follow the same steps as for the ideal gas EOS.

The NN architecture consists of an input layer with 3 neurons for the conservative variables(D,|S|,τ)and 4 hidden layers, each consisting of 3 neurons. The output layer consists of a single neuron representing the variablez. The input does not considerYe, since the variablezdoes not significantly depend onYefor the SFHo EOS considered here. While this design choice potentially reduces the accuracy of the network, we found that it results in smaller networks that are cheaper to evaluate and still achieve high enough accuracy for our simulations if combined within a hybrid approach with more traditional methods (see below). The learning rate is set to 0.001, and we obtain a validation error of6.0×10-3after the training.

Compared to the ideal gas EOS, approximating the conservative-to-primitive routine for a realistic, tabulated EOS is challenging. For the case of a TOV star, we found that the prediction of NN is able to recover primitives with sufficient accuracy, hence we replace the root-solver with NN. But, for the BNS mergers, because of more complex dynamics compared to TOV star, NN predictions are not sufficient. As a result, we have found that the NN cannot be used directly as a replacement for the conservative-to-primitive routine in all cases. Reducing the error of the NN predictions would require a more complex NN architecture, which would then dominate the execution time. Therefore, we propose for the BNS case a hybrid conservative-to-primitive recovery scheme for tabulated EOS. In particular, we use the NN output as an initial guess for the Illinois root-finding method [87,88] implemented in BAM. Since the root-finding algorithm ensures that we achieve the numerical accuracy required by simulations, we opt for a simple NN architecture that is efficient to evaluate. The initial guess coming from the NN is then instead used to constrain the bounds employed in the Illinois scheme, cf. Eq. (34). After computing the NN predictionzNNfor the root, our algorithm verifies ifzNN∈[z-,z+]. If this is not the case, the algorithm defaults to the Illinois method. If, however,zNNlies within the bounds, it further checks the sign of the function valuef(zNN). Depending on the sign, the bounds are adjusted. After that, the Illinois algorithm is executed with the adjusted bounds.

For our hydrodynamical simulations, we are using the BAM code [53,70,71,89–93]. BAM uses an adaptive mesh refinement method based on multiple levels, labeled froml=0(coarsest) tol=L-1(finest). Each level can consist of a number of refinement boxes, where for levelsl>lmv, the refinement boxes can move dynamically during the simulation to follow the motion of the compact objects. The grid spacing at each level follows a 2:1 refinement strategy, meaning the spacing at levellis half of the spacing at levell-1. All grid points are cell-centered and staggered to avoid singularities at the origin.

The time evolution is handled using a Berger–Oliger [94] scheme for local-time stepping and the Berger–Colella [95] scheme to ensure flux conservation across refinement boundaries. For the time integration, we use a fourth-order explicit Runge–Kutta scheme. For solving spacetime evolution, we use here the Z4c formulation [96,97], discretized with a fourth-order finite difference scheme. The lapse function is evolved with1+logslicing [98], and the shift vector follows the gamma-driver conditions [99].

For the hydrodynamic equations, cf. Sect.2.1, we reconstruct the primitive variables employed for the flux computation using the WENOZ [92,100] method together with the HLL Riemann solver [101]. Similar to our previous works, e.g., [70,102,103] we use an artificial atmosphere for low-density material. For the ideal gas runs, we use an atmosphere density ofρatm=1×10-13, corresponding to a fraction1×10-9of the maximum density in the grid at the initial timestep. A point whose density isρ≤fatmρatmis set to atmosphere, wherefatm=100. For our tabulated EOS simulations, we employρatm=2.7×10-14, i.e., one order of magnitude larger than the minimum tabulated density. In this case, we choosefatm=1, meaning that points withρ≤ρatmare set to atmosphere.

For this test, the traditional conservative-to-primitive transformation is fully replaced by the predictions from the NN. Figure1demonstrates that the NN can replace root solvers in terms of accuracy and speed. The maximum absolute error between the root solver and the NN for our prediction ofpis6.395×10-14, and the average error is1.111×10-15, which is sufficient to use the NN prediction directly for dynamical simulations.

The time3taken for the simulation (averaged over 10 simulations) is13.490s, whereas, when using a root solver, the simulation was completed in12.714s. Given the difference of∼0.7sfor both methods, it seems natural to potentially reduce the size of the network, reducing the accuracy until a still acceptable level, for instance, by pruning our NNs [107,108].

As the next test case, we will consider a spherically symmetric star described with an ideal gas EOS withΓ=5/3. We obtain the initial configurations by solving the Tolmann–Oppenheimer Volkoff equations [109,110] using a polytropic constant ofκ=100. Because of the chosen EOS, the star with a central density of10-4has a very large radius of 44.5, a baryonic mass of 8.491 and a gravitational mass of 8.160. Hence, it should not be considered as a realistic test, but rather to check the consistency of the implemented method. The simulation employs five refinement levels with a grid spacing of 0.5 in the finest level. To save computational costs, we employ octant symmetry, i.e., just one octant of the full grid for which we would have 256 grid points per direction. Effectively, this means that we cover the positive x-, y-, and z-axis with 128 points in our simulations.4All levels employ the same number of points, but different grid spacing according to the refinement strategy.

As for the shocktube test, we employ the Newton–Raphson as our default root-solver option, with initial guess from the previous time step and compare it with the performance of the NN conservative-to-primitive routine. However, for this particular case, we find that the NN prediction is not always accurate enough, and therefore, we decided to use the NN prediction as our initial guess for the Newton–Raphson root solver.

we find that our NN method is slower than the traditional Newton–Raphson root solver. Clearly, this is not surprising, as our NN prediction here only serves as an initial guess for the root solver. However, this leads to two immediate conclusions: (i) although NN predictions can be accurate enough in specialized special-relativistic shocktubes, as shown in previous works in the literature [63], they might fail for more complicated scenarios; (ii) since potentially one always has to use a hybrid approach in which a root solver simply takes the NN prediction as an initial guess, it might be better to use a simple NN architecture to reduce computational costs. Both aspects have motivated our design choices for the following studies using a tabulated EOS.

As our next test, we consider a single TOV star but with the tabulated EOS SFHo. We employ a grid setup consisting of three refinement levels with a grid spacing of 0.233 in the finest level. We employ 96 points per direction for the full grid, but only simulate the positive x-, y-, and z-axis (each covered with 48 points) by employing octant symmetry to reduce computational costs. For this test, the NN can give accurate predictions for most cases, but it fails if the conservative variables encounter unphysical values during the evolution step, i.e., outside of the trained data. In such a scenario, we fall back to the original root solver, which has additional checks to ensure the physical consistency of the conservative variables, e.g., imposingD>ρatm,τ>0, and|S|<τ+D. Although, in principle, one could have added similar checks to the NN-implementation, we have not done this in the current version of the code. Overall, this hybrid method increases the speed of this simulation while ensuring its stability.

Figure3compares the results of the simulation employing our algorithm with those using the traditional root solver. The stability of the new method is confirmed by the agreement between the Hamiltonian norm||H||2and the central densityρmax, in the first and second panel of Fig.3. In the third panel, we show the total baryonic massMB, which differs from the Illinois method only at the order of10-14. The bottom panel shows a direct comparison of the speed of simulation for the different methods. One can see that by employing the NN, the speed of the simulation increases by up to 30%.5Therefore, employing our proposed method holds promise to accelerate more complex simulations, as we explore in the next section.

As our final test to check the validity of the proposed method, we want to investigate how the modified conservative-to-primitive routine performs during BNS simulations. For this purpose, we simulate an equal mass binary in which the stars have a gravitational mass ofM1=M2=1.28, a baryonic mass ofMb,1=Mb,2=1.4, with initial coordinate separationd0=26≈38.8km. As in the previous test, we employ the SFHo EOS.

A total of 4 BNS simulations were performed with identical grid configurations, as specified in the following. Two simulations employ the traditional root solver (RS) with the Illinois method, while two simulations use the hybrid approach (NN). Each run is performed with accuracy threshold set to either1×10-9or1×10-11, identified by subscript 9 or 11, respectively in the plots.

The simulations use a grid consisting of five refinement levels with 192 points per direction on the coarser levels. The two finest levels are split into two boxes with 96 points per direction. The boxes can follow the movement of the stars to ensure high resolution around the regions with the strongest spacetime curvature. The code uses a 2:1 refinement strategy, in which each coarser level has a doubled grid spacing. The resolution in the finest level is about 0.168. In addition, we employ reflection symmetry across the orbital plane to reduce computational costs, i.e., we employ 96 (coarse levels) and 48 points (moving levels) along the z-direction.

For the simulation of the BNS systems, we employ the hybrid algorithm described in Sect.2.3.2. In contrast to the single TOV test with the tabulated EOS (Sect.3.3), we have to use the NN prediction as an initial guess for the Illinois algorithm and can not use it to provide the final guess of the conservative-to-primitive recovery due to its insufficient accuracy.

In Fig.4, we show the result of our dynamical simulation, where the top row shows the density profile at three different times computed with the standard root solver (ρRS) used for the conservative-to-primitive recovery. In addition, we overlay the same density contours when using the NN-informed conservative-to-primitive routines, and we find a very good agreement. The middle and bottom panels show the absolute difference in density when instead employing our deep-learning based algorithm. Our comparison considers two different accuracy thresholds for the conservative-to-primitive recovery, namely10-9(middle panel) and10-11(bottom panel), to assess the influence of the threshold on the overall runtime. To better compare simulations with accuracy threshold10-9(10-11), we define the average deviation of a simulation at a given instant as the mean valueμ9=⟨|Δρ9|/ρRS⟩(μ11=⟨|Δρ11|/ρRS⟩) on thex-yplane, taken from the distributions in the middle (bottom) rows of Fig.4. While the results visually agree for both thresholds at different instants, for the post-merger configuration presented in the right panels we findμ11to be around10%smaller thanμ9. This simulation can be considered as a proof of principle that our proposed deep-learning method can be used during dynamical simulations of neutron star spacetimes.

In Fig.5, we compare the speed of our BNS simulations. These simulations are performed on the HAWK System of the Höchstleistungsrechenzentrum Stuttgart using AMD EPYC 7742 CPUS. We have run the simulations on one compute node employing 8 MPI tasks with each 16 OpenMP threads per MPI-task.

For the error threshold of10-9, we find that the Illinois method has an average speed of 52/h. In contrast, the average reduces to 49.3/hwhen NN predictions were used as input for the initial guess. For the accuracy error threshold of10-11, we obtain an average speed of 48.0/hfor the Illinois method and 50.4/hwith the NN input. However, it is clearly visible from Fig.5that in real applications, the variation in the speed, e.g., due to I/O, communication, and the overall load on the system, strongly influences the speed. Hence, the speedup or slowdown that the new conservative-to-primitive method achieves is subdominant, and one can conclude that similar performance is obtained within realistic scenarios. Our tests6also confirm this by employing different HPC systems and grid resolutions.

General-relativistic hydrodynamics simulations of compact binary mergers are generally connected to high computational costs. For this reason, several attempts have been made to reduce the computational footprint of such simulations. In this regard, Dieselhorst et al. [63] and, later, Kacmaz et al. [66] investigated the possibility of using NNs to speed up the required conservative-to-primitive recovery during hydrodynamical simulations. However, none of these works employed NNs in an actual simulation of a BNS merger, which was the main aim of the present work.

While we have found that the usage of NNs achieves a sufficiently high accuracy to be directly employed in simple tests, during the simulation of neutron star spacetimes, the recovery is not accurate enough to avoid the use of a root-finding algorithm. We expect that more complex networks could overcome this issue, at the cost of a more expensive NN to evaluate. Therefore, we have employed a hybrid approach in which we use NNs to improve the initial guesses handed to a root-solver routine. Since the exact speed depends on the resolution, the requested accuracy threshold for the conservative-to-primitive routine, as well as the computational setting, i.e., the number of nodes and the employed MPI/OpenMP settings, our results should only be considered as estimates.

It is worth highlighting some of the existing limitations of our work. First, our study was restricted to the usage of two different EOSs, one rather simple ideal gas EOS withΓ=5/3and one tabulated EOSs based on the SFHo [69] EOS. Although there is no reason to expect that other EOSs could not be used, it might be that the presence of strong phase transitions or other particular features would make the training harder. In general, for each different EOS, we would require a newly trained NN. While the training of the NN adds only a small amount of extra computational costs (see Sect.2.3), it certainly adds another layer of complexity, in particular, for the studies that involve a large number of EOSs.

Second, we expect that further fine-tuning of the trained NN might further reduce the computational footprint. On this behalf, we think that, with the upcoming GPU-based generation of numerical-relativity codes, NNs will become more competitive with respect to traditional root finders, due to their simpler flow chart.

Third, another possible speedup could be obtained by connecting the NN prediction with a Newton–Raphson method because of its higher convergence order compared to the Illinois method. However, this approach would require us to know accurate derivatives of the pressure. In principle, as shown by Dieselhorst et al. [63], one could also train an NN to predict these derivatives. However, this also increases the complexity of the overall method and would require detailed tests.

The authors thank Michele Mattei, Sebastian Khan, Pouyan Salehi, Ka Wa Tsang, Tjonnie G.F. Li, Arthur Offermans, and Patrick Chi-Kit Cheong for discussions at a very early stage of the project. This work was partially funded by the European Union (ERC, SMArt, 101076369). Views and opinions expressed are those of the authors only and do not necessarily reflect those of the European Union or the European Research Council. Neither the European Union nor the granting authority can be held responsible for them. T.W. acknowledges funding through NWO under grant number OCENW.XL21.XL21.038. F.S. acknowledges funding through the grant PID2022-138963NB-I00 funded by MCIN/AEI/10.13039/501100011033/FEDER, UE. A.N. acknowledges funding from the Deutsche Forschungsgemeinschaft (DFG) through Project No. 504148597. The simulations were performed on the national supercomputer HPE Apollo Hawk at the High Performance Computing (HPC) Center Stuttgart (HLRS) under the grant number GWanalysis/44189, and at the DFG-funded research cluster (INST 336/173-1; project number: 502227537) jarvis.

Open Access funding enabled and organized by Projekt DEAL.