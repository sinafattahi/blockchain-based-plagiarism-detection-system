Response curves are widely used in biomedical literature to summarize time-dependent outcomes, yet raw data are not always available in published reports. Meta-analysts must frequently extract means and standard errors from figures and estimate outcome measures like the area under the curve (AUC) without access to participant-level data. No standardized method exists for calculating AUC or propagating error under these constraints.

We evaluate two methods for estimating AUC from figure-derived data: (1) a trapezoidal integration approach with extrema variance propagation, and (2) a Monte Carlo method that samples plausible response curves and integrates over their posterior distribution. We generated 3,920 synthetic datasets from seven functional response types commonly found in glycemic response and pharmacokinetic research, varying the number of timepoints (4–10) and participants (5–40). All response curves were normalized to a true AUC of 1.0.

The standard method consistently underestimated the true AUC, especially in curves with skewed or long-tailed structures. Monte Carlo method produced near-unbiased estimates with tighter alignment to the known AUC across all settings. Increasing the number of datapoints and participants improved performance for both methods, but the Monte Carlo approach retained robustness even under sparse conditions.

This is the first large-scale benchmarking of AUC estimation accuracy from graphically extracted data. The Monte Carlo method outperforms standard approaches in both accuracy and uncertainty quantification. We recommend its adoption in meta-analytic contexts where only figure-derived data are available and advocate for improved data sharing practices in primary publications.

Graphically summarized response curves are a common feature in experimental biomedical literature, particularly in glycemic response studies [1–3], pharmacokinetics/pharmacodynamics [4–6], toxicology [7], analytical chemistry [8], and comparative clinical studies [9]. These curves often present the temporal evolution of a biological signal across a small sample population, with group-level means and error bars reported at discrete time points. In the absence of raw participant-level data, researchers—especially those conducting meta-analyses—frequently rely on these figures and reported effect measures as the only available representation of a study’s time-dependent outcomes [10–14].

In many of these applications, area under the curve (AUC) or incremental AUC (iAUC) is the key outcome metric used to compare experimental groups [9,15–25]. While primary study authors have access to participant-level time series and can compute individual AUCs followed by statistical comparison, secondary users of figure-based data are limited to estimating the AUC from extracted summary values. This creates a methodological challenge: how to best approximate AUC and its uncertainty from digitized plots that typically report only group means and either standard deviations (SD) or standard errors of the mean (SEM), across an arbitrary and often sparse number of timepoints.

While tools such as PlotDigitizer have been widely adopted for extracting values from images, there is no accepted statistical protocol for computing AUC or propagating its uncertainty under these conditions [26,27]. The Cochrane Handbook and related training materials acknowledge this gap, noting that no standard method is available for deriving AUC from extracted graphical data [28]. Despite this, numerous meta-analyses cite the use of “standard formulas” to estimate AUC from digitized points, often without elaboration or error propagation detail [29]. This lack of transparency could have significant implications for the reproducibility and validity of quantitative syntheses.

In this work, we conduct a systematic investigation of this problem. First, we evaluate a commonly used “standard method” that applies the trapezoidal rule to the extracted means, using simple bound-based estimates for error approximation. Second, we propose and test a novel Monte Carlo approach that simulates a posterior distribution over possible AUCs given the extracted means and error bars. This method uses curve-wise sampling of synthetic individual-level responses, fitting interpolated splines to the sampled points, and integrating over the resulting distributions.

To evaluate both approaches, we create a synthetic library of response curves derived from seven well-established functional forms used in biomedical modeling. We vary the number of datapoints and number of participants across thousands of combinations, each normalized to a true AUC of 1.0. This setup allows us to measure bias and variance for both methods under controlled conditions, providing the first large-scale quantitative assessment of AUC estimation reliability from figure-derived data.

This study systematically evaluates the accuracy of two approaches for estimating the area under the curve from digitized figure data: (1) a standard trapezoidal rule method with basic error propagation and (2) a Monte Carlo method using spline-based interpolation. The evaluation is conducted on a large synthetic dataset spanning diverse response curve shapes, varying participant sample sizes, and varying numbers of timepoints per curve.

To simulate figure-derived data, we first constructed a model zoo of seven biologically plausible response functions commonly used in glycemic response modeling and pharmacokinetics: (1) skewed Gaussian (2), biexponential or dual exponential decay (3), Gamma distribution (4), Log-normal distribution (5), Weibull distribution (6), Bateman function (absorption-elimination), and (7) inverse Gaussian.

For each model, default parameter ranges were defined based on prior literature and empirical usage. We generated 10 parameterized variations per model by uniform random sampling within specified parameter bounds. Each function was evaluated on a high-resolution time grid (x ∈ [0, 200], 1000 points), then normalized to a total AUC of 1.0 using the trapezoidal rule.

To simulate experiment-like conditions, we computed the “support” region for each response curve by identifying the interval between the x-values at which the cumulative integral of the response first exceeded 1% and 99% of the total area under the curve. We then selected a fixed number of grid points within this region, ensuring representative sampling while mimicking practical experimental designs.

Each synthetic response curve was used as a generative model to produce a large collection of study-like datasets, enabling systematic evaluation of AUC estimation methods across a wide range of experimental scenarios. To reflect the variability of typical real-world studies, we independently varied two key experimental parameters: the number of participants and the number of reported timepoints per curve. Simulated cohort sizes ranged from 5 to 40 in increments of five, capturing both small and moderately powered study designs. For each cohort size, we considered temporal sampling schemes consisting of 4 to 10 equally spaced timepoints, mimicking the sparse reporting frequency often encountered in published figures.

To maintain plausibility, timepoints were not sampled across the full curve domain but were instead restricted to the active support region of each response function, defined as the interval between the x-values where the cumulative integral first exceeded 1% and 99% of the total area under the curve. This ensured that sampling focused on the most informative portion of the trajectory while excluding low-signal tails. Within this interval, the true underlying response was evaluated at the specified number of timepoints to create a noise-free reference trajectory.

Simulated participant-level measurements were generated at each timepoint by adding Gaussian noise to the reference value at each timepoint. The noise model assumed heteroscedasticity: the standard deviation of the noise was proportional to the local signal magnitude, specifically 20% of the true value at each sampled point. This approach captured realistic intra-cohort variability and preserved signal-dependent noise characteristics commonly observed in physiological data.

Across these noisy, simulated individual measurements at each timepoint, we then calculated group-level summary statistic values of mean and standard deviation. These aggregate statistics represented the digitized figure data typically available in secondary analyses. In total, this resulted in 3,920 digitized study-like curves, each annotated with its ground truth (AUC = 1.0).

The standard method approximates the AUC by applying the trapezoidal rule directly to the group-level means. To estimate uncertainty, AUC bounds were estimated by computing the trapezoidal rule on the mean ± standard deviation at each timepoint. The resulting range gives a comprehensive view of the estimated AUC by accounting for variability.

This yields an interval, which we report as an approximate confidence range.

At each timepoint, we sampled 1,000 synthetic observations from a distribution defined by the group mean and standard deviation, generating an equal number of artificial response curves to capture variability at each timepoint. For each of the 1,000 generated sets of synthetic observations across timepoints, a univariate cubic spline was fitted. The AUC of each interpolated curve was then calculated using the trapezoidal rule. While explicit methods for integrating cubic splines exist, we opted for numerical integration using numpy.trapz due to its simplicity, robustness, and computational efficiency. The final AUC distribution was summarized by its mean and standard deviation.

Our simulation-based Monte Carlo approach captures uncertainty by repeatedly sampling from the posterior predictive distribution implied by the mean and standard deviation at each timepoint.

Letdenote theth sample of synthetic response values.

Fit a smooth interpolating splinethrough the sampled values.

Evaluate the spline at a dense gridover the time range.

Return the mean and standard deviation of the simulated AUCs as the final estimate and its uncertainty.

This method captures both within-point uncertainty and the effect of interpolation, propagating error through the integration step to yield a full posterior distribution of plausible AUC values.

To evaluate the accuracy and precision of each AUC estimation method under simulation conditions, we computed a set of standard performance metrics as recommended by Morris et al. [30]. This included bias, defined as the average deviation of the estimated AUC values from the known true values; empirical standard error (SE), defined as the standard deviation of the estimates across simulation replicates; and root mean squared error (RMSE), defined as the square root of the mean squared deviation between estimated and true values. Coverage was also assessed, defined as the proportion of simulation replicates in which the 95% confidence interval for a given estimate contained the true value. For Monte Carlo method that yielded posterior distributions, the 95% highest density interval (HDI) was used to assess coverage, where applicable. All performance metrics were computed using custom Python functions developed for this study.

To validate the utility of our approach on real published data, we extracted glycemic response curves for 10 g allulose and 10 g fructose intakes from Fig.1of reference [31] usingPlotDigitizer. Mean response values and their associated standard deviations were obtained at each reported timepoint. Both the standard trapezoidal method with basic error propagation and the Monte Carlo-based approach were applied to these extracted summary statistics to estimate the AUC for each curve.

As a proof-of-concept application, we evaluated the AUC of digitized glycemic response curves for allulose and fructose (Fig.1[31]). Table1summarizes the estimated differences in AUC between the two interventions. The standard method yielded a difference of 31.41 ± 43.28 mmol/L·min, while the Monte Carlo method estimated a difference of 34.98 ± 21.83 mmol/L·min. Unlike the standard approach, which relies on simplified bound approximations or restrictive analytic formulas like Bailer’s, the Monte Carlo procedure offers a flexible framework capable of accommodating complex time-response profiles and distributional assumptions. Here, the narrower uncertainty bounds obtained with the Monte Carlo approach suggest improved precision and potential for increased statistical sensitivity, despite being derived from the same digitized data.

To comprehensively benchmark both AUC estimation methods, we generated a testbed of representative response curves based on seven widely used mathematical models. For each model, 10 random parameterizations were sampled, yielding a total of 70 distinct, normalized ground truth response curves (see Fig.2). These curves served as reference functions for the synthetic simulation of digitized study data. As described in the Methods section, synthetic observations were generated by sampling from distributions with 20% relative uncertainty, across varying combinations of participant numbers and data point densities. This resulted in a total of 3,920 simulated response curves, systematically spanning realistic conditions encountered in small-scale experimental studies.

We next applied both AUC estimation methods to all 3,920 synthetic response curves, each normalized to an AUC of 1.0 for consistent evaluation. Figure3summarizes the performance of the standard and Monte Carlo methods across diverse functional forms, sample sizes, and timepoint resolutions.

The Monte Carlo method consistently produced AUC estimates with higher fidelity to the true value, exhibiting distributions that were symmetric and tightly centered around 1.0. In contrast, the standard trapezoidal method showed a tendency to underestimate the AUC, particularly for response curves with strong asymmetry, rapid early peaks, or long-tailed decays.

Importantly, the Monte Carlo estimates were not only more accurate but also yielded error distributions with well-calibrated variance. These distributions were generally more symmetric and better aligned with the known ground truth. The standard method, despite producing narrower intervals in some cases, often missed the true value due to its systematic bias and limited error modeling.

Performance varied systematically by response curve type (Table2). The Monte Carlo method consistently produced AUC estimates that were more accurate and symmetric around the true value (AUC = 1.0), with reduced bias across all curve families.

The largest discrepancies were observed for complex or long-tailed functions such as the Bateman and biexponential models. Here, the standard method significantly underestimated the AUC (means: 0.80 and 0.83, respectively), while the Monte Carlo method yielded improved estimates (0.88 and 0.89) with identical or lower variance. Similar improvements were seen for gamma and lognormal functions, both of which exhibit moderate skew and variability.

Performance was highest on smoother, symmetric curves. For inverse Gaussian, skewed Gaussian, and Weibull models, both methods achieved estimates near the true AUC, but the Monte Carlo method was more tightly centered and less variable. Notably, skewed Gaussian and inverse Gaussian curves reached Monte Carlo means of 1.01 and 1.00, respectively, demonstrating robustness even under asymmetric conditions.

These results underscore the Monte Carlo method’s reliability across diverse curve morphologies, especially when digitized data is sparse or the functional form introduces skew, peaks, or tail complexity.

The Monte Carlo method provides superior performance across multiple statistical criteria when compared to standard approach. The Monte Carlo implementation achieved the lowest RMSE values for the majority of probability distributions examined, including skewed Gaussian (0.033), gamma (0.094), lognormal (0.144), and inverse Gaussian (0.036) distributions. This superior precision indicates that Monte Carlo methods provide more accurate parameter estimates across diverse distributional contexts.

Bias performance further supports the superiority of the Monte Carlo approach. The method demonstrated substantially lower absolute bias compared to standard methods for several key distributions, most notably the gamma distribution (−0.029 vs. −0.082), lognormal distribution (−0.022 vs. −0.098), and Bateman distribution (−0.124 vs. −0.194). These improvements in bias reduction suggest that Monte Carlo sampling provides more unbiased parameter estimation, particularly for complex probability distributions where analytical solutions may be suboptimal.

Coverage probability analysis reveals that the Monte Carlo method maintains excellent reliability in uncertainty quantification. The method achieved perfect coverage (100%) for both skewed Gaussian and Weibull distributions, while demonstrating superior coverage compared to standard methods across multiple distributions including biexponential (92.3% vs. 91.6%), gamma (94.3% vs. 92.7%), lognormal (90.2% vs. 87.9%), and Bateman (82.1% vs. 75.7%) distributions. This consistent improvement in coverage probability indicates that Monte Carlo confidence intervals provide more reliable uncertainty bounds.

Both methods showed improved performance with increasing numbers of participants, reflected in reduced bias and narrower uncertainty estimates. However, the Monte Carlo method exhibited greater sensitivity to sample size increases, yielding rapid convergence toward the true AUC value.

Across all tested configurations, the standard method remained consistently biased, with mean AUC estimates plateauing around 0.90 regardless of participant count. In contrast, the Monte Carlo estimates steadily approached the ground truth, with mean values stabilizing around 0.95 and progressively tighter posterior distributions. Notably, with as few as 25 participants, the Monte Carlo method achieved near-zero bias across all curve types, while maintaining standard deviations lower than or equal to those of the standard approach.

These findings suggest that the Monte Carlo method not only provides better point estimates, but also scales more favorably with data quantity, making it particularly well-suited for meta-analyses using digitized summary data from modestly sized studies.

The number of digitized timepoints (grid points) had a pronounced effect on the accuracy and reliability of both AUC estimation methods. As shown in Table3, increasing the number of extracted timepoints from 4 to 10 systematically improved the performance of both the standard and Monte Carlo methods, with the Monte Carlo approach demonstrating superior convergence characteristics across all metrics.

The Monte Carlo method consistently outperformed the standard method in terms of bias reduction, precision, and coverage probability. At low resolution (4 points), the Monte Carlo method exhibited substantially lower bias (−0.11 vs. −0.19) and better root mean square error (RMSE) (0.22 vs. 0.25) compared to the standard method. As the number of timepoints increased, the Monte Carlo method achieved near-optimal performance more rapidly, with bias approaching zero and RMSE declining to 0.03 by 10 points. Notably, the Monte Carlo method achieved 100% coverage probability at 9–10 timepoints, indicating reliable confidence interval estimation.

In contrast, the standard method showed more gradual improvement with increasing resolution. While bias and RMSE decreased with additional timepoints, the method required more points to achieve comparable performance. The coverage probability for the standard method improved from 67.7% at 4 points to 100% at 7–10 points but consistently lagged the Monte Carlo approach at lower resolutions.

These findings underscore the Monte Carlo approach’s superior ability to extract meaningful information from sparse digitized curves, making it a more reliable and robust tool in situations where graphical data is coarse or incomplete. The method’s superior performance at low resolutions is particularly valuable for practical applications where high-resolution digitization may not be feasible.

We conducted the first large-scale, systematic evaluation of methods for estimating area under the curve (AUC) from figure-derived response data—a common challenge in meta-analysis where individual-level data is often inaccessible. Using a diverse set of 3920 synthetic response curves across seven realistic pharmacokinetic and nutritional models, we benchmarked the performance of standard trapezoidal integration with propagated error against a newly proposed Monte Carlo method.

Our results show that the standard method consistently underestimates AUC, particularly for skewed, peaked, or long-tailed functions, and performs poorly when only a small number of timepoints are available. In contrast, the Monte Carlo approach achieved nearly unbiased estimates across all curve types, with tighter distributions centered around the true AUC—even at low resolution or sample sizes. This advantage was especially pronounced when the number of participants or extracted timepoints was limited, where the standard method’s bias remained high.

Additionally, we applied both methods to a real-world glycemic response dataset, demonstrating that the Monte Carlo approach yielded more statistically informative differences and narrower uncertainty bounds than the standard method. These findings support the practical superiority of simulation-based AUC estimation from digitized figures.

Based on our findings, we recommend that meta-analysts adopt simulation-based approaches—such as the Monte Carlo method—when estimating AUC from figure-derived data, due to their superior accuracy and uncertainty handling. Primary researchers should not limit reporting to graphical summaries but also provide tabulated AUC values and their associated uncertainty estimates. Finally, journals should encourage, and where possible require, the sharing of full time-resolved datasets to support transparent, reproducible, and high-precision meta-analytic research.

DDC conceived the study, provided the funding and supervision; ST, JE, DDC conducted the statistical analysis; KDC provided supervision; all authors contributed to the final manuscript writing and editing.