Fatty acid ethyl esters (FAEEs) are widely used in biofuels, pharmaceuticals, and lubricants, offering an eco-friendly alternative due to their biodegradability and renewable nature, contributing to environmental sustainability. The objective of this study is to construct advanced predictive algorithms using various machine learning methods, including AdaBoost, Decision Trees, KNN, Random Forests, Ensemble Learning, CNN, and SVR. These models aim to accurately predict the density of FAEEs across different temperature, pressure, molar mass, and elemental composition (oxygen, carbon, and hydrogen content). Experimental data reported in earlier publications were employed to develop the models. Results indicate that the dataset is highly well-suited for developing reliable models based on data. Analysis reveals that temperature exerts a considerable influence on density, with pressure also playing a critical role. The reliability of the dataset, consisting of 1307 experimental datapoints gathered from the literature, was ensured through the application of a Monte Carlo outlier detection algorithm, which validated its suitability for model training and validation. Through extensive statistical evaluations and visualization techniques, SVR emerged as the most accurate model for density prediction. Sensitivity analysis confirms the influence of all input features, with SHAP analysis identifying temperature as the most dominant factor affecting density. The developed framework provides an economical and time-saving substitute for laboratory-based experimentation density measurements, enabling precise density estimation for FAEEs under various conditions.

The increasing worldwide need for sustainable and environmentally friendly energy solutions has intensified research into renewable alternatives. In this context, fatty acid ethyl esters (FAEEs) have appeared as encouraging options for biofuels due to their renewable nature, biodegradability, and favorable physicochemical properties. FAEEs are widely utilized in biofuel production, pharmaceuticals, and industrial applications, offering a cleaner alternative to conventional fossil fuels1,2. Their low toxicity and compatibility with existing fuel infrastructure further enhance their viability as a sustainable energy source. Additionally, FAEEs contribute to environmental sustainability by decreasing emissions of greenhouse gas and lessening the ecological effects of energy generation.

Liu et al. executed research on viscosities and densities of ethyl heptanoate and ethyl octanoate within a temperature span of 303–353 K and pressures attaining up to 15 MPa. Their findings demonstrated that density displayed an increasing trend with pressure and a decreasing trend with temperature3. This research contributes valuable experimental data to further our understanding of thermophysical properties of FAEE. Wang et al. carried out a research on densities of pure ethyl octanoate and its mixtures with n-hexadecane within a temperature range of 293.15 K to 363.15 K and pressures reaching up to 60 MPa. They employed a U-shape vibrating-tube densimeter for the measurements4. The study achieved precise density predictions with deviations below 0.52%, thus contributing important knowledge about the characteristics of FAEEs. Ndiaye et al. conducted a research on sound speed in ethyl caprate and methyl caprate under various pressure conditions, ranging up to 210 MPa, and temperatures between 283.15 and 403.15 K. They also performed density measurements at pressures reaching 100 MPa and extended density values for higher pressures5. Their research offered valuable insights into the thermophysical properties of FAEE, like isentropic and isothermal compressibilities, thus expanding our understanding of these substances.

Wang et al. carried out a research analysis on the density of ethyl laurate and methyl laurate through the application of an oscillating-tube density measurement device. The assessments were conducted within a temperature range of 283.15 to 363.15 K and pressures up to 60 MPa6. The study also included calculations of thermodynamic properties like isothermal thermal expansivity and compressibility, further enhancing our understanding of the density behavior of fatty acid ethyl esters. He et al. conducted a study on viscosity and density of ethyl dodecanoate and methyl dodecanoate within a temperature range of 302–354 K and pressures up to 15.2 MPa7. This research provides useful perspectives into the pressure and temperature-dependent properties of biodiesel components, thereby contributing to a deeper understanding of these materials.

Habrioux et al. conducted a study on density, compressibility, sound speed, and viscosity of ethyl methyl and laurate laurate in liquid form. The assessments were conducted within a pressures reaching 200 MPa and a temperature span of 293.15 to 353.15 K. Acoustic wave sensors and pulse-echo techniques were utilized to measure density through the Newton-Laplace Eq.8. This research provides important data on thermophysical characteristics of fatty acid ethyl esters in high-pressure environments, contributing to our overall understanding of these substances. Aissa et al. carried out an investigation into speeds of sound, densities, viscosities, and refractive indices of various fatty acid esters, among which was ethyl laurate. The measurements were carried out over a broad spectrum of pressures and temperatures9. This research offers valuable thermophysical data, emphasizing the differences in density and compressibility between methyl and ethyl esters, and contributes to our overall understanding of these substances.

Ndiaye et al. carried out a research on sound speeds and densities of fatty acid esters, with ethyl myristate being one of the investigated substances. The measurements covered an extensive range of temperatures and pressures10. The study resulted in an equation of state that precisely predicts speed of sound and density, thus offering significant insights into the thermophysical characteristics of FAEE.

Tat and Van Gerpen conducted a study on sound speed, isentropic bulk modulus, and density of biodiesel and its pure ester constituents across a range of temperatures and pressures. Their research shed light on the significance of these properties, as they impact fuel injection timing and, consequently, may affect engine performance and emissions11. The variations in density and speed of sound may lead to timing advances, which could potentially influence NOx emissions in biodiesel-fueled engines. Their findings suggest that understanding these properties is crucial for optimizing fuel injection strategies and minimizing emissions in biodiesel-powered engines. Recently, Sukpancharoen et al. employed machine learning algorithms for estimating the output of biodiesel produced through transesterification reactions using various catalyst types, including homogeneous, heterogeneous, and enzymatic ones. Their study highlights the effectiveness of computational approaches particularly extreme gradient boosting in capturing complex relationships in biofuel production systems12. Rermborirak et al. developed a an affordable and compact system for identifying microplastics, combining Nile Red dyeing techniques with a YOLOv8-driven deep learning framework, demonstrating the practical feasibility and cost-effectiveness of machine learning tools in real-world analytical applications13. Their work exemplifies how advanced computational methods can significantly reduce operational costs while maintaining high predictive accuracy an approach that aligns with the objectives of our FAEE density prediction framework.

Over the past few years, the incorporation of machine learning techniques into renewable energy systems has advanced rapidly, offering promising alternatives to traditional modeling techniques14–19. Within the biodiesel research domain, ML has been widely applied to optimize and predict key outcomes such as yield, purity, and performance. For instance, several studies have explored the use of ML to forecast biodiesel yield based on variables like catalyst type, feedstock composition, and reaction parameters, achieving high predictive accuracy20,21. Additionally, artificial neural networks (ANNs) have demonstrated excellent performance in estimating engine behavior and emissions from biodiesel-diesel blends22. Recent developments have also combined ML with optimization methods such as response surface methodology (RSM) and evolutionary algorithms to improve biodiesel output and reduce environmental impact23,24. Despite these advances, limited studies have focused specifically on the density prediction of FAEEs, which is a critical thermophysical property influencing fuel transport, injection timing, and combustion.

Despite these advantages, the precise prediction of FAEE density continues to pose a major obstacle owing to the intricate nature of interactions between temperature, pressure, molar mass, and elemental composition (oxygen, carbon, and hydrogen content). Density is a critical parameter that influences fuel performance, combustion efficiency, and transport properties, making its accurate estimation essential for industrial applications. Experimental density measurements, while reliable, are often time-consuming and resource-intensive, necessitating the development of efficient computational models for rapid and precise predictions. This study seeks to address this limitation through the creation of sophisticated machine learning frameworks (Decision Trees, AdaBoost, Random Forests, KNN, Ensemble Learning, CNN, and SVR models) to accurately predict FAEE density, leveraging a refined dataset of 1307 data points. An anomaly detection algorithm (Monte Carlo Outlier Detection (MCOD) algorithm) was applied to guarantee the integrity of data reliability, and an analysis of input variable importance was performed to evaluate how each factor influences density of FAEEs. A range of evaluation indicators and graphical methods were applied to assess how precisely the models predicted the target values. Furthermore, SHapley Additive exPlanations (SHAP) analysis was employed to interpret the impact on key features on density predictions, offering meaningful understanding of the role of elemental composition, molar mass, temperature, and pressure. The overall methodology is illustrated in Fig.1. The present work addresses this gap by systematically evaluating multiple ML algorithms to model FAEE density using a broad dataset that incorporates temperature, pressure, molar mass, and elemental composition. By doing so, it extends existing efforts in biodiesel-related ML modeling beyond yield estimation and into the accurate prediction of transport-relevant physical properties.

Methodology for identifying the most effective model based on data-driven approaches.

where D represents databank, A denotes feature, Values(A) indicates potential feature A values, and Dvis subset of D where feature A has value v, and Entropy(D) is the entropy of the dataset D.

One of the key advantages of DT lies in their exceptional ease of interpretation. The resulting model is easy to visualize and comprehend, making it an ideal resource in situations where transparent reasoning behind decisions is essential27,28. Despite their simplicity and interpretability, Decision Tree algorithms possess both strengths and limitations.

Benefits include reduced need for data preprocessing, the ability to handle numerical and categorical data, and some resilience against outliers29,30. Additionally, the algorithm inherently identifies nonlinear relationships between features without requiring complex transformations. However, a significant challenge of Decision Trees is their tendency to overfit, particularly when trees become too deep or complex, leading to poor performance on new datasets31,32. Techniques such as tree pruning, setting a maximum depth, or employing ensemble algorithms like gradient boosting and random forests can reduce overfitting issues. While Decision Trees may not achieve the accuracy of more advanced algorithms, their ability to offer transparent understanding of the decision-making process makes them a valuable asset in fields like medicine, finance, and marketing33,34.

Where Errort​ is the weak learner’s weighted mistake ht​at iteration t.

AdaBoost effectively addresses clustering and overfitting challenges by intelligently integrating weak learners, resulting in a versatile and precise prediction model42,43. This approach allows AdaBoost to harness the unique advantages offered by each base model while minimizing their limitations, leading to improved overall performance.

In this equation, ŷ denotes the aggregated output, T refers to the total number of decision trees within the ensemble, and ht​(x) corresponds to the prediction generated by the t-th tree for the input instance x.

This ensemble strategy enables Random Forest to leverage the predictive capabilities of multiple models while mitigating overfitting and enhancing generalization performance47,48. The utilization of random subsets and features in Random Forest results in a model that exhibits both precision and resilience, while effectively minimizing overfitting risks49,50. Overfitting, a common challenge where a model exhibits strong performance during training yet struggles with unseen data during testing, is mitigated through Random Forest’s ensemble approach51–53. By combining multiple decision trees, Random Forest reduces the reliance on individual models and effectively captures patterns and relationships within the data54,55.

EL is widely recognized in statistics and machine learning for combining several models to produce a single, unified prediction from a dataset44,45. This approach involves several algorithms working together to generate individual predictions, which are then combined to produce the ultimate result56,57. Although the most frequent output is often selected as the final prediction, different ensemble learning models may assign varying weights to individual predictions or adopt a sequential approach, utilizing the outputs of previous models58,59.

where: T denotes the total number of models within the ensemble, wt​indicates the weight allocated to the tth model, ht​(x) is the output of the t-th model for the input x, I(·) represents an indicator function that yields 1 if the specified condition holds true and 0 otherwise, and c refers to the set of possible class labels59,60.

Within this framework, f refers to the input image or intermediate feature map, g designates the convolutional filter applied during the operation, and (x, y) specifies the spatial location within the resulting activation map62.

One significant advantage of CNNs is their effectiveness in handling data with many dimensions, making them well-suited for tasks such as identifying objects and classifying images. These models often incorporate pooling layers to reduce feature map size and mitigate the risk of overfitting. Due to their impressive accuracy, CNNs have had a profound impact on advancements in computer vision63.

In this formulation, x and y represent two samples within the feature space, n indicates the total number of features, and xiand yicorrespond to the values of the i-th feature for data points x and y, respectively.

KNN operates as a non-parametric method, meaning it makes no assumptions about the data’s underlying distribution. This characteristic grants it adaptability, making it applicable to a wide range of data structures68,69. One of the main advantages of the K-Nearest Neighbors (KNN) algorithm is its simplicity and ease of implementation. However, its performance is highly sensitive to the choice of the parameter k and the distance measurement used. Selecting a small k may cause the model to overfit the training data, while a larger k can lead to underfitting by oversmoothing the decision boundaries70. Moreover, KNN can be resource-intensive for extensive datasets since it necessitates computing distances between the target point and every other point in dataset. In spite of these difficulties, KNN is commonly utilized in areas like recommendation systems, image identification, and medical diagnostics, due to its straightforward approach and efficiency in identifying local patterns in data71,72.

In this setting, w defines the hyperplane’s weight vector, b is the bias constant, xidenotes theith input sample, yicorresponds to its associated class label (either + 1 or − 1), and n represents the complete count of samples in the dataset76–78.

When the data cannot be separated linearly, SVM employs kernel functions like Gaussian or polynomial kernels to convert the information into a more complex-dimensional space, enabling for better separation79,80. One of the primary strengths of Support Vector Machines (SVM) is their ability to handle datasets with many features, making them highly effective for applications like visual recognition and language processing tasks. Nonetheless, a significant obstacle of this algorithm is its computational complexity and extended processing duration for sizable datasets81,82. Moreover, adjusting model parameters like the kernel type, penalty parameter (C), and parameters specific to the kernel necessitates substantial experimentation and cross-validation methods. In spite of these constraints, SVM continues to be a key algorithm in machine learning because of its excellent accuracy and adaptability across different applications83,84.

The information required for developing the machine learning models in this study was obtained based on findings reported in earlier studies that conducted extensive experimental analyses on the density characteristics of various FAEEs under different laboratory conditions. The dataset includes 1307 data points, incorporating key input variables such as temperature, pressure, molar mass, and elemental composition (oxygen, carbon, and hydrogen content)3–11. The FAEEs considered in this study include: Ethyl caprate, Ethyl dodecanoate, Ethyl heptanoate, Ethyl laurate, Ethyl linoleate, Ethyl myristate, Ethyl octanoate, Ethyl oleate, and Ethyl stearate. Table1presents the range of temperature, pressure, and density values for each fatty acid ethyl ester (FAEE) included in this study. The dataset covers a broad spectrum of thermodynamic conditions, with temperatures ranging from 283.15 K to 413.15 K and pressures extending up to 200 MPa. This wide variation ensures that the machine learning algorithms are trained on diverse scenarios, enhancing their generalizability and robustness. The density values also span a significant range, reflecting differences in molecular structure and composition among the FAEEs, which reinforces the demand for highly reliable forecasting tools capable of capturing such complex variations.

Temperature, pressure, and density ranges for the studied fatty acid Ethyl esters (FAEEs).

In this study, density is treated as the primary output variable, whereas temperature, pressure, molecular weight, and the elemental percentages of oxygen, carbon, and hydrogen are considered the main predictors. To explore the impact of these variables on FAEEs density and to assess their range and behavior, visual correlation plots have been generated and are presented in Fig.2. These visual tools offer an in-depth perspective of the dataset, highlighting patterns, inter-variable relationships, and potential anomalies. This exploratory step plays a key role in understanding the dataset’s underlying structure and supports the creation of robust forecasting algorithms. Furthermore, Fig.3illustrates raincloud diagrams for every parameter individually, enabling a clear view of their distribution characteristics.

Scatter matrix visualization illustrating the interdependencies among the variables.

Visualization of variable distributions using raincloud plots.

To enhance the accuracy of machine learning algorithms, the K-fold cross-validation technique was applied, which allows the entire dataset to be systematically leveraged for evaluation over K iterations85–87. This method involves dividing the dataset into K equally sized segments, with each fold serving a single time as the validation set, and the other K–1 portions serve for model training. After all K cycles are completed, the validation results are combined to yield a more stable and unbiased performance estimate, reducing the effects of randomness in data partitioning. Additionally, this strategy significantly lowers the risk of overfitting. In this study, each machine learning model was trained using a five-fold cross-validation scheme to enhance its ability to generalize to unseen data.

In the given formulas, the subscript i refers to the index corresponding to a specific observation within the databank. The abbreviations pred and exp indicate the predicted and measured values for every respective entry. Furthermore, N signifies the total number of data instances contained in the dataset91–93.

The predictive models are constructed using a set of input features that include temperature, pressure, molecular weight, and the elemental composition specifically the percentages of oxygen, carbon, and hydrogen. The output variable to be predicted is the density of FAEEs. For a comprehensive evaluation of model performance, databank is randomly split into three distinct portions. The majority of the data (90%) is allocated for training purposes, while the remaining 10% is reserved for testing.

In the normalization formula, the symbols represent the following: n refers to the original, unprocessed data value; nmaxand nmindenote the maximum and minimum values within the dataset, respectively; and nnormindicates the resulting standardized value.

Before constructing data-driven algorithms to estimate density of fatty acid ethyl esters (FAEEs), it is crucial to ensure data reliability by addressing outliers. This study employs the Monte Carlo Outlier Detection (MCOD) algorithm, which efficiently detects anomalies in large datasets by combining random sampling with density-based techniques. MCOD identifies local density variations to highlight points that significantly deviate from their surrounding values. By leveraging Monte Carlo sampling, the algorithm evaluates a subset of the data, reducing computational costs while maintaining accuracy94. Due to its ability to scale effectively and operate with high speed, it is well-adapted for use in real-time environments and with datasets containing a large number of features. However, like any method, MCOD requires a trade-off between precision and computational efficiency, affected by elements like dataset magnitude and the selected count of closest neighbors (k). Even with these factors in mind, MCOD remains a valuable method for preliminary data exploration and identifying unusual patterns, especially when precise accuracy is not critical or when processing power is constrained.

Figure4displays a boxplot that visualizes the dataset applied in this investigation, highlighting the spread of FAEE density values and establishing the permissible boundaries for model training. The concentration of data points within the defined limits suggests strong data integrity. In this work, the entire dataset was employed throughout the model learning process using machine learning techniques algorithms, promoting the development of models grounded in a complete and well-balanced sample. This strategy improves the models’ capacity to generalize across new inputs by effectively learning the intrinsic trends and fluctuations in the data. Consequently, the models demonstrate improved precision and robustness in predicting the density of FAEEs.

(A) Identifying outliers using the monte carlo algorithm, (B) Boxplot of data distribution.

Within this framework, the subscript j refers to the particular feature under examination. The relevance factor ranges between − 1 and + 1, where values approaching + 1 reflect a strong positive link between the input and the target variable. On the other hand, values closer to − 1 imply a strong inverse association. A negative score reveals that the input and output move in opposite directions, while a positive score denotes a direct relationship.

As shown in Fig.5, correlation matrix illustrates the interdependencies among the input features pressure, temperature, molar mass, and elemental composition (oxygen, carbon, and hydrogen content) and the output parameter. The correlations of molar mass and elemental composition with density are very weak (-0.06 to 0.02). The findings indicate that pressure exhibits a slight positive correlation (0.17) with density, suggesting that an increase in pressure could cause a minor enhancement in the density of FAEEs, although the relationship is not particularly strong. Temperature, on the other hand, shows a negative correlation (-0.28) with density, indicating that temperature changes have direct impact on the density of FAEEs.

The determined significance score corresponding to each input variable.

This part of the study describes the procedure used to fine-tune the hyperparameters for the various machine learning algorithms developed in this research. As illustrated in Fig.6, each subplot presents the tuning results for a specific algorithm. The best maximum depth for Decision Tree algorithm was found to be 15, minimizing the Mean Squared Error (MSE). For the AdaBoost algorithm, 49 estimators yielded the best performance. In the case of Random Forest, the MSE reached its lowest value with a maximum depth of 14. The K-Nearest Neighbors (KNN) model achieved optimal results using 4 neighbors. Additionally, the CNN model’s loss function exhibited steady convergence over training epochs, and the SVR model demonstrated optimal performance at a specific value of the regularization parameter C. Collectively, these results presented in Fig.6underscore the importance of proper hyperparameter tuning in maximizing efficiency of forecasting frameworks.

The optimal value for various mashine learning method.

Table2summarizes the evaluation results for multiple data-driven modeling techniques, such as Decision Tree, KNN, Random Forest, AdaBoost, Ensemble Learning, CNN, and SVR. The reported performance indicators include MSE, R², and AARE%. A visual comparison of these metrics during the test stage is illustrated in Fig.7, offering clearer insights into model effectiveness.

The recorded performance metric values for each developed model across all dataset partitions are presented.

R-squared, MSE and AARE% of all developed models during the testing stage.

Based on the test results, the SVR (Support Vector Regression) method outperforms the other algorithms, exhibiting the lowest MSE (1.5169392) and the highest R² (0.9975452), indicating its superior predictive accuracy. Additionally, it achieves the lowest AARE% (0.0792602), further confirming its robustness and reliability. In contrast, KNN (K-Nearest Neighbors) appears to be the least accurate in this study, yielding the highest MSE (17.39721) and AARE% (0.2797323) values, along with a relatively low coefficient of determination (R² = 0.9718468).

To assess how effectively the trained models perform in generating predictions, this research utilizes a range of visual analysis techniques. As part of the initial assessment, cross plots were generated for each algorithm, with the results shown in Fig.8. Among the evaluated models, SVR displayed exceptional predictive capability, as indicated by the close clustering of points around the unite slope line and regression curves aligning well with the bisector. In addition, Fig.9illustrates the distribution of relative errors for all models, where predictions situated near the horizontal axis (y = 0) reflect greater precision. Based on these findings, SVR emerges as the most effective model in terms of predictive reliability.

Crossplots of predicted versus actual values for all segments for all created intelligent algorithms.

Relative error percent for all segments and for all the constructed algorithms in this study.

Figure10illustrates the contribution of every input feature to predictions of density estimation model, as interpreted through SHAP. The model considers several inputs, including temperature, pressure, molecular weight, and elemental composition specifically the weight percentages of oxygen, carbon, and hydrogen in various FAEE compounds. The chart ranks the input features according to their average absolute SHAP values, reflecting the extent to which each variable influences the model’s output. Among these, temperature emerges as the most impactful predictor, indicating its dominant role in shaping the model’s results. Pressure ranks next in terms of its impact among the input variables, with a comparatively lower but still notable SHAP score. This indicates that while pressure has a noticeable impact on the density of FAEE, its effect is less pronounced compared to temperature. Elemental composition and molar mass appear to have the least impact among the variables considered, as reflected by their lower SHAP score. This evaluation underscores the comparative significance of each individual factor parameter in influencing density of FAEE, with temperature being the most critical factor.

Figure11presents the SHAP interpretation results for a density prediction model focused on FAEEs, using input features such as molecular weight, pressure, temperature, and elemental composition. The plot illustrates the contribution of every input feature contributes to algorithm’s predictions: positive SHAP values reflect an increase in predicted density, while values below zero reflect a downward effect. Among all inputs, temperature shows the widest distribution of SHAP values, confirming its dominant influence. Pressure also plays a notable role, though its effect appears more moderate due to a narrower SHAP range. This analysis ranks the relative importance of the variables, with temperature exerting the strongest influence, followed by pressure, then elemental makeup and molar mass. These findings offer meaningful direction for both further research and practical applications in density estimation tasks.

While the developed machine learning models demonstrated high predictive accuracy, it is important to recognize the constraints they possess and applicability domain. These models are trained on a dataset comprising 1307 data points, covering a specific range of temperature (283–363 K), pressure (up to 100 MPa), and FAEE molecular compositions. Therefore, their reliability outside these ranges remains uncertain.

Moreover, the models rely on features derived from existing experimental studies; thus, any extrapolation beyond the observed parameter space (e.g., novel esters with significantly different structures or compositions) may lead to decreased performance. Additionally, deep learning models like SVR are sensitive to feature scaling and hyperparameter tuning, which could affect model robustness in unseen conditions.

Regarding uncertainty quantification, although performance metrics such as R² and MSE provide insight into overall accuracy, they do not capture prediction variability. To estimate the model’s confidence, we evaluated prediction intervals using repeated cross-validation and analyzed the standard deviation of residuals across folds. This preliminary uncertainty assessment suggests that predictions remain within ± 2% error bounds in most cases. However, a more rigorous uncertainty analysis e.g., via Monte Carlo dropout or bootstrapped ensembles can further enhance the model’s reliability for real-world applications.

The methodology developed in this study represents a novel and versatile framework that can be extended beyond the specific context of fatty acid ethyl ester (FAEE) density prediction. By integrating advanced machine learning algorithms with robust data preprocessing (e.g., Monte Carlo outlier detection) and interpretability tools such as SHAP, this approach offers a transferable blueprint for tackling complex predictive tasks in various scientific and engineering domains. Specialists across different disciplines can adapt this data-driven strategy to explore thermophysical properties, optimize system performance, and accelerate experimental workflows with minimal resource expenditure.

Future research should investigate the broader applicability of this methodology in aerospace trajectory optimization and path planning (e.g., self-reconfigurable satellite operations and proximity control)96–99, advanced materials science (e.g., solidification microstructure analysis, phase transformations in alloys, and high-performance ceramic composites)100–103, and biomedical and pharmaceutical engineering (e.g., stem cell therapy optimization and inflammation-targeted drug delivery systems)104–107. Moreover, emerging fields such as environmental and structural monitoring in civil engineering (e.g., noise reduction barriers, cable dome stress distribution, and marine pasture sensing)108,109stand to benefit from this adaptable framework. Applying this methodology to such domains can enable rapid knowledge transfer, reduce dependency on costly experimental trials, and facilitate real-time predictive modeling for complex systems.

To further enhance its impact, future studies should aim to (i) integrate domain-specific physical constraints into the modeling process to improve extrapolation capabilities, (ii) explore hybrid modeling by coupling data-driven methods with first-principle simulations, and (iii) develop user-friendly interfaces or open-source toolkits to encourage cross-disciplinary adoption. These extensions will ensure that the proposed methodology evolves into a practical and widely deployable tool for modern scientific inquiry and engineering design.

In this work, sophisticated models based on data-driven techniques were constructed by employing a range of machine learning algorithms, including AdaBoost, Decision Trees, KNN, Random Forests, Ensemble Learning, CNN, and SVR, to predict the density of FAEE. The models utilized a comprehensive dataset of 1307 data points, incorporating temperature, pressure, molar composition, and elemental analysis as input variables. Alongside the typical factors of temperature and pressure, the study also integrates molar mass and elemental analysis as key variables. These additional factors enable a more profound comprehension of the chemical properties and behavior of fatty acid ethyl esters, offering a more accurate and cost-effective solution for predicting FAEE density. The correlation matrix reveals weak relationships between density and input variables like molar mass and elemental composition (O, C, H), while pressure shows a slight positive correlation (0.17) and temperature a negative correlation (-0.28) with density, indicating temperature has a more direct impact on FAEE density compared to pressure. Among the machine learning models evaluated, the SVR algorithm consistently outperformed others in terms of prediction accuracy. The SHAP analysis further revealed the specific contributions of each input, showing that temperature and pressure had the greatest influence on the estimated density of FAEE. By utilizing these advanced machine learning techniques, this study provides an efficient, cost-effective tool for accurately predicting FAEE density, which can be used as an alternative to expensive and time-consuming laboratory experiments. The tool developed here contributes to the optimization of industrial processes involving FAEE, offering a practical solution for predicting their physical properties.

The authors extend their appreciation to the Deanship of Scientific Research at Northern Border University, Arar, KSA, for funding this research work through the project number NBU-FFR-2025-2230-05.