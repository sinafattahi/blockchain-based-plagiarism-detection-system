To address the limitations of the standard equilibrium optimizer (EO) in terms of insufficient optimization capability, multiple strategies are proposed to enhance its performance. These include a reverse equilibrium state pool, a non-uniform equilibrium state selection strategy, and an equilibrium state mutation strategy. The reverse equilibrium state pool is introduced to encourage candidate solutions with poorer positions to search in a wider search space, under such considerations the global search ability of the improved EO can be enhanced. The non-uniform equilibrium state selection strategy is proposed to select equilibrium state. Under the proposed selection strategy, the candidate solutions with better positions are more likely to be chosen as the equilibrium state, allowing for sufficient exploration of positions near the current optimal point. The equilibrium state mutation strategy leads to cross mutation between candidate solutions and equilibrium state, increasing the likelihood of the group exploring the global optimal solution. To verify and further analyze the performance and superiority of the improved EO, i.e., reverse equilibrium states EO (RO), 29 benchmark functions are adopted. It is verified theoretically from the experimental results that the RO is with a significant improvement in performance by comparison between the standard EO and certain frequently-used heuristic optimization algorithms. Finally, the RO is successfully applied in path planning for surface marine vehicles under the situations of both dynamic and static obstacles.

Nowadays, application-oriented optimization problems have attracted numerous researchers to study and seek for solutions, as highlighted in recent review papers1–5. In the real word, being directed against specific engineering problems, various heuristic optimization algorithms have already demonstrated their excellent performances in dealing with optimization problems, such as differential evolution6, genetic algorithm7,8, ant colony optimization9, simulated annealing algorithm10, equilibrium optimizer (EO)11, particle swarm optimization (PSO)12and so on.

The EO is a heuristic optimization algorithm introduced by the authors in11. Owing to the outstanding optimization performance, EO is with strong application potential and has been successfully applied in various practical applications to cope with the optimization issues, see for instance13–21. In14, by sufficiently considering slime mould algorithm, an EO-based job shop scheduling solution has been proposed, which can solve bigger-scale job shop scheduling problem with faster rate of convergence. An EO-basedk-nearest neighbor classifier has been designed in15to maintenance internet security and further reduce the losses caused by cyber-attacks. By introducing EO into slime mould algorithm, the algorithm efficiency has been improved by means of optimizing the search of slime mould algorithm in17, and the modified algorithm has well solved nine engineering design problems by seeking out feasible solutions under all engineering constraints. Moreover, the power flow optical calculation for power systems in18and the capacitated vehicle routing problems in20have been also addressed by employing EO, respectively.

Although EO has been widely applied and has shown effectiveness in engineering practices, significant research efforts are still focused on improving its accuracy. And so far, the performance of the EO has been improved from different perspectives. For example, in order to avoid duplicated solutions and conserve valuable evaluation opportunities, an improved EO algorithm based on dual population of non revisit mechanism has been proposed in22. For the sake of balancing the abilities of exploration and exploitation, a hybrid algorithm EO-grey wolf optimizer is proposed in23, where EO-grey wolf optimizer is used to search the optimization solutions obtained from EO and the additional evaluation of the objective function is not added. In24, by introducing an opposition-based learning strategy, an ameliorated equilibrium optimizer has been proposed. In25, an enhanced EO has been investigated for a class of distributed generations with the distribution systems. To the best of the authors’ knowledge, there are relatively few research results on the improved EO based on multiple strategies and its optimization performance has not been fully analyzed, which construct the primary motivation of this study.

The core of the path planning problem is to design an algorithm which can permit an agent to travel from the starting point to the required end point and meanwhile ensures that the path picked out is a collision-free path within an environment space26. The path planning problem has been investigated for decades and the common goal is to find a solution to the optimal path planning problem. In the fields of control and robotics, many researchers have paid a lot of time and effort on the optimal path planning issues and a large number of remarkable research results have been published, see27–34. Moreover, when it comes to the intelligent algorithm-based solutions to the optimal path planning issues, the outcomes are relatively few. In35, an ameliorated EO has been proposed by combining learning mechanism to deal with the smooth path planning problem for unmanned ground vehicle. So far, a solution based on the RO to the path planning problem is not yet available. For this reason, it is of significance to look for a solution to the path planning problem based on the improved RO, which is another intention to this study.

Inspired by the above analysis and discussion, the aim of this paper is to further improve the optimization performance of EO and look for a solution to the path planning problem based on the RO, and then the obtained results will be applied in path planning problem for surface marine vehicle (SMV). The main contributions are twofold: (1) the multiple strategies which conclude the reverse equilibrium state pool, the non-uniform equilibrium state selection strategy and the equilibrium state mutation strategy are proposed to improve the performance of EO; (2) the RO is successfully applied in determining the optimal path planning problem for SMV.

The remainder of this paper is organized as follows. The basic principle of the EO is detailed in Section "The basic principle of the EO". Section "The proposed reverse equilibrium states equilibrium optimizer" describes the proposed RO. The performance of the proposed RO is verified in Section “Simulation results”. The application in path planning for SMV is given in Section "Application of the proposed RE2O to path planning for SMV". In Section “Conclusion” the conclusions are presented.

whereVrepresents the control volume,Cis the concentration within the control volume, andQrepresents the volumetric flow rate of mass entering or leaving the control volume,is the concentration within the control volume when there is no mass generation,Gis the rate of mass generation within the control volume.

whereFis the exponential coefficient,is the liquidity rate, andis the initial concentration of the control volume at time. The core of the EO is shown in (2), and each individual in population mainly relies on equation (2) for iterative updates.

In EO, the candidate solutions in the population are iteratively updated according to (9), withbeing randomly selected from the equilibrium state pool, which to some extent helps prevent individuals from getting stuck in low-quality local optima. However, in this mode, individuals in the population only continuously search around better solutions and ignore other parts of the search space. We rank the individuals in the population in ascending order of fitness value, and individuals with lower fitness values represent higher quality candidate solutions. According to the fitness value, the population is divided into elites with lower fitness values, masses with common fitness values, and scumbags with higher fitness values.

Theandin equation (16) are randomly selected as individuals from the population,is a random number obeying to a uniform distribution. Based on the above description, the proposedReverse Equilibrium States Equilibrium Optimizer(RO) is summarized and shown in Algorithm 1.

In the statement above for discussion and theoretical analysis, the principle of the proposed RO has been enunciated and the corresponding pseudo-code of the Proposed RO algorithm has been given in Algorithm 1. The novelty of the RO, on the one hand, is to adopt multiple strategies, including the reverse equilibrium state pool, the non-uniform equilibrium state selection strategy, and the equilibrium state mutation strategy, to improve the performance of the standard EO. On the other hand, it can be used for the path planing problem of SMV under the situation of both dynamic and static obstacles. In the subsequent section, from aspects of benchmark functions test and the application under different situations, the simulation will be implemented to verify the effectiveness of the RO.

The computational complexity ofO can be analyzed by decomposing its operations within a single iteration. LetNdenote the number of individuals,dthe dimensionality of the search space, andTthe maximum number of iterations. Letrepresent the cost of a single fitness evaluation, which is typicallyO(d) for standard benchmark functions.

1) Initialization: The initialization of the populationrequiresO(Nd) operations.

2) Fitness Evaluation and Boundary Handling: At each iteration, all individuals are clipped to the search boundaries, which takesO(Nd) operations, and their fitness values are computed, leading tocomplexity.

3) Sorting and Elite Selection: Unlike the original EO algorithm, which identifies the top four individuals using simple comparisons (O(N)),O performs a full sort of the population fitness, which has a computational complexity of. This step allowsO to construct both elite and inferior candidate pools, introducing additional overhead compared to EO.

4) Position Updates: The position update for each individual involves vector arithmetic over all dimensions, yieldingO(Nd) operations.O introduces more complex update rules with multiple branches (based on the rank of individuals), but these remain in the sameO(Nd) order with slightly higher constant factors.

The CEC2017 benchmark functions includes 29 functions, whereis an unimodal function,are simple multimodal functions,are hybrid functions, andare composition functions. For a more detailed introduction to CEC2017 benchmark functions, please refer to36. In order to fairly compare the performance of algorithms, the initial parameters of all algorithms are kept the same: the maximum number of iterations is 3000, the size of the population is 100, and the dimensions of the optimization problems are 10. Set,,,, and. For each test function, all algorithms are run 30 times and the experimental results are recorded. The settings of the specific parameters of the experimental platform are shown in Table1.

After running 30 times in CEC2017, the experimental results of the proposed RO and the comparative algorithms are recorded in Tables2and3, where Ave, Opt, Med, and std indicate, respectively, the average, optimal, median, and standard deviation of 30 experimental results. It can be seen that for testing problems,,,,, and, the proposed RO can find its global best advantage. For most testing problems, RO has a significant improvement in performance compared with the EO. In addition, RO is also compared with some popular optimization algorithms such as PSO37, whale optimization algorithm (WOA)38, and gravitational search algorithm (GSA)39, and the comparison of experimental results show that the performance of the RO is sounder than these comparative optimization algorithms.

Comparison between the proposed RO and EO, PSO, WOA and GSA on CEC2017.

Comparison between the proposed RO and EO, PSO, WOA and GSA on CEC2017.

Figures1,2and3present the convergence curves of the proposed RO and the comparative algorithms on 29 benchmark functions. It can be observed that RO consistently converges faster than the others, especially on multimodal problems such as,, and, where its fitness values drop significantly within the first few hundred iterations. This demonstrates the superior exploitation ability of the proposed method.

The convergence curves of both the proposed RO and the comparative algorithms.

The convergence curves of both the proposed RO and the comparative algorithms.

The convergence curves of both the proposed RO and the comparative algorithms.

To further assess performance stability, Figures4,5and6provide the box plots of the best fitness values obtained by each algorithm over 30 independent runs. The proposed RO exhibits not only the best median performance on most functions, such as,, and, but also smaller variances, indicating its robustness and consistency.

The box plots of the proposed RO and the comparative algorithms.

The box plots of the proposed RO and the comparative algorithms.

The box plots of the proposed RO and the comparative algorithms.

Table4reports the computational cost of EO andO. It can be observed thatO incurs a slightly higher CPU time compared with EO. Specifically, across the benchmark functions-,O increases the average runtime by approximately-. Nevertheless, this additional overhead is negligible compared with the performance improvements achieved byO, as demonstrated in its faster convergence and higher solution accuracy.

Average CPU execution time (in seconds) for EO andO methods over 30 independent runs.

To evaluate the contribution of each proposed strategy, an ablation study is conducted on. In this study, three reduced versions of the proposedO are designed by individually disabling specific strategies. In the first variant, the reverse equilibrium state pool and its associated update rule (Eqs. (10) - (13)) are removed, and the individuals are updated solely based on the standard equilibrium pool. In the second variant, the non-uniform equilibrium state selection mechanism (Eq. (14)) is replaced by a uniform selection strategy where each candidate has the same selection probability. In the third variant, the equilibrium state mutation operator (Eqs. (15) - (16)) is removed, so the elites are updated only by the standard EO operators without any mutation. The original EO and the completeO with all strategies are also included for comparison. For each method, 30 independent runs are conducted, and the optimal (Opt), average (Ave), median (Med), and standard deviation (Std) of the fitness values are reported.

The ablation results onare presented in Table5. It can be observed that the completeO achieves the best performance with Opt, Ave, and Med values all reaching the global optimum of 100.00, and a standard deviation of 0.00, indicating stable convergence across all 30 runs. Compared with the original EO, all three proposed strategies effectively enhance performance, as removing any of them leads to a noticeable deterioration in the average and median results. Among these strategies, the reverse equilibrium state pool has the most significant impact, as its removal causes the average fitness to increase from 100.00 to 1218.40. The non-uniform equilibrium state selection and the equilibrium state mutation also contribute to improved convergence, with their absence resulting in average fitness values of 742.30 and 698.20, respectively. These observations confirm that the combination of the three strategies is essential for achieving both high accuracy and robustness in the optimization process.

SMVs have been widely used in tasks such as environmental monitoring, maritime surveillance, and offshore engineering due to their low cost and high flexibility. A key challenge in SMV navigation is path planning, which aims to find a collision-free and energy-efficient trajectory from the starting point to the target location. The complexity of this problem arises from multiple factors, including the presence of stationary or dynamic obstacles, the physical constraints of the vehicle, and the requirement for safe and smooth maneuvering in a marine environment.

Simulation-based path planning plays an essential role in validating and optimizing SMV navigation strategies before real-world deployment. By constructing a two-dimensional or three-dimensional marine environment with representative obstacles, the optimization algorithm can be tested under various conditions to evaluate its capability of finding an optimal path. Such simulations not only reduce experimental costs and risks but also allow rapid prototyping of algorithms and fine-tuning of parameters. Therefore, applying the proposed RO algorithm to SMV path planning provides a practical and cost-effective way to evaluate its performance in real-world-like navigation scenarios.

whereis the amplification factor of the collision coefficient.

The proposed RO is used to plan the movement path for SMV in the above considered environment. To verify the effectiveness of the RO in optimizing the path of SMVs, the algorithm is run 50 times in the above considered environment, with a maximum iteration count of 150, a population count of 50, and a middle point count of 6. The experimental results are recorded in Table6, where Opt, Ave, Var, and AveT are, respectively, the optimal value, average value, variance, and average time spent for the length of the optimal path found after 50 runs of the algorithm. Fig.8and Fig.9depict the planed path and the iteration curve of the RO operation process, respectively. Fig.10illustrates the statistical results of the length of the optimal path. It can be seen that in the considered environment, the RO can look for the optimum path with the shortest movement distance while effectively avoiding obstacles.

Statistics of the length results of the optimal path.

Statistical results of the length of the optimal path.

Due to the influence of certain factors, such as ocean currents and winds, on ships or other objects in the ocean, these objects are frequently not in a static state, but rather dynamic. In view of those considerations, a simulation under the situation of dynamic obstacles is conducted, which can also further demonstrate the performance of the proposed RO. The collision detection rule in (18) is used to ensure the safety of the ship during movement. The results of path planning are depicted in Fig.11, where the planned paths at the different horizontal distances are given. The simulation shows that, according to the propose RO, SMV from the starting point to the end point can well avoid dynamic obstacles to move along the real time planned path. In summary, the performance of the proposed RO has been well demonstrated through simulations under both dynamic and static obstacles.

The planned path using the proposed RO under the situation of dynamic obstacles.

Remark:AlthoughO demonstrates superior performance on the tested 10-dimensional benchmarks and 2D SMV path planning tasks, its scalability to highly complex, high-dimensional, or real-time path planning problems may be limited due to the enlarged search space and increased computational demands, which could also raise the risk of premature convergence. ExtendingO with adaptive parameter control, hybrid strategies, or parallel computation will be considered in future work to improve its robustness and practical applicability.

For the sake of alleviating the shortcomings of the insufficient optimization capability of the standard EO, the multiple strategies, concluding the reverse equilibrium state pool, the non-uniform equilibrium state selection strategy and the equilibrium state mutation strategy, have been proposed in this paper. Specifically, for the global of enhancing the search ability of the EO, the reverse equilibrium state pool has been introduced to encourage candidate solutions with poorer positions to search in a wider search space. The non-uniform equilibrium state selection strategy is proposed to select equilibrium state. Then, under the proposed non-uniform equilibrium state selection strategy, the candidate solutions with better positions can be chosen as the equilibrium state. The equilibrium state mutation strategy can complete cross mutation between candidate solutions and equilibrium state, increasing the likelihood of the group exploring the global optimal solution. Subsequently, the performance of the proposed RO has been verified and analyzed by adopting 29 benchmark functions. The experimental results have demonstrated that the RO is with a significant improvement in performance by comparison between the standard EO, PSO, WOA, and GSA. Finally, in both static and dynamic environments of obstacles, the path planning problem for SMVs has been solved in terms of the proposed RO. Future research will focus on extending RO to high-dimensional and real-time path planning tasks, incorporating adaptive parameter control or hybrid mechanisms with learning-based strategies, and exploring its scalability under more complex environmental constraints such as dynamic currents and energy limitations40–42.