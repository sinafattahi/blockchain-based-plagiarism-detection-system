The aim of this study is to synthesize existing literature on patient attitudes toward artificial intelligence in cancer care and identify knowledge gaps that can inform future research and clinical implementation.

A scoping review was conducted following the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) guidelines. MEDLINE, Embase, PsycINFO, and CINAHL were searched for peer-reviewed primary research studies published until February 1, 2025. The Population-Concept-Context framework guided study selection, focusing on adult patients with cancer and their attitudes toward artificial intelligence. Studies with quantitative or qualitative data were included. Two independent reviewers screened studies, with a third resolving disagreements. Data were synthesized into tabular and narrative summaries.

Our search yielded 1240 citations, of which 19 studies met the inclusion criteria, representing 2114 patients with cancer across 15 countries. Most studies used quantitative methods (9/19, 47%) such as questionnaires or surveys. The most studied cancers were melanoma (375/2114, 17.7%), prostate (n=323, 15.3%), breast (n=263, 12.4%), and colorectal cancer (n=251, 11.9%). Although patients with cancer generally supported artificial intelligence when used as a physician-guided tool (9/19, 47%), concerns about depersonalization, treatment bias, and data security highlighted challenges in implementation. Trust in artificial intelligence (10/19, 53%) was shaped by physician endorsement and patient familiarity, with greater trust when artificial intelligence was physician-guided. Geographic differences were observed, with greater artificial intelligence acceptance in Asia, while skepticism was more prevalent in North America and Europe. Additionally, patients with metastatic cancer (99/2114, 5%) were underrepresented, limiting insights into artificial intelligence perceptions in this population.

This scoping review provides the first synthesis of patient attitudes toward artificial intelligence across all cancer types and highlights concerns unique to patients with cancer. Clinicians can use these findings to enhance patient acceptance of artificial intelligence by positioning it as a physician-guided tool and ensuring its integration aligns with patient values and expectations.

Artificial intelligence (AI) refers to computer systems that simulate human intelligence to perform tasks such as learning, decision-making, and pattern recognition with minimal human input [1]. In health care, AI technologies include structured machine learning, natural language processing, and computer vision, which are increasingly applied to improve diagnosis, prognosis, and treatment planning [2-4]. In cancer care, AI is advancing detection, diagnosis, and treatment by analyzing complex data to support clinical decisions. These technologies are being applied to improve diagnostic accuracy, predict survival outcomes, and personalize treatment strategies [5-12]. However, AI’s impact depends not only on its technical capabilities but also on patient acceptance and trust. Understanding these perspectives is essential to ensuring a successful patient-centered approach to AI implementation [13].

Although general attitudes of all patients toward AI have been studied, research specifically examining the perspectives of patients with cancer remains limited [14]. The chronic and severe nature of cancer creates unique psychosocial challenges for patients, which may shape their attitudes toward AI in ways distinct from other medical contexts [15,16]. The limited existing studies primarily focus on individual cancer types, such as breast and skin cancer [17-20], leaving gaps in understanding how AI is perceived across diverse cancer care contexts. A more comprehensive evaluation is needed to capture the full spectrum of patients’ attitudes toward AI in cancer care.

This scoping review maps the existing literature, identifies knowledge gaps, and highlights opportunities for future research regarding patients’ attitudes toward AI in cancer care. Given its broad and exploratory scope, this review provides a foundation for guiding the patient-centered development and implementation of AI in cancer care [21-23].

This scoping review followed a 6-stage methodological framework and adhered to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews guideline (PRISMA-ScR) as seen inChecklist 1[22,24]. The review was registered with Open Science Framework and was conducted according to the published protocol [25].

To formulate the research question, we applied a conceptual framework for evaluating patient attitudes toward AI in health care [26]. Following the Joanna Briggs Institute’s recommended 3-step search strategy, we conducted an initial limited search of MEDLINE and Embase to identify keywords and relevant index terms [21-24,27,undefined,undefined,undefined]. These keywords and index terms were used to develop a final search strategy and to conduct a literature search across the identified databases for this review. The MEDLINE, Embase, PsycINFO, and CINAHL databases were searched for English-language primary qualitative and quantitative studies published in peer-reviewed journals from inception until February 1, 2025. The reference lists of literature included in this scoping review were searched for additional relevant studies. The final search strategy, found inMultimedia Appendix 1, was developed with support from subject librarians at the University of British Columbia.

The eligibility criteria were determined using the Population-Concept-Context framework [27].

We included studies with adult patients diagnosed with any type or stage of cancer. Studies with mixed populations (eg, patients with and without cancer) were included if the patients with cancer population was the majority or if the population was composed of those with cancer and those with nonmalignant tumors receiving specialized care. We also included mixed populations of patients with cancer and physicians or caregivers, only if patient attitudes were reported independently. For a study to be included, AI must have been involved, and we defined AI as a computer system modeling intelligent behavior with minimal human intervention [1].

We focused on patient attitudes toward AI in cancer care. Attitudes were broadly defined as any form of input from patients such as thoughts, feelings, emotions, perspectives, attitudes, opinions, sentiments, beliefs, and experiences.

We included English-language primary qualitative and quantitative studies published in peer-reviewed journals until February 1, 2025, and included all geographies and clinical settings. We excluded non-English studies, gray literature, and secondary research.

Patient population with cancer in the included study only. For detailed information on participant size and characteristics, please seeMultimedia Appendix 2.

Sources were identified as either having a patient attitude that prefers AI, a physician, or a combined AI plus physician model.

Predominant attitudes in each paper are indicated by positive (+), negative (−), or undefined (U) to describe patients’ feelings with respect to the given attitude.

The top 4 types of cancer included in the study have been included in this list. For more detailed information, please seeMultimedia Appendix 2.

The 19 included studies, published between 2019 and 2025, represented 2114 patients from 15 countries, with the majority originating from Germany, China, and South Korea [17-19,28-43,undefined,undefined,undefined,undefined,undefined,undefined,undefined,undefined,undefined,undefined,undefined,undefined,undefined,undefined,undefined,undefined,undefined]. The majority of studies were published after 2022. Cancer types most frequently examined included prostate, melanoma, breast, colorectal, and lung cancers and are detailed inMultimedia Appendix 3. Most studies used quantitative methods (9/19, 47%), primarily using questionnaires or surveys, while qualitative studies (5/19, 26%) relied on interviews. The remaining mixed methods studies used a combination of surveys with both quantitative and qualitative answers in addition to interviews. The process of study selection is detailed inFigure 1.

Eight studies identified recurring concerns regarding AI integration [17-19,31,36,38,39,42,undefined,undefined]. Patients frequently questioned the impact of AI on quality of care, with concerns that AI could lead to shorter appointment times, reduced patient-physician communication, and fewer opportunities for questions [17-19,31,36,39,42,undefined,undefined]. Many also feared that AI could weaken the physician-patient relationship, contributing to depersonalized interactions [17-19,36,42,undefined,undefined]. Concerns about AI’s susceptibility to false positives and false negatives were also raised, particularly regarding its lack of accountability in clinical decisions [17-19,36,undefined,undefined]. Some patients also questioned whether AI systems might introduce or reinforce bias, particularly if training data lacked representation from diverse populations [17,38]. Similarly, concerns about the collection and storage of patient data emerged, with patients emphasizing the need for explicit consent before data use and assurances that their information would be deidentified and protected from commercialization [17,18,31,38].

Despite these concerns, 7 studies highlighted optimism regarding AI’s role in their care [17-19,31,36,39,43,undefined,undefined]. Many patients recognized AI’s potential to improve diagnostic accuracy, particularly in identifying subtle patterns that might be overlooked by physicians [17-19,31,36,39,undefined,undefined]. AI was also seen as enhancing early detection and treatment efficiency, potentially reducing the need for invasive procedures and leading to less intensive treatment strategies [17,36]. Additionally, AI was perceived as a tool that could improve the overall efficiency of their care and the health care system by reducing wait times, alleviating health care burdens, and lowering costs [17-19,36,undefined,undefined]. Some patients believed that AI could also help reduce physician bias and ensure more consistent, data-driven treatment recommendations [17,19,31,39].

Trust in AI varied across studies [29-32,37-40,42,43,undefined,undefined,undefined,undefined,undefined,undefined]. Although some studies found high levels of trust, this was primarily dependent on whether AI was integrated with physician oversight [30,32,37-39,undefined,undefined]. Multiple studies found that trust in AI was often rooted in physician endorsement rather than the AI itself, suggesting that patient trust in AI is closely tied to physician guidance [31,39,40]. Education level played a role in AI trust; two studies found that patients with postsecondary education were more likely to participate in AI research [29,37]. Education level was also correlated to previous exposure to and understanding of AI technologies, which was another factor that positively influenced trust in AI [19,29]. Conversely, another study found that older patients and those with lower education levels were more likely to trust AI assessments [30].

Five studies examined patient satisfaction with AI-assisted care [28,33-35,41,undefined,undefined]. Patients reported greater satisfaction when AI improved diagnostic accuracy and increased health care efficiency [34]. A study comparing an AI chatbot to specialists found that patients rated the AI’s responses slightly higher in empathy, comprehensibility, and content quality [33]. One patient who used AI-driven emotional support tools, such as AI chatbots, reported reduced distress and anxiety following their cancer diagnosis [28]. However, another study found that less than half of the participants in their study were satisfied with care received from AI, emphasizing the importance of integrating patients’ experiences into the development of AI technologies [41].

Three studies explored fear as a patient response to AI integration [30,36,39]. Some patients feared that AI could replace human interactions and limit their autonomy in decision-making [36,39]. However, AI-driven diagnoses were better received when physicians confirmed the AI’s findings, underscoring the importance of physician oversight in maintaining patient trust [30].

As recommended by the Joanna Briggs Institute and outlined in our protocol, we reviewed initial findings of this scoping review with research users at a BC Cancer Summit workshop [25,27]. The workshop was attended by over 60 research users including clinicians, decision makers, researchers, and patients. Participants provided informal feedback, which broadly aligned with our findings, with many identifying more with the optimistic aspects of AI in cancer care. This engagement was intended to validate the relevance of our results and inform future research directions.

As AI adoption in cancer care accelerates, understanding patient perspectives is critical for ensuring its effective and ethical implementation. This scoping review provides the first synthesis of patient attitudes toward AI across all cancer types, revealing both areas of support and challenges for its integration in cancer care. Although patients with cancer generally support AI when it is physician-guided, concerns about depersonalization, treatment bias, and data security highlight the need for careful implementation. This review identified unique emotional and psychological concerns for patients with cancer, in contrast to the existing literature, which focused more on general patient and public perspectives of AI, particularly related to its impact on diagnostic accuracy, efficiency, and cost-saving in health care [14].

This review highlights a geographic imbalance in studies examining patient attitudes toward AI in cancer care. Most research has been conducted in Europe (1288/2114 patients, 60.9%) [17,29,30,32,33,36,37,39-43,undefined,undefined,undefined,undefined] and Asia (688/2114, 32.5%) [19,28,34], with North American patient populations notably underrepresented (138/2114, 6.5%) [18,31,35,38]. Studies from Asia have reported more optimistic attitudes toward AI, with some patients expressing trust in AI-assisted care without concerns [19,34]. In contrast, studies from North America and Europe revealed more skepticism, with patients citing concerns related to overreliance on AI [17,31,42], treatment bias [31,36], and data security [17,38]. These findings align with prior literature suggesting that trust and AI adoption are generally higher in Asia compared to Europe and North America [43,47,48]. These differences may reflect broader cultural and health care system factors. Greater acceptance in some Asian countries may be linked to higher trust in technology and centralized health care systems [47]. In contrast, skepticism in North America and Europe may reflect stronger emphasis on individual autonomy and privacy [48]. These contextual differences underscore the need for culturally sensitive AI implementation strategies aligned with local values and expectations of care. Future research should aim to incorporate more geographically diverse populations to ensure that AI implementation strategies reflect the values, concerns, and trust levels of patients across different health care settings.

The influence of educational background on patient attitudes toward AI in cancer care was underrepresented within the studies included in our review. Although several studies explored the role of age and education on attitudes toward AI, a bias toward highly educated populations in these studies limited the generalizability of the findings [17-19,29-31,37,38,undefined,undefined,undefined,undefined]. AI technologies have been shown to produce biased and inequitable outcomes across different patient backgrounds, and this underrepresentation in our review highlights a notable gap in research [49,50]. It is essential that future research and AI implementation in cancer care incorporates the perspectives of diverse educational and socioeconomic groups to ensure that AI-driven care benefits all patients equitably.

Young adult patients with cancer were underrepresented in the studies included in this review. It is critical to understand the attitudes of this population as these patients have differences in disease biology, distribution, and survivorship compared to older patients with cancer [51]. Greater exposure to AI technology among younger patients may foster increased trust in its applications [19,37], but some evidence suggests that a deeper understanding of AI’s complexity may also contribute to skepticism towards its diagnostic accuracy [30,52]. Conversely, data suggesting that older patients were more likely to trust AI diagnoses raise concerns that misconceptions of AI technologies may result in misplaced trust and lead to uninformed or misguided decision-making around AI involvement in their cancer care [30]. These generational differences in AI familiarity and usage will shape future patient attitudes as AI becomes more integrated into clinical practice. Further research is needed to ensure that perspectives of both younger and older populations are adequately represented in studies on AI implementation in cancer care [51].

The successful integration of AI into cancer care depends on aligning these technologies with patient expectations and addressing concerns about trust, concerns about depersonalization, and ethical considerations. For AI researchers and developers, patients consistently expressed a preference for AI as a decision-support tool rather than an autonomous decision maker [17-19,30,31,36,40,undefined,undefined]. AI researchers and developers should prioritize human-AI collaboration models, ensuring that AI augments, rather than replaces, physician expertise. To build and maintain patient trust, AI developers must address concerns about algorithmic bias by seeking training data that reflects diverse populations and ensuring that systems are evaluated for equitable performance [53]. Additionally, to improve the trust and usability of AI tools, researchers and developers should co-develop these tools alongside patients with cancer. In addition, given the limited research on AI attitudes across different cancer stages, particularly metastatic cancer, future AI developments should consider how disease progression and prognosis influence treatment decisions. Developers must also recognize that AI acceptance varies globally, highlighting the need for regionally tailored AI implementation strategies that reflect diverse patient perspectives. Future AI development should incorporate the perspectives of young adult patients and individuals with diverse educational and socioeconomic backgrounds to promote more inclusive and patient-centered implementation.

For clinicians, clear communication and transparency about AI’s role in care are essential for building patient trust [54]. Clinicians should proactively discuss how AI is being used, emphasizing that it supports rather than replaces their expertise. Preserving a strong physician-patient relationship is essential, as patients remain concerned that AI could depersonalize their care [17-19,36,42,undefined,undefined]. Given that patient trust in AI is often linked to physician endorsement, clinicians can facilitate patient acceptance by integrating AI in a way that strengthens the human connection in care. Clinicians also play a role in the ethical implementation of AI by selecting tools that align with patient values and addressing concerns identified in this review, including depersonalization, bias, and data security. Lastly, clinicians can provide feedback to AI developers, ensuring that AI models are refined to better align with patient priorities and improve trust in AI-assisted care.

This scoping review makes several novel contributions to the existing literature by being the first to comprehensively examine the attitudes of patients with cancer toward AI across all cancer types and treatment settings. Although previous research has focused on AI acceptance in narrow contexts such as melanoma and breast cancer screening, this review provides a broader, more comprehensive synthesis of patient perspectives [14,17,18]. Another strength of this review is its robust methodology, adhering to PRISMA-ScR guidelines, systematically identifying knowledge gaps, and synthesizing findings across diverse populations [25]. Additionally, this review provides a patient-centered focus, offering insights that can inform AI development and guide clinical implementation.

Several limitations should be considered. As a scoping review, this study did not assess the quality of included articles, which is standard practice given that scoping reviews aim to map existing literature rather than evaluate methodological rigor. We observed considerable variability in study quality, especially in sample size, methodological rigor, and reporting of participant demographics and cancer staging. Recognizing this heterogeneity is important, as it influences the strength and applicability of the findings of this review. Future research should prioritize transparent reporting and the use of standardized tools to improve consistency and enable more meaningful cross-study comparisons. In addition, the relatively small number of studies (n=19) included in the review may restrict the generalizability of our findings. This low number of studies is expected given the emerging nature of AI in cancer care. Although this highlights a gap in the current literature, it also suggests that there is the opportunity for further research to build on the findings presented in this review. Other limitations include the exclusion of non-English studies, secondary research, and gray literature. Although secondary research could have offered relevant insights, we excluded it to avoid duplication and ensure that the review focused solely on primary literature. Although this review aimed to capture global perspectives, we limited inclusion to English-language, peer-reviewed primary studies due to resource constraints for translation and the challenges of systematically identifying and appraising gray literature. We recognize that this may introduce language and publication bias, potentially underrepresenting patient perspectives from non–English-speaking regions or low- and middle-income countries. However, our review still included studies from several non–English-speaking countries, such as China and South Korea, indicating some geographic diversity despite the language restriction. Future reviews should consider collaborative efforts with multilingual teams and the use of gray literature databases to ensure broader inclusion and enhance the global relevance of findings. As the literature in this area expands, future work may also benefit from applying a theoretical framework to better interpret emerging patterns in patient attitudes. Despite these limitations, the insights provided by this review offer a foundation for future research and will help guide the patient-centered implementation of AI into cancer care.

This scoping review is the first to synthesize patient attitudes toward AI across all cancer types. We identified 19 studies representing diverse geographies, cancer types, and AI applications. Patients generally supported the use of AI in their care when it complemented physician decision-making, but expressed concerns about depersonalization, treatment bias, and data security. The attitudes of patients varied across regions, cancer types, and stages of illness. Clinicians can use these findings to integrate AI in cancer care in ways that align with patient priorities, maintain human connection, and enhance trust, while researchers should address gaps in understanding AI perceptions among patients with advanced cancer and young adult patients.

The authors are grateful to the University of British Columbia librarian, Jane Jun, for her contributions to the search strategy. The authors acknowledged the use of ChatGPT (GPT-4o, OpenAI) for language copyediting to enhance the fluency of the manuscript on February 1, 2025. All ideas, concepts, and original content were independently developed by the authors, and ChatGPT had no role in shaping the intellectual content. The authors take full responsibility for the accuracy and integrity of the manuscript. The authors received no specific funding for this work.