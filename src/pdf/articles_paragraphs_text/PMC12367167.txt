Lymphoma is a severe condition with high mortality rates, often requiring ICU admission. Traditional risk stratification tools like SOFA and APACHE scores struggle to capture complex clinical interactions. Machine learning (ML) models offer a more accurate alternative for predicting outcomes by analyzing large datasets. However, their application in predicting in-hospital mortality for lymphoma patients remains limited.

This study aims to develop and validate machine learning models to predict in-hospital mortality in ICU patients with lymphoma using data from the Medical Information Mart for Intensive Care IV (MIMIC-IV) database, thereby enhancing risk stratification and clinical decision-making.

We conducted a retrospective cohort study using data from the MIMIC-IV database, which includes detailed clinical data from adult patients admitted to the ICU. Patients with a primary diagnosis of lymphoma were included. Baseline characteristics, laboratory parameters, and clinical outcomes were extracted. Lasso regression was employed to screen for significant risk factors associated with in-hospital mortality. Fifteen machine learning models, including logistic regression, random forest, gradient boosting, and neural networks, were developed and compared using receiver operating characteristic (ROC) curves and area under the curve (AUC) analysis. Model performance was evaluated through cross-validation and SHapley Additive exPlanation (SHAP) values to interpret variable importance.

A total of 1591 patients were included, with 342 (21.5%) in-hospital deaths. Lasso regression identified significant predictors of mortality, including blood urea nitrogen (BUN), platelets, PT, heart rate, systolic blood pressure, APTT, spo2, and bicarbonate. The CatBoost Classifier demonstrated the highest predictive performance with an AUC of 0.7766. SHAP analysis highlighted the critical role of BUN as the most important factor in mortality prediction, followed by platelets and PT. The SHAP force plot provided individualized risk assessments for patients, demonstrating the model’s ability to identify high-risk subgroups.

Machine learning models, particularly the CatBoost Classifier, effectively predict in-hospital mortality in ICU patients with lymphoma. These models outperform traditional statistical methods and provide valuable insights into risk stratification. Future work should focus on external validation and clinical implementation to improve patient outcomes in this high-risk population.

Lymphoma is a severe condition that often requires admission to the intensive care unit (ICU) due to its associated high mortality rate and complex clinical presentation [1]. The pathophysiology of lymphoma involves a combination of immune dysregulation, metabolic disturbances, and potential complications such as infections and organ failure [2–5]. Early identification of patients at high risk of in-hospital mortality is crucial for optimizing treatment strategies and improving outcomes. Traditional risk stratification tools, such as the Sequential Organ Failure Assessment (SOFA) score and the Acute Physiology and Chronic Health Evaluation (APACHE) score, have limitations in capturing the complex interactions among multiple clinical variables [6–8]. Machine learning (ML) models offer a promising alternative by leveraging large datasets to identify patterns and predict outcomes more accurately [9]. ML has been increasingly applied in various medical fields, including disease diagnosis, treatment optimization, and prognosis prediction [10,11]. However, its application in predicting in-hospital mortality for patients with lymphoma remains limited. This study aims to develop and validate ML models to predict in-hospital mortality in ICU patients with lymphoma using data from the Medical Information Mart for Intensive Care IV (MIMIC-IV) database, thereby enhancing risk stratification and clinical decision-making.

Compared to the general ICU population, lymphoma patients present distinct mortality determinants that traditional risk scores (e.g., SOFA, APACHE) fail to capture. Rapid tumor lysis syndrome (TLS) precipitates acute kidney injury and electrolyte derangements [12], while profound chemotherapy-induced immunosuppression predisposes to opportunistic infections such as Pneumocystis jirovecii pneumonia and invasive aspergillosis [13]. Direct organ infiltration by lymphoma (e.g., renal or hepatic parenchyma) and cardiotoxicity from anthracycline-based regimens further complicate clinical trajectories [14]. These lymphoma-specific pathophysiological features create complex, non-linear interactions among variables, rendering generic ML models inadequate. Yet, ML tailored specifically to lymphoma ICU patients remains unexplored, highlighting a critical gap this study aims to address.

This study is a retrospective cohort study using data from the MIMIC-IV database, a publicly available, de-identified electronic health records database that contains comprehensive clinical data from adult patients admitted to the ICU at Beth Israel Deaconess Medical Center in Boston, USA [15]. Author Guang Tu finished the CITI Data or Specimens Only Research course, obtained approval for database access, and assumed responsibility for data extraction (certification number 65828445). The study included adult ICU patients with a primary diagnosis of lymphoma. The diagnosis was based on the International Classification of Diseases, 10th Revision (ICD-10) codes. Exclusion criteria included missing key predictor or outcome variables” instead of the overly broad phrase, hospital stay less than 24 hours, and age under 18 years. The included patient data covered hospitalizations from 2008 to 2019 (Fig 1). The study utilized fully de-identified data from the publicly available MIMIC-IV database. Because the dataset lacks direct patient identifiers, the institutional review boards of the authors’ institutions determined that this research is exempt from IRB review and informed consent (Helsinki Declaration, 1964 and its later amendments).

Baseline characteristics, laboratory parameters and clinical outcomes were extracted from MIMIC-IV. Prior to any modelling, the proportion of missing values for each variable was quantified (S1 Table). Across the 1 591 included patients, missingness ranged from 0% (gender, age, comorbidities, hospital-mortality flag) to 11.1% (APTT). Laboratory variables with the highest missing proportions were INR (9.9%), PT (9.9%), calcium (4.3%) and temperature (2.2%). The missing-data pattern was examined using Little’s MCAR test (χ² = 2 184.7, df = 1 959,p= 0.002), suggesting data were not missing completely at random. To minimise bias, we performed multivariate imputation by chained equations (MICE) with predictive mean matching for continuous variables and logistic/ polytomous regression for categorical variables, generating 20 imputed datasets (m = 20) under the missing-at-random (MAR) assumption. Each machine-learning model was then fitted independently on every imputed dataset; Rubin’s rules were applied to pool performance metrics (AUC, accuracy, F1-score). Sensitivity analyses restricted to complete cases yielded similar AUCs (< 2% difference), indicating that the imputation procedure did not materially distort model discrimination.

In this study, in-hospital mortality is defined as death occurring at any time between ICU admission and hospital discharge, consistent with the standard definition adopted by the MIMIC-IV database and prior ICU outcome studies [15–17]. This endpoint was selected to capture the full spectrum of acute and subacute mortality risk during the hospital stay, aligning with clinical decision-making contexts where ICU prognostication directly influences treatment intensity and goals-of-care discussions.

To identify risk factors significantly associated with in-hospital mortality, we used Lasso regression for variable selection. Lasso regression is a regularized linear regression method that introduces an L1 penalty term to automatically select variables with significant effects on the dependent variable. We determined the regularization parameter (λ) for Lasso regression through cross-validation and visualized the variable selection process using coefficient path and cross-validation plots. Ultimately, Lasso regression identified key risk factors including blood urea nitrogen, platelets, PT, heart rate, systolic blood pressure, APTT, spo2, and bicarbonate.

Based on the key risk factors selected by Lasso regression, we developed 15 machine learning models, including logistic regression, random forest, gradient boosting, neural networks, and CatBoost Classifier. To ensure an unbiased estimate of model performance, the entire dataset was first subjected to a single stratified split into a 70% training set and a 30% hold-out test set based on the in-hospital mortality label. LASSO-based feature selection, and Bayesian hyper-parameter tuning (100 trials maximizing 5-fold cross-validated AUC) were performed exclusively within the training set using nested 5-fold cross-validation to prevent information leakage. The final CatBoost classifier, incorporating the selected features and optimized hyper-parameters, was then retrained on the full 70% training set and evaluated only once on the untouched 30% test set.

To address the 21.5% positive-class imbalance, we combined class weighting and resampling: models supporting class weights (CatBoost, Logistic, Ridge, SVM, LightGBM, XGBoost, Gradient Boosting) received minority-class weight w = N_majority/ N_minority ≈ 3.65 in their loss functions; the remaining models (Random Forest, Extra Trees, AdaBoost, MLP, Naive Bayes, KNN, Decision Tree) were trained after RandomOverSampler expanded the minority class to match the majority within each cross-validation fold, preventing data leakage, while all reported metrics (AUC, accuracy, F1-score) were computed on the untouched, imbalanced test set.

To enhance the clinical interpretability of the models, we used SHAP values for model interpretation. SHAP values, based on game theory, quantify the contribution of each variable to model predictions and reveal complex interactions among variables. Through SHAP value analysis, we not only validated the key variables identified by Lasso regression but also further evaluated their specific impacts on individual predictions. Moreover, SHAP waterfall plots decomposed the prediction results for individual patients, clearly showing the positive or negative contributions of each variable to the prediction outcomes, thereby providing a tool for clinicians to conduct individualized risk assessments.

All statistical analyses were performed using R Statistical Software (Version 4.2.2) and the Free Statistics Analysis Platform (Version 2.1) [15]. AP-value less than 0.05 was considered statistically significant. Data processing and model training were completed on a local server to ensure data security and privacy.

A total of 1591 patients with lymphoma admitted to the ICU were included in this study, with 342 (21.5%) in-hospital deaths. The baseline characteristics of the patients are detailed inTable 1. Significant differences were observed between the survivor and non-survivor groups across multiple variables. The mean age of non-survivors (70.1 years) was slightly higher than that of survivors (69.1 years,P= 0.220), though not significantly. Non-survivors exhibited significantly higher heart rate, lower systolic and diastolic blood pressure, lower SpO2, lower hematocrit and hemoglobin levels, lower platelet counts, higher anion gap, lower bicarbonate levels, higher BUN, lower calcium levels, higher INR, longer PT, and longer APTT compared to survivors. The frequency and percentage of missing values for all variables are reported inS1 Table.

Lasso regression was used to identify significant risk factors associated with in-hospital mortality. The screening process is illustrated inFig 2, with the coefficient path plot (Panel A) and cross-validation plot (Panel B). The identified risk factors included blood urea nitrogen, platelets, PT, heart rate, systolic blood pressure, APTT, spo2, and bicarbonate. These factors were subsequently used as key input variables for the development of machine learning models.

A: Coefficient path plot of Lasso regression; B: Cross-validation plot of Lasso regression.

The performance of 15 machine learning models in predicting in-hospital mortality is summarized inTable 2. The CatBoost Classifier achieved the highest area under the receiver operating characteristic curve (AUC) of 0.7766, with an accuracy of 79.24% and an F1 score of 0.344. The Random Forest Classifier (AUC, 0.7691) and Extra Trees Classifier (AUC, 0.7667) also demonstrated strong performance. The ROC curves for all models are shown inFig 3, intuitively reflecting their discriminatory power. The CatBoost Classifier exhibited superior performance in distinguishing between high-risk and low-risk patients.

To evaluate potential multicollinearity among the eight variables retained by LASSO, we computed a Pearson correlation matrix (S1 Fig). The strongest absolute correlations were 0.60 between BUN and creatinine and 0.40 between platelet count and PT; all remaining pairwise correlations were below 0.30. These low-to-moderate values indicate that multicollinearity is not a concern after LASSO regularisation, supporting the stability of the final model.

The importance weights of each variable in the models are displayed inFig 4. Variables such as blood urea nitrogen, platelets, and PT were assigned higher weights, indicating their critical roles in predicting mortality. SHAP value analysis, shown inFig 5, quantified the contribution of each variable to model predictions, validating the importance of key variables identified by Lasso regression. The SHAP waterfall plot (Fig 6) decomposed the prediction results for individual patients, clearly showing the positive or negative contributions of each variable to the prediction outcomes.

Our study successfully developed and validated machine learning (ML) models to predict in-hospital mortality among ICU patients with lymphoma. This achievement provides significant support for optimizing treatment strategies and improving patient outcomes. Traditional risk stratification tools are limited in their ability to handle the complex interactions among multiple clinical variables, whereas ML models, with their powerful data processing and pattern recognition capabilities, can provide more accurate predictions [9]. In this study, the CatBoost Classifier showed moderate discrimination, with an AUC of 0.7766, with potential incremental value over traditional scores and offering a new tool for clinical decision-making.

Compared with general medical or even oncologic ICU cohorts, lymphoma mellitus patients exhibit distinctive biological and therapeutic determinants of mortality risk. First, rapid tumour-lysis syndrome and hyper-metabolic states can precipitate acute kidney injury, directly elevating BUN independent of hypovolaemia or sepsis [16]. Second, marrow infiltration or ongoing cytotoxic chemotherapy frequently induces severe thrombocytopenia that is both more sudden and profound than in other malignancies [17]. Third, anthracycline-based regimens and immune checkpoint inhibitors increase the incidence of chemotherapy-associated cardiomyopathy, arrhythmias, and capillary leak, leading to haemodynamic instability (lower systolic blood pressure, higher heart rate) and coagulopathy (prolonged PT/APTT) [18,19]. Finally, opportunistic infections common in lymphoma (e.g., Pneumocystis jirovecii, invasive moulds) generate hypoxaemia (lower SpO₂) and lactic acidosis (lower bicarbonate) that may be disproportionate to the apparent severity of organ failure [20,21]. These lymphoma-specific factors collectively confound traditional scores such as APACHE or SOFA, which were calibrated on mixed ICU populations without accounting for tumour burden or chemotherapy-related toxicities.

Previous research has primarily focused on the application of machine learning in disease diagnosis and treatment optimization, with limited exploration into predicting in-hospital mortality for specific conditions like lymphoma in the ICU [22–25]. Our study fills this gap. Unlike previous studies that relied on a single model, we compared 15 different ML models and identified the CatBoost Classifier as the best performer. Moreover, through SHAP value analysis, we not only validated the key variables identified by Lasso regression but also revealed their specific impacts on individual predictions, providing clinicians with a more intuitive risk assessment tool. SHAP waterfall plots translate these individual explanations into immediate bedside actions: elevated BUN or severe thrombocytopenia prompts urgent nephrology consultation for renal-replacement therapy ± rasburicase and haematology review for platelet transfusion or chemotherapy dose adjustment; a large positive SHAP contribution from low SpO₂ triggers intensified respiratory monitoring and early bronchoscopy with targeted anti-Pneumocystis or antifungal therapy; when cumulative SHAP values exceed a predefined threshold (e.g., > 0.6), the ICU team can initiate goals-of-care discussions—turning the waterfall plot into a real-time, pathophysiology-based action checklist. In this study, several variables significantly associated with in-hospital mortality were identified through Lasso regression and SHAP value analysis, including blood urea nitrogen, platelets, PT, heart rate, systolic blood pressure, APTT, SpO₂, and bicarbonate. These variables are not only statistically significant but also potentially related to the pathophysiological mechanisms of lymphoma. Elevated blood urea nitrogen levels may indicate renal dysfunction, In the lymphoma context, BUN elevation is often multifactorial: tumour-lysis–induced urate nephropathy [26], cisplatin or ifosfamide nephrotoxicity [27], and sepsis-related acute tubular necrosis all contribute [28]. Similarly, thrombocytopenia reflects not only bone marrow suppression but also immune-mediated platelet destruction (e.g., Evans syndrome) and chemotherapy-induced myelosuppression [29,30]. Prolonged PT and APTT mirror both disseminated intravascular coagulation triggered by tumour tissue factor expression and drug-induced coagulopathy (l-asparaginase, anthracyclines) [31]. These mechanistic links underscore why the CatBoost model, trained on lymphoma-specific data, outperforms generic scores that weight these variables identically across all ICU patients. A common complication in lymphoma patients that can be related to tumor burden, chemotherapy-induced nephrotoxicity, or infection [21,32,33]. Thrombocytopenia may suggest bone marrow suppression or disseminated intravascular coagulation (DIC), both of which are common in lymphoma patients and associated with disease severity and poor prognosis [34,35]. Additionally, changes in heart rate and blood pressure may reflect circulatory instability, while decreased SpO₂ may indicate respiratory failure, both of which are critical conditions frequently encountered in ICU patients [36–38]. By leveraging ML models, we can link these clinical variables to biological mechanisms, further elucidating the underlying causes of mortality risk in lymphoma patients admitted to the ICU. Future external validation using multicenter cohorts (e.g., eICU or regional ICU networks) is warranted to confirm the generalizability of our findings beyond the MIMIC-IV setting. Subsequent studies should incorporate longitudinal tumour-burden markers (LDH, PET-CT metabolic tumour volume) and detailed chemotherapy histories to refine lymphoma-specific mortality prediction beyond the current model.

Our study has several strengths. First, the data were sourced from the MIMIC-IV database, which contains a wealth of detailed clinical information, providing a solid foundation for model development and validation. Second, we employed multiple ML models and comprehensively evaluated their performance through cross-validation and SHAP value analysis, ensuring the reliability and interpretability of the results. Finally, our study not only focused on overall model performance but also assessed individual patient risks through SHAP force plots, offering more specific guidance for clinical applications.

Despite the positive outcomes, our study has some limitations. First, MIMIC-IV is a single-center database derived from Beth Israel Deaconess Medical Center (Boston, USA), which may introduce selection bias and limit generalizability to other ICUs with different patient demographics, clinical practices, or resource availability. Future research should conduct external validation on multiple independent datasets to confirm the generalizability of the models. Second, although ML models can identify key risk factors, their predictive mechanisms remain complex and difficult to fully explain using traditional medical theories. Additionally, our study did not consider the impact of treatments and interventions during the ICU stay on patient outcomes, which may limit the precision of the model’s predictions. Because MIMIC-IV lacks lymphoma-specific variables such as histological subtype, Ann Arbor stage, recent chemotherapy exposure, tumour-lysis syndrome, or neutrophil nadir, these high-risk features could not be included in the analysis; future multicenter studies with dedicated oncology-ICU databases are needed to capture these predictors. Given the absence of granular treatment data (e.g., specific chemotherapy agents, immunotherapies, or evolving ICU bundles) in MIMIC-IV, we could not control for temporal changes in lymphoma management or critical-care practices. Future multicenter studies that incorporate longitudinal drug and intervention data are warranted to address this limitation. Additionally, because MIMIC-IV lacks detailed, time-stamped data on ICU interventions (mechanical ventilation, vasopressors, dialysis, or lymphoma-specific treatments administered after admission), our models are restricted to admission/early-ICU variables and cannot perform dynamic risk reassessment. Future linkage with high-resolution treatment logs is required to develop longitudinal prediction frameworks.

In summary, the ML models, particularly the CatBoost Classifier, may assist in risk estimation in-hospital mortality among ICU patients with lymphoma. These models not only offer additional insights alongside traditional approaches but also provide interpretable risk assessments through SHAP value analysis. Future research should focus on external validation and clinical implementation to improve outcomes for this high-risk patient population.