Wheat is significantly impacted by fungal diseases, which result in severe economic losses. These diseases result from pathogenic spores invading wheat. Rapid and accurate detection of these spores is essential for post-harvest contamination risk assessment and early warning. Traditional detection methods are time-consuming and labor-intensive, and difficult to detect small target spores in complex environments. Therefore, a YOLO-ASF-MobileViT detection algorithm is proposed to detect pathogenic wheat spores with varying sizes, shapes, and textures. Four types of common pathogenic wheat spores are used as the study object, includingFusarium graminearum,Aspergillus flavus,Tilletia foetida(sporidium maturum), andTilletia foetida(sporidium immaturum). The Attentional Scale Sequence Fusion (ASF) is integrated into the original YOLOv5s to enhance the capture of small details in spore images and fuse multi-scale feature information of spores. Additionally, the Mobile Vision Transformer (MobileViT) attention mechanism is incorporated to enhance both local and global feature extraction for small spores. Experimental results show that the proposed YOLO-ASF-MobileViT model achieves an overall mAP@0.5 of 97.0%, outperforming advanced detectors such as TPH-YOLO (95.6%) and MG-YOLO (95.5%). Compared to the baseline YOLOv5s model, it improves the average detection accuracy by 1.6%, with a notable 4.3% increase in detecting small Aspergillus flavus spores (reaching 90.8%). The model maintains high robustness in challenging scenarios such as spore adhesion, occlusion, blur, and noise. This approach enables efficient and accurate detection of wheat fungal spores, supporting early contamination warning in post-harvest management.

Wheat is an important food crop that provides an abundance of carbohydrates, essential amino acids, and minerals, making it a crucial source of energy and nutrients for humans [1,2]. Wheat is widely grown worldwide, and its healthy growth is crucial for food security [3]. The growth process of wheat is susceptible to a variety of fungal stresses that can lead to disease [4]. The three diseases explored in this paper—Fusarium head blight (FHB), common bunt, andAspergillus flavus(A. flavus) infection—not only significantly reduce the yield and quality of wheat but also pose severe health risks and have widespread, lasting impacts due to spore transmission. FHB is caused byFusarium graminearum(F. graminearum). FHB manifests as pink-orange sporodochia on infected spikelets and may cause shriveled kernels and weight loss [5]. Historical data from 1919 to the mid-1990s revealed yield losses of 15–29% in India, 30–40% in the Yangtze River Basin of China, and even 70% in parts of Romania [6,7]. Wheat infected with FHB also produces mycotoxins, especially deoxynivalenol (DON), which seriously threaten the health of animals and humans [8]. Common wheat bunt is caused byTilletia foetida(T. foetida). It is characterized by bunt balls—infected kernels filled with dark brown to black teliospores that emit a fetid odour at harvest [9,10]. Common bunt in wheat also affects the weight, germination effect and vigour of seeds [11]. In addition, wheat is infected withA. flavus, which is characterized by the appearance of yellow mould on the surfaces of wheat kernels.A. flavusproduces aflatoxins B1 and B2 (AFB1 and AFB2, respectively), which form a stable class of carcinogenic mycotoxins that pose a deadly threat to human health [12]. Fungal spores are a major source of inoculum in wheat fungal diseases. Other transmission pathways include infected seeds, crop residues, and rain-splash dispersal [13,14]. This study focuses on the post-harvest stage, where rapid spore detection supports early warning and contamination risk assessment during storage and procurement.

Manual visual rating of wheat ears and grains is labour‑intensive, low‑throughput, and prone to subjective bias, with inter‑rater inconsistencies and frequent underestimation or overestimation of disease severity [15]. This method is inefficient [16,17]. To solve this problem, in recent years, methods that use image processing and deep learning to detect the severity of diseases in wheat have gradually attracted attention [18]. A spore, as a propagule in the life cycle of a fungus, can provide reliable early warning of potential contamination during post-harvest handling [19]. Traditional methods such as PCR and ELISA offer high specificity and sensitivity [20,21]. However, their reliance on multi-step preparation, specialised equipment, and trained personnel, along with turnaround times of several hours, limits their use for rapid, large-scale screening in post-harvest settings [22]. In contrast, image-based spore detection offers a faster and more accessible alternative for on-site early warning [17].

Deep learning algorithms have been widely used to classify spore microscopy images. Qamar et al. conducted a classification study on bacterial spore images acquired via transmission electron microscopy (TEM) [23]. They used a convolutional neural network (CNN) for feature extraction and combined it with a random forest (RF) for classification purposes. Ultimately, they achieved 73% accuracy. They proposed an innovative idea combining deep learning-based feature extraction and machine learning-based classification for spores. Crespo-Michel et al. presented novel deep learning algorithms for classifying four species of grapevine wood fungi [24]. They used four different neural network architectures, including ResNet-50, VGG-16, MobileNet, and InceptionV3, to classify spore microscopy images with accuracies of up to 97.4%. The above methods have made some progress in terms of spore image classification. However, depending only on deep learning is insufficient for large-scale spore detection and counting tasks [25]. In contrast, a target detection approach based on deep learning has the potential to achieve multi-target classification and counting. This method enables the completion large-scale, diverse spore detection tasks [17].

In recent years, target detection algorithms have made significant progress in fungal spore microscopy image detection, but most of them have focused on detecting a single type of pathogenic spore. For example, Zhang et al. proposed an improved You Only Look Once version 5 (YOLOv5) model for detectingF. graminearumspores [26]. They incorporated efficient channel attention (ECA) and adaptive spatial feature fusion (ASFF) mechanisms into their model to effectively address the small sizes and limited features of spores. The method achieved remarkable results in terms of detectingF. graminearumspores, with an average accuracy of 98.57%. Li et al. proposed a high-precision, lightweight detection method based on YOLOv5 for detecting downy mildew spores in complex backgrounds [27]. They introduced a normalization-based attention module (NAM) and receptive field blocks (RFB-s) with dilated convolution to improve the detection accuracy attained for small target spores, and their approach ultimately achieved a mean average precision (mAP) of 95.6%. Wei et al. introduced the Faster region-based CNN (R-CNN), which used ResNet-50 and two small-scale region proposal networks (RPNs) to extract features for detecting microscopic hyperspectral images of thick-wall spores, yielding an average accuracy of 94.68% [28]. The authors also used the model to detect small spores in complex backgrounds. The above studies show that the existing methods have achieved significant improvements in terms of detecting a single type of pathogenic spore, especially small spores, in complex contexts. Wheat is often exposed to various fungal propagules, including airborne spores of different shapes and sizes, which are the main targets of image-based detection in post-harvest scenarios [29]. Larger spores are relatively easy to detect, whereas smaller spores are easily overlooked. Therefore, we need to introduce a method for detecting multiple spores in complex environments and improve the accuracy of small spore detection, thereby providing technical support for providing early warnings concerning multiple fungal diseases in wheat.

We propose a neck with the introduction of the Attentional Scale Sequence Fusion (ASF). The ASF significantly enhance the capture of tiny details in spore images and fuse multi-scale feature information of spores.

The Mobile Vision Transformer (MobileViT) attention is inserted before the P3 detection head to capture both local and global features of small spores. The method reduces missed small fungal spore detection.

A novel detection method called YOLO-ASF-MobileViT is proposed for detecting small diverse pathogenic wheat spores; extensive experiments show that YOLO-ASF-MobileViT maintains high robustness even when faced with spore adhesion, overlap, blurred contours, and impurity interference.

The method proposed in this paper not only provides a novel technique for detecting diverse pathogenic wheat spores but also effectively detects small spores, which provides a new idea for the early detection of fungal wheat diseases.

Wheat is susceptible to fungal contamination throughout the crop cycle, including sowing, vegetative and reproductive growth stages, as well as harvest, transportation, and storage [32,33]. To simulate the actual detection process, we collected microscopy images specifically of teliospores fromT. foetida, macroconidia fromF. graminearum, and conidia fromA. flavus.For T. foetida, sori were dissected from diseased wheat samples, soaked in sterile distilled water, and shaken overnight. The suspension was filtered through double-layer gauze, washed twice with 0.25% sodium hypochlorite, and rinsed repeatedly with 0.01% sterile water.F. graminearumandA. flavuswere cultured on potato dextrose agar (PDA) at 25–28 °C for 7–10 days. Spore suspensions were obtained by washing sporulated cultures with 0.01% sterile water and filtering through gauze. Spore concentration was determined using a hemocytometer and calculated following standard protocols. The final concentration of each spore type was adjusted to 1 × 10⁶ spores/mL, and equal volumes of the three spore suspensions were mixed to prepare the dataset. The mixed spore solution was obtained as shown in Fig.1(a). Subsequently, to acquire image data, spore suspensions were prepared in this study. The fungal samples used in this study were obtained from the Key Laboratory of Biotoxin Analysis & Assessment for State Market Regulation. An inverted microscopy system was used to capture microscopy images of the fungal spores. As shown in Fig.1(b), the system consisted of a CKX53 inverted fluorescence microscope (OLYMPUS, Japan), an EP50 microscopic digital camera (OLYMPUS, Japan), and a host computer. All microscopic images were captured at a fixed 40× magnification using an inverted microscope. The average sizes of the spores captured under 40× are: teliosporesofT. foetida, 16–25 μm [34]; macroconidia ofF. graminearum, 25–50 μm × 3–5 μm [35]; and conidia ofA. flavus, 3–6 μm [36].

To satisfy the model training requirements, we used Labelme software to label each image for distinguishing diverse spores. We manually classified the spores contained in the images into four categories:T. foetida(sporidium immaturum) spores were labelled “UNGXHF”;T. foetida(sporidia maturum) spores were labelled “GXHF”;F. graminearumspores were labelled “HGLD”; andA. flavusspores were labelled “HQM”. In this study, a total of 1015 microscopic images were acquired at 40× magnification using an inverted microscope, with each image having a resolution of 5540 × 3648 pixels. Although the visual distribution may vary in individual microscopy images due to differences in spore morphology and settling, all spore types were mixed in equal concentrations (1 × 106spores/mL) and homogenized before sample preparation.

During the image acquisition process, improper slide preparation or imaging may have resulted in the presence of foreign objects within the slides, severe spore adhesion, image defocusing or ghosting. Ultimately, we screened 959 microscopy images of fungal wheat spores. Given the relatively small number of obtained spore images, data augmentation was used in this study to expand the dataset. We used several data augmentation methods: flipping (horizontal and vertical), luminance transformation, and contrast transformation [37]. Through these methods, we expanded the dataset to 2330 images, which increased the complexity and diversity of the data samples. These methods also effectively prevented model overfitting and improved the generalization performance of the model.

The enhanced wheat spore images were divided into training, validation and test sets at a 6:2:2 ratio. The dataset comprised 1,398 training images, 466 validation images, and 466 test images. This division scheme ensured that sufficient images were available for efficiently constructing the model. The validation set was used to adjust the hyperparameters of the model and improve its generalizability, whereas the test set was used to evaluate the robustness and accuracy of the model.

In this study, we proposed a novel YOLO model to more efficiently and accurately detect pathogenic fungal wheat spores, especially small spores such asA. flavus. The ASF was adopted to replace the original FPN in YOLOv5s. This modification allowed the model to capture local detail features. It also focused on global features, which improved the detection accuracy achieved for spores, especially small spores. The MobileViT attention mechanism was added in front of the P3 detection head. The P3 detection head could receive feature information from the TFE module and the SSFF module in the shallow layer. Therefore, this part contained local detail features. The MobileViT attention mechanism was added before the detection head of the shallow layer to finally optimize the features. The improved YOLO-ASF-MobileViT is shown in Fig.2. By combining these two methods, the detection accuracy attained forA. flavusspores was significantly improved. The pathogenic wheat spore detection performance also improved overall.

In this study, an ASF mechanism was introduced to fuse multiscale spatial features [38]. This mechanism captured spore features of different sizes. The feature fusion mechanism comprised two key modules: a TFE module was designed to capture the features of dense, small spores, and the SSFF module was utilized to integrate multiscale semantic information. This approach effectively improved the feature extraction performance achieved for spore images. It provided more comprehensive and accurate feature information for the subsequent detection step. To verify the effectiveness of the introduced ASF mechanism, we compared the performance of the original YOLOv5s model to that of YOLO-ASF on the same test set.

The traditional feature pyramid network (FPN) only up-sampled small-sized feature maps and then added them to the previous layer, thus ignoring the detailed information of large-sized feature maps. Therefore, the TFE module was introduced to capture both the detailed and overall features of spore images for accurately localizing and regressing the target bounding boxes. The TFE module extracted the P3, P4, and P5 feature maps from the backbone of YOLOv5s. Among these maps, the P3 feature map had the largest scale and smallest receptive field. It primarily captured the local detailed features of small spore images. The P4 feature map had a moderate scale and a medium-sized receptive field. It focused on the local detail features of large spore images. The P5 feature map had the smallest scale and the largest receptive field. It mainly represented the global semantic features of spore images.

The specific structure of the TFE module is shown in Fig.3. After extracting features from the P3 and P5 feature maps via 2D convolution, the feature maps were normalized in scale through downsampling and upsampling, respectively. A fusion operation combining global pooling and average pooling was employed to downsample the P3 feature map, which ensured the diversity of the high-resolution detail features. The nearest-neighbour interpolation method was used to upsample the P5 feature map, which mitigated the loss of information from the low-resolution features. The normalized P3 and P5 feature maps were consistent in scale with the P4 feature map. Convolution and concatenation were used to extract the information from the normalized P3 and P5 feature maps and fuse it, respectively, with the P4 feature map. The fused feature map channels were three times as numerous as those in the original feature maps (P3, P4, and P5).

The wheat spore images were characterized by their sizes, shapes, and colours. TheA. flavusspores were smaller than theT. foetidaspores, whereas theF. graminearumspores were more elongated. The tiny features of theA. flavusspores could be clearly recognized in the high-resolution images. However, as the depth increased, the image resolution decreased, which led to the loss of tiny features. The traditional FPN fusion method failed to effectively utilize the relationships between different levels of pyramid feature maps, which resulted in a lack of communication between the local and global information. Therefore, we introduced SSFF. This module was inspired by video frame processing methods [39]. It performed interactive fusion on multiscale information by stitching multiscale feature maps. SSFF also utilized 3D convolution for feature extraction purposes. The specific structure of this module is shown in Fig.4. First, we used 1 × 1 2D convolutions to adjust the numbers of channels in the P4 and P5 feature maps, which ensured that both maps had 256 channels. Next, the nearest-neighbour up-sampling method was used to normalize the sizes of the P3, P4, and P5 feature maps to match the feature map with the highest resolution (P3). Then, the 3D [height, width, channel] tensors were converted into 4D [depth, height, width, channel] tensors. 3D convolution, batch normalization, and the leaky rectified linear unit (LeakyReLU) activation function were used to extract features from the 4D tensors. Finally, maximum pooling was used to down-sample the feature maps, and the down-sampled outputs were fused with the output of the TFE module.

The traditional attention mechanism focused on the channel and spatial aspects of images, whereas the ASF mechanism fused multichannel and multiscale information. Therefore, we shifted the focus of the attention mechanism to global semantic information and local detail information. We introduced the MobileViT attention mechanism, which is based on the ViT [40]. Compared with the traditional ViT, in the MobileViT, the transformer extracted global features, whereas the CNN extracted local features. The MobileViT endowed the model with spatial inductive bias and global representation capabilities [41]. The structure of the MobileViT is shown in Fig.5. It included local feature representation, global feature representation, and feature fusion components. In the local feature representation module, an n×n convolution was used to extract local features from the input feature map, and a 1 × 1 convolution was employed to adjust the number of channels. In the global feature representation module, the feature maps were divided into multiple fixed-size blocks, and each block was flattened into a one-dimensional vector. Through linear transformation, these one-dimensional vectors were mapped to higher-dimensional feature vectors. These feature vectors with positional encoding information were subsequently concatenated and fed into the transformer encoder. The transformer encoder incorporated a multihead attention mechanism and a positional feedforward neural network. The self-attention mechanism was used to capture the dependencies between different positions in the input image. The positional feedforward neural network contained multiple hidden layers to perform nonlinear mapping and feature extraction on the feature information at each position. Finally, the feature image processed by the ViT module was fused with the original image. Through the MobileViT attention mechanism, the local features were better preserved, and global features were obtained. This enabled the model to fully utilize both global semantic information and local details [42]. This approach improved the accuracy of wheat spore detection, particularly for smallerA. flavusspores.

In this study, we conducted ablation experiments to validate the performance of the introduced MobileViT attention mechanism in terms of spore detection, particularly its ability to detect small spores. We compared it with the SE (Squeeze-and-Excitation) network [43], SA (Spatial Attention) [44], ECA (Efficient Channel Attention) [45] and the CBAM (Convolutional Block Attention Module) [46].

where TP represents the number of true-positive samples and FP represents the number of false-positive samples. Similarly, TN represents the number of true-negative samples, and FN represents the number of false-negative samples. Additionally, r denotes the recall, and P(r) represents the precision corresponding to r. N denotes the number of data categories detected in this study.

In this study, all the models were trained and tested in the following experimental environment: the deep learning framework was PyTorch 1.12.1, and the operating system was Ubuntu 16.04. The computer was equipped with an Intel(R) Core(TM) i7-9700 K 8-core processor at 3.60 GHz and 16 GB of RAM. To increase the training speed, we utilized an NVIDIA GeForce GTX 2080Ti GPU with 11 GB of video memory, CUDA version 11.3, and cuDNN version 8.2.1.

The results of a comparison between the original and improved feature fusion mechanisms are shown in Table1. Compared with that of the original model, the overall precision of YOLO-ASF increased by 3%, and its overall recall increased by 0.6%. Regarding the detection ofF. graminearum,A. flavus, andT. foetida(sporidium immaturum), the mAP_0.5 values increased by 2%, 2.7%, and 0.3%, respectively. However, forT. foetida(sporidium maturum), the mAP_0.5 of the improved model did not increase. Overall, mAP_0.5 increased by 1.1%. The results showed that the YOLO-ASF model more accurately detected spores than did the other methods. Notably, for small and denseA. flavusspores, the introduced ASF mechanism increased the mAP_0.5 of the proposed model by 2.7%, which significantly enhanced its performance in terms of detecting small target spores. This was attributed to the TFE and SSFF modules contained in the ASF mechanism. In the TFE module, three feature maps with large, medium, and small sizes were convolved once and spliced in the channel dimension, which prevented the loss of small spore features. Moreover, the global semantic information contained in the deep feature maps was combined with the local detail information of the SSFF module, which enabled the model to more comprehensively understand the image content. The ASF mechanism significantly improved the ability of the model to extract target features, which in turn improved its detection performance. However, the original model achieved a high detection accuracy of 99% because of the relatively large sizes and distinctive colour texture features ofT. foetida(sporidium maturum) spores. The detection performance was close to the optimal level. It was difficult to further improve the detection accuracy under the current conditions.

We applied gradient-weighted class activation mapping (Grad-CAM) to further analyse the performance of YOLO-ASF. Grad-CAM is a visualization technique that is used to interpret neural network prediction results [54]. The gradient computation process in Grad-CAM was used to show where the model was interested in different objects. The detection weights yielded by the original YOLOv5s model and the YOLO-ASF model for the four spore classes included in the same image are visualized in Fig.6. The four left panels of Fig.6visualize the weights of the original YOLOv5s model, whereas the four right panels visualize the weights of the YOLO-ASF model. The first and third images of Fig.6show that the original YOLOv5s model did not sufficiently focus on spores, and its weights covered a wide and imprecise area, even including areas without spores. In the case with a dense spore distribution, this model also ignored certain spores. In contrast, the two images in the fourth row of Fig.6show that the original YOLOv5s model did not accurately focus on small objects. Many small impurities were also incorrectly detected as spores. However, the YOLO-ASF model could focus on detecting small spores and selectively filtering out impurities. The TFE module integrated small spore features derived from three different resolution feature maps, enriching the spore features. The SSFF module combined the detailed information and global information acquired from the feature maps. This allowed for the precise localization of small spores. In summary, the ASF mechanism comprehensively improved the detection performance of the proposed model, especially in terms of detecting small spores.

A comparison among different attention mechanisms is shown in Table2. All performance metrics reported in Table2were evaluated on the independent test set. Compared with the YOLO-ASF model, only YOLO-ASF-CBAM and YOLO-ASF-MobileViT improved theA. flavusspore detection process, with their mAP_0.5 values increasing by 0.7% and 1.6%, respectively. This occurred because the attention mechanisms, such as SE, SA and ECA, focused on the dependencies between channels but ignored spatial information. In contrast, the CBAM combined a spatial attention mechanism with a channel attention mechanism, which enabled the model to obtain more effective features from both the channel and spatial dimensions. Both the CBAM and MobileViT focused on spatial and channel information, which significantly improved the resulting small target detection performance. Notably, the precision and recall of the YOLO-ASF-CBAM model were superior to those of the YOLO-ASF-MobileViT model, but the mAP_0.5 of the former was lower than that of the latter. The CBAM could correctly detect the targets, but it failed to precisely regress the bounding boxes because of its inaccurate localization effect. The MobileViT did not involve pooling operations. Therefore, it better preserved the global semantic information, which allowed for the target boxes to be more accurately predicted. In object detection tasks, we paid more attention to mAP_0.5, as the precision and recall values achieved at different confidence levels were considered in this metric, which better reflected the overall performance of the models. The YOLO-ASF-MobileViT model had the best performance, with an overall detection mAP_0.5 of 97%, which was 1.6% better than that of the original YOLOv5s model. The MobileViT attention mechanism combines the local feature extraction ability of a CNN with the global feature extraction ability of a ViT. This approach was more suitable for detecting various spores with significant size differences.

A comparison between the training iteration curves produced before and after improving the model is shown in Fig.7. Both models exhibited significant fluctuations in their mAP_0.5 values during the first 150 iterations. Because the pretrained model was not used in this experiment, the model parameters were randomly initialized, resulting in a poor data fitting ability. Consequently, the initial training process was unstable. During the last 50 iterations, the mAP_0.5 values of both models gradually stabilized. Notably, after stabilization, the mAP_0.5 of the improved YOLOv5s model consistently remained higher than that of the original YOLOv5s model. Additionally, the improved model exhibited smaller fluctuations in its mAP_0.5 data and more quickly converged to a relatively stable state. Figure7. shows the training and validation performance curves, reflecting intermediate results on the validation set. In contrast, all metrics in Table2were computed on an independent test set. Slight differences are expected, as the test set evaluates the fully converged model on unseen data, demonstrating better generalization.

Figures8,9and10show the detection performance of the model both before and after improvements, under four different extreme conditions. First, spore adhesion was shown in Fig.8. In sample 1 of Fig.8, T.foetidaspores were adhered to each other. The original model misidentified the two adhered spores as three separate spores. In sample 2 of Fig.8, T.cariesspores were adhered toF. graminearumspores. The original model misidentified a singleF. graminearumspore as two separate spores. However, the improved model significantly reduced the false detection rate attained for adherent spores. The original model was overly concerned with the local features of the spores and ignored their overall features, thus misidentifying them as new spores. A case with overlapping spores is shown in Fig.9. In sample 1 of Fig.9, twoF. graminearumspores overlapped. The original model could not accurately determine their target boxes and attempted to detect targets with multiple target boxes. In sample 2 of Fig.9, threeT. foetidaspores overlapped, with the middle spore partially covering the other two spores, which caused them to form a single cluster. It was difficult for the original model to accurately locate their positions, which resulted in false detections. This occurred because the original model identified multiple local features within the overlapping area and attempted to label these features with multiple target boxes. These target boxes had different sizes, and the overlap region between them was small. The intersection over union (IoU) between the adjacent target boxes did not reach the filtering threshold of the nonmaximum suppression (NMS) algorithm, which led to false detection results. Blurry spore images are shown in Fig.10. In sample 1 of Fig.10, the upper-right corner of the image shows a typicalF. graminearumspore outline. However, owing to the influence of background lighting, its phenotypic features were not distinct. Therefore, the original model missed this target spore, whereas the improved model accurately detected the blurry spore. Similarly, in sample 2 of Fig.10, the upper-right corner shows the outlines of twoF. graminearumspores. The original model detected the two spores as a single entity, whereas the improved model correctly detected both spores. During model training, the size and resolution of the feature map decreased as the model depth and the step size of the convolution operation increased. Therefore, the blurred spores lacked clear edges and texture features. This caused the deep feature maps of the original model to easily lose detail information. The impurity interference case is shown in Fig.11. In sample 1 of Fig.11, impurities appear in the lower-right corner, and the original model misclassified them asF. graminearum. In sample 2 of Fig.11, the same spore-like impurity appears in the lower-right corner, resemblingA. flavus. The original model misclassified them as bothA. flavusandT. foetida. In the impurity interference case, the backbone layers of the backbone layer performed poorly in terms of describing the shape and texture features of spores, leading to misdetection.

The ASF mechanism and MobileViT attention mechanism introduced in this paper effectively solved the above problems. The MobileViT was added to the backbone layer. The self-attention mechanisms contained in the MobileViT were employed to capture the global relationships within features. Unlike traditional CNN algorithms with fixed receptive fields, this approach enabled the model to dynamically learn the long-range dependencies between different regions. The MobileViT incorporated CNNs as local feature extractors. This effectively integrated the local and global features. This approach improved the feature representation ability of the model and effectively addressed the misdetection issues caused by spore adhesion, intersection, and overlapping. In the ASF mechanism, the TFE module spliced features with three different sizes in the spatial dimension to capture detailed small spore information. The SSFF mechanism effectively fused the multichannel feature maps of P3, P4, and P5, which captured different spatial scales covering diverse spores with various sizes and shapes. This method mitigated the loss of detail information. Compared with the original model, the improved model exhibited greater robustness. It demonstrated better detection capabilities in terms of handling extreme conditions such as spore adhesion, overlap, impurity interference, and blurry spores. However, in real-world samples, interference may arise from fungal spores of other genera commonly found in cereals, such asAlternaria,Bipolaris, andPenicillium[55]. This may affect the model’s specificity. Thus, expanding the spore classes used for training will be essential to further enhance detection performance under complex field conditions.

The quantitative results of the state-of-the-art detection methods in the test are shown in Table3, which contains the precision, recall and mAP_0.5 values produced by each model. Regarding the traditional one-stage detection networks, the mAP_0.5 of the improved model was 1.6%, 24.9%, and 5.1% higher than those of YOLOv5s, the SSD, and CenterNet, respectively. With respect to the traditional two-stage detection network, the mAP_0.5 of the improved model was 23.3% higher than that of the Faster R-CNN. The performance of the SSD in terms of detectingA. flavusspores was poor, with a recall of only 60.1% and an mAP_0.5 value of just 18.1%. This occurred because the SSD algorithm lacked a feature resampling step, which easily led to missed detections [46]. CenterNet significantly surpassed the SSD in overall detection performance, but its ability to detectA. flavusspores was relatively poor, with an mAP_0.5 of only 76.4%. In the two-stage detection networks, such as the Faster R-CNN, a base neural network was utilized for feature extraction purposes, and an RPN was employed on deeper feature maps to generate target boxes. The Faster R-CNN had the lowest mAP_0.5 forA. flavusspores at only 17.2% because of the small spore features lost from the depth feature maps.

Furthermore, the mAP of TPH-YOLO, MG-YOLO, SPD-YOLO, YOLO-ECA-ASFF, and YOLO-CG-HS in detecting total fungal spores was 95.6%, 95.5%, 94.8%, 95.0%, and 95.8%, respectively, and the mAP of the proposed model was at least 1.2% higher than theirs. Particularly, these cutting-edge spore detection methods had relatively low accuracy in detectingA. flavusspores (AP_0.5 < 90%). By comparing mAP, Precision, and Recall, YOLO-ASF-MobileViT showed higher accuracy, especially in detecting small spores. This was because the ASF module effectively fused multi-scale feature information of spores, enhancing fine details. Meanwhile, MobileViT better captured the local and global features of microspores, which significantly reduced the missed detection rate. Our model has more parameters (8.4 M) and a longer inference time (10.8 ms) due to its global attention design. However, it achieves the highest mAP (97.0%) among all models. Lightweight models like TPH-YOLO and MG-YOLO run faster (< 7 ms) but perform worse, especially in detectingA. flavussmall spores. Overall, our model balances accuracy and speed well for post-harvest early warning.

This study introduced the YOLO-ASF-MobileViT network, which is an improved detection method that combines an ASF mechanism and the MobileViT attention mechanism. It effectively identifies morphologically diverse wheat fungal spores, with particular improvements in detectingA. flavus spores. The model achieved a mAP@0.5 of 97.0%, outperforming advanced detectors such as TPH-YOLO (95.6%) and MG-YOLO (95.5%). Although it introduces more parameters (8.4 M) and a longer inference time (10.8 ms), the inclusion of global attention significantly boosts detection robustness. The proposed model maintained high accuracy even under challenging conditions such as adhesion, occlusion, and noise. Overall, this method aims to provide early warning of potential fungal contamination in the post-harvest phase. It can assist in the risk assessment of seed-borne or storage-related fungal threats, thereby supporting timely intervention and quality control measures in wheat management.

In the future research, we will focus on collecting more microscopic images to expand the model’s application scenarios. We also plan to incorporate additional cereal-associated fungal spore types into the training dataset to improve the model’s generalizability and reduce false positives in mixed-contamination environments.