The implementation of interventions, digital tools, and policy plans in health systems research is highly complex. Proof-of-Concept (PoC) studies facilitate the development of these applications although they are rarely conducted or reported in mental health research. This paper describes the principles and processes to conduct PoC studies in mental health systems research.

The Technology Readiness Level in Implementation Sciences (TRL-IS) serves as the reference framework for this study. A ‘lessons learned’ process was applied to refine the concepts and develop a research strategy based on previous experiences with PoC studies. This process incorporated insights gained from a scoping review, case studies and discussion with both a core group and an extended group of experts.

PoC studies assess the workability of an application, formulating the basic concept and determining whether its functionality can be transformed into a real prototype to be tested as intended via a pilot study and later demonstrated in the real world. The strategy to conduct PoC studies should be part of the analysis of readiness of any application in health system’s research. The first four levels of readiness in the TRL-IS scale include (1) foundational knowledge, (2) formalised prior knowledge base, (3) completion of a workable PoC, and (4) prototyping. It’s design requires input from experts in all four levels. Twenty-three main elements relevant to PoC have been identified in these four phases.

PoC is generally omitted (or not reported) in mental health systems research. Researchers should be actively encouraged to overcome this omission. A common language, classification and vocabulary is needed for implementation science which incorporate this domain. The description of the specific activities conducive to PoC and prototyping should be provided. Training on the use of the TRL-IS framework including expert knowledge should also be promoted in mental health system research.

Implementation science is defined here as the study of methods and strategies used to promote, integrate and apply research findings in the real world including health, social care and public health settings [1–3]. It focuses on understanding the factors that influence how interventions are implemented effectively and the processes involved in the planning, process, actioning, adoption, and sustainability of health or social applications (a program, policy, intervention, treatment or device), in practice. Impact analysis refers to the evaluation of the effects of the application on a targeted audience in a specific real-world context [4].

Impact analysis is particularly challenging in mental health systems research as this field involves highly complex structures and technologies characterised by intricate interactions among multiple factors involving structures, processes and outputs. To effectively develop, implement, evaluate and enhance these applications, a series of standardised steps should be considered, including Proof-of-Concept (PoC) analysis.

In implementation sciences, PoC is the part of early development of an application involving the design of a conceptual model that confirms the principles of the application and its theoretical workability, as the basis for the development of a prototype [5,6]. This early stage of development builds on a wide array of methods and information sources.

PoC studies play a pivotal role to later test and validate innovative approaches, and therefore they should be taken into consideration to optimise project development, efficiency, and value-based planning [7]. PoC studies are not meant to provide comprehensive results or solutions but rather to show that the application is worthy of further investment, to identify potential issues, and refine the study design prior to developing a prototype that could be tested in a small-scale pilot study before being demonstrated in the real world [8,9].

Despite its importance, little attention has been paid to PoC in mental health systems research. Published PoC studies in mental health are scarce and frequently suffer from significant methodological flaws, largely due to the absence of a standardised reference framework, unclear components, inadequate definitions and boundaries related to other stages of development of the application—such as prototyping, piloting, demonstration, and deployment. These stages are often improperly combined into a single, entangled process referred broadly to as “proof of concept” [7]. A previous scoping review highlighted the significant lack of real PoC studies in mental health systems research. Only one out of 22 selected papers was actually a PoC study, the rest involving other stages of project development or its combination [10]. Additionally, rapid cycles, particularly in health policy research and in digital health, impose shortened and accelerated development processes before demonstration and deployment. This often results in merging different stages of development into a single process, bypassing the PoC step.

The aim of this conceptual paper is to establish a standardised framework for conducting PoC and prototyping studies in implementation science, with a specific focus in mental health systems research.

This paper provides and overview and conceptualises PoC studies within implementation research, integrating the Technology Readiness Level approach to guide the development and evaluation of innovative health applications. It introduces the structured framework, and the specific steps involved in conducting a PoC and prototyping studies. Following this, we conduct a detailed exploration of the conceptual foundation underlying these processes are thoroughly explained, offering a comprehensive understanding of how PoC studies contribute to the broader field of implementation research. This process incorporated insights gained from a scoping review, case studies and discussion with both a core group and an extended group of experts.

Three main phases of scientific knowledge have been defined: discovery, corroboration by independent groups and implementation [11]. The complexity of all steps of study planning and design increases as research moves from one phase to the next. While the hypothesis, the research question and the related measurements could be clear, specific and linear in the discovery phase, the key components of study design get increasingly complex when research moves to real world conditions [12]. The results of randomised control trials and their metanalysis become difficult to interpret in different contexts and time series. Rather than knowledge derived from a small number of RCTs, a broad perspective is required in implementation science, taking into consideration multi-site, multi-level and multi-project programs, as well as multicriteria decision making [13]. Under these conditions, and after producing a synthesis of the discovery and corroboration knowledge, a reformulation of both the problem and its solution should be conducted, including the PoC of the suggested application.

In implementation research, PoC studies are part of the readiness of applications. “Readiness” has been defined as the level of preparedness of an application of the emerging scientific knowledge for its release, marketing, commercialisation, and/or open access in the real world [14].

Originally developed by NASA in the 1970s [15], the TRL framework has since been adopted across various fields. In 2014, the European Commission adapted it for use in scientific research, and it has become widely applied in other sectors, particularly in government planning [16], medical drug development [17], and healthcare information technologies [18]. In 2024, the TRL was further refined to evaluate the development of applications in public health and implementation sciences (TRL-IS) [18].

The Technology Readiness Level – Implementation Science (TRL-IS) framework is a nine-level tool for evaluating the maturity (readiness) of applications [10,18], which has significantly advanced implementation research in digital and in mental health (Fig.1). The TRL-IS was designed to measure progress and guide development from the conceptual phase through to full implementation of a health application [18]. It uses a standardised set of criteria to assess the current readiness level of the technology or application and determines whether it is ready to advance to the next stage, with each stage representing increasing maturity (Fig.1).

Readiness should not be considered in isolation, but as part of a broader evaluation of impact. The Global Impact Analysis Framework (GIAF) is an international system for assessing the process conducive to impact in the three main phases of implementation [19,20]: initiation or pre-implementation, maturity or early implementation, and evolution or later implementation. Within GIAF, readiness is considered a transitional domain between initiation and maturity. “Pre-readiness” encompasses the first 6 levels of TRL as part of the initiation phase and includes PoC as level 3. Meanwhile levels 7 to 9 which involve demonstration and release are categorised as part of the maturity phase or early implementation. To assess the process in the three phases of evolution, GIAF uses an onto-terminological approach (Fig.2), that includes a taxonomy, a glossary of terms, and associated measurement tools with the TRL framework serving as the main tool for measuring readiness [18–21].

Expert knowledge is key to the development of PoC. It has been defined as a set of formalised know-how, understanding, and insight in a defined area of knowledge, which is informed, contextualised, stable, consistent, and connected. It is elicited using qualitative approaches alone or combined with quantitative methods to generate inferences and other knowledge to complement evidence based on data [11]. Expert knowledge is a mixture of semantic and episodic proficiency which typically has been gained by working in an area more than 10,000 h [22]. Expert knowledge also includes the tacit knowledge (the knowledge the expert has but that has not been formalised in a written format). Tacit knowledge is critical, and should be elicited and formalised within the Prior Knowledge Base. Experiential knowledge, on the other hand, is acquired through the lived experience of an event or a condition. Engaging people with lived experience ensures that the co-design process is not only theoretically sound but also grounded in practical realities that can improve user-centred outcomes.

The “pillars” multidimensional model (Fig.3), is a development of the health system’s framework applied to scientific knowledge [11,23], and regards expert and experiential knowledge as two of the six key pillars of scientific knowledge together with culture; and experimental, observational, and contextual evidence based on data [24] (Fig.3). The pillars approach to expert knowledge differs substantially from the Cochrane Pyramid model of scientific knowledge, widely adopted by the evidence-based medicine framework [12]. The Cochrane model places expert “opinion” or “colloquial evidence” at the bottom of the pyramid following a unidimensional representation of scientific knowledge in health system research. On the contrary, real-world environments are complex, non-linear, context dependent, and time dependent [11], making expert knowledge essential at every step of development and particularly in the generation of PoC.

Experts typically participate in a formal structured process using different qualitative techniques such as testimonies, field notes, in-depth interviews, ethnographic observations, focus group, nominal groups, Delphi or Mini-Delphi panels, or participatory workshops. Several approaches have been developed to integrate expert knowledge into the development of health applications. For example, the Expert-based Collaborative Analysis (EbCA) [25] is a structured approach to problem-solving or decision-making that involves gathering input, insights, and judgments from multiple experts, across various fields or domains using expert groups. This approach to expert knowledge leverages the collective knowledge, experience, and expertise of a group of specialists to address complex issues, evaluate options, or develop solutions that would benefit from diverse perspectives. Visualisation tools facilitate the representation and elicitation of tacit knowledge and plays a critical role in the formation of the prior knowledge base [26].

EbCA and other qualitative approaches provide a synthesis of multiple viewpoints into a coherent and actionable understanding of the problem and the tentative solutions [27,28]. This involves reconciling differing ideas or assumptions and identifying areas of consensus among experts. Therefore, the selected experts should represent the main perspectives on the topic being studied. Naturally, the resulting knowledge base will vary depending on the experts selected. However, the results could be replicated or contested as long as the selection process and the characteristics of the experts are clearly explained.

Experts will contribute to the different components of these phases, including the knowledge derived from the discovery and corroboration prior to implementation, the review of the previous literature, gap analysis, and estimates for missing data. Wherever gaps are identified experts can recommend conducting additional studies, such as secondary analysis of databases or a survey. Experts may then review the existing data and case studies, contribute to the analysis of barriers and incentives and the final synthesis of prior knowledge. Experts could also facilitate the external validation of the application throughout the different levels of TRL. Interestingly, omissions in the external validation process have been identified even in the study design for guideline development [29].

The levels of readiness in implementation are related to, but distinct from, those followed in single study planning and design. In general, these steps typically include: (1) Problem identification and prioritisation; (2) Formulation of objectives and questions (e.g., SMART objectives, PICO question or realist synthesis questions); and (3) Study design and methods of data analysis and interpretation, such as the various approaches mentioned in the EQUATOR network [30]. However, readiness may involve a whole set of different descriptive, interpretative and evaluative studies. A previous search via the EQUATOR Network Repository [30,31]. found no reporting guideline for impact analysis of implementation research protocols. This illustrates the challenges integrating all components into a single, cohesive framework for design and planning [31].

In addition, planning in implementation science should also include other components such as the logic for change (theory of change), identification of the various key targets (sample, target population and target audience), the resource allocation plan, the dissemination plan, and the development plan (including business, marketing and commercialisation). These elements fall under the planning domain of the initiation phase within the GIAF framework [14].

Three TRL steps encompass the development of the PoC: Foundational knowledge (TRL-IS 1), formalised prior knowledge base (TRL-IS 2), and its translation into a workable PoC of the application (TRL-IS 3). These steps conduce to the final development of a prototype (TRL-IS 4). Although there is no standard definition of the different components or a guideline to conduct PoC in health intervention and systems research, it is essential to clearly outline the steps and components followed to develop an intervention in every study. This clarity not only helps in understanding the background of the application being analysed but also facilitates replication by independent research groups. The main components relevant to PoC are listed in Table1.

The aim of this step is to build a comprehensive understanding of the problem and its potential solution by implementing an application in practice. Although these ideas are based on the knowledge gained in the phases of discovery and corroboration, they are still speculative in regards to their implementation in the real world and have not been validated in practice yet.

In health systems research, the development of applications typically require the establishment of an expert group following a co-design approach. Whenever feasible, the creation of the expert group should take place at the beginning of readiness process. The core team, supported by the experts, could then identify key aspects of the foundational knowledge, such as the context, the study’s perspective – whether the application impact will focus on society, a specific population group, the whole public system, a provider corporation, or a funding body-, and the target audience.

The target audience is broader than, or may even differ from, the target population and the study sample. For example, the target audience in the development of the EMPOWER digital platform for improving mental health at the workplace [32], included the managers of small and medium companies, while the study sample were employees working in these companies.

Subsequently, the core team could delve into fundamental concepts, theories, frameworks relevant to describe the problem and the application, and/or to explain the mechanisms by which the intervention could operate to solve or to attenuate the problem [4]. A framework is a formalised description (of a defined system or topic based on scientific knowledge (evidence-based and qualitative). Whilst frameworks are descriptive, theories provide an explanation of causality. Models are graphical representations of both frameworks and theories. In health systems and complexity research, a single framework may not suffice to incorporate all the different conceptual and methodological components required to produce the new application. A meta-framework is an overarching structure that integrates multiple frameworks to guide research, analysis and interpretation, typically in the design to address system-level questions from a multidisciplinary approach.

Practical examples of the development of a meta-framework could be found in the standard evaluation of the context of implementation [33], the development of a full system’s approach to integrated person-centred care [34], or in the analysis of the patterns of health service provision for indigenous peoples in Australia [35]. The later [36], encompasses a framework of indigenous health (social and emotional wellbeing -SEWB), a holistic approach to scientific knowledge, a framework for the whole system evaluation of geographical areas, and a socio-technical approach to the evaluation of the local care provision system.

Finally, a synthesis of the foundational knowledge is produced to facilitate the formalised (written and published) prior knowledge base in TRL-2.

At TRL-IS Level 2, researchers explore how the basic scientific principles formulated in TRL-IS Level 1 could be applied to real-world problems and opportunities. Formalisation refers to the process of systematically defining and standardising concepts, methods, procedures and applications to enhance clarity and consistency. This process culminates in the production of reports and scientific publications to facilitate consensus formation and reproducibility [37]. The key focus is on identifying potential innovations that could emerge from the foundational knowledge. This stage is often theoretical, as there are no physical prototypes yet. However, the concepts are more concrete than at TRL-IS Level 1, with potential paths for application being defined and formalised. The development of the prior knowledge base draws on multiple sources of data and qualitative knowledge.

The review should be combined with expert knowledge for translation into policy and practice. A practical example was the use of Rapid Synthesis and Translation Process (RSTP) for knowledge transfer, implemented as part of the Interactive Systems Framework (ISF) for Dissemination and Implementation by the Division of Violence Prevention at the US Centres for Disease Control and Prevention [39].

Gaps identified in the literature review may be filled with estimates and assumptions made by experts. Expert assumptions could be driven by visualisation of data (Gibert et al., 2010), and replaced or supported by other sources of information, such as information from historic or secondary analysis of administrative datasets. Additionally, it may be possible to conduct brief surveys or whenever feasible, or add new questions in population surveys. The analysis of costs of mental health disorders in Catalonia (Spain), exemplifies the combination of expert knowledge with multiple sources of information such as the secondary analysis of the primary and specialised care databases, data from the annual population health survey, modelling and scenario building informed by experts [11,40].

Modelling could be conducted at every stage of the TRL, from the PoC, to piloting and demonstration. Withing the healthcare ecosystem approach, the procedures for building scenarios and modelling has been inspired by the IPBES models [4,41]. Its use is illustrated by the study of service utilisation patterns and performance of the main types of MH care in the Helsinki-Uusimaa region (Finland) [42]. The use of different modelling tools to inform the mental health system has been recently revised in Australia [43], including health economics modelling of clinical trials.

Clinical trials related to health systems research constitute a major challenge in real world conditions. Implementation trials should adapt the design to unplanned events that could have a large impact on recruitment and adherence, require revising allocation ratios used for randomisation, enriching the target population, or changes in the most appropriate endpoint [44]. The European EMPOWER project illustrates the problems encountered in the development of the readiness of a digital platform for improving mental health at the workplace in Europe [32,45]. The project faced major logistic problems and need to adjust the sample size and the target. The target where companies in three countries (Finland, Poland and Spain) that where heavily impacted by COVID-19 in 2020, and later, by the Ukrainian war in 2022, with effects being particularly pronounced in Ukraine’s neighbouring countries, Poland and Finland. The rapid cycle of innovation in the digital sector had a significant impact on the PoC of this study. It made it necessary to develop the knowledge base (systematic, scoping and narrative reviews, as well as accompanying tools), alongside the development of the prototype and its testing. The reduce time assigned to completion of levels 1 to 4, and merging levels 6 and 7 (piloting and demonstration), impacted on the overall readiness of the final tool. Eventually the clinical trial was amended to adapt it to the different events mentioned above.

Any clinical trial involving applications in the real world should contemplate an adaptive trial approach [46]. In the planning phase to enable further modifications in the design as the study progresses. Other emerging approaches to be considered, are sequential multiple assignment randomized trials (SMART), master protocol and seamless designs. Kaizer and colleagues provide examples of these approaches in implementation studies [44].

Ray Pawson has suggested analysing randomised trials as case studies “evaluating just one out of a kaleidoscope of different configurations in which a knowledge transfer scheme may be implemented” [47], transforming the analysis into multi-method case series (i.e., a group of cases presented together as representatives of a common phenomenon).

Moving forward from the traditional evidence-base model represented by the Cochrane pyramid, case studies are particularly relevant contributors to the knowledge-base throughout the whole readiness process. Collective case studies involve in-depth analysis of multiple cases using a standard method and tools to provide a broader understanding of a given phenomenon (e.g. factors influencing the success of the application across different contexts). This approach is particularly relevant in organisational studies of complex phenomena and facilitates pattern recognition and its implementation in policy and practice. The collective case study analysis of mental health provision in Canberra (Australia) [48] and Helsinki (Finland) [42] illustrate the importance of this approach for planning.

The analysis of barriers and facilitators constitutes a major element of PKB. Unfortunately, there is no standard checklist to conduct such studies and a number of methodological questions have been raised [49]. In any case the key is to ensure clarity and reproducibility of the results by a transparent and clear explanation of the method followed and its limitations.

The findings from this level are generally documented in academic publications, technical papers, other reports, and syntheses documents. This documentation serves as a roadmap for moving the application to higher TRLs and its real-world implementation. The goal is to propose potential applications and identify key technical challenges and workability questions.

The primary goal of TRL-IS level 3 is to design a workable theoretical model of the application that could potentially be realised in a prototype. The aim is to show that the underlying scientific principles can be applied in a way that supports the desired outcome. Within the GIAF framework workability is defined as the potential usefulness of an application design before a prototype is produced. This concept falls into the broader category of “usefulness” (Fig.2), which can be assessed at every phase of the implementation process. During the initiation phase, “usefulness” encompasses workability at Level 3 and feasibility at Level 5. In the early maturity phase, usefulness is referred to as “usability” (Level 7), and in the evolution phase, it is named “sustainability” [4,10]. Usefulness incorporates the same six subdomains at every stage of implementation: relevance, its potential acceptability, applicability and practicality, as well as the estimated efficiency and value, which can be assessed by the experts and other stakeholders.

An example of the analysis of the usefulness of health system applications could be found in the development of a machine learning support decision system to inform decision making in the Basque Country (Spain) [50].

The primary goal of TRL-IS level 4 is to design an actual prototype or “Minimum Viable Product” of the intended application. An MVP is the first version with the functions required to perform an internal testing, so early users can provide feedback for future development. It could be a physical device or a functional intervention (e.g. a new psychotherapy) ready so feedback can be gathered and incorporated into more developed version of the application. The Alpha-version is a more advanced model that, although not feature-complete, can be validated and piloted in a relevant environment (Levels 5 and 6). The Beta-version would be the one demonstrated in a number of real-world sites before the final version is ready for release (Levels 8 and 9).

A co-design approach could be favoured by a blend of expert insights, practical experience and lessons learned, making it more responsive to the needs of all stakeholders involved.

Despite the inherent complexity of health systems, the strategic approach and key steps leading to PoC are frequently overlooked in this field of research. PoC studies are not supported by the funding agencies, as they are considered as a preliminary step of research that is supposedly conducted prior to any formal study proposal. PoCs and pilot studies are often disregarded in scientific publications, and the use of these terms in research lacks scientific rigour as it was shown in a prior scoping review [10].

In 2019, a funding organisation requested our research team to conduct a PoC study prior to piloting and demonstrating a decision support tool to inform mental health planning in Australia [51]. The funding body considered the proposal highly innovative and relevant but sought to mitigate risks by first conducting a PoC. This specific funding enabled us to dedicate time and resources to a focused PoC study which revealed the importance and magnitude of the existing gap in PoC research within mental health systems research. In this study following the Technology Readiness Level approach, helped us determine where PoC studies fit within the overall development of health applications. Additionally, this approach enabled us to better frame the various elements relevant for the production of decision support tools. For instance, it clarified the role of meta-frameworks in the foundational knowledge, the importance of integrating literature reviews with other sources of prior knowledge, such as secondary analysis of administrative databases, and highlighted the crucial role of expert panels in guiding the whole process, beyond the co-design of the tool.

Given the absence of a comprehensive framework for overall planning and design in implementation science, the TRL-IS offers a unique perspective on the role of PoC in the overall development of health applications. It also provides a better understanding of the different elements that could contribute to the creation of decision support tools and other health applications.

In summary, the level of foundational knowledge (TRL-IS Level 1), involves the translation of fundamental research into practical applications, which forms the basis for future socio-technical developments as the concept and its application progresses through the higher TRL-IS levels. At TRL-IS Level 1, no real-world application or tangible technology is developed yet; instead, it is about exploring and understanding the principles that could be the starting point for innovative applications. TRL-IS Level 2 involves the formalisation of the knowledge base. This is a dynamic and iterative process, involving a whole set of elements that typically are not connected among them (e.g. literature reviews, secondary analysis of databases and expert knowledge). Although typically not recognised as such in research, the Prior Knowledge Base is a dynamic and iterative process, open to continuous improvement at every level of tool development, maturity and evolution.

The production of the PoC is delineated in TRL-IS Level 3. In this level, the concept moves from theory to planning. The focus is on conducting initial activities to demonstrate the potential workability of the concept in a structured environment. This stage provides evidence that the application could potentially work, while identifying any challenges that need to be addressed before advancing to more complex development and higher levels on TRL-IS. Finally, TRL-IS Level 4 emphasizes the development of an actual prototype that can be validated and tested. All these levels should be informed and guided by an expert panel, whose role extends beyond the co-design of the tool. End-users contribute to all aspects of its functionality and play a critical role in ensuring its external validity.

In the future, it would be highly beneficial to prioritize the inclusion of PoC proposals in funding initiatives and to facilitate the publication of PoC studies. In addition, establishing a common language, classification and vocabulary for categories within the readiness domain, particularly for PoC, pilot and demonstration studies will be essential for enhancing clarity and communication among researchers. Additionally, training and dissemination of tools designed to facilitate PoC, such as the TRL-IS framework and expert-based collaborative analysis should also be incorporated into research practice.

Incorporating this PoC approach will not only strengthen the development of effective health applications but also address the gaps identified in our previous research, ultimately leading to more robust and user-centred solutions in mental health systems research and beyond.

The authors would like to express their gratitude to Dr. Anna-Maree Syme for her assistance in preparing the visual materials.