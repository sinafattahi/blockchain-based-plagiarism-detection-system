Named entity recognition (NER) is a significant natural language processing task (NLP) in several applications, including question-answering and data retrieval. NER’s primary goal is to classify, discover, and extract named entities into predetermined classes: location, person, and organization. Arabic NER is a tedious process due to its unique characteristics and complexity. Unlike Classical Arabic, the earlier study on deep learning (DL)-Arabic NER focuses on modern standard Arabic (MSA) and dialectal Arabic. The transformers and recurrent neural networks (RNNs) are DL approaches that have accomplished extraordinary results in many NLP tasks since they do not trust huge knowledge sources or handcrafted features. Thus, this study introduces a novel Northern Goshawk Optimization with Artificial Intelligence for Arabic Named Entity Recognition (NGOAI-ANER) technique in Moroccan Dialect. The NGOAI-ANER technique enhanced the precision and efficiency of NER systems for Arabic text. The NGOAI-ANER technique begins by applying word embedding methods to convert text into dense vector representations, effectively capturing the semantic information essential for NER tasks. Furthermore, the stacked attention long short-term memory (SALSTM) technique is trained on the embedded data, leveraging the strength of DL architectures to identify named entities within Arabic text accurately. The NGOAI-ANER technique utilizes the northern goshawk optimization (NGO) model to fine-tune hyperparameters effectively to optimize the solution of the DL technique. An experimental assessment of the DarNERcorp dataset demonstrates the efficacy and scalability of the NGOAI-ANER model. The experimentation of the NGOAI-ANER model demonstrated a superior accuracy value of 97.86% over existing approaches.

Arabic is one of the authorized languages in the world of Arabs and the strongest natural dialect in terms of morphological derivation and inflexion1. It is considered one of the top 10 common languages in the world by 420 million native talkers and 25 standard dialects. Arabic contains numerous exclusive features which make Arabic text both interesting and challenging. Special appreciation for the growing convenience of social media sites; there is a significant growth in the availability of Arabic texts on the Internet2. Arabic NER (ANER) draws attention to the efficient procedure of these texts. NER is the challenge of classifying indications related to exact kinds, like person name, position, and organization3. Also, general areas in numerous exact fields, namely the field of medicinal and drug processes, are removed by NER. With the help of Arabic NER, removing significant data in dissimilar areas is very useful. Additionally, it supports a range of downstream tasks comprising entity linking, machine translation, coreference resolution, relation extraction, and event extraction4. NER is a task of NLP that categorizes named entities in an assumed text predefined semantic classes like the person’s name, organization name, and position name. In the 1990s, NER was presented as a data extractor challenge in the message understanding conferences (MUC)5. It generally plays a vital part in numerous tasks of NLP, like data retrieval, machine translation, question answering, and text summarization. So, exploring a precise NER method can function as a source of data for diverse NLP uses. As a simple module of NLP, NER is familiar with English but still wants to complete a survey in Arabic. English NER is easier than Arabic NER because most English comments begin with capital letters, unlike Arabic, where this is not standard practice6.

Furthermore, Arabic is a morphologically compound dialectal owing to its very morphological and numerous variants. There is a reasonable quantity of work on NER study in Chinese, English, and other extensively spread dialects7. Previous NER methods were commonly dependent upon three techniques such as machine learning (ML)-based, hybrid-based, and rule-based NER. The Rule-based NER is based on a pair of manual rubrics removed by specialists in morphology. ML-based NER depends on statistical and feature-engineering methods8. Then, the hybrid-based NER unites either ML- or rule-based techniques. At present, through the innovation of multi-layered neural networks (NN), DL-based methods have attained remarkably higher performance in numerous NLP challenges, such as NER. DL is measured as a sub-area of ML that utilizes NN of manifold layers9. A multistage model determines and absorbs the depiction and structure of unstructured and unlabeled data like documents and imageries10. A large number of informal and dialectal Arabic texts are now easily accessible on online platforms due to the rise in -generated content on social media platforms. This growth highlights the requirement for advanced models to detect and classify named entities within these texts precisely. Effectual entity recognition in Arabic dialects like Moroccan can significantly improve data retrieval, sentiment analysis, and machine translation applications. It is crucial for unlocking the full potential of Arabic language processing in real-world scenarios.

This study introduces a novel Northern Goshawk Optimization with Artificial Intelligence for Arabic Named Entity Recognition (NGOAI-ANER) technique in Moroccan Dialect. The NGOAI-ANER technique enhanced the precision and efficiency of NER systems for Arabic text. The NGOAI-ANER technique begins by applying word embedding methods to convert text into dense vector representations, effectively capturing the semantic information essential for NER tasks. Furthermore, the stacked attention long short-term memory (SALSTM) technique is trained on the embedded data, leveraging the strength of DL architectures to identify named entities within Arabic text accurately. The NGOAI-ANER technique utilizes the northern goshawk optimization (NGO) model to fine-tune hyperparameters effectively to optimize the solution of the DL technique. An experimental assessment of the DarNERcorp dataset demonstrates the efficacy and scalability of the NGOAI-ANER model. The key contribution of the NGOAI-ANER model is listed below.

The NGOAI-ANER technique employs word embedding to transform textual data into dense vector representations that capture rich semantic relationships. This improves the quality of input features, enabling a better understanding of context and meaning. As a result, it improves the overall accuracy and efficiency of the subsequent sequence modelling.

The NGOAI-ANER method integrates the SALSTM network to capture complex dependencies and improve context understanding in text sequences. This enhances the capability to concentrate on relevant data across long-range interactions, thereby improving the accuracy and robustness of NER tasks.

The NGOAI-ANER approach implements the NGO technique to tune hyperparameters efficiently, optimizing the training process. This results in faster convergence and improved model accuracy. It ensures a more effective and automated parameter selection for enhanced overall performance.

The NGOAI-ANER model presents a novel hybrid framework by uniquely integrating the SALSTM network with NGO for hyperparameter tuning. This incorporated model simultaneously improves understanding of attention-based context and optimizes model parameters. The approach improves accuracy and convergence speed in NER tasks. Its combination of advanced sequence modelling and bio-inspired optimization distinguishes it from existing methods.

Anam et al.11introduced a DL model for Urdu NER, which connects Floret and FastText word embeddings by considering the nearby context of words for an enhanced feature extractor. The pre-trained Floret and FastText word embeddings are openly accessible for the Urdu language and are employed for producing the feature vector of 4 benchmark Urdu language datasets. Such features must be implemented as input for training diverse integrations of gated recurrent unit (GRU) LSTM, Bi-LSTM, CRF, and DL methods. Ait Benali et al.12introduced a multi-headed self-attention mechanism (SAM) employed in the BiLSTM-CRF NN architecture for identifying Arabic-called individuals in social media platforms employing two embeddings. The introduced model unites character and word embedding at the layer of embedding. In13, a technique that links a variety of Word embedding methods, manifold clustering, identification models, and Irace for automated model formation was presented. This technique includes the formation of dissimilar Word embedding techniques, the execution of dissimilar identification and clustering models, and altering these executions by dissimilar parameter mixtures to make an Arabic NER Method by the maximum rate of precision. In14, a significant variation of RNN, such as Bi-LSTM, is particularly employed for series identification issues for the task of NER. Word context features play a vital part in precisely forecasting termed entities. The current work donates to emerging new word embedding, i.e. increased word embedding, which can absorb contextual features well. Alsultani and Aliwy15project an effective NER method that influences the encoding block of the Transformer, whereas either character- or word-level embedding was implemented. The united character- and word-level embedding served an encoding with Bi-LSTM. The encoding output is assumed to be a layer of Multi-head SAM. This executes the encoding block of the transformer containing a SAM tracked by a feed-forward system. Hatab et al.16employ Madamira, an exterior knowledge basis, to make extra word features. The technique assesses the value of inserting these features into conventional characters and word embeddings to execute the task of NER on MSA. The NER technique was applied utilizing BiLSTM-CRF. The morphological and syntactical features are also inserted into dissimilar word embeddings to train the method. Goyal et al.17project a DL-based NER method utilizing hybrid embedding with a mixture of fast text and BiLSTM-based character embedding. These embeddings take the text’s context, semantic, and syntactic assets that increase the intellectual influence of DL techniques. Diverse tests are executed with significant variations of RNN such as LSTM and Bi-LSTM, GRU and Bi-GRU.

Hamad and Abushaala18developed a NER technique. After pre-processing, the research signified every word with multiple features like Part of Speech (PoS), FastText embedding, non-medical word matching, and TF-IDF. To classify the word, the surrounding words are considered to arrest its context. Therefore, the research has categorized every word into its entity through the SVM technique. Tibi and Messaoud19developed a DL-based system using multi-scale product analysis and a Hamilton neural network (HNN) technique to detect Arabic dialects from speech signals accurately. Bourahouat, Abourezq, and Daoudi20presented a model to improve sentiment analysis for Moroccan Arabic using pre-trained Arabic BERT models integrated with DL and ML techniques, addressing data imbalance challenges. Mansour et al.21proposed a method to analyze Arabic dialect sentiment on social media using several ML, DL, and transformer-based models to detect the most effective approach. Jbel et al.22created a comprehensive Moroccan dialect sentiment dataset and computed various ML and DL approaches for effectual sentiment analysis across Arabic and Latin scripts. Bahbib et al.23developed and evaluated an automated system for accurately categorizing Arabic medical questions utilizing integrated feature extraction and DL techniques. Ouza et al.24developed an accurate Arabic sentiment analysis system using AraBERT incorporated with neural network models to capture the language’s morphological and syntactic variances effectively. Dandash and Asadpour25presented a technique to analyze the relationship between Arabic Twitter language use, personality traits, and sentiment using ML techniques to enhance understanding of user behaviour. Skiredj et al.26developed and evaluated DarijaBanking and the BERTouch model to strengthen and improve intent classification in Moroccan Darija for the banking domain. Magdy et al.27developed and evaluated Jawaher, a benchmark for assessing large language models’ ability to comprehend and interpret Arabic proverbs across dialects. Mohammad, Alkhnbashi, and Hammoudeh28proposed a model to improve the performance of large language models like ChatGPT for accurate Arabic healthcare query understanding and response generation.

Despite significant advancements, various limitations and research gaps remain in Arabic NLP tasks. Many existing studies depend on pre-trained embeddings without fully capturing complex contextual and dialectal variations, particularly in under-resourced dialects like Moroccan Darija. Integrating diverse embeddings and architectures often lacks comprehensive evaluation across varied datasets, limiting generalizability. Furthermore, the handling of imbalanced datasets and the fusion of multimodal features remain insufficiently explored. While transformer-based models exhibit efficiency, their cultural and linguistic adaptability, specifically in dialect-rich environments, requires additional refinement. Addressing these research gaps is crucial for developing more robust, scalable, and dialect-aware Arabic NLP systems.

This research introduces a novel NGOAI-ANER methodology for the Moroccan dialect. The methodology aims to enhance the precision and efficiency of NER systems for Arabic text. Various procedures, namely word embedding, SALSTM-based classification, and NGO-based hyperparameter tuning, are used to accomplish that. Figure1specifies the workflow of the NGOAI-ANER method.

Initially, the NGOAI-ANER approach begins with the word embedding techniques that transform the text into dense vector representations, capturing semantic information crucial for NER tasks29. Word embedding presents a method of signifying individual words utilizing higher dimension real number vectors, which take the semantic and syntactic relations among words. Word2Vec (W2V) is an instance of a method employed to make word embeddings. This model is used to make AraVec because it is a pre-trained word embedding method for Arabic. Word embedding cannot take every orthographic and morphological data of words because it is crucial for morphological-rich dialects such as Arabic. Therefore, the requirement for additional word representation is dependent upon its characters.

FastText is a word embedding method that complements W2V. It delivers optimum outcomes for rare or hidden words because it pauses a term to character‐grams and signifies a term by the amount of the vector representation of its portions.

At this stage, the SALSTM model is trained on the embedded data, utilizing the power of DL architectures to classify named entities within Arabic text30accurately. To enhance the learning capability of LSTM, several LSTMs are loaded into layers. The authors discovered the benefits of deep-stacked LSTM. Wang et al. discovered a different manner to integrate multi-single LSTM layers combined and deliberated the benefits and drawbacks of deep LSTM. During this case, 2-LSTMs are set as part of the model’s framework. By loading the LSTM layer, the resultant hidden layer (HL) was spread to the adjacency LSTM cells and, apart from the input, to the subsequent LSTM layer. Additional HLs allow the method to define the spread among network output and input by noticing the mapping connection with multiple dimension spaces and enhancing the model’s capability to manage non-linearity. Every LSTM layer outcome in a vector sequence is employed as input for the next LSTM layer. Thelayer is upgraded by Eqs. (1-5).

The first layer input is the mapping features removed by CNN, but the output is assumed to be the hierarchical feature. Stacking multi-LSTM layers allows the method to rebuild the representation acquired from the preceding layer, and a novel representation with a higher level of abstraction was obtained. The parameters are divided in the entire space of the model, which accelerates the trained convergence and executes the optimum non-linear function of the data. However, a solitary LSTM resolves specific issues presented in RNN; managing long and complicated series is still very complex. Employing 2-layer LSTMs as part of the system framework makes the HL more compactly connected, improving the predictive accuracy. Figure2portrays the structure of SALSTM.

The AM in NN is a resource allocation method to allocate resources to the most crucial challenges and resolve excess data problems with restricted calculation resources. In NNs, with extra parameters, a model takes better feature expression capability it will get, and additional data saved by the model. However, this can generate a data overload problem. By establishing the AM, the system could concentrate on the critical data to the existing tasks amongst several input data, decreasing the attention to other ineffective data. The AM resolves the data overload issue and enhances the model’s effectiveness and precision.

However, the optimum method of AM is attained by integrating the basics with attention distribution co-efficient. The AM maintains the in-between solutions of the trained method, acquires these in-between solutions, and connects the resultant series with them by allocating weights. Moreover, related to the typical RNN, the AM can be calculated in parallel, but the computational of all the steps is no longer dependent upon the computation solutions of the preceding stage. So, the AM has some parameters and more effective computation.

The computation is separated into two stages: (i) compute attention distribution between every input data; (ii) calculate the weighted average of input data dependent upon attention distributions.

The Eqs. (6–9) illustrate the computational rules of the AM. The inputand the preceding HL variableimplies the weighted average of the subsequent HL unit and each HL of the RNN layer.defines the equal-weighted ratio among 2 HL units.represents the value of the target.signifies the weighted computation process.

Finally, the NGOAI-ANER technique utilizes the NGO approach to fine-tune hyperparameters effectively to optimize the DL model performance31. This approach is chosen for its efficiency in optimization by replicating the natural hunting strategies of the Northern Goshawk, enabling compelling exploration and exploitation of the search space. This method provides faster convergence and avoids getting trapped in local optima, enhancing model performance. Its adaptability and capability in balancing exploration–exploitation make it particularly appropriate for intrinsic DL models with several parameters. Additionally, NGO requires less computational resources and tuning effort, making it an ideal choice over other metaheuristic algorithms. This efficiency and robustness justify its selection for improving model accuracy and convergence speed. Figure3specifies the working flow of the NGO methodology.

The developed NGO is a population-based method where the north goshawks are explorer members in this system. In an NGO, every member of a population requires a presented solution to the issue, which defines the values of variables. From an opinion of mathematics, every member of the population is a vector, and they are organized from the population as a matrix. Initially, population members were arbitrarily set in the space of searching. The matrix of population was defined utilizing Eq. (10).

Here,represents thepresented solution,denotes the northern Goshawks population,specifies the number of population members,refers to the problem variables amount andrefers to the value ofvariable definite by thedeveloped result.

As indicated above, every member of a population is a projected performance to the issue. So, the objective function (OF) is assessed and depends on every population member. These values acquired for the OF are signified as a vector utilizing Eq. (11).

whereas,signifies the OF value attained byprojected solution andrepresents the vector of acquired OF value.

The principle for determining which solution is finest is the OF value. In minimized issues, the OF value is lesser; in maximized issues, the OF value is greater, enhancing the projected solution. Let every iteration novel value be acquired for the objective function, and the finest developed solution must be upgraded in every iteration.

In creating the developed NGO model to upgrade the population members, the imitation of the northern goshawk tactic throughout searching was used. The dual foremost northern goshawk behaviours are given below.

In the hunting method, the northern goshawk arbitrarily picks a target and rapidly assaults it. This stage will upsurge the NGO search authority owing to the collection of arbitrary prey from the search space. It chiefs to a global space search to classify the optimum region. The models conveyed are exactly demonstrated utilizing Eqs. (12) to (14).

Here,denotes the location of prey for thenorthern goshawk,refers to the value of an OF,represents a randomly generated natural number in the rangerepresents the novel location for thedeveloped solution,signifies itsdimension,denotes the value of OF dependent upon the initial stage of NGO,refers to the arbitrarily formed number in the interval of, andspecifies randomly generated number within 1 or 2., andrefers to the randomly produced values employed to make arbitrary NGO performance in the hunt and upgrade.

Once the northern goshawk assaults the target, the prey attempts to escape. So, in a chase and escape procedure, the northern goshawk endures to hunt prey. Owing to the higher velocity, they can hunt their target in any condition and finally chase. The imitation of this conduct upsurges the exploitation influence of the model in searching for locals. In the projected NGO model, it is highly expected that this search was secure to an attack location with a radius. The models stated are exactly demonstrated utilizing Eqs. (15–17).

whereindenotes the highest iteration count,states the iterations count,represents the novel position fordeveloped solution,specifies thedimension,indicates the value of an OF.

Once every population follower is upgraded, dependent upon the 1stand 2ndstages of the NGO model, an iteration is finished, and the novel population member’s values, a function of objective, and the finest solution are defined. Then, the model arrives at the subsequent iteration, and the population member’s upgrade depends on Eqs. (12) to (17) till the preceding iteration of the model was achieved. Afterwards, the execution of NGO, the finest projected solution acquired throughout the iteration, is presented as a quasi‐optimum solution for the assumed optimizer issue. Algorithm 1 demonstrates the NGO method.

The NGO method originates from a fitness function (FF) to boost classification performance. It designates a positive number to indicate the higher execution of the candidate outcomes. During this work, the minimizer of the classification error rate is determined as FF is given in Eq. (18).

In this part, the experimental validation of the NGOAI-ANER approach is examined under the DarNERcorp dataset32. The dataset contains 9130 records under four classes, as exposed in Table1.

Figure4defines the classification results of the NGOAI-ANER technique on 80%:20% of TRAS/TESS. Figures4a, b illustrates the confusion matrices produced by the NGOAI-ANER technique. The results demonstrate that the NGOAI-ANER method accurately detects and precisely distinguishes all four classes. Afterwards, Fig.4c establishes the PR curve of the NGOAI-ANER methodology. The figure shows that the NGOAI-ANER method enlarged the highest PR performance in every class. However, Fig.4d determines the ROC of the NGOAI-ANER method. The figure displays that the NGOAI-ANER method has produced accomplished solutions with the most significant value of ROC at different class labels.

80%:20% of TRAS/TESS (a–b) confusion matrices and (c–d) PR and ROC curves.

NER analysis of NGOAI-ANER approach at 80%TRAS and 20%TESS.

Average of NGOAI-ANER method at 80%:20% of TRAS/TESS.

The performance of the NGOAI-ANER technique is provided in Fig.6in the training(TRAAC) and validation(VALAC) outcomes of 80%:20% of TRAS/TESS. The results illustrate useful clarification into the behaviour of the NGOAI-ANER technique across numerous epochs, representing its learning method and generalization data. The outcome substantially improved from the TRAAC and VALAC, with epoch growth. It safeguards the NGOAI-ANER technique in the pattern identification process on both data. The increasing trend in VALAC reviews the skill of the NGOAI-ANER model in explaining the TRA data and shining in presenting an accurate classifier of unseen data.

Figure7reveals a comprehensive analysis of the training loss (TRALS) and validation loss (VALLS) curves of the NGOAI-ANER methodology at dissimilar epochs 80:20 of TRAS/TESS. The gradual decrease in TRALS highlights the NGOAI-ANER methodology, improving the weights and reducing the identification error on both data. The result specifies a strong knowledge of the NGOAI-ANER approach linked with the TRA data, underlining its proficiency in seizing patterns in both data. Noticeably, the NGOAI-ANER approach frequently improves its parameters in decreasing the alterations among the prediction and real TRA classes.

Loss curve of NGOAI-ANER model at 80%TRAS:20%TESS.

Figure8exhibits the classification results of the NGOAI-ANER method at 70%:30% of TRAS/TESS. Figures8a, b portrays the confusion matrix presented by the NGOAI-ANER method. The figure shows that the NGOAI-ANER method is familiar and considers every four classes exactly. Similarly, Fig.8c exposes the PR research of the NGOAI-ANER method. The result defined that the NGOAI-ANER method has the maximum PR solution under four classes. However, Fig.8d exemplifies the ROC curve of the NGOAI-ANER model. The figure shows that the NGOAI-ANER model has achieved adept results with peak values of ROC in separate classes.

70%:30% of TRAS/TESS (a–b) confusion matrices and (c–d) PR and ROC curves.

NER analysis of NGOAI-ANER approach at 70%TRAS:30%TESS.

Average of NGOAI-ANER approach under 70%TRAS and 30%TESS.

The performance of the NGOAI-ANER is presented in Fig.10under the technique of TRAAC and VALAC outcomes 70:30 of TRAS/TESS. The outcome exhibits valuable clarification into the behaviour of the NGOAI-ANER model over various epochs, representing its learning method and generalization data. Unusually, the outcome achieves a solid development in the TRAAC and VALAC with progress in epoch counts. It verifies the NGOAI-ANER technique from the pattern recognition procedure on both data. The growing tendency in VALAC summarizes the NGOAI-ANER model’s capability to explain the TRA data and precisely identify unnoticed data.

curve of NGOAI-ANER approach at 70%:30% of TRAS/TESS.

Figure11establishes a comprehensive investigation of the TRALS and VALLS results of the NGOAI-ANER model over discrete epochs of 70%:30% of TRAS/TESS. The advanced decrease in TRALS highlights the NGOAI-ANER methodology, enhancing the weights and decreasing the identification error on both data. The outcome directs an explicit consideration into the NGOAI-ANER approach suggestion with the TRAS, emphasizing its capability to take patterns within both data. Significantly, the NGOAI-ANER model frequently recovers its parameters in decreasing the variances among the real and forecast TRA classes.

Loss curve of NGOAI-ANER approach at 70%:30% of TRAS/TESS.

In Table4and Fig.12, the final comparison outcome of the NGOAI-ANER method is illustrated33,34. The NGOAI-ANER model attained anof 97.86%,of 95.52%,of 95.51%, and anof 95.52%, significantly outperforming the other models. The BERT-BGRU model exhibited anof 90.46%,of 90.40%,of 90.66%, and anof 90.51%. The BRNN-ANER model achieved anof 94.94%,of 87.73%,of 86.51%, and anof 87.12%. Meanwhile, the AraBERT model illustrated anof 92.76%,of 86.99%,of 87.37%, and anof 84.20%. The CNN model achieved anof 93.29%,of 85.28%,of 85.62%, and anof 85.10%, and the GRU model attained anof 91.05%,of 85.09%,of 85.36%, and anof 85.16%. These results highlight the superiority of the NGOAI-ANER model in presenting higher,,, andfor improved NER performance.

Comparative result of NGOAI-ANER technique with existing models.

Comparative analysis of NGOAI-ANER technique with existing models.

Table5and Fig.13demonstrate the ablation study of the NGOAI-ANER method with existing techniques. The NGOAI-ANER method exhibits superior performance across all evaluation metrics with anof 97.86%,of 95.52%,of 95.51%, andof 95.52%, indicating its robust capability in handling the classification task effectively. The SALSTM model also exhibits competitive results with anof 97.35%,of 94.80%,of 94.88%, andof 94.85%, exhibiting its strength in capturing sequential dependencies. Meanwhile, the NGO-based method depicts robust performance with anof 96.65%,of 94.17%,of 94.30%, andof 94.17%, highlighting the value of its optimization strategy. Overall, the NGOAI-ANER model outperforms both SALSTM and NGO techniques.

Result analysis of the ablation study of the NGOAI-ANER method.

Result analysis of the ablation study of the NGOAI-ANER method.

Table6and Fig.14depict the error analysis of the NGOAI-ANER approach with existing models. The error analysis reveals that the NGOAI-ANER approach exhibits the lowest error rates across all metrics, with anerror of 2.14%,error of 4.48%,error of 4.49%, anderror of 4.48%, indicating its robustness and reliability. The BERT-BGRU model exhibits higher error margins with 9.54%error, 9.60%error, 9.34%error, and 9.49%error. The BRNN-ANER model attains 5.06% inerror, 12.27% in, 13.49% in, and 12.88% in, illustrating greater inconsistencies. AraBERT exhibits a 7.24%error, 13.01% in, 12.63% in, and a notably high 15.80%error. The CNN model has a 6.71% error in, 14.72% in, 14.38% in, and 14.90% in. Meanwhile, the GRU model depicts 8.95%error, 14.91%, 14.64%, and 14.84%. These figures emphasize the consistent and minimal error of the NGOAI-ANER model compared to existing techniques.

Error analysis of the NGOAI-ANER methodology with existing techniques.

Error analysis of the NGOAI-ANER methodology with existing techniques.

This work introduces a novel NGOAI-ANER technique in the Moroccan dialect. The NGOAI-ANER technique aims to enhance the precision and efficiency of NER models for Arabic text. To achieve that, the NGOAI-ANER technique contains various procedures, namely word embedding, SALSTM-based classification, and hyperparameter tuning. Initially, the NGOAI-ANER technique begins with word embedding techniques to transform the text into dense vector representations, capturing semantic information crucial for NER tasks. Moreover, the SALSTM model is trained on the embedded data, utilizing the merits of DL architectures to identify named entities within Arabic text accurately. The NGOAI-ANER approach utilizes the NGO model to fine-tune hyperparameters effectively to optimize the solution of the DL method. An experimental assessment of the DarNERcorp dataset demonstrates the efficacy and scalability of the NGOAI-ANER model. The experimentation of the NGOAI-ANER model demonstrated a superior accuracy value of 97.86% over existing approaches.

The authors extend their appreciation to the Deanship of Research and Graduate Studies at King Khalid University for funding this work through Large Research Project under grant number RGP2/231/46. Princess Nourah bint Abdulrahman University Researchers Supporting Project number (PNURSP2025R708), Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia. Ongoing Research Funding program, (ORF-2025-714), King Saud University, Riyadh, Saudi Arabia. The authors extend their appreciation to the Deanship of Scientific Research at Northern Border University, Arar, KSA for funding this research work through the project number “NBU-FFR-2025-2913-02. The authors are thankful to the Deanship of Graduate Studies and Scientific Research at University of Bisha for supporting this work through the Fast-Track Research Support Program.