RNA sequencing (RNA-seq) is a widely used method in transcriptomics research, offering insights into gene expression, variant discovery, and, when deconvoluted, the cellular composition of complex tissues. However, existing RNA-seq pipelines frequently emphasize gene expression analysis and often lack cell deconvolution and variant calling. To address these limitations, we present RnaXtract, a comprehensive and user-friendly pipeline designed to maximize extraction of valuable information from bulk RNA-seq data. RnaXtract automates an entire workflow, encompassing quality control, gene expression quantification, variant calling, and the cell-type deconvolution. Built on the Snakemake framework, RnaXtract ensures robust reproducibility, efficient resource management, and flexibility to adapt to diverse research needs. The pipeline integrates state-of-the-art tools, from quality control to the new updates on variant calling and cell-type deconvolution tools such as EcoTyper and CIBERSORTx, enabling researchers to extract biological insights with precision. By providing an end-to-end solution for bulk RNA-seq, RnaXtract addresses critical gaps in existing workflows, empowering researchers to explore gene expression, genetic variation, and cellular heterogeneity within a single cohesive framework.

Despite the emergence of new technologies, such as single-cell and spatial transcriptomics, bulk RNA sequencing (RNA-seq) remains the most widely employed due to its cost-effectiveness in providing a comprehensive tissue overview1. Consequently, short-read sequencing technologies, which typically produce tens of millions of reads per sample, are the predominant methods for gene expression profiling2. The widespread adoption of bulk RNA sequencing has led to the development of standardized workflows for data analysis. These workflows typically begin with quality control, assessing the quality and accuracy of bases in each read, followed by a trimming step to remove low-quality reads3,4. The subsequent step involves mapping the reads to a reference genome or transcriptome, which is used for gene expression quantification by counting the reads mapped to each gene5,6. This alignment also facilitates variant calling, allowing for the identification of individual-specific mutations7,8. The extensive use and standardization of these methods have resulted in numerous analytical pipelines9.

The advent of single-cell sequencing has provided new insights into cellular composition and characterization, opening the opportunity for analyzing tissue composition and its differentiation under various conditions10. Single-cell transcriptomics is usable to deconvolute bulk RNA-seq to estimate cellular composition of the tissue and their specific states11,12. However, these methods are relatively new, and not included in existing bulk RNA-seq analysis pipelines. Additionally, many of these pipelines are optimized for gene expression analysis and do not align with current gold-standard methods for variant calling (Table1).

Comparative analysis of RnaXtract and other RNA-Seq processing pipelines.

Table placing RnaXtract in the various RNA-seq analysis tools in performing three key tasks: gene expression, variant calling, and cell deconvolution.

With the quantity of data generated from bulk RNA sequencing, machine learning (ML) methods are used for biomarker discovery, enabling the identification of molecular signatures that correlate with specific conditions or therapeutic responses13,14. Consequently, its use is becoming prevalent in biological analyses to identify significant genes, pathways and disease mechanisms14,15. However, many current pipelines are not optimized for ML integration. This often necessitates data transformation by the user, which can be burdensome and may deter biologists from using these types of tools.

In this study, we present RnaXtract, a complete workflow designed to maximize extraction of the information contained in RNA-Seq data. RnaXtract not only generates the conventional normalized gene expression matrix but also performs state-of-the-art variant calling analysis and cellular deconvolution using CIBERSORTx and its extension, EcoTyper11,16. This cellular composition analysis provides an additional layer of feature extraction beyond genomics and gene expression.

The complete pipeline was developed using Snakemake, a Python-based workflow definition language, due to its efficiency, scalability, and ease of use17. Snakemake facilitates seamless workflow management and reproducibility in bioinformatics analyses. To ensure long-term reproducibility, all tools and environments were containerized using Singularity images18. A script was created to simplify the generation of a config.yml file to manage user interactions. Running RnaXtract requires four dependencies: R (v3.6.0)19, Snakemake17, Python320, and a container runtime engine: Singularity. The list of Docker containers utilized by RnaXtract is provided in Supplementary Table.S1.

RnaXtract is structured into four modules: preprocessing with quality control, gene expression analysis, cell deconvolution and variant calling with an optional recalibration step for variant calling (Fig.1).

RnaXtract workflow. Overview of the RNA-seq analysis pipeline, including quality control, pre-processing, variant calling, gene expression quantification, and cell deconvolution. The workflow begins with quality control using FastQC and MultiQC, generating a quality report. Pre-processing includes trimming and preparing FASTQ files. Variant calling involves alignment (STAR), deduplication (Picard), read splitting, and read group addition (GATK), followed by base quality score recalibration (BQSR) and variant identification using HaplotypeCaller and GenotypeGVCFs. Gene expression analysis is performed using Kallisto for quantification and subsequent formatting with the r-rnaseq package, generating gene count and TPM tables. Cell deconvolution is conducted with EcoTyper for ecotype analysis and CIBERSORTx for cell type abundance estimation. Final outputs include tables summarizing gene expression, variant calls, and inferred cell type compositions.

Initially, raw sequences are inputted into the workflow, and fastp (v0.20.0)4is employed to perform quality trimming and filtering of reads, utilizing default parameters for window size, mean quality, and length. Subsequently, FastQC (v0.11.5) generates a quality report for each pre-processed read file, and MultiQC (v0.11.5) compiles a comprehensive report across all samples. Following quality control, alignment is conducted using STAR (v2.7.2b)6against a reference genome (or transcriptome), which is essential for variant calling. For the gene expression quantification Kallisto (v0.48.0)21was chosen as it is the quickest tool for this step while having equivalent quality to its concurrents22.

Genomic variants can be inferred from RNA data through variant calling. Due to the number of intermediate steps carried out during this process, it was encapsulated in an independent sub-workflow run at sample level. The input data consists of the alignments generated with STAR and the output is a list of variants in the variant call format (VCF) and a table format file. The whole process is performed using the Genome Analysis ToolKit (v4.1.3.0)7,21, and it was designed following the GATK best practices for the variant calling from RNA-Seq data which is the gold standard in the field. The variant calling is done on all the samples together instead of them separately using the “HaplotypeCaller” and “GenotypeGVCFs” functions following GATK and genotyping recommendations23,24. This reduces the direct dependency of the depth and enhances the quality of the mutation identification.

Variants are separated between single nucleotide polymorphism (SNP) and insertion/deletion (INDEL) to be filtered using a hard filter. The filters differ between the two types of variants and were chosen following GATK guidelines. The filtering differences exist because SNPs and INDELs have distinct characteristics, error profiles, and detection challenges. Filtering criteria were tailored to maximize sensitivity and specificity for each type of variant while minimizing false positives from sequencing or alignment artifacts.

A primary challenge in machine learning applications is overfitting, where models capture dataset-specific features rather than generalizable biological signals. To reduce the risk of overfitting when using RnaXtract for downstream machine learning approaches, we implemented a user-defined script to filter variants based on their frequency within the dataset. The output VCFs are then transformed into a table format. This table has as lines the sample identification and as columns the variant which name is composed of: chromosome:position_reference > mutation. The value of the column is represented by the two numbers associated with mutation present at this position separated by an underscore with 0 representing the absence of mutation. Mutations with absence of information for at least one sample at the position of the mutation were removed. Also, a possibility to exclude variants based on a threshold of presence in the cohort was added.

The use of Transcripts per Million (TPM) was chosen as a normalization method for gene expression data. TPM accounts for both sequencing depth and gene length, ensuring comparability across samples by normalizing gene expression values relative to the total transcript count. This normalization method is essential for building machine learning models, as it enhances the model’s ability to generalize and reduces its susceptibility to batch effects. In addition, the cell deconvolution step in the pipeline required TPM, as it is one of the two input formats supported by EcoTyper and CIBERSORTx.

The cell deconvolution is achieved through the utilization of EcoTyper, a tool specifically designed to decode cellular heterogeneity within bulk RNA-seq data. EcoTyper is a pre-trained deep learning tool capable of estimating the cell composition and states which compose the ecotype of the bulk sample. Moreover, in the case that the user possesses their own single-cell RNA-seq datasets as reference, another step using CIBERSORTx was added. CIBERSORTx enables the creation of custom signature matrices from single-cell data, thereby improving the accuracy of cell type quantification and functional analysis. CIBERSORTx has been shown to be one of the best tools for deconvolution25and its extension offers a pre-trained model for cancer research which enhances its granularity by going into cell ecotypes. The combined use of EcoTyper and CIBERSORTx provides insight on the cellular landscapes in bulk RNA-seq datasets.

RnaXtract is mostly oriented for the analysis of human transcriptomic data. However, it can be used for other species that possess both a reference genome and transcriptome, with only minor adjustments, primarily the selection of appropriate reference annotations and, when relevant, species-specific single-cell reference datasets. For cell deconvolution, CIBERSORTx has demonstrated utility across multiple organisms26–28. There are certain limitations in the use of EcoTyper, as its models were trained on human single-cell data. However, an option was included for users to apply EcoTyper if they supply a conversion table mapping their organism’s cell types to corresponding human counterparts.

To evaluate RnaXtract’s ability to extract relevant data, we analyzed human breast cancer samples collected pre-chemotherapy to identify biomarkers predictive of treatment failure using machine learning. We selected 24 tumor samples from the European Nucleotide Archive project PRJNA100459329(Supplementary Table S2). These samples included 12 patients who succeeded and 12 who failed the post-neoadjuvant chemotherapy. A random selection of 2,000 cells from a breast cancer single-cell dataset, available at CELLxGENE30,31, were used to create the reference for CIBERSORTx. For the variant analysis, a threshold of 0.1 was applied, retaining only those variants present in at least 10% of the cohort.

A gene expression table in TPM format, SNP and INDEL tables, and custom-generated cell composition and ecotype data were generated. These outputs were used to develop individual models with BioDiscML32, a machine learning tool capable of identifying biomarkers. The most relevant features were combined to create a final model combining accuracy and optimal feature usage.

Multiple models predicting chemotherapy success were derived with varying model performance. A broad range of Matthews Correlation Coefficient (MCC) scores were observed with the lowest for the EcoTyper deconvolution model (MCC = 0.029, 4 features) and the highest for the Gene Expression model (MCC = 0.762, 75 features). Integrating all four data types allowed us to reduce the number of features while building a high quality model. This integrated model achieved an MCC of 0.737—comparable to the Gene Expression model—but significantly lowering the standard deviation (STD) from 0.287 to 0.042 and requiring only 2 features (Fig.2): a mutation within the 3’UTR of Syntaxin-16 (STX16) and the RNA level of ELMO Domain Containing 1 (ELMOD1).

Quality of machine learning model. (a) Comparison of the number of selected features and (b) model performance measured by the Matthews Correlation Coefficient (MCC) across different feature sets. The “Merged” model, which integrates all data types, demonstrates a reduced number of features compared to the “Expression” model while maintaining a high MCC. Additionally, the STD (error bars) in MCC is lower in the “Merged” model compared to individual models, indicating increased stability and robustness. This suggests that integrating multiple data sources improves classification performance while reducing feature redundancy and variability.

STX16is primarily involved in intracellular transport, particularly within the endosomal and Golgi apparatus pathways. It has been reported to be overexpressed in cervical cancer33, and data from The Cancer Genome Atlas Breast Invasive Carcinoma suggest that patients withSTX16amplification exhibit poorer disease-free survival (Supplementary Fig. 1). Mutations affecting the 3’UTR could impact mRNA stability, potentially enhancing cancer cell survival. In our cohort, although no consistent pattern was observed between the number of adenine repeats in the STX16-associated variant and its expression level, patients who experienced treatment failure consistently displayed higher STX16 expression compared to those who responded well (Fig.3a). This observation aligns with our initial hypothesis that elevated STX16 expression may be linked to poor outcomes.

Interpretation of features from the machine learning model. (a) Mean STX16 expression (TPM) grouped by haplotype, with bars colored according to treatment outcome (green: success; red: failure). (b) ELMOD1 expression levels (TPM) ordered by individual patients and stratified by treatment outcome. Each bar represents a single patient.

Similarly,ELMOD1is a GTPase-activating protein for the Arf family of small G proteins34, playing a key role in cellular signaling regulation. Recent studies indicate thatELMOD1andELMOD2are upregulated in breast cancer cell lines and are essential for cancer cell migration35. LowELMOD1RNA expression may suggest reduced cancer cell migration and an improved likelihood of treatment success as seen in the cohort (Fig.3b).

This example highlights RnaXtract’s effectiveness in multi-layered biomarker analysis for cancer research, offering a comprehensive and automated tool for RNA-seq data extraction with applications in machine learning. However, it is important to note that the chemotherapy response prediction model presented here is based on a limited sample size (n = 24). Further validation on larger, independent datasets will be necessary to confirm the predictive value. It has to be noted that it’s the same patient which has results indicating a failure but had the treatment succeeding, showing the heterogeneity in data and the need to be careful with these models.

To assess the performance and resource utilization of the RnaXtract pipeline, we conducted analyses on multiple human datasets with diverse characteristics, encompassing a total of 30 samples derived from two distinct datasets (24 paired-end and 6 single-end)29,36. The pipeline was executed on an AMD EPYC 7601 32-Core Processor37, utilizing the default core configuration specified by the pipeline. Initial evaluations revealed that the variant calling step was the most computationally intensive, requiring an average of 29 h of CPU time (Fig.4a). Subsequent steps, including dataset integration, genotyping, and variant filtration, each consumed approximately 10 h of CPU time and demonstrated potential for parallelization. In contrast, EcoTyper and CIBERSORTx exhibited significantly lower computational demands, completing within 20 min of CPU time, with EcoTyper further benefiting from multi-threaded execution. The RNA-seq function, which processes Kallisto output into tabular format, was the least resource-intensive, completing in under 2 min.

RnaXtract performance results. (a) The barplot illustrates the comparison of data processing steps for paired-end and single-end sequencing data. The y-axis represents the CPU-times in minutes while the x-axis denotes the different steps involved in multi-samples RnaXtract’s steps. Two distinct data sets were used: the breast cancer SRA cohort, paired-end (dark grey) and a cohort using single-end sequencing (white). The bars for each step show the average performance with the standard deviation. (b) Maximum memory usage (in MB), measured as peak Resident Set Size (RSS), for pipeline executions with 40 and 100 CPU cores across datasets of 10, 24, and 50 samples.

To characterize memory usage during the most demanding step of the pipeline, we benchmarked RnaXtract on the PRJNA1004593 dataset of increasing the number of samples (10, 25, and 50), using either 40 or 100 CPU cores with smem tool. A peak memory consumption was measured using Resident Set Size (RSS), which reflects the actual physical memory held in RAM during execution (Fig.4b). Memory usage scaled with the number of samples and was consistently higher with 100 cores, due to greater parallelism and concurrent memory allocation. At the largest scale (50 samples), maximum RSS exceeded 125 GB with 100 cores, compared to under 100 GB with 40 cores. These results show a linear correlation between the number of CPUs and samples for the memory usage. The step which consumed the most memory was HaplotypeCaller.

In order to evaluate the place of RnaXtract within the field of bulk RNA-seq data processing, we compiled a list of pipelines published after 2020 (Table1). Six pipelines were selected as they were specialized for bulk RNA-seq and were taking as input raw FASTQ files: MIGNON9, Latch38, RNAflow39, SPEAQeasy40, sequana_rnaseq41, and GenPipes RNA42. A key observation is that most of these pipelines primarily focus on differential gene expression analysis, with only two (MIGNON and SPEAQeasy) supporting variant calling. This highlights that RnaXtract will operate in a distinct niche compared to existing tools. The primary objective of RnaXtract is to maximize the extraction of raw information from bulk RNA sequencing, offering outputs such as gene expression, variant calling, and novel cell deconvolution in a format that is easily accessible for machine learning applications. Notably, the other tools performing variant calling present variants in VCF format, which is less suited for downstream machine learning applications.

RnaXtract provides an automated RNA-seq data analysis workflow, transforming raw sequencing reads into structured, machine learning-compatible datasets. It offers a robust framework for extracting genomic, transcriptomic, and cellular composition data efficiently. Leveraging state-of-the-art methods for read processing, RnaXtract integrates the CIBERSORTx/EcoTyper deep learning model to deliver detailed cellular and ecotype profiling of samples. This makes it highly applicable for advancing personalized medicine, particularly in predicting cancer trajectories, due to its machine learning-compatible output format. Furthermore, RnaXtract can be deployed seamlessly across diverse computational environments, ensuring optimized resource utilization. Its modular architecture facilitates straightforward upgrades and maintenance, enhancing adaptability for evolving research needs.

We thank all lab members for many interesting discussions. This work was supported by the Fonds de recherche du Québec (FRQ) through the research centre grant for the CHU de Québec-Université Laval Research Center (reference: 30641).