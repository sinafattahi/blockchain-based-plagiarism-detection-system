Contextual factors, or determinants, are commonly assessed in implementation studies due to their impact on the implementation process. While a substantial number of determinants have been identified, less research has examined the strength of their impact on the implementation process. Identification of key determinants, or those found to play the biggest role in the implementation process more frequently, may assist in guiding implementation of health programs and services. Damschroder & Lowery (2013) developed a rating system to assess which Consolidated Framework for Implementation Research (CFIR) constructs have the strongest impact on implementation. The purpose of this article was to systematically review articles that have utilized this rating system in order to identify key determinants.

We conducted forward citation searching of articles citing Damschroder & Lowery’s (2013) rating criteria in three databases (PubMed, Web of Science, and Google Scholar) in February 2023. Included articles examined the magnitude and valence of factors affecting the implementation process. Quality appraisal was completed using the Mixed Methods Appraisal Tool (MMAT). Articles were included regardless of design, setting, location, or target population. A comprehensive examination of the determinants through numerous graphs and tables was conducted to identify key determinants.

Forty-eight articles were included in the final review. Eight key determinants were identified: Leadership Engagement, Formally Appointed Internal Implementation Leaders, Compatibility, Available Resources, External Change Agents, Champions, Relative Advantage, and Key Stakeholders.

A more systematic approach to guiding implementation efforts will lead to the development of effective implementation strategies that could ultimately improve implementation outcomes. While quantifying qualitative data inherently removes some important nuance, by identifying key determinants, we hope to help researchers and practitioners identify which factors are likely to facilitate success of their implementation efforts.

The protocol for this systematic review was published with PROSPERO (CRD42023416340).

The online version contains supplementary material available at 10.1186/s43058-025-00712-1.

There are a number of factors known to impact the implementation process. No project can account for all these factors. However, it can be difficult to decide which to focus on or which are most important.

A systematic assessment of which factors most commonly have the largest impact on the implementation process would be helpful in guiding future projects.

This review examines articles that have rated the impact of factors affecting the implementation process. It identified eight key factors that most commonly have the largest impact on the implementation process.

Review findings provide guidance for both researchers and practitioners to streamline implementation projects and assist in the selection of implementation strategies.

Implementation science examines and tests methods to successfully integrate and sustain health programs and interventions into routine practice [1]. This process is greatly impacted by contextual factors, such as funding, resources, and individuals’ perceptions of the intervention. Consequently, a focal point in implementation research has been on contextual factors, often referred to as determinants (barriers and facilitators), that affect the implementation process. Over the past few decades, our knowledge surrounding the implementation process and common barriers and facilitators to implementation has grown exponentially. Researchers have identified a wide range of determinants operating at multiple levels (individual, organizational, and community level) that affect the implementation process, and in turn, implementation outcomes [2,3]. Several frameworks have been developed to identify, organize, and define these determinants with the goal of understanding and guiding the implementation process [4–6]. One of the most commonly cited determinant frameworks is the Consolidated Framework for Implementation Research (CFIR), first created in 2009 and recently updated in 2022, [7,8] which currently includes 48 specific constructs and 19 subconstructs under five domains: Innovation, Outer Setting, Inner Setting, Individuals, and Implementation Process [8].

Historically, most of the research on the implementation process been context specific, focusing on how determinants impact the implementation of individual projects and often utilizing qualitative methods to describe those processes. While this research on the implementation processes has provided valuable insight into the relevance certain determinants play throughout the implementation process, there has been a notable lack of research comparing the relevance and/or strength of particular determinants across programs [9]. As such, there is a pressing need to systematically specify which determinants have the greatest impact on implementation processes across projects and programs. Identifying these key determinants would mark an important step toward clarifying how determinants affect implementation outcomes.

Recently, more systematic reviews have been done examining the frequency with which different barriers to, and facilitators of the implementation process are assessed and/or found in different fields and/or target populations [10–17]. For the most part, these reviews have focused on simply listing and organizing determinants, without examining the strength or impact of certain barriers or facilitators. While it is valuable to investigate how frequently a particular determinant is noted in implementation efforts, it is also important to know how much of an impact that factor had throughout the process or relative to other factors. For example, leadership engagement is commonly noted as a factor affecting the implementation process. Yet, its effect on the implementation process could be minor or monumental.

Another problem facing the field is that the sheer number of potential determinants can be overwhelming to track, and it is often difficult for researchers to decide on which are likely to be most relevant to their implementation efforts. For example, when working with the CFIR framework, researchers are faced with the prospect of 48 constructs and 19 subconstructs. As one study could not possibly account for all these factors, researchers and stakeholders must focus on those deemed most salient. Yet, given the complexity of implementation research, with multiple stakeholders and varying perspectives, deciding which are most salient can be challenging. For example, Possemato et al. [18] had providers and leaders involved with the implementation of a mobile PTSD app rate the three most important CFIR constructs. They found little consensus among the nine stakeholders, such that none of the constructs were rated in the top three by more than two stakeholders [18]. The current ambiguity about what matters most in the implementation process is a major obstacle to progress in the field of implementation science. While a uniform consensus is likely not feasible, identification of key determinants, or those found to play the biggest role in the implementation process most frequently, may assist researchers and practitioners in setting their priorities, investing their resources, and tracking their implementation activities, hopefully leading to more efficiency.

To address this issue, Damschroder & Lowery [19] developed a rating system to assess which CFIR constructs (from the original 2009 CFIR) have the strongest impact on implementation. This rating system allows researchers to quantify qualitative data, identifying the valence (positive or negative effect) and magnitude (strength of effect) of determinants, ranging from −2 (major barrier) to + 2 (major facilitator) (see Table1for summary of rating criteria) [19]. These scores were then used to understand differences between high and low implementation effectiveness sites. Damschroder & Lowery [19] found that of the 31 CFIR constructs assessed, 10 strongly distinguished between low and high implementation effectiveness sites: Relative Advantage, Patient Needs and Resources, Networks and Communications, Tension for Change, Relative Priority, Goals and Feedback, Learning Climate, Leadership Engagement, Planning, and Reflecting and Evaluating.

While this rating system has been used for a decade, no systematic review of these key determinants across studies has been published. To further develop implementation science, there is a need to systematically identify key determinants that have been found to have the greatest impact on the implementation process. As such, this review was conducted to systematically clarify which CFIR constructs have the strongest and most consistent impact on the implementation process.

We conducted a systematic review of articles that used the Damschroder & Lowery [19] rating scale. We applied the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) 2020 guidelines for organizing and reporting our results (see Additional file 4) [20,21]. Details of the protocol for this systematic review were registered on PROSPERO (CRD42023416340) and can be accessed athttps://www.crd.york.ac.uk/prospero/display_record.php?RecordID=416340.

We included all studies that utilized the Damschroder & Lowery [19] rating scale to examine the magnitude and valence of factors affecting the implementation process. Studies were included regardless of design, setting (e.g., clinical, community, educational), location (e.g., inside or outside US), or target population (e.g., adolescents, adults). Table2provides a more detailed inclusion and exclusion criteria.

We used PubMed, Web of Science, and Google Scholar to search for possible articles. Other databases were initially examined (e.g., EMBASE, EBSCO, PsycINFO) but they did not identify many articles, and none of the articles were unique from the three databases utilized. Forward citation searching of Damschroder & Lowery [19] was conducted in February 2023 to identify relevant articles [22]. This approach was chosen in favor of the more traditional keyword search query for a number of reasons. First, during a preliminary, non-systematic review of articles that utilized the rating system, it was noted that it was often impossible to know the rating system was used just from scanning the title and abstract. In addition, different terms were used to note utilization of the rating system (e.g., quantification of qualitative data) and sometimes no term was used at all. Thus, traditional keyword searches would require full-text review of all implementation articles to not miss relevant articles. Due to those issues and the fact that articles using/adapting the Damschroder & Lowery [19] article should have cited the article, forward citation searching was conducted to identify relevant articles more efficiently. While it is possible that this approach may have missed articles that did not cite the original Damschroder & Lowery [19] rating system, in alternative pilot search strategies, we did not find any such articles.

Articles were reviewed and data extracted by the first author and verified by the second author, both of whom are PhD prepared public health researchers with experience conducting systematic reviews. The initial forward citation search yielded 1059 articles (254 PubMed; 268 Web of Science; 537 Google Scholar). Prior to the title and abstract screening, 513 duplicates were removed and four were marked as ineligible by automation tools in EndNote. Then, 542 articles were screened based on their title and abstract. Any article that clearly examined the role of determinants—barriers and facilitators—was retained for full-text screening. Three-hundred and fifty articles were excluded during the title and abstract review, leaving 192 articles retrieved for full-text screening. Of the 192 articles, 144 were excluded during full-text screening. In total, 48 articles met the inclusion and exclusion criteria and were included in this review. The flow of this search and reasons for exclusion is presented in Fig.1.

For the 48 articles included, two spreadsheets were created to extract relevant data. The first spreadsheet included: Full citation, setting, program/intervention, type of data collected (e.g., semi-structured interviews, focus groups), level of data collection (e.g., staff, administrators, patients, etc.), phase of implementation data collected (if mentioned), rating language used (e.g., ‘ratings,’ ‘rank degree of influence,’ ‘quantification of qualitative data’), and brief notes on the data provided (e.g., number of participants, how data organized, any adaptations made).

The second spreadsheet included all CFIR constructs in separate columns and the rating scores from each article were entered in rows (See Additional file 3). As this review was conducted in early 2023, shortly after the updated CFIR framework was published, all articles used the original 2009 CFIR framework in their analysis. Therefore, the results are synthesized using the original CFIR framework [7]. A data extraction protocol was developed to ensure consistency across studies. For each article, the rating of each construct (−2, −1, 0, 1, 2) was added. If articles included a ‘mixed’ rating (sometimes donated as ‘M’ or ‘X’ or ‘*’), this category was combined with the ‘0’ category. Combining ‘0’ and ‘mixed’ was done to align with Damschroder & Lowery [19] rating criteria of constructs that have a neutral influence (interviewees contradict each other,there are positive and negative influence that balance each other out or overall produce a neutral effect). When scores were aggregated by site or outcome (e.g., high implementation sites), the scores from each stratum were included. Therefore, many articles had multiple lines of ratings. Some articles included inductive or study-specific codes. In such instances, definitions were closely examined and entered into a relevant CFIR code if possible. If no relevant CFIR code was found, they were not included. The CFIR construct ‘complexity’ was often reverse-coded, for this review it would be corrected so it was not reverse-coded.

The Mixed Methods Appraisal Tool (MMAT) version 2018 was used to assess the methodological quality of the included articles [23]. The MMAT was chosen as articles in this review included both qualitative and mixed methods studies and the MMAT allows for the assessment of quality and bias across multiple study designs [23]. Two reviewers independently reviewed half of the articles. Discrepancies were discussed and resolved through discussion of the original articles and team discussion (including a third reviewer). The remaining articles were reviewed by one reviewer, consulting with the larger team if any uncertainties arose. In addition, each article was checked to verify whether the Damschroder & Lowery [19] rating scale was used with minimal adaptations to the rating criteria. ‘Minimal adaptations’ was defined as changes to the qualitative rating criteria definitions from Damschroder & Lowery [19] that made the criteria more study specific but did not alter the core meaning or essence of each rating criteria. No articles were removed following this check.

Of the 48 included studies, 25 took place outside the United States and 23 took place in the United States. Studies conducted outside the United States were largely from Australia [7], Canada [4], various countries in Africa (Mozambique, Uganda, Burkina Faso, Kenya, Côte d’Ivoire) [4], and various countries in Europe (Norway, Netherlands, Spain, Belgium, Poland, Portugal) [4]. Programs/interventions implemented were diverse, including workplace health promotion programs, various telemedicine programs, weight management programs, and dengue fever control. Most data was collected via semi-structured interviews and/or focus groups though one study had implementation leaders fill out regular ‘diaries’ [24]. It was not always clear at what stage(s) of implementation (pre, during, post) the data was collected. However, the majority of studies collected data during and/or post-implementation (see Additional file 2 for more information on each study).

All articles provided aggregate scores, most frequently by site, thus multiple lines of data were collected from most articles. In total, the 48 articles provided 301 lines of data. Data was collected on 41 constructs in total. This includes the 39 constructs and sub-constructs of the 2009 CFIR framework and two constructs added to the Process domain as sub-constructs of Engaging due to frequent inclusion in articles. Engaging: Participants was used in 12 articles and thus was added to capture engagement of participants. Engaging: Key Stakeholders was used in 16 articles. Of those 16 articles, six did not clearly define what they considered key stakeholders. However, most articles defined key stakeholders as individuals directly impacted by the intervention, such as staff (e.g., Chinman et al., 2017) and/or leaders (e.g., Damschorder et al., 2017). Thus, this construct was added to capture engagement of key stakeholders. To mirror articles included in this review, we broadly define key stakeholders as staff and/or leaders.

Of the 48 included studies, 16 were mixed methods and 32 were qualitative. No articles were found to have any major quality or bias concerns (see Additional file 5).

To develop a comprehensive understanding of these determinants, the data was examined in numerous ways. Graphs and tables were created and compared in eight different ways. We examined how often each determinant was coded: (1) as a major facilitator [+ 2], (2) as a major barrier [−2], (3) as a facilitator [+ 1], (4) as a barrier [−1], (5) as neutral [0], (6) at all, regardless of score, (7) average rating across all studies, and (8) minimum/maximum rating for each determinant. To keep the list of key determinants manageable, and thus useful for researchers, the aim was to identify between five and ten key determinants. This cutoff was also chosen due to the fact that there was commonly a drop off in frequency after the first 8–10 determinants and many of the same determinants were in the top lists regardless of how they were examined. Additional file 1 provides more details on the key determinants identified.

When comparing the determinants in these diverse ways, it was noted that many were consistently appearing in the top eight. Thus, to further refine and identify key determinants, (1) the top eight major determinants overall (rated as either −2 or + 2), (2) the top eight key barriers (rated as −2), and (3) the top eight key facilitators (rated as + 2) were compared (see Additional file 1 for more details). These lists were reviewed and discussed extensively as a team to become exceedingly familiar with the data as to which were consistently appearing as key determinants.

In examining the data, we identified that the four most commonly cited determinants overall (regardless of score) were Leadership Engagement, Available Resources, Formally Appointed Internal Implementation Leaders, and Compatibility. They were also in the top 11 of both key barriers and key facilitators. Three of the four; Leadership Engagement, Formally Appointed Internal Implementation Leaders, and Compatibility, were in the top eight for major barriers (−2) and major facilitators (+ 2). We also noted External Change Agents, Champions, and Relative Advantage were cited overall fifth-seventh most frequently respectively, but much more frequently cited as major facilitators than barriers. Finally, Key Stakeholders was cited eighth most frequently, slightly more frequently as a facilitator than a barrier.

Following our extensive analysis, eight key determinants were identified through this systematic review: Leadership Engagement, Formally Appointed Internal Implementation Leaders, Compatibility, Available Resources, External Change Agents, Champions, Relative Advantage, and Key Stakeholders (Table3). As mentioned in the introduction, to align with other reviews, these eight key determinants can be organized into multi-level factors [2,3]. At the individual level, five key determinants were found: Leadership Engagement, Formally Appointed Internal Implementation Leaders, External Change Agents, Champions, and Key Stakeholders. At the organization level, two key determinants were found: Compatibility and Available Resources. At the intervention level, one determinant was found: Relative Advantage.

The purpose of this systematic review was to identify the determinants that play a key role in the implementation process. This review identified, across a wide range of implementation efforts, which determinants most frequently were identified as playing a major role in implementation. This systematic review is novel in that it examines implementation projects across fields and settings and examines the use of the Damschroder & Lowery [19] rating system, which is used to identify the perceived key determinants of the implementation process. However, it also contributes to the growing number of systematic reviews in the implementation science field. For example, reviews have examined barriers and facilitators of health-focused interventions in vulnerable populations [14], task-sharing mental health programs in low-income countries [15], peer support [17], and stroke care [16]. Across these fields, Leadership Engagement and Available Resources consistently appeared as key determinants, aligning with the findings of this review.

A unique aspect of this rating system, and in turn, this systematic review, is the examination of both valence and magnitude. While valence allows us to see how often certain determinants function as either a barrier, facilitator, or both, magnitude is a critical piece not always included which provides a much more detailed look at the role these determinants play. This allows us to move past purely descriptive studies and identify which constructs influence implementation and in what way. Future studies should prioritize examining both valence and magnitude of these constructs.

Five of the eight key determinants were individual level or ‘people’ focused determinants. This aligns with changes in the updated 2022 CFIR framework, which significantly updated the Characteristics of Individuals domain, by expanding and clarifying the impact of individuals through additional subdomains: ‘Roles’ and ‘Characteristics’ [8]. These updates were meant to reflect the important role individuals play in implementation, specifically who they are (the updated CFIR framework has 9 different roles) and unique characteristics that shape that individuals behavior (the updated CFIR framework has four different characteristics) [8]. The importance of individuals also aligns with Rogers’ Diffusion of Innovations, which orients diffusion as a social process, greatly influenced by communication, networks, and different types of adopters (innovators, early adopters, early majority, late majority, laggards) [25].

Compatibility, an organizational level key determinant, is also a feature of Rogers’ Diffusion of Innovations [25]. Compatibility has been found to be positively correlated with implementation outcomes [5,26,27] and is multi-faceted as a program may be compatible with workflows or systems but not an individuals’ values or perceived needs. Available Resources, the other organizational level determinant, was updated in the 2022 CFIR framework to include three subconstructs: funding, space, and materials and equipment [8]. This added detail emphasizes the importance of resources and specifying the type of resources available (or not) to an implementation project. This higher level of specificity allows for more effective implementation strategies, as well as systematic identification of the influence resources may have on projects.

Relative Advantage, the innovation level key determinant, is also a key feature of Rogers’ Diffusion of Innovations [25]. In the updated 2022 CIFR framework, the Relative Advantage construct only had minor definition changes from focusing broadly on ‘alternative solutions’ in 2009 to ‘other available innovations or current practice’ in 2022 [8]. Among our findings, Relative Advantage was often seen as a major facilitator. For example, in both Ward et al. [28] and Inguane et al., (2022) every site saw the new intervention as advantageous over current or similar clinical models [28,29]. It certainly makes sense that the perceived advantage (or lack thereof) would greatly influence the motivation of individuals and organizations to implement and sustain a proposed new intervention.

It would be useful to assess all the key determinants across different levels of individuals in organizations and throughout the implementation process. This continuous examination will help guide implementation strategies as perceptions change [30,31]. For example, a program may be perceived as compatible or advantageous (Relative Advantage) prior to implementation, but once implementation begins, some providers may struggle implementing and change their perception of the intervention and its fit with their organization. Identifying these varying and changing perceptions quickly would aid implementation efforts greatly.

The key determinants identified fall under three of the five CFIR domains: Inner Setting (Leadership Engagement, Compatibility, Available Resources), Process (Formally Appointed Internal Implementation Leaders, External Change Agents, Champions, Key Stakeholders) and Intervention Characteristics (Relative Advantage). No key determinants came from the Outer Setting or Characteristics of Individuals domain. These two domains appear to be assessed less frequently but the reasoning is not always clear. A common critique of implementation science is that researchers do not clarify or justify the constructs employed in their research [9]. Another critique is that when researchers choose to not assess particular domains, they do not explain the rationale for that choice. Kirk et al. [9] recommended that researchers provide more explanation for the constructs utilized in order to reduce this ambiguity [9]. A brief description of why the chosen constructs were included or excluded would improve our understanding of how researchers gauge the importance (or not) of each determinant. It is possible that Outer Setting constructs are assessed less frequently due to the difficulty in altering their influence. However, while many Outer Setting constructs may be difficult to modify, they are influential in the implementation process and acknowledging and accounting for their impact is important, especially when examining why an implementation project struggled or was unsuccessful. Systematically examining Outer Setting determinants may help guide the field in developing implementation strategies more effective at influencing organizational or system level influences [32]. Our finding that individuals, such as leaders and champions, make such a strong impact is consistent with the changes made to the 2022 updated CFIR framework, as discussed above. These changes were done in part to recognize overlap with constructs in other domains such as Leadership Engagement (Inner Setting domain) and Formally Appointed Internal Implementation Leaders (Process domain), which were also were identified as key determinants in this review [8]. Thus, while no constructs from the Characteristics of Individuals domain were identified in this review, it is likely that the constructs play a significant role, but that the 2009 constructs did not properly capture their impact or may be accounted for in other similar constructs, such as Leadership Engagement.

It is also worth noting that one of the individual level key determinants found, Key Stakeholders, is not in the original 2009 CFIR framework. This was one of two constructs added during this review due to how many articles had cited it as an influence on implementation. However, of those articles that included a ‘Engaging: Key Stakeholders’ construct, just over half (62.5%) clearly defined what was meant by ‘key stakeholders.’ This ambiguity limits a more detailed assessment of the impact of these individuals. While most articles defined Key Stakeholders as leaders and/or individuals providing/executing the program (e.g., Chinman et al., 2017; Damschorder et al., 2017), there still remains ambiguity in what type of leaders (implementation leaders, administration, mid-level leaders, etc.). The 2009 CFIR does have multiple Engaging sub-constructs (e.g., Opinion Leaders, Formally Appointed Internal Implementation Leaders, Champions, External Change Agents) and the 2022 CFIR includes a Roles sub-domain in the Individuals domain which includes: High-Level Leaders, Mid-Level Leaders, Opinion Leaders, Implementation Facilitators, Implementation Leads, Implementation Team Members, Other Implementation Support, Innovation Deliverers, and Innovation Recipients [8]. While this increased level of specification may initially seem daunting, it supports clarity and more systematic assessments of the role each of these individuals play in the implementation process.

This article is novel as it is the first systematic review of an approach to quantifying the impact of CFIR constructs in implementation projects across diverse topics and settings globally. Due to its diverse and global synthesis, the findings are applicable to all implementation projects. While site and project-specific variation will always need to be considered, these eight key determinants will likely routinely appear as influential in implementation projects, and thus merits careful attention.

Nineteen articles were not included in this review because they only examined valence (barrier or facilitator) but not magnitude. We were unable to evaluate magnitude independently as we would need to request original transcripts to gain proper familiarization with the data for accurate rating. Some articles included in this review did not examine all of the CFIR constructs. Other articles examined all of the CFIR constructs but only reported those that were found relevant to the study. However, depending on the level of detail and clarity in the methods and/or results section, this distinction was not always clear. It would be reasonable to assume that constructs deemed not salient for a particular implementation project would not be examined, and thus the constructs that were found not as relevant in this systematic review are in fact not as frequently relevant to implementation projects than other constructs. However, due to the variation in reporting, we are unable to make any definitive statements.

Another limitation is that eight articles excluded from final analysis provided either summed scores or averages instead of aggregate scores. These articles were examined separately as their method obscured proper systematic interpretation. A number of the constructs found to be most commonly influential were the same. In addition, excluding non-English studies may have limited generalizability of findings to certain cultures or contexts. It is also worth noting that while all articles utilized the 2009 CFIR definitions for each determinant, there may be some slight variation from study to study in how researchers conceptualized each determinant. All of these limitations reduced the number of articles that were able to be included in this review. A larger sample size of articles may have improved the generalizability of these findings, however, due to the novel design of this systematic review, it still takes a step towards creating more systematic, directed assistance in implementation efforts.

As a final note, while ratings allow us to look more closely at the impact of specific determinants and their relationship with outcomes, these ratings can gloss over important differences that are only found in qualitative data, which can provide a deeper understanding of how researchers think about the implementation process. While the nuance is likely missed by quantifying the qualitative experience of researchers, quantification allows us to systematically compare determinants, which is necessary to achieve a more organized understanding the implementation process.

This systematic review takes a step towards creating a systematic approach to guiding and evaluating implementation efforts. Identifying key determinants provides a clearer understanding of what factors impact implementation and what factors to consider when designing an implementation project or study. Findings suggest there are eight key determinants – described in Table3– that warrant close attention when implementing public health interventions. While keeping in mind the potential impact of all the determinants found in implementation projects, future researchers and practitioners may benefit from focusing more resources on impacting these eight key determinants. For example, developing and maintaining a diverse implementation team of internal and external individuals may be vital to any projects success. Future systematic assessment of determinants may also help refine current determinant frameworks by developing hierarchies or relational patterns among determinants. Beyond this review of the key determinants, there is also a need for research on implementation strategies to influence these determinants (for example, the use of external facilitators, the use of implementation teams, and developmental of educational materials). For example, the CFIR-ERIC Matching tool has been updated with the new CFIR constructs, however, there remains a high level of heterogeneity which suggests more research is needed to better guide decision-making [30,31]. Focusing on testing implementation strategies to impact these eight key determinants may help focus and expediate future research. As implementation strategies mediate the relationship between determinants and outcomes, effective choice of implementation strategies may help facilitate implementation, sustainment, and in turn, community outcomes.

Additional file 1. Detailed Look at Key Constructs.

Additional file 2. Articles included in systematic review.

Additional file 3. Rating data pulled from articles included in systematic review.

MS led the study design, searches, article review, and data extraction. MH verified article review and data extraction. PF assisted with interpretation, mentored MS throughout, and was a major contributor in writing the manuscript. All authors read and approved the final manuscript.

This work was funded by the Zilber School of Public Health Dissertation Award.