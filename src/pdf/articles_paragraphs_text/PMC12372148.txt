We evaluated the clinical applications of artificial intelligence models in diagnosing corneal diseases, highlighting their performance metrics and clinical potential. A systematic search was conducted for several disease categories: keratoconus (KC), Fuch’s endothelial corneal dystrophy (FECD), infectious keratitis (IK), corneal neuropathy, dry eye disease (DED), and conjunctival diseases. Metrics such as sensitivity, specificity, accuracy, and area under the curve (AUC) were extracted. Across the diseases, convolutional neural networks and other deep learning models frequently achieved or exceeded established diagnostic benchmarks (AUC > 0.90; sensitivity/specificity > 0.85–0.90), with a particularly strong performance for KC and FECD when trained on consistent imaging modalities such as anterior segment optical coherence tomography (AS-OCT). Models for IK and conjunctival diseases showed promise but faced challenges in heterogeneous image quality and limited objective training criteria. DED and tear film models benefited from multimodal data yet lacked direct comparisons with expert clinicians. Despite high diagnostic precision, challenges from heterogeneous data, a lack of standardization in disease definitions, imaging acquisition, and model training remain. The broad implementation of artificial intelligence must address these limitations to improve eye care equity.

Ocular diseases impose a substantial burden of blindness and visual impairment worldwide [1]. Despite the progress in lowering age-adjusted blindness since 1990, population growth, aging, and evolving lifestyles have caused a notable increase in the number of blindness and vision impairment cases. The overwhelming of ophthalmic services has been noted as a major factor behind this rise, marking the need for more efficient methods [2].

Corneal diseases, in particular, are a major contributor to the global burden of eye diseases [3]. Additionally, disorders including dry eye disease (DED), corneal neuropathy, keratoconus (KC), and infectious keratitis (IK) have substantial effects on patients’ quality of life and drive substantial economic costs [2,4,5,6,7,8,9,10,11].

There are a variety of diagnostic methods available for each of these disorders, including slit lamp examinations, various imaging devices such as anterior segment optical coherence tomography (AS-OCT), tear film assessments, in vivo corneal confocal microscopy (IVCM), and microbial cultures [12,13,14,15,16]. However, they are often time-consuming and labor-intensive, requiring precise manual analysis and limiting clinical workflow. Moreover, these approaches also demand trained specialists that are in limited supply, especially in low-resource regions.

The applications and performance of artificial intelligence (AI) have emerged as a promising tool for improving diagnostic dilemmas and addressing the current limitations. Machine learning (ML), a subset of AI, and deep learning (DL), a subset of ML, offer novel and efficient insights. They have been used for enhancing the diagnosis of multiple eye diseases [17,18]. Thus far, various algorithms and models have been developed using existing data, enabling automated segmentation, feature extraction, and predictive analytics on par with highly trained specialists [19,20,21,22,23,24,25,26].

With the continuous advancements in AI technologies, including large language models (LLMs) such as ChatGPT-4.0, becoming more accessible, their integration into clinical practice necessitates ongoing evaluation. While previous studies have explored the applications of AI in corneal disease, many focus on only one or a few corneal conditions. Our study offers a comprehensive overview of several corneal diseases and AI models, allowing for the recognition of patterns between models and diseases. Additionally, we identify the strengths and areas of improvement for this rapidly evolving field.

In this narrative study, a systematic literature search across three databases, using PubMed, Web of Science, and SCOPUS, was performed. All articles published until April 2025 were included in the search. The search strategy utilized a combination of keywords and controlled vocabulary (e.g., MeSH terms) such as “artificial intelligence,” “machine learning,” “deep learning,” “corneal diseases,” “keratoconus,” “infectious keratitis,” “corneal neuropathy,” “dry eye disease,” “corneal dystrophy,” “corneal degeneration,” “ocular surface tumors,” “pterygium,” and “conjunctival diseases,” tailored to each database’s syntax. Abstracts meeting the criteria were selected for full-text review. Two independent reviewers then assessed the full texts for eligibility. Discrepancies between the reviewers were resolved through discussion to reach a consensus on inclusion. Studies were included if they reported LLM-, ML-, or DL-based approaches (e.g., neural networks, support vector machines) applied to corneal disease diagnosis or monitoring. No language or publication date restrictions were applied initially, though primarily English-language articles were ultimately reviewed. Data extraction focused on performance metrics (sensitivity, specificity, accuracy, area under the curve [AUC]), imaging techniques, AI model types, and study limitations. Qualitative synthesis was employed to summarize the findings, with an emphasis on model performance, challenges, and clinical implications. Study quality was not formally assessed, aligning with the narrative review framework, but key trends and discrepancies were critically evaluated based on the extracted data. The study adhered to the tenets of the Declaration of Helsinki.

Keratoconus is a progressive condition where the cornea bulges into a cone shape due to stromal thinning [27,28]. The early detection of KC is crucial for preventing unpredictable outcomes in refractive surgery and contact lens fitting [29,30,31,32]. However, identifying subclinical KC (SKC) remains a significant challenge before refractive surgery due to the overlap in topography and tomography imaging parameters between SKC and normal eyes [33,34,35,36]. The condition’s cause is multifactorial, involving genetic predisposition, eye rubbing, and biomechanical factors. A cascade of biomechanical decompensation triggered by a focal change in corneal elasticity is thought to drive KC progression [37,38,39,40,41]. ML algorithms and neural networks have the potential to determine disease progression in an unbiased manner [37,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60]. For instance, DL of optical coherence tomography (OCT) color-coded maps have shown strong potential in identifying progressive from non-progressive KC with an 85% accuracy using the adjusted age algorithm [61].

Numerous studies have tested a variety of AI models in the context of KC diagnosis, screening, and prediction [61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135]. Most commonly, traditional ML models are utilized such as neural networks (NNs), decision trees, random forest (RF) models, support vector machines (SVMs) and more. However, DL models such as convolutional neural networks (CNNs) and generative adversarial networks (GAN) are also used. Models are trained with extensive data from corneal imaging including Placido topography, Scheimpflug tomography, slit scanning systems, OCT, and Pentacam topography. Pentacam topography, especially, has made the most significant contribution to enhancing sensitivity and specificity in ML algorithms (27 studies) [31,32,43,45,46,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83].

Neural networks, including multi-layer perceptrons (MLPs), have demonstrated high diagnostic accuracy, with some analyses reporting a sensitivity up to 100% [84]. Our review showed that 30 studies used neural networks for KC detection [27,28,29,51,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109], with most relying on corneal topography. The highest sensitivity and specificity (both 100%) were achieved in the study by Fisher et al. [94]. The FPA-K-means unsupervised algorithm, free from pre-labeling bias, also efficiently identified KC [110]. Additionally, an SVM model using eight key corneal parameters from OCT-based topography achieved 94% accuracy [111].

Random forest classifiers achieved 98% and 95% accuracy in identifying class 2 and class 4 keratoconus, respectively, using the Harvard Dataverse KC dataset with sequential forward selection [112]. Logistic regression and SVM models helped develop indices such as the Fourier-based keratoconus detection index (FKI), which demonstrated strong subclinical KC diagnostic performance [113,114,115,116,117]. SVMs using a cubic kernel and elevation parameters achieved 96.6% accuracy in distinguishing KC from normal cases [66] and reported over 93% prediction accuracy and 95% overall accuracy in other studies [32].

Naïve Bayes (NB) classifiers and clustering methods like hierarchical clustering and k-nearest neighbor were also used to stratify patient subgroups and enhance diagnostic precision [114,118]. Among various AI models proposed for KC screening, an ensemble model using soft voting achieved the highest sensitivity—90.5% on internal and 96.4% on external validation data [119]. Newer AI-based indices such as BESTi showed improved sensitivity and specificity (84.97%) for detecting SKC compared with the Pentacam Random Forest Index (PRFI) and Belin–Ambrósio Deviation Index (BAD-D) [120].

In a diagnostic study evaluating AI’s power in distinguishing non-KC, SKC, and KC cases, the global diagnostic accuracy reached 95.53%; the aforementioned model exceeded ophthalmology residents’ accuracy of 93.55%, with a validation AUC of 0.99 [121]. Automated tree-based ML classifiers reached 100% sensitivity and 99.5% specificity in differentiating KC from normal corneas [82]. Deep learning models, particularly CNNs, were trained on Scheimpflug tomography and OCT images. These DL models demonstrated excellent performance in differentiating non-KC, SKC, and manifest KC [84,115,122]. Summary sensitivity and specificity for manifest KC diagnosis reached 98.6% and 98.3%, respectively [113], while SKC detection reported a slightly lower sensitivity (90.0%) [113]. Combining CNNs with color-coded Scheimpflug images showed that the model was dependent on specific spatial regions to differentiate between KC, SKC and non-KC eyes (accuracies ranging from 0.98 to 0.99) [123]. One study cited that a combination of corneal elevation data and tomography improved SKC discrimination from normal eyes with 92.5% sensitivity and 92% specificity [124].

Other DL approaches included GANs used for data augmentation and representation learning [122]. Deep learning on OCT color-coded maps demonstrated 85% accuracy in distinguishing progressive from non-progressive KC using an adjusted age algorithm [61]. The Ectasia Status Index (ESI), developed using unsupervised ML from OCT data, effectively assessed KC severity [35]. Posterior corneal surface characteristics and thickness were also predictive of disease progression. Neural networks achieved the highest prediction accuracy (98.29%), followed by SVMs (97.72%), though SVMs performed better in terms of training and testing time [107].

In a novel approach, researchers assessed KC severity using the RETICS scale. The model achieved 85% sensitivity on validation and 95% on training data [60]. Influential risk factors included gender, coma-like aberrations, central thickness, higher-order aberrations, and temporal corneal thinning. This RETICS-based web application enables rapid, objective, and quantitative KC evaluation, aiding early diagnosis and disease grading.

Across 25 ML models that utilized OCT-based topography and multiple corneal parameters (topography, elevation, pachymetry), the most accurate model was an SVM algorithm using eight corneal features, which achieved 94% accuracy [110]. These models show strong potential for integration into clinical imaging devices or as diagnostic software for early KC detection and assessment. The keratoconus AI models are summarized inTable 1.

Fuch’s endothelial corneal dystrophy (FECD) is a progressive disease characterized by corneal endothelial loss [136]. As a consequence, this leads to stromal edema and guttata formation [136]. This sequence of events can lead to significant visual impairment. Artificial intelligence has shown significant promise in the diagnosis and management of FECD, particularly through imaging modalities such as AS-OCT, specular microscopy, and slit lamp photography.

Several DL models have been developed to differentiate between early- and late-stage FECD, as well as to distinguish FECD from non-FECD corneas. Eleiwa et al., using high-definition OCT images, developed a model capable of differentiating non-FECD corneas from early and late FECD with a sensitivity of 99% and specificity of 98% [137]. The same authors using AS-OCT achieved a high accuracy in distinguishing between early-FECD, late-FECD, and non-FECD eyes. Early-stage FECD reached an AUC of 0.997 (sensitivity 91%, specificity 97%), late-stage FECD had an AUC of 0.974 (sensitivity up to 100%, specificity 92%), and distinguishing all FECD cases from non-FECD eyes achieved an AUC of 0.998 (sensitivity 99%, specificity 98%) [137]. Another AS-OCT-based DL model diagnosing DED, KC, and FECD demonstrated excellent performance, achieving AUCs of 1.0 (F1 score 100%) for FECD, 0.99 for KC (F1 98%), and 0.99 for DED (F1 90%) [138].

In studies using slit lamp photographs (SLP), Gu et al. reported an AUC of 0.939 in detecting corneal dystrophy and degeneration, including FECD, alongside other ocular surface conditions [139]. The hierarchical DL model achieved AUCs ranging from 0.903 to 0.951 in retrospective testing and >0.91 in a prospective cohort of 510 cases [139]. Another study applying semantic segmentation to SLP images reported a high diagnostic accuracy across ten anterior segment pathologies, with accuracy ranging from 79 to 99%, sensitivity from 53 to 99%, and specificity from 85 to 99% [140].

AI has also been used for the quantitative assessment of the corneal endothelium using specular microscopy [141]. DL models based on CNN U-net architectures have enhanced the speed and accuracy of morphologic analyses compared with manual assessments and conventional software [141]. In one comparative analysis, CNN-based models could estimate endothelial parameters in 98% of images with a percentage error of 2.5–5.7%, while conventional specular microscopy could only analyze 31–72% of images with higher error margins of 7.5–18.3% [142]. Despite these advancements, specular microscopy is limited in advanced FECD due to corneal edema that obscures imaging [143,144].

To overcome these limitations, salience map (SM) imaging has been explored. One study using 775 SM images reported a strong performance in internal validation (AUC 0.92, sensitivity 0.86, specificity 0.86) and a moderate performance in external validation (AUC 0.82, sensitivity 0.74, specificity 0.74) for detecting abnormal images [145]. For distinguishing FECD from other diagnoses, internal validation showed an AUC of 0.96 (sensitivity 0.91, specificity 0.91), whereas external validation showed a lower performance (AUC 0.77, sensitivity 0.69, specificity 0.68) [145]. A separate DL model identified widefield SM images with an endothelial cell density (ECD) > 1000 cells/mm2, diagnosing FECD eyes with a sensitivity of 0.79, specificity of 0.78, and an AUC of 0.88 [145].

A support vector machine (SVM) model was used to differentiate non-pathological and pathological corneas based on pupil size and principal components (PCs) [146]. For a 3 mm pupil analysis with three PCs, the model achieved an accuracy of 92.8%, a sensitivity of 96.9%, and a precision of 94.8%; with five PCs, the accuracy remained at 92.8%, the sensitivity was 96.1%, and the precision was 95.2% [146]. At 5 mm pupil size, performance slightly decreased but remained strong, with an accuracy around 90.2–90.7%, sensitivity of 94.8%, and precision of 92.1–92.7% [146].

Another innovation involved the use of edema fraction (EF), the ratio of pixels labeled as edema to the total corneal pixels, as a marker for early disease detection [147]. For detecting a 20 µm change in differential central corneal thickness (DCCT), EF achieved an AUC of 0.97 overall, 0.96 in FECD and normal eyes, and 0.99 in non-FECD and normal eyes [147].

Additionally, one study highlighted the importance of guttae area ratio (GAR%) as a quantitative imaging biomarker that aligns well with the m-Krachmer grading scale. However, this study was focused on the central corneal region [148].

Despite all these advances, a systemic review by Liu et al. found no studies utilizing Scheimpflug imaging (e.g., from Pentacam) for AI training in FECD [149]. They hypothesized that this was due to limitations in data accessibility from proprietary formats [149]. AS-OCT remains the preferred modality due to its superior resolution and capacity to differentiate between epithelial and stromal edema—critical for evaluating disease severity and treatment response [149].

Nevertheless, AI applications in FECD diagnosis have demonstrated excellent diagnostic accuracy, sensitivity, and specificity across imaging modalities, highlighting its potential to augment clinical evaluation, especially in early or ambiguous cases. A summary of the models discussed in this section is found inTable 2.

Dry eye disease is a prevalent eye condition worldwide, affecting between 5 and 50% of the population, depending on the diagnostic criteria and study population. DED is a multifactorial condition classified into aqueous-deficient and evaporative DED, associated with insufficient tear production and dysfunctional meibomian glands, respectively [150].

The subjective nature of diagnostic tools has made DED diagnosis challenging [151]. Key clinical signs include decreased tear volume, rapid tear film break-up, and ocular surface microwounds. However, diagnostic tests may not always correlate with symptom severity. A comprehensive DED evaluation utilizes a range of tests to assess tear film parameters, including tear film break-up time (TBUT), Schirmer’s test, tear osmolarity, and tear meniscus height [152]. Additional diagnostic tools include ocular surface staining, corneal sensibility, interblink frequency, corneal topography, interferometry, aberrometry, and advanced imaging techniques like meibography and corneal confocal microscopy (CCM) [152].

Applying AI to the analysis of DED testing and protocol development for diagnosis and disease monitoring potentially enhances the accuracy and consistency of DED diagnosis. Newer studies have integrated AI with bioinformatics tools in the analysis of biofluid markers for DED. Artificial Neural Networks (ANNs), hierarchical clustering, and RF models have been utilized alongside the protein and metabolite profiling of tears for various functions: classifying disease subgroups, differentiating DED from other ocular surface diseases (OSDs), identifying risk factors, and predicting prognosis [153]. One study utilizing a nonlinear iterative partial least squares (NIPALS) algorithm followed by a multi-layer perceptron neural network (MLP NN) achieved 89.3% accuracy in classifying tear proteome profiles of non-dry eye, dry eye, and MGD-associated dry eye individuals [153]. Another study employed a multi-layer feed-forward network trained on a seven-biomarker tear panel reported an AUC of 0.93 [153]. Despite their strong performance, these models were limited in interpretability and generalizability due to their “black-box” approach [153].

Additionally, AI-driven tools have been used to analyze temperature profiles from thermal images of the cornea to distinguish between non-ADDE eyes and those with Aqueous Deficient Dry Eye (ADDE) [154]. One study using an infrared thermography (IRT) model reported 84% sensitivity, 83% specificity, and AUC of 0.87 [141]. Other IRT studies using ML classifiers like PNN, KNN, and SVM reported near-perfect metrics, with one achieving 99.8% sensitivity, specificity, and accuracy (left eye), and another reaching 99.9% sensitivity, 99.4% specificity, and 99.8% accuracy (right eye) [154]. A KNN-based model with ten-fold cross-validation reported 99.88% accuracy, 99.7% sensitivity, and 100% specificity [154].

Cartes et al. found that the tear film osmolarity variability was higher in individuals with dry eye syndrome compared with non-dry eye controls. They created a classification model with an initial accuracy of around 85%, emphasizing the potential diagnostic value of tear osmolarity in distinguishing between non-DED individuals and those with DED [155].

The analysis of tear proteins’ electrophoretic patterns using an ML-based ANN achieved an accuracy rate of 89% in diagnosing DED. The ANN demonstrated the ability to detect signs of DED from electrophoretic patterns [156].

Protein chip array profiling of tear samples, combined with AI analysis, achieved 90% sensitivity and specificity in distinguishing DED patients from non-DED controls [157].

The creation of innovative diagnostic algorithms, based on TBUT, is a significant advancement in the assessment of DED as well. Combining video-based TBUT analysis with advanced computational techniques demonstrates the value of using new technologies to tackle challenges linked to diagnosing and grading DED. In 2007, Yedidya et al. developed an algorithm using the EyeScan system to automatically detect DED by analyzing slit lamp videos for the first time. Their initial method achieved 91% accuracy compared with optometrist assessment and was later expanded to include additional tear film metrics [158]. Su et al. conducted a study to explore the potential of CNN technology in evaluating tear film stability by analyzing fluorescein TBUT (FTBUT). They developed a CNN-based method to segment fluorescent images and detect areas of broken tear film using a 5 s cutoff value after blinking. The method achieved a high accuracy rate of 98.3% in detecting the break-up area, highlighting the effectiveness of CNN-based FTBUT assessment as a reliable tool for evaluating tear film stability and screening for DED [159].

Vyas et al. proposed a new algorithm that uses TBUT data from video recordings to diagnose and grade the severity of DED. Their approach achieved 83% accuracy in detecting TBUT frames and classifying the severity of DED as normal, moderate, or severe [160].

Su et al. investigated the effectiveness of CNN classifiers in detecting superficial punctate keratitis (SPK), an important clinical feature of DED. The trained CNN classifiers achieved an accuracy of 97% in detecting punctate dots observed through fluorescein staining. Additionally, the proposed CNN-SPK grading system effectively estimated the coverage of punctate dots and demonstrated a strong correlation (r = 0.81,p< 0.05) with clinical gradings [161].

The utilization of tear film lipid interferometer imaging has shown promise in aiding the classification of DED [149]. Recent studies have used ML techniques to develop predictive models that analyze tear film lipid interferometer images. These models have shown a strong positive correlation with Schirmer test values and a high level of agreement (0.82) in accurately classifying the images into healthy, aqueous-deficient DED, or evaporative DED categories [162,163].

Moreover, the use of DL algorithms to study blink patterns in video recordings has shown promising results in assessing DED. Recent studies have shown the frequency of incomplete blinking, as measured by the DL-based algorithm, is closely correlated with the clinical presentation of DED [164,165].

In a more recent study, researchers used blink videos to study spontaneous blink patterns in patients with DED. They used a U-Net image segmentation algorithm to identify complete and partial blink patterns and developed a ResNet-based DL model to classify the blink videos [166]. The study found that DED patients exhibit a higher incidence of partial blinks, shorter closure time, and reduced blink amplitude compared with non-DED controls [166]. The U-Net segmentation model achieved 96.3% accuracy, and the classification model achieved 96.0% accuracy [166].

By using AS-OCT corneal epithelial mapping data, researchers created a diagnostic AI algorithm using random forest regression. This approach yielded outstanding performance results, with a sensitivity of 86.4% and a specificity of 91.7% [167]. Additionally, superior intermediate epithelial thickness was identified as a potential AS-OCT marker for diagnosing DED (AUC: 0.87) [167]. The difference between inferior and superior peripheral epithelial zones was identified as the best marker for grading DED [167].

A recent study used a rapid, non-invasive DED screening algorithm combining the Symptom Assessment in Dry Eye (SANDE) questionnaire and NIBUT, using optimal cutoffs of SANDE ≥ 30 and NIBUT < 10 s. The results exhibited 86% sensitivity and 94% specificity for detecting DED according to Tear Film and Ocular Surface Society Dry Eye Workshops (TFOS DEWS II) criteria, indicating its potential to facilitate the efficient clinical identification of the condition [168].

According to a meta-analysis of AI usage in the diagnosing of DED, the overall accuracy of AI models was found to be 91.91% (95% confidence interval: 87.46–95.49) with a sensitivity of 89.58 (±6.13) and a specificity of 92.62 (±6.61) [169]. These data indicate that the combination of bioinformatics and AI-driven technologies in the diagnosis, management, and mass screening of DED potentially improves the accuracy, consistency, and objectivity of DED assessment. The DED AI models are summarized inTable 3.

Just as a combination of biofluid markers and AI-driven tools were utilized for DED, similar methodologies have been implemented for tear film analysis. These models are guiding biomarker discovery, differentiation between various OSDs, and making prognostications in clinical settings.

Santos et al., for instance, developed a fully automated model to quantify in vivo tear film thickness using high-resolution OCT. The model demonstrated a relative accuracy of 65% and excellent reproducibility, which can aid in DED diagnosis and treatment evaluation [170].

Tear meniscus height (TMH) is a valuable diagnostic tool in the assessment of aqueous-deficient DED. Researchers have developed an automated method using a CNN to segment the tear meniscus area and calculate TMH [171]. This system achieved an average Intersection of Union (IoU) of 82.5% and demonstrated a higher correlation (0.965) with ground truth data compared with manual measurements (0.898) [171]. The improved accuracy and consistency of this approach suggests the potential to enhance the diagnosis and monitoring of aqueous-deficient DED [171].

Stegmann et al. utilized ultrahigh-resolution OCT to assess various tear film parameters, including TMH, tear meniscus area, tear meniscus depth, and tear meniscus radius. Using conventional image processing algorithms, the researchers accurately segmented the tear meniscus and quantified these crucial metrics, revealing significant correlations among them (allp< 0.001, all r ≥ 0.657) [172].

Moreover, they developed an ML-based approach to segment the lower tear meniscus using AS-OCT images. Their thresholding-based algorithm demonstrated exceptional performance, achieving a sensitivity of 96% and a specificity of 100% [173]. This automated segmentation technique represents a significant advancement in the objective quantification of tear meniscus parameters, which is crucial for the assessment and management of DED [173]. A summary of tear film models is shown inTable 4.

Infectious keratitis is a sight-threatening disease that requires early diagnosis due to its significant morbidity and potential for poor outcomes [174,175,176]. Traditional diagnostic tools, such as slit lamp-based evaluations, remain the cornerstone of IK diagnosis [177]. However, the visual interpretation of microbial keratitis (MK) patterns is highly subjective and requires extensive clinical experience [178]. Standard diagnostic methods like corneal scrapings and cultures are time-consuming, expertise-dependent, and often yield false-negative results due to their low sensitivity [178,179,180,181]. These limitations have driven the development and adoption of AI, particularly DL and ML, as more efficient and accurate alternatives [182,183,184,185,186].

AI models for IK classification commonly utilize images from various modalities, including slit lamp, digital anterior segment photographs (ASP), and IVCM [182,183,184,185,186,187]. These models serve several diagnostic functions: distinguishing infectious from noninfectious keratitis, differentiating among bacterial, fungal, viral, and Acanthamoeba keratitis, and even identifying fungal subtypes like yeast versus filamentous species [182,183,184,185,186,187].

As early as 2003, Jagjit S. Saini et al. introduced neural networks for identifying bacterial keratitis (BK) and fungal keratitis (FK), achieving an accuracy of 90.7% and outperforming clinician diagnoses [188]. Since then, AI applications have expanded significantly; CNN-based DL models developed for slit lamp photographs demonstrated a high diagnostic accuracy in multiple studies. One study developed three models: one for diagnosing IK (accuracy 99.3%), another for distinguishing BK from FK (accuracy ~84%), and a third for classifying yeast versus filamentous fungi (accuracy 77.5%) [183].

More complex DL systems, like DeepIK, mimicked expert diagnostic processes using a two-stage classifier: one to distinguish infectious from noninfectious keratitis and another to classify specific etiologies. DeepIK outperformed other DL models like DenseNet121, InceptionResNetV2, and Swin-Transformer, in line with reference standards (Cohen’s Kappa 0.70–0.77) and rapid image processing (0.034 s/image) [185]. VGG19, ResNet50, and DenseNet121 were evaluated on 2167 mixed BK and FK images; VGG19 outperformed the others with an F1 score of 0.78 and AUPRC of 0.86 [189].

Large-scale DL evaluations have further validated these models. For instance, an ensemble model analyzing 2167 slit lamp photos achieved a high performance in differentiating BK from FK, with sensitivity, F1 scores, and AUPRC of 0.77, 0.83, and 0.904, respectively [190,191]. Other models trained on 1330 cropped images reached a diagnostic accuracy of 80.0% for BK and FK [190]. MobileNet achieved the highest performance among five CNNs, with an AUC of 0.86 in single-center and 0.83 in multi-center tests [191]. ResNet-50 CNN models showed a specificity and sensitivity of 80% and 70% for BK, and 70% and 80% for FK, respectively [192].

Advanced AI methods also analyze lesion characteristics. Natural language processing (NLP) algorithms quantified microbial keratitis (MK) centrality, thinning, and depth with sensitivities ranging from 50% to 100% [193]. EfficientNet B3 achieved a sensitivity and specificity of 74 and 64, respectively, for BK diagnosis, comparable to ophthalmologists [194].

For lesion segmentation, models like SLIT-Net and multi-scale CNNs with ResNeXt achieved up to 88.96% diagnostic accuracy [195,196]. Region-based CNNs reached Dice similarity coefficients between 0.74 and 0.76 for segmenting stromal infiltrates, hypopyons, and other features [197]. ResNet50-based multi-attribute networks identified keratitis characteristics with 89.51% accuracy [198]. Ming-Tse Kuo’s DenseNet model used corneal photos for FK diagnosis, and semi-automated algorithms measuring epithelial defects (ED) showed high reliability (ICC 0.96–0.98) compared with ophthalmologists (ICC 0.84–0.88) [199,200,201].

Image enhancement techniques like histogram matching fusion (HMF) have been applied to AlexNet and VGGNet models, yielding accuracies as high as 99.95% [202]. Confocal texture analysis using an adaptive robust binary pattern (ARBP) reached 99.74% accuracy, with a TPR, TNR, and AUC near 1 [203]. A ResNet-based DL model for FK via IVCM demonstrated a high AUC (0.987), accuracy (0.962), sensitivity (0.918), and specificity (0.9834) [204].

Web-based models using confocal microscopy and networks like AlexNet, ZFNet, and VGG16 showed excellent performance, with VGG16 achieving a high accuracy (0.992), sensitivity (0.993), specificity (0.992), and AUC (0.999) [205]. Slit lamp photo datasets used by Li et al. and others covered thousands of cases. One DL model processed 1772 slit lamp photos to classify corneal disorders, while another processed 5325 images to distinguish between IK subtypes, neoplasms, and dystrophies, with AUCs over 0.910 [140].

In another study, a hybrid DL model on 4306 images yielded the following accuracy and AUC: 90.7% and 0.963 for bacteria, 95.0% and 0.975 for fungi, 97.9% and 0.995 for Acanthamoeba, and 92.3% and 0.946 for HSV, respectively [206]. A separate CNN study using 10,739 images achieved accuracies of 91.91%, 79.77%, and 81.27% for BK, FK, and Acanthamoeba, respectively [207].

Models using 928 slit photos achieved near-perfect training and testing accuracies of 100%, 99.1%, and 99.6% across AlexNet, VGG-16, and VGG-19 networks [208]. In sequential-level DL using 362 photos, diagnostic accuracies for BK, FK, and HSK surpassed 121 ophthalmologists at 78.7%, 74.23%, and 75.1%, respectively [209]. Visual Concept Mining (VCM) improved classification through pixel-level saliency analysis, with DenseNet121 yielding the best F1 scores (0.431 for BK, 0.872 for FK, 0.651 for HSK) [210]. DenseNet121 also outperformed ResNet50 and InceptionV3 in classifying healthy eyes versus BK, FK, and HSK with a 72% accuracy [211]. Additionally, HSV necrotizing stromal keratitis classification using DenseNet on 307 images showed 72% accuracy, 0.73 AUC, 69.6% sensitivity, and 76.5% specificity [212]. Other CNN models distinguished between active and scarred keratitis with 78.2% sensitivity and 91.3% specificity [213]. SVM classifier models were able to classify ulcer severity better than type, however [214].

For AK diagnosis, a CNN based on IVCM images (HRT3) differentiated AK from nonspecific findings with 76% accuracy, sensitivity, and specificity [185]. Meanwhile, ML models including logistic regression, random forest, and decision trees have also been explored for FK diagnosis, alongside lasso regression for assessing clinical signs [183].

Systematic reviews report a varied performance: a pooled accuracy of 64.38% for BK vs. FK classification and 96.6% for infectious vs. noninfectious keratitis classification [180]. DL was found to outperform human experts in all comparative studies [180]. IVCM-based DL models were more effective than ASP-based ones, with a higher sensitivity (91.8% vs. 86.2%) and specificity (94.0% vs. 83.6%), likely due to better image consistency and patient selection [181]. A summary of keratitis models can be seen inTable 5.

Diabetes adversely impacts corneal nerves through reduced sensitivity and epithelial regeneration, thereby potentially making the corneal nerve plexus a surrogate for diabetic peripheral neuropathy [215]. Manifestations range from decreased sensitivity to vision-threatening ulcers. Changes include decreased branching, reduced sub-basal density, and increased tortuosity, potentially representing regeneration [215]. Moreover, the cornea’s integrity relies on its dense innervation, enabling the protection of its tear film through reflex arcs. The disruption of the tear film in DED leads to epithelial and nerve damage, resulting in nerve dysfunction that drives DED progression, ocular pain, and neuropathic symptoms [216]. The sub-basal plexus is more accessible for in vivo confocal evaluation than stromal nerves. The IVCM evaluation of corneal nerve fiber length (CNFL) is a valuable diagnostic tool, but current manual methods lack efficiency and objectivity. Rapid and automated segmentation techniques for evaluating the morphology of sub-basal corneal nerves are essential for the accurate diagnosis and effective management of corneal neuropathies [217].

Preston et al. designed an AI-based algorithm that could classify CCM images of patients without the need for prior image segmentation [218]. The algorithm demonstrated high levels of sensitivity, correctly identifying healthy control subjects with a sensitivity of 1.0 [218]. Furthermore, it achieved sensitivities of 0.85 in detecting patients with diabetic peripheral neuropathy (DPN) and 0.83 for patients without DPN [218].

Salahoudin et al. developed a novel, automated AI-based algorithm that utilized CCM images to rapidly quantify corneal nerve fiber length and classify DPN patients [219]. The algorithm, built upon a U-Net network and adaptive neuro-fuzzy inference system, achieved an AUC of 0.95 (92% sensitivity, 80% specificity) for detecting patients with and without DPN [219]. Furthermore, the algorithm demonstrated an AUC of 1.0 (100% sensitivity, 95% specificity) in discriminating healthy subjects from DPN patients, surpassing the ACCMetrics method [219].

Scarpa et al. developed a CNN model that utilized three non-overlapping CCM images from each eye to discriminate between healthy controls and individuals with DPN [220]. The CNN model demonstrated excellent performance, achieving a sensitivity of 0.98, a specificity of 0.96, and an overall accuracy of 0.97 in this classification task [220].

William et al. developed an innovative model that can automatically segment sub-basal nerve plexus fibers in CCM images, demonstrating promising diagnostic capabilities with a sensitivity of 0.68, a specificity of 0.87, and an AUC of 0.83 in detecting DPN [221]. Importantly, the model outperformed ACCMetrics in quantifying and evaluating corneal nerve fiber morphology [221].

Mou et al. developed a CNN-based deep grading algorithm that demonstrated a superior performance in segmenting and quantifying corneal nerve tortuosity, achieving 85.64% accuracy in four-level classification [222]. This automated DL algorithm identified significant differences in nerve tortuosity between diabetic patients and non-diabetic controls [222]. The results of these models are summarized inTable 6.

Ocular diseases affecting the conjunctiva, such as conjunctivitis and DED, significantly impact vision and quality of life. A wide range of AI models have been explored for the diagnosis and classification of conjunctival and ocular surface diseases, demonstrating promising results across multiple modalities and disease categories. Traditionally, conjunctival assessment relied on subjective clinician evaluations. However, the introduction of AI-powered diagnostic tools will potentially revolutionize the objectivity of conjunctival examination [223].

AI tools have been applied to various types of vascular assessments and disease diagnostics. For instance, Delgado-Rivera et al. applied CNN to segmented conjunctival images and achieved a 77.58% sensitivity in detecting anemia compared with laboratory test results [224].

Derakhshani et al. explored two approaches to assess conjunctival vascularity from color digital images, with the best method achieving a 0.89 correlation between predicted and actual values using an ANN [225]. Conjunctival blood velocity is known to decrease in various ocular diseases such as diabetic retinopathy and DED; hence, it serves as a valuable indicator of disease progression. However, eye movements during image acquisition and motion artifacts can hinder the accuracy of conjunctival blood flow segmentation and velocity measurement. To address this challenge, Jo et al. developed a motion correction algorithm and a segmentation approach to blurred images based on the Attention U-Net architecture [226]. Owen et al. developed an automated algorithm for measuring conjunctival vessel width, which demonstrated high session reliability and strong agreement with manual assessment methods on digital photographs [227]. Given the clinical value of monitoring ocular interventions and diseases, such as diabetes, this automated approach can facilitate the accurate and rapid assessment of conjunctival vessels [227].

Researchers developed a neural network system trained on the Japan Ocular Allergy Society (JOAS) criteria to accurately grade the severity of conjunctival hyperemia, successfully determining the vessel coverage area in 71.8% of images, with a strong correlation (r = 0.737,p< 0.01) between the model’s predictions and expert assessments [228].

The study by Li et al. showed that diabetes could be detected from conjunctival images with 75.1% accuracy [229]. Changes in the conjunctival microcirculation reflect diabetic vasculopathy, with 78.7% sensitivity and 69.0% specificity for type 2 diabetes diagnosis [229].

For ocular surface neovascularization, a fine-tuned U-Net model on 120 annotated slit lamp images showed excellent segmentation capabilities as well. The IoU scores for detecting total corneal area ranged from 90.0% to 95.5%, and for non-vascularized regions from 76.6% to 82.2%, with specificity values above 96% for both [230].

A recent systemic review discussed the usage of deep learning algorithms in combination with anterior segment swept-source OCT (AS SS-OCT). Studies showed success in the detection and classification of angle closure glaucoma, with near-perfect sensitivity and specificity [231]. These models were also able to strongly estimate visual acuity in patients with senile cataracts [231]. The usage of AS SS-OCT as an imaging modality for AI models offers potential in extending its use in diagnosing conjunctival diseases such as conjunctival tumors and structural lesions for future studies.

Yoo et al. developed a CNN model to diagnose various conjunctival conditions, including rare diseases such as conjunctival melanoma, which has an incidence as low as 0.3 per 1,000,000 [232]. Given the limited image data available for training, the researchers employed data augmentation techniques to enhance the size and diversity of the training dataset. With this data augmentation approach, the CNN model achieved an accuracy of 97% in the detection of conjunctival melanoma using smartphone-captured images [232].

Other studies have demonstrated a high diagnostic accuracy for detecting ocular surface tumors using AI as well. A YOLOv5-based DL model applied to slit lamp images captured via smartphones achieved an AUC of 0.997 for ocular surface tumors, and a similarly high accuracy for corneal scars and corneal deposits [233]. The CorneAI platform, also using smartphone and slit lamp images, significantly improved ophthalmologists’ diagnostic accuracy, from 79.2% to 88.8% overall (p< 0.001), with specialists improving from 82.8% to 90.0% and residents from 75.6% to 86.2% [234]. CorneAI’s own accuracy was 86%, and its use enhanced physicians’ performance beyond its standalone output [234]. However, individual task performance varied: CorneAI achieved an AUC of 0.62 for tumor detection and 0.71 for deposits [235].

Other DL models such as ResNet50V2, YOLOv8x, and VGG19 trained on 2774 IVCM images, including of ocular surface squamous neoplasias (OSSNs), achieved binary classification accuracies above 97%, with precision ≥ 98%, recall ≥ 85%, and F1 scores ≥ 92% [236]. Furthermore, DL has shown potential for OSSN subtype stratification, aiding in potentially personalizing treatment plans [237].

The ocular surface pretrained model (OSPM)-enhanced classification model (OECM), trained on 1455 histologically confirmed ocular surface tumor (OST) images, demonstrated AUCs ranging from 0.891 to 0.993 across internal, external, and prospective datasets [238]. OECM significantly outperformed conventional CNNs and matched senior ophthalmologists in performance while enhancing the diagnostic capabilities of junior ophthalmologists [238].

Laslty, another study using 398 publicly available ocular surface images and CNN models such as MobileNetV2, NASNet, GoogleNet, ResNet50, and InceptionV3 were tested. MobileNetV2 performed best for conjunctival melanoma detection (AUC: 0.976, accuracy: 96.5%) [239]. When synthetic images generated via GANs were added, model performance improved further—MobileNetV2 reached an AUC of 0.983 and an accuracy of 97.2% [239].

The pterygium is a fleshy conjunctival growth that extends onto the cornea and can obscure vision [240]. AI applications for pterygia span from segmentation to classification. A comprehensive review of 33 studies highlighted the evolution from manual image segmentation to end-to-end DL-based diagnosis [241]. Though DL models match ophthalmologists in accuracy, variability in clinical manifestations and the absence of a standardized grading system remain challenges [241].

Several studies underscore DL’s high performance in pterygium detection. One ensemble model trained on 172 anterior segment images achieved an accuracy of 94.12% and an AUC of 0.980 [242]. In a binary classification task involving 367 normal and 367 pterygium images, the VGG16 model achieved 99% accuracy, 98% sensitivity, 99.33% specificity, a Kappa of 0.98, and an F1 score of 99% [243].

Segmentation models also performed well. One CNN-based model using 489 slit lamp images achieved Dice coefficients of 0.9620 for cornea and 0.9020 for pterygium segmentation. The Kappa agreement with clinical visual inspection was 0.918 [244]. Another DL model distinguishing among primary, recurrent, and no pterygium in 258 eyes achieved 91.7% for sensitivity, specificity, accuracy, and an F1 score of 0.846 [245].

The RFRC (Faster RCNN + ResNet101) detection model and SRU-Net (SE-ResNeXt50-based U-Net) segmentation model, trained on 20,987 slit lamp and 1094 smartphone images, achieved 95.24% detection accuracy [246]. The fusion segmentation model achieved a microaverage F1 score of 0.8981, a sensitivity of 0.8709, a specificity of 0.9668, and an AUC of 0.9295, demonstrating robust performance across smartphone brands and matching experienced clinicians [246].

Two DL algorithms were developed to detect any pterygium and referable pterygium using anterior segment photographs. For any pterygium, the AUROCs were 99.5% (internal set, sensitivity = 98.6%, specificity = 99.0%), 99.1% (external set 1), and 99.7% (external set 2) [247]. For referable pterygium, AUROCs were 98.5% (internal), 99.7% (external set 1), and 99.0% (external set 2), confirming high sensitivity and specificity across settings [247].

In another study using 436 anterior segment images, MobileNetV2 again showed strong results with a sensitivity of 0.8370, a specificity of 0.9048, and an F1 score of 0.8250 [248].

Finally, the MOSAIC system—a multimodal assessment tool using gpt-4-turbo, claude-3-opus, and gemini-1.5-pro—demonstrated 86.96% accuracy in detecting ocular surface diseases and 66.67% accuracy in grading pterygium using 375 smartphone-acquired images [249]. This highlights the growing role of large language models in multimodal diagnostic pipelines.

Collectively, these studies showcase the diverse and high-performing AI approaches in diagnosing and managing conjunctival and ocular surface disorders, particularly emphasizing their potential as clinical decision support tools and screening instruments.

Similarly to applications of AI in DED and tear film, the use of molecular biomarkers in combination with AI is an area of critical interest. A recent study used ML algorithms to analyze RNA sequencing data from conjunctival samples of patients with presumed infectious conjunctivitis [250]. The primary goal was to predict corneal involvement, a marker of disease severity, based on gene expression profiles. SHAP (Shapley Additive Explanations) values identified apolipoprotein E (APOE) as a key gene associated with corneal involvement [250]. The model’s performance dropped significantly when APOE was excluded, underscoring its potential clinical value [250]. By identifying biomarkers that predict disease progression or severity, the models could eventually guide treatment decisions and prognostication in clinical settings. A summary of all conjunctival model results is inTable 7.

LLMs are text-based AI models that have gained massive popularity over the past few years, with several new studies being published using LLMs in the diagnosis of corneal diseases. Some examples of LLMs include ChatGPT-4.0, DeepSeek V3, Qwen 2.5 MAX, Claude3.5 Sonnet, Grok3, Gemini 1.5 Flash, or other variations of these models. A few studies compared the performance of LLMs on text-based clinical case reports and vignettes against each other and expert ophthalmologists [251,252,253]. The results of the studies are summarized inTable 8. Generally, the models that performed the best were ChatGPT-4.0 and DeepSeek V3 [252,253]. Human cornea specialists, however, generally outperformed LLMs [254]. Earlier models, especially, performed the worst among all models tested, regardless of LLM type [251,252,253].

This review provides an overview of different AI models used in diagnosing corneal diseases. We noticed a diverse range of models and imaging modalities utilized in the various studies cited. However, many of these studies did share the same performance metrics extracted during our literature search: accuracy, AUC, sensitivity, and specificity.

According to many published reporting guidelines, an AUC greater than 0.90 or sensitivity/specificity exceeding 0.85–0.90 is considered “excellent” or “clinically meaningful” for AI diagnostic standards [255,256,257]. Across all types of corneal diseases examined in this paper, AI has proven itself to meet and at times even exceed these standards. For example, a deep learning model trained on OCT topography exceeded the diagnostic accuracy of keratoconus compared with resident ophthalmologists [121]. Their ability to differentiate between subclinical KC, KC, and non-KC corneas is excellent [81,113,115,121,122,123], showing promise in future clinical applications. However, these metrics cannot be taken simply at face-value. It is important to note that these studies are retrospective [81,113,121], which possess inherent biases especially in patient selection for case–controlled studies. Additionally, there was a high degree of variability in the variables and imaging modalities the models were trained on.

Studies evaluating the performance of FECD demonstrated high performance metrics, often meeting or exceeding reporting guidelines [137,138,139,140,142,145,146,147]. Models trained for FECD evaluation used a variety of different imaging sources for training. Most commonly, AS-OCT, which is also deemed the most preferred form of imaging [137,138,149]. Other modalities such as SLP and specular microscopy were used. Some studies creatively implemented salience maps, edema fraction, and guttae area ratio as model variables as well [139,140,141,142,145,147,148]. While some models had objective variables such as the Krachmer scale or edema fraction to compare between eyes [145,146,147], others did not [138,139]. Feeding the models images for training purposes without objective metrics for analysis contributes to the “black box” approach in their decision-making capabilities.

Several models for dry eye disease and tear film assessment achieved high diagnostic metrics as well [153,154,155,156,157,158,159,160,161,162,163,164,165,166,169,171,172,173]. Many of these models integrated clinical signs, biomarkers, and imaging to improve objectivity and accuracy. Unfortunately, due to the fact that data providing direct comparisons to expert clinicians was limited, it affects their clinical adoption. Additionally, there was great variability in the number of images used to train these models, ranging from double digits to thousands. Some studies tried to mitigate the limited sample size by implementing multiple training cycles [155]. Others did not specify the quantity of images used, which should warrant caution in interpreting their results for generalizability and reproducibility [154,166,170].

In the diagnosis of infectious keratitis, several AI models have been used to differentiate between types of keratitis, even as specific as yeast versus filamentous fungi [182,183,184,185,186]. DeepIK matched Cohen’s Kappa reference standards, indicating agreement with expert-level diagnosis [181]. Similarly, ensemble CNNs reached F1 and AUPRC metric values that indicate deep learning models can achieve robust results even in imbalanced classification settings [189,190]. Just as there were many models without objective criteria to screen for in FECD training images, the same applies for IK models [183,185,190,191,192,194,199]. Nevertheless, some models did use specific variables and annotation methods to train their models [188,189,193,200,201,202,203,204,205]. However, AI models for IK still face challenges such as image quality variability and risk of overfitting [180]. To improve generalizability, future research should incorporate multivariate models that combine clinical history, physical exam findings, and imaging data [184].

For conjunctival disease, a neural network trained on JOAS criteria exhibited strong agreement with expert grading (r = 0.737,p< 0.01), suggesting that AI can match clinician assessments in more subjective domains as well [228]. Even more impressive is the ability to diagnose ocular surface tumors, such as conjunctival melanoma, with simple smartphone images to such a high degree of accuracy [232,233,234,235]. The same can be seen with models trained to classify pterygia [242,243,244,245,246,247] and nerve morphologies for corneal neuropathy [219,220]. The main limitation for studies in this category of disease were the high variability in image quality and quantity [224,225,226,227,228,229,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250]. Some studies with smaller sample sizes utilized a multi-fold cross-validation technique to account for this limitation as well [232,242].

Large language models have become popular in recent years, with significant improvements in diagnostic capabilities over the past few generations of models. These models have been tested with diverse sets of corneal cases and vignettes. The best performing LLMs were the newer generation ChatGPT and DeepSeek models [251,252,253]. Despite these advancements, they do not quite measure up to the “excellent” standards set by AI diagnostic guidelines. They still do perform well overall, however, with studies citing their potential utility in augmenting clinical decision-making [251,252,253,254]. More studies using LLMs are still emerging and warrant further exploration. There are currently a limited number of studies on the use of LLMs in corneal disease, far too limited to make any broad generalizations at this time.

Collectively, these findings across all types of ocular surface diseases show that AI models are able to achieve a high diagnostic accuracy aligning closely with expert-level performance, or at least enough to consider augmenting clinical practice. Despite the fact that many models performed highly in this review, certain models outshined others in comparison. Across all types of corneal disease, neural networks performed well, specifically, CNNs consistently performed the best compared with other types of models [107,115,122,123,159,161,166,181,184,205,206,209,220,222,232,239,244,246]. Deep learning models typically outperformed traditional machine learning, large language, and algorithm-based models. Deep learning models especially outperformed traditional machine learning and algorithm-based models in image analysis and expert-level classification tasks [107,115,121,122,123,137,138,139,140,141,146,159,161,166,181,184,205,206,209,220,222,236,237,238,239]. Several ML models performed excellently in dry eye disease and tear film analysis [152,154,156,157,167,172,173]. Meanwhile, algorithm-based models excelled in screening tasks, such as the thresholding segmentation of tear meniscus and fixed-cutoff screening tools (SANDE + NIBUT) [168,173]. Lastly, LLMs performed well in text-based clinical cases, offering potential for augmenting clinical practice, though not comparable enough to experienced ophthalmologists [251,252,253,254].

While different AI models were created or trained differently by the investigators, we noticed a lack of standardization in model development and reporting. Even with similar models, there are inconsistencies in the cohort size, imaging modality used, methods for result validation, and ratio for dataset splitting to train the models [113,117,122,136,137,138,141,148,152,183,185,258]. While it may be difficult to standardize AI models due to a multitude of variables, such as what is being studied and institutional-, disease-, or patient-specific limitations, we recommend the standardization of reporting information in AI studies. In fact, standardization tools for AI studies already do exist, such as the STARD-AI [257] and QUADAS-AI [259] checklists. The STARD-AI checklist requires the clear reporting of study design, methodology, and evaluation to ensure transparency in AI diagnostic research. Meanwhile, QUADAS-AI assesses bias risk and methodology quality. These tools should be applied when evaluating these studies, especially in systemic reviews and meta-analyses, to allow fair comparisons between model types. Some systematic reviews in our review did apply the QUADAS-2 checklist [84,115,122,149,181,182]. Yet quite a few studies did not or utilized assessment tools not specific to AI studies [117,132,133,151,169,231,258].

Without the consistent application of these tools, it becomes challenging to evaluate AI models fairly or implement them in the clinical setting. Nevertheless, the successful integration of AI into healthcare systems could alleviate healthcare burden and reduce health disparities, especially in low-resource or -access settings [260]. For example, the Ophthalmologist Robot was developed to automate the collection of ocular surface and fundus images [261]. This robot supports the early detection of sight-threatening disease through eye screening and AI integration [261]. Innovations such as this one, along with the AI models evaluated in this review, could enable earlier interventions and reduce healthcare burden, though further studies are needed to confirm their impact on health equity.

Studies implementing smartphone images and smartphone-based AI tools offer a promising solution to eye care access in underserved areas as well [232,233,234,235,246,249]. These new technologies may advance the field of teleophthalmology. However, despite their auspicious results, the performance in real-world scenarios rather than a controlled environment may yield different results. Hence, future studies should take these tools a step further by focusing on user training, validation using different smartphone devices, and diversifying the datasets.

In the realm of healthcare access, ML models have also been effective in triaging patients with an elevated risk of developing ocular pathologies. For instance, one model achieved an AUC of 0.803 for ocular surface diseases requiring medication [262]. These algorithms could empower primary care providers to identify patients who would otherwise go unnoticed [262]. Therefore, AI integrations hold potential in allowing timely referrals that mitigate disease progression.

However, the integration of AI into ophthalmology necessitates an emphasis on ethical considerations. Transparency in model development, validation using diverse data, and performance monitoring can minimize the risk of bias and data misuse. Ethical oversight using tools such as the STARD-AI and QUADAS-AI could prevent the propagation of existing healthcare inequities, especially among socioeconomically disadvantaged populations.

Looking forward, the evolution of AI in ophthalmology must be guided by the technical expertise of AI developers, ophthalmologist clinical insights, and a universal ethical foundation. As AI advancements in ophthalmology continue, its success will be judged by its ability to equitably transform care delivery and reduce preventable blindness.

Several AI models have been developed for diagnosing corneal diseases. Many of these models perform well according to published practice guidelines. Deep learning models specifically seem to outperform other models; however, other models also perform strongly in their defined tasks. AI will have a potentially profound impact on maximizing diagnostic efficiency and providing equitable care in under-resourced regions. However, with the rise in AI technologies, it is prudent to consider standardizing model comparison metrics, diagnostic definitions, and training methodologies. Standardization tools such as the STARD-AI and QUADAS-AI checklists already exist and would allow just comparison between these diverse model sets. Furthermore, these tools, along with consistent experimental methodologies, will ensure the ethical oversight of newly developed models.