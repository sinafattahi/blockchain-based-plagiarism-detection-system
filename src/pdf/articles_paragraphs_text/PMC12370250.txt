In Fahrenfort et al., 2025 we show the influence of non-perceptual criterion shifts on neural measures of consciousness. We fully agree (and point out in our article) that it was already known that subjective measures are sensitive to criterion confounds, and we are happy to read that this is acknowledged by Sandberg and Overgaard in their comment (Sandberg and Overgaard, 2025). However, we contest that the main findings of our simulations and empirical studies had already been demonstrated. Several findings from our studies are novel, such as the fact that criterion effects reveal themselves as over- (or under-) estimations of both conscious and unconscious processing in tandem, and that this has tangible implications when analyzing real neural data. We also challenge the suggestion that our experimental manipulations are (too) radical compared to signal-to-noise variations that occur naturally between experiments.

Sandberg and Overgaard now claim that it is a niche position to suggest that “awareness ratings should be treated as flawless insights into participants’ experience”, referring to their own care in highlighting that this implication is unwarranted (Sandberg and Overgaard, 2025). They further underpin this by reference to the fact that 32 researchers advise against relying on subjective measures alone to establish evidence of unconscious processing (Stockart et al., 2024, p. 14). Indeed, wise advice that is supported by our manuscript, although we would like to note that a relatively recent survey has shown that most consciousness researchers believe that subjective measures - and the PAS specifically - are the best measures to check whether a stimulus is consciously perceived (Francken et al., 2022, Figure 4). We fail to see how highlighting imperfections of subjective measures can serve as an argument in their defense, or how these concerns disappear when acknowledging them. Similarly, we fail to see how the continued use of subjective measures (with or without the acknowledgement of their imperfection) builds support for their continued use.

A second criticism of Sandberg and Overgaard is that ‘the main findings <of our manuscript> have already been demonstrated in other experiments’. To support this idea, they reference a publication (Sandberg et al., 2022) in which they model behavioral data from subjective reports. We have trouble matching the results presented in that article to the data, simulations and analyses from our own publication. Their article is not about neural measures of consciousness, nor does it contain brain imaging data. As such it bears little resemblance to our studies. Our article is specifically about the effect criterion shifts have on post-hoc sorted data to create neural conditions that are claimed to correspond to ‘real’ subjective states (such as expressed in the labels of the PAS, or in a ‘yes’/’no’ response). Further, we use empirical data from two EEG experiments to support the claim that the effects that we model in a signal detection framework are not merely theoretical artifacts but can have real implications for claims regarding the neural correlates of consciousness (NCC). The only correspondence seems to be that we agree on the somewhat unreliable nature of the PAS response, when discussing the fact that the PAS is not exhaustive (i.e. it may or may not capture weak conscious experiences depending on the experimental context).

Further, Sandberg and Overgaard claim that they had already established that report criteria depend on experimental context (Skewes et al., 2021). However, that article is intrinsically very different from ours, because it provided false performance feedback, which also affected participants’ accuracy. In our experiments we only provided veridical feedback and specifically kept accuracy the same between conditions so that the effects are criterion specific and not related to general effects of sensitivity or other cognitive effects. More importantly, the aim of our paper was not to show that report criteria depend on experimental context. Rather, we took this as a starting point to show the effect of this contextual change on neural correlates based on subjective measures and post-hoc sorting, including the PAS. Furthermore, we not only show that the experimental context influences report criteria, which should be well-known (although we contest that this is widely accepted given the lenient use of subjective measures in the literature), but we also show through simulation that the experimental context determines whether the relative confounding effect of criterion placement is larger in neural measures of either conscious or unconscious processing.

Next, Sandberg and Overgaard contend that we made changes to the PAS that we ourselves consider so substantial that it may be argued that we did not use the PAS at all (referencing our Discussion). However, this is not what we argued. Rather, we merely acknowledged Sandberg and Overgaard’s potential concern on our usage of the PAS, already in the first version of the manuscript prior to three peer reviews. Subsequently, after personal communication with them, we conceded that a particular sentence that Sandberg and Overgaard highlight and that occurred somewhere in the instructions (“Only press 0 if you are 100% convinced that no square appeared and only press 3 if you are 100% convinced that a square appeared.”) might be misconstrued by participants as a general confidence rating. To give them a fair hearing in our article, we expounded on this issue in an updated Discussion, and we asked them beforehand whether they agreed with the way we explicitly highlight this concern in the discussion of our Version of Record (to which they agreed).

However, this does not mean that we believe that our usage of the scale should not be characterized as the PAS. The PAS refers to verbal labels of a scale, i.e. it is a measurement instrument. In our experiment, the proper PAS labels were used throughout the experiment and repeatedly shown to remind participants of what we specifically asked of them. Thus, we disagree with the statement that we “did not use the PAS at all” and we do not believe that the single sentence that Sandberg and Overgaard highlighted changes this fact or would have meaningfully changed the outcome of the study.

Concluding, we do not agree that our study primarily adds detail to what was already known about the limitations of subjective measures, as we explain here and in the manuscript. We also contest that our criticisms can be mitigated simply by acknowledging limitations of subjective measures. Claims based on post-hoc sorting of subjective reports are not likely to agree across experimental contexts, so that conclusions regarding the depth or extent of unconscious processing, or regarding the temporal or spatial profile of the NCC, vary considerably across the literature (Yaron et al., 2022). With respect to subjective measures, this is not due to mere ‘limitations’, but due to a serious confound in neural activation patterns based on subjective measures, one that deserves considerable attention. We hope our manuscript contributes to raising awareness about this confound.

The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.

Johannes Jacobus Fahrenfort, Email: j.j.fahrenfort@vu.nl.

Ming Meng, University of Alabama at Birmingham, United States.

Joshua I Gold, University of Pennsylvania, United States.

HORIZON EUROPE European Research Council

10.3030/715605 to Simon van Gaal.

Writing – original draft, Writing – review and editing.

Funding acquisition, Writing – review and editing.