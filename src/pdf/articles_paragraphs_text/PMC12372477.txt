To develop and validate a deep learning pipeline using prostate biopsy H&E slides to predict extraprostatic extension (EPE) in prostate cancer (PCa) patients.

A total of 2592 preoperative biopsy H&E slides from 260 consecutive PCa patients who underwent radical prostatectomy were collected from January 2019 to October 2023. Whole-slide images (WSIs) were digitized, tumor regions were annotated, and 224 × 224 pixel patches were extracted. The dataset was randomly divided into training and testing sets at the patient level in a ratio of 8:2. A tumor classification model and an EPE prediction model based on multiple instance learning were trained. Subsequently, we conducted an interpretability analysis of the EPE model and further carried out a correlation analysis between the predicted probabilities of the EPE and the biochemical recurrence (BCR) of the patients.

The ConvNeXt model achieved the best performance in tumor classification, with an accuracy of 0.965 and an area under the curve (AUC) of 0.981 on the test set. For EPE prediction, the model achieved AUCs of 0.943 and 0.886 in the training and test sets, respectively. Key features identified by the model, such as nuclear characteristics, were significantly associated with EPE. Predicted EPE probabilities were strongly correlated with BCR (p= 0.01).

The AI pathology model accurately predicts postoperative EPE via biopsy slides, achieving an AUC of 0.886 on the test set, offering a novel, feasible PCa preoperative risk stratification method to aid personalized treatment.

This study developed a deep learning pipeline based on biopsy H&E slides to predict extraprostatic extension (EPE) with high accuracy.

The model’s predictions were based on key pathological features like nuclear characteristics and were strongly correlated with biochemical recurrence.

This AI-based method offers a feasible tool for preoperative risk stratification and personalized treatment planning in prostate cancer.

Prostate cancer (PCa) is the most prevalent malignancies in the male urinary system globally, constituting approximately 15% of all male cancers [1]. It ranks second in incidence and the fifth in cancer-related mortality among man [1]. Extraprostatic extension (EPE)—defined as PCa spread through prostate capsule into periprostatic tissues—is observed in 15–40% of radical prostatectomy specimens and portends higher risks of positive surgical margins, biochemical recurrence, and the need for adjuvant therapies [2–4]. Precise identification of EPE is crucial for surgical planning (e.g. neurovascular bundle preservation vs. wide excision) and therapy decision-making [5,6].

Current EPE prediction primarily relies on numerous nomograms integrating PSA levels, digital rectal examination, magnetic resonance imaging (MRI), and biopsy Gleason scores, such as the Partin tables [7], CAPRA score [8], and Memorial Sloan Kettering Cancer Center (MSKCC) nomogram [9]. Among these tools, the Gleason score derived from prostate biopsies plays a crucial role in predicting EPE [10]. However, there exist substantial subjective discrepancies in reporting the Gleason score, with an inter-observer agreement rate merely ranging from 60% to 80% [11]. Moreover, the hematoxylin–eosin (H&E)-stained sections of prostate biopsies contain abundant morphological information that cannot be fully conveyed through pathological reports alone. Consequently, directly extracting morphological features associated with EPE from H&E-stained prostate biopsy sections is of particular importance.

In recent years, artificial intelligence (AI) has emerged as a cutting-edge technology in the medical field, enabling accurate individualized risk assessment. AI shows great potential in predicting EPE. Currently, most of the research on EPE prediction using AI focuses on magnetic resonance imaging (MRI) data. For example, the 3D Swin-Transformer deep learning model developed by Zhao et al. [12], Unfold AI used by Grunden et al. [13], and the machine-learning model developed by Van den Berg et al. [14] have an area under the curve (AUC) ranging from 0.81 to 0.91. There are also some studies that construct AI models based on biopsy information. Sighinolfi et al. [15] externally validated the PRECE model, and Mohamad et al. [16] trained an extreme gradient boosting tree model based on machine learning. Their AUCs are 0.8 and 0.749, respectively.

However, the importance of pathological section images of prostate biopsies has been overlooked in these studies. Although imaging techniques can offer macroscopic information of the entire prostate, not all patients undergo routine MRI examinations prior to radical surgery. Prostate biopsy, serving as the gold standard for diagnosing PCa, is an indispensable step in clinical risk stratification [17]. Currently, clinical methods for evaluating EPE also attach great importance to pathological results. For example, the biopsy Gleason score is one of the key variables in the Partin tables for predicting postoperative staging [7]. Pathological sections not only provide the Gleason score but also contain rich tumor-related details, such as tissue morphology, microenvironment, and tissue distribution patterns. These details can potentially be used to further extract microscopic features associated with EPE through AI technology [18,19].

To the best of our knowledge, no prior study has employed deep-learning techniques to predict EPE based on whole-slide images (WSIs) of prostate biopsies. In this study, we initially developed a classification model to differentiate whole-slide images into normal and tumor tissues. More importantly, we trained a deep-learning model that uses only H&E-stained prostate biopsy sections as input to predict EPE in prostate cancer patients. Our study explored the relationship between the unique microscopic information in pathological sections and EPE, as well as the correlation between the EPE probability predicted by the model and the biochemical recurrence (BCR) of patients.

This study encompassed patients who underwent systematic biopsy (SBx) or systematic biopsy combined with targeted biopsy (SBx + TBx) at the First Affiliated Hospital of China Medical University between January 2019 and October 2023, were diagnosed with PCa, and subsequently underwent radical prostatectomy. The hematoxylin–eosin-stained sections corresponding to the included patients were scanned at a high resolution of 20× using a NanoZoomer S210 digital slide scanner and evaluated by senior pathologists. The pathological outcomes following radical prostatectomy were regarded as the gold standard for determining the presence of EPE. BCR was defined as two consecutive postoperative prostate-specific antigen (PSA) test values of ≥0.1 ng/ml. For the remaining patients, telephone follow-ups were conducted to confirm the occurrence of BCR.

Inclusion criteria: (1) Diagnosis of PCa via prostate biopsy; (2) Treatment with radical prostatectomy at the First Affiliated Hospital of China Medical University; (3) Availability of complete biopsy H&E-stained section data; (4) Access to complete electronic medical records for review.

Exclusion criteria: (1) History of other urinary system malignancies; (2) Prior receipt of radiotherapy, chemotherapy, or other systemic treatments for PCa before surgery; (3) Incomplete postoperative PSA test records; (4) Incomplete follow-up data or inability to contact the patient for follow-up. (5) The quality of pathological images is poor. The flowchart of patient inclusion in this study is presented inFigure 1.

Flowchart of inclusion and exclusion: from January 2019 to October 2023, a total of 672 patients were diagnosed with prostate adenocarcinoma by puncture. Among them, 302 patients did not undergo radical surgery, and the remaining 370 patients received radical prostatectomy. Among these 370 patients, 40 received endocrine therapy before surgery, 13 had a history of other urinary system malignancies, and 65 had no PSA results or could not be followed up. Finally, 260 patients were included in the study, with 42 patients used for the tumor classification model and 218 patients used for the EPE prediction model.

This study was approved by the Ethics Committee of the First Affiliated Hospital of China Medical University (Approval No.: AF-SOP-07-1.2-01, KELUNSHEN [2024] No. 1091). Given that the study adopted a retrospective analysis approach using archived pathological specimens and clinical data, and did not involve the exposure of personally identifiable information, the Ethics Committee approved the waiver of informed consent for all participants after review. This exemption complies with the Helsinki Declaration and relevant domestic ethical review regulations, ensuring that the study is conducted within a compliant framework.

This model construction included three main stages: data pre-processing, tumor tissue classification, and EPE prediction using a Multiple Instance Learning (MIL) framework.Figure 2illustrates the overall technical roadmap of our approach.

Computational strategy: starting from the patient’s original pathological section, tissue segmentation, gridding, and patch extraction are performed in sequence to obtain patches. Then, the tumor patches are classified, and after patch selection, the selected tumor patches are used for feature extraction. The extracted features are input into the UNI model. The patch features output by the model are classified through modules such as the transformer block to determine the presence or absence of extraprostatic extension.

To capture fine local details from high-resolution WSI, we converted the color space of all WSI slices from RGB to HSV. We then apply Otsu’s method on the Hue channel to segment cell–tissue regions from the background, followed by morphological operations (noise reduction and hole filling) to refine the segmentation. Using the Histolab algorithm, we segment the tissue regions into 224 × 224 pixel patches. These patches, along with their coordinates, are saved for further analysis, ensuring that each patch contains relevant cell–tissue information.

From 414 WSIs of 42 patients, A pathologists (Y.P. with 3-year experience in PCa pathology diagnosis) used QuPath to label PCa areas, generating binary masks. All annotations were reviewed by a senior urology pathologist (M.Y., with 20 years of experience in PCa pathology). Based on these masks, patches with more than 30% cancerous area are classified as cancerous, while patches with no cancer cells are considered non-cancerous. Patches that do not meet either criterion are discarded.

The patches are split at the patient level into training, validation, and test sets with a roughly 7:1:2 ratio (training set: 30 patients, 143657 background patches, 24,255 foreground patches; validation set:4 patients, 15219 background patches, 2034 foreground patches; test set: 8 patients, 39367 background patches, 4718 foreground patches). To address the imbalance (fewer cancerous patches), we augment the cancerous patches with rotations and flips.

Five pre-trained networks (ResNet, ResNeXt, ViT, Swin-T, and ConvNeXt) are used to build a binary classification model to distinguish cancerous from non-cancerous patches. The network with the best classification result on the test set will be used.

We use a universal self-supervised model (UNI), specifically designed for pathological images, to extract high-dimensional features from the selected cancerous patches. The UNI model, trained on large-scale pathological data, captures subtle morphological details.

A novel MIL framework based on the transformer self-attention mechanism (TMIL) is developed. This model includes two transformer encoder layers that integrate multi-head attention, feed-forward neural networks, and layer normalization to capture relationships among patches. The extracted features are then processed by a multilayer perceptron (MLP) and a Softmax layer to output a probability distribution for EPE.

The MIL model is trained on patches from 2168 WSIs of 218 patients, with data divided into training and validation sets at an 8:2 ratio. The training uses the Adam optimizer with a dynamic learning rate decay strategy, running for 200 epochs. We employ the SmoothTop1SVM loss function, which focuses on ranking the top predicted probabilities, ensuring sensitivity in global lesion detection.

When validating the performance of the tumor tissue classification model, we used accuracy (ACC) and recall (REC) as the primary evaluation metrics. To comprehensively assess the accuracy of the model in predicting the presence of EPE, we utilized the receiver operating characteristic (ROC) curve as the evaluation tool and calculated several key metrics, including the AUC, ACC, precision (PRE), REC, and F1 score.

In addition, we randomly selected patches from those with a high probability of EPEpredicted by the model (the top 20%) and those with a low probability of EPE (the bottom 20%). Then, we used ImageJ software to extract quantifiable morphological vectors and outline the cell nuclei for comparative analysis.

Statistical analysis of the data was carried out using the SPSS 27.0 software. Continuous variables were expressed as the median (interquartile range, IQR), and categorical variables were expressed as counts (percentages). When the quantitative data of two independent samples were normally distributed and had homogeneous variances, thettest was used for comparison. The chi-square test was used for comparing the qualitative data of two independent samples, and the Mann–WhitneyUtest was used for comparing the ranked data of two independent samples. The Kaplan–Meier survival curve was applied to evaluate the predictive value of the EPE probability values predicted by AI for biochemical BCR during the postoperative follow-up period. Statistical significance was defined asp< 0.05.

Finally, 260 consecutive PCa patients, including 2592 biopsy H&E sections, were included in this study. The median age was 67 yr (IQR 63–72). Among them, 86 patients (33.08%) were found to have EPE. There were significant differences between the EPE group and the non-EPE group in terms of PSA level, positive biopsy proportion, Biopsy Gleason Grade (Biopsy GG), Prostatectomy Gleason Grade (Prostatectomy GG), Pathological T staging, Pathological N staging, and Nerve Invasion (p< 0.05). However, there were no statistically significant differences in age and Clinical T staging between the two groups (p> 0.05) (Table 1). Among the 260 patients, 25 patients underwent systematic biopsy, and 235 patients underwent targeted fusion biopsy. A total of 61 cases in the EPE group and 106 cases in the non-EPE group underwent multiparametric magnetic resonance imaging (mpMRI) examination. The specific distribution of PI-RADS scores is shown inSupplementary Table 2. Of these, 42 cases were included in the Tumor Tissue Classification Model study. These cases were divided into a training set (30 patients, 143,657 background patches, 24,255 foreground patches), a validation set (4 patients, 15,219 background patches, 2,034 foreground patches), and a test set (8 patients, 39,367 background patches, 4,718 foreground patches) at the patient level in a 7:1:2 ratio. The remaining 218 cases were included in the EPE prediction model study. These cases were divided into training set (n= 174) and test set (n= 44) at the patient level in an 8:2 ratio.

Clinicopathological characteristics of the study cohort.

The five pre-trained models’ performances on the training set, validation set, and test set are presented inTable 2. On the validation set, ConvNeXt outperformed the others with an accuracy of 96.8%, AUC of 0.979, and recall of 85.3%, and similar performance was observed on the test set (96.5% accuracy, AUC of 0.981, and recall of 84.6%).Supplementary Figure 1shows strong spatial overlap between pathologist annotations and model predictions, whileFigure 3a–ddisplay the ROC, calibration curves, and confusion matrices that confirm the model’s high sensitivity and robustness.

The classification performance of different models.

Performance of the classification model and the EPE prediction model:a. Receiver operating characteristic (ROC) curve of the classification model for distinguishing between tumor and non-tumor;b. Calibration curve;c. Confusion matrix of the validation set; d. Confusion matrix of the test set;e. ROC curve of the model for predicting the occurrence of extraprostatic extension;f. ROC curves of different models for predicting EPE in prostate cancer;g. Confusion matrix of the training set; h. Confusion matrix of the test set.

The model achieved an AUC of 0.943 in training set and 0.886 in test set (Figure 3e). In the test set, the model reached an accuracy of 86.4%, precision of 75%, recall of 85.7%, and an F1 score of 0.80. Specifically, 26 of 30 non-EPE patients were correctly predicted as non-EPE, and 12 of 14 EPE patients were correctly identified. The AUCs of MSKCC nomogram, Roach formula, and Partin Table were 0.780, 0.745, and 0.461, respectively in the test set (Figure 3f). The prediction performances of these three models are shown inTable 3.Figure 1g and hpresent the confusion matrices for the training set and the test set, respectively.

The performance of different models in predicting EPE.

Key morphological features—including the area, shape, density, and arrangement of the cell nuclei obtained through software-based nuclear segmentation – showed obvious differences between the patches with and without EPE. Patches predicted to have high EPE probability showed tumor nuclei that were larger, more irregular, and denser, often arranged as cords or strands. In contrast, patches with low EPE probability exhibited well-formed, regularly arranged glandular tubules (Figure 4).

Cell features of the EPE and NON-EPE groups: the tumor cell nuclei were automatically segmented by ImageJ. The tumor cell nuclei in the EPE group tiles exhibited larger volumes, more distorted shapes, and higher densities.

Kaplan–Meier survival analysis (Figure 5) demonstrated that patients classified as EPE positive by our AI model experienced significantly different BCR rates following radical prostatectomy compared to those classified as non-EPE (p= 0.01). This finding confirms that our model’s predictions are not only accurate but also prognostically meaningful. We further explored the relationships between other clinical factors and BCR. Among them, the prediction results of the EPE by the artificial intelligence model, the Gleason Grade Group after radical prostatectomy, and the highest Gleason Grade Group in the biopsy were significantly correlated with biochemical recurrence (seeSupplementary Table 1for details).

Kaplan–Meier curve of the EPE probability predicted by the model and biochemical recurrence: the curves in the figure represent the survival probabilities of the two groups, and the shaded areas are the confidence intervals. The data at the bottom show the number of patients at risk at different time points. Statistical analysis showed a significant difference between the two groups (p= 0.01), with a hazard ratio (HR) of 4.64 and a 95% confidence interval of (1.20, 17.98).

The EPE of PCa is associated with positive surgical margins, biochemical recurrence, and need for adjuvant therapy. However, definitive confirmation of EPE requires postoperative pathological examination. Accurate prediction of EPE during initial diagnosis is crucial in clinical practice [20]. In this study, we developed and validated a deep-learning pipeline for tumor tissue classification and prediction of EPE using digital pathology of prostate biopsy. The model in this study intentionally prioritizes validating the independent diagnostic value of pathological images, aiming to lay a foundation for multimodal integration and first establish the baseline utility of pathological morphology. To our knowledge, this is the first model to use preoperative biopsy images as the sole input for predicting pathological EPE status. Our results demonstrate that biopsy images contain critical microscopic features that correlate with EPE, offering valuable prognostic insights.

Our model achieved an AUC of 0.886 in the test set, outperforming the MSKCC nomogram (AUC = 0.780), Roach formula (AUC = 0.745), and Partin Table (AUC = 0.461), the results are basically consistent with previous studies [21]. The lower performance of Partin Table may be attributed to differences in cohort composition, with relatively few patients with clinical stage higher than T2c in our cohort. Previous AI-based studies on predicting EPE of PCa primarily relied on clinical and MRI data. Kwong et al. developed an AI-based prostate-specific peripheral extension risk assessment tool (SEPERA) by collecting twelve pieces of clinical information, including patient age, PSA, and GS score, to accurately predict lateral-specific EPE in patients with localized PCa, achieving an AUC of 0.77 [22]. Gu et al. applied an effective deep-learning network, NAFNet, to predict adverse pathological events based on MRI images and the AUC could reach 0.799 [23]. Some studies have combined radiomics and clinical data, such as Guerra et al.’s multimodal model, which achieved an AUC of 0.88 [24]. However, these studies overlooked the potential of biopsy pathological images in predicting EPE. Biopsy pathology-based prediction offers several advantages over MRI-based prediction for tumor staging. Unlike MRI, prostate biopsy is the gold standard for diagnosis and an indispensable step in the diagnosis and treatment of PCa. MRI provides a macroscopic view of PCa lesions, biopsy pathology provides direct microscopic evidence of tumor cells, allowing for more precise grading and staging through histological analysis. This detailed tissue information can reveal features—such as cellular atypia, mitotic rate, and specific biomarkers—that MRI may miss. AI-driven analysis of biopsy images enables the identification of subtle features that may not be apparent to pathologists, making it a powerful tool for predicting EPE. Biopsy pathology based DL models could capture microinvasive foci below MRI resolution (typically >3 mm) while avoiding susceptibility artifacts from rectal coils. Additionally, for patients with contraindications to MRI—such as those with pacemakers, metal implants, severe claustrophobia,—biopsy pathology is an effective alternative for EPE prediction.

At the same time, we also conducted a visual analysis of the model. We found that in pathological images with a high probability of EPE, the cell nuclei were larger, the nuclear atypia was more obvious, the density was higher, and the cancer cells did not form glands but were scattered and infiltrated in the stroma. Furthermore, Kaplan–Meier analysis confirmed that our AI-predicted EPE status significantly stratified patients by BCR risk after radical prostatectomy.

Despite these promising results, our study has limitations. First, this is a single-center study, necessitating external validation across multiple institutions before clinical implementation. Differences in tissue processing, staining protocols, and digital scanning methods may affect image quality and consistency. This variability can influence the deep learning model’s performance and may not be easily replicated across institutions. There are still some misjudgments in the current model. False positives may lead to unnecessary neurovascular bundle resection, increasing the risk of erectile dysfunction or urinary incontinence. False negatives may lead to undertreatment, increasing the positive rate of surgical margins. The model should be used as an auxiliary tool for comprehensive clinical evaluation rather than an independent decision-making basis. At present, multi-center validation is a priority to reduce risks. Additionally, the current model relies solely on pathological images without integrating MRI or clinical data. Studies have shown that PCa is an endocrine-responsive tumor, and its occurrence and development are affected by various hormone levels [25]. MpMRI combined with biopsy can improve the diagnostic accuracy of PCa [26], and the integration of MRI and PSA-derived indicators can achieve effective patient risk stratification, thereby providing a valuable decision-making approach [27]. In the future, efforts will focus on developing multimodal models that integrate multi-source data to enhance predictive accuracy.

This study was supported by the Natural Science Foundation of Liaoning Province (No. 2024-BS-047).

The data that support the findings of this study are available from the corresponding author upon reasonable request.

The authors declare no competing interests.Authors Yi Jing and Moyu Xia are affiliated with Neusoft Medical Systems Co., Ltd. The authors declare that no other financial or non-financial competing interests affect the objectivity of this study. All research processes were independent of the funders, and data analysis and conclusion derivation were not interfered with by the enterprise.