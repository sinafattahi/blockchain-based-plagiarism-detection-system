Early childhood development (ECD) lays the foundation for lifelong health, academic success and social well-being, yet over 250 million children in low- and middle-income countries are at risk of not reaching their developmental potential. Traditional measures fail to fully capture the risks associated with a child’s development outcomes. Artificial intelligence techniques, particularly machine learning (ML), offer an innovative approach by analysing complex datasets to detect subtle developmental patterns.

To map the existing literature on the use of ML in ECD research, including its geographical distribution, to identify research gaps and inform future directions. The review focuses on applied ML techniques, data types, feature sets, outcomes, data splitting and validation strategies, model performance, model explainability, key themes, clinical relevance and reported limitations.

Scoping review using the Arksey and O‘Malley framework with enhancements by Levacet al.

A systematic search was conducted on 16 June 2024 across PubMed, Web of Science, IEEE Xplore and PsycINFO, supplemented by grey literature (OpenGrey) and reference hand-searching. No publication date limits were applied.

Included studies applied ML or its variants (eg, deep learning (DL), natural language processing) to developmental outcomes in children aged 0–8 years. Studies were in English and addressed cognitive, language, motor or social-emotional development. Excluded were studies focusing on robotics; neurodevelopmental disorders such as autism spectrum disorder, attention-deficit/hyperactivity disorder and communication disorders; disease or medical conditions; and review articles.

Three reviewers independently extracted data using a structured MS Excel template, covering study ML techniques, data types, feature sets, outcomes, outcome measures, data splitting and validation strategies, model performance, model explainability, key themes, clinical relevance and limitations. A narrative synthesis was conducted, supported by descriptive statistics and visualisations.

Of the 759 articles retrieved, 27 met the inclusion criteria. Most studies (78%) originated from high-income countries, with none from sub-Saharan Africa. Supervised ML classifiers (40.7%) and DL techniques (22.2%) were the most used approaches. Cognitive development was the most frequently targeted outcome (33.3%), often measured using the Bayley Scales of Infant and Toddler Development-III (33.3%). Data types varied, with image, video and sensor-based data being most prevalent. Key predictive features were grouped into six categories: brain features; anthropometric and clinical/biological markers; socio-demographic and environmental factors; medical history and nutritional indicators; linguistic and expressive features; and motor indicators. Most studies (74.1%) focused solely on prediction, with the majority conducting predictions at age 2 years and above. Only 41% of studies employed explainability methods, and validation strategies varied widely. Few studies (7.4%) conducted external validation, and only one had progressed to a clinical trial. Common limitations included small sample sizes, lack of external validation and imbalanced datasets.

There is growing interest in using ML for ECD research, but current research lacks geographical diversity, external validation, explainability and practical implementation. Future work should focus on developing inclusive, interpretable and externally validated models that are integrated into real-world implementation.

A comprehensive and systematic search was conducted across four major databases and grey literature source.

The study followed the Preferred Reporting Items for Systematic Review and Meta-Analyses extension for Scoping Reviews guidelines to ensure transparency and methodological rigour.

A wide range of machine learning techniques and variants were captured, along with key model aspects such as output, features, performance, data types, data splitting and validation strategies, clinical relevance and explainability methods.

The review included only English-language articles, potentially excluding relevant studies published in other languages.

Studies focusing on neurodevelopmental disorders such as autism spectrum disorder, attention-deficit/hyperactivity disorder and communication disorders were excluded, which may limit the scope of findings.

Despite substantial evidence underscoring the importance of early intervention programmes for optimal childhood development,2over 250 million children in low- and middle-income countries (LMICs) are at risk of not reaching their full developmental potential.6This issue is particularly prevalent in sub-Saharan Africa (SSA), where factors such as poverty, malnutrition and a lack of stimulating home environments contribute to these developmental risks.7 8However, effective intervention can only occur if these children are identified early. Without early identification, opportunities to support their growth and development are missed, leading to long-term consequences for their academic, economic, behavioural and socio-emotional success. Thus, early identification is not only the first step, it is a crucial step to ensure that every child at risk receives the support they need to thrive.

Traditional population-level assessments rely on proxy measures like stunting or poverty levels, which may not fully capture a child’s holistic developmental progress.5In contrast, direct assessment tools offer precise evaluations but are resource-intensive and time-consuming.5This gap in ECD assessments is especially evident in low-resource settings, where scalable and accurate tools are urgently needed. Artificial intelligence techniques such as machine learning (ML) can bridge the gap between large-scale assessments and individual evaluations by analysing complex datasets to identify subtle patterns in child development.9By leveraging existing data like caregiver reports and clinical records, ML can predict developmental outcomes at lower costs, making it possible to identify at-risk children early on. This enables timely and targeted interventions that are crucial for supporting optimal development. Integrating ML into developmental assessments has the potential to transform child development monitoring globally, providing a scalable and cost-effective solution that enhances early identification and addresses the limitations of traditional methods.

Despite ML’s potential for identifying health outcomes,10its role in ECD research remains underexplored. This scoping review aims to map the existing literature, identify research gaps and highlight opportunities for leveraging ML to support young children’s full developmental potential. The primary research question guiding this review is: what is the current state of the use of ML in ECD research? As a secondary focus, we were also keen to explore the types of ML techniques applied, where they have been used, key variables examined (outcomes and features), data types, data splitting and validation strategies used, key themes, model performance, model explainability, clinical relevance and reported limitations. This review seeks to identify research gaps and inform future research directions that can maximise ML’s potential for enhancing early childhood outcomes globally.

This scoping review followed the methodological framework outlined by Arksey and O’Malley,11which was later enhanced by Levacet al.12To begin the scoping review, a suitable team was assembled consisting of experts in ML, ECD research and research synthesis.12The team agreed on the broad research question to be addressed and the overall study protocol. The review includes the following five key steps: (1) identifying the research question, (2) identifying relevant studies, (3) study selection, (4) charting the data and (5) collating, summarising and reporting the results. The last optional step of the framework, the ‘consultation exercise’, was not conducted, as stakeholder engagement was not required for this scoping review. A detailed review protocol was registered with the Open Science Framework on 2 July 2024. The protocol can be accessed using this link:https://osf.io/tdh86.

The initial search was conducted on 16 June 2024, in four electronic databases: PubMed, Web of Science, IEEE Xplore and PsycINFO,online supplemental text 1. Other than age limit filters placed on PubMed (birth to 18 years) and PsycINFO (birth to 12 years), no limits were applied to the database search. The search query was tailored to the specific requirements of each database and consisted of terms deemed by the authors to describe the scope of the review. These terms included “child”, “machine learning”, “physical development”, “language development”, “cognitive development”, “socioemotional development” and variants of these main terms. Boolean operators “OR” and “AND” were used to connect and refine the search results. The databases were selected due to their comprehensive coverage of peer-reviewed literature and their ability to allow for complex search string construction, Boolean operators and filtering options to refine search results effectively. Additionally, we conducted searches on grey literature databases, such as OpenGrey, on 7 September 2024, as well as reference tracking and hand-searching to identify relevant articles not captured in the initial search.

On search completion, all the identified citations were imported into Rayyan,14a software used to organise and manage literature reviews. Duplicates were identified and removed using the software. The remaining citations were managed for subsequent title and abstract relevance screening, as well as full-text screening by the software.

To be included in the review, studies needed to focus on children in their early years of life (0–8 years).4Eligible articles had to be written in English, use ML techniques or their variants such as deep learning (DL) and natural language processing techniques, and examine child development in specific domains such as cognitive, language, social-emotional and physical or motor development. There were no restrictions on the geographical location of the studies to allow for a comprehensive understanding of where ML has been applied across diverse populations and settings. Articles were excluded if the full text could not be obtained, if they examined the area of robotics; or if they focused on neurodevelopmental disorders such as autism spectrum disorder, attention-deficit/hyperactivity disorder, communication disorders or any disease condition such as malaria. Review articles were also excluded from consideration. Titles and abstracts were screened based on the inclusion criteria. The full text of the selected citations was then carefully evaluated by two independent reviewers (FNB and DC) to ensure they met the inclusion criteria, with reasons for excluding any sources that did not qualify being documented and reported. Any disagreements between the reviewers were resolved through discussions involving additional members of the author team.

Data from the articles included in the review were extracted and organised by three independent reviewers (FNB, DC and PNM) using a data extraction template created in MS Excel. Each reviewer completed the template independently. The extracted data covered various aspects, such as the country of origin, study aim, study theme, sample size, participants’ age, study outcomes, outcome measures, features, algorithms used, data types, data splitting and validation strategies, model performance, model explainability, clinical relevance and study limitations. The MS Excel template was refined as needed during the data extraction process. Studies were also excluded at this phase if they were found to not meet the eligibility criteria. The data extracted was further summarised to enhance the synthesis process.

A narrative approach, along with descriptive statistics and visualisation techniques, was employed to synthesise the extracted data from the included studies. This analysis encompassed several key areas, including publication trends over time, distribution of study themes and clinical relevance, types of algorithms used, countries represented, data types/sources used, outcomes and key features examined, data splitting and validation strategies, model performance and explainability and reported limitations. The goal was to understand the scope and focus of the studies across different geographical and methodological contexts. Visual representations such as flow charts and bar graphs were used to enhance the clarity and interpretation of these findings. The analysis was conducted using Python software V.3.11.4.

Patients or the public were not involved in the design, or conduct, or reporting, or dissemination plans of this research.

The search process identified 759 unique records. After screening and evaluating the articles for eligibility, 27 were selected for the final analysis. The search results are illustrated in a flow diagram infigure 1, while the data extracted from the included studies is presented inonline supplemental tables 1,2.

The 27 studies included in this scoping review originated from 12 different countries, with the USA leading in publications (n=11, 40.7%),15,25followed by the Republic of Korea (n=4, 14.8%).26,29Sri Lanka and China each contributed two publications (n=2, 7.4%),30 31while Finland, Bangladesh, Sweden, the Netherlands, Japan, the UK, Ireland and India each contributed one publication (n=1, 3.7%).32,39Over the 7 years covered in this review, publication numbers increased from one publication in 2018 to seven publications in 2023. As of the time of study retrieval, 16 June 2024, only one study had been published. The geographical distribution of studies is shown infigure 2.

To analyse the outcomes inonline supplemental table 1, seven categories were established: (1) cognitive, language and motor; (2) cognitive, language and emotional; (3) cognitive and motor development; (4) cognitive; (5) language; (6) motor; and (7) overall development. The most frequently investigated outcome in the studies was cognitive development (n=9, 33.3%),1618 23 25 30 35,38followed by motor development (n=8, 29.6%)15 19 26 29 32 33 39 41and language development (n=6, 22.2%).20 22 27 28 34 40Some studies examined combinations of outcomes, including cognitive, language and motor development (n=1, 3.7%)17; cognitive, language and emotional development (n=1, 3.7%)31; and cognitive and motor development (n=1, 3.7%).21One study focused on overall development (n=1, 3.7%),24while another did not specify any outcomes (n=1, 3.7%),28(figure 3).

A range of features was identified across the included studies as predictive of motor, cognitive, language or overall developmental outcomes in early childhood. The most frequently reported predictors fell into six broad categories.

First, brain features, both functional and structural, were predictive of motor, cognitive and language development delays. These included the frontal, limbic, occipital and parietal lobes; postcentral gyrus; superior occipital gyrus; subcortical grey features; thalamic features; curvature of the temporal lobe and insula; as well as morphometric and white matter features.

Second, anthropometric and clinical/biological indicators, such as gestational age, birth weight, head circumference, length, weight and Apgar score, were frequently reported in studies predicting motor and cognitive outcomes.

Third, motor indicators were commonly used to assess both motor and overall development. These included movement in prone, supine, sitting and standing positions, as well as key functional skills like sitting up, walking, running, jumping and climbing stairs. Additionally, some studies employed skeletal movement analysis and sensor-augmented toys to capture motor performance more objectively.

Fourth, linguistic and expressive features, such as grammatical and lexico-semantic complexity, utterance patterns, words and part-of-speech usage, were central to predicting language outcomes.

Fifth, socio-demographic and environmental factors, including maternal education, maternal age, socioeconomic status, sex, exposure to non-family language and maternal behaviours such as alcohol use and smoking, were linked to cognitive and language development.

Lastly, medical history and nutritional variables, such as a history of pulmonary hypertension, blood transfusions, antenatal corticosteroid exposure, patent ductus arteriosus, breastfeeding status, oxygen support, parenteral alimentation, maternal body mass index and twin status, were reported to be associated with cognitive and language development,online supplemental table 2.

The most frequently used measure for determining outcomes was Bayley Scales of Infant and Toddler Development-third edition (n=9, 33.3%).15 17 18 22 23 30 34 37 38Five studies did not specify the measures used (n=5, 18.5%).24 27 28 31 35Two studies employed the Korean Developmental Screening Test for Infants and Children (n=2, 7.4%),26 29while another two used the Mullen Scales of Early Learning (n=2, 7.4%).21 25Other measures reported include the Kaufman Brief Intelligence Test, second edition (n=1, 3.7%),36Test of Gross Motor Development, third edition (n=1, 3.7%),39Movement Assessment Battery for Children, second edition (n=1, 3.7%),19MacArthur-Bates Communicative Development Inventory (MBCDI) (n=1, 3.7%),40MBCDI/Clinical Evaluation of Language Fundamentals-Preschool 2 (n=1, 3.7%),20Alberta Infant Motor Scale (n=1, 3.7%),19Test of Gross Motor Development, second edition (n=1, 3.7%),41Reading and Math Assessments (n=1, 3.7%)16and Developmental Reference Age Prediction (n=1, 3.7%),33(figure 4).

To analyse the data types inonline supplemental table 1, eight categories were established: video, image, image-based, sensor-based, survey-based, text, clinical and game-based data. The most frequently used type of data in the included studies was image data (n=6, 22.2%),1516 21,23 35followed by both video data19 26 29 30 39and image-based data,17 25 31 34 41both representing 18.5% of the studies (n=5). Image-based data encompassed a variety of other types, including socio-demographic, clinical, audio and game data. Sensor-based data, which included socio-demographic and physical data, was used in four articles (14.8%).24 32 33 40Survey-based data, incorporating environmental data, totalled to three articles (11.1%).16 20 36Additionally, text data accounted for two articles (7.4%),27 28while clinical37and game-based data38were each used in one article (3.7%), (figure 5).

The majority of the 27 studies included in this review focused solely on prediction tasks (n=20, 74.1%).1517,27 30 32Other studies addressed both prediction and additional tasks, such as data curation (n=2, 7.4%),28 29data curation combined with object recognition (n=2, 7.4%),31 35causal inference (n=1, 3.7%),16object recognition (n=1, 3.7%)41and anomaly detection (n=1, 3.7%).39Out of the 27 studies reviewed, only 1 study (3.7%)33had been practically implemented in the context of clinical trials to quantify infants’ motor performance without healthcare worker supervision, using infant wearables comprising a multisensor garment paired with an automated DL-based algorithm. The remaining 26 studies (96.3%) were still in the research or development phase. While several studies focused on early screening, identification or intervention, none had progressed to clinical application,online supplemental table 2.

Nine studies1517 18 26 29,31 37 38adopted a common approach of splitting the data into training and test sets using a 70:30 or 80:20 ratio. In these cases, 70% or 80% of the data was used for training and cross-validation for hyperparameter tuning, typically employing k-fold, repeated or stratified cross-validation, while the remaining 30% or 20% served as an internal test set. In contrast, other studies1621,24 33 34 36 40relied solely on cross-validation techniques, such as k-fold or leave-one-out cross-validation, without including a separate internal test set. Some studies (n=2, 7.4%)20 25did not specify the type of cross-validation used but reported using an independent test set for external validation. A few studies applied uncommon data split ratios, such as 98:2,3293:728and 85:15,39often due to small sample sizes or other dataset-specific constraints. Some studies19 27 35 41did not report whether or how they split their data for model training and evaluation,online supplemental table 2.

The model performance analysis focused on the types of algorithms used, the evaluation metrics applied and the corresponding results. For SMLC, the most reported metric was the area under the curve (AUC), which appeared in six studies with values ranging from 0.75 to 0.92.23 26 30 36 37 40One study30also reported recall (0.832) and precision (0.823). Additionally, two studies23 36provided specificity, with values ranging from 96% to 98%, sensitivity (86% to 89%) and accuracy values between 91% and 95%.

Accuracy was the primary performance metric in four studies,20 24 34 36with values ranging from 76% to 94.4%. One study combined accuracy with sensitivity (0.89) and specificity (0.86). Another study22exclusively reported sensitivity (89%–100%) and specificity (86%–100%). However, one study16did not report conclusive results.

In studies using DL techniques, accuracy was the primary performance metric in six studies,2527,29 31 39with reported values ranging from 78% to 99.3%. One study41did not report performance details. Another study33provided an R² value of 0.99. A study combining DL and TL reported AUC values of 0.85 and 0.87,17while a study applying TL alone35did not specify performance metrics.

For SMLR, two studies19 33reported R² values of 0.95 and 0.99, while another study29reported a root mean square error (RMSE) of 0.18. Other studies15 38did not provide any performance measures.

Out of the 27 studies reviewed, approximately 41%15,1820 24applied explanation methods to interpret model outputs. These included Random forest feature importance, permutation importance, SHapley Additive exPlanations, random stump analysis, backtracked model weights, Gradient-weighted Class Activation Mapping, causal inference techniques, Least Absolute Shrinkage and Selection Operator regression and Circos plots. The remaining 59% of studies did not use any explanation method,online supplemental table 2.

This scoping review examined the application of ML techniques in ECD research, identifying existing evidence and highlighting gaps for further exploration. The results indicate a growing interest in using ML methodologies to enhance the understanding and prediction of early childhood developmental outcomes. However, notable limitations in the existing literature require attention.

The review also found that studies frequently relied on image, video and sensor-based data, while traditional survey and text-based data were less commonly used. Consistent with a prior review,44we observed a heavy reliance on high-tech modalities. This preference for image and video data may limit the incorporation of important risk factors, such as maternal mental health and parental economic variables, which are crucial for understanding child development.3 4Incorporating additional data sources, including parental inputs and environmental indicators, could provide a more comprehensive view of child development and enhance the robustness of ML models.

Diverse features, such as brain data, clinical indicators, medical history, nutrition and socio-demographic factors, were found to be predictive of the same developmental outcomes across studies. For example, cognitive development was predicted by brain-based measures, clinical/biological indicators, medical history, nutrition and socio-demographic variables. These findings mirror those in a prior neurodevelopmental review44and suggest that future research should prioritise comprehensive, multimodal approaches that integrate diverse types of predictors to improve accuracy and generalisability. For a long time, the expenses related to brain imaging have been a barrier to its inclusion in many child development data collection processes. However, with the emergence of faster and relatively affordable imaging technologies, there is hope that more studies in LMICs will begin to incorporate imaging data.

Across all the reviewed studies, only one demonstrated practical implementation and clinical use, while the rest, despite exploring early screening, identification or intervention, remain in the research or development phase. Several studies aimed to support early screening and intervention, but none delivered integrated or actionable frameworks to guide care. Only one study indirectly supported early cognitive development, without a direct pathway to clinical implementation. Consistent with a prior review,44this reveals a major gap between tool development and real-world application. Future directions should prioritise validating these models in diverse, real-world populations, embedding them into healthcare and education systems and linking screening outcomes to concrete early interventions. There is also a need for implementation studies that address feasibility, cost and scalability, especially in low-resource settings where early detection tools are most urgently needed.

The age distribution of predictive modelling studies in ECD reveals a concentration on children older than 2 years, with relatively fewer studies focusing on infants and younger toddlers. This presents a limitation in the context of early identification and intervention, as the optimal window for neuroplasticity occurs during infancy.5To maximise the impact of early detection and support timely care, future research should focus on developing models tailored to younger age groups, using accessible and scalable data sources.

Data splitting and validation approaches varied widely across studies. Notably, few studies used standard train-validation-test splits, while others relied only on cross-validation or did not report their methods. Consistent with a prior review,44external validation was rarely performed and a few studies used unconventional split ratios due to small sample sizes. Future studies should adopt standardised and transparent validation methods. Clear reporting practices and the inclusion of external validation are essential to enhance the generalisability and comparability of ML models across studies.

In evaluating model performance, the included studies used a range of metrics including accuracy, sensitivity, specificity, AUC, recall, precision, RMSE and R² values. Overall, the performance of the SMLC was reasonable and aligned with previous studies,44 45with the most reported metric being AUC, which ranged from 0.75 to 0.92, demonstrated good discriminative ability. Accuracy, sensitivity and specificity were reported in the selected studies and demonstrated good prediction performance of the models. Similarly, studies using SMLR and DL techniques showed comparable performance, with accuracy ranging from 78% to 99.3%, and a few studies reported R² values close to 1, indicating high predictive power. Although some studies did not provide complete performance details, the reported results suggest that these algorithms have the potential to support accurate prediction. Echoing previously observed trends in,44more than half of the studies did not apply any model explanation methods, limiting transparency and interpretability of their findings. This reduces the ability to understand which features drive predictions, especially in clinical or developmental contexts. Future studies should prioritise the use of explanation techniques to enhance model interpretability. This will support better understanding, trust and potential clinical adoption of predictive models, particularly when used by non-technical stakeholders like clinicians or caregivers.

Additional challenges noted in the review include unobserved confounding factors such as child’s age, birth weight and family income; missing data; and sampling biases due to the overrepresentation of low-risk, more advantaged participants, such as older, well-educated mothers with higher birth weight infants, which may limit the generalisability and equity of predictive models. Overcoming these issues requires rigorous data pre-processing and the integration of domain knowledge. Furthermore, computational and internet connectivity limitations were also identified as practical barriers to implementing ML models in ECD research.

Lastly, it should be acknowledged that the scoping review process had two main limitations. First, only English-language articles were included, which may have led to the exclusion of relevant studies published in other languages. This introduces a potential language bias, particularly in global research areas such as ECD and ML, where valuable insights may be published in non-English journals. Second, the review excluded studies focusing on neurodevelopmental disorders such as autism spectrum disorder, attention-deficit/hyperactivity disorder and communication disorders. While this exclusion helped maintain a clear focus on general child development, it may limit the applicability of the findings to children with developmental challenges who might also benefit from early prediction and intervention tools. Future reviews could broaden the scope to include such populations for a more comprehensive understanding.

This scoping review underscores the growing interest in applying ML to ECD, with a noticeable increase in publications over the past 7 years. However, the geographical representation remains heavily skewed toward high-income countries, with minimal contributions from LMICs, particularly in SSA. The most used algorithms were supervised ML classifiers and DL methods, with cognitive, motor and language development being the primary predicted outcomes. Yet, predictions were often made after the age of two, limiting opportunities for earlier intervention.

The predictors used spanned brain imaging, clinical indicators, behavioural milestones, language features, socio-demographic factors and nutrition. However, there was a reliance on high-tech data types like imaging and video, which may not be feasible in low-resource settings. Most studies focused on prediction rather than causal inference or real-world implementation, and nearly half did not apply any explainability methods, hindering model transparency. Moreover, small sample sizes, lack of external validation and imbalanced datasets were frequent limitations that threaten the robustness and generalisability of current models.

Future research should focus on collecting comprehensive, longitudinal data that captures developmental trajectories and contextually relevant factors and on expanding outcome domains to include socioemotional development and overall child development. Priority should be given to explainability, standardised validation methods and the development of scalable tools suitable for frontline use in diverse global contexts. Additionally, expanding research efforts in LMICs is critical to ensuring that ML tools for ECD are equitable, culturally relevant and practically useful in addressing developmental challenges worldwide.