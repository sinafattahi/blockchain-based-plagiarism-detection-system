Patient enrollment can be a substantial burden in rare disease trials.
One potential approach is to incorporate external control (EC) into concurrent randomized trials, or EC borrowing, to reduce such burden.
Extensive research has been conducted to explore statistical methodologies.
As in all designs, type I error control is essential.
Conditional type I error rate has been used in the literature as the de facto metrics for type I error rate.
However, research has shown that controlling the conditional type I error rate at the alpha level will disallow EC borrowing.
Therefore, EC borrowing is practically at an impasse.
Kopp‐Schneider et al. concluded that a more appropriate metrics for type I error is necessary.
We show that a trial with EC borrowing can be considered as a two‐stage adaptive design.
With this perspective, we propose to define type I error as the weighted averages of conditional type I error rate in trials with EC borrowing.
Dynamic borrowing methods for controlling type I error are proposed.
In some rare diseases, there may be difficulties enrolling enough patients to implement full randomization.
Instead, some patients in the control group may need to be borrowed from external sources.
This is commonly referred to as external control borrowing, or EC borrowing.
Consequently, the data will include a randomized treatment arm (T), a randomized current control arm (CC) and the borrowed EC, and the efficacy evaluation compares T with CC+EC.
The EC data were collected at a different time or environment (i.e., prior to or outside the current trial), where the standard of care procedures may be different from those in the current randomized trial, and the patient profiles from CC and EC may be different, thus potentially there can be selection bias which can in turn bias the efficacy evaluation of T versus CC+EC.
EC borrowing is valid (i.e., without type I error inflation) when EC and CC are similar, or that there is exchangeability between EC and CC.
However, exchangeability is not verifiable in practice.
Developing a method that can control type I error for EC borrowing without requiring the unverifiable exchangeability assumption has been the most critical challenge.
Pocock [1] was the first to propose a Bayesian model in which exchangeability was assumed.
Various dynamic borrowing methods, both Bayesian [2,3,4,5,6,7,8,9,10,11,12,13,14] and frequentist [13,15,16] were later proposed.
The basic motivation for dynamic borrowing is that the impact of selection bias can be discounted or reduced if less weight is given to the EC data when the difference between EC and CC is large.
Bayesian models [2,3,4,5,6,7,8,9,10,11,12,13,14] use different priors for EC to achieve the dynamic effect.
Frequentist methods include the test‐and‐pool (TNP) methods [13,16] and a weighted average approach [15].
It has been recognized [17,18,19] that type I error discussed in all literature are conditional on the borrowed EC data.
If EC is borrowed, then the conditional type I error rate (con‐TPI‐err) can be greater thanα, regardless of the given weight.
If the validity of EC borrowing requires controlling the con‐TPI‐err atα, then no dynamic method, regardless Bayesian, or frequentist, will meet this criterion.
It has been suggested [17] that a proper metric for type I error should not be conditional.
Best et al. [20] proposed an average type I error that averages over some informative prior regarding the control (design prior), which controls the unconditional type I error when the design prior is the same as the analysis prior, that is, under the unverifiable exchangeability assumption.
The objective of this article is to identify such a metric, which can assess type I error without requiring exchangeability.
We examine the parallels between adaptive designs for randomized trials and the trials with EC borrowing.
In adaptive designs, the metric of type I error is the weighted (by the distribution of the interim analysis data) average (e.g., [21,22]) of con‐TPI‐err, but not the con‐TPI‐err.
Applying this logic, the type I error in trials with EC borrowing can be defined similarly.
We propose some dynamic borrowing methods with which type I error can be controlled even when there is small deviation from exchangeability, ensuring the validity (i.e., adequate control of type I error) of trial design.
The proposed methods are supported by the DACT (Design and Analysis of Clinical Trials) software athttps://www.innovatiostat.com/software.
The software is free for academic researchers and research institutions.
Computing codes are available upon request.
Letθbe an efficacy parameter of interest.
For example,θmay be the mean of a normally distributed variable, or the mean rate of a binary or Poisson variable for each treatment group.
Letθ^be an unbiased maximum likelihood estimate (MLE) ofθands.e.θ^its standard error.
The associated Fisher's information time (e.g., [23])tis estimated byt^=s.e.θ^−2.
The Wald statistic isZt=θ^s.e.θ^−1~Nθt1, and the score function [24] isSt=θ^s.e.θ^−2=θ^t^~Nθtt.
The score function has independent increment, that is,Ss+t−Ss~Nθttand is independent [24] ofSs.
GivenSs=xs, the conditional distribution ofSs+tisxs+Bt+θt~Nxs+θtt, whereBt~N0,tis the standard Brownian motion [24].
This property is critical to the development of our approach.
Note thatθ^~Nθ1/t.
We note that the properties of the score function are all asymptotic, large sample properties.
LetθEC,θCC, andθTdenote theθrelated to the EC, CC, and T arms, respectively.
In this article,θC=θCC.
Let∆C=θCC−θEC.
The assumption of exchangeability/comparability meansθEC=θCC=θC, or∆C=0.
LetσEC,σCC, andσTbe the standard deviations.
Letθ^EC,θ^CC,θ^Tandσ^EC,σ^CC,σ^Tbe the corresponding estimates.
LetNEC,NCC,NTbe the sample sizes for EC, CC, and T. LettEC,tCC, andtTbe the information times for EC, CC and T, respectively.
Therefore the score function for EC, CC and T areSECt=θ^ECt^EC~NθECtECtEC,SCCt=θ^CCt^CC~NθCCtCCtCC, andSTt=θ^Tt^T~NθTtTtT, respectively [24].
The score function approach can be applied to any distribution (e.g., normal distribution, binary distribution, Poisson distribution, and negative binomial distribution) with which an unbiased MLE is available.
For normal distributions,tEC=NEC/σEC2,tCC=NCC/σCC2, andtT=NT/σT2.
Thenθ^EC~NθEC1/tEC,θ^CC~NθCC1/tCC, andθ^T~NθT1/tT.
In this article,θ^ECindicates a random variable, whilexECindicates a specific observed value ofθ^EC.
Note thatθ^ECandt^EC=s.e.θ^EC−2may be derived from meta‐analysis, propensity score matching or weighting, or other matching methods, statistical modeling, or as the mean and the reciprocal of the variance of the Bayesian prior distribution ofθECbased on the observed EC data.
There are specific, exact forms of prior and posterior distributions for different distributions such as the normal distribution, binary, exponential distributions, and so on.
By using the score functionSt~Nθtt, they can all be approximated with the prior and posterior distributions for normal distributions.
Such approximations allow for easier calculation and exploration of the properties of the posterior distributions.
Hence, we assume that both the prior and posterior distributions are normally distributed.
In Bayesian methods, the parametersθC,θCC,θEC, andθTare random variables.
Pocock [1] proposed a model in which the prior distribution is, whereδ=∆C~N0σδ2,tEC,Pocock=σEC2/NEC+σδ2−1, andxECis the observed value ofθEC.
The posterior distribution forθCispθCθ^CC=y~Nθ1τ12, whereτ12=wEC2tEC+wCC2tCCandθ1=wCCθ^CC+wECxEC, withwEC=tEC,PococktCC+tEC,Pocock, andwCC=1−wEC.
Other Bayesian models have been proposed, including the meta‐analytic‐predictive priors [9,10,12], mixture of conjugate priors [12], power/commensurate prior [4,5,6,7,13], calibrated power prior [11], equivalence probability weighted power prior [2], and propensity score‐integrated Bayesian prior [14].
It has been noted that with normal endpoints and conjugate priors, the posterior mean is a weighted average of prior mean and data mean [12].
This means that, in somewhat general terms, different priors are associated with different information timestEC,Bayesian, which corresponds to variouswEC=tEC,Bayesian,tEC,Bayesian+tCC, andwCC=1−wEC.
The expression of the weights has also been discussed in Best et al. [20], and does not require that the priors have closed forms.
Assuming a non‐informative prior forθTbefore the randomized trial, the posterior distribution ofθTgivenθ^TisθT~Nθ^TσT2/NT=Nθ^T,1/tT.
The posterior distribution ofθT−θCis thenθT−θC~Nθ^T−wCCθ^CC+wECxEC1tT+wEC2tEC+wCC2tCC[1].
The null hypothesis is rejected if the1−α×100%credible interval ofθT−θCexcludes 0, or equivalently,θ^T−xECwEC−θ^CCwCC1/tT+wEC2/ttEC,Bayesian+wCC2/tCC≥zα.
The type I error rate is the probability of rejecting the null hypothesis,θT−θC=0when the null is true.
An often‐mentioned frequentist method is the test‐and‐pool (TNP) method [13,16].
The EC data will not be borrowed ifθ^CC−xECis larger than a threshold.
Ifθ^CC−xECis smaller than the threshold, the EC data will be borrowed and pooled with CC data.
The test statistic isθ^T−xECwEC−θ^CCwCC1/tT+wEC2/tEC+wCC2/tCCwith EC borrowing (wherewEC=tECtCC+tEC,,wCC=1−wEC), andθ^T−θ^CC/1/tT+1/tCCwithout EC borrowing.
The null hypothesis is rejected if the test statistic is no less thanzα.The type I error rate is the probability of rejecting the null hypothesis,θT−θC=0when the null is true.
In frequentist statistics, the parameters of interest,θT,θC, andθ=θT−θCare considered to be constants.
A critical element of frequentist statistics is null hypothesis significance testing (NHST): the null hypothesis is thatθ≤0, and the alternative hypothesis is thatθ>0(assuming positiveθindicates efficacy).
The null hypothesis is rejected if the1−α×100%confidence interval excludes0.
Type I error is the probability of incorrectly rejecting the null hypothesis.
In a frequentist TNP approach, the null hypothesis is rejected ifθ^T−xECwEC−θ^CCwCC1/tT+wEC2/tEC+wCC2/tCC≥zα.
In Bayesian statistics,θT,θC, andθ=θT−θCare considered to be random variables.
A Bayesian alternative to NHST is a comparison between the posterior distributions ofθT,θC[25].
The equivalence of frequentist null hypothesis is that the distributions ofθT,θCare similar, or if the posterior distribution ofθis not different from 0.
The equivalence of frequentist alternative hypothesis is that the distributions ofθT,θCare different, or if the posterior distribution ofθis different from 0.
In practice, the new treatment is considered to be effective if the1−α×100%credible interval ofθ(from the posterior distribution) excludes 0 (i.e., the null hypothesis is rejected).
The Bayesian equivalence of frequentist type I error is the probability of incorrectly declaring the new treatment to be effective.
With Bayesian methods (including [1]), the null hypothesis is rejected (or the new drug is considered to be effective) ifθ^T−xECwEC−θ^CCwCC1/tT+wEC2/tEC,Bayesian+wCC2/tCC≥zα.
The exclusion of 0 from the1−α×100%confidence interval (frequentist) and the exclusion of 0 from the1−α×100%credible interval (Bayesian) are mathematically equivalent.
Hence, Bayesian methods and the frequentist TNP are mathematically similar, with the only differences being in the structure of the information timestECandtEC,Bayesian, which results in different weightswECandwCC.
Hence, both the power and type I error rate depend on the observed value ofxECand are thus conditional.
This has also been observed in literature (e.g., [18,19]).
The con‐TPI‐err increases whenxECdecreases.
The property of con‐TPI‐err raises a question whether it should be controlled and at what level.
It has been observed [17,19] that if the con‐TPI‐err must be controlled atα, then EC borrowing must be disallowed.
Kopp‐Schneider et al. [17] concluded that con‐TPI‐err may not be the appropriate metric for type I error control.
All of the dynamic borrowing procedures of both Bayesian and frequentist approaches are fundamentally based on the strategy of dynamically discount the amount of information borrowed from external data based on the discrepancy between the external and current data (also known as prior‐data conflict) ([17]).
The dynamic borrowing strategy aims to control type I error when exchangeability does not hold.
It is conceptually appealing, but no literature has provided any means or criteria to assess whether the discount by a given dynamic method is or isn't sufficient.
In other words, the discounts in all literature are, in fact, arbitrary.
In this section, we study the similarities between a conventional adaptive design (section4.1.1), an unconventional adaptive design (section4.1.2), and trials with EC borrowing (section4.2).
Metrics for type I error and threshold for type I error control for trials with EC borrowing are then proposed from the perspective of adaptive designs in Section4.2.2.
Consider a two‐stage adaptive design for a randomized trial that compares a test treatment and a control.
Suppose that an interim analysis will be conducted at information timet1and a final analysis att2.
Letθ^t1andθ^t2be the point estimates forθat information times t1 and t2.
Letθ^t1=x1.
LetZt2be the Wald statistics att2.
At the final analysis, the null hypothesisH0will be rejected ifZt2≥zα.
Under the null hypothesis ofθ=0,, that is, the conditional estimateθ^t2has a biased mean ofθ^t1t1/t2=x1t1/t2.
The conditional power isPZt2≥zαθ^t1=x1=1−Φzαt2−x1t1t2−t1−θt2−t1.
Under the null hypothesis ofθ=0, the con‐TPI‐err isecv,x1=et2,x1=1−Φzαt2−x1t1t2−t1, (cv is shorthand for conventional) which increases whenθ^t1=x1increases (Figure1).
Conditional type I error rate and conditional bias in a conventional adaptive design.
Letxα=zαt2−t2−t1/t1.
Thenecv,xα=et2,xα=α.
Letα−=−∞xα, andα+=xα+∞, thenecv,x<αfor allxinα−andecv,x>αfor allxinα+.
LetX~Nμσ2.
Letfxbe a function ofx,Ian interval, and letPμI=∫I12πσexp−x−μ22σ2dxbe the area under the density curve ofNμσ2(equivalently,X) over the intervalI.
LetεI,μfx=1PμI∫I12πσexp−x−μ22σ2fxdxbe the weighted (by the density ofNμσ2) area under thefxcurve over the intervalI.
In an adaptive design, at interim analysis att1,X=θ^t1,Nμσ2=Nθt11/t1.
Under the null ofθ=0, the con‐TPI‐err isecv,x=et2,x=1−Φzαt2−xt1t2−t1, and the metric for type I error rate isε−∞+∞,θt1ecv,x.
The type I error is controlled ifε−∞+∞,θt1ecv,x≤α.
An alternative approach for type I error control is to use the two parametersεα+,θt1ecv,xandεα−,θt1ecv,xas dual metrics.
Note thatPθt1α++Pθt1α−=1, andε−∞+∞,θt1ecv,x=Pθt1α+εα+,θt1ecv,x+Pθt1α−εα−,θt1ecv,x.
Note thatεα+,θt1ecv,x>α, becauseecv,x>αfor allxinα+.
Suppose that some adaptive change is made at the interim analysis, for example, if the sample size is changed toNnew, with a new information timeTnew, and the new con‐TPI‐err iseTnew,x, then the unconditional type I error, after the adaptive change, with the single metric isε−∞+∞,θt1eTnew,x, weighted by the density ofNθt11/t1.
Type I error is properly controlled if (e.g., [21,22])ε−∞+∞,θt1eTnew,x≤ε−∞+∞,θt1ecv,x.
If other adaptive changes are made with the new conditional type I error rateeadap,x, then the type I error is properly controlled ifε−∞+∞,θt1eadap,x≤ε−∞+∞,θt1ecv,x.
The con‐TPI‐errecv,x, oreTnew,xare not metrics for type I error control and controlling the con‐TPI‐err atαin an adaptive design is never considered to be of significance or necessary.
The only way to control all con‐TPI‐err atαis to discard the data before the interim analysis and start a new trial after the interim analysis, which would be statistically illogical in an adaptive design.
In this unconventional design, all parameters are the same as in a conventional two‐stage adaptive design.
Suppose that the sample sizes areNCfor the control arm andNTfor the new treatment arm.
The trial will have one interim analysis and a final analysis.
LettC,1be the information time for the control arm at the interim analysis,θ^C,tC,1be the point estimate of the efficacy parameterθfor the control arm attC,1.
In this unconventional adaptive design, onlyθ^C,tC,1will be observed attC,1, that is,θ^C,tC,1~NθC1/ttC,1andSCtC,1~NθCtC,1tC,1.
Such an interim analysis is hypothetical and unlikely to happen in an actual adaptive design for common diseases, hence it is unconventional.
Unconditional type I error rate can be properly controlled and hence such interim analysis is statistically valid.
It helps to explain the adaptive design perspective of trials with EC borrowing.
Let the observation beθ^C,tC,1=xC,tC,1.
At the final analysis, the information times aretT(for test arm, corresponding toNT) andtC,2(for control arm, corresponding toNC).
Let∆tC,2,1=tC,2−tC,1.
The null hypothesisH0will be rejected ifθ^T−θ^C,tC,2/1/tT+1/tC,2≥zα.
Letw1=tC,1tC,2andw∆2,1=∆tC,2,1tC,2.
Thenθ^C,tC,2=w1θ^C,tC,1+w∆2,1θ^C,∆tC,2,1.
Given thatθ^C,tC,1=xC,tC,1,and.
Hence the conditional bias forθ=θT−θCisθC−θ^C,tC,1w1.
Lety=θC−xC,tC,1, the con‐TPI‐err, under the null ofθT=θC, iseuncv,y=etT,tC,2,y=1−Φzα1/tT+1/tC,21/tT+w∆2,12/∆tC,2,1−yw11/tT+w∆2,12/∆tC,2,1, whereuncvis the shorthand for unconventional.
Letyα=zαw11/tT+1/tC,21/tT+w∆2,12/∆tC,2,1−11/tT+w∆2,12/∆tC,2,1.
Theneuncv,yα=α.
Letα−=−∞yα,α+=yα+∞.
Theneuncv,y<αfor allyinα−andeuncv,y>αfor allyinα+.
We note that Figures1and2are almost indistinguishable.
Similar to a conventional two‐stage adaptive design, con‐TPI‐err is not a metric for type I error control.
The unconditional type I error of the trial isε−∞+∞,θC−θtC,1euncv,y, weighted by the density ofNθC−θtC,1,1/t1=N0,1/tC,1.
Hence the metric isε−∞+∞,0euncv,y.
Per the metrics, it is not necessary to require that the con‐TPI‐err be controlled atα, and to achieve such a goal would require discarding the data up to the interim analysis and starting a new trial after the interim analysis.PθC−θtC,1α+=P0α+,PθC−θtC,1α−=P0α−,εα+,θC−θtC,1euncv,y=εα+,0euncv,y,εα−,θθC−θtC,1euncv,y=εα−,0euncv,yare defined similarly and.
Note thatεα+,θC−θtC,1euncv,y>α, becauseeuncv,y>αfor allyinα+.
Conditional Type I error rate and conditional bias in an unconventional adaptive design.
Suppose that some adaptive changes are made at the interim analysis, for example, if the sample sizes for the control arm and the new treatment arm are changed toNC,newandNT,newwith new information timesTC,new,TT.new.
LetTnewbe the combined new information time.
Let the new con‐TPI‐err beeTnew,y, which can be calculated similarly toetT,tC,2,yusing the properties of the score function (omitted since the actual form ofeTnew,yis not critical here).
The unconditional type I error rate with the single metric isε−∞+∞,θC−θtC,1eTnew,y.
The critical valuezαfor rejecting the null hypothesis can be adjusted to somecnewsimilarly (omitted here for simplicity, and also because the derivation is not critical for this article) as in Gao, Ware, Mehta, [21] to maintain the conditional type I error rate.
Type I error is properly controlled if (e.g., [21,22])ε−∞+∞,θC−θtC,1eTnew,y≤ε−∞+∞,θC−θtC,1euncv,y.
If other adaptive changes are made with the new conditional type I error rateeadap,y, then the type I error is properly controlled ifε−∞+∞,θC−θtC,1eadap,y≤ε−∞+∞,θC−θtC,1euncv,y.
A study design with EC borrowing can be considered the same as an unconventional two‐stage adaptive design.
Under the assumption of exchangeability (i.e.,∆C=θCC−θEC=0), simply pooling the EC with CC is statistically valid (i.e., there is no type I error inflation).
Following the notations in Section4.1.2, assuming exchangeability and considerθ^ECasθ^C,tC,1,tECastC,1, andtC,2=tEC+tCC.
LetwEC=w1, andwCC=w∆2,1.
The observed data ofθ^EC=xECcorresponds toθ^C,tC,1=xC,tC,1andy=θCC−xECcorresponds toy=θC−xC,tC,1.
Then parallel to the unconventional design, the conditional bias forθ=θT−θCCisθCC−θ^ECwEC=ywEC.
The conditional type I error rate is (EC−poolmeans simple pooling of EC data)eEC−pool,y=1−Φzα1/tT+1/tCC1/tT+wCC2/tCC−ywEC1/tT+wCC2/tCC.
Letyα=zαwEC1/tT+1/tCC1/tT+wCC2/tCC−11/tT+wCC2/tCC.
Thenyαsatisfies thateEC−pool,yα=α.
Letα−=−∞yα,α+=yα+∞.
TheneEC−pool,y<αfor allyinα−andeEC−pool,y>αfor allyinα+.
The con‐TPI‐err and conditional bias are exactly the same as in an unconventional adaptive design and the curves are exactly the same as in Figure2(omitted for simplicity).
The unconditional type I error rate of the trial isε−∞+∞,θCC−θECeEC−pool,y=ε−∞+∞,∆CeEC−pool,y, weighted by the density ofNθCC−θEC1/tEC=N∆C,1/tEC.
Per the metrics, it is not necessary to require that the con‐TPI‐err be controlled atα, and to achieve such a goal would require discarding the data up to the interim analysis (i.e., the EC data) and starting a new trial after the interim analysis (i.e., disallowing the EC borrowing).PθCC−θECα+=P∆Cα+,P∆Cα−,εα+,∆CeEC−pool,y,εα−,∆CeEC−pool,yare defined similarly.
Note thatεα+,∆CeEC−pool,y>α, becauseeEC−pool,y>αfor allyinα+.
Then, whenθC−xEC=y<yP,Pbr<Pnb, andPbr>PnbifθC−xEC>yP.
In practice, EC borrowing is based on power consideration: it is preferred only when there is benefit of increased power, otherwise EC borrowing is not desirable.
WhenθC−xEC>yP, pooling of EC data will increase the power and EC borrowing will be desirable.
IfθC−xEC<yP, pooling of EC data will decrease the power, and not desirable.
Hence,yPis the dividing point of whether EC borrowing will be beneficial or not.
This practice will be referred to as power consideration‐based borrowing, or PCB borrowing in this article.
The logic of PCB borrowing is to borrow EC if it increases power, and do not borrow if it reduces power.
This logic has never been questioned in any literature, and it will be assumed to be acceptable in this article as well.
Under the null,θ=θT−θC=0, andyα=yP.
Hence, in this article, PCB pooling means pooling EC inα+, and no pooling inα−area.
Because of the difference in pooling, it is necessary to consider the behavior of con‐TPI‐err separately inα+andα−.
In Figure3a, the dark green dashed curve is the con‐TPI‐err with simple pooling, and the red horizontal line is the con‐TPI‐err curve with no borrowing in theα−area.
Con‐TPI‐err curves and conditional power curves for simple and PCB pooling.
Under exchangeability,θEC=θCCand∆C=0.
Pooling in theα+area is valid because it is the same as if an interim analysis is conducted in an unconventional adaptive design, but without any adaptive action.
On the other hand, the decision of not to borrow inα−is acceptable because the logic of PCB pooling reflects the motivation of EC borrowing and is assumed acceptable (i.e., in all literature).
The combination of the con‐TPI‐err curve of no borrowing inα−with that from pooling inα+forms the con‐TPI‐err curve for PCB pooling.
This combined con‐TPI‐err curve, denoted asey=ePCB−pool,y, is plotted in Figure3b(refer to Figure3a, as the combination of the red horizontal line inα−and the dashed curve for pooling inα+.
The dashed curve inα−has been removed).
Figure3cshows the con‐TPI‐err curve and the conditional power curve with simple pooling, while Figure3dshows the con‐TPI‐err curve and the conditional power curve with PCB pooling.
The PCB pooled conditional power curve in Figure3dis exactly what is intended with PCB pooling logic and motivation.
An unconventional adaptive design is a randomized trial.
The effect sizes of the control arm in the intervals0tC,1andtC,1tC,2are the same, that is,θtC,1=θtC,1tC,2=θC.
This means that exchangeability holds in an unconventional adaptive design.
Hence,ε−∞+∞,θC−θtC,1euncv,y=ε−∞+∞,0euncv,y,εα+,θC−θtC,1euncv,y=εα+,0euncv,y,εα−,θθC−θtC,1euncv,y=εα−,0euncv,y.
We note thatε−∞+∞,0euncv,y,εα+,0euncv,y, andεα−,0euncv,yare the unconditional type I error without any adaptive change in the unconventional adaptive trial, and hence they are all acceptable.
The counterparts ofθtC,1andθtC,1tC,2in a trial with EC borrowing areθECandθCC.
Exchangeability, or∆C=θCC−θEC=0, is neither guaranteed nor verifiable.
The type I error metrics areε−∞+∞,∆CePCB−pool,y,εα+,∆CePCB−pool,y, andεα−,∆CePCB−pool,y.
Because∆C=0is unverifiable, the equalitiesε−∞+∞,∆CePCB−pool,y=ε−∞+∞,0ePCB−pool,y,εα+,∆CePCB−pool,y=εα+,0ePCB−pool,y, andεα−,∆CePCB−pool,y=εα−,0ePCB−pool,ymay not hold.
At the interim analysis att1in a conventional adaptive design,ε−∞+∞,θt1ecv,x=α, and attC,1in an unconventional adaptive designs,ε−∞+∞,0euncv,y=α.
We note thatε−∞+∞,θt1ecv,xandε−∞+∞,0euncv,yare the threshold forε−∞+∞,θt1eadap,cv,xorε−∞+∞,0eadap,uncv,yif the trial is altered in anyway after the interim analysis (e.g., [21,22]).
Also,εα+,θt1ecv,x>αandεα+,0euncv,y>αbecause the con‐TPI‐err curvesecv,xandeuncv,yare aboveαinα+.
Further,εα−,θt1ecv,x<αandεα−,0euncv,y<αbecause the con‐TPI‐err curvesecv,xandeuncv,yare belowαinα−.
In dual metrics,εα+,θt1ecv,xandεα+,0euncv,ycan be used as thresholds for unconditional type I error inα+.
Using the same logic as in either a conventional or unconventional adaptive design, in a trial with PCB pooling under exchangeability of∆C=0,ε−∞+∞,0ePCB−pool,yis acceptable and can be the threshold for type I error rate for the single metric,εα+,0ePCB−pool,y,εα−,0ePCB−pool,yare also acceptable and can be the threshold for type I error rate for the dual metrics.
Note thatε−∞+∞,0ePCB−pool,y>α, since the entireePCB−pool,ycurve is at or aboveαover−∞+∞.
Inα+,ePCB−pool,y=eEC−pool,y=euncv,y, all are aboveα, andεα+,0ePCB−pool,y=εα+,0eEC−pool,y=εα+,0euncv,y>α=0.025is acceptable since simple pooling is valid under exchangeability.
Also,εα−,0ePCB−pool,y=α, becauseePCB−pool,yis a constantαinα−, the same as the con‐TPI‐err with no borrowing.
For convenience of discussion, letε−∞+∞,0ePCB−pool,x=α−∞+∞,0PCB,εα+,0ePCB−pool,x=εα+,0et2,x=αα+,0PCB, andεα−,0ePCB−pool,x=αα−,0PCB.
As has been discussed,α−∞+∞,0PCB>α,αα+,0PCB>α, andαα−,0PCB=α.
Under exchangeability,∆C=0.
The density (Figure4a,b, blue curves) curve ofy~N0,1/tECis centered at 0. theε−∞+∞,0eEC−pool,yfor the simple pooling is exactlyα(Figure4a).
Non‐exchangeability meansθEC≠θCC, and∆C≠0.
The concern for type I error inflation is in the situation of∆C>0.
As∆Cincreases and greater than zero, the density curve ofy~N∆C,1/tECmoves to the right (Figure4b, purple curve).
This movement gives more weight to the right section of the type I error curveePCB−pool,y(the dashed curve in Figure4b).
Because this right section is higher, the weighted area under the curve, i.e.,ε−∞+∞,∆CePCB−pool,y, increases and exceedsα−∞+∞,0PCB(Figure4c).
For the same reason,εα+,∆CePCB−pool,yincreases and exceedsαα+,0PCBas∆Cincreases and greater than zero (Figure4d).
This means type I error inflation with the PCB pooling with nonexchangeability.
To control type I error due to nonexchangeability, it is necessary to change the con‐TPI‐err curveePCB−pool,yby lowering the right section ofePCB−pool,yto some dynamic curveedynamic,yto maintainε−∞+∞,∆Cedynamic,y≤α−∞+∞,0PCB, orεα+,∆Cedynamic,y≤αα+,0PCBwhen∆C>0.
The deviation ofθECfromθCC(i.e.,∆C>0) does not impactεα−,∆CePCB−pool,y(green cure in Figure4d).
This is becauseePCB−pool,y=αinα−, the weighted average ofePCB−pool,xoverα−by any distributionN∆C,1/tECwill remain unchanged atα.
Henceεα−,∆CePCB−pool,y=αfor any∆C.
In Section5, we propose some dynamic borrowing methods to lower the con‐TPI‐err curve inα+such thatedynamic,ycan meet either the single metric criterion or the dual metric criteria.
A conventional adaptive design typically involves sample size modification.
An unconventional adaptive design may also involve sample size modification.
However, adaptive design is not limited to sample size change.
There can be other types of adaptive changes to the trial after an interim analysis.
In a trial with EC borrowing, there is no sample size modification in the usual sense.
Because of the dynamic borrowing, different weights are given to the EC data, which is collected before the interim analysis.
The weight is determined after the data from the current trial is available.
One may interpret the different weights given to the EC data as some kind of sample size change.
But the change is on the size of the data before the interim analysis, while sample size change in conventional and unconventional adaptive design changes the sample size after the interim analysis.
The commonality shared by the conventional, unconventional adaptive designs and trials with EC borrowing is that they are not fixed designs.
The final trial structure of the conventional and unconventional adaptive design is determined by the data collected at the interim analysis, while the final structure of a trial with dynamic EC borrowing is determined by data collected beforeandafter the interim analysis.
It can be said that the conditional type I error after the interim analysis for all three designs are data driven and thus dynamic.
Because they all have an interim analysis, the metrics for unconditional type I error rate can be constructed using the distribution of the interim data.
In practice, exchangeability is not verifiable.
However, when exchangeability holds, or that the difference betweenθECandθCCis small, the probability ofθ^ECandθ^CCbeing close will be higher.
Hence, our proposed methods are based on the closeness ofθ^ECandθ^CC.
Test‐and‐pool (TNP): The EC will be pooled if the test of difference betweenθ^CC,θ^ECis not significant at the two‐sidedγlevel.
Otherwise, the EC will not be pooled.
With EC data pooling, the weight of EC and CC would bewEC=tECtEC+tCC, andwCC=tCCtEC+tCC, and the test statistic isZpool=θ^T−wECθ^EC+wCCθ^CC1/t^T+wEC2/t^EC+wCC2/t^CC.
When the EC is not pooled, the test statistic isZno−borrow=θ^T−θ^CC1/t^T+1/t^CC.
The null hypothesis is rejected ifZpool≥zα(with pooling), orZno−borrow≥zα(without borrowing).
The weight for the CC iswCC=1−wEC.
The test statistic isZEW=θ^T−wECθ^EC+wCCθ^CC1/t^T+wEC2/t^EC+wCC2/t^CC.
The null hypothesis is rejected ifZEW≥zα.The exponential power structure can rapidly reduce the weight of EC when the differenceθ^CC−xECincreases.
The parameterη≥0is used to control power loss.
Test and weight (TNW): The EC will be borrowed and given the exponential weight if the test of difference betweenθ^CC,θ^ECis not significant at the two‐sidedγlevel.
Otherwise, the EC will not be borrowed.
When the EC data are borrowed, the test statistic is the same as with the exponential weighting,ZEW.
When the EC is not borrowed, the test statistic isZno−borrow=θ^T−θ^CC1/t^EC+1/t^CC.
The null hypothesis is rejected ifZEW≥zα(with borrowing), orZno−borrow≥zα(without borrowing).
The proposed procedures, either the TNP, EW, or TNW make the decisions on borrowing based on the closeness between the EC data and the current trial data, such that more weight is given the EC data when the discrepancy between EC and CC is smaller, hence are dynamic borrowing, in the same sense as other dynamic borrowing methods proposed in literature.
The most critical issue in EC borrowing, as discussed in the literature, is whether the type I error can be controlled when exchangeability is not assured.
As discussed in Section3.3, the discount in all of the current dynamic borrowing methods in the literature is arbitrary because there are no criteria to assess if the discount is sufficient if exchangeability can't be assured.
With either the single or dual metrics, the proposed discount can be considered to be adequate on∆C∈0δ(δ>0) if the weighted type I error is controlled at the desired level for∆C∈0δ.
For eachγin TNP,dηin EW, orγdηin TNW, simulations will be conducted to identify someδ>0such that the conditions are satisfied on∆C∈0δ: (i)ε−∞+∞,∆Cedynamic,y≤α−∞+∞,0PCB(in single metric).
Or, (ii)εα+,∆Cedynamic,y≤αα+,0PCB, andεα−,∆Cedynamic,y≤αα−,0PCB=0.025(in dual metrics).
The discount associated with a particularγ,dη, orγdηis adequate on∆C∈0δif either the single metric or the dual metric criteria are met on this range.
A disease is defined as being rare by the US Food and Drug Administration [26] if it affects fewer than 200,000 people.
This research was motivated by the challenges in trial design in Duchenne muscular dystrophy (DMD).
DMD is an X‐linked, degenerative, neuromuscular disease caused by mutations within the dystrophin gene.
It is a rare, serious, debilitating, and ultimately fatal disease.
The incidence of DMD is approximately 1 in 5000 live male births worldwide [27,28].
Lake et al. [9] described a Bayesian design for trials in DMD.
For convenience of discussion, the background placebo (CC and EC) data in Lake et al. [9] are used here for a hypothetical design, simulations, and discussions.
Interested readers may refer to Lake et al. [9] for the information about the available external data sources.
In a hypothetical trial design, it is assumed that the primary efficacy endpoint is the change from baseline at 48 weeks in the total score of North Star Ambulatory Assessment (NSAA, [29]).
The NSAA assessment includes 17 functional item tests.
Each item takes values 0, 1, 2.
0 means that the patient is unable to perform the item test, 2 means the patient can perform the item test easily.
Hence the total NSAA score has a range of 0 to 34.
The NSAA score, though with discrete values, has been analyzed as a normally distributed [9] variable.
If the disease is not treated, the NSAA score will decline overtime.
An effective treatment will reduce the decline.
It is assumed that the mean change of the NSAA total score at 48 weeks from baseline for both the EC and CC isθCC=θEC=−4.06, with a standard deviation of 4 (Lake et al.,2021, Table 2).
Assuming that the new drug arm will result in a 50% less decline, andθT=−2.03.
In a trial with 1:1 randomization ratio between the test and control arms, a sample size of 80 subjects per arm would provide approximately 89.4% power.
However, due to anticipated enrolment difficulties, a 2:1 randomization ratio was chosen, such that the test and control arms will enroll 80 and 40 subjects, respectively.
The 2:1 trial design will provide about 74.6% power.
Simulations are being conducted to investigate the operating characteristics (OC) of the options for EC borrowing.
When∆C>0, the treatment effect ofθ=θT−θCmay be over‐estimated, which may also inflate type I error.
The range of∆C>0on which type I error is controlled is an important operating characteristic of type I error control for EC borrowing methods.
Larger range∆C∈0δindicates more adequate control.
The simulations were conducted as follows:σEC=σCC=σT=4,θCC=−4.06.nEC=nCC=40.nT=80.xEC=θ^EC=−8,−7.8,…,−0.2,0,0.2,…,1.8,2.
For type I error rate simulations,θT=−4.06.
For power simulations,θT=−2.03.
Simulations were conducted forγ=0.05,0.2,0.3(e.g., see [13]) For exponential weighted methods,d=0.5,1,2, andη=1.5,2.5,3.5.
In all the simulation figures,y=θCC−xEC, andyαwere chosen through simulations as the largest value ofyifor which the conditional type I error rate for the pooled analysis is less thanα.
For each value ofxEC,γ,d, andη, the simulations were repeated 500,000 times to reduce random variations and obtain smoother simulation curves (each curve is a function ofy=θCC−xEC).
In the simulations,α=0.025was used.
TheεI,μfx=1PμI∫I12πσexp−x−μ22σ2fxdxwere approximated as follows: Suppose that simulations were conducted to estimatefyony=θCC−xEC=y1…,yi,…,yn, withy1=a, andyn=b.
Then∫I∩a,b12πσexp−x−μ22σ2fxdxis approximated by the sum∑fyidyi∆yi, wheredy=12πσexp−y−μ22σ2,∆yi=yi+1−yi,σ2=1/tEC,andμ=∆C.
The sum is taken overyi∈I∩a,b.PμIis approximated by takingfx=1.
The precisions of the approximations depend on the number of simulations for eachfyi, the width of∆yi, and the rangea,b.εI,∆Cedynamic,ywill be used to represent eitherεI,∆CeTNP,y,εI,∆CeEW,yorεI,∆CeTNW,y, as appropriate.
WhentEC,tCCandtTare known,yα=zαwEC1/tT+1/tCC1/tT+wCC2/tCC−11/tT+wCC2/tCCcan be calculated.
BothwEC=tECtCC+tEC,,wCC=1−wECcan be calculated.
The type I error thresholdsα−∞+∞,0PCB,αα+,0PCBcan be obtained through numerical integration to any desired precision.
However, precise values ofε−∞+∞,∆Cedynamic,yandεα+,∆Cedynamic,ycannot be obtained through numerical integration, since the formulas for the con‐TPI‐err curves for the dynamic methods are not available.
In practice, only the estimatest^EC,t^CC, andt^Twill be available.
An estimatey^αwas chosen through simulations as the largest value ofyifor which the con‐TPI‐err for the simple pooled analysis is less thanα.
All estimatesα^−∞+∞,0PCB,α^α+,0PCB,ε^−∞+∞,∆Cedynamic,y, andε^α+,θHedynamic,ywill be obtained through simulations.
Further, the estimateε^α−,∆Cedynamic,ywill also be obtained through simulations (although theoretically,εα−,∆Cedynamic,y=α).
In the simulations,α^−∞+∞,0PCB=0.03650814, andα^α+,0PCB=0.05784508.
The impact ofγis demonstrated by using 3 different values ofγ(0.05, 0.2, 0.3).
Figure5a,bshow the con‐TPI‐err curves and the conditional power curves for different values ofγ, respectively.
Figure5bshows some loss of conditional power (as compared with no borrowing) in theα−area.
Smallerγis associated with higher conditional power inα+, as well as larger power loss inα−.
Conditional type I error rate, power and type I error rate metrics for TNP.
Figure5cshows thatε−∞+∞,∆CeTNP,y≤α^−∞+∞,0PCB=0.03650814is maintained for all the values ofγfor∆C∈0,0.14, or that type I error is controlled with the single metric when there is minor deviation of exchangeability.
Figure5dshows thatεα+,∆CeTNP,y≤α^α+,0PCB=0.05784508is maintained forγ=0.2,0.3when∆C∈0,0.24.
Figure5eshows thatεα−,∆CeTNPforγ=0.05,0.2,0.3are all belowα=0.025.
We note that from Figure5b,γ=0.05,0.2are associated more power loss thanγ=0.3in theα−area.
Figure6a,bshow the con‐TPI‐err curves and the conditional power curves forη=2.5and different values ofd(0.5,1, 2), respectively.
Figure6bshows some loss of conditional power (as compared with no borrowing) in theα−area ford= 0.5, 1, but no power loss ford= 2.
Smallerdis associated with higher conditional power inα+, as well as larger power loss inα−.
Conditional type I error rate, power and type I error rate metrics for EW (η= 2.5).
Figure6cshows thatε−∞+∞,∆CeEW,y≤α^−∞+∞,0PCB=0.03650814is maintained ford=2for∆C∈0,0.24, and ford=0.5,1for∆C∈0,0.34, or that type I error rate is controlled with the single metric when there is minor deviation of exchangeability.
Figure6dshows thatεα+,∆CeEW,y≤α^α+,0PCB=0.05784508is maintained for alldwhen∆C∈0,0.8.
Figure6eshows thatεα−,∆CeEW,yexceededα=0.025for all values of d when∆Cis slightly positive.
However, for all d's,εα−,∆CeEW,y<0.0255for∆C∈0,0.54andεα−,∆CeEW,y<0.026for∆C∈0,1.44.
In other words, the inflation ofεα−,∆CeEW,yis minor when∆C>0.
Simulation results for TNW in the case ofγ=0.05,η=2.5, andd=0.5,1,2, are presented.
Figure7a,bshow the con‐TPI‐err curves and the conditional power curves, respectively.
Figure7bshows no loss of conditional power (as compared with no borrowing) in theα−area for all values of d. Smallerdis associated with higher conditional power inα+.
Conditional type I error rate, power and type I error rate metrics for TNW.
Figure7cshows thatε−∞+∞,∆CeTNW,y≤α^−∞+∞,0PCB=0.03650814is maintained ford=0.5,1for∆C∈0,0.295, or that type I error rate is controlled with the single metric when there is minor deviation of exchangeability.
Figure7dshows thatεα+,∆CeTNW,y≤α^α+,0PCB=0.05784508is maintained for alldwhen∆C∈0,0.78.
Figure7eshows thatεα−,∆CeTNW,yexceededα=0.025for all values of d when∆C>0.
However, for all d's,εα−,∆CeTNW,y<0.0256for∆C∈0,0.59andεα−,∆CeTNW,y<0.026for∆C<0,1.44.
In other words, the inflation ofεα−,∆CeTNW,yis minor when∆C>0.
Besides usingε−∞+∞,εα+,εα−to reduce the chance of falsely rejecting the null hypothesis, the concern about the selection bias and the consequent comparison bias from EC borrowing can be further addressed by controlling the mean conditional bias in the estimates.
Figure8show the mean conditional bias for simple pooling (Figure8a) TNP (Figure8b), EW (Figure8c), and TNW (Figure8d,e).
The mean conditional bias for all of TNP, EW, and TNW are much smaller than that for the simple pooling, and can be adjusted by changing the values ofγ,ηandd.
The logic of PCB EC borrowing is to borrow EC only when borrowing will increase instead of reducing power.
This logic changed the con‐TPI‐err curve (Figure3a,b) in theα−area from belowαto being equal toα.
We note that the concern of type I error inflation is mainly inα+where borrowing is of interest, while borrowing inα−is of no interest, and con‐TPI‐err beingαwithout borrowing does not truly raise alarms.
Hence, arguably, this change in con‐TPI‐err could be acceptable.
However, the change resulted inε−∞+∞,0ePCB−pool,y>αfor trials with PCB EC borrowing.
This is not a normally accepted statistical standard, because the threshold ofαhas been enshrined in almost all statistical hypothesis testing.
It can be argued that the logic is justifiable only when there is truly urgent unmet medical need.
As previously mentioned, PCB borrowing is assumed to be acceptable in this article.
The single metricε−∞+∞(e.g.,ε−∞+∞,θt1e*,y) is used in all conventional adaptive designs for type I error control, while the dual metricsεα+,∆Ce*,yandεα−,∆Ce*,ywere introduced specifically for PCB EC borrowing.
In a trial with PCB EC borrowing,ε−∞+∞,0ePCB−pool,y>α.
Ifε−∞+∞,0ePCB−pool,y=0.025is required, thenαmust be less than 0.025.
The exact value ofαdepends ontEC,tCC, andtT.
It can be obtained either through numerical integration and search, or simulations and search.
Such a choice ofαwill result in reduced power, opposite to the motivation and objective for PCB EC borrowing and will inevitably discourage EC borrowing.
We note that the single metricε−∞+∞,∆Cedynamic,ydoes not accommodate the logic of PCB borrowing, because it does not distinguish the difference in borrowing strategy betweenα−andα+.
On the other hand, the dual metric are specific measures of unconditional type I error forα−andα+according to the PCB borrowing strategy.
Hence, under the assumption that PCB borrowing is acceptable, the dual metric is more suitable than the single metric for trials with PCB borrowing.
When exchangeability does not hold, but ifεα+,∆Cedynamic,y≤αα+,0PCBandεα−,∆Cedynamic,y≤αα−,0PCB=0.025both hold, then the type I error will be under control using the dual metric.
In our simulations, there have been situations in whichεα+,∆Cedynamic,y≤α^α+,0PCBcan be satisfied with considerable range∆C∈0δ,for example (Figure7d),εα+,∆CeTNW,y≤α^α+,0PCB=0.05784508is maintained with TNW for alldand∆C∈0,0.78, butεα−,∆Cedynamic,y>0.025.
Thus, strictly speaking,εα−,∆Cedynamic,y≤0.025is not satisfied and the dual metric criteria may not be guaranteed to have been met.
There are several reasons forεα−,∆Cedynamic,y>0.025: (i).y^αwas obtained thorough simulations; (ii) Smaller∆yiincreases the precisions of the estimatesε^−∞+∞,∆Cedynamic,y,ε^α+,∆Cedynamic,y,ε^α−,∆Cedynamic,y, but will also increase the burden of simulations.
In the simulations,∆yi=0.2.
(iii) Simulations are subject to random simulation inaccuracies.
However, the excess ofεα−,∆Cedynamic,yover 0.025 is minor.
For example, (Figures6e,7e),εα−,∆Cedynamic,y≤0.026for considerable range of∆C.
For (Figure7e) alld's,εα−,∆CeTNW,y<0.0256for∆C∈0,0.59.
andεα−,∆Cedynamic,y<0.026(figures 6e and 7e) for∆C∈0,1.44.
As discussed earlier, the theoretical value ofεα−,∆Cedynamic,yisα=0.025.
We propose that a random simulation error allowance of∆ε=0.001be acceptable and that the threshold ofε^α−,∆Cedynamic,ybe relaxed to 0.026.
Stake holders, for example, the regulatory authority and the pharmaceutical company may consider relaxing the simulation error allowance to say, 0.005, to lessen the burden of simulations.
We also note thatα+is the primary area of concern for type I error inflation, and the concern is addressed by the requirement thatε^α+,∆Cedynamic,y≤α^α+,0PCB.
Hence, we propose that the threshold forε^α−,∆Cedynamic,ycan be relaxed to 0.026, instead of 0.025.
We also note thatα+is the primary area of concern for type I error inflation.
This rule change maintains the dual metric criteria forα+atαα+,0PCB, this level of type I error is acceptable in an unconventional adaptive design.
Suppose that a trial in DMD is being designed based on the simulation results.
Suppose that the primary efficacy endpoint is the mean change of the NSAA total score at 48 weeks (e.g., see [9]).
It is assumed thatσEC=σCC=σT=4,θEC=θCC=−4.06.
A 50% improvement of efficiency is assumed such thatθT=−2.03.
Suppose that the 2:1 randomization ratio was chosen, such that the test and control arms will enroll 80 and 40 subjects, respectively.
The 2:1 trial design will provide about 74.6% power.
Suppose that 40 matched EC subjects will be potentially borrowed and be combined with CC for the primary analysis after study completion.
Simulation results in Section6(Figure7) show that dual metric criteria ofεα+,∆CeTNW,y≤α^α+,0PCB=0.05784508andεα−,∆CeTNW,y≤0.026are satisfied for∆C∈0,0.91with the TNW withγ=0.05,η=2.5andd= 0.5.
Hence this TNW combination can be used as the method for dynamic borrowing.
We note that the mean bias with this dynamic design is slightly over 0.2 (Figure8d), which is much smaller than 0.91.
If smaller mean conditional mean bias is desired, the TNW withγ=0.2,η=2.5, andd= 0.5 (Figure8e) can be used.
The score function [24] plays a fundamental role in the theoretical discussion of our proposed method.
The asymptotic properties of the score function rely on normality from large sample approximation.
A common challenge in clinical trials in rare diseases is the difficulties in patient enrollment.
Consequently, the sample sizes in rare disease trials are smaller than those for more common diseases.
Hence, an obvious question is whether normality approximation holds in a trial for which EC borrowing is been considered.
Although external control borrowing has been often discussed in the context of rare disease, it has also been discussed [18] in trials involving type 2 diabetes mellitus (T2DM), cardiovascular outcomes trials (CVOTs).
Both of these types of trials involve large number of patients, and normal approximation is generally not an issue.
Many published literatures on EC borrowing have discussed normal variables (e.g., [1,6,12]).
Viele et al. [13] discussed a trial design with a dichotomous endpoint for discussion.
With an assumed sample size of 200 patients per arm in this example, the normal approximation for the estimated event rate can be robust.
Several efficacy parameters in DMD trials such as NSAA total score, time/velocity to rise from floor, time/velocity of 10‐m walk/run, stride velocity 95th centile (SV95C), have been analyzed as normally distributed variables.
Phase 3 trials in DMD may enroll up to about 100 patients.
For example, the sample size for the trial design described in Lake et al. [9] was 150 for three arms.
The planned sample size for Pfizer—CIFFREO [30] is 99 patients for two arms.
The Sarepta—EMBARK trial [31] enrolled 126 patients for two arms.
With 50–60 patients per arm, the normality assumption of the score function for NSAA is justified.
Enrollment difficulties in rare disease trials may include two scenarios: (i) feasible sample size for trials may lack sufficient power to demonstrate efficacy, but the normality assumption is reasonable; (ii) the feasible sample sizes are so small such that the normality assumption can't be justified.
Our method can be applied for the first scenario.
For the second scenario, we note that the key elements of the proposed methods, such as conditional type I error rate, the definition ofyα, the areas ofα−andα+, conditional power, weighted average of conditional type I error rate and conditional power, can be obtained through simulations even when normality is not assured.
Hence, trials with EC borrowing but without assured normality can be designed and analyzed with the help of simulations.
To ensure proper control of type I error rate control without assurance of strict exchangeability, the simulations should verify that the weighted average of conditional type I error rate possess monotonicity with regard to∆C.
EC borrowing may play an important role in phase 3 trials in rare diseases.
Most phase 3 trials are designed with assumptions, such as effect size, variance.
The assumptions may also include the distribution of the efficacy variable, such as if it is normally distributed (true normality may not always strictly hold), or has a binary, or Poisson distribution, etc. Assumptions on effect size, variance and distributions (e.g., normality) will impact the power, as well as type I error control.
Similarly, assumptions will also be necessary for trials with EC borrowing using proposed methods.
For example, if the efficacy is assumed to be normally distributed, it is necessary to make assumptions on the effect size and variance of the treatment arm and control arm in the new randomized trial.
The trial planning must also include the randomization ratio, the number of subjects to be borrowed from the EC data.
For the power calculation, exchangeability will be assumed, and the number of subjects from the EC data will be included in the control arm in the new trial as if the new randomized trial includes subjects form both the new trial and EC data.
Such calculated power is the most optimistic power when the EC data is fully borrowed without any discount.
Based on these assumptions, simulations can be conducted on some values ofγ(for TNP),dη(for EW), orγdη(for TNW) to assess the operating characteristics, such as conditional type I error curve and conditional power curves (to assess conditional power gain and loss).
The simulations will also identify someδ>0such that either the single or the dual metrics criteria will be satisfied for∆C∈0δ.
The trial designers then can select the parametersγ,dη, orγdηthe provide satisfactory conditional power curve and range of∆C∈0δ.
Theγ,dη, orγdηmay be chosen such that the maximum mean bias (see Figure8b–8e) do not exceedδ.
The trial designers may revise the number of subjects in the new trial, theγ,dη, orγdηuntil the OC's are considered to be satisfactory.
The trial protocol or the statistical analysis plan (SAP) should include the planned sample size for the new trial, description of the EC data source, the dynamic borrowing procedure (i.e., TNP, EW, TNW) together with the parameters such asγ,dη, orγdη, and simulation results as those included in Figure5a–e(TNP), or Figure6a–e(EW), or Figure7a–e(TNW) to demonstrate that either the single metric or the dual metrics criteria are met on a reasonable range of∆C∈0δ.
At completion of the new trial, statistical hypothesis testing will strictly follow the planned analysis with chosenγ,dη, orγdη.
For non‐normally distributed efficacy variables, such as binary or Poisson distributions, assumptions should be made accordingly.
The formulas for TNP, EW, TNW are all based on normal distributions.
Hence it will be necessary to convert the non‐normally distributed variables into score function to conduct statistical analysis at the completion of the new trial.
The DACT software can be used for simulations with normal, binary or Poisson distributions variables.
Conversions to score function are part of the simulation procedures.
Although the proposed methods can control unconditional type I error using either the single or the dual metric without strict exchangeability, the justification of EC borrowing remains to be based on exchangeability.
Hence, every effort should be made such that the EC data is as similar to the CC data as much as possible.
There are various ways (e.g., [16,32]) to improve the similarity between the EC and CC data, these may include meta‐analysis, propensity score matching/weighting, applying the inclusion/exclusion criteria in the new trial to the EC data, etc. Methods involving propensity scores require the comparison of EC and CC data.
Hence, it may be necessary to reconduct simulations after the CC data becomes available.
Such simulations may require that the Fisher's information timestEC,tCC, andtT, be estimated from both the EC and CC data and then be converted to correspondingNEC,NCC, andNT,σEC,σCC, andσT.
Then these estimated parameters can be used to conduct simulations to selectγ,dη, orγdηwith acceptable OC.
Decision must be made on whether to use theγ,dη, orγdηfrom the original simulations conducted at trial designing stage or the revisedγ,dη, orγdηfrom the re‐simulations after CC data is available.
The decision must be justifiable.
Then the statistical analysis plan will be revised accordingly.
Since the re‐simulations will be conducted after the CC data becomes available, they are post hoc in nature and efforts should be made to avoid bias.
The resimulations should identify someδ>0such that the unconditional type I error (either with the single or the dual metric) criteria are satisfied for∆C∈0δ, and if the maximum mean conditional bias (e.g., Figure8) exceedsδ.
The possibility of and plan for re‐simulations should be communicated to and be accepted by regulatory authorities.
The dynamic methods discussed here, the TNP, EW and TNW, can control unconditional type I error in certain scenarios when∆C∈0δwith both the single and the dual metrics.
Users can use simulations to help select, which dynamic method (TNP, EW, or TNW) and which parametersγ(TNP),d,η(EW), andγ,d,η(TNW) to use.
Simulations can be used to determineδ, such that the unconditional type I error rate can be controlled for∆C∈0δ.
There are no closed form formulas for obtaining the critical parameters such asε−∞+∞,∆Cedynamic,y,εα+,∆Cedynamic,y, and so on.
The estimated threshold for type I error control, that is,α^−∞+∞,0PCB,α^α+,0PCBfor the PCB pooled analysis under the assumption of exchangeability, usually requires extensive simulations.
The assessment of other OCs such as maximum one‐sided conditional type I error rate and conditional bias also need intensive simulations.
To facilitate the application of the method, all the simulations can be conducted using the DACT software.