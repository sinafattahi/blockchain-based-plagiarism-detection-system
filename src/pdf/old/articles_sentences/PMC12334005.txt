Age-period-cohort (APC) analysis, one of the fundamental time-series models, has an identification problem of the inability to separate linear components of the three effects.
However, constraints to solve the problem are still controversial because multilevel analysis used in many studies results in the linear component of cohort effects being close to zero.
In addition, previous studies do not compare the Bayesian cohort model proposed by Nakamura with the well-known intrinsic estimator.
This paper focuses on three models of Bayesian regularization using priors of normal distributions.
A random effects model refers to multilevel analysis, a ridge regression model is equivalent to the intrinsic estimator, and a random walk model refers to the Bayesian cohort model.
Here, applying Bayesian regularization in APC analysis is to estimate linear components by using nonlinear components and priors.
We aim to suggest conditions for using the random walk model by comparing the three models through some simulations with settings for the linear and nonlinear components.
Simulation 1 emphasizes an impact of the indexes by making absolute values of the nonlinear components small.
Simulation 2 randomly generates the amounts of change in the linear and nonlinear components.
Simulation 3 randomly generates artificial parameters with only linear components are less likely to appear, to consider the Bayesian regularization assumption.
As a result, Simulation 1 shows the random walk model, unlike the other two models, mitigates underestimating the linear component of cohort effects.
On the other hand, in Simulation 2, none of the models can recover the artificial parameters.
Finally, Simulation 3 shows the random walk model has less bias than the other models.
Therefore, there is no one-size-fits-all APC analysis.
However, this paper suggests the random walk model performs relatively well in data generating processes, where only linear components are unlikely to appear.
Age-period-cohort (APC) analysis is one of the fundamental time-series analyses used in many research fields.
In APC analysis, age effects reflect the influence of individual differences in age and period effects reflect the influence of differences in time period.
Cohort effects represent the influence of differences in birth year.
APC analysis is important because long-term changes are also the result of demographic metabolism, in which older generations leave society and younger generations with different characteristics enter [1].
Given the nature of such cohort replacement, we need to consider not only period effects but also cohort effects.
It is well-known that APC analysis has a serious issue of identification.
In general, cohort is linearly associated with age and period according to the relationship cohort = period ‚Äì age.
This linear dependence of the three factors confounds linear components of the three effects.
In other words, the APC identification problem makes it impossible to directly estimate the linear components of these effects.
There are various constraints, such as using unequal-interval widths for age, period, and cohort indexes [2].
Many previous studies have applied multilevel analysis to solve the rank deficiency of the design matrix.
However, this constraint is problematic [3], especially because it results in the linear component of cohort effects being close to zero [4,5].
The intrinsic estimator [6] is also a well-known method in APC analysis.
This method is sensitive to the type of dummy parameterization of the design matrix [7,8], and is difficult to verify in empirical research [9].
On the other hand, there are few studies using the Bayesian cohort model proposed by Nakamura [10].
Sakaguchi and Nakamura [11] suggest that this assumption, unlike multilevel analysis, mitigates underestimating the linear component of cohort effects caused by the indexes of the three effects.
However, these constraints are still controversial [12], as the above previous studies do not compare the model with the intrinsic estimator and do not evaluate the performance of the three models.
Furthermore, they do not show whether the mitigation of underestimating the linear component of cohort effects reduces the bias in APC analysis.
Therefore, it is unclear when we should use the Bayesian cohort model.
This paper examines the major models of APC analysis by considering some simulations with settings for the linear and nonlinear components.
To compare the assumed constraints, we focus on three models of Bayesian regularization using prior probabilities of normal distributions.
A random effects model refers to multilevel analysis, a ridge regression model is equivalent to the intrinsic estimator, and a random walk model refers to the Bayesian cohort model.
Here, the linear components of the three effects are estimated using the nonlinear components and the priors.
This paper evaluates the three models in terms of how well the linear components are recovered.
The first simulation makes absolute values of the nonlinear components small to emphasize an impact of the indexes mentioned in the previous studies.
The next simulation randomly generates the amounts of change in linear and nonlinear components according to normal distributions.
The following simulation sets artificial parameters so that a pattern with only linear components is unlikely to appear, to consider the Bayesian regularization assumption.
By comparing the three models through these simulations, this paper suggests conditions for using the random walk model.
This paper reviews APC analysis in ‚ÄúTheory‚Äù section.
Specifically, ‚ÄúAPC analysis‚Äù subsection shows the notation and the identification problem.
‚ÄúBayesian regularization‚Äù subsection describes the constraints for the random effects model, the ridge regression model, and the random walk model.
‚ÄúMathematical mechanism‚Äù subsection shares the why the previous study suggests that the random walk model performs better than the random effects model.
‚ÄúMethods‚Äù section presents systematic simulations adopted in this paper and the definition of a bias evaluation function.
‚ÄúResults‚Äù section verifies the performance of the three models through these simulations.
‚ÄúDiscussion‚Äù section concludes that while there is no one-size-fits-all APC analysis, the random walk model performs relatively well in data generating processes, where only linear components are unlikely to appear.
excluding the constant term.
In general, estimates are obtained by maximizingEq (3); however, we need to add constraints in APC analysis since it is not possible to uniquely determine the estimates owing to the identification problem described below.
whereb^iA,b^jP, andb^kCare the particular solutions of the three effects andsdenotes an arbitrary real number.
In summary, the APC identification problem is that there are many maximum likelihood estimates ofEq (3)owing to the linear dependency of cohort = period ‚Äì age.
In other words, the linear components of the three effects affected byviA,vjP, andvkCcancel each other out completely when the slopes of the age and cohort effects increase bysand the slope of the period effect decreases bys.
On the other hand, we can easily separate the nonlinear components that are irrelevant to the identification problem.
To overcome the identification problem, Bayesian regularization constrains parameters of the three effects by assuming prior probabilities.
It is a strategy to statistically estimate mathematically indistinguishable linear components by using mathematically identifiable nonlinear components and priors.
Here, if there are an infinite number of maximum likelihood estimates, as in APC analysis, point estimates that maximize the posterior probabilities of Bayesian models are determined by maximizing the priors.
excluding the constant term.
Here, maximizingEq (5)means minimizing the sum of squares of the parameters.
Here, maximizingEq (7)means minimizing the sum of squares of the parameters as well aslogRE.
The intrinsic estimator is another well-known method in APC analysis and produces similar results to the ridge regression model.
The reason is that this operation minimizes the Euclidean norm of the parameters, giving a particular solution that is the average of the general solution [15].
Here, maximizingEq (8)means, unlikelogREandlogRR, minimizing the sum of squares of the differences in the adjacent parameters.
Furthermore, the random walk model is equivalent to the Bayesian cohort model proposed by Nakamura [10] and this constraint takes advantage of the fact that age, period, and cohort indexes are ordered.
We obtain the log priors of the ridge regression model by substitutingEq (6)intoEq (11).
For the same reason, it also tends to underestimate the linear component of the cohort effects owing to the index.
Thus, the comparison of the index weights inEq (15)suggests that the random walk model is less affected by the index weights than are the random effects and ridge regression models.
In other words, minimizing the sum of squares of the differences in the adjacent parameters rather than the parameters themselves mitigates underestimating the linear component of cohort effects.
This paper then setsI= 10,J= 10,Œ≥=0.1andN=I√óJ√ó10=1000, so that the error terms generated by the normal distributions do not greatly affect the simulation.
Simulation 1 focuses on underestimating the linear component of cohort effects under the constraints of shrinking the parameters because the indexes have a large influence on the cohort effects owing toK=I+J‚àí1inEq (1). To conduct a systematic simulation, we discuss combinations of the linear components that are the basis of the identification problem.
First, this paper assumes three types of slopes for the artificial parameters: 0, +, and ‚Äì.
The total number of combinations here is 33= 27, since each effect has three patterns.
Specifically,Œ≤A[ùêø]=0is expressed as(A)0,Œ≤P[ùêø]>0as(P)+, andŒ≤C[ùêø]<0as(C)‚àí.
In fact, we need only consider(27‚àí1)/2=13cases since this paper excludes the cases where there is no linear component, such as(A)0,(P)0,(C)0and where the positive slope is merely reversed to a negative.
The combinations are thus cases 1 to 3 having a positive linear component in one factor, cases 4 to 6 having positive linear components in two factors, cases 7 to 9 having positive and negative linear components in two factors, and cases 10 to 13 having linear components in all factors.
Simulation 1 emphasizes the impact of the index weights shown in ‚ÄúMathematical mechanism‚Äù subsection by making the absolute values of the nonlinear components small.
This paper sets the variation of the slope to 0.1 and the nonlinear component to 0.05.
Specifically,(A)0representsŒ≤A[ùêø]=0andŒ≤A[NL]=0,(P)+representsŒ≤P[ùêø]=0.1andŒ≤P[NL]=0.05, and(C)‚àírepresentsŒ≤C[ùêø]=‚àí0.1andŒ≤C[NL]=‚àí0.05.
To understand the 13 cases,Fig 1visualizes artificial data that includes only linear components usingyi,j=Œ≤A[ùêø]viA+Œ≤P[ùêø]vjP+Œ≤C[ùêø]vkC, andFig 2also includes nonlinear components usingyi,j=Œ≤iA+Œ≤jP+Œ≤kC.
The dot plots are visualizations by period and the x-axis represents cohort.
The solid lines connect the dots corresponding toj=1,4,7,10for each period.
Here,yi,jin case 1 ofFig 1increases by 0.1 as the age index increases, and we see the values of older cohorts as higher within the same period.
Case 2 increases by 0.1 as the period index increases and case 3 increases by 0.1 as the cohort index increases.
However,Fig 1shows that cases 1 and 7 are identical and very similar to case 10.
Moreover, cases 2 and 5 are identical and very similar to case 11, while cases 3 and 9 are identical and very similar to case 12.
In addition, the linear components of case 13 are offset and no variation appears in the artificial data.
In other words, the mixture of linear components in the identification problem means that combining different linear components can generate precisely the same data.
UnlikeFigs 1and2does not reveal identical data.
Consequently, this paper verifies whether the models of Bayesian regularization recover the artificial parameters using this small difference.
Note: Each panel represents a different combination of linear slopes as described inTable 2.
Note: Each panel represents a different combination of linear slopes as described inTable 2.
whereTdenotes the number of times the model converged in the simulation.
Fig 3visualizes the linear and nonlinear components of the generated artificial parameters as dots.
Here, this paper classifies the artificial parameters into four main patterns: (1) no linear and nonlinear components, (2) only linear components, (3) only nonlinear components, and (4) both linear and nonlinear components.
This simulation has an equal probability of the patterns containing only linear components and only nonlinear components.
Fig 4visualizes the linear and nonlinear components of the generated artificial parameters as dots.
Moreover, we add toFig 4the gray area bounded byŒ≤[NL]=0.2Œ≤[ùêø]andŒ≤[NL]=‚àí0.2Œ≤[ùêø], including the horizontal axis.
The absence of dots in the gray area indicates that Simulation 3 does not generate the artificial parameter containing only linear components.
The three models of Bayesian regularization were implemented using the probabilistic programming language Stan [18] and were run in R [19].
Sampling settings were chains = 4, iter = 2000, warmup = 500, and thin = 3.
The lower bounds ofœÉA,œÉP, andœÉCin the random effects model were set to 0.05 in order to search for parameters in a wide range, as this model can get stuck in locally optimal solutions.
This paper judges the model to have converged when all parameters satisfyR^<1.05.
The three models in Simulation 1 satisfy the convergence criterion in all cases.Table 2summarizes the systematic combinations of the linear components and the results of the three models.
The letters A through E that appear in three of the table columns are used to categorize the results: A if the absolute value ofsis less than 0.02, B if less than 0.04, C if less than 0.06, D if less than 0.08, and E if 0.08 or more.
As shown, among the 13 cases of artificial data, 10 cases in the random walk model rated B or better (i.e., the value ofswas less than 0.04) as compared to 4 cases in the random effects and ridge regression models, indicating that the random walk model performed relatively well.
Note: For example,Œ≤A[ùêø]=0is expressed as(A)0,Œ≤P[ùêø]>0as(P)+, andŒ≤C[ùêø]<0as(C)‚àí.
This paper calculatedsinEq (16). The letters A through E are used to categorize the results: A if the absolute value ofsis less than 0.02, B if less than 0.04, C if less than 0.06, D if less than 0.08, and E if 0.08 or more.
The cases where the models failed to effectively recover the artificial parameters in Simulation 1 contain the linear component of cohort effects.
First, constraints shrinking the parameters, such as in Bayesian regularization, always fail case 13, where the linear components completely cancel.
Moreover, we found the estimated linear component of the cohort effects in the failed cases to be close to zero, because(C)+leads tos< 0 and(C)‚àíleads tos> 0.
Specifically,Fig 5, which visualizes case 3, shows that the estimated slope of the cohort effects becomes horizontal, and the linear component is incorrectly assigned to the other effects.
The random effects and ridge regression models obtain the estimates like the artificial parameters in case 9 because the age effects have a negative slope and the period effects have a positive slope.
However, the random walk model did not underestimate the linear component of the cohort effects.
In Simulation 2, the number of times the models converged was 479 for the random effects model, 500 for the ridge regression model, and 487 for the random walk model.
In addition,Œ¥inEq (17)was 0.092 for the random effects model, 0.077 for the ridge regression model, and 0.088 for the random walk model.Fig 6shows that the histograms ofsinEq (16)for all three models are widely spread, indicating that none of the models can recover the artificial parameters.
Unlike Simulation 1, the random walk model did not perform well in Simulation 2.
The reason is that different artificial parameters generate the same artificial data, as shown inFig 1.
For example, the artificial parameters shown inFig 7generate the artificial data of case 3, meaning that the random walk model in this case incorrectly assigns the linear component to the cohort effects that include the nonlinear components.
Therefore, it is impossible to decide which model performs well with no constraints on the linear and nonlinear components.
In Simulation 3, the number of times the models converged was 469 for the random effects model, 500 for the ridge regression model, and 499 for the random walk model.
In addition,Œ¥inEq (17)was 0.063 for the random effects model, 0.070 for the ridge regression model, and 0.033 for the random walk model.Fig 8shows that since the histogram ofsinEq (16)for the random walk model is concentrated near zero, this model has less bias than the other models.
The models applying Bayesian regularization estimates the linear components using the nonlinear components and the priors.
Simulation 3 is less likely to generate artificial parameters with only linear components, which makes random walk models advantageous because this simulation does not generate patterns likeFig 7.
Here, the nonlinear components of the three effects determine the lower bounds ofœÉA,œÉP, andœÉCin the log prior probabilities of the random effects model and the random walk model, and their sigmas affect the assignment of the linear components.
However, the ridge regression model cannot effectively use the nonlinear components because this model usesŒªthat is common to the three effects.
Furthermore,Table 2shows that the random effects model underestimates the linear components of the cohort effects than the random walk model.
Therefore, the random walk model performs relatively well.
This paper focused on the three models in APC analysis of Bayesian regularization using the priors of normal distributions.
The random effects model refers to multilevel analysis, the ridge regression model is equivalent to the intrinsic estimator, and the random walk model refers to the Bayesian cohort model.
We verified some simulation with settings for the linear and nonlinear components.
Simulation 1 considers the systematic combinations of the linear components and emphasizes the impact of the indexes by making the absolute values of the nonlinear components small.
Simulation 2 randomly generates the amounts of change in the linear and nonlinear components according to normal distributions.
Simulation 3 sets the artificial parameters so that the pattern with only linear components is unlikely to appear.Table 3briefly summarizes the settings for the amount of change in each component of Simulation 1 to 3.
The purpose of this paper is to suggest conditions for using the random walk model by comparing the three models through these simulations in terms of how well artificial parameters are recovered.
In general, the constraints of shrinking the parameters tend to drive the linear component of the cohort effects close to zero because the indexes have a large influence on the cohort effects owing toK=I+J‚àí1inEq (1). The results of Simulation 1 showed the random effects model reproduced the findings [4,5] that the linear component of the cohort effects becomes flat.
Unlike the other two models, the random walk model mitigated underestimating the linear component of the cohort effects and successfully recovered the artificial parameters if one or more of the effects were zero.
On the other hand, Simulation 2 showed none of the models can recover the artificial parameters.
Therefore, the mitigation of underestimating the linear component of the cohort effects, mentioned in the previous study [11], does not determine which model performs well with no constraints on the linear and nonlinear components.
In Simulation 3, as the pattern with only linear components was unlikely to appear, the random walk model had less bias than the other models.
Applying Bayesian regularization in APC analysis is to statistically estimate mathematically indistinguishable linear components by using mathematically identifiable nonlinear components and priors.
This shrinking constraint always fails to estimate the cases where the linear components completely cancel each other, such as case 13 in Simulation 1.
However, the setting in Simulation 3 is consistent with the assumption of Bayesian regularization using the nonlinear components to estimate the linear components.
In addition, this means that the artificial parameters inFig 7, where the random walk model fails, are less likely to appear.
Here, the ridge regression model cannot effectively use nonlinear components to estimate linear components.
Furthermore,Table 2shows that the random effects model underestimates the linear components of the cohort effects than the random walk model.
As a result, the random walk model in Simulation 3 recovered the artificial parameters generated by trigonometric functions rather than random walks.
This paper classified artificial parameters into four main patterns: (1) no linear and nonlinear components, (2) only linear components, (3) only nonlinear components, and (4) both linear and nonlinear components.
Among them, the simulations using trigonometric functions for the nonlinear components showed that the random walk model recovered artificial parameters better than the other models, if the pattern with only linear components is unlikely to appear.
This subsection briefly discusses the possibility that the random walk models can estimate data generating processes other than trigonometric functions.
For example, polynomial functions are more common than trigonometric functions in analysis, as there is polynomial regression.
Therefore, we describe artificial parameters using them.
Fig 9visualizesŒ∑[L]andSD[NL]of the generated artificial parameters as dots.
Moreover, we add toFig 9the gray area bounded bySD[NL]=0.5Œ∑[L]andSD[NL]=‚àí0.5Œ∑[L], including the horizontal axis.
As in Simulation 3, the absence of dots in the gray area indicates that the polynomial function does not generate the artificial parameter containing only linear components.Fig 9shows that there are many dots in the gray area atH= 2 and no dots atH= 8.
The reason is thatw1affects only the linear component, whilew3andw5affect the linear and nonlinear components.
In addition, even if the absolute value ofw3is large, there is the possibility that the linear component is close to zero due tow1andw5.
However, it is difficult to cancel out the nonlinear component ofw3zm,3with other terms.
In summary, the polynomial functions in this subsection are less likely to generate the pattern with only linear components as the degree of the polynomial increases.
Therefore, the random walk model may have a smaller bias than the other models even when data generating processes can be approximated by polynomial functions with a large degree of polynomial.
Finally, this paper has several limitations, such as only discussing the main three models applying Bayesian regularization, not changing the indexes, for exampleI= 12 orJ= 8, and not considering nonlinear components other than trigonometric functions.
We should verify other data generating processes, and the simulations and bias evaluation functions in this paper will be useful in such cases.
This paper showed the simulations not only where no model can recover the artificial parameters but also where the random walk model performs well.
Therefore, future studies need to investigate not only failure cases but also constraints that reduce bias by imposing weak conditions on linear and nonlinear components.