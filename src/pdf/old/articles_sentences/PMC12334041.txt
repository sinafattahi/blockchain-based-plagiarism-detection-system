This research study focuses on calculating five entropy measures (Shannon, RÃ©nyi, Havrda-CharvÃ¡t, Arimoto, and Tsallis) for the Burr XII distribution, utilizing progressive Type-II censoring.
The study derives maximum likelihood estimators for each entropy measure and constructs two-sided confidence intervals.
A comprehensive simulation study evaluates the performance of these estimators across various sample sizes and parameter settings.
The results demonstrate that the proposed methods achieve low bias and variance under different censoring schemes, with coverage probabilities consistently close to the nominal level.
Additionally, an application to the Wisconsin Breast Cancer Database highlights the practical utility of the entropy estimators in distinguishing between benign and malignant cases.
Among the measures evaluated, the RÃ©nyi, Havrda-CharvÃ¡t entropy measures exhibited the most robust performance in both simulation and real life data analysis.
Entropy, introduced by Shannon in 1948, is a fundamental concept for quantifying uncertainty in random variables.
It measures the average information content of a variable, where higher entropy indicates greater uncertainty and a wider spread in the probability distribution.
Conversely, lower entropy suggests a more concentrated distribution with reduced uncertainty.
The concept of entropy has been widely applied across various scientific disciplines.
For example, [1] explored its significance in the insurance industry, particularly in evaluating risk and the severity of extreme events, where greater entropy correlates with increased variability and potential losses.
In reliability studies, [2â€“5] highlighted the relevance of entropy in assessing the uncertainty of failure distributions, noting that higher entropy is often associated with less reliable outcomes.
Furthermore, entropy-based methodologies have been employed in fields such as neurobiology, statistics, cryptography, quantum computing, linguistics, and bioinformatics, as reported by [6â€“8].
These applications underscore the importance of entropy in both theoretical and applied research.
Recent studies have also demonstrated the utility of entropy estimators in neuroscience and biomedical diagnosis, particularly in analyzing electrophysiological signals such as EEG data [9,10].
These applications highlight the versatility of entropy-based methods across diverse fields.
However, the present study focuses on the methodological development and evaluation of entropy measures for lifetime data analysis under progressive Type-II censoring, particularly within the context of reliability modeling and failure time uncertainty.
The Burr XII distribution is an extremely useful model, especially when dealing with non-monotonic failure rates, such as unimodal or bathtub-shaped failure rates, which are widespread in reliability and biological research.
Unlike the Weibull distribution, which may be the first choice for analysing monotonic failure rates due to its negatively and positively skewed density shape, the Burr XII distribution provides more flexibility in modeling non-monotonic failure rates.
The Burr XII model is crucial in reliability engineering as it predicts how long a system or component may last.
In particular, this is true when only partial data is available as a result of early terminations of tests.
Various medical outcomes can be modeled using this framework, commonly used in survival analysis.
Finance uses the Burr XII distribution to analyze extreme events, such as financial crises, thereby making it an essential resource for managing risk.
Likewise, environmental scientists use the Burr XII distribution to study complex patterns of nature, such as rainfall patterns, which are crucial for the effective management of natural resources.
Moreover, the cumulative distribution function and the reliability function of the Burr XII distribution have closed forms, allowing for simplified percentile and likelihood calculations under censored data.
For more on Burr XII and its applications, see [11â€“13].
Figs 1and2illustrate the hazard function of the Burr XII distribution with different parameters.
As shown, the hazard function is non-monotonic and can accommodate various shapes.
According to [14,15], due to the shapes ofh(t), the Burr XII distribution is widely used in quality control, reliability analysis, biological and life test studies, as well as in economics and industrial tests.
where,Ïˆ(s)is the digamma function andÎ³is the Euler-Mascheroni constantÎ³â‰ˆ0.5772.
Shannon entropy is one of the earliest and most commonly used entropy measures.
This measure has proven effective in the study of communication systems.
However, one significant disadvantage of the Shannon measure, particularly in the continuous case, is that it may be negative for certain probability distributions, complicating its interpretation as a measure of uncertainty.
Various generalizations have been proposed to address the limitations of Shannon entropy.
where,pis a parameter that leads to a positive entropy.
The R Ã©nyi entropy is known as the quadratic entropy whenp= 2.
whereÎ“(Â·)is the complete gamma function.
Eq8exists if and only ifp(Î²âˆ’1)+1>0, which is always satisfied ifÎ²â‰¥1, a condition considered in the subsequent simulation study.
HCentropy is often used in the context of fuzzy set theory and information retrieval, offering robustness in cases with incomplete or uncertain information.
Several researchers have studied entropy estimates for different life distributions.
[11,21] used progressive censoring to investigate entropy in the Burr XII distribution based on ranked set sampling.
[22] addressed entropy estimates for the Rayleigh distribution using doubly generalized Type-II hybrid censoring.
[23] considered entropy estimators for the inverse Lomax distribution via a multiple censored scheme.
[24,25] used non-informative prior to estimate the Shannon entropy of the Lomax distribution.
Additionally, [26] evaluated the performance of maximum likelihood and Bayesian models under progressively censored samples.
[27] applied Bayesian methods to Shannon entropy for the Burr XII distribution using progressive Type-II censored data.
[28,29] evaluated the accuracy of estimators using entropy measures for the Log-Logistic distribution.
[30,31] also examined the Shannon entropy of the inverse Weibull distribution under progressive first-failure censoring, comparing credible intervals to asymptotic intervals.
[32] used Monte Carlo simulations to illustrate Shannonâ€™s entropy estimates for progressively censored Maxwell distributions.
In this study, we explore these entropy measures within the context of the Burr XII distribution, which is known for its versatility in modeling non-monotonic failure rates.
In reliability studies, manufacturers seek to understand the failure time distributions of their products to ensure they meet high-quality standards and have a long lifespan.
This understanding is typically gained through life-testing experiments.
However, such experiments can be challenging due to time constraints and associated costs, especially when the experiment must be stopped before all items fail.
The data obtained from such prematurely ended experiments are known as censored samples.
Censoring is a practical technique used in life-testing experiments to save time and money, although it can lead to losing potentially essential data.
In the context of life-testing experiments, two widely recognized approaches are Type-I and Type-II censoring.
With Type-I censoring, the experiment is terminated once a specific time has passed.
In contrast, Type-II censoring involves ending the experiment only after a certain number of failures.
However, these conventional schemes do not allow for the removal of surviving items during the experiment other than at the final termination point.
To address these limitations, progressive Type-II censoring allows for the intermediate removal of surviving units throughout the experiment, providing a more flexible and practical approach.
With this type of censoring,nindependent and identically distributed items are simultaneously placed in a life-testing experiment, and onlym(<n) failures are fully observed.
The experiment progresses throughmstages: after the first failure occurs, a predetermined number of surviving units,R1, are randomly selected from the remainingnâ€“1 units, leavingnâˆ’1âˆ’R1surviving items.
In the event that the second item fails, the sample becomesnâˆ’2âˆ’R1, and another sample of sizeR2is randomly selected and removed from the remaining units.
This process continues untilmfailures are observed, and all the remainingnâˆ’mâˆ’R1âˆ’â€¦âˆ’Rmâˆ’1(=Rm)surviving units are removed from the experiment.
It is assumed that the lifetimes of thesenunits are independent and identically distributed with a common distribution functionF(x).
Further,n,m, and the censoring schemeR=(R1,R2,â€¦,Rm)are all predetermined.
IfR1=R2=â€¦=Rmâˆ’1=0, thenRm=nâˆ’m, corresponding to Type-II censoring.
IfR1=R2=â€¦=Rm=0, thenm=nrepresents the complete data set.
This method is particularly useful when units need to be removed from the test due to practical considerations, such as reallocating them for other purposes or observing degradation in a different context.
Progressive Type-II censoring, a generalized form of the traditional Type-II censoring method, empowers researchers to adjust it to suit various experimental needs.
If allRivalues are set to zero, the scheme reduces to standard Type-II censoring, where the experiment continues until allmfailures are observed without any intermediate removals.
The flexibility and practicality of progressive Type-II censoring have led to increased interest in this method, especially with the availability of high-speed computing.
This technological advancement facilitates extensive simulation studies and more efficient data collection, making researchers feel optimistic and forward-thinking about the future of reliability studies.
For those interested in a more detailed discussion of progressive censoring schemes, the works of [32] provide a comprehensive overview.
This is the first study, to our knowledge, to specifically investigate these five entropy estimators within the context of the Burr XII distribution using progressively Type-II censored data.
Our findings, including analytical expressions for each entropy measure, maximum likelihood estimators (MLEs), two-sided approximate confidence intervals for all five entropy indices, and numerical comparisons, provide valuable insights into the most effective entropy estimator.
This paper is composed of six sections.Sect 2discusses the maximum likelihood estimation of Burr XII distribution parameters under progressively Type-II censoring, as well as the derivation of maximum likelihood estimators for the five entropy measures: Shannon, RÃ©nyi, Havrda-CharvÃ¡t, Arimoto, and Tsallis.
The delta method is employed inSect 3to derive asymptotic confidence intervals for each of the five entropy measures.Sect 4comprehensively compares the entropy estimators through a simulation study, analyzing their performance in bias, variance, coverage probability, and confidence interval length under different censoring schemes.Sect 5applies the proposed methods to real-life data from the Wisconsin Breast Cancer Database (WBCD), using the perimeter-worst biomarker to assess the uncertainty between benign and malignant patient groups.
Finally,Sect 6concludes the paper by summarizing the key findings and emphasizing the practical applicability of the entropy measures.
The maximum likelihood estimation (MLE) method is often regarded as one of the most potent and acceptable approaches for drawing statistical inferences due to its consistency, sufficiency, invariance, and asymptotic efficiency.
While MLE can be computationally intensive in some cases, advances in computational power and software have made it more accessible and feasible for complex models and large data sets.
In this section, we focus on the estimation of the parameters of the Burr XII distribution under progressive Type-II censoring scheme.
We begin by deriving the MLEs for the shape parametersÎ±andÎ², which are essential for the subsequent analysis of the entropy measures.
These estimators form the foundation for calculating the entropy measures and constructing their associated confidence intervals, ensuring that the characteristics of the censoring scheme is accurately reflected in the results.
We use Newton Raphson algorithm to solve for theMLEofÎ²(Î²^).
Inserting this value into (19), we obtain theMLEofÎ±(Î±^).
The asymptotic confidence intervals (CIs) for entropy measures are derived to quantify the uncertainty of the estimates obtained from the Burr XII distribution under progressive Type-II censoring.
These intervals are based on the normal approximation of the maximum likelihood estimators.
To construct these confidence intervals, we apply the delta method.
This approach, combined with the observed Fisher information matrix, allows us to estimate the variance and covariance of the entropy measures, providing the necessary components for theCIcalculation.
For a detailed explanation of the delta method and its applications, see [33].
where,E^is the estimated entropy measure,ZÎ´/2denotes the upper(Î´/2)th percentile of the standard normal distribution, andVar^(E^)represents the estimated variance ofE^derived through the delta method.
whereÎ¾E=(âˆ‚Eâˆ‚Î±,âˆ‚Eâˆ‚Î²)âŠ¤evaluated at(Î±,Î²)=(Î±^,Î²^), andðˆâˆ’1(Î±^,Î²^)is the inverse of the observed Fisher information matrix at the estimated parametersÎ±^andÎ²^.
For the computation of the Fisher information matrix, the second derivatives of the log-likelihood function with respect to the parametersÎ±andÎ²are required.
These derivatives have been obtained using Mathematica 13 and are detailed in the appendix (see Appendix A).
These confidence intervals provide a rigorous means to quantify the uncertainty associated with the entropy estimators under the progressively Type-II censoring scheme.
For detailed mathematical derivations and the specific forms of the second derivatives used in the Fisher information matrix, refer to Appendix A.
This simulation study is designed to rigorously evaluate the performance of maximum likelihood estimators for the five proposed entropy measures.
These estimators are derived from various sets of progressive Type-II censored samples generated from the Burr XII distribution, following the methodology described by [32],x1,x2,...,xmis the progressive Type-II censored sample of sizemfrom the Burr XII distribution with parametersÎ±andÎ².
The sample size used isn= 100, with effective sample sizem=20,40,60.
The analysis is conducted for four values of the parameterp, specificallyp=0.5,0.7,1.5,3.
Results of the simulation are summarized inTables 1â€“4.
Due to space limitations, only some of the simulation results are presented.
The remaining results exhibit similar patterns.
It is evident fromTables 1â€“4that the performance of five entropy estimators consistently decreases as the effective sample sizemincreases across all schemes, particularly for the Renyi and Havrda-CharvÃ¡t measures.
The Tsallis and Arimoto estimators also demonstrate enhanced Bias reduction with increasingm.
However, the Tsallis estimator displays higher Bias at smallermand smallerpvalues, rendering it less dependable under those conditions.
The variance (Var) and confidence interval length (L) decrease asmincreases.
The Renyi estimator generally has the smallest variance for different values ofp, followed closely by Havrda-CharvÃ¡t and Arimoto.
Tsallis shows higher variance, especially at smallermand smallerp, but improves asmincreases.
Shannon is unaffected bypchanges and consistently shows small Bias, variance, and interval length across all schemes.
Regarding coverage probability (Cov), most estimators approach the nominal level of 0.95 as the sample size (m) increases.
Renyi and Havrda-CharvÃ¡t consistently achieve coverage close to 0.95 across all scenarios.
Meanwhile, Tsallis tends to perform poorly with smaller sample sizes and values ofp.
Overall, the Renyi and Havrda-CharvÃ¡t estimators offer the best balance between minimal Bias, low variance, and appropriate coverage probability, making them the most reliable across different scenarios.
The analysis results suggest that when choosing an entropy measure for practical use, the sample size and parameterpmust be considered.
Shannon entropy is a strong choice due to its stability.
However, Tsallis and HavrdÃ¡t can also be reliable estimation methods when used under specific conditions (such as largerm, lowerp, and a favorable scheme).
For the diagnosis of breast cancer, we utilized summary features from digitized images of a fine needle aspirate (FNA) of breast masses, which serve as biomarkers.
This section applies the proposed entropy measures to assess the uncertainty between benign and malignant patients using data from the Wisconsin Breast Cancer Database (WBCD), created by the University of Wisconsin [34].
The dataset consists of 569 observations and 30 features, with the variable â€œDiagnosisâ€ serving as the gold standard, where B = benign(n=357)and M = malignant(n=212).
Among the 30 features, we selected the perimeter-worst biomarker due to its superior diagnostic performance.
This biomarker demonstrates high sensitivity (0.920) and specificity (0.919), with a Youden Index of 0.839, outperforming other biomarkers in differentiating between benign and malignant cases.
The legitimacy of the Burr XII model for both benign and malignant data is assessed based on(Î±1,Î²1)=(1.6305,9.4945)for the benign group and(Î±2,Î²2)=(1.2270,11.1030)for the malignant group, using Kolmogorov-Smirnov (K-S), Anderson-Darling (A-D), and chi-squared tests.
The results, presented inTable 5at a significance level of 0.05, provide strong evidence that the Burr XII model fits both datasets well.
Additionally, the fitted pdfs and Q-Q plots for the benign and malignant datasets, shown inFigs 3and4(benign group) andFigs 5and6(malignant group), respectively, further confirm the Burr XII distribution as a suitable model for both datasets.
In this analysis, we apply the three different censoring schemes (Sc) described in Sect4to estimate the entropy measures for both the benign and malignant groups.
The sample sizes for the entropy estimates werem1= 119 for the benign group andm2= 90 for the malignant group.
We calculated the entropy measures and presented the results, including MLEs, Bias, asymptotic length (L), and asymptotic variance (Var), inTable 6.
Table 6reveals that Sc1 and Sc3 produce more precise estimates for all entropy measures, particularly in the benign group, where lower Bias and variance are observed compared to Sc2.
This pattern holds across benign and malignant datasets, with the differences in Bias and variance being more pronounced in the malignant group, where Sc2 again produces less reliable estimates.
Shannon entropy presents a notable limitation in this analysis, as it produced negative MLE values for both the benign and malignant datasets.
This complicates its interpretation, particularly for continuous distributions like the Burr XII, and raises questions about its suitability for this context.
The negative values may indicate potential misalignment between the data and the assumed distribution model, making Shannon entropy less reliable for measuring uncertainty in this dataset.
Among the entropy measures examined, RÃ©nyi entropy emerged as the most reliable indicator of uncertainty, consistently producing positive values across all schemes.
This contrasts with Shannon entropy, which yielded negative MLE values, and the Arimoto entropy, which exhibited higher Bias and variance under Sc2.
RÃ©nyi entropyâ€™s consistent performance across schemes and stability in both benign and malignant groups suggests its robustness in distinguishing between these two populations.
Scheme 3 generally provided the most precise estimates, whereas Sc2 produced the least reliable outcomes across all measures.
The perimeter-worst biomarker demonstrated lower uncertainty in the benign group compared to the malignant group across all entropy measures, highlighting its predictive power in distinguishing between diseased (malignant) and non-diseased (benign) cases.
This observation supports the effectiveness of the perimeter-worst biomarker as a diagnostic tool for breast cancer, particularly when paired with robust entropy measures like RÃ©nyi, which offer greater reliability in quantifying uncertainty in this context.
This study comprehensively evaluated five entropy measures, Shannon, RÃ©nyi, Havrda-CharvÃ¡t, Arimoto, and Tsallis, under progressive Type-II censoring schemes for the Burr XII distribution.
The simulation results indicated that RÃ©nyi and Havrda-CharvÃ¡t consistently outperformed the other measures in terms of Bias, variance, and coverage probability, particularly as sample sizes increased.
Tsallis and Arimoto improved with larger sample sizes but exhibited higher Bias and variance at smaller sample sizes.
Overall, the simulation results and the real-life example both suggest that RÃ©nyi entropy is the most robust and reliable measure of uncertainty, especially for larger sample sizes and across different censoring schemes.
Shannon entropyâ€™s stability makes it a strong choice, but its performance in terms of Bias and variance does not surpass that of RÃ©nyi or Havrda-CharvÃ¡t.
For practical applications, the choice of entropy estimator should consider both the sample size and the value ofp, with RÃ©nyi and Havrda-CharvÃ¡t offering the best overall balance between Bias, variance, and coverage probability.
whereÏˆ(.)=Î“â€²(.)Î“(.
)is the digamma function andÎ“â€²(.
)is the first derivative ofÎ“(.
),Ïˆâ€²(Î±)is the derivative of the digamma.
total2=âˆ‘i=t1mxiÎ²^logxixiÎ²^+1+âˆ‘i=t1mRixiÎ²^logxixiÎ²^+1+xmÎ²logxmR*(1+xmÎ²).
total2=âˆ‘i=t1mxiÎ²^logxixiÎ²^+1+âˆ‘i=t1mRixiÎ²^logxixiÎ²^+1+xmÎ²logxmR*(1+xmÎ²).
Î¾A|(Î±,Î²)=(Î±^,Î²^)=(âˆ‚Aâˆ‚Î±,âˆ‚Aâˆ‚Î²)|(Î±,Î²)=(Î±^,Î²^),âˆ‚Aâˆ‚Î±=pR00Î±(pâˆ’1)[(Î±Î²)pG1G2Î²G0]1p,âˆ‚Aâˆ‚Î²=âˆ’R0Î²2[(Î±Î²)pG1G2Î²G0]1p.