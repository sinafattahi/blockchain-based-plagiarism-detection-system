Lung diseases (LGDs) are related to an extensive range of lung disorders, including pneumonia (PNEUM), lung cancer (LC), tuberculosis (TB), and COVID-19 etc. The diagnosis of LGDs is performed by using different medical imaging such as X-rays, CT scans, and MRI. However, LGDs contain similar symptoms such as fever, cough, and sore throat, making it challenging for radiologists to classify these LGDs. If LGDs are not diagnosed at their initial phase, they may produce severe complications or even death. An automated classifier is required for the classification of LGDs. Thus, this study aims to propose a novel model named lung diseases classification network (LGD_Net) based on the combination of a capsule network (CapsNet) with the extreme learning machine (ELM) for the classification of five different LGDs such as PNEUM, LC, TB, COVID-19 omicron (COO), and normal (NOR) using CT scans. The LGD_Net model is trained and tested on the five publicly available benchmark datasets. The datasets contain an imbalanced distribution of images; therefore, a borderline SMOTE (BL_SMT) approach is applied to handle this problem. Additionally, the affine transformation methods are used to enhance LGD datasets. The performance of the LGD_Net is compared with four CNN-based baseline models such as Vgg-19 (D1), ResNet-101 (D2), Inception-v3 (D3), and DenseNet-169 (D4). The LGD_Net model achieves an accuracy of 99.71% in classifying LGDs using CT scans. While the other models such as D1, D2, D3, and D4attains an accuracy of 91.21%, 94.39%, 93.96%, and 93.82%, respectively. The findings demonstrate that the LGD_Net model works significantly as compared to D1, D2, D3, and D4as well as state-of-the-art (SOTA). Thus, this study concludes that the LGD_Net model provides significant assistance to radiologists in classifying several LGDs.

Lung diseases (LGDs) such as pneumonia (PNEUM), tuberculosis (TB), and COVID-19, etc., are infectious or transmissible diseases that can travel from one person to another [1–4]. These diseases are caused by numerous agents of infection, the most common of which are bacteria, fungi, and viruses, amongst others. The bacteria that triggered the infection [2], these symptoms can vary significantly. Some infections cause serious threats to one’s life, but many other infections do not. In December 2019, a new coronavirus known as COVID-19 first manifested itself in Wuhan, China, as an outbreak of fatal and severe infections, and it quickly spread throughout the country [1]. The COVID-19 is the pathogen that leads to the sickness. On March 11, 2020, the WHO designated COVID-19 as a global epidemic [2,3]. The COVID-19 pandemic resulted in the infection of millions of people all over the world [4–7]. Medical imaging techniques, including CXR, ultrasonography, and CT scans, have emerged as promising diagnostic tools for LGDs.

Malaise, migraine, headache, difficulty breathing, difficulty breathing, muscular soreness, parched mouth, backache, vomiting, and abdominal cramps were some of the clinical symptoms that were shown in the early stages of COVID-19 [8–10]. The absence of taste and fragrance was one of the most often-seen symptoms of COVID-19 [10]. Governments and regulatory bodies around the world have implemented a strict lockdown to maintain social isolation and stop the epidemic’s spread as daily reports of new breakouts have been arriving at an unprecedented rate [11]. The countries that have been hit the worst by COVID-19 have instituted travel and transit bans in trying to stop the virus from spreading further. In light of the current public health crisis, the medical community was making concerted efforts to identify and implement innovative methods, technologies, and approaches that allow them to monitor and curb the development of the COVID-19 outbreak [12]. AI [13] is now one of the most effective approaches that track the progress of COVID-19, assess its risk and severity [14], and predict its rate of increase.

In the beginning, an assay known as RT-PCR was utilized to identify COVID-19 [15]. To carry out this test, it is necessary to first extract the infected person’s DNA using reverse transcription. This DNA is then passed on to PCR to undergo DNA amplification and analysis. Because only RNA sequences are conveyed by this virus, it is, therefore, able to detect COVID-19 [16]. However, the PCR test does have certain drawbacks and has false-positive and false-negative outputs [17]. The diagnosis of COVID-19 at its initial phase is challenging for radiologists because the symptoms of COVID-19 are similar to LGDs. Recent studies are seeking to devise a categorization system that is both useful and effective for patients who are infected with COVID-19 and other LGDs. For the identification of the LGDs, CT scans are used [18]. By examining specific features, such as opacity or unclear patterns in the airways, CT imaging can play a significant role in the diagnosis of LGDs and COVID-19.

A novel LGD_Net model, which is based on the combination of CapsNet and ELM for the classification of LGDs using CT scans. Additionally, SegCaps is used with the LGD_Net to perform the segmentation process.

The imbalance distribution of LGD images in each class of the dataset is balanced by using BL-SMT. Additionally, an affine transformation method is applied to enhance the size of the datasets.

The GRAD-CAM highlights the infected area of LGDs by using the proposed LGD_Net model.

In this present work, we also perform the ablation study to demonstrate the efficacy of the LGD_Net.

The performance of the proposed LGD_Net model is compared with four baseline models such as D1, D2, D3, and D4in terms of many metrics such as accuracy (Z1), precision (Z2), recall (Z3), F1-score (Z4), dice similarity coefficient (Z5), and an AUC (Z6).

The proposed LGD_Net model attains the classification accuracy of 99.17% which is superior to baseline models and SOTA methods.

This study is divided into the following sections: Section II presents the modern literature on LGDs using different medical imaging modalities. The dataset description, dataset preprocessing, and proposed LGD_Net model are discussed in section III. The findings of the present study are discussed in section IV. The conclusion and future work are described in section V.

Recent studies used different imaging methods with AI for the classification of LGDs such as PNEUM, TB, LC, etc.Table 1presents the latest studies that use AI approaches for the diagnosis of LGDs. Wang et al., [31] designed a novel TL-based model for the identification of COVID-19 and PNEUM using CXR. Before training their model, they applied several image enhancement methods to prevent their model from overfitting. They achieved an accuracy of 94.52%.

Ioannis et al., [45] developed a CNN based on COVID-19 and PNEUM classification. They performed two experiments, firstly, they applied their model for binary classification such as COVID-19 and NOR cases. Secondly, they used their model for multi-classification such as COVID-19, NOR, and PNEUM. They attained an accuracy of 98.75% and 93.48% for binary and multiclass classification, respectively. The CoVNet was designed by [46] for LGD classification and they achieved a classification accuracy of 98.28%.

A CDC_Net model was designed by Malik et al., [35] for the classification of several LGDs i.e., LC, PNEUM, and COVID-19 using LGD CXR. The CDC_Net contains residual thoughts and they achieved an accuracy rate of 97.99%. The two models, i.e., Vgg-16 and ResNet-34 were used by Choudary et al., [47] for LGDs classification. The ResNet-34 attained the highest classification accuracy of 95.74% which is superior to Vgg-16. Goyal et al., [48] fined-tuned the Inception-v3 for the detection of LGDs by using CT scan images. Their model achieved an accuracy of 92.63%. The BDCNet model was made by Malik et al., [49] for the diagnosis of several lung disorders by using CXR. They applied several augmentation methods and attained the F1 score of 97.21%.

Another study by Malik et al., [50] designed a DMFL_Net with the combination of FL & CNN for the classification of LGDs. Additionally, their objective is to handle patient data privacy with LGD classification and they achieved significant outcomes in identifying lung disorders.

Sufian et al., [51] compared the performance of 06 TL models for the classification of LGDs using CT scans. They used the HE method to enhance the contrast of CT scans. Additionally, the data augmentation methods were also used before training the TL models. The highest accuracy of 96.78% was achieved by the InceptionNet-v3 model.

The study [52] proposed a MobileNet with the amalgamation of residual DCNN for the classification of lung diseases using CT scans. They attained a remarkable accuracy of 94.48%.

A ResNet model was used by the study [53] for the detection of lung disorders using CXR. They trained and tested the ResNet model on 02 public datasets. Additionally, 70% of training data were used for training, and the rest CXR data were used for testing the model. The ResNet model gained an accuracy of 97.00% in the classification of LGDs.

In [54], they ensembled the Vgg-16 with DenseNet-169 for LGD classification using CXR and CT scans. Their model achieved a recall of 95.50%. Malik et al., [36] proposed a CNN model for the diagnosis of COVID-19. They also applied BCT and FL to secure the patient data at the time of training. The remarkable results of 98.00% were achieved in terms of accuracy. Additionally, the study [55] also used the adversarial model to annotate lung disease using a CT scan.

Malik et al., [56] used the CNN model for the classification of several chest disorders. Initially, the SURF and ORB were applied to extract the features, and then these features were fed to the proposed CNN model. The ORB + Vgg-19 model attained a significant precision value of 97.15%. Kermany et al., [57] applied the InceptionNet-v3 model for the diagnosis of PNEUM using CXR. The InceptionNet-v3 model attained an accuracy of 92.80% in finding the PNEUM.

In [60], they proposed a three-layer CNN model for the PNEUM classification from NOR cases. They compared the outcomes of the three layers of the CNN model with ResNet-18, DenseNet-169, and Vgg-16. Additionally, a small dataset of lung diseases was used for training the proposed model and they achieved the classification accuracy of 92.40% in the identification of pneumonia.

Bernheim et al. [61] developed a ResNet-18 model with SVM for the identification of PNEUM. Initially, they applied the ResNet-18 for the identification of lung disorders. After that, they fused the SVM with the last convolutional layers of ResNet-18 for the classification of LGDs. The ResNet-18 model with SVM achieved a classification precision of 95.30%.

The classification of PNEUM and NOR cases were performed by Harmon et al., [62] by using DenseNet-121. They trained and tested the DenseNet-121 model on several publicly available databases of LGDs. They achieved significant results in the identification of LGDs.

The work [34] used the ResNet-18 model for the identification of viral PNEUM, NOR, and COVID-19 using 3D scan slices. The 3D was applied to train and test the ResNet-18 model. Their performance was compared with Vgg-16, DenseNet, and InceptionNet. The ResNet-18 outperforms these models and obtained an accuracy of 96.57%.

Another study was conducted by Bhandary et al., [63] for the classification of LGDs by combination of AlexNet and SVM. They applied the image enhancement techniques to enhance the contrast of the CXR images. Then, they applied data augmentation before training the proposed model. Their AlexNet and SVM models attained an accuracy of 95.63%.

Previous studies [8–13,15,17–19,21] employed DL models for the classification of COVID-19 and NOR cases using CT scans. Additionally, the studies [22–26,28–31,46] also used CT scan images for the identification of PNEUM. Several studies [1–3,5,23,53,36] conclude that the symptoms of LGDs are similar to each other and their classification becomes challenging for the doctor. No proper pre-processing methods were used by the previous studies [5–9]. Major studies [1–3] trained DL on an imbalanced dataset of the LGDs. However, these studies also used the deep CNN model which produces the vanishing gradient problem and might affect the classification performance of the models. Therefore, to handle these problems, this study uses spatial and signal normalization methods as data preprocessing approaches. Additionally, BL-SMT is used to resolve the problem of the imbalance number of images. Then, the LGD_Net model is used to perform the classification of the LGDs.

The experimental methodology of the LGD_Net model and four baseline models such as D1, D2, D3, and D4are discussed in this section.

The initial diagnosis of LGDs such as PNEUM, COO, LC, TB, and NOR can help doctors stop the progression of the illness and limit its impact. There is a possibility that the manual categorization of LGDs is inefficient and time-consuming. Because of this, there is a need for a diagnostic method for this condition that is more cutting-edge and has more automated components. Thus, this study proposed a model that combines CapsNet and ELM for classifying LGDs such as PNEUM, COO, LC, TB, and NOR through the use of CT scans. For training the LGD_Net model and D1, D2, D3, and D4, we fixed the resolution of the input CT scan image at 224 × 224 pixels. The spatial and signal normalization methods were also used to prevent the model from overfitting. To deal with the problem of datasets being unevenly distributed and to equalize the number of samples within each category, we additionally used the technique BL-SMT [64]. Then, we applied affine transformation methods to increase the size of the LGDs dataset. The LGDs dataset is divided into three portions such as training, testing, and validation.Fig 1presents the study flow diagram for the classification of LGDs using CT scan images. The experimental technique spanned 30 training epochs. Based on the confusion matrix, the performance of the LGD_Net was compared with D1, D2, D3, and D4in terms of Z1, Z2, Z3, Z4, Z5, and Z6. Furthermore, the Grad-CAM heat map was generated with LGD_Net to depict the visual features of LGDs.

This section presents an extensive description of five publicly available benchmark datasets that are used for training and testing the proposed LGD_Net and four baseline models such as D1, D2, D3, and D4. Due to the global prevalence of COVID-19, this investigation focused on CT scans of COO, PNEUM, LC, TB, and NOR diseases. Initially, we accessed a Kaggle repository that had been established by Gupta et al., [43] and downloaded a total of 800 CT scan images of the COO and 1540 images of NOR. Then, the LC images were collected from the study [65]. This dataset contains a total of 20,000 CXR and CT scans of which 5000 images are CT scans and the rest are chest X-rays. Additionally, for this study, CXR images are not considered in this study. Stefanini et al., [66] provide a multiclass CT scan image dataset of SARS-CoV-2 and PNEUM. The dataset contains a total of 4173 CT scans from 210 distinct patients, of which 2168 relate to 80 individuals who have been verified to have SARS-CoV-2 infection using RT-PCR and the rest were of PNEUM. Both the Public Hospital of the Government Employees of Sao Paulo (HSPM) and the Metropolitan Hospital of Lapa, both located in the Brazilian state of Sao Paulo, contributed to the collection of this lung dataset. Furthermore, 1247 CT scans of PNEUM were collected from [57]. TB CT scans were collected from the study [67]. The TB dataset contains a total of 4200 CT scans of which 3500 are of NOR images while the 700 images were of TB. A detailed summary of the LGDs dataset is demonstrated inTable 2. Additionally, a few sample CT scan images of LGDs are depicted inFig 2.

This section contains a comprehensive discussion of the data-preprocessing methods used in this study. Initially, data normalization methods are discussed. Secondly, the BL-SMT method is described to handle the imbalanced distribution of LGD CT scan images. Lastly, affine transformation methods are briefly explained which are used to enhance the dataset before training the LGD_Net model and D1, D2, D3, and D4.

The DL model faces challenges while processing the input CT scan image data [68]. Because the input data is coming from different CT scan machines, and every machine has its measuring parameters [69]. Therefore, in this study, two different D_Norm methods such as spatial normalization (SPN) and signal normalization (SGN) are used. The purpose of using these two methods is to make the quality of CT scan images consistent, regardless they are generated from different CT scan machines [68,69]. Initially, we applied SPN to maintain the resolution of the LGD CT scan [15], while SGN was used to adjust the brightness of each voxel to the lung window [70].

SPN is an image processing method used to align anatomical structure into standardized coordinate space of medical imaging such as CT scan, MRI, etc. The purpose is to ensure that CT scan images from different scanners are comparable by removing variations due to individual differences in size, shape, or orientation. This study uses SPN to determine the resolution of LGD CT scan images. Several studies [15,66–69] conclude that CT scans of human lungs have a standardized volume of 332 × 332 × 512 mm3. Thus, SPN is applied to the five LGD datasets used in this study. It converts the CT scan images of different formats into a single standard format [71] to make LGD_Net a viable option. As a direct result of this, improvements may be seen in both performance and learning.

This study uses the SGN method to adjust the pixel intensity values to a standardized scale, improving consistency across CT scan images of LGDs and enhancing the performance of the proposed LGD_Net model. Thus, the SGN is applied to get the final value by computing the intensity of each voxel with the LGDs window. The Hounsfield unit (HU) is required for measuring the window of the CT scan. The HU is obtained by using the window level (HWin_Level) and window width (HWin_Width). Eq (1) is applied to get the final normalized value by utilizing the current window size as the parameter.

whereILGD_Orignalrepresents the LGD images.ILGD_Normshows the normalized intensity of LGD CT scan images. For this study, we set the lower limit ofHWin_Levelbetween −0.05 and 0.5.

In this study, the BL-SMT upsampling method is employed to solve the problem of the dataset having an uneven distribution of LGD images. Most of the recent work [15,67–72] believes that providing an uneven distribution of images at the time of training the DL model can affect its performance. Thus, the BL-SMT model is used to balance the distribution of LGD images. The BL-SMT up-sampled the LGD images by adding the zero values in between the original LGD samples so that the sampling rate may be increased. The SMT produced the CT scan images of LGD by using Euclidean distance of each minority class of LGD data and BL focused on minority instances that are near the boundary with the majority class. Thus, we combine the BL-SMT to create the synthetic images of LGD from the original LGD CT scan images as shown inFig 3. The pseudocode of BL-SMT is presented in Algorithm 1. Furthermore,Table 3presents a detailed summary of the LGD image generated synthetically after using BL-SMT.

Input Parameters:TTrain_LGD: Set LGD images for training,MMin_LGD: Instances of minority set of LGD dataset,KNN,PNN:No. of nearest neighbors,UOri_LGD: Quantity of synthetic LGD images required to compensate for the original LGD images in the specified class.

Output:RSYN_LGD: A group of synthetic LGD images from the minority class.

1.I = ɸ// I represents a collection of LGD images that are considered BL.

5.IFL/2 ≤ r < L then//riis a borderline sample of LGDs.

9.RSYN_LGD= ɸ//RSYN_LGDis a set containing synthetic samples of LGD images.

14.si′ ←si+ j*(si– i)//j is a random number in(0, 1),siis a synthetic sample of LGD images.

18.RSYN_LGD′=RSYN_LGDURSYN_LGD′//RSYN_LGD′is the union of minority samples and synthetic samples.

In this study, several affine transformation approaches (ATP) such as rotation (RROT), scaling (SSCAL), horizontal shift (HH_Shift), vertical shift (HV_Shift), and random translation (RRAN_TRANS)to enhance the LGD datasets. The purpose of enhancing the LGD dataset is to prevent the LGD_Net model from overfitting. The dataset (DLGD−Data)generated after applying BL-SMT is split into three steps as presented in Eq (2).

HereTtrain=[ttrain(1ldotsttrain(i)…ttrain(|Ttrain|)]shows the training set of LGD images,TVal=[tVal(1ldotstVal(i)…tVal(|TVal|)]represents the validation set and the testing set is represented asTTest=[tTest(1ldotstTest(i)…tTest(|TTest|)]. Thus,DLGD−Datadivided into{Ttrain,TVal,TTest}as mentioned in Eq (3).

The ATPs are applied to theDLGD−Data→{Ttrain}which enhances the LGD images dataset. The enhanced image dataset(DNEW−LGD−Data)is obtained by using Eq (4).

Initially, we applied theRROTthe function of ATP, which rotates the angle vector (TRROT)by skipping the value of zero. TheRROTis performed by using the Eqs (5–6).

TheSSCALoperation is performed on the LGD dataset by applying theTSCALfactor by skipping the value ofTSCAL= 1. The following Eqs (7–8) are used to perform theSSCAL.

For this study,HH_Shiftis used. TheHH_Shiftshift the X-coordinates of each point of the CT scan image to a certain amount that is proportional to the Y-coordinate. However, the points of the Y-coordinate remain unchanged. After usingHH_Shiftfor a value (P, R) the new coordinates are produced (P′, R′) with a shift value of (L) measured using Eqs (9–10).

However, Eq (11) and (12) is used to create the new image by usingHH_Shift.

For this study,HV_Shiftis used. TheHV_Shiftshift the Y-coordinates of each point of the CT scan image to a certain amount that is proportional to the X-coordinate. However, the points of the X-coordinate remain unchanged. After usingHV_Shiftfor a value (P, R) the new coordinates are produced (P′, R′) with a shift value of (M) measured using Eqs (13–14).

However, Eq (15) and (16) is used to create the new image by usingHV_Shift.

By usingRRAN_TRANS, we transformed the LGD dataset byitimes using random horizontal movement (RHM) and random vertical movements (RVM) keeping the value in a range between[−HRanT,HRanT]for equal distribution as discussed in Eq (17). However, the symbols RXand RYshow theRHMandRVM, respectively.

TheRRAN_TRANSis applied to produce the new LGD images by using Eqs (18–19).

This section is divided into two parts. Initially, we used SegCaps to perform the CT scan image segmentation of LGDs. After that, the segmented CT scan images are used with a proposed LGD_Net model based on CapsNet with ELM for the classification of LGDs.

We used the SegCaps method to perform the segmentation process of several LGDs such as COO, PNEUM, LC, TB, and NOR. The procedure of segmenting the CT scan images was carried out with the assistance of SegCaps, as described in [71]. In addition, segmented CT scan images are utilized by the proposed model during the entirety of the training process in conjunction with ELM for the identification of LGDs. When it comes to the process of chest CT scam image segmentation, the strategy that is recommended makes use of 2D slices as the input. When segmenting the CT scan of the lungs, a volume with the dimensions 332 × 332 × 512 mm3is used. SX, SY, and SZare the three planes that make up each volume of a three-dimensional (3D) CT scan. We established these planes to make it easier to differentiate between different types of LGDs. The Eq (20) is applied to quantify these CT scans of LGDs.

whereCIrefers to the likelihood of chest diseases andLstands for the location of the disease. The letterErepresents the technique that is applied while defining voxel views in three-dimensional space. MethodLwas used to predict thePSX,PSY, andPSZvoxels. The conventional method takes a long time; therefore, we made the following change to Eq (20).

In recent years, CNN has seen an increase in the number of medical applications for CT scan image classification [71–73]. This results in a significant increase in the amount of complexity that must be computed and even has an effect on the degree of performance that can be attained by the classifier. This is because the pooling layers (P_lay) of a CNN do not process the spatial relation that is present between the features of LGD images [74]. The LGD_Net model overcomes the previously described issues and achieves improvements in the diagnostic accuracy of LGDs such as COO, PNUEM, LC, TB, and NOR by fusing the potent capabilities of CapsNet [24] with ELM [25]. In LGD_Net, the CapsNet has provided the extraction of strong features [71] while ELM [72] has been effectively substituted for the more conventional dense classification layers to enhance LGD predictions [75]. In contrast to traditional ANN [75,76] methods, the proposed LGD_Net model calculates its inputs and then summarizes the outcome into a small vector of final outputs.Table 4presents the comparison between LGD_Net and ANN.

In LGD_Net, each layer of the CapsNet design has its encoder and decoder. Encoders typically consist of three layers: the convolutional layer (ConvL), the PrimaryCaps (PCAP) layer, and the DigitCaps (DCAP) layer [65]. Decoders, on the other hand, typically consist of three FCLs. The structure of LGD_Net used for the classification of LGDs is illustrated inFig 4.

In the proposed LGD_Net model, the initial ConvL consists of 512 kernels that are 5 × 5 × 1 in size and have a ReLU function. The value of stride to set to 01 for the initial ConvL of the LGD_Net model. This layer is responsible for converting the individual pixel intensity data into the activity levels of nearby feature detectors. The translated output is subsequently passed to the PCAP layer. PCAP layer is the name given to a ConvL, and it features 32 channels of 8-D ConvL capsules. This represents that the PCAP layer of 8D ConvL capsules contains a 5 × 5 kernel with a stride having a value of 2. The responsibility of the PCAP layer is to generate the original CT scan images of LGDs. To do this, it performs inverse graphics [76,77] and reverse engineering [78,79].

Following this, the LGD_Net consists of 5 × 5 × 256 kernels to an input volume that is 20 × 20 × 256, the capsule results in the production of a tensor with an output of 8-D that is 6 × 6. Considering that there are 8-D capsules included within the proposed model, the output would have the dimensions 6 × 6, 8 × 8, and 32 kernels. The input for each of the 16-D capsules that go into making up a class in the DCAP layer is taken from the capsule that is positioned immediately before it in the stack. The 8 × 16 weight matrix, denoted by the notationW(s,t),is utilized to carry out ATPs on each 8-D capsule. The Eq (23) is used to encode the (E(s,t)) the spatial relation that exists between the CT scan images of LGD.

whereas the weight matrix is denoted byW(s,t)andH(s,t)shows the component vector. Additionally, the input vector of the LGD CT scan is represented byVt.To get the current value of the capsule (C), the followingEq (24)is used to calculate the sum input vector and its weight.

After that, we put the encode (E(s,t)) the spatial relation as mentioned in Eq (23) to (24), and the following Eq (25) is obtained for measuring the weighted sum of the input vector of CT scan of LGDs.

TheC(i,j)represents the routing softmax method (RSM). The RSM is calculated by using the Eq (26).

Then, the value ofC(i,j)is entered in the Eq (25). The final Eq (27) is used by the LGD_Net model for calculating the weighted sum of the input vector.

This study uses the LGD_Net model for the multiclassification of LGDs, their probability ranges from 0 to 1. So, the squashing function is applied, which is measured by using Eq (28).

To gain an appropriate ratio, the low-level capsule (LLC) to the high-level capsule (HLC) ratio is gradually modified based on the experiment’s results. Algorithm 2 presents the pseudocode of the LGD_Net model by distributing the LLC to HLC using CapsNet. The reason for using Algorithm 2 is to process the several iterations at the time of distributing the LLC to HLC is is progressively updated depending on the output of the HLC and the finest outcome is achieved.

Algorithm 2: Proposed LGD_Net for processing all capsules.

Input Parameters: Capsule Network = CCAP_NET; Layers in CapsNet = LCAP_LAYERS; Weighted Sum = WCAP_SUM.

The LGD_Net model extracts the dominant features from CT scan images with the help of the CapsNet model and feeds these features to ELM for the classification of several LGDs such as COO, PNEUM, NOR, TB, and NOR. For this study, ELM contains a single hidden unit. The purpose of this layer is to auto-tune the features obtained from CapsNet as shown inFig 4. The ELM only makes use of a single hidden layer, thus there is no need to make any modifications to that particular component of the network. To achieve a high level of accuracy and increase its overall speed, ELM makes use of the kernel function. ELM uses weight-biased autotuning in conjunction with non-zero activation functions; thus, the key benefits are enhanced approximation and reduced training error [80,81]. To measure the output of ELM, the following Eqs (29–30) are used.

Here, the variableLis used to measure the bias vector [82]. The total training samples used for the LGD_Net model are presented by the parameterN. Additionally, the input vector and hidden units are represented asKandG, respectively [83–85]. Additionally, the value ofbdisplays the weight vector between the hidden and output layers, whileJis the vector that lies between the input layer and the hidden layer. Like ANN which uses backpropagation, for this study, we usedβ-matrix as a pseudo-inverse. Eq (31) is used to perform this operation.

The values ofR, H, andβare calculated using Eq (32) and (33), respectively. Additionally, the resultant matrix is described in Eq (34).

Here, the variablesH, R,andLpresent the hidden layer, training data, and no. of output, respectively. The pseudocode of the LGD_Net with ELM is presented in Algorithm 3.

Algorithm 3:Proposed LGD_Net model with CapsNet and ELM.

Input:LGDs Image  = CCT_SCAN; Epoch = EEPOCH; Capsule Network = CCAPS-NET; Features = CCAPS_FE; ELMs = ELGD_ELM.

Output:Classification of several LGDs i.e., COO, PNEUM, NOR, TB, and NOR.

By using the confusion matrix (C_Mat), the performance of the proposed LGD_Net model and D1, D2, D3, and D4are measured. The C_Mat shows the original(γOri)and predicted (γPre) value obtained by these models. For this study, we executed the LGD_Net and D1, D2, D3, and D4models up to 30 epochs to get the output. The C_Mat for each epoche=1,2,…Eare presented in Eq (35).

whereCtshows the test set of the LGDs data, and|Ct|2represent a balanced enhanced LGDs dataset obtained after applying the ATPs. In this study, when the LGD_Net model is applied toCt, then the diagonal elements change into|c|2. The following Eq (36) is the operation of C_Mat used in this study.

From above Eq (36), the four variables{l1(e),l2(e),l3(e),l4(e}Represent true positive (TP), false positive (FP), false negative (FN), and true negative (TN) at the ethrun. The{l1(e}shows that the LC, is accurately COO, NOR, PNEUM, and TB is correctly classified. The{l3(e}shows that the COO is wrongly classified as NOR or vice versa. The{l2(e}presents that NOR CT scans are inaccurately classified as COO, LC, PNEUM, and TB. The{l4(e}the PNEUM images are accurately classified as PNEUM. Several metrics such as{Z1(e),Z2(e),Z3(e),Z4(e),Z5(e),Z6(e}were used to measure the efficacy of LGD_Net and D1, D2, D3, and D4model. Where accuracy is denoted by (Z1), precision is denoted by (Z2), recall is denoted by (Z3), F1-score is denoted by (Z4), dice similarity coefficient (DSC) is denoted by (Z5), and an AUC is denoted by (Z6) and these are mathematically written as Eqs (37–42).

In addition, theZ5is applied to evaluate the effectiveness of the segmentation performed by the SegCaps. The Eq (41) is used to measure theZ5.

whereZ5(A,Bis used to assess the amount of spatial overlap between two different segmentations, with A and B standing for the target regions. Lastly, the Eq (42) is used to calculate theZ6of the LGD_Net and four D1, D2, D3, and D4models.

This section contains the outcomes produced by the LGD_Net, D1, D2, D3, and D4in classifying the several LGDs using CT scan images.

In this study, an open-source TensorFlow (TF) library version 2.15.0 was used to implement the proposed LGD_Net model. The TF version is also used for the development of four models such as D1, D2, D3, and D4. However, the Keras library is also used to execute the backend operations. The implementation that has no link with DL models was programmed in Python 3.12.5v. The Imblearn library having version 0.12.4 was used to implement the BL_SMT. Additionally, the affine library was used to perform the ATP operations. This experiment was performed on a PC having Windows 10. The specifications of the PC are core i8 11thgeneration, having 02 RAMs of 16 GB, and 11 GB NVIDIA GPU. Several hyperparameters of the LGD_Net model are fine-tuned. The detailed description of the hyperparameters is demonstrated inTable 5.

Table 6contains the comprehensive obtained by using LGD_Net, D1, D2, D3, and D4for the classification of several LGDs using CT scans. The results reveal that the proposed LGD_Net model achieved the highest Z1of 99.71% as compared to D1, D2, D3, and D4. However, the LGD_Net model without using ATPs and BL-SMT achieved a Z1of 90.64%. The use of ATPs and BL-SMT with LGD_Net increases the Z1by 9.07%. The D1model achieved the classification Z1of 91.21%. The D2and D3achieved the Z1of 94.39% and 93.96%, respectively for classifying the LGDs using CT scans. Additionally, D4achieved a Z1of 93.82% in the classification of LGDs. The graphical representation of the LGD_Net, D1, D2, D3, and D4in terms of Z1is illustrated inFig 5.

The Z2is used to measure the proportion of TP values from actual LGD image sample data [86]. In this study, the TP means the individuals have PNEUM, and the proposed LGD_Net and other models recognize it as PNEUM. The higher Z2shows that models accurately predicted the TP LGD image samples. The Z2of LGD_Net, D1, D2, D3, and D4are depicted inFig 6. FromTable 6, the results of Z2demonstrate that the proposed LGD_Net achieved the highest results. The Z2of the LGD_Net model is 99.71%. However, LGD_Net without ATPs & BL-SMT gained the Z2of 86.69%. The D1attained the Z2of 92.77%. The D2achieved the Z2of 96.25%. Additionally, Z2of 96.53% and 96.54% were achieved by D3and D4, respectively.

For this study, the Z3denotes the precision as discussed in Eq (39). The Z3of the LGD_Net, D1, D2, D3, and D4are compared with each other. The highest Z3of 99.69% was achieved by the LGD_Net model. The results show that LGD_Net has the capability of identifying the correct TP cases from all positive predicted cases [87–89]. The detailed results of the LGD_Net model and other models are shown inFig 7. The D1has achieved a significant Z3value of 95.39%. The D2has gained 96.39% of Z3. The LGD_Net model without ATPs & BL_SMT has gained the Z3of 94.14%. The Z3of 96.51% and 96.09% was gained by the D3and D4.

The Z4is used to measure the harmonic mean of Z2and Z3[89–91]. The high value of Z4shows that models are efficient in classifying the LGDs using CT scan images. The results show that the LGD_Net model has attained the highest Z4value of 99.70% in identifying the LGDs as compared to other models used in this study. Without ATPs and BL-SMT, the LGD_Net model achieved the Z4of 75.37%. The use of ATPs and BL-SMT has shown a significant impact and raised the Z4to 24.33%. The D1has gained the Z4of 93.83%. The D2model attained the Z4of 96.34%. Additionally, the Z4of 96.86% and 96.78% were attained by the D3and D4, respectively. The results of Z4are depicted inFig 8.

For this study, we used Z6to represent the model capability in distinguishing the LGDs. The high AUC shows that models perform appropriately in distinguishing the TP and TN cases. The results fromTable 6show that the proposed LGD_Net attained the highest AUC of 99.90%. However, other models used in this study also perform quite well in terms of Z6. The 99.59% Z6was achieved by D1. The D2 and D3 models achieved the Z6of 99.72% and 99.88%, respectively. In last, D4and LGD_Net without ATPs & BL-SMT achieved the Z6of 99.62% and 99.13%, respectively. The Z6of these models is graphically illustrated inFig 9.

In this work, the loss represents measures of LGD_Net, D1, D2, D3, and D4prediction aligning with actual results. Therefore, we used a cross-entropy loss function for this work. A very low loss value of 0.023 was attained by the LGD_Net as compared to the other models such as D1, D2, D3, and D4. It shows that LGD_Net correctly predicts the LGDs from the actual LGDs CT scan images. Moreover, the LGD_Net without ATPs and BL-SMT gained a loss of 0.267. The D1has a loss of 0.161, while the D2and D3have a loss value of 0.095 and 0.193, respectively. The loss curves achieved by these models are presented inFig 10.

For this study, we used ROC to represent the LGD_Net and D1, D2, D3, and D4efficacy and reliability of LGD classification. The higher the ROC means that the model performance in LGDs classification is more correct. The ROC results of LGD_Net, D1, D2, D3, and D4are presented inFig 11. The results show that LGD_Net attained ROC of 0.9967 and outperforms the other models used in this work. The LGD_Net without ATPs and BL-SMT model achieved an ROC of 0.9859. The ROC values of 0.9889, 0.9959, 0.9919, and 0.9962 were achieved by the D1, D2, D3, and D4. The ROC of these models is graphically presented inFig 11.

The AU (ROC) is used to represent the classwise performance of the LGD_Net, D1, D2, D3, and D4in classifying the LGDs using CT scan images as illustrated inFig 12. InFig 12, class 0 represents the COO, class 1 shows the PNEUM, class 2 shows the LC, class 3 represents the TB, and class 4 shows the NOR.

To assess the viability of the LGD_Net and other models, a total of 692 LGD CT scans were used.Fig 13provides a segmentation of several LGDs such as COO, PNEUM, LC, and TB, which illustrates that the LGD_Net with SegCaps model works more effectively than UNET and UNET++. The results from the LGD_Net are quite close to ground truth.Table 7presents a detailed presentation of the findings.

The original image of LGD CT scans is illustrated in the first row. The second row presents the original mask of the original image LGDs. From third to fifth, predicted masks are shown that were produced by the UNET, UNET++, and LGD_Net with SegCaps, respectively.

FromTable 7, it has been determined that UNET has a Z5of 85.29%, a Z2of 85.43%, and an Z1of 85.16%. Likewise, UNET++ manages to attain a Z5of 87.11%, Z3of 87.29%, and Z1of 87.20%. The LGD_Net with SegCaps yields a Z5of 96.69%, which is superior by 11.40% and 9.58%, respectively, to both UNET and UNET++.

The C_Mat was developed to evaluate the performance of the LGD_Net model and the other four models used in this work for the classification of LGDs. The LGD_Net achieved the highest result by accurately classifying the 690 LGD of CT scans out of 692, including 143 cases as LC, 143 cases as COO, 131 cases PNEUM, 150 cases Nor, and 123 cases as TB. The LGD_Net model misclassifies the two cases as TB and LC as presented inFig 14(f). The LGD_Net without ATPs and BL-SMT shows poor performance in classifying the LGDs. Additionally, 74 cases of LC, 18 cases of COO, 06 cases of NOR, and 11 cases of TB were correctly classified as illustrated inFig 14(e). The D1correctly predicts the 153 cases as LC. While, 110, 145, 134, and 110 cases of COO, PNEUM, NOR, and TB, respectively, were correctly classified. Furthermore, the 14 cases of TB are misclassified as COO. The D2produced significant results as compared to D3and D4. The D2correctly classifies the 146 cases of LC, 123 cases of COO, and 122 cases of PNEUM. However, the D2misclassified the 3 cases of NOR as COO and 10 cases of TB as COO. The detailed C_Mat results are depicted inFig 14.

In addition, this study uses the Grad-CAM [86–90] heatmap technique to provide a graphical illustration of the results produced by LGD_Net. The purpose of the heatmap is to illustrate the particular region of interest that is being focused on by the LGD_Net.Fig 15epresents the GRAD-CAM of the LGD_Net model for highlighting the infection that occurred due to the LGDs.

For this work, the LGD_Net model was developed by combining the ATPs and BL-SMT. The control variable strategy, which was also utilized to concurrently adjust a variable to determine whether the LGD_Net relates to LGDs, was used to statistically determine the experimental outcomes. This study examines the LGD_Net model classified the several LGDs using ATPs & BL-SMT and without it. To ascertain the significance of the new module to the model, we compared the models using the current techniques. The outcomes of LGD_Net are shown in Experiment 1, and the ATPs & BL-SMT approach is shown alongside the LGD_Net in Experiment 2. The experiments’ detailed findings are shown inTable 8.

Comparing the results of Experiment 1 and Experiment 2, it is clear that adding ATPs and BL-SMT enhanced the classification accuracy of LGD_Net by 9.07%. There are two reasons for producing the remarkable outcomes in Experiment 2, initially, ATPs produced effective synthetic image data by preserving geometric relationships while modifying feature sizes and locations. Additionally, the ATPs in LGD_Net facilitate the efficient learning of intricate patterns. Secondly, the use of SMOTE resolves the class imbalance problem of the LGDs by generating synthetic LGD CT scan images for the minority class. While BL generates the synthetic LGD CT scan samples that are near the decision boundary between minority and majority class [92–94]. Thus, the use of ATPs and BL-SMT supports the LGD_Net model to improve performance and lowering bias towards the majority class [45,95–98].

To assess the applied viability of the LGD_Net model in clinical environments, we conducted a detailed computational performance evaluation. The computational analysis is performed between the proposed LGD_Net model and D1, D2, D3, and D4in terms of training time, latency, complexity, and storage requirement. The detailed results of the computational cost analysis are presented inTable 9.

FromTable 9, the results show that the LGD_Net model trained significantly faster than D1, D2, D3, and D4due to its lighter architecture and fewer parameters. Additionally, the LGD_Net model outperformed these four models in terms of latency, an essential criterion for real-time clinical diagnosis. Thus, the study concludes that LGD_Net offers a balanced trade-off between accuracy, speed, and resource usage, showing strong potential for real-world clinical settings.

For this study, we compare the LGD_Net with recent modern studies [45,36,37,43,91–97,99]. Furthermore,Table 10presents the comprehensive analysis of the LGD_Net with SOTA in terms of Z1, Z2, Z3, and Z4.

LGDs are a cluster of lung disorders. Different medical imaging such as CT scans, CXR, etc., is used to diagnose and classify a wide variety of LGDs [1–3]. Most of the studies [16–17,23] conclude that CT scans are the most accurate [11] and efficient [19–21] method for detecting lung disorders [98]. Thus, for this study, the proposed LGD_Net has been developed with the combination of CapsNet and ELM. Additionally, the SegCaps were used with LGD_Net for the segmentation of the LGDs using CT scan images. In this study, five publicly benchmark LGD datasets were applied for training and testing the LGD_Net model. The D_Norm method such as SPN and SGN were applied to improve the LGDs CT scan image data integrity. The LGDs datasets contain an imbalanced number of images, so, BL-SMT was applied to handle this. After that, ATPs were applied to enhance the LGD dataset to prevent the LGD_Net and baseline models D1, D2, D3, and D4from overfitting. Algorithm 1 outlined the pseudocode of BL-SMT.

The performance of LGD_Net with and without using ATPs and BL-SMT was compared with D1, D2, D3, and D4in classifying LGD using CT scans. The LGD_Net with ATPs and BL-SMT attained the remarkable classification Z1of 99.71%. While other models, D1, D2, D3, and D4were achieves the Z1of 91.21%, 94.39%, 93.96%, and 93.82%. The comprehensive outcomes of the LGD_Net, D1, D2, D3, and D4are presented inTable 6. The results ofTable 6demonstrate that LGD_Net is more capable of identifying the LGDs and extracting dominant discriminative patterns from CT scans. Moreover, the outcomes of D1, D2, D3, and D4are also discussed inTable 6. The D1, D2, D3, and D4perform less in classifying LGDs as compared to LGD_Net. The reason is that D1, D2, D3, and D4have been restricted by their FCL. Because the neurons attached to the input are so big, the filter size in D1, D2, D3, and D4is insufficient, ignoring the key components of the LGD CT scan images. Furthermore, because these models contain a lot of layers, the vanishing gradient issue arose during training. Thus, all these problems are overcome by using LGD_Net which contains CapsNet capsules that capture spatial interactions and increase the robustness of LGD classification using CT scans. Furthermore, the single-layer architecture of ELMs with randomly assigned hidden nodes enables the LGD_Net to train quickly by determining the output weight analytically.

The results of the LGD_Net were also compared with SOTA as presented inTable 9. Huyut [91] proposed a model based on KNN for the classification of COVID-19 and NOR cases. They achieved a classification Z1of 94.05%. Lasker et al., [99] designed a novel LWSNet model for the identification of LGDs such as COO, NOR, and PNEUM. Their LWSNet model achieved the Z1and Z4of 96.98% and 96.92%, respectively. The study [92] proposed a CNN-based model for lung diseases and achieved a remarkable Z 1 of 97.38%. Khan et al., [93] designed an EfficienctNet-B1 model for classifying chest diseases using CT scans. Their model scored a Z1of 92.13%. Zhang et al., [96] proposed CNN model COO classification and achieved 72.77% of Z1. FromTable 9, the results reveal that LGD_Net achieved the highest classification Z1of 99.71% in diagnosing the five LGDs such as COO, LC, TB, NOR, and PNEUM as compared to SOTA methods.

For this study, a novel LGD_Net was designed for the classification of LGDs using CT scan images. Currently, lung disorders associated with LGDs are rapidly expanding and harming communities all over the world. There have been a significant number of fatalities as a result of ineffective and time-consuming testing processes and a failure to diagnose lung disorders at an earlier stage. Thus, this study suggested an LGD_Net model to classify several LGDs such as COO, PNEUM, TB, LC, and NOR using CT scan images. Five publicly available benchmark LGD datasets were used for training the LGD_Net model. The datasets contain imbalanced classes of LGDs, therefore, BL-SMT was applied to handle this problem. Additionally, ATPs were also applied to enhance the datasets and prevent the LGD_Net from overfitting. The SegCaps were used to process the segmentation of the lung disorder’s CT scan images. The GRAD-CAM was produced with LGD_Net to highlight the infected region. The results of the ablation study also demonstrate the effectiveness of the LGD_Net in classifying LGDs. The highest classification accuracy of 99.71% was achieved by the LGD_Net. Hence, this study concludes that the LGD_Net model produced significant outcomes as compared to the baseline models such as D1, D2, D3, D4, and SOTA classifiers. Additionally, the LGD_Net can be of great assistance to radiologists. The limitation of the study is that the LGD_Net is not effective for other medical imaging modalities such as sonography, MRI, etc. However, in the future, we evaluate the LGD_Net by integrating the blockchain with federated learning for patients’ data privacy.