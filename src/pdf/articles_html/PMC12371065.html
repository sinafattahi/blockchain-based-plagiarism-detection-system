
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            Automated detection of Parkinson’s disease using improved linknet-ghostnet model based on handwriting images - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="D2E4A3288AF2063305A328003D7E9641.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="scirep">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12371065/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="Scientific Reports">
<meta name="citation_title" content="Automated detection of Parkinson’s disease using improved linknet-ghostnet model based on handwriting images">
<meta name="citation_author" content="P Pradeep">
<meta name="citation_author_institution" content="Research Scholar, School of Computer Science and Engineering and Information System, Vellore Institute of Technology, Vellore, 632002 Tamil Nadu India">
<meta name="citation_author" content="J Kamalakannan">
<meta name="citation_author_institution" content="Research Scholar, School of Computer Science and Engineering and Information System, Vellore Institute of Technology, Vellore, 632002 Tamil Nadu India">
<meta name="citation_publication_date" content="2025 Aug 21">
<meta name="citation_volume" content="15">
<meta name="citation_firstpage" content="30731">
<meta name="citation_doi" content="10.1038/s41598-025-12636-w">
<meta name="citation_pmid" content="40841807">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12371065/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12371065/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12371065/pdf/41598_2025_Article_12636.pdf">
<meta name="description" content="Parkinson’s disease (PD), is a neural disorder that damages movement control, which is reflected by different non-motor and motor symptoms. PD is caused by the weakening of neurons that produce dopamine in the brain, and it includes symptoms like ...">
<meta name="og:title" content="Automated detection of Parkinson’s disease using improved linknet-ghostnet model based on handwriting images">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="Parkinson’s disease (PD), is a neural disorder that damages movement control, which is reflected by different non-motor and motor symptoms. PD is caused by the weakening of neurons that produce dopamine in the brain, and it includes symptoms like ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12371065/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12371065">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1038/s41598-025-12636-w"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/41598_2025_Article_12636.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12371065%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12371065/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12371065/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12371065/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-scirep.jpg" alt="Scientific Reports logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to Scientific Reports" title="Link to Scientific Reports" shape="default" href="http://www.nature.com/srep" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">Sci Rep</button></div>. 2025 Aug 21;15:30731. doi: <a href="https://doi.org/10.1038/s41598-025-12636-w" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1038/s41598-025-12636-w</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22Sci%20Rep%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sci%20Rep%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22Sci%20Rep%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22Sci%20Rep%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Automated detection of Parkinson’s disease using improved linknet-ghostnet model based on handwriting images</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Pradeep%20P%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">P Pradeep</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">P Pradeep</span></h3>
<div class="p">
<sup>1</sup>Research Scholar, School of Computer Science and Engineering and Information System, Vellore Institute of Technology, Vellore, 632002 Tamil Nadu India </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Pradeep%20P%22%5BAuthor%5D" class="usa-link"><span class="name western">P Pradeep</span></a>
</div>
</div>
<sup>1</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kamalakannan%20J%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">J Kamalakannan</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">J Kamalakannan</span></h3>
<div class="p">
<sup>1</sup>Research Scholar, School of Computer Science and Engineering and Information System, Vellore Institute of Technology, Vellore, 632002 Tamil Nadu India </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kamalakannan%20J%22%5BAuthor%5D" class="usa-link"><span class="name western">J Kamalakannan</span></a>
</div>
</div>
<sup>1,</sup><sup>✉</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="Aff1">
<sup>1</sup>Research Scholar, School of Computer Science and Engineering and Information System, Vellore Institute of Technology, Vellore, 632002 Tamil Nadu India </div>
<div class="author-notes p"><div class="fn" id="_fncrsp93pmc__">
<sup>✉</sup><p class="display-inline">Corresponding author.</p>
</div></div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2025 Jan 29; Accepted 2025 Jul 18; Collection date 2025.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© The Author(s) 2025</div>
<p><strong>Open Access</strong> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="https://creativecommons.org/licenses/by/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://creativecommons.org/licenses/by/4.0/</a>.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12371065  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40841807/" class="usa-link">40841807</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="Abs1"><h2>Abstract</h2>
<p id="Par1">Parkinson’s disease (PD), is a neural disorder that damages movement control, which is reflected by different non-motor and motor symptoms. PD is caused by the weakening of neurons that produce dopamine in the brain, and it includes symptoms like bradykinesia (delay in movements), stiffness, and tremors. People frequently suffer from loss of motor skills when the illness worsens, which has a big influence on everyday tasks like writing. Micrographia is a disorder marked by very tiny, cramped handwriting and is one of the symptoms of PD. As a reflection of the disease’s wider motor impairments, patients may observe that their handwriting gets harder to read and control. Detecting Parkinson’s disease via handwriting images is one of the major research areas in the medical field. This research proposes an automated PD detection approach with handwriting images using an improved hybrid classification model. Primarily, a modified Wiener filter is employed for pre-processing the handwriting image. Then, modified PHOG, Deep features and Shape features are extracted. Finally, detection is performed using hybrid Improved LinkNet and Ghostnet models, termed (ILN-GNet), whose outcomes indicate if the individual is healthy or affected. From the analysis, a higher precision of 0.99 is achieved by the ILN-GNet, while existing methods attained low precision. Thus, these innovations significantly enhance early diagnosis and monitoring, enabling timely interventions before the disease progresses. Moreover, the proposed approach can contribute to remote healthcare solutions, by providing a scalable, and efficient tool for PD diagnosis.</p>
<section id="kwd-group1" lang="en" class="kwd-group"><p><strong>Keywords:</strong> Parkinson’s disease, Modified wiener filter, Modified PHOG, Improved LinkNet, Ghostnet</p></section><section id="kwd-group2" class="kwd-group"><p><strong>Subject terms:</strong> Parkinson's disease, Computer science</p></section></section><section id="Sec1"><h2 class="pmc_sec_title">Introduction</h2>
<p id="Par42">Parkinson’s disease is a progressive neurological disorder that affects movement, gradually worsening over time. Key symptoms include resting tremors (involuntary shaking, often in the hands), bradykinesia (slowness of movement), and postural instability (poor balance and coordination), all of which impair fine motor skills and daily activities<sup><a href="#CR1" class="usa-link" aria-describedby="CR1">1</a></sup>. The main symptom of PD, a chronic and complicated neurological disorder, is movement. Although the precise origin of PD is unknown, it most likely results from a confluence of environmental variables such as pesticides, solvents, and air pollution with hereditary factors<sup><a href="#CR2" class="usa-link" aria-describedby="CR2">2</a>,<a href="#CR3" class="usa-link" aria-describedby="CR3">3</a></sup>. PD is caused by the slow degeneration of certain brain neurons that generate the neurotransmitter dopamine. Dopamine is essential for controlling coordination and movement<sup><a href="#CR4" class="usa-link" aria-describedby="CR4">4</a>–<a href="#CR6" class="usa-link" aria-describedby="CR6">6</a></sup>. PD patients have a variety of symptoms as their dopamine levels drop. The major signs of this condition are tremor, sluggish movement, rigidity of limb and volatility of body position<sup><a href="#CR7" class="usa-link" aria-describedby="CR7">7</a>,<a href="#CR8" class="usa-link" aria-describedby="CR8">8</a></sup>. The presence of such a sign could definitely influence the standard of handwriting, which is a complicated activity, which includes motor, sensory and cognitive skills. Since Parkinson’s disease severely affects fine motor control, it often causes noticeable tremors that appear as shakiness in patients’ drawings or handwriting<sup><a href="#CR9" class="usa-link" aria-describedby="CR9">9</a></sup>. As a result, analyzing these motor irregularities in handwriting or sketches serves as a valuable indicator for detecting PD and constitutes the base for diagnosis of the condition at its earliest stages when the severity of typical signs is minor<sup><a href="#CR10" class="usa-link" aria-describedby="CR10">10</a>–<a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup>. Thus, changes in handwriting can be a symptom of PD.</p>
<p id="Par43">Numerous neurodegenerative diseases that affect brain functions, like PD, have a notable impact on writing abilities<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a>–<a href="#CR14" class="usa-link" aria-describedby="CR14">14</a></sup>. People with PD have demonstrated evidence of micrography or dysgraphia that could be utilized as indicators to determine the possibility or severity of the disease<sup><a href="#CR15" class="usa-link" aria-describedby="CR15">15</a>–<a href="#CR17" class="usa-link" aria-describedby="CR17">17</a></sup>. Handwriting analysis is, therefore widely acknowledged as an efficient and reasonably priced approach to real-time Parkinson’s disease identification. Data about handwriting can be collected offline or online. The offline approach uses a scanner to record handwritten material on paper<sup><a href="#CR2" class="usa-link" aria-describedby="CR2">2</a>,<a href="#CR18" class="usa-link" aria-describedby="CR18">18</a>,<a href="#CR19" class="usa-link" aria-describedby="CR19">19</a></sup>.</p>
<p id="Par44">Using online handwriting to identify PD presents several obstacles and hurdles. The diversity of handwriting impairments is one of the main obstacles. In actuality, each person is affected by PD in various ways and the handwriting deficits that PD sufferers experience can differ greatly<sup><a href="#CR20" class="usa-link" aria-describedby="CR20">20</a>–<a href="#CR22" class="usa-link" aria-describedby="CR22">22</a></sup>. Micrographia, or excessively tiny handwriting, is a condition that certain individuals may have. Other patients may have changes in their handwriting’s speed, pressure, or fluency. It is challenging to develop reliable handwriting characteristics for PD identification because of this diversity<sup><a href="#CR2" class="usa-link" aria-describedby="CR2">2</a></sup>.</p>
<p id="Par45">A variety of diagnosis methods are required for the detection and treatment of PD, and not every healthcare facility is prepared to perform all of them. Spiral and wave diagrams are effective tools for evaluating motor skills and tremor patterns in Parkinson’s patients, offering both qualitative and quantitative insights into fine motor control<sup><a href="#CR1" class="usa-link" aria-describedby="CR1">1</a></sup>. The accessibility of diagnostic equipment and treatment processes might vary based on the level of resources and specialization of the healthcare facility. Certain medical facilities or neurology clinics may be the only ones with the specific knowledge and tools needed for some treatments, particularly aggressive ones like DBS surgery<sup><a href="#CR23" class="usa-link" aria-describedby="CR23">23</a>,<a href="#CR24" class="usa-link" aria-describedby="CR24">24</a></sup>. There is an urgent need for an efficient method that offers dependable, accurate PD detection. Such an approach would contribute to increasing the wellness and standard of patient life<sup><a href="#CR2" class="usa-link" aria-describedby="CR2">2</a></sup>.</p>
<p id="Par46">The usage of ML methods for health data has led to DSS creation that aids medical experts in accurate decision-making. Common ML methods like KNN, RF, NB and SVM are deployed for PD detection. In particular, the development of the aforementioned techniques led to create CNN-assisted CAD models for several medical applications. CNN can learn features from the provided images, which is in contrast to hand-crafted techniques<sup><a href="#CR25" class="usa-link" aria-describedby="CR25">25</a></sup>. However, they do not work well with larger datasets and struggle to handle varied data types<sup><a href="#CR26" class="usa-link" aria-describedby="CR26">26</a></sup>. With the introduction of DL techniques like CNN and DNN, the detection of PD severity became more precise. It was discovered that CNN is more accurate than existing methods<sup><a href="#CR27" class="usa-link" aria-describedby="CR27">27</a>,<a href="#CR28" class="usa-link" aria-describedby="CR28">28</a></sup>. While pooling layers in CNNs are effective for typical image recognition tasks, they can lead to the loss of fine-grained features essential for classifying spiral drawings in Parkinson’s disease. This presents a limitation in applying standard CNN architectures in medical handwriting analysis<sup><a href="#CR29" class="usa-link" aria-describedby="CR29">29</a></sup>. These drawbacks encourage the development of a novel PD detection strategy in this study. Utilizing the complementing advantages of modified WF-based preprocessing and modified PHOG-based feature extraction, appropriate patterns are substantially preserved for accurate identification. Additionally, combining the improved LinkNet and GhostNet models contributes to the robust detection of PD in contrast to the existing methods.</p>
<p id="Par47">The presented PD detection approach involves the contributions beneath.</p>
<ul class="list" style="list-style-type:disc">
<li><p id="Par48">Proposing a modified WF for preprocessing the handwriting image using the new pixel value for the original image with the noisy image and the original image with the filtered image using the proposed Gaussian filtering, which significantly reduces the noise while preserving the edges. This results in enhancing the quality of the image for effective feature extraction.</p></li>
<li><p id="Par49">Employing the modified PHOG-based feature descriptor using the improved entropy for gradient computation. This improved feature effectively captures features at different resolution levels minimizes the influences of higher frequency noise and allows the model to better detect fine-grained distortions.</p></li>
<li><p id="Par50">Proposing a new hybrid DL model that integrates the improved LinkNet and GhostNet models for detecting PD. Leverages the capturing of multi-scale context information of the improved LinkNet and the efficient feature generation of GhostNet, leading to a well-balanced model in terms of accuracy and efficiency.</p></li>
<li><p id="Par51">Employing an improved LinkNet model for detection, in which the enhancements made in its architecture specifically additional layers such as WAP-BN and the MDSCM layer. This improved architecture enhances the model’s ability to learn complex spatial and channel-wise relationships and contributes to more accurate, and robust PD detection.</p></li>
</ul>
<p id="Par52">The reviews on PD detection are specified in Section “<a href="#Sec2" class="usa-link">Literature review</a>”. The proposed PD detection is in Section “<a href="#Sec5" class="usa-link">Proposed model for Parkinson’s disease detection</a>”. Modified WF and modified features are given under Section “<a href="#Sec6" class="usa-link">Pre-processing via modified wiener filtering</a>” and Section “<a href="#Sec12" class="usa-link">Feature extraction</a>” Improved LinkNet and Ghostnet are explained in Section “<a href="#Sec18" class="usa-link">Hybrid classifiers for PD detection: Improved linknet and ghostnet</a>”. Section “<a href="#Sec21" class="usa-link">Results and discussions</a>” and Section “<a href="#Sec32" class="usa-link">Conclusions</a>” elucidated the results and conclusion.</p></section><section id="Sec2"><h2 class="pmc_sec_title">Literature review</h2>
<section id="Sec3"><h3 class="pmc_sec_title">Related works</h3>
<p id="Par53">In 2023, Naz et al<em>.</em><sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup> utilized 3 renowned PD data sets to study the issue of early PD detection using handwriting and drawing activities. The task was believed to be very challenging as there were few handwriting examples available, and the symptoms of PD might vary greatly. Various data augmentation approaches were used to increase the dataset size to accomplish better PD detection. Following that, many DCNN architectures were implemented and trained; each one’s distinct structure and layout allowed it to extract distinct prominent characteristics and aspects of the input data. Following the experimental evaluation of each CNN’s performance, the most promising feature vectors were chosen, and several early fusion techniques were used before the final classification. An ensemble of feature vectors from multiple models demonstrated significantly better generalization than a single model’s freeze vector. However, a limitation of the study is the exclusive use of the SVM classifier; despite its strong performance, other machine learning classifiers should also be explored and evaluated.</p>
<p id="Par54">An effective DL model that helped with early PD identification was proposed by Abdullah et al<em>.</em><sup><a href="#CR31" class="usa-link" aria-describedby="CR31">31</a></sup> in 2023. The suggested model made a substantial contribution by choosing the best characteristics, which resulted in excellent performance accuracy. The KNN approach was used in GA to optimize features. The suggested innovative model leads to reduced loss and increased detection accuracy. The classification using optimized features is performed with KNN, which is computationally efficient. However, the model’s heavy reliance on feature optimization could limit its scalability and potentially affect its robustness.</p>
<p id="Par55">Kamble et al<em>.</em><sup><a href="#CR32" class="usa-link" aria-describedby="CR32">32</a></sup> suggested a thorough scrutiny of the spirals formed by PD patients in 2021. For this, mathematical models were used to extract kinematic characteristics created for 25 individuals and 15 healthier ones. Using feature design and four ML classifiers, LR, C-SVC, KNN classifier, and ensemble model RF, the results showed a classification accuracy of almost 91% in distinguishing PD patients from healthy ones. Moreover, the model effectively identifies key kinematic features for early PD detection without complex processing. However, its reliance on a limited dataset and computational framework restricts its ability to support more comprehensive PD diagnosis.</p>
<p id="Par56">In 2023, Konstantin et al<em>.</em><sup><a href="#CR33" class="usa-link" aria-describedby="CR33">33</a></sup> has introduced an FC approach that consisted of 3 stages: constructing the structure, picking the useful features, and parameter optimization. It was advised to use 32 variations of the approach using various metaheuristic algorithms. To diagnose PD, experiments were carried out. The handwriting of 40 persons, including 25 PS sufferers, was included in Parkinson’s HW. The handwriting exercises involved creating meanders and spirals. The handwriting of 75 persons, including 37 PD patients, was included in PaHaW. The advantages of certain realization variations in terms of prediction accuracy and interpretability were demonstrated by statistical comparisons of efficiency with other accessible classifiers, DT, and FGS. Additionally, the incorporation of a fuzzy handwriting classifier avoids the necessity of computing resources and has faster inference processing. However, there is a need for additional ML algorithms for model deployment and monitoring.</p>
<p id="Par57">Zhu et al<em>.</em><sup><a href="#CR29" class="usa-link" aria-describedby="CR29">29</a></sup> has investigated several spiraling hand drawing characteristics of PD in 2022 and created an alternative diagnosis system based on hand drawings. First, the visual information of hand drawings accurately depicted the drawing features of individuals with PD. Second, an "Archimedes spiral hand drawing dataset" was created that was independent of the application scenario and could capture the image’s spacing, shape, and tremor features. The CC-Net was used for lowering the pooling layer. Moreover, CC-Net outperforms traditional networks in feature extraction and classification accuracy, while ensuring stable performance. However, more spiral data and multi-classification experiments across different tremor diseases are needed for further improvement.</p>
<p id="Par58">In 2024, Hossein et al<em>.</em><sup><a href="#CR26" class="usa-link" aria-describedby="CR26">26</a></sup> has created a new technique for identifying PD with UPDRS by combining fuzzy clustering and LS-SVR. PCA and feature selection were employed to address the multicollinearity problems in the data. This study demonstrated how the suggested approach enhanced prediction through thorough assessments with existing techniques. Moreover, the PCA + FCM + LS-SVR achieve maximum precision across the test sets for Total-UPDRS and Motor-UPDRS, according to comparison results with other prediction techniques. However, using machine learning optimization techniques and adaptive heuristic search algorithms is essential to further improving the approach.</p>
<p id="Par59">A general approach for diagnosing PD utilizing handwritten images and/or voice cues was developed by Yousif et al<em>.</em><sup><a href="#CR34" class="usa-link" aria-describedby="CR34">34</a></sup> in 2023. To diagnose PD, eight pre-trained CNN were used. 16 feature-extracting techniques were used to numerically extract features for the speech signals, which were then input into four distinct ML algorithms that were adjusted via the GSA. The segmentation of varying durations of speech signals was the basis for the novel feature extraction method used for the voice dataset. Finally, the outcomes of the experiments were gathered and documented. The incorporation of a novel feature extraction algorithm significantly enhanced detection performance. However, its main limitation is the lack of comprehensive datasets, as no publicly available PD dataset includes both handwriting and voice data from the same patients.</p>
<p id="Par60">To enhance PD detection and classification, Mansour et al<em>.</em><sup><a href="#CR35" class="usa-link" aria-describedby="CR35">35</a></sup> presented a novel method in 2024 called QMFOFS-HCNN. The purpose of QMFOFS-HCNN was to solve the dimensionality problem and find the best feature subsets. It combined a QMO strategy for choosing features with CNN with an A-LSTM for PD recognition and classification. The Nadam optimizer was also used to optimize the selection of hyperparameters. Experimental validation utilizing benchmark datasets gave impressive findings. These numerical results highlighted how DL greatly improved the accuracy of early PD identification. It contributes to medical diagnostics by providing an effective PD detection and classification tool. The performance assessment was carried out on benchmark datasets. Nevertheless, more validation using a wider range of datasets may be necessary to ensure the technique’s practical applicability.</p>
<p id="Par61">In 2024, Xuechao Wang et al<em>.</em><sup><a href="#CR36" class="usa-link" aria-describedby="CR36">36</a></sup> has proposed a hybrid deep learning approach that effectively combined the strengths of both LSTM and CNN for the diagnosis of Parkinson’s disease. Specifically, the LSTM component was utilized to capture time-varying features, while a CNN-based module, implemented using one-dimensional convolution, was employed to maintain low computational complexity. During data preprocessing, the forward difference algorithm was applied to extract Parkinson’s disease-related features such as resting tremor from the geometric characteristics of handwriting signals, thereby improving diagnostic accuracy with minimal processing time. Finally, the model incorporated an inference strategy that included a majority voting mechanism, resulting in highly efficient CPU inference performance. Nonetheless, a major limitation of the study lay in the small dataset size, which could potentially limit the generalizability of the findings.</p>
<p id="Par62">In 2024, Abderrazak Benchabane et al<em>.</em><sup><a href="#CR1" class="usa-link" aria-describedby="CR1">1</a></sup> introduced an innovative method for Parkinson’s disease detection utilizing deep convolutional neural networks built upon the AlexNet architecture. Their approach centered on analyzing hand-drawn images from affected or potentially affected individuals, extracting features from these drawings for classification purposes. By merging features from two distinct types of hand drawings, the detection accuracy was notably enhanced. Nevertheless, further improvements could be achieved by exploring alternative CNN architectures, incorporating additional features, and refining the ensemble techniques used in the classification process.</p></section><section id="Sec4"><h3 class="pmc_sec_title">Problem statement</h3>
<p id="Par63">PD is a progressive neurological disorder with early symptoms often reflected in handwriting. Early detection is vital, but current methods face several limitations such as limited dataset diversity, model robustness, and generalizability. For instance, Naz et al<em>.</em> (2023)<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup> used ensemble DCNNs with data augmentation but highlighted challenges due to few handwriting examples and reflected the necessity of ML classifiers. Moreover, Kamble et al<em>.</em> (2021)<sup><a href="#CR32" class="usa-link" aria-describedby="CR32">32</a></sup> extracted kinematic features from spiral drawings, yet their study was limited by sample size. Abdullah et al<em>.</em> (2023)<sup><a href="#CR31" class="usa-link" aria-describedby="CR31">31</a></sup> achieved high accuracy using genetic algorithms and KNN but noted potential scalability issues. Additionally, Konstantin et al<em>.</em> (2023)<sup><a href="#CR33" class="usa-link" aria-describedby="CR33">33</a></sup> applied fuzzy clustering and metaheuristic optimization but emphasized the need for diverse ML integration. Zhu et al<em>.</em> (2022)<sup><a href="#CR29" class="usa-link" aria-describedby="CR29">29</a></sup> and Benchabane et al<em>.</em> (2024)<sup><a href="#CR1" class="usa-link" aria-describedby="CR1">1</a></sup> used CNN-based methods, like CC-Net and AlexNet, showing high accuracy but requiring more varied data and better feature extraction methods. Yousif et al<em>.</em> (2023)<sup><a href="#CR34" class="usa-link" aria-describedby="CR34">34</a></sup> explored both handwriting and voice data but faced limitations due to the lack of datasets with both modalities from the same subjects. Mansour et al<em>.</em> (2024)<sup><a href="#CR35" class="usa-link" aria-describedby="CR35">35</a></sup> introduced QMFOFS-HCNN for feature selection and classification, yet the approach needs further validation on diverse datasets. Xuechao Wang et al<em>.</em> (2024)<sup><a href="#CR36" class="usa-link" aria-describedby="CR36">36</a></sup> proposed a hybrid CNN-LSTM model, but its effectiveness is limited by a small dataset. To overcome these limitations, this research proposes an automated PD detection method using handwriting images. The majority of the current methods face challenges with limited datasets. To address these issues, the proposed model is validated using two datasets, namely the HandPD Dataset and Meander HandPD images in the HandPD dataset. By employing augmentation techniques like rotation, translation and shearing, the dimension of datasets gets increased sufficiently, which addresses the issues of limited sample size. Specifically, the incorporation of a modified Wiener filter for pre-processing and extracts modified PHOG, deep, and shape features. A hybrid model combining Improved LinkNet and GhostNet (ILN-GNet) for final classification, which significantly enhanced the detection performance. Therefore, this proposed framework aims to deliver high detection accuracy, improved generalization, and computational efficiency, which enables the proposed system to be well-positioned for deployment in practical clinical settings, potentially supporting early diagnosis.</p></section></section><section id="Sec5"><h2 class="pmc_sec_title">Proposed model for Parkinson’s disease detection</h2>
<p id="Par64">A clinical assessment of PD is made difficult due to the absence of very accurate biomarkers. The most widely used scale for evaluating both non-motor and motor symptoms of PD is the UPDRS. This scale allows doctors to evaluate the severity of motor signs in PD patients without the requirement for specialized equipment. Another issue is that the doctor’s subjective awareness has a significant impact on how this scale is evaluated. Numerous motion capture tools, including electromyography, laser displacement, accelerometers, and sensors, are available to better measure quantified tremors. Nevertheless, with the resumption of the pandemic, a simple PD screening system suitable for iPads or mobile phones would assist early identification and earlier evaluation of suspicious persons and benefit enhanced diagnosis for the patient. Many researchers have conducted significant studies on computer-aided technology in an effort to achieve an easier and more precise diagnosis of PD. However, the accuracy of PD detection remains a question. To enhance the accuracy and efficiency of the PD detection, a novel DL-based model is proposed in this research. This approach encompasses three key stages such as preprocessing, feature extraction and PD detection phases. The overall architecture of the proposed PD detection approach is shown in Fig. <a href="#Fig1" class="usa-link">1</a>. Initially, the research begins with the preprocessing, where, the modified WF is proposed and applied to the input image to reduce noise within the image and preserve the important details for detection, leading to enhanced image quality. Subsequently, several pertinent features, including modified PHOG, Deep features and Shape features are obtained from the preprocessed image, which would offer valuable information for precise detection. Lastly, a hybrid detection model that combines the Ghostnet and Improved LinkNet models is suggested and receives the derived features as input. A more reliable and robust detection is provided by the beneficial characteristics of both models. The final detection outcomes are determined by averaging the intermediate scores from both classifiers.</p>
<figure class="fig xbox font-sm" id="Fig1"><h3 class="obj_head">Fig.1.</h3>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12371065_41598_2025_12636_Fig1_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/3b8314190210/41598_2025_12636_Fig1_HTML.jpg" loading="lazy" id="MO1" height="796" width="773" alt="Fig.1"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Overall Architecture of the PD detection model.</p></figcaption></figure><section id="Sec6"><h3 class="pmc_sec_title">Pre-processing via modified wiener filtering</h3>
<p id="Par65">Image pre-processing involves varied methods for improving the quality of digital images, and it helps to extract pertinent information before images are further examined and processed by ML algorithms. Here, we take into consideration the input handwriting image <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq1"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/ad52f5717ed7/d33e704.gif" loading="lazy" id="d33e704" alt="Inline graphic"></span> that has undergone pre-processing using the modified WF method.</p>
<section id="Sec7"><h4 class="pmc_sec_title">Conventional WF method:</h4>
<ol class="list" style="list-style-type:decimal">
<li><p id="Par67">Calculate the PSD of noise and the original image, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq2"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/ad52f5717ed7/d33e720.gif" loading="lazy" id="d33e720" alt="Inline graphic"></span>.</p></li>
<li><p id="Par68">A mask is applied to the noise image pixel.</p></li>
<li><p id="Par69">Determine local variance <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq3"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/982d21c8365c/d33e736.gif" loading="lazy" id="d33e736" alt="Inline graphic"></span> and mean <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq4"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/90f7659f422f/d33e742.gif" loading="lazy" id="d33e742" alt="Inline graphic"></span>.</p></li>
<li><p id="Par70">Compute the new pixel value using noise power and variance, and mean.</p></li>
<li><p id="Par71">The steps 2 to 4 are repeated for all noise image pixels.</p></li>
</ol>
<p id="Par72">Although WF reduces random noise in images, it poses certain limits. If noise PSD is erroneously computed, the existing WF might over-smooth the image or fail to eliminate the noise adequately.</p>
<p id="Par73">While lessening the noise, it might smooth out significant details, which results in a loss of image information. Therefore, to overcome these issues, a modified WF is introduced in this work. Specifically, the incorporation of the new pixel computation for the original image with noise image and the original image with the filtered image using the proposed Gaussian filter helps to preserve the multiplicative relationships in pixel intensity values, which often better represent natural textures and subtle handwriting variations. Also, this combination not only reduces noise within the image but also significantly enhances the image quality for subsequent feature extraction processes.</p></section><section id="Sec8"><h4 class="pmc_sec_title">Modified WF method:</h4>
<p id="Par74">The modified WF comprises two steps for computing the new pixel value.</p>
<ol class="list" style="list-style-type:lower-alpha">
<li><p id="Par75">Original image with noise image.</p></li>
<li><p id="Par76">Original image with filtered image.</p></li>
</ol>
<section id="Sec9"><h5 class="pmc_sec_title">Original image with noise image:</h5>
<p id="Par77">1. Calculate the PSD of noise and the original image, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq5"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/ad52f5717ed7/d33e782.gif" loading="lazy" id="d33e782" alt="Inline graphic"></span>.</p>
<p id="Par78">2. A mask is applied to the noise image pixel.</p>
<p id="Par79">3. Arrange the intensity of all pixels that fall under the mask.</p>
<p id="Par80">4. Compute the median and allot it to the middle pixel of the mask.</p>
<p id="Par81">5. Compute local variance <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq6"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/982d21c8365c/d33e796.gif" loading="lazy" id="d33e796" alt="Inline graphic"></span> and mean <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq7"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/90f7659f422f/d33e802.gif" loading="lazy" id="d33e802" alt="Inline graphic"></span>. The mean is computed based on the geometric mean as revealed in Eq. (<a href="#Equ1" class="usa-link">1</a>), here, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq8"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/3a27c7db809d/d33e811.gif" loading="lazy" id="d33e811" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq9"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/e68298343484/d33e817.gif" loading="lazy" id="d33e817" alt="Inline graphic"></span> signifies the row and column of image <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq10"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/ad52f5717ed7/d33e824.gif" loading="lazy" id="d33e824" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq11"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/10c81be4a07d/d33e830.gif" loading="lazy" id="d33e830" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq12"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/c4ddf470d238/d33e836.gif" loading="lazy" id="d33e836" alt="Inline graphic"></span> signifies the count of the row and column. The variance is computed as revealed in Eq. (<a href="#Equ2" class="usa-link">2</a>).</p>
<table class="disp-formula p" id="Equ1"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/a412c7a23509/d33e845.gif" loading="lazy" id="d33e845" alt="graphic file with name d33e845.gif"></td>
<td class="label">1</td>
</tr></table>
<table class="disp-formula p" id="Equ2"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/b8935d7be404/d33e851.gif" loading="lazy" id="d33e851" alt="graphic file with name d33e851.gif"></td>
<td class="label">2</td>
</tr></table></section><section id="Sec10"><h5 class="pmc_sec_title">Original image with filtered image:</h5>
<p id="Par82">1. Enhance the brightness of the original handwriting image <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq13"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/ad52f5717ed7/d33e861.gif" loading="lazy" id="d33e861" alt="Inline graphic"></span>.</p>
<p id="Par83">2. An improved Gaussian filter is applied. The conventional Gaussian filter is formulated as in Eq. (<a href="#Equ3" class="usa-link">3</a>), where, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq14"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/906e271ec85e/d33e872.gif" loading="lazy" id="d33e872" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq15"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/0a33f142b04d/d33e878.gif" loading="lazy" id="d33e878" alt="Inline graphic"></span> refers to pixels.</p>
<table class="disp-formula p" id="Equ3"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/4aeb4626ffa3/d33e884.gif" loading="lazy" id="d33e884" alt="graphic file with name d33e884.gif"></td>
<td class="label">3</td>
</tr></table>
<p id="Par84">The proposed Gaussian filter is formulated as in Eq. (<a href="#Equ4" class="usa-link">4</a>).</p>
<table class="disp-formula p" id="Equ4"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/80b074b7f88a/d33e895.gif" loading="lazy" id="d33e895" alt="graphic file with name d33e895.gif"></td>
<td class="label">4</td>
</tr></table>
<p id="Par85">3. Evaluate the median <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq16"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/c3c546b9c6aa/d33e903.gif" loading="lazy" id="d33e903" alt="Inline graphic"></span> and variance <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq17"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/982d21c8365c/d33e909.gif" loading="lazy" id="d33e909" alt="Inline graphic"></span> and mean <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq18"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/90f7659f422f/d33e915.gif" loading="lazy" id="d33e915" alt="Inline graphic"></span> for the filtered image.</p>
<p id="Par86">4. Evaluate the novel value <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq19"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/48ba1cb4ae80/d33e923.gif" loading="lazy" id="d33e923" alt="Inline graphic"></span> of pixel for the original image with the filtered image and noisy image as shown in Eq. (<a href="#Equ5" class="usa-link">5</a>). Here, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq20"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/08a3cd99b60c/d33e932.gif" loading="lazy" id="d33e932" alt="Inline graphic"></span> signifies noise variance.</p>
<table class="disp-formula p" id="Equ5"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/3c6b07b40069/d33e938.gif" loading="lazy" id="d33e938" alt="graphic file with name d33e938.gif"></td>
<td class="label">5</td>
</tr></table>
<p id="Par87">5. The steps of the original with noise and the original with filtered image are repeated for all noise image pixels.</p>
<p id="Par88">The pre-processed image is indicated by <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq21"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/9e98bbea7327/d33e948.gif" loading="lazy" id="d33e948" alt="Inline graphic"></span>.</p>
<p id="Par89">Thus, the modified WF is capable of removing the noise, whereas the edges are preserved. In addition, the modified WF reduces the distortions. The modified WF could conserve edges and significant details and effectively lessen the noise.</p></section></section></section><section id="Sec11"><h3 class="pmc_sec_title">Feature extraction</h3>
<p id="Par90">In image processing, feature extraction is crucial. Digital images can have factors like motion, shapes, or edges that are detected during feature extraction. Following their identification, the data may be processed to carry out several image analysis tasks. The distinctive features listed below are obtained from this study:</p>
<ul class="list" style="list-style-type:disc">
<li><p id="Par91">Modified PHOG features</p></li>
<li><p id="Par92">Shape features</p></li>
<li><p id="Par93">Deep features (VGG 16 and ResNet)</p></li>
</ul>
<p id="Par94">The combination of modified PHOG features, shape features, and deep features from VGG16 and ResNet creates a comprehensive, multi-layered feature set that significantly improves the accuracy of PD detection. The modified PHOG features capture information across different spatial resolutions, enhancing gradient calculations by reducing the impact of high-frequency noise and emphasizing significant gradient variations. Meanwhile, the shape features provide crucial global geometric insights, that are key for distinguishing PD-related handwriting abnormalities. The deep features extracted from VGG16 and ResNet offer robust hierarchical representations, enabling the model to detect intricate and abstract patterns. Together, these diverse and complementary features enhance the model’s ability to detect PD with greater precision and ensure more reliable detection.</p>
<section id="Sec12"><h4 class="pmc_sec_title">Modified PHOG features</h4>
<p id="Par95">The PHOG model<sup><a href="#CR37" class="usa-link" aria-describedby="CR37">37</a></sup> splits the image, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq22"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/9e98bbea7327/d33e980.gif" loading="lazy" id="d33e980" alt="Inline graphic"></span> at various resolutions to districts depending upon spatial pyramid matching. The doubling of divisions in the axis direction is repeated by splitting <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq23"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/9e98bbea7327/d33e986.gif" loading="lazy" id="d33e986" alt="Inline graphic"></span> into fine spatial grids. In PHOG, the derivative mask is deployed in the vertical and horizontal directions of <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq24"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/9e98bbea7327/d33e992.gif" loading="lazy" id="d33e992" alt="Inline graphic"></span> to calculate the gradient. Especially, this model requires gray level image filtering for kernels like, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq25"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/5f4dabc35201/d33e998.gif" loading="lazy" id="d33e998" alt="Inline graphic"></span> and the derivatives of <em>X</em> and <em>Y</em> are achieved with convolution operations namely <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq26"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/589388871c4a/d33e1011.gif" loading="lazy" id="d33e1011" alt="Inline graphic"></span>. The orientation and magnitude of the gradient are assessed as in Eq. (<a href="#Equ6" class="usa-link">6</a>) and (<a href="#Equ7" class="usa-link">7</a>).</p>
<table class="disp-formula p" id="Equ6"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/6031f8f1e77c/d33e1023.gif" loading="lazy" id="d33e1023" alt="graphic file with name d33e1023.gif"></td>
<td class="label">6</td>
</tr></table>
<table class="disp-formula p" id="Equ7"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/214ce745257a/d33e1030.gif" loading="lazy" id="d33e1030" alt="graphic file with name d33e1030.gif"></td>
<td class="label">7</td>
</tr></table>
<p id="Par96">While traditional PHOG features are good at explaining the image’s spatial information, they primarily focus on local gradient details and are unable to effectively capture global context details without additional features. Also, the conventional PHOG is based solely on gradient orientation and magnitude, which makes it highly sensitive to noise and artifacts. This leads to poor capturing of non-linear distortions, as it assumes relatively stable gradient behavior. In order to address these shortcomings, a modified PHOG feature is proposed based on the incorporation of improved entropy in the gradient operation, which allows for focusing on high-information regions. Additionally, the modified PHOG is more resilient to noise and slight distortions, ensuring clearer and more trustworthy feature maps and improving the precision of PD identification.</p>
<p id="Par97"><strong>Modified PHOG:</strong> As per modified PHOG, the gradient operation is modelled depending upon improved entropy as shown in Eq. (<a href="#Equ8" class="usa-link">8</a>) and (<a href="#Equ9" class="usa-link">9</a>).</p>
<table class="disp-formula p" id="Equ8"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/a5a68c55f091/d33e1048.gif" loading="lazy" id="d33e1048" alt="graphic file with name d33e1048.gif"></td>
<td class="label">8</td>
</tr></table>
<table class="disp-formula p" id="Equ9"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/88a7246d9b6b/d33e1054.gif" loading="lazy" id="d33e1054" alt="graphic file with name d33e1054.gif"></td>
<td class="label">9</td>
</tr></table>
<p id="Par98">1. Computation of improved entropy for each gradient image:</p>
<ul class="list" style="list-style-type:disc">
<li><p id="Par99">Evaluate the improved entropy of the horizontal gradient image <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq27"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/f6238745caaa/d33e1066.gif" loading="lazy" id="d33e1066" alt="Inline graphic"></span>.</p></li>
<li><p id="Par100">Evaluate the improved entropy of the vertical gradient image <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq28"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/05052a307d5b/d33e1075.gif" loading="lazy" id="d33e1075" alt="Inline graphic"></span>.</p></li>
</ul>
<p id="Par101">The conventional Shannon entropy is given in Eq. (<a href="#Equ10" class="usa-link">10</a>).</p>
<table class="disp-formula p" id="Equ10"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/102a228ab248/d33e1086.gif" loading="lazy" id="d33e1086" alt="graphic file with name d33e1086.gif"></td>
<td class="label">10</td>
</tr></table>
<p id="Par102">The improved Shannon entropy used in modified PHOG for gradient computation is given in Eq. (<a href="#Equ11" class="usa-link">11</a>). In Eq. (<a href="#Equ11" class="usa-link">11</a>), <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq29"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/a0b60aa263bb/d33e1100.gif" loading="lazy" id="d33e1100" alt="Inline graphic"></span> signifies the cardinality of the focal component <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq30"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/665ac1c299c3/d33e1106.gif" loading="lazy" id="d33e1106" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq31"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/cab6347f1d8d/d33e1112.gif" loading="lazy" id="d33e1112" alt="Inline graphic"></span> signifies the FOD.</p>
<table class="disp-formula p" id="Equ11"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/d16001fad664/d33e1119.gif" loading="lazy" id="d33e1119" alt="graphic file with name d33e1119.gif"></td>
<td class="label">11</td>
</tr></table>
<p id="Par103">2. Comparing the improved entropy values:</p>
<ul class="list" style="list-style-type:disc">
<li><p id="Par104">After evaluating the improved entropy of <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq32"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/f6238745caaa/d33e1131.gif" loading="lazy" id="d33e1131" alt="Inline graphic"></span>, the threshold should be set as the mean of entropy.</p></li>
<li><p id="Par105">Higher entropy in <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq33"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/f6238745caaa/d33e1140.gif" loading="lazy" id="d33e1140" alt="Inline graphic"></span> denotes a high difference in the horizontal edge, while higher entropy in <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq34"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/05052a307d5b/d33e1146.gif" loading="lazy" id="d33e1146" alt="Inline graphic"></span> denotes a high difference in the vertical edge. If entropy is similar in both gradients, it denotes that edge info is distributed evenly in both orientations.</p></li>
<li><p id="Par106">Select the high entropy value that sums with <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq35"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/f6238745caaa/d33e1155.gif" loading="lazy" id="d33e1155" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq36"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/05052a307d5b/d33e1161.gif" loading="lazy" id="d33e1161" alt="Inline graphic"></span>. Here, the gradient entropy quantifies how much difference persists in every gradient image.</p></li>
<li><p id="Par107">Now, by summing the higher entropy value to the gradient mean, the gradient containing the more directional info can be enhanced.</p></li>
</ul>
<p id="Par108">The modified PHOG features denoted by <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq37"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/bb9d70654593/d33e1172.gif" loading="lazy" id="d33e1172" alt="Inline graphic"></span> captivates features at varied spatial resolution levels. It further improves the accuracy of gradient computation by lessening the influence of higher-frequency noise and highlighting remarkable gradient disparities. Thus, compared to existing PHOG, the modified PHOG features aid in gathering fine details needed for PD detection.</p></section><section id="Sec13"><h4 class="pmc_sec_title">Shape features</h4>
<p id="Par109">Shape features <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq38"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/4b2dd2d788b9/d33e1182.gif" loading="lazy" id="d33e1182" alt="Inline graphic"></span><sup><a href="#CR38" class="usa-link" aria-describedby="CR38">38</a></sup><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq39"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/c43c231d33d0/d33e1190.gif" loading="lazy" id="d33e1190" alt="Inline graphic"></span> are extracted in this proposed work to improve the understanding of object geometry in the image, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq40"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/9e98bbea7327/d33e1196.gif" loading="lazy" id="d33e1196" alt="Inline graphic"></span>. Features like area, epsilon, hull and perimeter are specifically taken into account. Epsilon assesses the shape’s intricacies and imperfections to determine how closely a component’s shape resembles its usual form. The perimeter establishes the overall length of the border, while the area determines the item’s size. The convex hull provides the lowest convex border that may surround the shape. When combined, these form elements are essential for image evaluation and retrieval because they enable accurate object comparison and characterisation based on geometric aspects.</p></section><section id="Sec14"><h4 class="pmc_sec_title">Deep features</h4>
<p id="Par110">Deep features <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq41"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/8fd9cd851b65/d33e1206.gif" loading="lazy" id="d33e1206" alt="Inline graphic"></span> are obtained from <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq42"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/9e98bbea7327/d33e1212.gif" loading="lazy" id="d33e1212" alt="Inline graphic"></span> by applying the ResNet and VGG 16 models, are considered in the suggested study for PD identification.</p>
<p id="Par111"><strong><em>ResNet:</em></strong> The ResNet model incorporates residual connections that allow the network to go deeper without suffering from the vanishing gradient problem. This enables ResNet to capture more complex and abstract visual representations by learning deeper hierarchical features for precise detection. Convolutional, pooling, normalizing, and FCL are all included in the ResNet-50 model<sup><a href="#CR39" class="usa-link" aria-describedby="CR39">39</a></sup>. By obtaining residual functions that allow the network to gather a wide range of attributes from input images, including both specific low-level and high-level data, residual blocks facilitate optimization. Features are extracted using convolutional layers, filtered using residual blocks, the spatial extent is reduced using max pooling, and non-linearity is addressed using ReLU. These specific attributes are then used by the final FCL to categorize the image.</p>
<p id="Par112"><strong><em>VGG 16:</em></strong> It<sup><a href="#CR40" class="usa-link" aria-describedby="CR40">40</a></sup> is a DCNN architecture noted for its simplicity and efficacy in image classification. VGG16 is known for its deep, uniform architecture, this design enables the model to learn hierarchical features at multiple levels, from basic edges and textures at lower layers to complex, high-level patterns at deeper layers. This characteristic allows the model to capture both fine details crucial for accurate detection. Its architecture comprises 16 weight layers: 13 con layers and 3 FCL grouped into five conv blocks. To enable VGG-16 to acquire hierarchical features from simple edges to intricate patterns, each block reduces spatial dimensions by using max pooling and raises the filter count from 64 to 512. To capture micro features, the network uses tiny 3 × 3 filters in conv layers. In VGG16, the input moves via a sequence of conv layers and max pooling layers. The flattened feature maps are categorized by FCLs, and the learning process is enhanced by the non-linearity added by the ReLU activation.</p>
<p id="Par113">The final feature <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq43"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/37bdc80f6cae/d33e1236.gif" loading="lazy" id="d33e1236" alt="Inline graphic"></span> is an inclusive grouping of modified PHOG, deep features and shape features. This varied set of features permits robust detection by capturing thorough information from several aspects of <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq44"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/9e98bbea7327/d33e1242.gif" loading="lazy" id="d33e1242" alt="Inline graphic"></span>.</p></section></section><section id="Sec15"><h3 class="pmc_sec_title">Hybrid classifiers for PD detection: Improved LinkNet and Ghostnet</h3>
<p id="Par114">The features <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq45"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/0793a80e9314/d33e1252.gif" loading="lazy" id="d33e1252" alt="Inline graphic"></span> are subjected to hybrid classifiers such as improved LinkNet and GhostNet for identifying the PD. Rather than the application of single classifiers, the application of hybrid classifiers will result in better outcomes. Integrating the improved LinkNet and GhostNet models in the proposed ILN-GNet framework offers a powerful synergy that enhances the accuracy, efficiency, and robustness of PD detection. The improved LinkNet excels in detailed spatial feature extraction and multi-scale context learning through its advanced encoder-decoder structure, and modules like MDSCM and WAP-BN, making it highly effective at capturing subtle handwriting variations. On the other hand, GhostNet contributes lightweight, high-efficiency feature extraction by generating more feature maps through simple linear operations, significantly reducing computational complexity without sacrificing performance. Combining the improved LinkNet with GhostNet models offers an efficient and compact representation of learning, and effectively distinguishing PD-affected handwriting. The performance of improved LinkNet and GhostNet is examined using “HandPD Dataset<sup><a href="#CR41" class="usa-link" aria-describedby="CR41">41</a></sup> and Meander HandPD images in the HandPD dataset<sup><a href="#CR42" class="usa-link" aria-describedby="CR42">42</a></sup>”. The HandPD Dataset detects the individual as “healthy or patient”.</p>
<section id="Sec16"><h4 class="pmc_sec_title">GhostNet</h4>
<p id="Par115">The features <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq46"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/c6d8eafafdc3/d33e1270.gif" loading="lazy" id="d33e1270" alt="Inline graphic"></span> are subjected to the GNet architecture for the detection of PD. However, the traditional deep models may provide high accuracy but often come with large numbers of parameters and heavy computational demands. In contrast, the GhostNet model strikes a balance by maintaining competitive accuracy while drastically reducing computational costs. Hence this model has been employed in this research for detection. GNet<sup><a href="#CR43" class="usa-link" aria-describedby="CR43">43</a></sup> comprises a novel Ghost module that uses low-cost operations to produce additional feature maps. This novel NN efficiently generates more feature maps with fewer variables and computations. The implementation of this module consists of two parts. Using a conventional convolutional computation, GNet first generates feature maps with fewer channels. Next, it uses a straightforward procedure to generate more feature maps. Finally, it combines several feature maps to produce a new output. The GBM in GNet is separated into two categories based on stride. Two Ghost modules make up the GBM design when stride = 1, which is described using conventional residuals. To add more channels, the initial module serves as an extension layer. In order to link the outputs and inputs of these two Ghost modules, the second module first decreases the number of channels to match the shortest path. When stride = 2, the GBM has the conventional bottleneck structure’s layout, and when stride = 1, it keeps its structural features. The ReLU nonactivation operation and BN are used by the subsequent layers following the second Ghost module. The final result from GNet is displayed as <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq47"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/8a26733cd5e0/d33e1280.gif" loading="lazy" id="d33e1280" alt="Inline graphic"></span>.</p></section><section id="Sec17"><h4 class="pmc_sec_title">Improved LinkNet</h4>
<p id="Par116">The features <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq48"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/c6d8eafafdc3/d33e1290.gif" loading="lazy" id="d33e1290" alt="Inline graphic"></span> are employed in the LinkNet classifier for PD detection. 3 encoder and decoder components make up the LinkNet architecture<sup><a href="#CR44" class="usa-link" aria-describedby="CR44">44</a></sup>. They both often carry out ReLu activations, BNs, and convolution. While the BN helps to standardize training and attain a high rate of convergence, the Conv layer is utilized to detect spatial patterns. The normalized output is then sent into the Leaky ReLU for training the complex features and the average pooling layer to reduce the spatial dimensions. Similarly, encoder block 2 applies Conv, BN, average pooling, and mix pooling layers to encoder block 1 to enhance the accuracy of PD detection. The results of encoder block 2 are then sent to encoder block 3, which includes a conv layer and BN.</p>
<p id="Par117">Even while ordinary LinkNet generates fine-detected outputs, the recurrent striding and pooling techniques utilized in LinkNet lower feature resolution. This makes it possible that some information will be lost. Therefore, to prevail over such problems, we introduce an improved LinkNet model for PD detection. Thereby, an improved LinkNet architecture is proposed with varied modifications in its structure. The proposed LinkNet architecture includes extra layers such as mixed pooling, average pooling, encoder 1 followed by conv, BN, Leaky ReLU, encoder 2 followed by conv, BN, ELU, encoder 3 followed by conv, BN, swish, decoder 1, 2 and 3 followed by WAP-BN layers. Particularly, the MDSCM layer is included in the improved LinkNet architecture. This improved architecture enables the model to learn complex, non-linear handwriting patterns more effectively. The use of mixed and average pooling improves feature preservation by balancing edge detection and texture retention, while the decoder stages incorporate WAP-BN to enhance reconstruction accuracy and training stability. Notably, the integration of the MDSCM allows efficient multi-scale feature extraction with reduced computational cost, making the model both lightweight and powerful. Overall, these structural improvements enhance the model’s ability to capture subtle variations in handwriting, leading to more accurate and robust PD detection.</p>
<p id="Par118"><strong>MDSCM layer:</strong> The MDSCM layer includes 3 Gabor filters, 3 conv layers with strides 3 × 3, 5 × 5 and 7 × 7, 3 BN layers and 3 encoders. Each Gabor filter output is connected to the Conv layer with each stride. The output from the conv layer is passed as input to the BN layer. The output from the BN layer and each encoder block is XOR-ed, and the outputs are concatenated to get the final output. The MDSCM architecture is shown in Fig. <a href="#Fig2" class="usa-link">2</a>.</p>
<figure class="fig xbox font-sm" id="Fig2"><h5 class="obj_head">Fig.2.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12371065_41598_2025_12636_Fig2_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/aa59de857626/41598_2025_12636_Fig2_HTML.jpg" loading="lazy" id="MO2" height="742" width="775" alt="Fig.2"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Architecture of Suggested MDSCM module.</p></figcaption></figure><p id="Par119"><strong>Proposed WAP-BN computation:</strong> The conventional BN is modelled as in Eq. (<a href="#Equ12" class="usa-link">12</a>), where, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq49"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/6b5f5ae7b14a/d33e1323.gif" loading="lazy" id="d33e1323" alt="Inline graphic"></span> denotes the decoder output,<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq50"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/4cc6318c8e99/d33e1329.gif" loading="lazy" id="d33e1329" alt="Inline graphic"></span> represent the mean value of <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq51"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/6b5f5ae7b14a/d33e1335.gif" loading="lazy" id="d33e1335" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq52"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/b2bc129adef3/d33e1341.gif" loading="lazy" id="d33e1341" alt="Inline graphic"></span> refers to a constant deployed for numerical constancy.</p>
<table class="disp-formula p" id="Equ12"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/8639d87c09f3/d33e1348.gif" loading="lazy" id="d33e1348" alt="graphic file with name d33e1348.gif"></td>
<td class="label">12</td>
</tr></table>
<p id="Par120">However, for better stabilization of parameters, instead of the existing BN, we propose weighted average pooling-based BN in the modified LinkNet design.</p>
<p id="Par121">The proposed WAP-BN is modelled as in Eq. (<a href="#Equ13" class="usa-link">13</a>), where, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq53"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/e9823be851c1/d33e1361.gif" loading="lazy" id="d33e1361" alt="Inline graphic"></span> signifies weighted average pooling<sup><a href="#CR45" class="usa-link" aria-describedby="CR45">45</a></sup> that is formulated as given in Eq. (<a href="#Equ14" class="usa-link">14</a>).</p>
<table class="disp-formula p" id="Equ13"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/29959f2a3e5d/d33e1374.gif" loading="lazy" id="d33e1374" alt="graphic file with name d33e1374.gif"></td>
<td class="label">13</td>
</tr></table>
<table class="disp-formula p" id="Equ14"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/6443bd42c13a/d33e1380.gif" loading="lazy" id="d33e1380" alt="graphic file with name d33e1380.gif"></td>
<td class="label">14</td>
</tr></table>
<p id="Par122">In Eq. (<a href="#Equ14" class="usa-link">14</a>), <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq54"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/020274b3a072/d33e1391.gif" loading="lazy" id="d33e1391" alt="Inline graphic"></span> is set as 1, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq55"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/65008bc80c37/d33e1397.gif" loading="lazy" id="d33e1397" alt="Inline graphic"></span> refers to a parameter, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq56"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/5b7cd53ba371/d33e1403.gif" loading="lazy" id="d33e1403" alt="Inline graphic"></span> refers to the feature value at the position <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq57"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/a086866e2160/d33e1409.gif" loading="lazy" id="d33e1409" alt="Inline graphic"></span> inside the pooling area <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq58"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/9b25dbee9ccc/d33e1416.gif" loading="lazy" id="d33e1416" alt="Inline graphic"></span>.</p>
<p id="Par123">The improved LinkNet model is highly useful for utilizing global data at different scales. When compared to the current LinkNet model, the modifications made to the upgraded LinkNet model reduce processing costs and preserve aggregate multi-scale context information. Additionally, improved LinkNet speeds up training and makes the procedure much more efficient. Figure <a href="#Fig3" class="usa-link">3</a> shows an architecture of the improved LinkNet.</p>
<figure class="fig xbox font-sm" id="Fig3"><h5 class="obj_head">Fig.3.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12371065_41598_2025_12636_Fig3_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/a04197a0addc/41598_2025_12636_Fig3_HTML.jpg" loading="lazy" id="MO3" height="843" width="742" alt="Fig.3"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Proposed improved LinkNet Architecture.</p></figcaption></figure><p id="Par124">The final improved link output is signified by <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq59"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/0b2babb4d10a/d33e1436.gif" loading="lazy" id="d33e1436" alt="Inline graphic"></span>.</p>
<p id="Par125">The outcomes from improved LinkNet <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq60"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/ab064ae3fb3f/d33e1444.gif" loading="lazy" id="d33e1444" alt="Inline graphic"></span> and GhostNet <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq61"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/366ead9128ef/d33e1450.gif" loading="lazy" id="d33e1450" alt="Inline graphic"></span> are subjected to mean and final PD-detected outcomes are attained as “healthy or patient”.</p></section></section></section><section id="Sec18"><h2 class="pmc_sec_title">Results and discussion</h2>
<section id="Sec19"><h3 class="pmc_sec_title">Simulation procedure</h3>
<p id="Par126">The ILN-GNet model developed for PD detection was implemented using Python. Additionally, to run the simulation, we employed a system that had a 11th Gen Intel(R) Core (TM) i5-1135g7 CPU operating at 2.40 GHz and 2.42 GHz and 16.0 GB (15.7 GB usable) of RAM. An × 64-based CPU running a 64-bit operating system was the system type. The valuation was done for ILN-GNet over LinkNet, GhostNet, GoogleNet, AlexNet<sup><a href="#CR1" class="usa-link" aria-describedby="CR1">1</a></sup>, EfficientNet, CNN<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup>, Ensemble<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup>, LSTM-CNN<sup><a href="#CR36" class="usa-link" aria-describedby="CR36">36</a></sup> and XGBoost<sup><a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup>. The study data was attained using HandPD Dataset (dataset 1)<sup><a href="#CR41" class="usa-link" aria-describedby="CR41">41</a></sup> and Meander_HandPD images in HandPD dataset (dataset 2)<sup><a href="#CR42" class="usa-link" aria-describedby="CR42">42</a></sup>.</p></section><section id="Sec20"><h3 class="pmc_sec_title">Dataset description</h3>
<section id="Sec21"><h4 class="pmc_sec_title">HandPD dataset (dataset 1)</h4>
<p id="Par127">The HandPD dataset consists of handwritten tests from two groups of people: the (i) Healthy Group and the (ii) Patient Group, which is made up of people with Parkinson’s disease (PD). Of the 92 participants in the sample, 74 are patients (patients group) and 18 are healthy (Healthy group). A synopsis of each group can be found below:</p>
<p id="Par128">Healthy Group: There were six men and twelve women, representing ages 19 to 79 (average age: 44.22 ± 16.53 years). Two of those people are left-handed, and sixteen are right-handed.</p>
<p id="Par129">The patient group consisted of 15 females and 59 males, aged 38 to 78 (average age: 58.75 ± 7.51 years). Of those people, 69 are right-handed and 5 are left-handed. Consequently, the entire dataset consists of 736 images labeled in two groups: 72 images in the healthy group and 296 images in the patient group. This results in a dataset including 368 images from each drawing, such as meanders and spirals. After the application of augmentation techniques such as rotation, translation and shearing, the total number of images was increased to 1240, which were distributed into the healthy group has 648 images and the patient group has 592 images. The images are labeled as follows: ID_EXAM-ID_IMAGE.jpg, in which ID_EXAM stands for the exam’s identifier, and ID_IMAGE denotes the number of the image of that exam”.</p></section><section id="Sec22"><h4 class="pmc_sec_title">Meander_HandPD images in HandPD dataset (dataset 2)</h4>
<p id="Par130">Handwritten samples from two groups such as a Healthy Group and a Patient Group, consisting of people with PD diagnoses make up the HandPD dataset. These samples of handwriting were acquired at São Paulo State University’s Botucatu Medical School in Brazil. Participants were instructed to complete a form containing four spiral patterns and four meander patterns. These sections were later cropped from the forms and saved as individual JPEG images. The dataset contained 368 images, categorized into two classes: MeanderControl (72 images), and MeanderPatients (296 images). To expand the dataset, data augmentation techniques (rotation, translation and shearing) were applied, increasing the total number of images to 1,240. Post-augmentation, the distribution included 648 images for MeanderControl and 592 images for MeanderPatients. The samples of handwriting images for PD detection for Dataset 1 and Dataset 2 are shown in Fig. <a href="#Fig4" class="usa-link">4</a> and Fig. <a href="#Fig5" class="usa-link">5</a> respectively.</p>
<figure class="fig xbox font-sm" id="Fig4"><h5 class="obj_head">Fig.4.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12371065_41598_2025_12636_Fig4_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/e5cf939410a0/41598_2025_12636_Fig4_HTML.jpg" loading="lazy" id="MO4" height="263" width="753" alt="Fig.4"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Sample for PD detection using handwriting images for dataset 1 (<strong>a</strong>) sample 1 (<strong>b</strong>) sample 2 and (<strong>c</strong>) sample 3.</p></figcaption></figure><figure class="fig xbox font-sm" id="Fig5"><h5 class="obj_head">Fig.5.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12371065_41598_2025_12636_Fig5_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/13ed98b08884/41598_2025_12636_Fig5_HTML.jpg" loading="lazy" id="MO5" height="242" width="730" alt="Fig.5"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig5/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Sample for PD detection using handwriting images for dataset 2 (<strong>a</strong>) sample 1 (<strong>b</strong>) sample 2 and (<strong>c</strong>) sample 3.</p></figcaption></figure></section></section><section id="Sec23"><h3 class="pmc_sec_title">Pre-processing analysis</h3>
<p id="Par131">The study of the modified WF used to pre-process the handwriting images using Dataset 1 and Dataset 2. For accurate detection, the handwriting images utilized for PD detection should have a high resolution. The visual representation of the conventional WF, Gaussian filter, median filters, modified WF for datasets 1 and 2 are illustrated in Fig. <a href="#Fig6" class="usa-link">6</a> and Fig. <a href="#Fig7" class="usa-link">7</a> respectively.</p>
<figure class="fig xbox font-sm" id="Fig6"><h4 class="obj_head">Fig.6.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12371065_41598_2025_12636_Fig6_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/e9afb5c82d02/41598_2025_12636_Fig6_HTML.jpg" loading="lazy" id="MO6" height="851" width="716" alt="Fig.6"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig6/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Sample for PD detection using handwriting images (<strong>a</strong>) Original image (<strong>b</strong>) Traditional wiener filter (<strong>c</strong>) Gaussian filter (<strong>d</strong>) Median filter and (<strong>e</strong>) Improved Wiener filter for dataset 1.</p></figcaption></figure><figure class="fig xbox font-sm" id="Fig7"><h4 class="obj_head">Fig.7.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12371065_41598_2025_12636_Fig7_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/f9a3936168e0/41598_2025_12636_Fig7_HTML.jpg" loading="lazy" id="MO7" height="824" width="712" alt="Fig.7"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig7/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Sample for PD detection using handwriting images (<strong>a</strong>) Original image (<strong>b</strong>) Traditional wiener filter (<strong>c</strong>) Gaussian filter (<strong>d</strong>) Median filter and (<strong>e</strong>) Improved Wiener filter for dataset 2.</p></figcaption></figure><p id="Par132">Table <a href="#Tab1" class="usa-link">1</a><strong>.</strong> illustrates the preprocessing analysis in terms of PSNR and SSIM metrics regarding datasets 1 and 2. After preprocessing, PSNR is frequently used to assess an image’s quality. Greater PSNR values show that there is reduced noise and distortion from the filter, bringing the processed image closer to the original. SSIM, on the other hand, takes into account structural details like texture, contrast, and brightness when determining an image’s perceived quality. The model successfully maintains the structural details when the SSIM value is high. The model can detect the PD more precisely when higher PSNR and SSIM are achieved. The PSNR and SSIM attained using modified WF are high, around 32.97 and 0.946, respectively. On the other hand, extant WF, Gaussian and median filters attain lower PSNR and SSIM values. Using dataset 2, the Improved Wiener filter achieved a greater value on PSNR, about 33.450, meanwhile Conventional Wiener filter = 30.540, the Gaussian filter = 23.640 and the Median filter = 26.480. Additionally, the Improved Wiener filter acquired better values on SSIM, about 0.957, in contrast to the traditional methods. Therefore, the enhancements carried out in the improved WF offer high PSNR and SSIM, which translate directly into better input quality for the hybrid ILN-GNet model. As a result, the ILN-GNet model can more effectively distinguish between healthy and PD-affected individuals, leading to improved detection accuracy.</p>
<section class="tw xbox font-sm" id="Tab1"><h4 class="obj_head">Table 1.</h4>
<div class="caption p"><p>Pre-processing Analysis for Datasets 1 and 2.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead>
<tr>
<th align="left" colspan="3" rowspan="1">Dataset 1</th>
<th align="left" colspan="3" rowspan="1">Dataset 2</th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1">Methods</th>
<th align="left" colspan="1" rowspan="1">PSNR (dB)</th>
<th align="left" colspan="1" rowspan="1">SSIM</th>
<th align="left" colspan="1" rowspan="1">Methods</th>
<th align="left" colspan="1" rowspan="1">PSNR (dB)</th>
<th align="left" colspan="1" rowspan="1">SSIM</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Traditional Wiener filter</td>
<td align="center" colspan="1" rowspan="1">29.560</td>
<td align="center" colspan="1" rowspan="1">0.906</td>
<td align="left" colspan="1" rowspan="1">Conventional Wiener filter</td>
<td align="center" colspan="1" rowspan="1">30.540</td>
<td align="center" colspan="1" rowspan="1">0.917</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Gaussian filter</td>
<td align="center" colspan="1" rowspan="1">25.120</td>
<td align="center" colspan="1" rowspan="1">0.857</td>
<td align="left" colspan="1" rowspan="1">Gaussian filter</td>
<td align="center" colspan="1" rowspan="1">23.640</td>
<td align="center" colspan="1" rowspan="1">0.826</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Median filter</td>
<td align="center" colspan="1" rowspan="1">27.860</td>
<td align="center" colspan="1" rowspan="1">0.876</td>
<td align="left" colspan="1" rowspan="1">Median filter</td>
<td align="center" colspan="1" rowspan="1">26.480</td>
<td align="center" colspan="1" rowspan="1">0.857</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Improved Wiener filter</td>
<td align="center" colspan="1" rowspan="1">32.970</td>
<td align="center" colspan="1" rowspan="1">0.946</td>
<td align="left" colspan="1" rowspan="1">Improved Wiener filter</td>
<td align="center" colspan="1" rowspan="1">33.450</td>
<td align="center" colspan="1" rowspan="1">0.957</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="Sec24"><h3 class="pmc_sec_title">Performance analysis</h3>
<p id="Par133">Figures <a href="#Fig8" class="usa-link">8</a>, <a href="#Fig9" class="usa-link">9</a>, and <a href="#Fig10" class="usa-link">10</a> illustrates the performance comparison of ILN-GNet over the conventional method using dataset 1. As per the outcomes, ILN-GNet for PD detection attains better precision than LinkNet, GhostNet, GoogleNet, AlexNet, EfficientNet, CNN<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup>, Ensemble<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup>, LSTM-CNN<sup><a href="#CR36" class="usa-link" aria-describedby="CR36">36</a></sup> and XGBoost<sup><a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup>. The ILN-GNet model achieved a higher precision of 0.99 at TD = 90%, where LinkNet, GhostNet, GoogleNet, AlexNet, EfficientNet, CNN<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup>, Ensemble<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup>, LSTM-CNN<sup><a href="#CR36" class="usa-link" aria-describedby="CR36">36</a></sup> and XGBoost<sup><a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup> got minimal precision values. Here, hybrid classifiers such as improved LinkNet and GhostNet are used for identifying the PD. Several modifications to structures are suggested for the improved LinkNet architecture. The improved LinkNet model includes the MDSCM layer in particular. Furthermore, rather than using BN layers, the decoder uses WAP-BN layers. Comparing the improved LinkNet model to the conventional, the modifications made reduce processing costs and preserve aggregate multi-scale context information. The negative measure, FDR using ILN-GNet for PD detection is less than 0.02, while LinkNet, GhostNet, GoogleNet, AlexNet, EfficientNet, CNN<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup>, Ensemble<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup>, LSTM-CNN<sup><a href="#CR36" class="usa-link" aria-describedby="CR36">36</a></sup> and XGBoost<sup><a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup> attain high FDR values. Likewise, the neutral and positive metrics using ILN-GNet for PD detection are high, while, negative metrics using ILN-GNet attain low values. Therefore, faster training and more process effectiveness are achieved by the combination of improved LinkNet and Ghostnet.</p>
<figure class="fig xbox font-sm" id="Fig8"><h4 class="obj_head">Fig.8.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12371065_41598_2025_12636_Fig8_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/e5a25713bd26/41598_2025_12636_Fig8_HTML.jpg" loading="lazy" id="MO8" height="639" width="757" alt="Fig.8"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig8/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Performance of PD detection with handwriting images using ILN-GNet over traditional method on (<strong>a</strong>) Precision, (<strong>b</strong>) Sensitivity, (<strong>c</strong>) Accuracy, (<strong>d</strong>) Specificity using dataset 1.</p></figcaption></figure><figure class="fig xbox font-sm" id="Fig9"><h4 class="obj_head">Fig.9.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12371065_41598_2025_12636_Fig9_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/1bb36eb057db/41598_2025_12636_Fig9_HTML.jpg" loading="lazy" id="MO9" height="642" width="740" alt="Fig.9"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig9/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Performance of PD detection with handwriting images using ILN-GNet over traditional method on (<strong>a</strong>) F measure, (<strong>b</strong>) MCC, (<strong>c</strong>) NPV for dataset 1.</p></figcaption></figure><figure class="fig xbox font-sm" id="Fig10"><h4 class="obj_head">Fig.10.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12371065_41598_2025_12636_Fig10_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/9547d3158fb1/41598_2025_12636_Fig10_HTML.jpg" loading="lazy" id="MO10" height="623" width="746" alt="Fig.10"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig10/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Performance of PD detection with handwriting images using ILN-GNet over traditional method on (<strong>a</strong>) FNR, (<strong>b</strong>) FDR and (<strong>c</strong>) FPR for dataset 1.</p></figcaption></figure><p id="Par134">Additionally, the performance comparison of the proposed ILN-GNet model over the existing methods such as LinkNet, GhostNet, GoogleNet, AlexNet, EfficientNet, CNN<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup>, Ensemble<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup>, LSTM-CNN<sup><a href="#CR36" class="usa-link" aria-describedby="CR36">36</a></sup> and XGBoost<sup><a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup> using dataset 2 is shown in Fig. <a href="#Fig11" class="usa-link">11</a>, Fig. <a href="#Fig12" class="usa-link">12</a> and Fig. <a href="#Fig13" class="usa-link">13</a>, respectively. The proposed ILN-GNet model achieved a greater specificity of 0.974 at 80% of training data, which surpasses the results of the traditional methods such as the LinkNet (0.0.950), GhostNet (0.847), GoogleNet (0.853), AlexNet (0.873), EfficientNet (0.804), CNN<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup> (0.849), Ensemble<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup> (0.762), LSTM-CNN<sup><a href="#CR36" class="usa-link" aria-describedby="CR36">36</a></sup> (0.861) and XGBoost<sup><a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup> (0.752). Moreover, the suggested ILN-GNet model scored minimal ratings of FNR and FPR across different splits of training data, demonstrating a lower probability of misclassification. Additionally, the suggested ILN-GNet model acquired greater values on F-measure and MCC about 0.961 and 0.974 respectively, in contrast, the existing methods offer lower values on these measures. Therefore, improvements over the conventional methods are largely due to the preprocessing method based on the modified WF, feature extraction based on the modified PHOG, and the integration of the improved LinkNet and GhostNet architecture.</p>
<figure class="fig xbox font-sm" id="Fig11"><h4 class="obj_head">Fig.11.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12371065_41598_2025_12636_Fig11_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/2410246b969d/41598_2025_12636_Fig11_HTML.jpg" loading="lazy" id="MO11" height="611" width="737" alt="Fig.11"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig11/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Performance of PD detection with handwriting images using ILN-GNet over traditional method on (<strong>a</strong>) Precision, (<strong>b</strong>) Sensitivity, (<strong>c</strong>) Accuracy, (<strong>d</strong>) Specificity for dataset 2.</p></figcaption></figure><figure class="fig xbox font-sm" id="Fig12"><h4 class="obj_head">Fig.12.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12371065_41598_2025_12636_Fig12_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/0fa646ca73c1/41598_2025_12636_Fig12_HTML.jpg" loading="lazy" id="MO12" height="644" width="754" alt="Fig.12"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig12/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Performance of PD detection with handwriting images using ILN-GNet over traditional method on (<strong>a</strong>) F measure, (<strong>b</strong>) MCC, (<strong>c</strong>) NPV for dataset 2.</p></figcaption></figure><figure class="fig xbox font-sm" id="Fig13"><h4 class="obj_head">Fig.13.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12371065_41598_2025_12636_Fig13_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/d67fdbfa84ee/41598_2025_12636_Fig13_HTML.jpg" loading="lazy" id="MO13" height="629" width="752" alt="Fig.13"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig13/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Performance of PD detection with handwriting images using ILN-GNet over traditional method for (<strong>a</strong>) FNR, (<strong>b</strong>) FDR and (<strong>c</strong>) FPR for dataset 2.</p></figcaption></figure></section><section id="Sec25"><h3 class="pmc_sec_title">Ablation analysis</h3>
<p id="Par135">The ablation study employing ILN-GNet for PD identification for datasets 1 and 2, respectively, is displayed in Tables <a href="#Tab2" class="usa-link">2</a> and <a href="#Tab3" class="usa-link">3</a>. The performance of ILN-GNet is examined over ILN-GNet with conventional LinkNet, ILN-GNet with conventional LinkNet and Ghostnet, ILN-GNet with conventional PHOG, ILN-GNet with conventional WF, ILN-GNet without feature extraction, Model without MDSCM and Model without WAP-BN. In Table <a href="#Tab2" class="usa-link">2</a>, ILN-GNet shows a high accuracy of 0.964, while ILN-GNet with standard LinkNet is 0.931, ILN-GNet with conventional LinkNet and Ghostnet is 0.952, ILN-GNet with standard PHOG is 0.903, ILN-GNet with conventional WF is 0.863, ILN-GNet without extraction of feature is 0.923, Model without MDSCM is 0.893 and Model without WAP-BN is 0.908, displays less accuracy values on dataset 1. In contrast to conventional WF, the modified WF preserves the edges while effectively removing the noise. The enhanced PHOG characteristics aid in gathering the precise details needed for PD identification by increasing the accuracy of gradient magnitude estimation and lessening the effect of higher-frequency noise. Additionally, the changes made to the enhanced LinkNet reduced computation costs and captured aggregate multi-scale context information as compared to the original LinkNet. Particularly, the FDR using ILN-GNet is less than 0.035, while ILN-GNet with conventional LinkNet, ILN-GNet with conventional LinkNet and Ghostnet, ILN-GNet with conventional PHOG, ILN-GNet with conventional WF, ILN-GNet without feature extraction, Model without MDSCM and Model without WAP-BN scores less FDR values.</p>
<section class="tw xbox font-sm" id="Tab2"><h4 class="obj_head">Table 2.</h4>
<div class="caption p"><p>Ablation study on ILN-GNet for PD Detection using Dataset 1.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Metrics</th>
<th align="left" colspan="1" rowspan="1">ILN-GNet</th>
<th align="left" colspan="1" rowspan="1">Model with conventional LinkNet</th>
<th align="left" colspan="1" rowspan="1">Model with conventional LinkNet and Ghostnet</th>
<th align="left" colspan="1" rowspan="1">Model with conventional PHOG</th>
<th align="left" colspan="1" rowspan="1">Model with conventional WF</th>
<th align="left" colspan="1" rowspan="1">Model without Feature Extraction</th>
<th align="left" colspan="1" rowspan="1">Model without MDSCM</th>
<th align="left" colspan="1" rowspan="1">Model without WAP-BN</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Accuracy</td>
<td align="center" colspan="1" rowspan="1">96.40%</td>
<td align="center" colspan="1" rowspan="1">93.10%</td>
<td align="center" colspan="1" rowspan="1">95.20%</td>
<td align="center" colspan="1" rowspan="1">90.30%</td>
<td align="center" colspan="1" rowspan="1">86.30%</td>
<td align="center" colspan="1" rowspan="1">92.30%</td>
<td align="center" colspan="1" rowspan="1">89.30%</td>
<td align="center" colspan="1" rowspan="1">90.80%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Sensitivity</td>
<td align="center" colspan="1" rowspan="1">95.70%</td>
<td align="center" colspan="1" rowspan="1">92.20%</td>
<td align="center" colspan="1" rowspan="1">95.70%</td>
<td align="center" colspan="1" rowspan="1">89.60%</td>
<td align="center" colspan="1" rowspan="1">84.30%</td>
<td align="center" colspan="1" rowspan="1">93.90%</td>
<td align="center" colspan="1" rowspan="1">89.10%</td>
<td align="center" colspan="1" rowspan="1">91.50%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Specificity</td>
<td align="center" colspan="1" rowspan="1">97.00%</td>
<td align="center" colspan="1" rowspan="1">94.00%</td>
<td align="center" colspan="1" rowspan="1">94.70%</td>
<td align="center" colspan="1" rowspan="1">91.00%</td>
<td align="center" colspan="1" rowspan="1">88.00%</td>
<td align="center" colspan="1" rowspan="1">91.00%</td>
<td align="center" colspan="1" rowspan="1">89.50%</td>
<td align="center" colspan="1" rowspan="1">90.20%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Precision</td>
<td align="center" colspan="1" rowspan="1">96.50%</td>
<td align="center" colspan="1" rowspan="1">93.00%</td>
<td align="center" colspan="1" rowspan="1">94.00%</td>
<td align="center" colspan="1" rowspan="1">89.60%</td>
<td align="center" colspan="1" rowspan="1">85.80%</td>
<td align="center" colspan="1" rowspan="1">90.00%</td>
<td align="center" colspan="1" rowspan="1">87.90%</td>
<td align="center" colspan="1" rowspan="1">89.00%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">F-measure</td>
<td align="center" colspan="1" rowspan="1">96.10%</td>
<td align="center" colspan="1" rowspan="1">92.60%</td>
<td align="center" colspan="1" rowspan="1">94.80%</td>
<td align="center" colspan="1" rowspan="1">89.60%</td>
<td align="center" colspan="1" rowspan="1">85.10%</td>
<td align="center" colspan="1" rowspan="1">91.90%</td>
<td align="center" colspan="1" rowspan="1">88.50%</td>
<td align="center" colspan="1" rowspan="1">90.20%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">MCC</td>
<td align="center" colspan="1" rowspan="1">92.70%</td>
<td align="center" colspan="1" rowspan="1">86.20%</td>
<td align="center" colspan="1" rowspan="1">90.30%</td>
<td align="center" colspan="1" rowspan="1">80.50%</td>
<td align="center" colspan="1" rowspan="1">72.40%</td>
<td align="center" colspan="1" rowspan="1">84.70%</td>
<td align="center" colspan="1" rowspan="1">78.60%</td>
<td align="center" colspan="1" rowspan="1">81.60%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">NPV</td>
<td align="center" colspan="1" rowspan="1">96.30%</td>
<td align="center" colspan="1" rowspan="1">93.30%</td>
<td align="center" colspan="1" rowspan="1">96.20%</td>
<td align="center" colspan="1" rowspan="1">91.00%</td>
<td align="center" colspan="1" rowspan="1">86.70%</td>
<td align="center" colspan="1" rowspan="1">94.50%</td>
<td align="center" colspan="1" rowspan="1">90.60%</td>
<td align="center" colspan="1" rowspan="1">92.60%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">FPR</td>
<td align="center" colspan="1" rowspan="1">3.00%</td>
<td align="center" colspan="1" rowspan="1">6.00%</td>
<td align="center" colspan="1" rowspan="1">5.30%</td>
<td align="center" colspan="1" rowspan="1">9.00%</td>
<td align="center" colspan="1" rowspan="1">12.00%</td>
<td align="center" colspan="1" rowspan="1">9.00%</td>
<td align="center" colspan="1" rowspan="1">10.50%</td>
<td align="center" colspan="1" rowspan="1">9.80%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">FNR</td>
<td align="center" colspan="1" rowspan="1">4.30%</td>
<td align="center" colspan="1" rowspan="1">7.80%</td>
<td align="center" colspan="1" rowspan="1">4.30%</td>
<td align="center" colspan="1" rowspan="1">10.40%</td>
<td align="center" colspan="1" rowspan="1">15.70%</td>
<td align="center" colspan="1" rowspan="1">6.10%</td>
<td align="center" colspan="1" rowspan="1">10.90%</td>
<td align="center" colspan="1" rowspan="1">8.50%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">FDR</td>
<td align="center" colspan="1" rowspan="1">3.50%</td>
<td align="center" colspan="1" rowspan="1">7.00%</td>
<td align="center" colspan="1" rowspan="1">6.00%</td>
<td align="center" colspan="1" rowspan="1">10.40%</td>
<td align="center" colspan="1" rowspan="1">14.20%</td>
<td align="center" colspan="1" rowspan="1">10.00%</td>
<td align="center" colspan="1" rowspan="1">12.10%</td>
<td align="center" colspan="1" rowspan="1">11.00%</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><section class="tw xbox font-sm" id="Tab3"><h4 class="obj_head">Table 3.</h4>
<div class="caption p"><p>Ablation study on ILN-GNet for PD Detection using Dataset 2.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Metrics</th>
<th align="left" colspan="1" rowspan="1">ILN-GNet</th>
<th align="left" colspan="1" rowspan="1">Model with conventional LinkNet</th>
<th align="left" colspan="1" rowspan="1">Model with conventional LinkNet and Ghostnet</th>
<th align="left" colspan="1" rowspan="1">Model with conventional PHOG</th>
<th align="left" colspan="1" rowspan="1">Model with conventional WF</th>
<th align="left" colspan="1" rowspan="1">Model without Feature Extraction</th>
<th align="left" colspan="1" rowspan="1">Model without MDSCM</th>
<th align="left" colspan="1" rowspan="1">Model without WAP-BN</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Accuracy</td>
<td align="center" colspan="1" rowspan="1">95.20%</td>
<td align="center" colspan="1" rowspan="1">92.30%</td>
<td align="center" colspan="1" rowspan="1">94.40%</td>
<td align="center" colspan="1" rowspan="1">89.10%</td>
<td align="center" colspan="1" rowspan="1">85.10%</td>
<td align="center" colspan="1" rowspan="1">91.10%</td>
<td align="center" colspan="1" rowspan="1">88.10%</td>
<td align="center" colspan="1" rowspan="1">89.60%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Sensitivity</td>
<td align="center" colspan="1" rowspan="1">97.40%</td>
<td align="center" colspan="1" rowspan="1">94.80%</td>
<td align="center" colspan="1" rowspan="1">94.80%</td>
<td align="center" colspan="1" rowspan="1">89.60%</td>
<td align="center" colspan="1" rowspan="1">87.80%</td>
<td align="center" colspan="1" rowspan="1">90.40%</td>
<td align="center" colspan="1" rowspan="1">89.10%</td>
<td align="center" colspan="1" rowspan="1">89.80%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Specificity</td>
<td align="center" colspan="1" rowspan="1">93.20%</td>
<td align="center" colspan="1" rowspan="1">90.20%</td>
<td align="center" colspan="1" rowspan="1">94.00%</td>
<td align="center" colspan="1" rowspan="1">88.70%</td>
<td align="center" colspan="1" rowspan="1">82.70%</td>
<td align="center" colspan="1" rowspan="1">91.70%</td>
<td align="center" colspan="1" rowspan="1">87.20%</td>
<td align="center" colspan="1" rowspan="1">89.50%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Precision</td>
<td align="center" colspan="1" rowspan="1">92.60%</td>
<td align="center" colspan="1" rowspan="1">89.30%</td>
<td align="center" colspan="1" rowspan="1">93.20%</td>
<td align="center" colspan="1" rowspan="1">87.30%</td>
<td align="center" colspan="1" rowspan="1">81.50%</td>
<td align="center" colspan="1" rowspan="1">90.40%</td>
<td align="center" colspan="1" rowspan="1">85.90%</td>
<td align="center" colspan="1" rowspan="1">88.20%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">F-measure</td>
<td align="center" colspan="1" rowspan="1">94.90%</td>
<td align="center" colspan="1" rowspan="1">92.00%</td>
<td align="center" colspan="1" rowspan="1">94.00%</td>
<td align="center" colspan="1" rowspan="1">88.40%</td>
<td align="center" colspan="1" rowspan="1">84.50%</td>
<td align="center" colspan="1" rowspan="1">90.40%</td>
<td align="center" colspan="1" rowspan="1">87.50%</td>
<td align="center" colspan="1" rowspan="1">89.00%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">MCC</td>
<td align="center" colspan="1" rowspan="1">90.40%</td>
<td align="center" colspan="1" rowspan="1">84.80%</td>
<td align="center" colspan="1" rowspan="1">88.70%</td>
<td align="center" colspan="1" rowspan="1">78.20%</td>
<td align="center" colspan="1" rowspan="1">70.40%</td>
<td align="center" colspan="1" rowspan="1">82.20%</td>
<td align="center" colspan="1" rowspan="1">76.30%</td>
<td align="center" colspan="1" rowspan="1">79.20%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">NPV</td>
<td align="center" colspan="1" rowspan="1">97.60%</td>
<td align="center" colspan="1" rowspan="1">95.20%</td>
<td align="center" colspan="1" rowspan="1">95.40%</td>
<td align="center" colspan="1" rowspan="1">90.80%</td>
<td align="center" colspan="1" rowspan="1">88.70%</td>
<td align="center" colspan="1" rowspan="1">91.70%</td>
<td align="center" colspan="1" rowspan="1">90.20%</td>
<td align="center" colspan="1" rowspan="1">91.00%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">FPR</td>
<td align="center" colspan="1" rowspan="1">6.80%</td>
<td align="center" colspan="1" rowspan="1">9.80%</td>
<td align="center" colspan="1" rowspan="1">6.00%</td>
<td align="center" colspan="1" rowspan="1">11.30%</td>
<td align="center" colspan="1" rowspan="1">17.30%</td>
<td align="center" colspan="1" rowspan="1">8.30%</td>
<td align="center" colspan="1" rowspan="1">12.80%</td>
<td align="center" colspan="1" rowspan="1">10.50%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">FNR</td>
<td align="center" colspan="1" rowspan="1">2.60%</td>
<td align="center" colspan="1" rowspan="1">5.20%</td>
<td align="center" colspan="1" rowspan="1">5.20%</td>
<td align="center" colspan="1" rowspan="1">10.40%</td>
<td align="center" colspan="1" rowspan="1">12.20%</td>
<td align="center" colspan="1" rowspan="1">9.60%</td>
<td align="center" colspan="1" rowspan="1">10.90%</td>
<td align="center" colspan="1" rowspan="1">10.20%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">FDR</td>
<td align="center" colspan="1" rowspan="1">7.40%</td>
<td align="center" colspan="1" rowspan="1">10.70%</td>
<td align="center" colspan="1" rowspan="1">6.80%</td>
<td align="center" colspan="1" rowspan="1">12.70%</td>
<td align="center" colspan="1" rowspan="1">18.60%</td>
<td align="center" colspan="1" rowspan="1">9.60%</td>
<td align="center" colspan="1" rowspan="1">14.10%</td>
<td align="center" colspan="1" rowspan="1">11.80%</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p id="Par136">On observing results in Table <a href="#Tab3" class="usa-link">3</a>, the suggested ILN-GNet model’s sensitivity for Dataset 2 is 0.974, which is higher than that of the models with Standard LinkNet (0.948), with Standard LinkNet and GhostNet (0.948), with Standard PHOG (0.896), with Standard WF (0.878), without feature extraction (0.904), with MDSCM (0.891), and with WAP-BN (0.898). With an accuracy of 0.952, the ILN-GNet model has a strong overall detection capability. Notably, the absence of Modified PHOG and Modified WF results in significant accuracy drops to 0.891 and 0.851, respectively. Similarly, the removal of MDSCM and WAP-BN modules causes consistent declines across all performance metrics, emphasizing their importance in enhancing feature representation and classification robustness. These findings underscore the critical role of the Modified Wiener Filter, Modified PHOG-based features, and the enhanced LinkNet architecture incorporating MDSCM and WAP-BN layers in achieving improved detection performance for Parkinson’s Disease.</p></section><section id="Sec26"><h3 class="pmc_sec_title">Statistical analysis</h3>
<p id="Par137">Tables <a href="#Tab4" class="usa-link">4</a> and <a href="#Tab5" class="usa-link">5</a> detail the statistical analysis in terms of accuracy utilizing ILN-GNet-based PD detection for datasets 1 and 2 respectively. The study displays the improvement of ILN-GNet over LinkNet, GhostNet, GoogleNet, AlexNet, EfficientNet, CNN<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup>, Ensemble<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup>, LSTM-CNN<sup><a href="#CR36" class="usa-link" aria-describedby="CR36">36</a></sup> and XGBoost<sup><a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup>. For detecting PD, this work employs improved LinkNet and GhostNet classifiers. Utilizing global information at different scales is greatly aided by the enhanced LinkNet architecture that has been suggested with several structural changes. Furthermore, the improved LinkNet accelerates training and greatly improves operational efficiency. In Table <a href="#Tab4" class="usa-link">4</a>, the ILN-GNet reached a higher accuracy of 0.984 for the maximum statistical metric, whereas, LinkNet, GhostNet, GoogleNet, AlexNet, EfficientNet, CNN<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup>, Ensemble<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup>, LSTM-CNN<sup><a href="#CR36" class="usa-link" aria-describedby="CR36">36</a></sup> and XGBoost<sup><a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup> reach lesser accuracies of 0.952, 0.863, 0.903, 0.927, 0.806, 0.871, 0.847, 0.944 and 0.855 respectively. Similarly, a high accuracy of 0.950 is gained for the mean case by ILN-GNet, while LinkNet, GhostNet, GoogleNet, AlexNet, EfficientNet, CNN<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup> and Ensemble<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup> attain lower accuracies. The suggested ILN-GNet model outperformed the existing methods, such as XGBoost (0.760), LSTM-CNN (0.861), LinkNet (0.911), GhostNet (0.821), GoogleNet (0.861), AlexNet (0.880), EfficientNet (0.760), CNN (0.831), and Ensemble model (0.800), as shown by the results in Table <a href="#Tab5" class="usa-link">5</a> for dataset 2. Additionally, when compared to traditional methods, ILN-GNet demonstrated improved classification accuracy with a maximum efficiency value of 0.976. These results demonstrate that the enhancements introduced namely the modified Wiener Filter for preprocessing, modified PHOG-based feature extraction, and the hybrid integration of improved LinkNet with GhostNet collectively contribute to the significant improvement in detection accuracy over traditional methods.</p>
<section class="tw xbox font-sm" id="Tab4"><h4 class="obj_head">Table 4.</h4>
<div class="caption p"><p>Statistical study of PD detection with handwriting images using ILN-GNet over traditional methods for dataset 1.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Methods</th>
<th align="left" colspan="1" rowspan="1">Mean</th>
<th align="left" colspan="1" rowspan="1">Minimum</th>
<th align="left" colspan="1" rowspan="1">Median</th>
<th align="left" colspan="1" rowspan="1">SD</th>
<th align="left" colspan="1" rowspan="1">Maximum</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">XGBoost</td>
<td align="center" colspan="1" rowspan="1">0.824</td>
<td align="center" colspan="1" rowspan="1">0.796</td>
<td align="center" colspan="1" rowspan="1">0.823</td>
<td align="center" colspan="1" rowspan="1">0.024</td>
<td align="center" colspan="1" rowspan="1">0.855</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">LSTM-CNN</td>
<td align="center" colspan="1" rowspan="1">0.912</td>
<td align="center" colspan="1" rowspan="1">0.883</td>
<td align="center" colspan="1" rowspan="1">0.911</td>
<td align="center" colspan="1" rowspan="1">0.024</td>
<td align="center" colspan="1" rowspan="1">0.944</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">LinkNet</td>
<td align="center" colspan="1" rowspan="1">0.919</td>
<td align="center" colspan="1" rowspan="1">0.891</td>
<td align="center" colspan="1" rowspan="1">0.916</td>
<td align="center" colspan="1" rowspan="1">0.024</td>
<td align="center" colspan="1" rowspan="1">0.952</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GhostNet</td>
<td align="center" colspan="1" rowspan="1">0.829</td>
<td align="center" colspan="1" rowspan="1">0.800</td>
<td align="center" colspan="1" rowspan="1">0.827</td>
<td align="center" colspan="1" rowspan="1">0.025</td>
<td align="center" colspan="1" rowspan="1">0.863</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GoogleNet</td>
<td align="center" colspan="1" rowspan="1">0.870</td>
<td align="center" colspan="1" rowspan="1">0.841</td>
<td align="center" colspan="1" rowspan="1">0.868</td>
<td align="center" colspan="1" rowspan="1">0.025</td>
<td align="center" colspan="1" rowspan="1">0.903</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">AlexNet</td>
<td align="center" colspan="1" rowspan="1">0.891</td>
<td align="center" colspan="1" rowspan="1">0.861</td>
<td align="center" colspan="1" rowspan="1">0.887</td>
<td align="center" colspan="1" rowspan="1">0.026</td>
<td align="center" colspan="1" rowspan="1">0.927</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">EfficientNet</td>
<td align="center" colspan="1" rowspan="1">0.770</td>
<td align="center" colspan="1" rowspan="1">0.742</td>
<td align="center" colspan="1" rowspan="1">0.766</td>
<td align="center" colspan="1" rowspan="1">0.026</td>
<td align="center" colspan="1" rowspan="1">0.806</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">CNN</td>
<td align="center" colspan="1" rowspan="1">0.839</td>
<td align="center" colspan="1" rowspan="1">0.810</td>
<td align="center" colspan="1" rowspan="1">0.837</td>
<td align="center" colspan="1" rowspan="1">0.024</td>
<td align="center" colspan="1" rowspan="1">0.871</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Ensemble</td>
<td align="center" colspan="1" rowspan="1">0.810</td>
<td align="center" colspan="1" rowspan="1">0.780</td>
<td align="center" colspan="1" rowspan="1">0.806</td>
<td align="center" colspan="1" rowspan="1">0.026</td>
<td align="center" colspan="1" rowspan="1">0.847</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">PROP</td>
<td align="center" colspan="1" rowspan="1">0.950</td>
<td align="center" colspan="1" rowspan="1">0.921</td>
<td align="center" colspan="1" rowspan="1">0.947</td>
<td align="center" colspan="1" rowspan="1">0.025</td>
<td align="center" colspan="1" rowspan="1">0.984</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><section class="tw xbox font-sm" id="Tab5"><h4 class="obj_head">Table 5.</h4>
<div class="caption p"><p>Statistical study of PD detection with handwriting images using ILN-GNet over traditional methods for dataset 2.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Methods</th>
<th align="left" colspan="1" rowspan="1">Mean</th>
<th align="left" colspan="1" rowspan="1">Minimum</th>
<th align="left" colspan="1" rowspan="1">Median</th>
<th align="left" colspan="1" rowspan="1">Std-Dev</th>
<th align="left" colspan="1" rowspan="1">Maximum</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">XGBoost</td>
<td align="center" colspan="1" rowspan="1">0.760</td>
<td align="center" colspan="1" rowspan="1">0.732</td>
<td align="center" colspan="1" rowspan="1">0.759</td>
<td align="center" colspan="1" rowspan="1">0.022</td>
<td align="center" colspan="1" rowspan="1">0.790</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">LSTM-CNN</td>
<td align="center" colspan="1" rowspan="1">0.861</td>
<td align="center" colspan="1" rowspan="1">0.831</td>
<td align="center" colspan="1" rowspan="1">0.859</td>
<td align="center" colspan="1" rowspan="1">0.024</td>
<td align="center" colspan="1" rowspan="1">0.895</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">LinkNet</td>
<td align="center" colspan="1" rowspan="1">0.911</td>
<td align="center" colspan="1" rowspan="1">0.881</td>
<td align="center" colspan="1" rowspan="1">0.909</td>
<td align="center" colspan="1" rowspan="1">0.024</td>
<td align="center" colspan="1" rowspan="1">0.944</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GhostNet</td>
<td align="center" colspan="1" rowspan="1">0.821</td>
<td align="center" colspan="1" rowspan="1">0.790</td>
<td align="center" colspan="1" rowspan="1">0.819</td>
<td align="center" colspan="1" rowspan="1">0.024</td>
<td align="center" colspan="1" rowspan="1">0.855</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GoogleNet</td>
<td align="center" colspan="1" rowspan="1">0.861</td>
<td align="center" colspan="1" rowspan="1">0.831</td>
<td align="center" colspan="1" rowspan="1">0.859</td>
<td align="center" colspan="1" rowspan="1">0.024</td>
<td align="center" colspan="1" rowspan="1">0.895</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">AlexNet</td>
<td align="center" colspan="1" rowspan="1">0.880</td>
<td align="center" colspan="1" rowspan="1">0.851</td>
<td align="center" colspan="1" rowspan="1">0.878</td>
<td align="center" colspan="1" rowspan="1">0.023</td>
<td align="center" colspan="1" rowspan="1">0.911</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">EfficientNet</td>
<td align="center" colspan="1" rowspan="1">0.760</td>
<td align="center" colspan="1" rowspan="1">0.732</td>
<td align="center" colspan="1" rowspan="1">0.759</td>
<td align="center" colspan="1" rowspan="1">0.022</td>
<td align="center" colspan="1" rowspan="1">0.790</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">CNN</td>
<td align="center" colspan="1" rowspan="1">0.831</td>
<td align="center" colspan="1" rowspan="1">0.800</td>
<td align="center" colspan="1" rowspan="1">0.830</td>
<td align="center" colspan="1" rowspan="1">0.024</td>
<td align="center" colspan="1" rowspan="1">0.863</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Ensemble</td>
<td align="center" colspan="1" rowspan="1">0.800</td>
<td align="center" colspan="1" rowspan="1">0.770</td>
<td align="center" colspan="1" rowspan="1">0.799</td>
<td align="center" colspan="1" rowspan="1">0.023</td>
<td align="center" colspan="1" rowspan="1">0.831</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">ILN-GNet</td>
<td align="center" colspan="1" rowspan="1">0.942</td>
<td align="center" colspan="1" rowspan="1">0.911</td>
<td align="center" colspan="1" rowspan="1">0.940</td>
<td align="center" colspan="1" rowspan="1">0.024</td>
<td align="center" colspan="1" rowspan="1">0.976</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab5/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="Sec27"><h3 class="pmc_sec_title">ROC analysis</h3>
<p id="Par138">Figure <a href="#Fig14" class="usa-link">14</a> and Fig. <a href="#Fig15" class="usa-link">15</a> express the ROC analysis for varied TD, such as 60, 70, 80 and 90 using datasets 1 and 2 respectively. It is observed that for all TDs, the proposed ILN-GNet attains high TPR values when compared to others. Particularly, the proposed ILN-GNet attains a high TPR of 1.0 for all TDs when FPR is 1.0 for dataset 1. The AUC values for the proposed ILN-GNet are 0.92, 0.93, 0.96 and 0.98 for TDs 60, 70, 80 and 90, respectively. Thus, the ROC plot shows the performance of the proposed ILN-GNet over LinkNet, GhostNet, GoogleNet, AlexNet, EfficientNet, CNN<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup>, Ensemble<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup>, LSTM-CNN<sup><a href="#CR36" class="usa-link" aria-describedby="CR36">36</a></sup> and XGBoost<sup><a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup> models with high TPR values. For dataset 2, at 70% of training data, the ILN-GNet model scored better values on TPR about 0.96 and FNR about 0.1. The AUC value of the ILN-GNet method is 0.98. the findings show that the suggested ILN-GNet model scored higher TPR demonstrating fewer false negatives and lower FPR scores, suggesting that the model contributes to minimal misclassified cases. These results demonstrate the suggested ILN-GNet model precisely classified the healthy and patients in contrast to the existing methods.</p>
<figure class="fig xbox font-sm" id="Fig14"><h4 class="obj_head">Fig.14.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12371065_41598_2025_12636_Fig14_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/690525e0eda0/41598_2025_12636_Fig14_HTML.jpg" loading="lazy" id="MO14" height="581" width="756" alt="Fig.14"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig14/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>ROC analysis for TD (<strong>a</strong>) 60%, (<strong>b</strong>) 70%, (<strong>c</strong>) 80% and (<strong>d</strong>) 90% for dataset 1.</p></figcaption></figure><figure class="fig xbox font-sm" id="Fig15"><h4 class="obj_head">Fig.15.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12371065_41598_2025_12636_Fig15_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/35daf73ff85e/41598_2025_12636_Fig15_HTML.jpg" loading="lazy" id="MO15" height="578" width="754" alt="Fig.15"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig15/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>ROC analysis for TD (<strong>a</strong>) 60%, (<strong>b</strong>) 70%, (<strong>c</strong>) 80% and (<strong>d</strong>) 90% for dataset 2.</p></figcaption></figure></section><section id="Sec28"><h3 class="pmc_sec_title">Confusion matrix</h3>
<p id="Par139">The confusion matrix given in Fig. <a href="#Fig16" class="usa-link">16</a> aids in evaluating the classification efficiency of the DL model for datasets 1 and 2. It distinguishes the predicted output by DL from the actual targeted values. The confusion matrix contains the values of TP, FP, FN and TN. Using the proposed ILN-GNet for PD detection at 80% TD exhibits TP = 129, FP = 5, FN = 4 and TN = 110, respectively. This indicates that five healthy individuals’ handwriting was incorrectly classified as PD-affected. This suggests that the model may be overly sensitive to certain handwriting characteristics that are shared between healthy and PD samples. Using dataset 2, the ILN-GNet model achieved TP = 124 and FN = 3, which indicates that the PD-affected individuals were incorrectly classified as healthy. Overall, the ILN-GNet model efficiently detects the healthy and patient classes.</p>
<figure class="fig xbox font-sm" id="Fig16"><h4 class="obj_head">Fig.16.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12371065_41598_2025_12636_Fig16_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9fd5/12371065/2bce9e52c29e/41598_2025_12636_Fig16_HTML.jpg" loading="lazy" id="MO16" height="404" width="753" alt="Fig.16"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig16/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Confusion matrix using proposed ILN-GNet for PD detection for (<strong>a</strong>) Dataset 1 and (<strong>b</strong>) Dataset 2.</p></figcaption></figure></section><section id="Sec29"><h3 class="pmc_sec_title">Analysis of computational time</h3>
<p id="Par140">Computational time analysis is the process of determining how long a model will take to complete a task. It is a crucial performance indicator that assesses the efficacy of the model. The proposed ILN-GNet model’s computational time comparison with existing methods, such as EfficientNet, Ensemble, CNN, LSTM-CNN, LinkNet, XGBoost, GhostNet, GoogleNet, and AlexNet utilizing datasets 1 and 2, is shown in Table <a href="#Tab6" class="usa-link">6</a>. As a result, the suggested ILN-GNet method demonstrates superior efficiency in terms of processing speed. ILN-GNet recorded minimal computational times of 63.748 s on Dataset 1 and 62.355 s on Dataset 2, outperforming all other compared models. In contrast, the LSTM-CNN required significantly more time, with 128.650 s for dataset 1 and 125.650 s for dataset 2, and LinkNet took 107.111 s on dataset 1 and 106.452 s on dataset 2. Even relatively lightweight architectures such as GhostNet, GoogleNet, and EfficientNet demonstrated higher computation times compared to ILN-GNet, with GhostNet being the closest in efficiency at 74.134 s and 73.658 s, still slower. Traditional models like XGBoost also lag behind, requiring over 100 s on both datasets. These results confirm that ILN-GNet not only delivers high precision, as previously shown but also maintains a low computational burden, making it highly suitable for real-time PD detection applications.</p>
<section class="tw xbox font-sm" id="Tab6"><h4 class="obj_head">Table 6.</h4>
<div class="caption p"><p>Analysis of computational time for datasets 1 and 2.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead>
<tr>
<th align="left" rowspan="2" colspan="1">Methods</th>
<th align="left" colspan="1" rowspan="1">Dataset 1</th>
<th align="left" colspan="1" rowspan="1">Dataset 2</th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1">Computational Time (s)</th>
<th align="left" colspan="1" rowspan="1">Computational Time (s)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">XGBoost</td>
<td align="center" colspan="1" rowspan="1">105.680</td>
<td align="center" colspan="1" rowspan="1">103.587</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">LSTM-CNN</td>
<td align="center" colspan="1" rowspan="1">128.650</td>
<td align="center" colspan="1" rowspan="1">125.650</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">LinkNet</td>
<td align="center" colspan="1" rowspan="1">107.111</td>
<td align="center" colspan="1" rowspan="1">106.452</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GhostNet</td>
<td align="center" colspan="1" rowspan="1">74.134</td>
<td align="center" colspan="1" rowspan="1">73.658</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GoogleNet</td>
<td align="center" colspan="1" rowspan="1">88.958</td>
<td align="center" colspan="1" rowspan="1">85.649</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">AlexNet</td>
<td align="center" colspan="1" rowspan="1">85.521</td>
<td align="center" colspan="1" rowspan="1">83.652</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">EfficientNet</td>
<td align="center" colspan="1" rowspan="1">84.165</td>
<td align="center" colspan="1" rowspan="1">86.568</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">CNN</td>
<td align="center" colspan="1" rowspan="1">96.555</td>
<td align="center" colspan="1" rowspan="1">97.688</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Ensemble</td>
<td align="center" colspan="1" rowspan="1">101.466</td>
<td align="center" colspan="1" rowspan="1">102.697</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">ILN-GNet</td>
<td align="center" colspan="1" rowspan="1">63.748</td>
<td align="center" colspan="1" rowspan="1">62.355</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab6/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="Sec30"><h3 class="pmc_sec_title">Analysis of cross-validation</h3>
<p id="Par141">An important machine learning technique is cross-validation, which tests a model on several dataset subsets to assess its generalizability and resilience. This study evaluates the effectiveness of the proposed ILN-GNet model using two datasets, Dataset 1 and Dataset 2. The cross-validation results of the ILN-GNet model for these datasets are presented in Table <a href="#Tab7" class="usa-link">7</a> and Table <a href="#Tab8" class="usa-link">8</a>, respectively. The model’s efficiency is validated using standard measures such as specificity, accuracy, sensitivity, precision, MCC, NPV, F-measure, FNR, and FPR. For Dataset 1 (trained on Dataset 1 and tested on Dataset 2), the ILN-GNet model achieved an accuracy of 0.951 and a precision of 0.914, demonstrating its high reliability in distinguishing between healthy and affected individuals. Similarly, the model performed even better in several areas for Dataset 2 (trained on Dataset 2 and tested on Dataset 1), obtaining a sensitivity of 0.970 and an NPV of 0.969, demonstrating a significant capacity to accurately detect true positive and true negative cases. Furthermore, the model maintained low error rates, with an FNR of 0.030 and FPR of 0.030, signifying a minimal rate of missed or incorrect predictions. These cross-validation results show that the proposed ILN-GNet model performs better in PD identification and has good generalizability and reliability across two datasets.</p>
<section class="tw xbox font-sm" id="Tab7"><h4 class="obj_head">Table 7.</h4>
<div class="caption p"><p>Analysis of Cross-validation for Dataset 1.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Measures</th>
<th align="left" colspan="1" rowspan="1">Training with Dataset 1 and Testing with Dataset 2</th>
<th align="left" colspan="1" rowspan="1">Training with Dataset 2 and Testing with Dataset1</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Accuracy</td>
<td align="center" colspan="1" rowspan="1">95.10%</td>
<td align="center" colspan="1" rowspan="1">95.20%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Sensitivity</td>
<td align="center" colspan="1" rowspan="1">96.40%</td>
<td align="center" colspan="1" rowspan="1">96.50%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Specificity</td>
<td align="center" colspan="1" rowspan="1">92.10%</td>
<td align="center" colspan="1" rowspan="1">92.20%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Precision</td>
<td align="center" colspan="1" rowspan="1">91.40%</td>
<td align="center" colspan="1" rowspan="1">91.50%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">F-measure</td>
<td align="center" colspan="1" rowspan="1">93.70%</td>
<td align="center" colspan="1" rowspan="1">93.80%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">MCC</td>
<td align="center" colspan="1" rowspan="1">90.20%</td>
<td align="center" colspan="1" rowspan="1">90.40%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">NPV</td>
<td align="center" colspan="1" rowspan="1">96.20%</td>
<td align="center" colspan="1" rowspan="1">96.40%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">FPR</td>
<td align="center" colspan="1" rowspan="1">7.90%</td>
<td align="center" colspan="1" rowspan="1">7.80%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">FNR</td>
<td align="center" colspan="1" rowspan="1">3.60%</td>
<td align="center" colspan="1" rowspan="1">3.50%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">FDR</td>
<td align="center" colspan="1" rowspan="1">8.60%</td>
<td align="center" colspan="1" rowspan="1">8.50%</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab7/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><section class="tw xbox font-sm" id="Tab8"><h4 class="obj_head">Table 8.</h4>
<div class="caption p"><p>Analysis of Cross-validation for Dataset 2.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Measures</th>
<th align="left" colspan="1" rowspan="1">Training with Dataset 1 and Testing with Dataset 2</th>
<th align="left" colspan="1" rowspan="1">Training with Dataset 2 and Testing with Dataset1</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Accuracy</td>
<td align="center" colspan="1" rowspan="1">94.80%</td>
<td align="center" colspan="1" rowspan="1">94.90%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Sensitivity</td>
<td align="center" colspan="1" rowspan="1">96.90%</td>
<td align="center" colspan="1" rowspan="1">97.00%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Specificity</td>
<td align="center" colspan="1" rowspan="1">92.50%</td>
<td align="center" colspan="1" rowspan="1">92.60%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Precision</td>
<td align="center" colspan="1" rowspan="1">91.30%</td>
<td align="center" colspan="1" rowspan="1">91.30%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">F-measure</td>
<td align="center" colspan="1" rowspan="1">93.30%</td>
<td align="center" colspan="1" rowspan="1">93.40%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">MCC</td>
<td align="center" colspan="1" rowspan="1">89.20%</td>
<td align="center" colspan="1" rowspan="1">89.30%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">NPV</td>
<td align="center" colspan="1" rowspan="1">96.80%</td>
<td align="center" colspan="1" rowspan="1">96.90%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">FPR</td>
<td align="center" colspan="1" rowspan="1">7.50%</td>
<td align="center" colspan="1" rowspan="1">7.40%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">FNR</td>
<td align="center" colspan="1" rowspan="1">3.10%</td>
<td align="center" colspan="1" rowspan="1">3.00%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">FDR</td>
<td align="center" colspan="1" rowspan="1">8.70%</td>
<td align="center" colspan="1" rowspan="1">8.70%</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab8/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="Sec31"><h3 class="pmc_sec_title">Analysis of statistical test</h3>
<p id="Par142">The results of the statistical test establish if the suggested ILN-GNet model’s improvements over traditional techniques are statistically significant. The T-test, Friedman, and Wilcoxon tests were used in this study to evaluate the ILN-GNet model’s performance against the results of traditional techniques.</p>
<p id="Par143">The Wilcoxon test results, which compare the efficiency of the suggested ILN-GNet model to other approaches across two datasets, are shown in Table <a href="#Tab9" class="usa-link">9</a>. A p-value less than 0.1 indicates statistical significance, suggesting a significant performance difference between ILN-GNet and the respective models. For Dataset 1, ILN-GNet demonstrates statistically significant improvements over XGBoost, LSTM-CNN, LinkNet, GhostNet, GoogleNet, AlexNet, EfficientNet, and Ensemble, with p-values consistently below 0.1, except for CNN (p-value = 0.100), which shows no significant difference. On Dataset 2, ILN-GNet outperforms most models, including XGBoost, LSTM-CNN, GoogleNet, AlexNet, and EfficientNet, with p-values ranging from 0.004 to 0.082, indicating clear statistical significance. The Wilcoxon test highlights ILN-GNet’s superior performance across both datasets, with the model’s architecture leading to more accurate and robust PD detection, particularly in comparison to models like CNN and LinkNet, which show no significant advantage over ILN-GNet. Overall, the results suggest that the hybrid design of ILN-GNet is highly effective for PD detection tasks.</p>
<section class="tw xbox font-sm" id="Tab9"><h4 class="obj_head">Table 9.</h4>
<div class="caption p"><p>Analysis of Wilcoxon test using datasets 1 and 2.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead>
<tr>
<th align="left" rowspan="2" colspan="1">ILN-GNet model Vs</th>
<th align="left" colspan="1" rowspan="1">Dataset 1</th>
<th align="left" colspan="1" rowspan="1">Dataset 2</th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1">Wilcoxon p-value</th>
<th align="left" colspan="1" rowspan="1">Wilcoxon p-value</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">XGBoost</td>
<td align="center" colspan="1" rowspan="1">0.065</td>
<td align="center" colspan="1" rowspan="1">0.008</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">LSTM-CNN</td>
<td align="center" colspan="1" rowspan="1">0.032</td>
<td align="center" colspan="1" rowspan="1">0.062</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">LinkNet</td>
<td align="center" colspan="1" rowspan="1">0.048</td>
<td align="center" colspan="1" rowspan="1">0.100</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GhostNet</td>
<td align="center" colspan="1" rowspan="1">0.082</td>
<td align="center" colspan="1" rowspan="1">0.082</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GoogleNet</td>
<td align="center" colspan="1" rowspan="1">0.056</td>
<td align="center" colspan="1" rowspan="1">0.032</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">AlexNet</td>
<td align="center" colspan="1" rowspan="1">0.076</td>
<td align="center" colspan="1" rowspan="1">0.011</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">EfficientNet</td>
<td align="center" colspan="1" rowspan="1">0.022</td>
<td align="center" colspan="1" rowspan="1">0.004</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">CNN</td>
<td align="center" colspan="1" rowspan="1">0.100</td>
<td align="center" colspan="1" rowspan="1">0.065</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Ensemble</td>
<td align="center" colspan="1" rowspan="1">0.051</td>
<td align="center" colspan="1" rowspan="1">0.067</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab9/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p id="Par144">The Friedman test results are shown in Table <a href="#Tab10" class="usa-link">10</a>, which contrasts the suggested ILN-GNet model’s performance with that of several alternative models for Datasets 1 and 2. A p-value less than 0.1 indicates statistical significance, suggesting a significant performance difference between ILN-GNet and the respective models. For Dataset 1, ILN-GNet shows statistically significant improvements over LSTM-CNN (p-value = 0.037), EfficientNet (p-value = 0.022), XGBoost (p-value = 0.082), LinkNet (p-value = 0.061), and GoogleNet (p-value = 0.072) approach significance. For Dataset 2, ILN-GNet outperforms XGBoost (p-value = 0.005), EfficientNet (p-value = 0.002), and AlexNet (p-value = 0.008), showing stronger statistical significance. Other models like LSTM-CNN (p-value = 0.078), GoogleNet (p-value = 0.037), and Ensemble (p-value = 0.083) show some level of significance. Models such as CNN, and LinkNet do not show significant performance differences from ILN-GNet on either dataset. Overall, the Friedman test confirms that ILN-GNet consistently demonstrates superior performance, particularly on Dataset 2, underscoring its effectiveness in detecting Parkinson’s Disease across different model comparisons.</p>
<section class="tw xbox font-sm" id="Tab10"><h4 class="obj_head">Table 10.</h4>
<div class="caption p"><p>Analysis of Friedman test for Dataset 1 and Dataset 2.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead>
<tr>
<th align="left" rowspan="2" colspan="1">ILN-GNet model Vs</th>
<th align="left" colspan="1" rowspan="1">Dataset 1</th>
<th align="left" colspan="1" rowspan="1">Dataset 2</th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1">Friedman p-value</th>
<th align="left" colspan="1" rowspan="1">Friedman p-value</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">XGBoost</td>
<td align="center" colspan="1" rowspan="1">0.082</td>
<td align="center" colspan="1" rowspan="1">0.005</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">LSTM-CNN</td>
<td align="center" colspan="1" rowspan="1">0.037</td>
<td align="center" colspan="1" rowspan="1">0.078</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">LinkNet</td>
<td align="center" colspan="1" rowspan="1">0.061</td>
<td align="center" colspan="1" rowspan="1">0.100</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GhostNet</td>
<td align="center" colspan="1" rowspan="1">0.095</td>
<td align="center" colspan="1" rowspan="1">0.095</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GoogleNet</td>
<td align="center" colspan="1" rowspan="1">0.072</td>
<td align="center" colspan="1" rowspan="1">0.037</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">AlexNet</td>
<td align="center" colspan="1" rowspan="1">0.091</td>
<td align="center" colspan="1" rowspan="1">0.008</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">EfficientNet</td>
<td align="center" colspan="1" rowspan="1">0.022</td>
<td align="center" colspan="1" rowspan="1">0.002</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">CNN</td>
<td align="center" colspan="1" rowspan="1">0.100</td>
<td align="center" colspan="1" rowspan="1">0.082</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Ensemble</td>
<td align="center" colspan="1" rowspan="1">0.065</td>
<td align="center" colspan="1" rowspan="1">0.083</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab10/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p id="Par145">The T-test results comparing the efficiency of the suggested ILN-GNet model with several different models across Datasets 1 and 2 are shown in Table <a href="#Tab11" class="usa-link">11</a>. A p-value less than 0.1 indicates statistical significance, suggesting a significant performance difference between ILN-GNet and the respective models. For Dataset 1, ILN-GNet shows statistically significant superiority over EfficientNet (p-value = 0.045) and XGBoost (p-value = 0.080), as both p-values are below 0.1, indicating a meaningful performance gap. Models like LSTM-CNN (p-value = 0.070), GoogleNet (p-value = 0.080), and Ensemble (p-value = 0.070) also show a significant difference, although the performance gap is smaller. Other models such as LinkNet (p-value = 0.080), GhostNet (p-value = 0.090), AlexNet (p-value = 0.090), and CNN (p-value = 0.100) show no significant performance difference, with p-values approaching 0.1. For Dataset 2, ILN-GNet shows statistically significant improvement over EfficientNet (p-value = 0.016), XGBoost (p-value = 0.025), and AlexNet (p-value = 0.045), with all these models having p-values below 0.1, indicating that ILN-GNet performs better. GoogleNet (p-value = 0.061) also shows a significant difference, though not as strong as the previous models. In contrast, models like LSTM-CNN (p-value = 0.080), Ensemble (p-value = 0.080), and CNN (p-value = 0.080) have p-values near 0.1, which indicate marginal but not conclusive differences in performance. Overall, the T-test results show that ILN-GNet significantly outperforms several models on both datasets.</p>
<section class="tw xbox font-sm" id="Tab11"><h4 class="obj_head">Table 11.</h4>
<div class="caption p"><p>Analysis of T-test for datasets 1 and 2.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead>
<tr>
<th align="left" rowspan="2" colspan="1">ILN-GNet model Vs</th>
<th align="left" colspan="1" rowspan="1">Dataset 1</th>
<th align="left" colspan="1" rowspan="1">Dataset 2</th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1">T-test</th>
<th align="left" colspan="1" rowspan="1">T-test</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">XGBoost</td>
<td align="center" colspan="1" rowspan="1">0.080</td>
<td align="center" colspan="1" rowspan="1">0.025</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">LSTM-CNN</td>
<td align="center" colspan="1" rowspan="1">0.070</td>
<td align="center" colspan="1" rowspan="1">0.08</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">LinkNet</td>
<td align="center" colspan="1" rowspan="1">0.080</td>
<td align="center" colspan="1" rowspan="1">0.1</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GhostNet</td>
<td align="center" colspan="1" rowspan="1">0.090</td>
<td align="center" colspan="1" rowspan="1">0.09</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GoogleNet</td>
<td align="center" colspan="1" rowspan="1">0.080</td>
<td align="center" colspan="1" rowspan="1">0.061</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">AlexNet</td>
<td align="center" colspan="1" rowspan="1">0.090</td>
<td align="center" colspan="1" rowspan="1">0.045</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">EfficientNet</td>
<td align="center" colspan="1" rowspan="1">0.045</td>
<td align="center" colspan="1" rowspan="1">0.016</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">CNN</td>
<td align="center" colspan="1" rowspan="1">0.100</td>
<td align="center" colspan="1" rowspan="1">0.08</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Ensemble</td>
<td align="center" colspan="1" rowspan="1">0.070</td>
<td align="center" colspan="1" rowspan="1">0.08</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab11/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section></section><section id="Sec32"><h2 class="pmc_sec_title">Conclusion</h2>
<p id="Par146">This research developed a novel PD detection approach with handwriting images using an improved hybrid classification model. The handwriting image was pre-processed primarily using modified WF. Next, deep features, shape features, and modified PHOG were obtained. Lastly, a hybrid ILN-GNet framework was used for detection, and its average indicated whether the person was affected or healthy. Additionally, the effectiveness of the proposed ILN-GNet model is contrasted with conventional techniques like EfficientNet, LinkNet, GhostNet, GoogleNet, and AlexNet as well as cutting-edge models like CNN and Ensemble. Thus, at 90% of training data, the proposed ILN-GNet model had a higher accuracy of 0.982, while LinkNet, GhostNet, GoogleNet, AlexNet, EfficientNet, CNN, and Ensemble had an accuracy of 0.921, 0.864, 0.916, and 0.827, respectively. The F-measure and MCC of the suggested ILN-GNet model were higher, at 0.966 and 0.971, respectively. The incorporation of the modified wiener filter, the extraction of improved PHOG along the retrieval of deep features and shape features contribute to enhanced detection. Additionally, the Improved LinkNet architecture is proposed with structural modifications using an MDSCM layer and integrated with GhostNet. The resulting hybrid model demonstrates significantly better performance compared to existing methods.</p>
<p id="Par147">Despite the promising results, this study has several limitations. The performance of the modified Wiener filter used in pre-processing is critical; improper tuning may lead to the loss of important handwriting features. Furthermore, the combination of Improved LinkNet with GhostNet raises the model’s overall complexity even though it might improve classification accuracy. In order to improve the model’s performance even more, future studies will concentrate on resolving these issues. Future research would examine improving preprocessing methods to lower false positives. Only the most pertinent features are chosen, which helps keep the framework from overfitting to unimportant data and increases the model’s overall accuracy by concentrating on the most significant patterns. For this purpose, optimal feature selection techniques could be explored in future studies. Moreover, future studies will explore alternative ML classifiers and fusion strategies such as weighted fusion to assess and improve the overall performance of the model. Furthermore, recognizing that PD has no cure but that early intervention can significantly alleviate symptoms, our future work’s aim is to integrate the proposed approach into the healthcare environment with the support of medical professionals and to enhance the model to assess symptom severity and eventually provide personalized treatment suggestions such as medication options, physical therapy, or speech therapy, based on patient data.</p></section><section id="glossary1" class="glossary"><h2 class="pmc_sec_title">Abbreviations</h2>
<dl class="def-list">
<dt>A-LSTM</dt>
<dd><p id="Par2">Attention-based long short-term memory</p></dd>
<dt>BN</dt>
<dd><p id="Par3">Batch normalization</p></dd>
<dt>Conv</dt>
<dd><p id="Par4">Convolution</p></dd>
<dt>CC-Net</dt>
<dd><p id="Par5">Continuous convolution network</p></dd>
<dt>CNN</dt>
<dd><p id="Par6">Convolutional neural networks</p></dd>
<dt>DT</dt>
<dd><p id="Par7">Decision trees</p></dd>
<dt>DL</dt>
<dd><p id="Par8">Deep learning</p></dd>
<dt>DBS</dt>
<dd><p id="Par9">Deep brain stimulation</p></dd>
<dt>DCNN</dt>
<dd><p id="Par10">Deep convolutional neural network</p></dd>
<dt>DNN</dt>
<dd><p id="Par11">Deep neural networks</p></dd>
<dt>DSS</dt>
<dd><p id="Par12">Decision support systems</p></dd>
<dt>ELU</dt>
<dd><p id="Par13">Exponential linear unit</p></dd>
<dt>FCL</dt>
<dd><p id="Par14">Fully connected layer</p></dd>
<dt>FGS</dt>
<dd><p id="Par15">Fuzzy genetic systems</p></dd>
<dt>FC</dt>
<dd><p id="Par16">Fuzzy classifier</p></dd>
<dt>GNet</dt>
<dd><p id="Par17">Ghostnet</p></dd>
<dt>GA</dt>
<dd><p id="Par18">Genetic algorithms</p></dd>
<dt>GBM</dt>
<dd><p id="Par19">Ghost bottleneck module</p></dd>
<dt>GSA</dt>
<dd><p id="Par20">Grid search algorithm</p></dd>
<dt>ILN-GNet</dt>
<dd><p id="Par21">Improved linknet and ghostnET</p></dd>
<dt>KNN</dt>
<dd><p id="Par22">K-nearest neighbor</p></dd>
<dt>LR</dt>
<dd><p id="Par23">Logistic regression</p></dd>
<dt>LS-SVR v</dt>
<dd><p id="Par24">Least squares support vector regression</p></dd>
<dt>MDSCM</dt>
<dd><p id="Par25">Multisize depth wise separable convolution module</p></dd>
<dt>ML</dt>
<dd><p id="Par26">Machine learning</p></dd>
<dt>NB</dt>
<dd><p id="Par27">Naïve bayes</p></dd>
<dt>PSD</dt>
<dd><p id="Par28">Power spectral density</p></dd>
<dt>PHOG</dt>
<dd><p id="Par29">Pyramid histogram of oriented gradients</p></dd>
<dt>PCA</dt>
<dd><p id="Par30">Principal component analysis</p></dd>
<dt>PD</dt>
<dd><p id="Par31">Parkinson’s disease</p></dd>
<dt>QMFOFS-HCNN</dt>
<dd><p id="Par32">Quantum mayfly optimization-based feature subset selection with hybrid convolutional neural network</p></dd>
<dt>QMO</dt>
<dd><p id="Par33">Quantum mayfly optimization</p></dd>
<dt>RF</dt>
<dd><p id="Par34">Random forest</p></dd>
<dt>SD</dt>
<dd><p id="Par35">Standard deviation</p></dd>
<dt>SVC</dt>
<dd><p id="Par36">Support vector classification</p></dd>
<dt>TL</dt>
<dd><p id="Par37">Transfer learning</p></dd>
<dt>TD</dt>
<dd><p id="Par38">Training data</p></dd>
<dt>UPDRS</dt>
<dd><p id="Par39">Unified parkinson’s disease rating scale</p></dd>
<dt>WF</dt>
<dd><p id="Par40">Wiener filter</p></dd>
<dt>WAP-BN</dt>
<dd><p id="Par41">Weighted average pooling-batch normalization</p></dd>
</dl></section><section id="notes1"><h2 class="pmc_sec_title">Author contributions</h2>
<p>[P Pradeep] Conceptualization, Writing, Methodology, Data Curation [Dr J Kamalakannan] Editing, Data Analysis.</p></section><section id="notes2"><h2 class="pmc_sec_title">Funding</h2>
<p>Open access funding provided by Vellore Institute of Technology. This research did not receive any specific funding.</p></section><section id="notes3"><h2 class="pmc_sec_title">Data availability</h2>
<p>The data underlying this article are available in the Kaggle repository named as HandPD dataset, at <a href="https://www.kaggle.com/datasets/claytonteybauru/spiral-handpd/data" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/datasets/claytonteybauru/spiral-handpd/data</a> and theMeander_HandPD images in HandPD dataset at <a href="https://wwwp.fc.unesp.br/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://wwwp.fc.unesp.br/</a> ~ papa/pub/datasets/Handpd/dataset, at <a href="https://www.kaggle.com/datasets/claytonteybauru/spiral-handpd/data" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/datasets/claytonteybauru/spiral-handpd/data</a> and theMeander_HandPD images in HandPD dataset at<a href="https://wwwp.fc.unesp.br/~papa/pub/datasets/Handpd/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://wwwp.fc.unesp.br/~papa/pub/datasets/Handpd/</a></p></section><section id="notes4"><h2 class="pmc_sec_title">Declarations</h2>
<section id="FPar1"><h3 class="pmc_sec_title">Competing interests</h3>
<p id="Par148">The authors declare no competing interests.</p></section><section id="FPar2"><h3 class="pmc_sec_title">Ethics</h3>
<p id="Par149">There are no human or animal participants in this article, therefore ethical approval is not applicable for this work.</p></section></section><section id="fn-group1" class="fn-group"><h2 class="pmc_sec_title">Footnotes</h2>
<div class="fn-group p font-secondary-light font-sm"><div class="fn p" id="fn1">
<p><strong>Publisher’s note</strong></p>
<p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</div></div></section><section id="Bib1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="Bib1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="CR1">
<span class="label">1.</span><cite>Benchabane, A. &amp; Charif, F. Parkinson’s disease detection through hand drawings and AlexNet model. <em>Diagnostyka</em><strong>25</strong>, 1–6 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Benchabane,%20A.%20&amp;%20Charif,%20F.%20Parkinson%E2%80%99s%20disease%20detection%20through%20hand%20drawings%20and%20AlexNet%20model.%20Diagnostyka25,%201%E2%80%936%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR2">
<span class="label">2.</span><cite>Dhieb, T. et al. Parkinson’s disease detection from online handwriting based on beta-elliptical allebawi approach and fuzzy perceptual detector. <em>IEEE Access</em><strong>12</strong>(56936), 56950 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Dhieb,%20T.%20et%20al.%20Parkinson%E2%80%99s%20disease%20detection%20from%20online%20handwriting%20based%20on%20beta-elliptical%20allebawi%20approach%20and%20fuzzy%20perceptual%20detector.%20IEEE%20Access12(56936),%2056950%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR3">
<span class="label">3.</span><cite>Impedovo, D. &amp; Pirlo, G. Dynamic handwriting analysis for the assessment of neurodegenerative diseases: A pattern recognition perspective. <em>IEEE Rev. Biomed. Eng.</em><strong>12</strong>, 209–220 (2018).
</cite> [<a href="https://doi.org/10.1109/RBME.2018.2840679" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/29993722/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Impedovo,%20D.%20&amp;%20Pirlo,%20G.%20Dynamic%20handwriting%20analysis%20for%20the%20assessment%20of%20neurodegenerative%20diseases:%20A%20pattern%20recognition%20perspective.%20IEEE%20Rev.%20Biomed.%20Eng.12,%20209%E2%80%93220%20(2018)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR4">
<span class="label">4.</span><cite>Impedovo, D. Velocity-based signal features for the assessment of Parkinsonian handwriting. <em>IEEE Signal Process. Lett.</em><strong>26</strong>(4), 632–636 (2019).</cite> [<a href="https://scholar.google.com/scholar_lookup?Impedovo,%20D.%20Velocity-based%20signal%20features%20for%20the%20assessment%20of%20Parkinsonian%20handwriting.%20IEEE%20Signal%20Process.%20Lett.26(4),%20632%E2%80%93636%20(2019)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR5">
<span class="label">5.</span><cite>Dhivyaa, C. R., Nithya, K., &amp; Anbukkarasi, S. Enhancing parkinson’s disease detection and diagnosis: A survey of integrative approaches across diverse modalities. <em>IEEE Access</em>. 2024</cite>
</li>
<li id="CR6">
<span class="label">6.</span><cite>Ngo, Q. C. et al. NeuroDiag: Software for automated diagnosis of parkinson’s disease using handwriting. <em>IEEE J. Transl. Eng. Health &amp; Med.</em><strong>12</strong>, 291 (2024).
</cite> [<a href="https://doi.org/10.1109/JTEHM.2024.3355432" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10896420/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38410180/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Ngo,%20Q.%20C.%20et%20al.%20NeuroDiag:%20Software%20for%20automated%20diagnosis%20of%20parkinson%E2%80%99s%20disease%20using%20handwriting.%20IEEE%20J.%20Transl.%20Eng.%20Health%20&amp;%20Med.12,%20291%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR7">
<span class="label">7.</span><cite>Nolazco-Flores, J. A., Faundez-Zanuy, M., De La Cueva, V. M. &amp; Mekyska, J. Exploiting spectral and cepstral handwriting features on diagnosing Parkinson’s disease. <em>IEEE Access</em><strong>9</strong>, 141599–141610 (2021).</cite> [<a href="https://scholar.google.com/scholar_lookup?Nolazco-Flores,%20J.%20A.,%20Faundez-Zanuy,%20M.,%20De%20La%20Cueva,%20V.%20M.%20&amp;%20Mekyska,%20J.%20Exploiting%20spectral%20and%20cepstral%20handwriting%20features%20on%20diagnosing%20Parkinson%E2%80%99s%20disease.%20IEEE%20Access9,%20141599%E2%80%93141610%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR8">
<span class="label">8.</span><cite>Kan, P. J. et al. Polar expression feature of digitized handwritten pattern for automated-Parkinson’s-disease screening using perceptual color representation-based classifier. <em>IEEE Access</em><strong>7</strong>, 61738–61755 (2019).</cite> [<a href="https://scholar.google.com/scholar_lookup?Kan,%20P.%20J.%20et%20al.%20Polar%20expression%20feature%20of%20digitized%20handwritten%20pattern%20for%20automated-Parkinson%E2%80%99s-disease%20screening%20using%20perceptual%20color%20representation-based%20classifier.%20IEEE%20Access7,%2061738%E2%80%9361755%20(2019)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR9">
<span class="label">9.</span><cite>Ranjan, N. M., Mate, G., &amp; Bembde, M. Detection of parkinson’s disease using machine learning algorithms and handwriting analysis. Journal of Data Mining and Management (e-ISSN: 2456–9437) 8(1) 21–29. 2023</cite>
</li>
<li id="CR10">
<span class="label">10.</span><cite>Ali, L. et al. Reliable Parkinson’s disease detection by analyzing handwritten drawings: Construction of an unbiased cascaded learning system based on feature selection and adaptive boosting model. <em>Ieee Access</em><strong>7</strong>, 116480–116489 (2019).</cite> [<a href="https://scholar.google.com/scholar_lookup?Ali,%20L.%20et%20al.%20Reliable%20Parkinson%E2%80%99s%20disease%20detection%20by%20analyzing%20handwritten%20drawings:%20Construction%20of%20an%20unbiased%20cascaded%20learning%20system%20based%20on%20feature%20selection%20and%20adaptive%20boosting%20model.%20Ieee%20Access7,%20116480%E2%80%93116489%20(2019)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR11">
<span class="label">11.</span><cite>Collins, L. M. et al. Intensive training programme improves handwriting in a community cohort of people with Parkinson’s disease (1971-). <em>Irish J. Med. Sci.</em><strong>193</strong>(1), 389–395 (2024).
</cite> [<a href="https://doi.org/10.1007/s11845-023-03404-8" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10808167/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37249793/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Collins,%20L.%20M.%20et%20al.%20Intensive%20training%20programme%20improves%20handwriting%20in%20a%20community%20cohort%20of%20people%20with%20Parkinson%E2%80%99s%20disease%20(1971-).%20Irish%20J.%20Med.%20Sci.193(1),%20389%E2%80%93395%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR12">
<span class="label">12.</span><cite>Aljohani, A. Late feature fusion using neural network with voting classifier for Parkinson’s disease detection. <em>BMC Med. Inform. Decis. Mak.</em><strong>24</strong>(1), 269 (2024).
</cite> [<a href="https://doi.org/10.1186/s12911-024-02683-0" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11429630/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39334295/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Aljohani,%20A.%20Late%20feature%20fusion%20using%20neural%20network%20with%20voting%20classifier%20for%20Parkinson%E2%80%99s%20disease%20detection.%20BMC%20Med.%20Inform.%20Decis.%20Mak.24(1),%20269%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR13">
<span class="label">13.</span><cite>Ma, L. et al. Twin-tower transformer network for skeleton-based Parkinson’s disease early detection. <em>Complex &amp; Intell. Syst.</em><strong>10</strong>, 6745 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Ma,%20L.%20et%20al.%20Twin-tower%20transformer%20network%20for%20skeleton-based%20Parkinson%E2%80%99s%20disease%20early%20detection.%20Complex%20&amp;%20Intell.%20Syst.10,%206745%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR14">
<span class="label">14.</span><cite>Du, Q., Shen, J., Wen, P. &amp; Chen, X. Parkinson’s disease detection by using machine learning method based on local classification on class boundary. <em>Discover. Appl. Sci.</em><strong>6</strong>(11), 1–12 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Du,%20Q.,%20Shen,%20J.,%20Wen,%20P.%20&amp;%20Chen,%20X.%20Parkinson%E2%80%99s%20disease%20detection%20by%20using%20machine%20learning%20method%20based%20on%20local%20classification%20on%20class%20boundary.%20Discover.%20Appl.%20Sci.6(11),%201%E2%80%9312%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR15">
<span class="label">15.</span><cite>Mannone, M., Fazio, P., Kurths, J., Ribino, P. &amp; Marwan, N. A brain-network operator for modeling disease: a first data-based application for Parkinson’s disease. <em>Euro. Phys. J. Special Topics</em><strong>234</strong>, 119 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Mannone,%20M.,%20Fazio,%20P.,%20Kurths,%20J.,%20Ribino,%20P.%20&amp;%20Marwan,%20N.%20A%20brain-network%20operator%20for%20modeling%20disease:%20a%20first%20data-based%20application%20for%20Parkinson%E2%80%99s%20disease.%20Euro.%20Phys.%20J.%20Special%20Topics234,%20119%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR16">
<span class="label">16.</span><cite>Sarasso, E. et al. Neural correlates of bradykinesia in Parkinson’s disease: A kinematic and functional MRI study. <em>npj Parkinson’s Disease</em><strong>10</strong>(1), 167 (2024).
</cite> [<a href="https://doi.org/10.1038/s41531-024-00783-2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11379907/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39242570/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Sarasso,%20E.%20et%20al.%20Neural%20correlates%20of%20bradykinesia%20in%20Parkinson%E2%80%99s%20disease:%20A%20kinematic%20and%20functional%20MRI%20study.%20npj%20Parkinson%E2%80%99s%20Disease10(1),%20167%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR17">
<span class="label">17.</span><cite>Taleb, C., Likforman-Sulem, L., Mokbel, C. &amp; Khachab, M. Detection of Parkinson’s disease from handwriting using deep learning: A comparative study. <em>Evol. Intell.</em><strong>16</strong>, 1813 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Taleb,%20C.,%20Likforman-Sulem,%20L.,%20Mokbel,%20C.%20&amp;%20Khachab,%20M.%20Detection%20of%20Parkinson%E2%80%99s%20disease%20from%20handwriting%20using%20deep%20learning:%20A%20comparative%20study.%20Evol.%20Intell.16,%201813%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR18">
<span class="label">18.</span><cite>Müller, T. &amp; Harati, A. Levodopa improves handwriting and instrumental tasks in previously treated patients with Parkinson’s disease. <em>J. Neural Transm.</em><strong>127</strong>(10), 1369–1376 (2020).
</cite> [<a href="https://doi.org/10.1007/s00702-020-02246-3" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7497291/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32813086/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?M%C3%BCller,%20T.%20&amp;%20Harati,%20A.%20Levodopa%20improves%20handwriting%20and%20instrumental%20tasks%20in%20previously%20treated%20patients%20with%20Parkinson%E2%80%99s%20disease.%20J.%20Neural%20Transm.127(10),%201369%E2%80%931376%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR19">
<span class="label">19.</span><cite>García-Ordás, M. T., Benítez-Andrades, J. A., Aveleira-Mata, J., Alija-Pérez, J. M. &amp; Benavides, C. Determining the severity of Parkinson’s disease in patients using a multi task neural network. <em>Multimed. Tools &amp; Appl.</em><strong>83</strong>(2), 6077–6092 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Garc%C3%ADa-Ord%C3%A1s,%20M.%20T.,%20Ben%C3%ADtez-Andrades,%20J.%20A.,%20Aveleira-Mata,%20J.,%20Alija-P%C3%A9rez,%20J.%20M.%20&amp;%20Benavides,%20C.%20Determining%20the%20severity%20of%20Parkinson%E2%80%99s%20disease%20in%20patients%20using%20a%20multi%20task%20neural%20network.%20Multimed.%20Tools%20&amp;%20Appl.83(2),%206077%E2%80%936092%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR20">
<span class="label">20.</span><cite>Indu, R. &amp; Dimri, S. C. Customized treatment for Parkinson’s disease: Extending lifespan and improving symptoms. <em>Egypt. J. Neurol. Psychiatr. &amp; Neurosurg.</em><strong>60</strong>(1), 71 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Indu,%20R.%20&amp;%20Dimri,%20S.%20C.%20Customized%20treatment%20for%20Parkinson%E2%80%99s%20disease:%20Extending%20lifespan%20and%20improving%20symptoms.%20Egypt.%20J.%20Neurol.%20Psychiatr.%20&amp;%20Neurosurg.60(1),%2071%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR21">
<span class="label">21.</span><cite>Cuk, A. et al. Tuning attention based long-short term memory neural networks for Parkinson’s disease detection using modified metaheuristics. <em>Sci. Rep.</em><strong>14</strong>(1), 4309 (2024).
</cite> [<a href="https://doi.org/10.1038/s41598-024-54680-y" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10881563/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38383690/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Cuk,%20A.%20et%20al.%20Tuning%20attention%20based%20long-short%20term%20memory%20neural%20networks%20for%20Parkinson%E2%80%99s%20disease%20detection%20using%20modified%20metaheuristics.%20Sci.%20Rep.14(1),%204309%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR22">
<span class="label">22.</span><cite>Dentamaro, V., Impedovo, D., Musti, L., Pirlo, G. &amp; Taurisano, P. Enhancing early Parkinson’s disease detection through multimodal deep learning and explainable AI: Insights from the PPMI database. <em>Sci. Rep.</em><strong>14</strong>(1), 20941 (2024).
</cite> [<a href="https://doi.org/10.1038/s41598-024-70165-4" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11385236/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39251639/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Dentamaro,%20V.,%20Impedovo,%20D.,%20Musti,%20L.,%20Pirlo,%20G.%20&amp;%20Taurisano,%20P.%20Enhancing%20early%20Parkinson%E2%80%99s%20disease%20detection%20through%20multimodal%20deep%20learning%20and%20explainable%20AI:%20Insights%20from%20the%20PPMI%20database.%20Sci.%20Rep.14(1),%2020941%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR23">
<span class="label">23.</span><cite>Szlepák, T. et al. GBA-associated Parkinson’s disease in Hungary: Clinical features and genetic insights. <em>Neurol. Sci.</em><strong>45</strong>(6), 2671–2679 (2024).
</cite> [<a href="https://doi.org/10.1007/s10072-023-07213-w" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11082009/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38153678/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Szlep%C3%A1k,%20T.%20et%20al.%20GBA-associated%20Parkinson%E2%80%99s%20disease%20in%20Hungary:%20Clinical%20features%20and%20genetic%20insights.%20Neurol.%20Sci.45(6),%202671%E2%80%932679%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR24">
<span class="label">24.</span><cite>Rosenblum, S., Meyer, S., Richardson, A. &amp; Hassin-Baer, S. Early identification of subjective cognitive functional decline among patients with Parkinson’s disease: A longitudinal pilot study. <em>Sci. Rep.</em><strong>12</strong>(1), 22242 (2022).
</cite> [<a href="https://doi.org/10.1038/s41598-022-26280-1" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9789081/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36564494/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Rosenblum,%20S.,%20Meyer,%20S.,%20Richardson,%20A.%20&amp;%20Hassin-Baer,%20S.%20Early%20identification%20of%20subjective%20cognitive%20functional%20decline%20among%20patients%20with%20Parkinson%E2%80%99s%20disease:%20A%20longitudinal%20pilot%20study.%20Sci.%20Rep.12(1),%2022242%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR25">
<span class="label">25.</span><cite>Mani, R. C., Kamalakannan, J., Rangaiah, Y. P. &amp; Anand, S. A bio-inspired method for breast histopathology image classification using transfer learning. <em>J. Artific. Intell. &amp; Technol.</em><strong>4</strong>(2), 89–101 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Mani,%20R.%20C.,%20Kamalakannan,%20J.,%20Rangaiah,%20Y.%20P.%20&amp;%20Anand,%20S.%20A%20bio-inspired%20method%20for%20breast%20histopathology%20image%20classification%20using%20transfer%20learning.%20J.%20Artific.%20Intell.%20&amp;%20Technol.4(2),%2089%E2%80%93101%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR26">
<span class="label">26.</span><cite>Ahmadi, H., Huo, L., Arji, G., Sheikhtaheri, A. &amp; Zhou, S. M. Early diagnosis of Parkinson’s disease using a hybrid method of least squares support vector regression and fuzzy clustering. <em>Biocybern. &amp; Biomed. Eng.</em><strong>44</strong>(3), 569–585 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Ahmadi,%20H.,%20Huo,%20L.,%20Arji,%20G.,%20Sheikhtaheri,%20A.%20&amp;%20Zhou,%20S.%20M.%20Early%20diagnosis%20of%20Parkinson%E2%80%99s%20disease%20using%20a%20hybrid%20method%20of%20least%20squares%20support%20vector%20regression%20and%20fuzzy%20clustering.%20Biocybern.%20&amp;%20Biomed.%20Eng.44(3),%20569%E2%80%93585%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR27">
<span class="label">27.</span><cite>Topka, M. et al. Motor cortex excitability is reduced during freezing of upper limb movement in Parkinson’s disease. <em>npj Parkinson’s Dis.</em><strong>8</strong>(1), 161 (2022).
</cite> [<a href="https://doi.org/10.1038/s41531-022-00420-w" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9691624/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36424411/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Topka,%20M.%20et%20al.%20Motor%20cortex%20excitability%20is%20reduced%20during%20freezing%20of%20upper%20limb%20movement%20in%20Parkinson%E2%80%99s%20disease.%20npj%20Parkinson%E2%80%99s%20Dis.8(1),%20161%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR28">
<span class="label">28.</span><cite>Rios-Urrego, C. D., Rusz, J. &amp; Orozco-Arroyave, J. R. Automatic speech-based assessment to discriminate Parkinson’s disease from essential tremor with a cross-language approach. <em>npj Digital Med.</em><strong>7</strong>, 37 (2024).</cite> [<a href="https://doi.org/10.1038/s41746-024-01027-6" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10874421/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38368458/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Rios-Urrego,%20C.%20D.,%20Rusz,%20J.%20&amp;%20Orozco-Arroyave,%20J.%20R.%20Automatic%20speech-based%20assessment%20to%20discriminate%20Parkinson%E2%80%99s%20disease%20from%20essential%20tremor%20with%20a%20cross-language%20approach.%20npj%20Digital%20Med.7,%2037%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR29">
<span class="label">29.</span><cite>Li, Z. et al. Early diagnosis of Parkinson’s disease using continuous convolution network: Handwriting recognition based on off-line hand drawing without template. <em>J. Biomed. Inform.</em><strong>130</strong>, 104085 (2022).
</cite> [<a href="https://doi.org/10.1016/j.jbi.2022.104085" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35490964/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Li,%20Z.%20et%20al.%20Early%20diagnosis%20of%20Parkinson%E2%80%99s%20disease%20using%20continuous%20convolution%20network:%20Handwriting%20recognition%20based%20on%20off-line%20hand%20drawing%20without%20template.%20J.%20Biomed.%20Inform.130,%20104085%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR30">
<span class="label">30.</span><cite>Naz, S., Kamran, I., Gul, S., Hadi, F. &amp; Khalifa, F. Multi-model fusion of CNNs for identification of parkinson’s disease using handwritten samples. <em>IEEE Access</em><strong>11</strong>, 135600–135608 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Naz,%20S.,%20Kamran,%20I.,%20Gul,%20S.,%20Hadi,%20F.%20&amp;%20Khalifa,%20F.%20Multi-model%20fusion%20of%20CNNs%20for%20identification%20of%20parkinson%E2%80%99s%20disease%20using%20handwritten%20samples.%20IEEE%20Access11,%20135600%E2%80%93135608%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR31">
<span class="label">31.</span><cite>Abdullah, S. M. et al. Deep transfer learning based parkinson’s disease detection using optimized feature selection. <em>IEEE Access</em><strong>11</strong>, 3511–3524 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Abdullah,%20S.%20M.%20et%20al.%20Deep%20transfer%20learning%20based%20parkinson%E2%80%99s%20disease%20detection%20using%20optimized%20feature%20selection.%20IEEE%20Access11,%203511%E2%80%933524%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR32">
<span class="label">32.</span><cite>Kamble, M., Shrivastava, P., &amp; Jain, M. Digitized spiral drawing classification for Parkinson’s disease diagnosis. <em>Measurement: Sensors</em><em>16</em> 100047 2021</cite>
</li>
<li id="CR33">
<span class="label">33.</span><cite>Sarin, K. et al. A three-stage fuzzy classifier method for Parkinson’s disease diagnosis using dynamic handwriting analysis. <em>Decis. Analytics J.</em><strong>8</strong>, 100274 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Sarin,%20K.%20et%20al.%20A%20three-stage%20fuzzy%20classifier%20method%20for%20Parkinson%E2%80%99s%20disease%20diagnosis%20using%20dynamic%20handwriting%20analysis.%20Decis.%20Analytics%20J.8,%20100274%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR34">
<span class="label">34.</span><cite>Yousif, N. R., Balaha, H. M., Haikal, A. Y. &amp; El-Gendy, E. M. A generic optimization and learning framework for Parkinson disease via speech and handwritten records. <em>J. Ambient. Intell. Humaniz. Comput.</em><strong>14</strong>(8), 10673–10693 (2023).</cite> [<a href="https://doi.org/10.1007/s12652-022-04342-6" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9411848/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36042792/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Yousif,%20N.%20R.,%20Balaha,%20H.%20M.,%20Haikal,%20A.%20Y.%20&amp;%20El-Gendy,%20E.%20M.%20A%20generic%20optimization%20and%20learning%20framework%20for%20Parkinson%20disease%20via%20speech%20and%20handwritten%20records.%20J.%20Ambient.%20Intell.%20Humaniz.%20Comput.14(8),%2010673%E2%80%9310693%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR35">
<span class="label">35.</span><cite>Mansour, R. F. Quantum mayfly optimization based feature subset selection with hybrid CNN for biomedical Parkinson’s disease diagnosis. <em>Neural Comput. Appl.</em><strong>36</strong>(15), 8383–8396 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Mansour,%20R.%20F.%20Quantum%20mayfly%20optimization%20based%20feature%20subset%20selection%20with%20hybrid%20CNN%20for%20biomedical%20Parkinson%E2%80%99s%20disease%20diagnosis.%20Neural%20Comput.%20Appl.36(15),%208383%E2%80%938396%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR36">
<span class="label">36.</span><cite>Wang, X. et al. LSTM-CNN: An efficient diagnostic network for Parkinson’s disease utilizing dynamic handwriting analysis. <em>Comput. Methods Programs Biomed.</em><strong>247</strong>, 108066 (2024).
</cite> [<a href="https://doi.org/10.1016/j.cmpb.2024.108066" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38364361/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Wang,%20X.%20et%20al.%20LSTM-CNN:%20An%20efficient%20diagnostic%20network%20for%20Parkinson%E2%80%99s%20disease%20utilizing%20dynamic%20handwriting%20analysis.%20Comput.%20Methods%20Programs%20Biomed.247,%20108066%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR37">
<span class="label">37.</span><cite>Saïdani, A., &amp; Echi, A. K. (2014, August). Pyramid histogram of oriented gradient for machine-printed/handwritten and Arabic/Latin word discrimination. In <em>2014 6th International Conference of Soft Computing and Pattern Recognition (SoCPaR)</em> (pp. 267–272). IEEE.</cite>
</li>
<li id="CR38">
<span class="label">38.</span><cite>Zenggang, X. et al. Research on image retrieval algorithm based on combination of color and shape features. <em>J. Signal Process. Syst.</em><strong>93</strong>, 139–146 (2021).</cite> [<a href="https://scholar.google.com/scholar_lookup?Zenggang,%20X.%20et%20al.%20Research%20on%20image%20retrieval%20algorithm%20based%20on%20combination%20of%20color%20and%20shape%20features.%20J.%20Signal%20Process.%20Syst.93,%20139%E2%80%93146%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR39">
<span class="label">39.</span><cite>Priya, T. S. Resnet based feature extraction with decision tree classifier for classificaton of mammogram images. <em>Turkish J. Comput. &amp; Mathematics Edu. (TURCOMAT)</em><strong>12</strong>(2), 1147–1153 (2021).</cite> [<a href="https://scholar.google.com/scholar_lookup?Priya,%20T.%20S.%20Resnet%20based%20feature%20extraction%20with%20decision%20tree%20classifier%20for%20classificaton%20of%20mammogram%20images.%20Turkish%20J.%20Comput.%20&amp;%20Mathematics%20Edu.%20(TURCOMAT)12(2),%201147%E2%80%931153%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR40">
<span class="label">40.</span><cite>Cıbuk, M., Budak, U., Guo, Y., Ince, M. C. &amp; Sengur, A. Efficient deep features selections and classification for flower species recognition. <em>Measurement</em><strong>137</strong>, 7–13 (2019).</cite> [<a href="https://scholar.google.com/scholar_lookup?C%C4%B1buk,%20M.,%20Budak,%20U.,%20Guo,%20Y.,%20Ince,%20M.%20C.%20&amp;%20Sengur,%20A.%20Efficient%20deep%20features%20selections%20and%20classification%20for%20flower%20species%20recognition.%20Measurement137,%207%E2%80%9313%20(2019)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR41">
<span class="label">41.</span><cite><a href="https://www.kaggle.com/datasets/claytonteybauru/spiral-handpd/data" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/datasets/claytonteybauru/spiral-handpd/data</a></cite>
</li>
<li id="CR42">
<span class="label">42.</span><cite><a href="https://wwwp.fc.unesp.br/~papa/pub/datasets/Handpd/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://wwwp.fc.unesp.br/~papa/pub/datasets/Handpd/</a></cite>
</li>
<li id="CR43">
<span class="label">43.</span><cite>Wang, Z. &amp; Li, T. A lightweight CNN model based on GhostNet. <em>Comput. Intell. Neurosci.</em><strong>2022</strong>(1), 8396550 (2022).
</cite> [<a href="https://doi.org/10.1155/2022/8396550" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9357762/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35958795/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Wang,%20Z.%20&amp;%20Li,%20T.%20A%20lightweight%20CNN%20model%20based%20on%20GhostNet.%20Comput.%20Intell.%20Neurosci.2022(1),%208396550%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR44">
<span class="label">44.</span><cite>Ruba, M. T., Tamilselvi, R., Beham, M. P. &amp; Gayathri, M. Segmentation of a Brain Tumour using Modified LinkNet Architecture from MRI Images. <em>J. Innov. Image Process.</em><strong>5</strong>(2), 161–180 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Ruba,%20M.%20T.,%20Tamilselvi,%20R.,%20Beham,%20M.%20P.%20&amp;%20Gayathri,%20M.%20Segmentation%20of%20a%20Brain%20Tumour%20using%20Modified%20LinkNet%20Architecture%20from%20MRI%20Images.%20J.%20Innov.%20Image%20Process.5(2),%20161%E2%80%93180%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR45">
<span class="label">45.</span><cite>Gholamalinezhad, H., &amp; Khosravi, H. (2020). Pooling methods in deep neural networks, a review. <em>arXiv preprint </em><a href="http://arxiv.org/abs/2009.07485" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2009.07485</a>.</cite>
</li>
<li id="CR46">
<span class="label">46.</span><cite>Selvaraj, B., Rajasekar, E. &amp; Balaguru Rayappan, J. B. Machine learning approaches: Detecting the disease variants in human-exhaled breath biomarkers. <em>ACS Omega</em><strong>9</strong>(1), 215–226 (2023).
</cite> [<a href="https://doi.org/10.1021/acsomega.3c03755" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10785631/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38222575/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Selvaraj,%20B.,%20Rajasekar,%20E.%20&amp;%20Balaguru%20Rayappan,%20J.%20B.%20Machine%20learning%20approaches:%20Detecting%20the%20disease%20variants%20in%20human-exhaled%20breath%20biomarkers.%20ACS%20Omega9(1),%20215%E2%80%93226%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adda93_" lang="en" class="data-availability-statement"><h3 class="pmc_sec_title">Data Availability Statement</h3>
<p>The data underlying this article are available in the Kaggle repository named as HandPD dataset, at <a href="https://www.kaggle.com/datasets/claytonteybauru/spiral-handpd/data" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/datasets/claytonteybauru/spiral-handpd/data</a> and theMeander_HandPD images in HandPD dataset at <a href="https://wwwp.fc.unesp.br/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://wwwp.fc.unesp.br/</a> ~ papa/pub/datasets/Handpd/dataset, at <a href="https://www.kaggle.com/datasets/claytonteybauru/spiral-handpd/data" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/datasets/claytonteybauru/spiral-handpd/data</a> and theMeander_HandPD images in HandPD dataset at<a href="https://wwwp.fc.unesp.br/~papa/pub/datasets/Handpd/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://wwwp.fc.unesp.br/~papa/pub/datasets/Handpd/</a></p></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from Scientific Reports are provided here courtesy of <strong>Nature Publishing Group</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1038/s41598-025-12636-w"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/41598_2025_Article_12636.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (11.0 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12371065/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12371065/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12371065%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12371065/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12371065/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12371065/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40841807/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12371065/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40841807/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12371065/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12371065/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="aT2mX3pnm90HtFPb0rkaFI9O6PBGYKvuUvMSxDv3LqKbbWVprjpEY54WBr1qNaZp">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
    

    </body>
</html>
