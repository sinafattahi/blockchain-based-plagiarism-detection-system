
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            ”My AI is Lying to Me”: User-reported LLM hallucinations in AI mobile apps reviews - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="D2E4B34E8AF37D5305B34E00001987D1.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="scirep">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12365265/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="Scientific Reports">
<meta name="citation_title" content="”My AI is Lying to Me”: User-reported LLM hallucinations in AI mobile apps reviews">
<meta name="citation_author" content="Rhodes Massenon">
<meta name="citation_author_institution" content="Department of Software Engineering, Obafemi Awolowo University, Ile-Ife, Nigeria">
<meta name="citation_author" content="Ishaya Gambo">
<meta name="citation_author_institution" content="Department of Software Engineering, Obafemi Awolowo University, Ile-Ife, Nigeria">
<meta name="citation_author" content="Javed Ali Khan">
<meta name="citation_author_institution" content="Department of Computer Science, University of Hertfordshire, Hatfield, UK">
<meta name="citation_author" content="Christopher Agbonkhese">
<meta name="citation_author_institution" content="Department of Digital and Computational Studies, Bates College, Lewiston, ME 04240 USA">
<meta name="citation_author" content="Ayed Alwadain">
<meta name="citation_author_institution" content="Computer Science and Engineering Department, College of Applied Studies, King Saud University, Riyadh, 145111 Saudi Arabia">
<meta name="citation_publication_date" content="2025 Aug 19">
<meta name="citation_volume" content="15">
<meta name="citation_firstpage" content="30397">
<meta name="citation_doi" content="10.1038/s41598-025-15416-8">
<meta name="citation_pmid" content="40830185">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12365265/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12365265/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12365265/pdf/41598_2025_Article_15416.pdf">
<meta name="description" content="Large Language Models (LLMs) are increasingly integrated into AI-powered mobile applications, offering novel functionalities but also introducing the risk of “hallucinations” generating plausible yet incorrect or nonsensical information. These AI ...">
<meta name="og:title" content="”My AI is Lying to Me”: User-reported LLM hallucinations in AI mobile apps reviews">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="Large Language Models (LLMs) are increasingly integrated into AI-powered mobile applications, offering novel functionalities but also introducing the risk of “hallucinations” generating plausible yet incorrect or nonsensical information. These AI ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12365265/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12365265">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1038/s41598-025-15416-8"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/41598_2025_Article_15416.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12365265%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12365265/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12365265/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12365265/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-scirep.jpg" alt="Scientific Reports logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to Scientific Reports" title="Link to Scientific Reports" shape="default" href="http://www.nature.com/srep" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">Sci Rep</button></div>. 2025 Aug 19;15:30397. doi: <a href="https://doi.org/10.1038/s41598-025-15416-8" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1038/s41598-025-15416-8</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22Sci%20Rep%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sci%20Rep%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22Sci%20Rep%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22Sci%20Rep%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>”My AI is Lying to Me”: User-reported LLM hallucinations in AI mobile apps reviews</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Massenon%20R%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Rhodes Massenon</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Rhodes Massenon</span></h3>
<div class="p">
<sup>1</sup>Department of Software Engineering, Obafemi Awolowo University, Ile-Ife, Nigeria </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Massenon%20R%22%5BAuthor%5D" class="usa-link"><span class="name western">Rhodes Massenon</span></a>
</div>
</div>
<sup>1,</sup><sup>✉</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Gambo%20I%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Ishaya Gambo</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">Ishaya Gambo</span></h3>
<div class="p">
<sup>1</sup>Department of Software Engineering, Obafemi Awolowo University, Ile-Ife, Nigeria </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Gambo%20I%22%5BAuthor%5D" class="usa-link"><span class="name western">Ishaya Gambo</span></a>
</div>
</div>
<sup>1,</sup><sup>#</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Khan%20JA%22%5BAuthor%5D" class="usa-link" aria-describedby="id3"><span class="name western">Javed Ali Khan</span></a><div hidden="hidden" id="id3">
<h3><span class="name western">Javed Ali Khan</span></h3>
<div class="p">
<sup>2</sup>Department of Computer Science, University of Hertfordshire, Hatfield, UK </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Khan%20JA%22%5BAuthor%5D" class="usa-link"><span class="name western">Javed Ali Khan</span></a>
</div>
</div>
<sup>2,</sup><sup>#</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Agbonkhese%20C%22%5BAuthor%5D" class="usa-link" aria-describedby="id4"><span class="name western">Christopher Agbonkhese</span></a><div hidden="hidden" id="id4">
<h3><span class="name western">Christopher Agbonkhese</span></h3>
<div class="p">
<sup>3</sup>Department of Digital and Computational Studies, Bates College, Lewiston, ME 04240 USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Agbonkhese%20C%22%5BAuthor%5D" class="usa-link"><span class="name western">Christopher Agbonkhese</span></a>
</div>
</div>
<sup>3,</sup><sup>#</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Alwadain%20A%22%5BAuthor%5D" class="usa-link" aria-describedby="id5"><span class="name western">Ayed Alwadain</span></a><div hidden="hidden" id="id5">
<h3><span class="name western">Ayed Alwadain</span></h3>
<div class="p">
<sup>4</sup>Computer Science and Engineering Department, College of Applied Studies, King Saud University, Riyadh, 145111 Saudi Arabia </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Alwadain%20A%22%5BAuthor%5D" class="usa-link"><span class="name western">Ayed Alwadain</span></a>
</div>
</div>
<sup>4,</sup><sup>✉,</sup><sup>#</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="Aff1">
<sup>1</sup>Department of Software Engineering, Obafemi Awolowo University, Ile-Ife, Nigeria </div>
<div id="Aff2">
<sup>2</sup>Department of Computer Science, University of Hertfordshire, Hatfield, UK </div>
<div id="Aff3">
<sup>3</sup>Department of Digital and Computational Studies, Bates College, Lewiston, ME 04240 USA </div>
<div id="Aff4">
<sup>4</sup>Computer Science and Engineering Department, College of Applied Studies, King Saud University, Riyadh, 145111 Saudi Arabia </div>
<div class="author-notes p">
<div class="fn" id="_fncrsp93pmc__">
<sup>✉</sup><p class="display-inline">Corresponding author.</p>
</div>
<div class="fn" id="_eqcntrb93pmc__">
<sup>#</sup><p class="display-inline">Contributed equally.</p>
</div>
</div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2025 Jun 10; Accepted 2025 Aug 7; Collection date 2025.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© The Author(s) 2025</div>
<p><strong>Open Access</strong> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="https://creativecommons.org/licenses/by/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://creativecommons.org/licenses/by/4.0/</a>.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12365265  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40830185/" class="usa-link">40830185</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="Abs1"><h2>Abstract</h2>
<p id="Par1">Large Language Models (LLMs) are increasingly integrated into AI-powered mobile applications, offering novel functionalities but also introducing the risk of “hallucinations” generating plausible yet incorrect or nonsensical information. These AI errors can significantly degrade user experience and erode trust. However, there is limited empirical understanding of how users perceive, report, and are impacted by LLM hallucinations in real-world mobile app settings. This paper presents a large-scale empirical study analyzing  3 million user reviews from 90 diverse AI-powered mobile apps to characterize these user-reported issues. Using a mixed-methods approach, a heuristic-based User-Reported LLM Hallucination Detection algorithm were applied to identify  20,000 candidate reviews, from which 1,000 are manually annotated. This analysis estimates the prevalence of user reports indicative of LLM hallucinations, which was found to be approximately 1.75% within reviews initially flagged as relevant to AI errors. A data-driven taxonomy of seven user-perceived LLM hallucination types, were developed with Factual Incorrectness (H1) emerged as the most frequently reported type, accounting for 38% of instances, followed by Nonsensical/Irrelevant Output (H3) at 25%, and Fabricated Information (H2) at 15%. Furthermore, linguistic patterns were identified using N-grams generation, Non-Negative Matrix Factorization (NMF) topics and sentiment characteristics using VADER, showing significantly lower scores for hallucination reports associated with these reviews. These findings offer critical implications for software quality assurance, highlighting the need for targeted monitoring and mitigation strategies for AI mobile apps. This research provides a foundational, user-centric understanding of LLM hallucinations, paving the way for improved AI model development and more trustworthy mobile applications.</p>
<section id="kwd-group1" class="kwd-group"><p><strong>Subject terms:</strong> Information technology, Software</p></section></section><section id="Sec1"><h2 class="pmc_sec_title">Introduction</h2>
<p id="Par2">The proliferation of mobile applications integrating advanced Large Language Models (LLMs) has ushered in a new era of user interaction and functionality, ranging from ai chatbots and productivity assistants to creative content generation tools<sup><a href="#CR1" class="usa-link" aria-describedby="CR1">1</a>–<a href="#CR3" class="usa-link" aria-describedby="CR3">3</a></sup>. These AI-powered mobile apps like ChatGPT, Midjourney and Copilot promise to revolutionize user experiences by offering more intuitive, personalized, and intelligent services<sup><a href="#CR4" class="usa-link" aria-describedby="CR4">4</a>,<a href="#CR5" class="usa-link" aria-describedby="CR5">5</a></sup>. However, this rapid adoption is accompanied by a significant and persistent challenge inherent to current LLM technology: the phenomenon of “hallucination.” LLMs, despite their remarkable capabilities in generating fluent and coherent text, are prone to producing outputs that are factually incorrect, nonsensical, unfaithful to provided source content, or deviate from user intent, often with a high degree of apparent confidence<sup><a href="#CR6" class="usa-link" aria-describedby="CR6">6</a>–<a href="#CR9" class="usa-link" aria-describedby="CR9">9</a></sup>. As users increasingly interact with these AI mobile apps, their encounters with such erroneous outputs can lead to confusion, frustration, and a critical erosion of trust, sometimes prompting sentiments akin to “My AI is Lying to Me.”</p>
<p id="Par3">Understanding real-world user encounters with LLM hallucinations is crucial, particularly as evaluations conducted in controlled laboratory settings or using synthetic benchmarks may not fully capture the spectrum of issues or their nuanced impact on everyday users interacting with deployed mobile applications<sup><a href="#CR10" class="usa-link" aria-describedby="CR10">10</a>–<a href="#CR13" class="usa-link" aria-describedby="CR13">13</a></sup>. App store reviews, a readily available and voluminous source of unsolicited user feedback, offer a unique lens through which to observe these “in-the-wild” experiences<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a>–<a href="#CR18" class="usa-link" aria-describedby="CR18">18</a></sup>. These reviews can contain direct or indirect reports of AI misbehavior, reflecting genuine user pain points when LLM-generated content fails to meet expectations of accuracy, relevance, or coherence. From a software engineering perspective, LLM hallucinations are not merely an algorithmic quirk but represent a significant software quality and reliability challenge<sup><a href="#CR19" class="usa-link" aria-describedby="CR19">19</a>,<a href="#CR20" class="usa-link" aria-describedby="CR20">20</a></sup>. The integrity of information provided by AI mobile apps directly affects user satisfaction and the perceived value of the application, making the management of hallucinations a critical concern for developers<sup><a href="#CR21" class="usa-link" aria-describedby="CR21">21</a>,<a href="#CR22" class="usa-link" aria-describedby="CR22">22</a></sup>.</p>
<p id="Par4">The impact of LLM hallucinations on mobile users can be substantial. For instance, an AI travel planning app might generate incorrect flight details or recommend non-existent attractions<sup><a href="#CR23" class="usa-link" aria-describedby="CR23">23</a>,<a href="#CR24" class="usa-link" aria-describedby="CR24">24</a></sup>; a learning app could provide erroneous factual information; or a productivity tool might summarize a document with fabricated key points<sup><a href="#CR13" class="usa-link" aria-describedby="CR13">13</a>,<a href="#CR25" class="usa-link" aria-describedby="CR25">25</a></sup>. Such experiences can directly mislead users, lead to wasted time, cause frustration, and severely undermine their trust in the AI feature and the application as a whole<sup><a href="#CR26" class="usa-link" aria-describedby="CR26">26</a>,<a href="#CR27" class="usa-link" aria-describedby="CR27">27</a></sup>. Despite the acknowledgment of hallucination as a general LLM problem<sup><a href="#CR28" class="usa-link" aria-describedby="CR28">28</a>–<a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup>, there remains a significant gap in empirically characterizing how these issues manifest specifically within AI mobile apps and how users articulate these problems in their natural language feedback. Current understanding is often based on technical evaluations<sup><a href="#CR31" class="usa-link" aria-describedby="CR31">31</a>–<a href="#CR33" class="usa-link" aria-describedby="CR33">33</a></sup> or general surveys on LLM challenges<sup><a href="#CR19" class="usa-link" aria-describedby="CR19">19</a>,<a href="#CR34" class="usa-link" aria-describedby="CR34">34</a>–<a href="#CR37" class="usa-link" aria-describedby="CR37">37</a></sup>, rather than a focused analysis of user-generated reports from the mobile app ecosystem.</p>
<p id="Par5">Consequently, this study aims to bridge this gap by systematically analyzing user reviews from a diverse range of AI-powered mobile applications. Our primary goal is to understand and detect user-reported LLM hallucinations directly from their feedback. To achieve this, we address the following research questions: (RQ1) How prevalent are user reports potentially related to LLM hallucination in reviews of AI mobile apps? (RQ2) What types of LLM hallucination do users appear to report in their reviews? (RQ3) What characteristics do user reviews containing potential hallucination reports have? and (RQ4) What are the implications of user-reported hallucination for software quality assurance and the development of AI mobile apps?</p>
<p id="Par6">To address these questions, this paper makes the following contributions: first, it provides an estimation of the prevalence of user-reported issues indicative of LLM hallucinations across a diverse set of AI-powered mobile apps. Second, it introduces a novel, data-driven taxonomy categorizing the types of LLM hallucinations as perceived and described by mobile app users. Third, it presents an analysis of the linguistic patterns and sentiment characteristics associated with these hallucination reports. Finally, it discusses actionable implications for software engineering practices, particularly concerning the quality assurance, monitoring, and iterative improvement of AI-infused mobile applications.</p>
<p id="Par7">The remainder of this paper is structured as follows: Section 2 details the methodology employed for data collection and analysis. Section 3 presents the findings corresponding to each research question. Section 4 discusses the implications of these findings. Section 5 outlines the threats to the validity of this study. Section 6 reviews related work on LLM hallucinations and user feedback analysis. Finally, Section 7 concludes the paper and suggests avenues for future research.</p></section><section id="Sec2"><h2 class="pmc_sec_title">Methodology</h2>
<p id="Par8">This research employs an empirical, mixed-methods approach to understand and characterize user-reported LLM hallucinations in AI-powered mobile application reviews. The study’s goal is to systematically collect relevant user feedback, qualitatively derive a taxonomy of perceived hallucination types, and quantitatively analyze the prevalence and characteristics of these reports. This approach directly addresses the research questions concerning the prevalence of user-reported LLM hallucinations (RQ1), the types of hallucinations users report (RQ2), the characteristics of these reports (RQ3), and the implications for software quality assurance in AI mobile apps (RQ4). The overall research design, depicted conceptually in Fig. <a href="#Fig1" class="usa-link">1</a>, initiates with targeted data selection and collection, proceeds to an initial filtering stage to identify candidate reviews using a heuristic-based algorithm, followed by in-depth manual annotation for verification and taxonomy construction, and culminates in a quantitative characterization of the confirmed hallucination reports.</p>
<figure class="fig xbox font-sm" id="Fig1"><h3 class="obj_head">Fig. 1.</h3>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12365265_41598_2025_15416_Fig1_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8ee4/12365265/615f1dc1dade/41598_2025_15416_Fig1_HTML.jpg" loading="lazy" id="MO1" height="242" width="750" alt="Fig. 1"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Overview of the research design</p></figcaption></figure><section id="Sec3"><h3 class="pmc_sec_title">Data selection and collection</h3>
<p id="Par9">The initial stage focuses on systematically gathering a corpus of user reviews from a diverse range of AI-powered mobile applications. App selection targets AI applications available on the Google Play Store and Apple App Store that prominently integrate significant LLM or generative AI functionalities. A total of 90 AI mobile apps are selected across ten categories where such AI features are prevalent, including General Chatbots, Generative AI Tools, and General Virtual Assistants. Inclusion criteria for apps include a substantial volume of user reviews at least 10,000 total to ensure a sufficient feedback pool, and evidence of AI feature integration. Automated web scraping techniques, utilizing Python libraries such as Selenium and BeautifulSoup, are employed to collect review text, associated star ratings, and review timestamps for the selected apps. The collection period focuses on recent reviews between January 2022 - December 2024 to reflect current AI capabilities. Following raw data collection, an initial filtering strategy is applied to enrich the dataset with reviews more likely to pertain to AI performance and potential errors. This strategy involves the following two main steps.</p>
<p id="Par10">Firstly, an AI context filtering step scans reviews for keywords indicating user interaction with or reference to AI features. This list includes general terms like “AI,” “bot,” “chatbot,” “assistant,” “generated,” “response,” “answer,” “suggestion,” as well as terms specific to generative AI outputs such as “image created,” “image generated,” “music composed,” “video edit,” “avatar looks,” “rewritten text,” “summarize text,” and “voice sounds.” This step reduced the dataset to approximately 350,000 potentially relevant reviews. This further refined the dataset to approximately 20,000 reviews, as outlined in Table <a href="#Tab1" class="usa-link">1</a>. Secondly, a hallucination keyword filtering step searches the AI-context-filtered reviews using a curated dictionary of keywords, phrases. This dictionary presented conceptually in Table <a href="#Tab2" class="usa-link">2</a>, includes terms related to factual incorrectness, nonsensical output, fabrication, logical inconsistency, and direct user expressions of confusion or distrust regarding AI outputs.</p>
<section class="tw xbox font-sm" id="Tab1"><h4 class="obj_head">Table 1.</h4>
<div class="caption p"><p>Characteristics of the analyzed AI mobile app review dataset.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Metric</th>
<th align="left" colspan="1" rowspan="1">Value</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Number of Unique AI Mobile Apps Analyzed</td>
<td align="left" colspan="1" rowspan="1">90</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">App Categories Represented</td>
<td align="left" colspan="1" rowspan="1">10 (Chatbots, AI Image, AI Music, etc.)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Total User Reviews Collected (Pre-Filter)</td>
<td align="left" colspan="1" rowspan="1"> 3,000,000</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Time Period of Reviews</td>
<td align="left" colspan="1" rowspan="1">Jan 2022 - Dec 2024</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Reviews After AI Context Keyword Filter</td>
<td align="left" colspan="1" rowspan="1"> 350,000</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Reviews After Hallucination Keyword Filter</td>
<td align="left" colspan="1" rowspan="1"> 20,000</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><section class="tw xbox font-sm" id="Tab2"><h4 class="obj_head">Table 2.</h4>
<div class="caption p"><p>Curated dictionary of LLM Hallucination keywords.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Hallucination Type</th>
<th align="left" colspan="1" rowspan="1">Hallucination-Indicative Terms/ Phrases</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Factual Incorrectness</td>
<td align="left" colspan="1" rowspan="1">“wrong info,” “incorrect fact,” “not true,” “false statement,” “misinformation.”</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Nonsensical/Irrelevant Output</td>
<td align="left" colspan="1" rowspan="1">“makes no sense,” “gibberish,” “random answer,” “irrelevant,” “off-topic.”</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Fabrication Information/Invention</td>
<td align="left" colspan="1" rowspan="1">“made up,” “invented this,” “fabricated,” “didn’t happen.”</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Logical Inconsistency</td>
<td align="left" colspan="1" rowspan="1">“contradicts itself,” “doesn’t add up,” “illogical.”</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">User Confusion/Distrust</td>
<td align="left" colspan="1" rowspan="1">“AI is confused,” “bot is lying,” “can’t trust this.”</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="Sec4"><h3 class="pmc_sec_title">Identifying and annotating hallucination reports</h3>
<p id="Par11">The filtered dataset of approximately 20,000 reviews, identified as having a higher likelihood of containing reports related to LLM performance issues, undergoes a systematic multi-phase analysis to identify, categorize, and characterize instances of user-reported LLM hallucinations.</p>
<section id="Sec5"><h4 class="pmc_sec_title">Manual annotation and verification</h4>
<p id="Par12">The selected 1,000 candidate reviews are subjected to in-depth manual qualitative analysis by two researchers. To ensure representative coverage, stratified random sampling is employed: the 1,000 candidates are first divided into strata based on their primary app category (e.g., Chatbot, AI Image Generator, Productivity). A proportional number of reviews is then randomly selected from each stratum for annotation. For each review, annotators determine: (a) if it contains a clear report of an LLM hallucination (Yes/No); (b) the specific claim/output perceived as a hallucination; and (c) its category based on an emergent taxonomy. An iterative qualitative coding process as depicted in Fig. <a href="#Fig2" class="usa-link">2</a> is used: initial open coding to identify initial themes related to AI errors, followed by focused coding to refine categories of perceived hallucinations. The codebook and taxonomy categories are refined until theoretical saturation is achieved, and strong inter-rater reliability of Cohen’s Kappa <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq1"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8ee4/12365265/24c50dfb2a52/d33e449.gif" loading="lazy" id="d33e449" alt="Inline graphic"></span> 0.75 is established on a commonly coded subset of reviews.</p>
<figure class="fig xbox font-sm" id="Fig2"><h5 class="obj_head">Fig. 2.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12365265_41598_2025_15416_Fig2_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8ee4/12365265/fd3d338c8d4d/41598_2025_15416_Fig2_HTML.jpg" loading="lazy" id="MO2" height="317" width="750" alt="Fig. 2"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Annotation and verification process.</p></figcaption></figure></section><section id="Sec6"><h4 class="pmc_sec_title">User-reported LLM hallucinations detection algorithm</h4>
<p id="Par13">To efficiently identify strong candidates for manual annotation from the 20,000 filtered reviews, a heuristic-based prioritization algorithm, detailed in Algorithm 1, was applied. The core of this algorithm is to compute a composite Relevance_Score for each review by integrating signals from multiple unsupervised techniques. This strategy is not designed to be a perfect detector, but rather a method to systematically enrich the sample with reviews that are highly likely to contain hallucination reports, thereby making the manual annotation process more effective. The algorithm works by combining the following components:</p>
<ul class="list" style="list-style-type:disc">
<li><p id="Par14"><strong>Preprocessing:</strong> Each review first undergoes standard text cleaning procedures. This includes removing special characters, normalizing inconsistent whitespace, and converting text to lowercase to ensure uniformity. The cleaned text is then segmented into individual sentences, which allows for more granular analysis in the subsequent steps.</p></li>
<li><p id="Par15"><strong>Keyword and N-gram Scoring:</strong> The algorithm scans each sentence for the co-occurrence of terms from two distinct dictionaries: the AI Context Dictionary (e.g., “AI,” “bot,” “assistant”) and the Hallucination Indicators Dictionary (e.g., “wrong fact,” “made this up,” “nonsense,” as shown in Table <a href="#Tab2" class="usa-link">2</a>). A review’s Relevance_Score is incremented each time a sentence contains terms from <em>both</em> dictionaries. The rationale is that reviews discussing AI features while simultaneously using the language of falsehood or confusion are the strongest initial candidates for containing a hallucination report.</p></li>
<li><p id="Par16"><strong>Thematic Relevance Scoring (NMF):</strong> This component is designed to capture relevant reviews that may not use our exact keywords but are semantically related to the concept of hallucination. The process has two stages. First, Non-Negative Matrix Factorization (NMF) is applied to the entire 20,000-review corpus to discover a set of latent topics. We then manually inspect these topics and identify the indices of those whose top-ranking words are clearly aligned with themes of incorrectness, fabrication, or nonsensical output. Second, for each individual review, the algorithm calculates the review’s thematic distribution (i.e., its loading score for each topic). The Relevance_Score is then increased in proportion to the review’s loading on the pre-identified “hallucination-related” topics.</p></li>
<li><p id="Par17"><strong>Sentiment Contribution (VADER):</strong> To leverage the emotional content of the feedback, Valence Aware Dictionary and sEntiment Reasoner (VADER) is used to calculate a compound sentiment score for each review (ranging from -1 for most negative to +1 for most positive). If a review’s sentiment score is strongly negative (e.g., below -0.05), its absolute value is multiplied by a weight and added to the Relevance_Score. This ensures that more intensely negative reviews, which often detail significant user frustration, contribute more heavily to their ranking as a potential hallucination report.</p></li>
<li><p id="Par18"><strong>Low Rating Amplifier:</strong> This component acts as a powerful confidence booster. A low star rating (e.g., 1 or 2 stars) on its own is a noisy signal, but it becomes highly informative when combined with other indicators. The algorithm applies a conditional bonus: if a review has a low star rating <em>and</em> has already been flagged by the keyword or NMF components, it receives an additional, significant boost to its Relevance_Score. This helps to prioritize reviews where the user’s explicit rating corroborates the negative textual feedback.</p></li>
</ul>
<p>Finally, all 20,000 reviews are ranked in descending order based on their final composite Relevance_Score. The top-ranked 1,000 reviews are then selected as the high-priority candidate set for the in-depth manual annotation and taxonomy construction.</p></section></section><section id="Sec7"><h3 class="pmc_sec_title">Analysis and taxonomy construction</h3>
<p id="Par19">Through review of academic definitions, known types, and technical evaluation methods for LLM hallucinations from the literature review, codes are refined, grouped, and abstracted to develop a hierarchical taxonomy of user-reported LLM hallucination types. If a hallucination is confirmed, classify it according to the hierarchical taxonomy of user-reported LLM hallucination types. The types of hallucinations identified through this process are categorized in Table <a href="#Tab3" class="usa-link">3</a>. Categories might include, for example, Factual Incorrectness, Nonsensical/Irrelevant Output, Object/Attribute Fabrication (for generative AI), Logical Inconsistency, Persona/Role Inconsistency, or Unwanted/Harmful Generation.</p>
<section class="tw xbox font-sm" id="Tab3"><h4 class="obj_head">Table 3.</h4>
<div class="caption p"><p>Taxonomy of user-reported LLM hallucinations in AI mobile apps.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Category ID</th>
<th align="left" colspan="1" rowspan="1">Hallucination Type</th>
<th align="left" colspan="1" rowspan="1">Definition</th>
<th align="left" colspan="1" rowspan="1">Anonymized Example from User Review</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">H1</td>
<td align="left" colspan="1" rowspan="1">Factual Incorrectness</td>
<td align="left" colspan="1" rowspan="1">LLM provides information that is verifiably false or contradicts established facts relevant to the app’s domain or general knowledge.</td>
<td align="left" colspan="1" rowspan="1">“The AI travel guide said Paris is the capital of England. That’s just wrong!”</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">H2</td>
<td align="left" colspan="1" rowspan="1">Fabricated Information / Invention</td>
<td align="left" colspan="1" rowspan="1">LLM generates details, entities, features, or sources that are entirely non-existent or not present within the app’s context or reality.</td>
<td align="left" colspan="1" rowspan="1">“My AI recipe app invented a spice called ’solar-salt’ for a simple pasta dish.”</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">H3</td>
<td align="left" colspan="1" rowspan="1">Nonsensical / Irrelevant Output</td>
<td align="left" colspan="1" rowspan="1">LLM produces responses that are grammatically sound but semantically meaningless, incoherent, repetitive, or completely off-topic to the user’s query or interaction.</td>
<td align="left" colspan="1" rowspan="1">“I asked the AI story generator for a sci-fi plot and it just gave me a list of farm animals.”</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">H4</td>
<td align="left" colspan="1" rowspan="1">Logical Inconsistency / Self-Contradiction</td>
<td align="left" colspan="1" rowspan="1">LLM’s output contains statements that contradict each other within the same response, across a short conversational turn, or demonstrates clearly flawed reasoning.</td>
<td align="left" colspan="1" rowspan="1">“The AI first told me the event was on Saturday, then later insisted it was on Tuesday.”</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">H5</td>
<td align="left" colspan="1" rowspan="1">Persona Deviation / Role Inconsistency</td>
<td align="left" colspan="1" rowspan="1">The AI’s responses deviate significantly from its established persona, intended role within the app, or the expected tone, potentially using inappropriate or unexpected language.</td>
<td align="left" colspan="1" rowspan="1">“The professional AI assistant for my work app suddenly started using slang and emojis.”</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">H6</td>
<td align="left" colspan="1" rowspan="1">Visual Fabrication (Generative AI)</td>
<td align="left" colspan="1" rowspan="1">Specific to generative AI tools (e.g., image, avatar generators), where the output contains elements that are physically impossible, bizarrely malformed, or violate common sense visual constraints.</td>
<td align="left" colspan="1" rowspan="1">“The AI avatar creator gave my character three hands and a floating hat. Looked ridiculous.”</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">H7</td>
<td align="left" colspan="1" rowspan="1">Repetitive Output (Non-functional)</td>
<td align="left" colspan="1" rowspan="1">LLM gets stuck in a loop, repeating the same phrase, sentence, or set of characters nonsensically and without progression, often indicating a failure state.</td>
<td align="left" colspan="1" rowspan="1">“When the AI got confused, it just kept typing ’hello hello hello hello’ endlessly.”</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="Sec8"><h3 class="pmc_sec_title">Method evaluation</h3>
<p id="Par20">The primary contribution of this paper is the qualitative analysis and characterization of user-reported hallucinations. However, to conduct this analysis on a large dataset of 3 million reviews, a systematic and effective filtering strategy is a methodological necessity. The performance of our heuristic-based candidate identification algorithm is therefore evaluated not as a standalone contribution, but to demonstrate the validity and rigor of our sampling process. This evaluation quantifies the algorithm’s ability to create a manageable and enriched subset of candidate reviews for the labor-intensive manual annotation, ensuring that our qualitative findings are drawn from a relevant and representative sample. To this end, we use three standard metrics to assess the effectiveness of the filtering method on the 1,000 manually annotated reviews.</p>
<ul class="list" style="list-style-type:disc">
<li><div class="p" id="Par21">
<strong>Precision</strong> measures the proportion of reviews flagged by the algorithm that were actual, confirmed hallucination reports. A high precision indicates that the algorithm is efficient, reducing the manual effort spent on irrelevant reviews. It is calculated as: <table class="disp-formula p" id="Equ1"><tr><td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8ee4/12365265/7ce3bd42d17a/d33e537.gif" loading="lazy" id="d33e537" alt="graphic file with name d33e537.gif"></td></tr></table>
</div></li>
<li><div class="p" id="Par22">
<strong>Recall</strong> measures the proportion of all confirmed hallucination reports in the sample that were successfully identified by the algorithm. A high recall indicates that the algorithm is comprehensive, minimizing the number of relevant reports missed during the filtering stage. It is calculated as: <table class="disp-formula p" id="Equ2"><tr><td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8ee4/12365265/c0caae5b5cf8/d33e547.gif" loading="lazy" id="d33e547" alt="graphic file with name d33e547.gif"></td></tr></table>
</div></li>
<li><div class="p" id="Par23">
<strong>F1-Score</strong> provides the harmonic mean of Precision and Recall, offering a single, balanced measure of the algorithm’s overall effectiveness. It is crucial for understanding the trade-off between identifying as many reports as possible (Recall) and ensuring that the identified reports are relevant (Precision). It is calculated as: <table class="disp-formula p" id="Equ3"><tr><td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8ee4/12365265/2f8a413f189a/d33e557.gif" loading="lazy" id="d33e557" alt="graphic file with name d33e557.gif"></td></tr></table>
</div></li>
</ul>
<p>The results of this evaluation, presented in Section 3, serve to validate that the subset of reviews chosen for our in-depth qualitative analysis is not arbitrary but is systematically and effectively curated, thereby strengthening the confidence in the taxonomy and characteristics derived from it.</p>
<figure class="fig xbox font-sm" id="Figa"><h4 class="obj_head">Algorithm 1.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12365265_41598_2025_15416_Figa_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8ee4/12365265/02c92f41b8cf/41598_2025_15416_Figa_HTML.jpg" loading="lazy" id="MO3" height="935" width="789" alt="Algorithm 1"></a></p>
<div class="p text-right font-secondary"><a href="figure/Figa/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>User-reported LLM hallucination candidate prioritization.</p></figcaption></figure></section></section><section id="Sec9"><h2 class="pmc_sec_title">Results</h2>
<p id="Par25">This section presents the empirical findings derived from the analysis of user reviews collected from AI-powered mobile applications. The results are structured to directly address the research questions concerning the prevalence of user-reported LLM hallucinations (RQ1), the types of hallucinations observed (RQ2), and the characteristics of the reviews containing these reports (RQ3).</p>
<section id="Sec10"><h3 class="pmc_sec_title">RQ1: Prevalence of user-reported LLM hallucinations</h3>
<p id="Par26">To address the first research question (RQ1: How prevalent are user reports potentially related to LLM hallucination in reviews of AI mobile apps?), we analyzed the manually annotated sample of 1,000 candidate reviews that were prioritized by our User-Reported LLM Hallucination detection algorithm. From this set, a total of 350 reviews were confirmed by human annotators to contain clear reports indicative of LLM hallucinations. Considering this sample was drawn from the  20,000 reviews that passed the initial keyword filtering for potential hallucination indicators, this suggests that approximately 1.75% of reviews initially flagged as highly relevant to AI errors indeed describe user-perceived LLM hallucinations. While this percentage is relative to the filtered set, it provides an initial estimate of the discernibility of such reports within targeted user feedback.</p>
<p id="Par27">Table <a href="#Tab4" class="usa-link">4</a> presents a breakdown of the number of apps analyzed per category and the proportion of the 1,000 manually annotated reviews that were confirmed to contain hallucination reports within each category. This allows for an initial view of potential variations in reporting prevalence across different types of AI mobile applications. The “Generative AI Tools” category, for instance, showed a higher proportion of reviews with confirmed hallucination reports compared to “General Chatbots,” suggesting that applications directly involved in content creation might elicit more user scrutiny regarding output factuality or coherence. Figure <a href="#Fig3" class="usa-link">3</a> visualizes these categorical proportions, providing a comparative overview.</p>
<section class="tw xbox font-sm" id="Tab4"><h4 class="obj_head">Table 4.</h4>
<div class="caption p"><p>Prevalence of confirmed hallucination reports.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">App Category</th>
<th align="left" colspan="1" rowspan="1"># Apps in Sample</th>
<th align="left" colspan="1" rowspan="1"># Annotated Reviews from Category</th>
<th align="left" colspan="1" rowspan="1"># Confirmed Hallucination Reports</th>
<th align="left" colspan="1" rowspan="1">% of Category Sample with Hallucinations</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">General Chatbots</td>
<td align="left" colspan="1" rowspan="1">20</td>
<td align="left" colspan="1" rowspan="1">250</td>
<td align="left" colspan="1" rowspan="1">75</td>
<td align="left" colspan="1" rowspan="1">30.0%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Generative AI Tools</td>
<td align="left" colspan="1" rowspan="1">25</td>
<td align="left" colspan="1" rowspan="1">300</td>
<td align="left" colspan="1" rowspan="1">120</td>
<td align="left" colspan="1" rowspan="1">40.0%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">AI Assistants</td>
<td align="left" colspan="1" rowspan="1">15</td>
<td align="left" colspan="1" rowspan="1">150</td>
<td align="left" colspan="1" rowspan="1">45</td>
<td align="left" colspan="1" rowspan="1">30.0%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">AI Educational</td>
<td align="left" colspan="1" rowspan="1">15</td>
<td align="left" colspan="1" rowspan="1">150</td>
<td align="left" colspan="1" rowspan="1">60</td>
<td align="left" colspan="1" rowspan="1">40.0%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Other AI apps</td>
<td align="left" colspan="1" rowspan="1">15</td>
<td align="left" colspan="1" rowspan="1">150</td>
<td align="left" colspan="1" rowspan="1">50</td>
<td align="left" colspan="1" rowspan="1">33.3%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Total / Weighted Avg.</td>
<td align="left" colspan="1" rowspan="1">90</td>
<td align="left" colspan="1" rowspan="1">1,000</td>
<td align="left" colspan="1" rowspan="1">350</td>
<td align="left" colspan="1" rowspan="1">35.0%</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><figure class="fig xbox font-sm" id="Fig3"><h4 class="obj_head">Fig. 3.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12365265_41598_2025_15416_Fig3_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8ee4/12365265/b311386b1809/41598_2025_15416_Fig3_HTML.jpg" loading="lazy" id="MO4" height="389" width="708" alt="Fig. 3"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Prevalence of user-reported LLM hallucinations across app categories.</p></figcaption></figure></section><section id="Sec11"><h3 class="pmc_sec_title">RQ2: Types of user-reported LLM hallucinations</h3>
<p id="Par29">To address RQ2 (<em>What types of LLM hallucination do users appear to report in their reviews?</em>), the 350 manually confirmed hallucination reports were categorized according to the taxonomy developed and defined in Table <a href="#Tab3" class="usa-link">3</a>. This user-derived classification scheme is crucial as it captures how end-users perceive and articulate different manifestations of AI errors that align with the concept of hallucination, providing a more practical perspective than purely technical classifications. Table <a href="#Tab5" class="usa-link">5</a> provides concrete examples that illustrate the annotation criteria applied.</p>
<section class="tw xbox font-sm" id="Tab5"><h4 class="obj_head">Table 5.</h4>
<div class="caption p"><p>Sample annotated instances across the assigned hallucination type.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Review ID</th>
<th align="left" colspan="1" rowspan="1">Candidate Review Snippet</th>
<th align="left" colspan="1" rowspan="1">AI Context Confirmed?</th>
<th align="left" colspan="1" rowspan="1">Halluc. Report? (Yes/No)</th>
<th align="left" colspan="1" rowspan="1">User’s Description of Hallucination</th>
<th align="left" colspan="1" rowspan="1">Assigned Halluc. Type (from Taxonomy)</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">REV001</td>
<td align="left" colspan="1" rowspan="1">“The AI chatbot gave me completely wrong historical dates.”</td>
<td align="left" colspan="1" rowspan="1">Yes (chatbot)</td>
<td align="left" colspan="1" rowspan="1">Yes</td>
<td align="left" colspan="1" rowspan="1">“wrong historical dates”</td>
<td align="left" colspan="1" rowspan="1">Factual Incorrectness</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">REV002</td>
<td align="left" colspan="1" rowspan="1">“Asked the AI to write a poem, and it just repeated ’cat’ 10 times.”</td>
<td align="left" colspan="1" rowspan="1">Yes (AI write)</td>
<td align="left" colspan="1" rowspan="1">Yes</td>
<td align="left" colspan="1" rowspan="1">“repeated ’cat’ 10 times”</td>
<td align="left" colspan="1" rowspan="1">Nonsensical Output</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">REV003</td>
<td align="left" colspan="1" rowspan="1">“This app is slow and crashes often. The AI feature is okay.”</td>
<td align="left" colspan="1" rowspan="1">Yes (AI feature)</td>
<td align="left" colspan="1" rowspan="1">No</td>
<td align="left" colspan="1" rowspan="1">(Complains about general bugs, not specifically AI content error)</td>
<td align="left" colspan="1" rowspan="1">N/A</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">REV004</td>
<td align="left" colspan="1" rowspan="1">“The AI image generator made a dog with five legs, so weird!”</td>
<td align="left" colspan="1" rowspan="1">Yes (AI image gen)</td>
<td align="left" colspan="1" rowspan="1">Yes</td>
<td align="left" colspan="1" rowspan="1">“dog with five legs”</td>
<td align="left" colspan="1" rowspan="1">Fabrication Information</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab5/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p id="Par30">The distribution of the 350 reports across the seven taxonomy categories, visualized in Fig. <a href="#Fig4" class="usa-link">4</a>, reveals a clear hierarchy of user concerns. The analysis shows that <strong>Factual Incorrectness (H1)</strong> is the most prevalent issue, constituting a significant <strong>38%</strong> of all identified hallucination reports. These reports typically involved the LLM providing verifiably false information in response to direct user queries. Users reported a wide spectrum of errors, from incorrect historical dates and biographical details in educational apps to wrong addresses or product specifications in productivity tools. This high frequency underscores that users often interact with AI assistants as knowledge retrieval engines and are quick to identify and report when the provided ‘facts’ are demonstrably erroneous.</p>
<figure class="fig xbox font-sm" id="Fig4"><h4 class="obj_head">Fig. 4.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12365265_41598_2025_15416_Fig4_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8ee4/12365265/00b30df39cb4/41598_2025_15416_Fig4_HTML.jpg" loading="lazy" id="MO5" height="325" width="625" alt="Fig. 4"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Distribution of identified user-reported LLM hallucination types.</p></figcaption></figure><p id="Par31">Following this, <strong>Nonsensical/Irrelevant Output (H3)</strong> was the second most common category, accounting for <strong>25%</strong> of cases. In these instances, users described the AI generating responses that, while often grammatically correct, were semantically meaningless, logically incoherent, or completely off-topic to the user’s prompt. This category represents a fundamental failure in the AI’s ability to maintain a relevant conversational context. The third most common category was <strong>Fabricated Information (H2)</strong> at <strong>15%</strong>. While closely related to factual errors, these reports were distinct in that users perceived the AI as actively ‘inventing’ or ‘making up’ details, such as citing non-existent sources, describing fictional product features, or referencing imaginary people. The combination of these top three categories accounts for over three-quarters (78%) of all reports, indicating that the core of user frustration with LLM hallucinations stems from a fundamental breakdown in reliability, coherence, and truthfulness.</p>
<p id="Par32">The remaining categories, though less frequent, highlight more nuanced aspects of AI failure. <strong>Logical Inconsistency / Self-Contradiction (H4)</strong> and <strong>Repetitive Output (H7)</strong> often pointed to deeper model failures where the AI either lost its conversational state, providing contradictory information within a single response, or entered a non-functional failure loop. Notably, <strong>Visual Fabrication (H6)</strong>, which included reports of bizarrely malformed objects like characters with extra limbs or impossible geometry, was a category-specific type of hallucination found exclusively in reviews for generative AI image and avatar applications. Similarly, <strong>Persona Deviation / Role Inconsistency (H5)</strong> captured a unique user experience issue reported for conversational AIs, where users noted jarring shifts in tone or persona (e.g., a professional assistant using overly casual slang) that broke the application’s expected interaction model.</p>
<p id="Par33">Overall, this detailed distribution provides a clear, user-grounded map of how LLM hallucinations manifest in the wild. It demonstrates that while technical definitions of hallucination can be broad, users are primarily sensitive to tangible failures in factuality and logical consistency, offering a clear set of priorities for developers and quality assurance teams aiming to improve user trust.</p></section><section id="Sec12"><h3 class="pmc_sec_title">RQ3: Characteristics of reviews reporting hallucinations</h3>
<p id="Par35">To address RQ3 (What characteristics do user reviews containing potential hallucination reports have?), we analyzed the linguistic patterns and sentiment of the 350 confirmed hallucination reports, and their association with review star ratings.</p>
<p id="Par36">N-gram analysis was performed on the text of hallucination reports to identify frequently occurring unigrams, bigrams, and trigrams that users employ when describing these AI errors. Table <a href="#Tab6" class="usa-link">6</a> lists some of the top distinctive N-grams. Phrases like “wrong information,” “made this up,” “no sense at all,” and “AI is incorrect” were significantly more frequent in hallucination reports compared to general AI-related reviews without such error reports. Topic modeling using Non-Negative Matrix Factorization (NMF) on the hallucination reports revealed 5-7 distinct latent themes. Table <a href="#Tab7" class="usa-link">7</a> presents these NMF-derived topics, their top keywords, and an illustrative review snippet.</p>
<section class="tw xbox font-sm" id="Tab6"><h4 class="obj_head">Table 6.</h4>
<div class="caption p"><p>Top differentiating N-grams in hallucination reports.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">N-gram Type</th>
<th align="left" colspan="1" rowspan="1">N-gram</th>
<th align="left" colspan="1" rowspan="1">Frequency in Hallucination Reports</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Unigram</td>
<td align="left" colspan="1" rowspan="1">Wrong</td>
<td align="left" colspan="1" rowspan="1">150</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Unigram</td>
<td align="left" colspan="1" rowspan="1">Incorrect</td>
<td align="left" colspan="1" rowspan="1">120</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Unigram</td>
<td align="left" colspan="1" rowspan="1">False</td>
<td align="left" colspan="1" rowspan="1">95</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Bigram</td>
<td align="left" colspan="1" rowspan="1">Made up</td>
<td align="left" colspan="1" rowspan="1">70</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Bigram</td>
<td align="left" colspan="1" rowspan="1">No sense</td>
<td align="left" colspan="1" rowspan="1">65</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Bigram</td>
<td align="left" colspan="1" rowspan="1">Wrong answer</td>
<td align="left" colspan="1" rowspan="1">60</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Trigram</td>
<td align="left" colspan="1" rowspan="1">AI gave wrong</td>
<td align="left" colspan="1" rowspan="1">40</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Trigram</td>
<td align="left" colspan="1" rowspan="1">Doesn’t make sense</td>
<td align="left" colspan="1" rowspan="1">35</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Trigram</td>
<td align="left" colspan="1" rowspan="1">Completely made up</td>
<td align="left" colspan="1" rowspan="1">30</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab6/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><section class="tw xbox font-sm" id="Tab7"><h4 class="obj_head">Table 7.</h4>
<div class="caption p"><p>NMF-derived topics from hallucination reports with example keywords.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Topic ID</th>
<th align="left" colspan="1" rowspan="1">Top Keywords</th>
<th align="left" colspan="1" rowspan="1">Review Snippet</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Topic 1</td>
<td align="left" colspan="1" rowspan="1">Wrong, information, fact, answer, incorrect</td>
<td align="left" colspan="1" rowspan="1">“The AI provided completely wrong information about the event date.”</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Topic 2</td>
<td align="left" colspan="1" rowspan="1">Nonsense, random, gibberish, irrelevant, off-topic</td>
<td align="left" colspan="1" rowspan="1">“Its response was just random words, total nonsense.”</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Topic 3</td>
<td align="left" colspan="1" rowspan="1">Made up, invented, fabricated, lie, not real</td>
<td align="left" colspan="1" rowspan="1">“I think the AI just made up that story, I can’t find it anywhere.”</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Topic 4</td>
<td align="left" colspan="1" rowspan="1">Confusing, illogical, contradicts, doesn’t follow</td>
<td align="left" colspan="1" rowspan="1">“The bot’s explanation was illogical and contradicted what it said earlier.”</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab7/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p id="Par37">VADER sentiment analysis was applied to the specific review snippets describing hallucinations and to the overall reviews containing these snippets. Figure <a href="#Fig5" class="usa-link">5</a> illustrates the distribution of VADER compound sentiment scores. Snippets describing hallucinations had a significantly lower average compound score (-0.65) compared to the average compound score of the full reviews they originated from (-0.40), and markedly lower than general AI-related reviews not reporting hallucinations (+0.15). A large proportion (85%) of hallucination-reporting snippets exhibited strong negative sentiment.</p>
<figure class="fig xbox font-sm" id="Fig5"><h4 class="obj_head">Fig. 5.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12365265_41598_2025_15416_Fig5_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8ee4/12365265/8ae8e941ea46/41598_2025_15416_Fig5_HTML.jpg" loading="lazy" id="MO6" height="428" width="678" alt="Fig. 5"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig5/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Sentiment score distribution for hallucination reviews vs. overall reviews.</p></figcaption></figure><p id="Par39">The analysis of star ratings, presented in Fig. <a href="#Fig6" class="usa-link">6</a>, shows a clear association between reported LLM hallucinations and user dissatisfaction. Reviews containing confirmed hallucination reports had a significantly lower average star rating (mean of 1.8 stars) compared to reviews that mentioned AI features but did not report hallucinations (mean of 3.5 stars) and the overall average rating for the studied apps (3.9 stars). This quantitative link underscores the negative impact of perceived AI errors on user ratings.</p>
<figure class="fig xbox font-sm" id="Fig6"><h4 class="obj_head">Fig. 6.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12365265_41598_2025_15416_Fig6_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8ee4/12365265/12bf64d5a1b0/41598_2025_15416_Fig6_HTML.jpg" loading="lazy" id="MO7" height="438" width="619" alt="Fig. 6"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig6/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Comparison of star ratings for reviews with vs. without hallucination reports.</p></figcaption></figure></section><section id="Sec13"><h3 class="pmc_sec_title">Method performance</h3>
<p id="Par40">The effectiveness of the heuristic-based candidate identification algorithm (described in Section 2.2.1), which combines keyword/N-gram matching and NMF-derived thematic relevance to prioritize reviews for manual annotation, was evaluated against the 1,000 manually labeled candidate reviews. Table <a href="#Tab8" class="usa-link">8</a> presents the Precision, Recall, and F1-score for this initial filtering stage’s ability to correctly identify reviews that genuinely contain reports of LLM hallucinations (True Positives) from the broader set of initially flagged candidate reviews. Table 9 presents these metrics, calculated based on the 1,000 manually labeled candidate reviews. The algorithm achieved a Precision of 0.65, indicating that 65% of the reviews it prioritized for analysis were indeed confirmed to contain hallucination reports. This demonstrates a reasonable efficiency in concentrating relevant data. More critically, the Recall of 0.78 suggests that our method successfully identified 78% of all confirmed hallucination reports present within the initial 1,000-review candidate pool. This high recall provides confidence that our subsequent qualitative analysis and taxonomy construction were performed on a sample that is largely representative of the diverse hallucination types present in the data, thereby reducing the risk of missing significant categories of user-reported issues. The F1-Score of 0.71 provides a balanced measure of this performance, confirming that the heuristic approach is a valid and effective tool for constructing a high-quality sample for in-depth qualitative study. While not perfect, this performance demonstrates the utility of the combined heuristic approach in significantly enriching the sample for manual analysis, reducing the effort compared to randomly sampling from the much larger pool of initially filtered reviews.</p>
<section class="tw xbox font-sm" id="Tab8"><h4 class="obj_head">Table 8.</h4>
<div class="caption p"><p>Performance of the candidate identification of user-reported LLM hallucination.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Metric</th>
<th align="left" colspan="1" rowspan="1">Value</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Precision</td>
<td align="left" colspan="1" rowspan="1">0.65</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Recall</td>
<td align="left" colspan="1" rowspan="1">0.78</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">F1-Score</td>
<td align="left" colspan="1" rowspan="1">0.71</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab8/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section></section><section id="Sec14"><h2 class="pmc_sec_title">Discussion</h2>
<p id="Par41">This section interprets the empirical findings, connecting them to the research questions and discussing their deeper, actionable implications for the software engineering of AI-powered mobile applications. We move beyond surface-level observations to address the complexities of mitigating user-reported hallucinations in practice.</p>
<p id="Par42">The estimated prevalence of user-reported LLM hallucinations (RQ1) at 1.75% of AI-error-related reviews, while seemingly modest, represents a high-impact, low-frequency type of error that significantly erodes user trust. For product managers and QA leads, this signals that while hallucinations may not be the most common complaint, their presence is a critical indicator of deep model failure. The variation across app categories, particularly the higher proportions in “Generative AI Tools” and “AI Educational Apps”, suggests that the risk and impact of hallucinations are context-dependent, rising with user expectations for factual accuracy and coherent content creation.</p>
<p id="Par43">The user-centric taxonomy (RQ2) offers a practical tool for software engineers. While technical classifications focus on model-internal causes (e.g., extrinsic vs. intrinsic hallucinations)<sup><a href="#CR6" class="usa-link" aria-describedby="CR6">6</a>,<a href="#CR7" class="usa-link" aria-describedby="CR7">7</a>,<a href="#CR11" class="usa-link" aria-describedby="CR11">11</a></sup>, our taxonomy is based on user-perceived symptoms like “Factual Incorrectness” (H1) and “Nonsensical Output” (H3). This is a critical distinction; developers and QA teams can use this taxonomy directly to design targeted, user-centric test cases. For instance, they can create adversarial prompts specifically engineered to provoke “Persona/Role Inconsistency” (H5) or to check for “Fabricated Information” (H2), moving beyond generic benchmarks to test for the failures that users actually report.</p>
<p id="Par44">The distinct characteristics of these reviews (RQ3) including specific N-grams like “made this up” and “wrong information” and strong negative sentiment serve as more than just signals. They represent a user-generated “problem-behavior” signature. This signature confirms that perceived hallucinations are a major driver of dissatisfaction, as evidenced by the sharp drop in star ratings. This finding aligns with broader concerns about AI reliability’s effect on user adoption<sup><a href="#CR27" class="usa-link" aria-describedby="CR27">27</a>,<a href="#CR38" class="usa-link" aria-describedby="CR38">38</a></sup> and quantitatively demonstrates that users treat an AI that “lies” as a severe product defect.</p>
<p id="Par45">Addressing RQ4, the practical implications for software engineering are nuanced and must account for real-world complexities. Simply stating that these findings can “guide efforts” is insufficient. For prompt engineering, which has evolved from simple zero-shot to complex Chain-of-Thought approaches, our findings provide critical guidance for refinement. Knowing that “Factual Incorrectness” is the dominant user complaint, developers can specifically implement self-correction mechanisms. For example, they can integrate a Chain-of-Verification (CoVe) step, where the model is prompted to first draft a response, then generate verification questions to fact-check its own draft before producing a final, corrected output, a technique shown to reduce hallucinations<sup><a href="#CR39" class="usa-link" aria-describedby="CR39">39</a></sup>. This directly targets the most common failure mode observed in our study.</p>
<p id="Par46">Furthermore, the challenge of selecting a base LLM, especially for resource-constrained mobile and edge computing environments, is significant. The reviewer’s concern about the practicality of installing large models is valid. However, our findings are arguably more critical for smaller, distilled models. These models have less parametric knowledge and are more prone to specific types of failures. By understanding that users are most sensitive to factual and fabrication errors, developers can prioritize fine-tuning these smaller models with datasets and reward functions that heavily penalize these specific hallucination types.</p>
<p id="Par47">Finally, while Retrieval-Augmented Generation (RAG) is a promising strategy to ground LLM responses in factual data, it is not a panacea, and the quality of the knowledge base itself can be a point of failure<sup><a href="#CR29" class="usa-link" aria-describedby="CR29">29</a>,<a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup>. Our analysis of user-reported errors provides a vital feedback loop. When a user reports a factual error in a RAG-powered app, it may signal a failure not in the LLM’s generation, but in its retrieval or grounding process. This insight allows developers to debug the entire RAG pipeline. Advanced RAG techniques, such as those that re-evaluate and revise retrieved knowledge, are being developed to address this very issue<sup><a href="#CR40" class="usa-link" aria-describedby="CR40">40</a>,<a href="#CR41" class="usa-link" aria-describedby="CR41">41</a></sup>. The user reports we analyzed provide the “in-the-wild” ground-truth data needed to guide the implementation and evaluation of such sophisticated verification layers. These “AI glitches” are not mere technical errors but significant user experience flaws<sup><a href="#CR13" class="usa-link" aria-describedby="CR13">13</a></sup>, and treating them as such, with targeted, evidence-based mitigation strategies, is essential for building trustworthy AI.</p></section><section id="Sec15"><h2 class="pmc_sec_title">Threats to validity</h2>
<p id="Par48">Several factors could influence the validity of this study’s findings. Regarding Construct Validity, a key threat is the interpretation of user reviews as definitively “reporting hallucinations.” Users may not use technical terminology, and their descriptions of AI errors can be ambiguous. We mitigated this by using multiple annotators for confirming hallucination reports based on clear definitions derived from literature (e.g., output that is factually incorrect, nonsensical, or ungrounded<sup><a href="#CR6" class="usa-link" aria-describedby="CR6">6</a></sup>) and achieving substantial inter-rater reliability (Cohen’s Kappa 0.78). However, subjectivity remains. The developed taxonomy (Table <a href="#Tab3" class="usa-link">3</a>), while data-driven from user reports, might not be exhaustive or its categories perfectly mutually exclusive, though iterative refinement aimed to improve its robustness. The use of VADER for sentiment analysis, while suitable for review text, provides a general sentiment score that might not always capture the nuance of frustration specific to an AI error versus other app issues if a review is multifaceted.</p>
<p id="Par49">Concerning Internal Validity, the initial keyword-based filtering and the subsequent heuristic algorithm (described in Section 2.2.1) for candidate identification could introduce bias. While designed to be broad, these filters might miss user reports of hallucinations phrased in unconventional ways or incorrectly flag reviews that are merely critical of AI without describing a hallucination. The NMF topic modeling is unsupervised; the interpretation and relevance of topics to “hallucination” themes depend on researcher judgment. The reliability of the manual annotation process, despite IRR checks, can be influenced by annotator fatigue or differing subjective thresholds, though a detailed codebook and consensus meetings were employed to minimize this.</p>
<p id="Par50">External validity of our findingsis subject to several limitations. The app selection, while aiming for diversity across 10 AI-relevant categories and 90 apps (Table <a href="#Tab1" class="usa-link">1</a>), is still a sample and may not represent the entire spectrum of AI mobile applications or all types of LLMs deployed therein. The findings might be influenced by the specific LLMs powering the selected apps, information often not publicly available. The focus on English-language reviews from major app stores (Google Play, Apple App Store) means the prevalence, types, and linguistic expressions of reported hallucinations might differ in other languages, cultures, or on different platforms. The time period of review collection (Jan 2022 - Dec 2024) captures a specific snapshot in the rapidly evolving LLM landscape; newer models might exhibit different hallucination patterns. The estimated prevalence (RQ1) is based on a filtered subset and then a sampled subset for annotation, so it should be interpreted as an indicator within that processed data rather than an absolute prevalence across all mobile app reviews.</p>
<p id="Par51">Finally, Conclusion Validity relies on the strength of the qualitative interpretations and descriptive statistics. While quantitative analysis like frequency counts and sentiment score comparisons are presented, the study is primarily exploratory and descriptive. Causal claims about why certain hallucination types are more prevalent or why users react in specific ways are inferential based on the observed data. The performance of the candidate identification method (Table <a href="#Tab8" class="usa-link">8</a>) is specific to its role in this study (enriching the sample for manual analysis) and should not be interpreted as a production-ready hallucination detection system.</p></section><section id="Sec16"><h2 class="pmc_sec_title">Related work</h2>
<p id="Par52">This research is situated at the intersection of three key domains: the study of Large Language Model (LLM) hallucinations, the analysis of user feedback in software engineering, and the broader context of trust and user experience in AI systems. This section reviews prior work in these areas to contextualize our study’s contributions.</p>
<p id="Par53">The phenomenon of LLM hallucination, broadly defined as the generation of outputs that are nonsensical, unfaithful to source content, or factually incorrect, has become a central focus of AI research<sup><a href="#CR6" class="usa-link" aria-describedby="CR6">6</a>,<a href="#CR8" class="usa-link" aria-describedby="CR8">8</a></sup>. From a technical perspective, hallucinations are often categorized based on their relationship to source material (intrinsic vs. extrinsic) or their underlying causes, which can stem from biases in training data, architectural limitations of models like transformers, or specific decoding strategies employed during inference<sup><a href="#CR7" class="usa-link" aria-describedby="CR7">7</a>,<a href="#CR11" class="usa-link" aria-describedby="CR11">11</a>,<a href="#CR42" class="usa-link" aria-describedby="CR42">42</a>,<a href="#CR43" class="usa-link" aria-describedby="CR43">43</a></sup>. A significant body of work has been dedicated to developing benchmarks and evaluation metrics to quantify this issue, such as TruthfulQA for measuring factual accuracy<sup><a href="#CR44" class="usa-link" aria-describedby="CR44">44</a></sup> and HaluEval for assessing a model’s ability to recognize hallucinations<sup><a href="#CR11" class="usa-link" aria-describedby="CR11">11</a></sup>. Consequently, numerous mitigation techniques have been proposed, including Retrieval-Augmented Generation (RAG) to ground responses in external knowledge<sup><a href="#CR29" class="usa-link" aria-describedby="CR29">29</a>,<a href="#CR40" class="usa-link" aria-describedby="CR40">40</a></sup>, knowledge injection from knowledge graphs<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup>, and specialized fine-tuning or prompting strategies like Chain-of-Verification (CoVe)<sup><a href="#CR39" class="usa-link" aria-describedby="CR39">39</a>,<a href="#CR41" class="usa-link" aria-describedby="CR41">41</a></sup>. However, these evaluations and mitigation strategies are often conducted in controlled, academic settings and focus on specific Natural Language Generation (NLG) tasks like summarization<sup><a href="#CR25" class="usa-link" aria-describedby="CR25">25</a></sup>, question answering<sup><a href="#CR45" class="usa-link" aria-describedby="CR45">45</a></sup>, or machine translation<sup><a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup>. While this research provides a crucial technical foundation, it often lacks the “in-the-wild” perspective of how end-users encounter, interpret, and are impacted by hallucinations within the context of deployed software applications.</p>
<p id="Par54">In parallel, the field of software engineering has a long and rich history of analyzing user feedback to improve software quality. User reviews from mobile app stores have been established as a valuable source for a variety of requirements engineering and maintenance tasks<sup><a href="#CR16" class="usa-link" aria-describedby="CR16">16</a>–<a href="#CR18" class="usa-link" aria-describedby="CR18">18</a></sup>. Researchers have developed numerous automated and semi-automated techniques to mine these reviews for bug reports, identify feature requests, and perform sentiment analysis. For instance, tools like AR-Miner<sup><a href="#CR47" class="usa-link" aria-describedby="CR47">47</a></sup> and KEFE<sup><a href="#CR48" class="usa-link" aria-describedby="CR48">48</a></sup> focus on identifying informative reviews and key features, respectively, while various studies have applied sentiment analysis to gauge user opinions on specific features or overall app quality<sup><a href="#CR49" class="usa-link" aria-describedby="CR49">49</a>–<a href="#CR52" class="usa-link" aria-describedby="CR52">52</a></sup>. Our own prior work has contributed to this area by developing methods for extracting features to improve requirements analysis<sup><a href="#CR53" class="usa-link" aria-describedby="CR53">53</a></sup>, identifying and resolving conflicting feedback in reviews<sup><a href="#CR54" class="usa-link" aria-describedby="CR54">54</a></sup>, enhancing trust through explainable AI for feature request detection<sup><a href="#CR15" class="usa-link" aria-describedby="CR15">15</a></sup>, and systematically mapping the landscape of these analysis tools<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a></sup>. While these methods are effective for understanding traditional software defects (e.g., crashes, UI flaws) and user preferences, they are not specifically designed to identify or characterize the unique nature of LLM content errors. A user reporting that an AI “made up facts” represents a fundamentally different type of software defect than a button crash, requiring a different analytical lens. Bridging these domains, research on user experience with AI and conversational agents has consistently highlighted the importance of trust, reliability, and error handling<sup><a href="#CR55" class="usa-link" aria-describedby="CR55">55</a></sup>. Studies have shown that AI errors, particularly those that seem nonsensical or violate user trust, can lead to significant frustration and abandonment of the technology<sup><a href="#CR26" class="usa-link" aria-describedby="CR26">26</a></sup>. The development of tools like HILL<sup><a href="#CR27" class="usa-link" aria-describedby="CR27">27</a></sup>, an interface designed to help users identify potential LLM hallucinations, underscores the recognized need for user-facing solutions to this problem. However, such work is often focused on designing interventions rather than empirically characterizing the problem as it naturally occurs in existing, widely used applications.</p>
<p id="Par55">This paper’s unique contribution, therefore, lies in systematically connecting these three research areas. While the technical nature of hallucinations is well-documented and user review analysis is a mature field, no prior work, to our knowledge, has conducted a large-scale empirical study to specifically understand and characterize user-reported LLM hallucinations within the context of AI-powered mobile applications. By developing a user-centric taxonomy of hallucination types directly from “in-the-wild” feedback and analyzing the associated linguistic and sentiment cues, this research bridges the gap between technical LLM evaluations and the lived experiences of mobile app users. It offers a distinct, user-grounded perspective that is crucial for informing practical software quality assurance strategies for the next generation of AI-infused software.</p></section><section id="Sec17"><h2 class="pmc_sec_title">Conclusion and future work</h2>
<p id="Par56">This empirical study provided a systematic characterization of user-reported LLM hallucinations in AI-powered mobile app reviews. By analyzing a large corpus of user feedback, we estimated the prevalence of such reports, developed a data-driven taxonomy of user-perceived hallucination types with “Factual Incorrectness” and “Nonsensical/Irrelevant Output” being most prominent and identified distinct linguistic and sentiment characteristics associated with these reports, notably strong negative sentiment and significantly lower star ratings. These findings underscore the real-world impact of LLM hallucinations on user experience and trust in AI mobile apps. The insights gained have direct implications for software engineering practices. The user-centric taxonomy and identified linguistic cues can inform the development of more effective monitoring tools and QA processes for AI features. Understanding how users articulate these AI errors is the first step towards building systems that can automatically detect and flag potential hallucination reports from the vast stream of user feedback.</p>
<p id="Par57">Future work should focus on leveraging these empirical insights to develop and rigorously evaluate robust, automated methods for detecting user-reported LLM hallucinations at scale. This includes exploring supervised machine learning models trained on annotated review data incorporating the identified linguistic and sentiment features. Larger-scale, cross-platform (iOS), and cross-lingual studies are needed to enhance generalizability. Longitudinal analyses could track how user reporting of hallucinations evolves alongside advancements in LLM technology. Further research could also investigate in-app feedback mechanisms tailored for reporting AI-specific errors like hallucinations, potentially linking reports directly to the problematic LLM interaction context, thereby providing developers with richer data for diagnosis and model improvement. Ultimately, understanding and addressing user-perceived hallucinations is key to fostering trustworthy and reliable AI in mobile applications.</p></section><section id="ack1" class="ack"><h2 class="pmc_sec_title">Acknowledgements</h2>
<p>The authors acknowledge the support of TETFund and Centre of Excellence Obafemi Awolowo University, Ile-Ife in carrying out the research.</p></section><section id="notes1"><h2 class="pmc_sec_title">Author contributions</h2>
<p>R.M. and I.G. conceived and designed the study. R.M. developed the methodology with input from I.G. and J.A.K., and performed the data collection and software implementation. R.M., I.G., and C.A. conducted the manual annotation and qualitative analysis. R.M. and I.G. performed the formal data analysis. A.A. analysed the results, provided resources and secured funding. R.M. wrote the initial draft of the manuscript. All authors (R.M., I.G., J.A.K., C.A., A.A.) contributed to reviewing, editing, and approving the final manuscript. I.G. and J.A.K. supervised the research. All authors reviewed the manuscript.</p></section><section id="notes2"><h2 class="pmc_sec_title">Funding</h2>
<p>This research is supported by the ongoing research funding program (ORF-2025-309), King Saud University, Riyadh, Saudi Arabia.</p></section><section id="notes3"><h2 class="pmc_sec_title">Data availability</h2>
<p>The datasets analyzed in this study were derived from publicly available mobile app reviews on the Google Play Store and Apple App Store. Due to platform terms of service, raw review data cannot be redistributed directly. However, aggregated and anonymized datasets generated during the study are available from the corresponding author (Rhodes Massenon, ramassenon@pg-student.oauife.edu.ng) upon reasonable request.</p></section><section id="notes4"><h2 class="pmc_sec_title">Declarations</h2>
<section id="FPar1"><h3 class="pmc_sec_title">Competing interests</h3>
<p id="Par62">The authors declare no competing interests.</p></section></section><section id="fn-group1" class="fn-group"><h2 class="pmc_sec_title">Footnotes</h2>
<div class="fn-group p font-secondary-light font-sm">
<div class="fn p" id="fn1">
<p><strong>Publisher’s note</strong></p>
<p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</div>
<div class="fn p" id="fn2"><p>These authors contributed equally: Ishaya Gambo, Javed Ali Khan, Christopher Agbonkhese and Ayed Alwadain.</p></div>
</div></section><section id="_ci93_" lang="en" class="contrib-info"><h2 class="pmc_sec_title">Contributor Information</h2>
<p>Rhodes Massenon, Email: ramassenon@pg-student.oauife.edu.ng.</p>
<p>Ayed Alwadain, Email: aalwadain@ksu.edu.sa.</p></section><section id="Bib1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="Bib1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="CR1">
<span class="label">1.</span><cite>Takale, D., Mahalle, P. &amp; Sule, B. Advancements and applications of generative artificial intelligence. <em>Journal of Information Technology and Sciences</em><strong>10</strong>, 20–27 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Takale,%20D.,%20Mahalle,%20P.%20&amp;%20Sule,%20B.%20Advancements%20and%20applications%20of%20generative%20artificial%20intelligence.%20Journal%20of%20Information%20Technology%20and%20Sciences10,%2020%E2%80%9327%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR2">
<span class="label">2.</span><cite>Ramdurai, B. &amp; Adhithya, P. The impact, advancements and applications of generative AI. <em>International Journal of Computer Science and Engineering</em><strong>10</strong>, 1–8 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Ramdurai,%20B.%20&amp;%20Adhithya,%20P.%20The%20impact,%20advancements%20and%20applications%20of%20generative%20AI.%20International%20Journal%20of%20Computer%20Science%20and%20Engineering10,%201%E2%80%938%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR3">
<span class="label">3.</span><cite>Wang, J. et al. Evaluation and analysis of hallucination in large vision-language models (2023). <a href="http://arxiv.org/abs/2308.15126" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2308.15126</a>.</cite>
</li>
<li id="CR4">
<span class="label">4.</span><cite>Nwanna, M. et al. AI-driven personalisation: Transforming user experience across mobile applications. <em>Journal of Artificial Intelligence, Machine Learning and Data Science</em><strong>3</strong>, 1930–1937 (2025).</cite> [<a href="https://scholar.google.com/scholar_lookup?Nwanna,%20M.%20et%20al.%20AI-driven%20personalisation:%20Transforming%20user%20experience%20across%20mobile%20applications.%20Journal%20of%20Artificial%20Intelligence,%20Machine%20Learning%20and%20Data%20Science3,%201930%E2%80%931937%20(2025)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR5">
<span class="label">5.</span><cite>Behare, N., Bhagat, S. &amp; Sarangdhar, P. Revolutionizing Customer Experience With AI-Powered Personalization. In <em>Strategic Brand Management in the Age of AI and Disruption</em>, 439–462 (IGI Global Scientific Publishing, 2025).</cite>
</li>
<li id="CR6">
<span class="label">6.</span><cite>Ji, Z. et al. Survey of hallucination in natural language generation. <em>ACM Computing Surveys</em><strong>55</strong>, 1–38 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Ji,%20Z.%20et%20al.%20Survey%20of%20hallucination%20in%20natural%20language%20generation.%20ACM%20Computing%20Surveys55,%201%E2%80%9338%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR7">
<span class="label">7.</span><cite>Zhang, Y. et al. Siren’s song in the AI ocean: a survey on hallucination in large language models (2023). <a href="http://arxiv.org/abs/2309.01219" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2309.01219</a>.</cite>
</li>
<li id="CR8">
<span class="label">8.</span><cite>Huang, L. et al. A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. <em>ACM Transactions on Information Systems</em><strong>43</strong>, 1–55 (2025).</cite> [<a href="https://scholar.google.com/scholar_lookup?Huang,%20L.%20et%20al.%20A%20survey%20on%20hallucination%20in%20large%20language%20models:%20Principles,%20taxonomy,%20challenges,%20and%20open%20questions.%20ACM%20Transactions%20on%20Information%20Systems43,%201%E2%80%9355%20(2025)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR9">
<span class="label">9.</span><cite>Rawte, V. et al. The troubling emergence of hallucination in large language models-an extensive definition, quantification, and prescriptive remediations. In <em>Findings of the Association for Computational Linguistics: EMNLP 2023</em> (Association for Computational Linguistics, 2023).</cite>
</li>
<li id="CR10">
<span class="label">10.</span><cite>Bang, Y. et al. A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity (2023). <a href="http://arxiv.org/abs/2302.04023" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2302.04023</a>.</cite>
</li>
<li id="CR11">
<span class="label">11.</span><cite>Li, J., Cheng, X., Zhao, W., Nie, J. &amp; Wen, J. Halueval: A large-scale hallucination evaluation benchmark for large language models (2023). <a href="http://arxiv.org/abs/2305.11747" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2305.11747</a>.</cite>
</li>
<li id="CR12">
<span class="label">12.</span><cite>Zhu, Z., Yang, Y. &amp; Sun, Z. Halueval-wild: Evaluating hallucinations of language models in the wild (2024). <a href="http://arxiv.org/abs/2403.04307" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2403.04307</a>.</cite>
</li>
<li id="CR13">
<span class="label">13.</span><cite>Shao, A. Beyond Misinformation: A Conceptual Framework for Studying AI Hallucinations in (Science) Communication (2025). <a href="http://arxiv.org/abs/2504.13777" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2504.13777</a>.</cite>
</li>
<li id="CR14">
<span class="label">14.</span><cite>Massenon, R. et al. Mobile app review analysis for crowdsourcing of software requirements: a mapping study of automated and semi-automated tools. <em>PeerJ Computer Science</em><strong>10</strong>, e2401 (2024).
</cite> [<a href="https://doi.org/10.7717/peerj-cs.2401" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11623114/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39650465/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Massenon,%20R.%20et%20al.%20Mobile%20app%20review%20analysis%20for%20crowdsourcing%20of%20software%20requirements:%20a%20mapping%20study%20of%20automated%20and%20semi-automated%20tools.%20PeerJ%20Computer%20Science10,%20e2401%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR15">
<span class="label">15.</span><cite>Gambo, I. et al. Enhancing user trust and interpretability in ai-driven feature request detection for mobile app reviews: an explainable approach. <em>IEEE Access</em> (2024).</cite>
</li>
<li id="CR16">
<span class="label">16.</span><cite>Dąbrowski, J., Letier, E., Perini, A. &amp; Susi, A. Analysing app reviews for software engineering: a systematic literature review. <em>Empirical Software Engineering</em><strong>27</strong>, 43 (2022).</cite> [<a href="https://scholar.google.com/scholar_lookup?D%C4%85browski,%20J.,%20Letier,%20E.,%20Perini,%20A.%20&amp;%20Susi,%20A.%20Analysing%20app%20reviews%20for%20software%20engineering:%20a%20systematic%20literature%20review.%20Empirical%20Software%20Engineering27,%2043%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR17">
<span class="label">17.</span><cite>Genc-Nayebi, N. &amp; Abran, A. A systematic literature review: Opinion mining studies from mobile app store user reviews. <em>Journal of Systems and Software</em><strong>125</strong>, 207–219 (2017).</cite> [<a href="https://scholar.google.com/scholar_lookup?Genc-Nayebi,%20N.%20&amp;%20Abran,%20A.%20A%20systematic%20literature%20review:%20Opinion%20mining%20studies%20from%20mobile%20app%20store%20user%20reviews.%20Journal%20of%20Systems%20and%20Software125,%20207%E2%80%93219%20(2017)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR18">
<span class="label">18.</span><cite>Palomba, F. et al. User reviews matter! tracking crowdsourced reviews to support evolution of successful apps. In <em>2015 IEEE international conference on software maintenance and evolution (ICSME)</em>, 291–300 (IEEE, 2015).</cite>
</li>
<li id="CR19">
<span class="label">19.</span><cite>Fan, A. et al. Large language models for software engineering: Survey and open problems. In <em>2023 IEEE/ACM International Conference on Software Engineering: Future of Software Engineering (ICSE-FoSE)</em>, 31–53 (IEEE, 2023).</cite>
</li>
<li id="CR20">
<span class="label">20.</span><cite>Görmez, M., Yılmaz, M. &amp; Clarke, P. Large Language Models for Software Engineering: A Systematic Mapping Study. In <em>European Conference on Software Process Improvement</em>, 64–79 (Springer Nature Switzerland, Cham, 2024).</cite>
</li>
<li id="CR21">
<span class="label">21.</span><cite>Khan, W., Daud, A., Khan, K., Muhammad, S. &amp; Haq, R. Exploring the frontiers of deep learning and natural language processing: A comprehensive overview of key challenges and emerging trends. <em>Natural Language Processing Journal</em><strong>4</strong>, 100026 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Khan,%20W.,%20Daud,%20A.,%20Khan,%20K.,%20Muhammad,%20S.%20&amp;%20Haq,%20R.%20Exploring%20the%20frontiers%20of%20deep%20learning%20and%20natural%20language%20processing:%20A%20comprehensive%20overview%20of%20key%20challenges%20and%20emerging%20trends.%20Natural%20Language%20Processing%20Journal4,%20100026%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR22">
<span class="label">22.</span><cite>Desai, B., Patil, K., Patil, A. &amp; Mehta, I. Large Language Models: A Comprehensive Exploration of Modern AI’s Potential and Pitfalls. <em>Journal of Innovative Technologies</em><strong>6</strong> (2023).</cite>
</li>
<li id="CR23">
<span class="label">23.</span><cite>Koenecke, A., Choi, A., Mei, K., Schellmann, H. &amp; Sloane, M. Careless whisper: Speech-to-text hallucination harms. In <em>Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency</em>, 1672–1681 (ACM, 2024).</cite>
</li>
<li id="CR24">
<span class="label">24.</span><cite>Moffatt v. Air Canada. McCarthy Tétrault TechLex Blog (2024). Available at: <a href="https://www.mccarthy.ca/en/insights/blogs/techlex/moffatt-v-air-canada-misrepresentation-ai-chatbot" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.mccarthy.ca/en/insights/blogs/techlex/moffatt-v-air-canada-misrepresentation-ai-chatbot</a>, Last accessed 2025/05/05.</cite>
</li>
<li id="CR25">
<span class="label">25.</span><cite>Maynez, J., Narayan, S., Bohnet, B. &amp; McDonald, R. On faithfulness and factuality in abstractive summarization (2020). <a href="http://arxiv.org/abs/2005.00661" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2005.00661</a>.</cite>
</li>
<li id="CR26">
<span class="label">26.</span><cite>Leiser, F. et al. From ChatGPT to FactGPT: A participatory design study to mitigate the effects of large language model hallucinations on users. In <em>Proceedings of Mensch und Computer 2023</em>, 81–90 (ACM, 2023).</cite>
</li>
<li id="CR27">
<span class="label">27.</span><cite>Leiser, F. et al. Hill: A hallucination identifier for large language models. In <em>Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems</em>, 1–13 (ACM, 2024).</cite>
</li>
<li id="CR28">
<span class="label">28.</span><cite>Xu, Z., Jain, S. &amp; Kankanhalli, M. Hallucination is inevitable: An innate limitation of large language models (2024). <a href="http://arxiv.org/abs/2401.11817" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2401.11817</a>.</cite>
</li>
<li id="CR29">
<span class="label">29.</span><cite>Tonmoy, S. et al. A comprehensive survey of hallucination mitigation techniques in large language models (2024). <a href="http://arxiv.org/abs/2401.01313" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2401.01313</a>.</cite>
</li>
<li id="CR30">
<span class="label">30.</span><cite>Martino, A., Iannelli, M. &amp; Truong, C. Knowledge injection to counter large language model (LLM) hallucination. In <em>European Semantic Web Conference</em>, 182–185 (Springer Nature Switzerland, Cham, 2023).</cite>
</li>
<li id="CR31">
<span class="label">31.</span><cite>Agrawal, A., Suzgun, M., Mackey, L. &amp; Kalai, A. Do Language Models Know When They’re Hallucinating References? (2023). <a href="http://arxiv.org/abs/2305.18248" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2305.18248</a>.</cite>
</li>
<li id="CR32">
<span class="label">32.</span><cite>Jiang, Z., Araki, J., Ding, H. &amp; Neubig, G. How can we know when language models know? on the calibration of language models for question answering. <em>Transactions of the Association for Computational Linguistics</em><strong>9</strong>, 962–977 (2021).</cite> [<a href="https://scholar.google.com/scholar_lookup?Jiang,%20Z.,%20Araki,%20J.,%20Ding,%20H.%20&amp;%20Neubig,%20G.%20How%20can%20we%20know%20when%20language%20models%20know?%20on%20the%20calibration%20of%20language%20models%20for%20question%20answering.%20Transactions%20of%20the%20Association%20for%20Computational%20Linguistics9,%20962%E2%80%93977%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR33">
<span class="label">33.</span><cite>Xiong, M. et al. Can llms express their uncertainty? an empirical evaluation of confidence elicitation in llms (2023). <a href="http://arxiv.org/abs/2306.13063" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2306.13063</a>.</cite>
</li>
<li id="CR34">
<span class="label">34.</span><cite>Khan, J., Qayyum, S. &amp; Dar, H. Large Language Model for Requirements Engineering: A Systematic Literature Review. Research Square, 10.21203/rs.3.rs-5589929/v1 (2025).</cite>
</li>
<li id="CR35">
<span class="label">35.</span><cite>Min, B. et al. Recent advances in natural language processing via large pre-trained language models: A survey. <em>ACM Computing Surveys</em><strong>56</strong>, 1–40 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Min,%20B.%20et%20al.%20Recent%20advances%20in%20natural%20language%20processing%20via%20large%20pre-trained%20language%20models:%20A%20survey.%20ACM%20Computing%20Surveys56,%201%E2%80%9340%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR36">
<span class="label">36.</span><cite>Hariri, W. Unlocking the potential of ChatGPT: A comprehensive exploration of its applications, advantages, limitations, and future directions in natural language processing (2023). <a href="http://arxiv.org/abs/2304.02017" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2304.02017</a>.</cite>
</li>
<li id="CR37">
<span class="label">37.</span><cite>Vinothkumar, J. &amp; Karunamurthy, A. Recent advancements in artificial intelligence technology: trends and implications. <em>Quing: International Journal of Multidisciplinary Scientific Research and Development</em><strong>2</strong>, 1–11 (2023).</cite>
</li>
<li id="CR38">
<span class="label">38.</span><cite>Farquhar, S., Kossen, J., Kuhn, L. &amp; Gal, Y. Detecting hallucinations in large language models using semantic entropy. <em>Nature</em><strong>630</strong>, 625–630 (2024).
</cite> [<a href="https://doi.org/10.1038/s41586-024-07421-0" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11186750/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38898292/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Farquhar,%20S.,%20Kossen,%20J.,%20Kuhn,%20L.%20&amp;%20Gal,%20Y.%20Detecting%20hallucinations%20in%20large%20language%20models%20using%20semantic%20entropy.%20Nature630,%20625%E2%80%93630%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR39">
<span class="label">39.</span><cite>Dhuliawala, S. et al. Chain-of-verification reduces hallucination in large language models (2023). <a href="http://arxiv.org/abs/2309.11495" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2309.11495</a>.</cite>
</li>
<li id="CR40">
<span class="label">40.</span><cite>Béchard, P. &amp; Ayala, O. M. Reducing hallucination in structured outputs via retrieval-augmented generation (2024). <a href="http://arxiv.org/abs/2404.08189" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2404.08189</a>.</cite>
</li>
<li id="CR41">
<span class="label">41.</span><cite>He, B. et al. Retrieving, rethinking and revising: The chain-of-verification can improve retrieval augmented generation (2024). <a href="http://arxiv.org/abs/2410.05801" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2410.05801</a>.</cite>
</li>
<li id="CR42">
<span class="label">42.</span><cite>Liu, F. et al. Exploring and evaluating hallucinations in llm-powered code generation (2024). <a href="http://arxiv.org/abs/2404.00971" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2404.00971</a>.</cite>
</li>
<li id="CR43">
<span class="label">43.</span><cite>Lee, Y. et al. Hallucination by Code Generation LLMs: Taxonomy, Benchmarks, Mitigation, and Challenges (2025). <a href="http://arxiv.org/abs/2504.20799" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2504.20799</a>.</cite>
</li>
<li id="CR44">
<span class="label">44.</span><cite>Lin, S., Hilton, J. &amp; Evans, O. Truthfulqa: Measuring how models mimic human falsehoods (2021). <a href="http://arxiv.org/abs/2109.07958" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2109.07958</a>.</cite>
</li>
<li id="CR45">
<span class="label">45.</span><cite>Zheng, S., Huang, J. &amp; Chang, K. Why Does ChatGPT Fall Short in Providing Truthful Answers? (2023). <a href="http://arxiv.org/abs/2304.10513" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2304.10513</a>.</cite>
</li>
<li id="CR46">
<span class="label">46.</span><cite>Guerreiro, N. et al. Mitigating Hallucinations in Neural Machine Translation through Fuzzy-match Repair. In <em>Proceedings of the 24th Annual Conference of the European Association for Machine Translation</em>, 123–132 (EAMT, 2023).</cite>
</li>
<li id="CR47">
<span class="label">47.</span><cite>Chen, N., Lin, J., Hoi, S., Xiao, X. &amp; Zhang, B. AR-miner: mining informative reviews for developers from mobile app marketplace. In <em>Proceedings of the 36th international conference on software engineering</em>, 767–778 (ACM, 2014).</cite>
</li>
<li id="CR48">
<span class="label">48.</span><cite>Wu, H., Deng, W., Niu, X. &amp; Nie, C. Identifying key features from app user reviews. In <em>2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)</em>, 922–932 (IEEE, 2021).</cite>
</li>
<li id="CR49">
<span class="label">49.</span><cite>Guzman, E. &amp; Maalej, W. How do users like this feature? a fine grained sentiment analysis of app reviews. In <em>2014 IEEE 22nd international requirements engineering conference (RE)</em>, 153–162 (IEEE, 2014).</cite>
</li>
<li id="CR50">
<span class="label">50.</span><cite>Ballas, V., Michalakis, K., Alexandridis, G. &amp; Caridakis, G. Automating mobile app review user feedback with aspect-based sentiment analysis. In <em>International Conference on Human-Computer Interaction</em>, 179–193 (Springer Nature Switzerland, Cham, 2024).</cite>
</li>
<li id="CR51">
<span class="label">51.</span><cite>Shah, F., Sabir, A. &amp; Sharma, R. A Fine-grained Sentiment Analysis of App Reviews using Large Language Models: An Evaluation Study (2024). <a href="http://arxiv.org/abs/2409.07162" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2409.07162</a>.</cite>
</li>
<li id="CR52">
<span class="label">52.</span><cite>Ossai, C. &amp; Wickramasinghe, N. Automatic user sentiments extraction from diabetes mobile apps–An evaluation of reviews with machine learning. <em>Informatics for Health and Social Care</em><strong>48</strong>, 211–230 (2023).
</cite> [<a href="https://doi.org/10.1080/17538157.2022.2097083" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35930432/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Ossai,%20C.%20&amp;%20Wickramasinghe,%20N.%20Automatic%20user%20sentiments%20extraction%20from%20diabetes%20mobile%20apps%E2%80%93An%20evaluation%20of%20reviews%20with%20machine%20learning.%20Informatics%20for%20Health%20and%20Social%20Care48,%20211%E2%80%93230%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR53">
<span class="label">53.</span><cite>Gambo, I. et al. Extracting Features from App Store Reviews to Improve Requirements Analysis: Natural Language Processing and Machine Learning Approach. <em>International Journal of Computing</em><strong>17</strong>, 1–19 (2025).</cite> [<a href="https://scholar.google.com/scholar_lookup?Gambo,%20I.%20et%20al.%20Extracting%20Features%20from%20App%20Store%20Reviews%20to%20Improve%20Requirements%20Analysis:%20Natural%20Language%20Processing%20and%20Machine%20Learning%20Approach.%20International%20Journal%20of%20Computing17,%201%E2%80%9319%20(2025)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR54">
<span class="label">54.</span><cite>Gambo, I., Massenon, R., Ogundokun, R. O., Agarwal, S. &amp; Pak, W. Identifying and resolving conflict in mobile application features through contradictory feedback analysis. <em>Heliyon</em><strong>10</strong> (2024).</cite> [<a href="https://doi.org/10.1016/j.heliyon.2024.e36729" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11400956/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39281433/" class="usa-link">PubMed</a>]</li>
<li id="CR55">
<span class="label">55.</span><cite>Dam, S., Hong, C., Qiao, Y. &amp; Zhang, C. A complete survey on llm-based ai chatbots (2024). <a href="http://arxiv.org/abs/2406.16937" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2406.16937</a>.</cite>
</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adda93_" lang="en" class="data-availability-statement"><h3 class="pmc_sec_title">Data Availability Statement</h3>
<p>The datasets analyzed in this study were derived from publicly available mobile app reviews on the Google Play Store and Apple App Store. Due to platform terms of service, raw review data cannot be redistributed directly. However, aggregated and anonymized datasets generated during the study are available from the corresponding author (Rhodes Massenon, ramassenon@pg-student.oauife.edu.ng) upon reasonable request.</p></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from Scientific Reports are provided here courtesy of <strong>Nature Publishing Group</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1038/s41598-025-15416-8"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/41598_2025_Article_15416.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (2.3 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12365265/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12365265/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12365265%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12365265/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12365265/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12365265/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40830185/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12365265/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40830185/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12365265/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12365265/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="MwZCwyzUKCHRFRlA9bgvsxw4JcwhxIT7AH4DgZ2SmvbJJ9yIP1kemrvzDklfVdKG">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
    

    </body>
</html>
