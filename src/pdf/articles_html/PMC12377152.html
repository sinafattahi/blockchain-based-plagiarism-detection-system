
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            Evaluating large language models as graders of medical short answer questions: a comparative analysis with expert human graders - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="AE53129E8AEF2D2305129E002DA03033.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="meo">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12377152/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="Medical Education Online">
<meta name="citation_title" content="Evaluating large language models as graders of medical short answer questions: a comparative analysis with expert human graders">
<meta name="citation_author" content="Olena Bolgova">
<meta name="citation_author_institution" content="College of Medicine, Alfaisal University, Riyadh, Kingdom of Saudi Arabia">
<meta name="citation_author" content="Paul Ganguly">
<meta name="citation_author_institution" content="College of Medicine, Alfaisal University, Riyadh, Kingdom of Saudi Arabia">
<meta name="citation_author" content="Muhammad Faisal Ikram">
<meta name="citation_author_institution" content="College of Medicine, Alfaisal University, Riyadh, Kingdom of Saudi Arabia">
<meta name="citation_author" content="Volodymyr Mavrych">
<meta name="citation_author_institution" content="College of Medicine, Alfaisal University, Riyadh, Kingdom of Saudi Arabia">
<meta name="citation_publication_date" content="2025 Aug 24">
<meta name="citation_volume" content="30">
<meta name="citation_issue" content="1">
<meta name="citation_firstpage" content="2550751">
<meta name="citation_doi" content="10.1080/10872981.2025.2550751">
<meta name="citation_pmid" content="40849930">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12377152/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12377152/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12377152/pdf/ZMEO_30_2550751.pdf">
<meta name="description" content="The assessment of short-answer questions (SAQs) in medical education is resource-intensive, requiring significant expert time. Large Language Models (LLMs) offer potential for automating this process, but their efficacy in specialized medical ...">
<meta name="og:title" content="Evaluating large language models as graders of medical short answer questions: a comparative analysis with expert human graders">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="The assessment of short-answer questions (SAQs) in medical education is resource-intensive, requiring significant expert time. Large Language Models (LLMs) offer potential for automating this process, but their efficacy in specialized medical ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12377152/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12377152">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1080/10872981.2025.2550751"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/ZMEO_30_2550751.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12377152%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12377152/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12377152/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12377152/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-meo.png" alt="Medical Education Online logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to Medical Education Online" title="Link to Medical Education Online" shape="default" href="https://doi.org/10.1080/10872981.2025.2550751" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">Med Educ Online</button></div>. 2025 Aug 24;30(1):2550751. doi: <a href="https://doi.org/10.1080/10872981.2025.2550751" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1080/10872981.2025.2550751</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22Med%20Educ%20Online%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Med%20Educ%20Online%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22Med%20Educ%20Online%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22Med%20Educ%20Online%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Evaluating large language models as graders of medical short answer questions: a comparative analysis with expert human graders</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Bolgova%20O%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Olena Bolgova</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Olena Bolgova</span></h3>
<div class="p">
<sup>1</sup>College of Medicine, Alfaisal University, Riyadh, Kingdom of Saudi Arabia</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Bolgova%20O%22%5BAuthor%5D" class="usa-link"><span class="name western">Olena Bolgova</span></a>
</div>
</div>
<sup>1</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Ganguly%20P%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Paul Ganguly</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">Paul Ganguly</span></h3>
<div class="p">
<sup>1</sup>College of Medicine, Alfaisal University, Riyadh, Kingdom of Saudi Arabia</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Ganguly%20P%22%5BAuthor%5D" class="usa-link"><span class="name western">Paul Ganguly</span></a>
</div>
</div>
<sup>1</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Ikram%20MF%22%5BAuthor%5D" class="usa-link" aria-describedby="id3"><span class="name western">Muhammad Faisal Ikram</span></a><div hidden="hidden" id="id3">
<h3><span class="name western">Muhammad Faisal Ikram</span></h3>
<div class="p">
<sup>1</sup>College of Medicine, Alfaisal University, Riyadh, Kingdom of Saudi Arabia</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Ikram%20MF%22%5BAuthor%5D" class="usa-link"><span class="name western">Muhammad Faisal Ikram</span></a>
</div>
</div>
<sup>1</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Mavrych%20V%22%5BAuthor%5D" class="usa-link" aria-describedby="id4"><span class="name western">Volodymyr Mavrych</span></a><div hidden="hidden" id="id4">
<h3><span class="name western">Volodymyr Mavrych</span></h3>
<div class="p">
<sup>1</sup>College of Medicine, Alfaisal University, Riyadh, Kingdom of Saudi Arabia</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Mavrych%20V%22%5BAuthor%5D" class="usa-link"><span class="name western">Volodymyr Mavrych</span></a>
</div>
</div>
<sup>1,</sup><sup>✉</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="aff0001">
<sup>1</sup>College of Medicine, Alfaisal University, Riyadh, Kingdom of Saudi Arabia</div>
<div class="author-notes p"><div class="fn" id="an0001">
<sup>✉</sup><p class="display-inline">CONTACT Volodymyr Mavrych <span>vmavrych@alfaisal.edu</span> College of Medicine, Alfaisal University, Al Takhassousi Str., Riyadh
11533, Kingdom of Saudi Arabia</p>
</div></div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2025 Jun 9; Accepted 2025 Aug 15; Collection date 2025.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© 2025 The Author(s). Published by Informa UK Limited, trading as Taylor &amp; Francis Group.</div>
<p>This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (<a href="https://creativecommons.org/licenses/by-nc/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://creativecommons.org/licenses/by-nc/4.0/</a>), which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited. The terms on which this article has been published allow the posting of the Accepted Manuscript in a repository by the author(s) or with their consent.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12377152  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40849930/" class="usa-link">40849930</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="abstract1"><h2>ABSTRACT</h2>
<p>The assessment of short-answer questions (SAQs) in medical education is resource-intensive, requiring significant expert time. Large Language Models (LLMs) offer potential for automating this process, but their efficacy in specialized medical education assessment remains understudied. To evaluate the capability of five LLMs to grade medical SAQs compared to expert human graders across four distinct medical disciplines. This study analyzed 804 student responses across anatomy, histology, embryology, and physiology. Three faculty members graded all responses. Five LLMs (GPT-4.1, Gemini, Claude, Copilot, DeepSeek) evaluated responses twice: first using their learned representations to generate their own grading criteria (A1), then using expert-provided rubrics (A2). Agreement was measured using Cohen’s Kappa and Intraclass Correlation Coefficient (ICC). Expert-expert agreement was substantial across all questions (average Kappa: 0.69, ICC: 0.86), ranging from moderate (SAQ2: 0.57) to almost perfect (SAQ4: 0.87). LLM performance varied dramatically by question type and model. The highest expert-LLM agreement was observed for Claude on SAQ3 (Kappa: 0.61) and DeepSeek on SAQ2 (Kappa: 0.53). Providing expert criteria had inconsistent effects, significantly improving some model-question combinations while decreasing others. No single LLM consistently outperformed others across all domains. LLM strictness in grading unsatisfactory responses varied substantially from experts. LLMs demonstrated domain-specific variations in grading capabilities. The provision of expert criteria did not consistently improve performance. While LLMs show promise for supporting medical education assessment, their implementation requires domain-specific considerations and continued human oversight.</p>
<section id="kwd-group1" class="kwd-group"><p><strong>KEYWORDS:</strong> Medical education, assessment, short answer questions, large language models, artificial intelligence, claude, GPT-4.1, gemini, DeepSeek, educational technology</p></section></section><section id="s0001"><h2 class="pmc_sec_title">Introduction</h2>
<p>Short Answer Questions (SAQs) are a vital component of assessment in medical education, offering distinct advantages over multiple-choice questions (MCQs) by requiring students to actively recall and articulate knowledge rather than merely recognizing correct answers [<a href="#cit0001" class="usa-link" aria-describedby="cit0001">1</a>]. SAQs play a crucial role in evaluating students’ understanding of complex medical concepts, their ability to synthesize information, and their capacity to express clinical reasoning in a concise format. Unlike MCQs that rely primarily on recognition, SAQs assess higher-order cognitive processes and better simulate the recall-based reasoning required in actual clinical practice [<a href="#cit0002" class="usa-link" aria-describedby="cit0002">2</a>]. SAQs assess students’ ability to articulate medical concepts clearly and concisely in writing – a critical skill for medical documentation, patient notes, and professional communication that cannot be evaluated through MCQs [<a href="#cit0003" class="usa-link" aria-describedby="cit0003">3</a>].</p>
<p>Despite their pedagogical value, the adoption of SAQs in medical education faces significant practical challenges. The grading of SAQs is notably time-intensive, requiring substantial faculty resources and expertise [<a href="#cit0004" class="usa-link" aria-describedby="cit0004">4</a>]. Grading open questions is a time-intensive task for teachers, which has a negative impact on scalability and can push educators toward favoring MCQs despite their limitations in assessing certain competencies [<a href="#cit0005" class="usa-link" aria-describedby="cit0005">5</a>]. The labor-intensive nature of SAQ grading can lead to delayed feedback, grader fatigue, and potential inconsistencies in evaluation, all of which compromise the educational value of these assessment tools [<a href="#cit0006" class="usa-link" aria-describedby="cit0006">6</a>]. SAQs, while pedagogically superior for certain types of assessment, are often underutilized due to the practical limitations of manual grading [<a href="#cit0007" class="usa-link" aria-describedby="cit0007">7</a>].</p>
<p>Recent years have witnessed remarkable advancements in artificial intelligence (AI), particularly in the domain of Large Language Models (LLMs). These sophisticated AI systems, including models such as GPT-4, Claude, Gemini, Copilot, and DeepSeek, have demonstrated unprecedented capabilities in understanding, generating, and analyzing human language [<a href="#cit0008" class="usa-link" aria-describedby="cit0008">8</a>]. ChatGPT could achieve scores on the United States Medical Licensing Examination (USMLE) that would be considered passing for medical students, specifically achieving accuracies of 64.4% on NBME-Free-Step1 and 57.8% on NBME-Free-Step2 questions, outperforming previous language models by a significant margin [<a href="#cit0009" class="usa-link" aria-describedby="cit0009">9</a>].</p>
<p>The capabilities of LLMs in medical education extend to performance on basic science subjects that form the foundation of medical curricula. In the field of anatomy, GPT-4 demonstrated the highest performance among six different LLMs on USMLE-style MCQs, correctly answering 60.5% of questions, followed by Copilot (42.0%) and ChatGPT-3.5 (41.0%) [<a href="#cit0010" class="usa-link" aria-describedby="cit0010">10</a>]. For embryology, LLMs correctly answered 78.7% of the questions, with GPT-4o and Claude performing best (89.7% and 87.5% correct answers, respectively) [<a href="#cit0011" class="usa-link" aria-describedby="cit0011">11</a>]. In neuroscience education, selected AI-driven chatbots could accurately answer 67.2% of MCQs from a medical neuroscience course, with Claude and GPT-4 outperforming other models with 83% and 81.7% correct answers, respectively, exceeding average student results [<a href="#cit0012" class="usa-link" aria-describedby="cit0012">12</a>]. For biochemistry, LLMs demonstrated impressive results, correctly answering 81.1% of questions on average – notably outperforming medical students by 8.3%, with Claude exhibiting the strongest performance (92.5% correct), followed by GPT-4 (85%), Gemini (78.5%), and Copilot (64%) [<a href="#cit0008" class="usa-link" aria-describedby="cit0008">8</a>]. Recent research in cardiovascular physiology assessment has demonstrated significant performance differences between the same LLM versions, with ChatGPT-4 achieving 83.33% accuracy compared to ChatGPT-3.5’s 60% accuracy on concept-based questions (<em>p</em> = 0.045) [<a href="#cit0013" class="usa-link" aria-describedby="cit0013">13</a>]. These findings collectively demonstrate that current LLMs possess substantial knowledge of basic medical sciences, though with important variations across models and topics. LLMs can achieve impressive accuracy rates, but their performance is not uniform across all medical domains [<a href="#cit0014" class="usa-link" aria-describedby="cit0014">14</a>].</p>
<p>The convergence of the need for more efficient SAQ grading methods and the advanced capabilities of LLMs presents a promising opportunity for innovations in medical education assessment. The ability of LLMs to understand, analyze, and evaluate complex textual responses makes them potentially valuable tools for automating or assisting with the grading of SAQs [<a href="#cit0015" class="usa-link" aria-describedby="cit0015">15</a>]. Automatic Short Answer Grading (ASAG) has been an area of research interest for several decades, with various approaches developed over time, but the advent of LLMs represents a significant leap forward in the capabilities of ASAG systems [<a href="#cit0005" class="usa-link" aria-describedby="cit0005">5</a>]. Unlike earlier rule-based systems or traditional statistical approaches such as keyword matching, n-gram analysis, and classical machine learning methods (e.g., support vector machines, naive Bayes), modern LLMs represent a paradigm shift in statistical modeling for natural language processing. Built on transformer architectures with attention mechanisms, LLMs employ deep neural networks trained on vast datasets, making reliable, scalable assessment approaches ever more pressing to learn probabilistic representations of language patterns. These transformer-based models can process and understand natural language in context through sophisticated statistical inference, potentially enabling them to evaluate student responses with a degree of nuance and comprehension previously unattainable by earlier automated systems [<a href="#cit0005" class="usa-link" aria-describedby="cit0005">5</a>]. LLMs offer several potential advantages for SAQ grading in medical education. They can provide immediate feedback, scale to accommodate large numbers of student responses, maintain consistency in evaluation criteria, and potentially reduce the subjective biases that can affect human graders [<a href="#cit0006" class="usa-link" aria-describedby="cit0006">6</a>]. Furthermore, LLMs could potentially offer detailed, individualized feedback on student responses, enhancing the formative aspect of assessment [<a href="#cit0014" class="usa-link" aria-describedby="cit0014">14</a>]. LLMs could transform traditional grading systems, characterized by their uniform and often manual approaches, into more nuanced, scalable, and efficient solutions [<a href="#cit0005" class="usa-link" aria-describedby="cit0005">5</a>,<a href="#cit0006" class="usa-link" aria-describedby="cit0006">6</a>].</p>
<p>Despite these promising potential applications, the use of LLMs for grading medical SAQs remains a relatively unexplored territory. While studies have examined the general capabilities of LLMs in understanding and generating medical content, there is limited research specifically investigating their effectiveness in evaluating student responses to medical SAQs. This gap in the literature is particularly notable given the unique challenges and requirements of medical education assessment, where accuracy, reliability, and validity are paramount [<a href="#cit0016" class="usa-link" aria-describedby="cit0016">16</a>].</p>
<p>Initial explorations into LLM-based grading in other domains suggest both promise and challenges. LLMs could achieve moderate agreement with human graders on undergraduate medical education short answer questions, with GPT-4 showing low rates of false positives and high precision for fully correct answers [<a href="#cit0005" class="usa-link" aria-describedby="cit0005">5</a>,<a href="#cit0015" class="usa-link" aria-describedby="cit0015">15</a>]. However, there are also limitations, including variability in performance across different questions and the need for high-quality sample solutions or rubrics to guide the LLM evaluation.</p>
<p>The integration of LLMs into medical education assessment also raises important ethical and practical considerations. Issues of bias, transparency, accountability, and the appropriate balance between automation and human judgment must be carefully addressed [<a href="#cit0006" class="usa-link" aria-describedby="cit0006">6</a>]. The deployment of LLMs in educational contexts must be approached with attention to both practical and ethical challenges to ensure that these technologies enhance rather than compromise the quality and fairness of assessment [<a href="#cit0017" class="usa-link" aria-describedby="cit0017">17</a>].</p>
<p>While preliminary research suggests the potential of LLMs in supporting SAQ grading, there remains a significant gap in our understanding of how these models perform specifically in medical education [<a href="#cit0005" class="usa-link" aria-describedby="cit0005">5</a>,<a href="#cit0015" class="usa-link" aria-describedby="cit0015">15</a>]. The unique characteristics of medical knowledge and reasoning, the high stakes of medical assessment, and the specific requirements of medical education create distinct challenges and opportunities for LLM application that warrant dedicated investigation.</p>
<p>This research gap is particularly significant given the importance of developing more efficient and effective assessment methods in medical education. As medical knowledge continues to expand and evolve, and educational programs face increasing demands for accountability and quality assurance, the need for reliable, scalable assessment approaches becomes ever more pressing. If LLMs can effectively support the grading of SAQs, they could enable more widespread use of this valuable assessment format, potentially enhancing the quality of medical education and assessment.</p>
<p>The potential of LLMs extends beyond medical assessment to transforming educational experiences across learning levels. These models can enhance reading and writing skills in elementary education, generate practice problems in secondary education, and assist university students with research tasks and complex material organization. However, successful educational integration requires careful consideration of its limitations, including interpretability challenges and potential biases, necessitating continued human oversight to ensure educational quality [<a href="#cit0018" class="usa-link" aria-describedby="cit0018">18</a>].</p>
<p>The emerging paradigm of ‘precision medical education’ integrates longitudinal data and analytics to drive precise educational interventions that address each individual learner’s needs and goals [<a href="#cit0019" class="usa-link" aria-describedby="cit0019">19</a>]. LLMs could potentially play a role in this paradigm, contributing to more personalized, data-driven approaches to medical education.</p>
<p>In light of these considerations, this study aims to explore the performance of LLMs in grading medical SAQs, focusing on understanding their agreement with expert human graders, the factors influencing their performance, and the potential implications for medical education assessment.</p></section><section id="s0002"><h2 class="pmc_sec_title">Materials and methods</h2>
<section id="s0002-s2001"><h3 class="pmc_sec_title">Study design</h3>
<p>This research evaluated the capability of Large Language Models to grade Short Answer Questions in medical examinations compared to expert human graders. This study involved a retrospective analysis of an existing examination database without directly interacting with students or collecting personal information. The files received from the assessment office were extracted from previous exams and contained 4 SAQs (one from anatomy, histology, embryology, and physiology) with 201 anonymous randomized answers each. So, there were 804 responses for evaluation in total. All prompts, parameters, and methods used with LLMs were documented to maintain transparency. <a href="#f0001" class="usa-link">Figure 1</a> summarizes SAQs used in this study, their respective grading scales, and steps in data collection.
</p>
<figure class="fig xbox font-sm" id="f0001"><h4 class="obj_head">Figure 1.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/d15f/12377152/082a8b248439/ZMEO_A_2550751_F0001_OC.jpg" loading="lazy" height="937" width="800" alt="Figure 1."></p>
<div class="p text-right font-secondary"><a href="figure/f0001/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>The workflow diagram that illustrates the data collection process.</p></figcaption></figure><p>Three independent faculty members (Expert X, Expert Y, and Expert Z) in the rank of full professor in the relevant fields constituted the expert panel. These experts graded responses independently without knowledge of student identity or other experts’ grades. Standardized, detailed rubrics were developed for each question to ensure consistent evaluation criteria.</p>
<p>Five different LLMs publicly available at the moment were included in the study: GPT-4.1 (OpenAI), Gemini 2.0 Flash (Google), Claude 3.7 Sonnet (Anthropic), Copilot (Microsoft), and DeepSeek R1 (Hangzhou Basic Technology Research Co.). The LLM evaluation process occurred in two phases. In the first attempt (A1), each LLM graded all 804 student responses based on internally generated criteria and correct answers based on learned representations. In the second attempt (A2), each LLM graded the same 804 student responses again, but this time using the expert-provided correct answers and grading criteria. <a href="#t0001" class="usa-link">Table 1</a> shows the different prompts used for A1 and A2 attempts. The prompts were developed using 10 tips for prompt development suggestions [<a href="#cit0020" class="usa-link" aria-describedby="cit0020">20</a>].</p>
<section class="tw xbox font-sm" id="t0001"><h4 class="obj_head">Table 1.</h4>
<div class="caption p"><p>Prompts used for LLM evaluation attempts.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col width="1*" align="left" span="1">
<col width="1*" align="left" span="1">
<col width="1*" align="left" span="1">
</colgroup>
<thead><tr>
<th align="left" colspan="1" rowspan="1">Attempt</th>
<th align="center" colspan="1" rowspan="1">Prompt Description</th>
<th align="center" colspan="1" rowspan="1">Example Prompt</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">A1 (First Attempt)</td>
<td align="left" colspan="1" rowspan="1">Basic prompts included question context and instructions to provide: 1) the correct answer, 2) create grading criteria, and 3) grade student responses</td>
<td align="left" colspan="1" rowspan="1">’Given the following medical question [SAQ], 1) What is the answer? 2) Generate rubrics/grading criteria to grade students“ answers on a scale of [0–2 or 0–3]. 3) Grade the students” answers below on a scale of [0–2 or 0–3] using the rubrics/grading criteria you designed before: [student answers]’</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">A2 (Second Attempt)</td>
<td align="left" colspan="1" rowspan="1">Enhanced prompts included question context, detailed expert-developed grading rubrics, and instructions to provide explanations for grades assigned</td>
<td align="left" colspan="1" rowspan="1">‘Given the following medical question [SAQ], use this expert-provided answer and grading rubric to evaluate student responses. The correct answer is: [expert answer]. The grading criteria are: [detailed rubric]. Evaluate all student responses and briefly explain your reasoning: [student answers]’</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/t0001/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p>This two-phase approach allowed for consistency testing, as each LLM evaluated all responses twice to test for consistency in grading and the impact of expert rubrics. The study also accounted for variations in prompt sensitivity by testing the impact of providing expert rubrics versus allowing LLMs to use criteria based on learned representations, and examined domain specificity by analyzing differences in LLM performance across the four medical disciplines.</p></section><section id="s0002-s2002"><h3 class="pmc_sec_title">Data collection</h3>
<p>The ability of GPT-4.1, Gemini, Claude, Copilot, and DeepSeek to grade student answers for 4 SAQs was assessed in May-June 2025. Data was collected in A1 and A2 independent testing sessions for each chatbot, separated by 24-hour intervals, ensuring each attempt was conducted as a fresh conversation session without access to previous responses. All LLM evaluations were conducted using the default settings provided by each model’s standard web interface without manual adjustment of hyperparameters such as temperature or top_p. This approach was chosen to reflect realistic usage scenarios where educators would interact with these LLMs through standard interfaces rather than API calls with customized parameters.</p>
<p>Results were compiled into separate CSV files for each SAQ (SAQ1-SAQ4). Each CSV file contained 13 columns representing grades from the 3 expert graders (Expert X, Expert Y, Expert Z), 5 LLMs’ first attempt (Claude A1, Copilot A1, DeepSeek A1, Gemini A1, GPT-4.1 A1), and 5 LLMs’ second attempt (Claude A2, Copilot A2, DeepSeek A2, Gemini A2, GPT-4.1 A2). A total of 10,452 responses (grades) were analyzed.</p>
<p>Cases where LLM grading students’ responses as ‘0’ (unsatisfactory) rationales were compiled and analyzed, with documentation provided in separate files for each SAQ. The quality and relevance of explanations provided by LLMs for their scoring decisions were evaluated, as was the LLMs’ handling of ambiguous or partially correct answers.</p>
<p>A consensus grade was created from the three experts for each response to serve as a gold standard. This consensus facilitated the calculation of performance metrics for LLMs against the expert standard and allowed for assessment of improvement from A1 to A2 for each LLM to evaluate the impact of expert rubrics.</p></section><section id="s0002-s2003"><h3 class="pmc_sec_title">Statistical analysis</h3>
<p>Agreement metrics were calculated between Expert-Expert pairs, Expert-LLM pairs (for both A1 and A2), LLM-LLM pairs, and A1-A2 for each LLM (to measure the impact of expert rubrics). Agreement among experts was quantified using Cohen’s Kappa and Intraclass Correlation Coefficient.</p>
<p>The statistical analysis compared mean scores and distribution of scores across experts and LLMs, analyzed differences in grading patterns across the four medical disciplines, identified systematic biases or strengths in LLM grading, conducted error analysis on cases with high disagreement, and evaluated the impact of expert rubrics on LLM performance (A1 vs. A2).</p>
<p>Performance metrics were calculated against the expert consensus for LLMs. The degree of improvement from A1 to A2 for each LLM was measured to evaluate the impact of expert rubrics on LLM performance. Statistical analyses were performed using R version 4.2.2 (R Foundation for Statistical Computing, Vienna, Austria).</p></section></section><section id="s0003"><h2 class="pmc_sec_title">Results</h2>
<p>A large amount of data was received and analyzed, including 2412 grades provided by three experts and 8040 responses from five LLMs. The examples of LLM responses to A1 and A2 prompts during SAQ grading are shown in <a href="#f0002" class="usa-link">Figure 2</a>.
</p>
<figure class="fig xbox font-sm" id="f0002"><h3 class="obj_head">Figure 2.</h3>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/d15f/12377152/8ef0b57256a3/ZMEO_A_2550751_F0002_OC.jpg" loading="lazy" height="829" width="800" alt="Figure 2."></p>
<div class="p text-right font-secondary"><a href="figure/f0002/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Copilot responses to A1 prompt - model-derived answers and rubrics (left side) and A2 prompt - expert-guided answers and rubrics (right side) in SAQ3 grading.</p></figcaption></figure><section id="s0003-s2001"><h3 class="pmc_sec_title">Agreement among experts</h3>
<p>The analysis of inter-rater reliability among the three expert graders (X, Y, and Z) revealed substantial agreement across all four short answer questions, as shown in <a href="#t0002" class="usa-link">Table 2</a>. The average Cohen’s Kappa values ranged from moderate to almost perfect agreement, providing a strong baseline against which to evaluate LLM performance. Expert agreement was consistently substantial across all question types, with SAQ4 (embryology) showing substantial to almost perfect agreement (average Kappa: 0.87), while SAQ2 (physiology) demonstrated the lowest, though still moderate, agreement (average Kappa: 0.57).</p>
<section class="tw xbox font-sm" id="t0002"><h4 class="obj_head">Table 2.</h4>
<div class="caption p"><p>Expert agreement summary (Cohen’s Kappa).</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col width="1*" align="left" span="1">
<col width="1*" align="char" char="." span="1">
<col width="1*" align="char" char="." span="1">
<col width="1*" align="char" char="." span="1">
<col width="1*" align="char" char="." span="1">
<col width="1*" align="char" char="." span="1">
</colgroup>
<thead><tr>
<th align="left" colspan="1" rowspan="1">Question</th>
<th align="center" colspan="1" rowspan="1">X vs Y</th>
<th align="center" colspan="1" rowspan="1">X vs Z</th>
<th align="center" colspan="1" rowspan="1">Y vs Z</th>
<th align="center" colspan="1" rowspan="1">Average</th>
<th align="center" colspan="1" rowspan="1">ICC</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">SAQ1 (0–2)</td>
<td align="center" colspan="1" rowspan="1">0.6500</td>
<td align="center" colspan="1" rowspan="1">0.6173</td>
<td align="center" colspan="1" rowspan="1">0.6598</td>
<td align="center" colspan="1" rowspan="1">0.6424</td>
<td align="center" colspan="1" rowspan="1">0.72</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">SAQ2 (0–2)</td>
<td align="center" colspan="1" rowspan="1">0.5537</td>
<td align="center" colspan="1" rowspan="1">0.4418</td>
<td align="center" colspan="1" rowspan="1">0.7154</td>
<td align="center" colspan="1" rowspan="1">0.5703</td>
<td align="center" colspan="1" rowspan="1">0.91</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">SAQ3 (0–3)</td>
<td align="center" colspan="1" rowspan="1">0.6604</td>
<td align="center" colspan="1" rowspan="1">0.6470</td>
<td align="center" colspan="1" rowspan="1">0.6737</td>
<td align="center" colspan="1" rowspan="1">0.6604</td>
<td align="center" colspan="1" rowspan="1">0.87</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">SAQ4 (0–2)</td>
<td align="center" colspan="1" rowspan="1">0.7990</td>
<td align="center" colspan="1" rowspan="1">0.8733</td>
<td align="center" colspan="1" rowspan="1">0.9398</td>
<td align="center" colspan="1" rowspan="1">0.8707</td>
<td align="center" colspan="1" rowspan="1">0.92</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"><strong>Average</strong></td>
<td align="center" colspan="1" rowspan="1"><strong>0.6658</strong></td>
<td align="center" colspan="1" rowspan="1"><strong>0.6449</strong></td>
<td align="center" colspan="1" rowspan="1"><strong>0.7472</strong></td>
<td align="center" colspan="1" rowspan="1"><strong>0.6860</strong></td>
<td align="center" colspan="1" rowspan="1"><strong>0.86</strong></td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/t0002/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="tfn0001"><p>Legend: This table presents agreement metrics between expert graders (X, Y, Z) across four different short-answer questions. Cohen’s Kappa values measure agreement adjusted for chance: 0.21–0.40 (fair), 0.41–0.60 (moderate), 0.61–0.80 (substantial), &gt; 0.81 (almost perfect). ICC (Intraclass Correlation Coefficient) measures consistency and absolute agreement among multiple raters: &lt; 0.50 (poor), 0.50–0.75 (moderate), 0.75–0.90 (good), &gt; 0.90 (excellent). The two metrics provide complementary perspectives on inter-rater reliability.</p></div></div></section><p>The Intraclass Correlation Coefficient (ICC) results further confirmed the high level of reliability among expert graders. The ICC values ranged from good (0.72 for SAQ1) to excellent (0.91 for SAQ2, 0.87 for SAQ3, and 0.92 for SAQ4), with an overall average of 0.86, indicating good to excellent consistency in absolute agreement among the expert raters. Notably, while SAQ2 showed the lowest Kappa values, it demonstrated excellent ICC (0.91), suggesting that despite some categorical disagreements captured by Kappa, the overall scoring pattern and magnitude of scores assigned by experts were highly consistent for this question.</p></section><section id="s0003-s2002"><h3 class="pmc_sec_title">Agreement between experts and LLMs using their own criteria (A1)</h3>
<p>When using internally generated criteria based on learned representations (A1), LLMs showed highly variable performance across question types and models, as detailed in <a href="#t0003" class="usa-link">Table 3</a>. Notable findings included best performances from Claude on SAQ3 (anatomy, Kappa: 0.61) and DeepSeek on SAQ2 (physiology, Kappa: 0.53), while the worst performances were observed for Copilot on SAQ1 (histology, Kappa: 0.04), DeepSeek on SAQ3 (anatomy, Kappa: 0.06), and Gemini on SAQ2 (physiology, Kappa: 0.06). GPT-4.1 emerged as the most consistent performer with Kappa values ranging from 0.13 to 0.39. This revealed significant variability in LLM performance when using their own grading criteria, with domain-specific strengths and weaknesses apparent across the different models.</p>
<section class="tw xbox font-sm" id="t0003"><h4 class="obj_head">Table 3.</h4>
<div class="caption p"><p>Expert-LLM agreement (Cohen’s Kappa) – A1 attempt.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col width="1*" align="left" span="1">
<col width="1*" align="char" char="." span="1">
<col width="1*" align="char" char="." span="1">
<col width="1*" align="char" char="." span="1">
<col width="1*" align="char" char="." span="1">
<col width="1*" align="char" char="." span="1">
</colgroup>
<thead><tr>
<th align="left" colspan="1" rowspan="1">LLM vs Avg Expert</th>
<th align="center" colspan="1" rowspan="1">SAQ1 (0–2)</th>
<th align="center" colspan="1" rowspan="1">SAQ2 (0–2)</th>
<th align="center" colspan="1" rowspan="1">SAQ3 (0–3)</th>
<th align="center" colspan="1" rowspan="1">SAQ4 (0–2)</th>
<th align="center" colspan="1" rowspan="1">Average</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Claude A1</td>
<td align="center" colspan="1" rowspan="1">0.2650</td>
<td align="center" colspan="1" rowspan="1">0.1167</td>
<td align="center" colspan="1" rowspan="1">0.6100</td>
<td align="center" colspan="1" rowspan="1">0.2257</td>
<td align="center" colspan="1" rowspan="1">0.3044</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Copilot A1</td>
<td align="center" colspan="1" rowspan="1">0.0394</td>
<td align="center" colspan="1" rowspan="1">0.4542</td>
<td align="center" colspan="1" rowspan="1">0.4134</td>
<td align="center" colspan="1" rowspan="1">0.0981</td>
<td align="center" colspan="1" rowspan="1">0.2513</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">DeepSeek A1</td>
<td align="center" colspan="1" rowspan="1">0.2735</td>
<td align="center" colspan="1" rowspan="1">0.5331</td>
<td align="center" colspan="1" rowspan="1">0.0560</td>
<td align="center" colspan="1" rowspan="1">0.0358</td>
<td align="center" colspan="1" rowspan="1">0.2246</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Gemini A1</td>
<td align="center" colspan="1" rowspan="1">0.1915</td>
<td align="center" colspan="1" rowspan="1">0.0645</td>
<td align="center" colspan="1" rowspan="1">0.5983</td>
<td align="center" colspan="1" rowspan="1">0.0712</td>
<td align="center" colspan="1" rowspan="1">0.2314</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GPT-4.1 A1</td>
<td align="center" colspan="1" rowspan="1">0.3851</td>
<td align="center" colspan="1" rowspan="1">0.2264</td>
<td align="center" colspan="1" rowspan="1">0.3518</td>
<td align="center" colspan="1" rowspan="1">0.1279</td>
<td align="center" colspan="1" rowspan="1">0.2728</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/t0003/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="tfn0002"><p>Legend: This table shows the Cohen’s Kappa values measuring agreement between each LLM (using internally generated criteria based on learned representations in the A1 attempt) and the average expert consensus. Values between 0.21–0.40 represent fair agreement, while values between 0.41–0.60 indicate moderate agreement and 0.61–0.80 substantial agreement.</p></div></div></section></section><section id="s0003-s2003"><h3 class="pmc_sec_title">Agreement between experts and LLMs using expert criteria (A2)</h3>
<p>When provided with expert grading criteria (A2), the agreement patterns shifted dramatically, as presented in <a href="#t0004" class="usa-link">Table 4</a>. Key observations included best performances from Gemini on SAQ3 (anatomy, Kappa: 0.61) and GPT-4.1 on SAQ3 (anatomy, Kappa: 0.58), while the worst performances were noted for Claude on SAQ4 (embryology, Kappa: 0.03) and Claude on SAQ2 (physiology, Kappa: 0.05). GPT-4.1 remained the most consistent performer with Kappa values ranging from 0.10 to 0.58. These results demonstrated that providing expert criteria did not universally improve agreement and, in some cases, substantially decreased it.</p>
<section class="tw xbox font-sm" id="t0004"><h4 class="obj_head">Table 4.</h4>
<div class="caption p"><p>Expert-LLM agreement (Cohen’s Kappa) – A2 attempt.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col width="1*" align="left" span="1">
<col width="1*" align="char" char="." span="1">
<col width="1*" align="char" char="." span="1">
<col width="1*" align="char" char="." span="1">
<col width="1*" align="char" char="." span="1">
<col width="1*" align="char" char="." span="1">
</colgroup>
<thead><tr>
<th align="left" colspan="1" rowspan="1">LLM vs Avg Expert</th>
<th align="center" colspan="1" rowspan="1">SAQ1 (0–2)</th>
<th align="center" colspan="1" rowspan="1">SAQ2 (0–2)</th>
<th align="center" colspan="1" rowspan="1">SAQ3 (0–3)</th>
<th align="center" colspan="1" rowspan="1">SAQ4 (0–2)</th>
<th align="center" colspan="1" rowspan="1">Average</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Claude A2</td>
<td align="center" colspan="1" rowspan="1">0.3630</td>
<td align="center" colspan="1" rowspan="1">0.0459</td>
<td align="center" colspan="1" rowspan="1">0.1298</td>
<td align="center" colspan="1" rowspan="1">0.0273</td>
<td align="center" colspan="1" rowspan="1">0.1415</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Copilot A2</td>
<td align="center" colspan="1" rowspan="1">0.2636</td>
<td align="center" colspan="1" rowspan="1">0.1190</td>
<td align="center" colspan="1" rowspan="1">0.3383</td>
<td align="center" colspan="1" rowspan="1">0.1396</td>
<td align="center" colspan="1" rowspan="1">0.2151</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">DeepSeek A2</td>
<td align="center" colspan="1" rowspan="1">0.0657</td>
<td align="center" colspan="1" rowspan="1">0.2226</td>
<td align="center" colspan="1" rowspan="1">0.5513</td>
<td align="center" colspan="1" rowspan="1">0.0817</td>
<td align="center" colspan="1" rowspan="1">0.2303</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Gemini A2</td>
<td align="center" colspan="1" rowspan="1">0.1844</td>
<td align="center" colspan="1" rowspan="1">0.0660</td>
<td align="center" colspan="1" rowspan="1">0.6142</td>
<td align="center" colspan="1" rowspan="1">0.0912</td>
<td align="center" colspan="1" rowspan="1">0.2390</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GPT-4.1 A2</td>
<td align="center" colspan="1" rowspan="1">0.2552</td>
<td align="center" colspan="1" rowspan="1">0.1027</td>
<td align="center" colspan="1" rowspan="1">0.5769</td>
<td align="center" colspan="1" rowspan="1">0.1574</td>
<td align="center" colspan="1" rowspan="1">0.2731</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/t0004/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="tfn0003"><p>Legend: This table presents Cohen’s Kappa values measuring agreement between each LLM (using expert-provided criteria in the A2 attempt) and the average expert consensus. Values between 0.21–0.40 represent fair agreement, while values between 0.41–0.60 indicate moderate agreement and 0.61–0.80 substantial agreement.</p></div></div></section></section><section id="s0003-s2004"><h3 class="pmc_sec_title">Impact of expert criteria (A1 vs A2)</h3>
<p>The impact of providing expert criteria varied dramatically by model and question type, as shown in <a href="#t0005" class="usa-link">Table 5</a>. Significant improvements were observed for DeepSeek on SAQ3 (anatomy, +0.50), Copilot on SAQ1 (histology, +0.22), and GPT-4.1 on SAQ3 (anatomy, +0.23). Conversely, significant declines were noted for Claude on SAQ3 (anatomy, −0.48), Copilot on SAQ2 (physiology, −0.34), and DeepSeek on SAQ2 (physiology, −0.31). Gemini emerged as the most consistent model, showing minimal changes across all SAQs when provided with expert criteria.</p>
<section class="tw xbox font-sm" id="t0005"><h4 class="obj_head">Table 5.</h4>
<div class="caption p"><p>Change in Cohen’s Kappa from A1 to A2.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col width="1*" align="left" span="1">
<col width="1*" align="char" char="." span="1">
<col width="1*" align="char" char="." span="1">
<col width="1*" align="char" char="." span="1">
<col width="1*" align="char" char="." span="1">
<col width="1*" align="char" char="." span="1">
</colgroup>
<thead><tr>
<th align="left" colspan="1" rowspan="1">LLM</th>
<th align="center" colspan="1" rowspan="1">SAQ1 (0–2)</th>
<th align="center" colspan="1" rowspan="1">SAQ2 (0–2)</th>
<th align="center" colspan="1" rowspan="1">SAQ3 (0–3)</th>
<th align="center" colspan="1" rowspan="1">SAQ4 (0–2)</th>
<th align="center" colspan="1" rowspan="1">Average</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Claude</td>
<td align="center" colspan="1" rowspan="1">+0.0980</td>
<td align="center" colspan="1" rowspan="1">−0.0708</td>
<td align="center" colspan="1" rowspan="1">−0.4803*</td>
<td align="center" colspan="1" rowspan="1">−0.1984*</td>
<td align="center" colspan="1" rowspan="1">−0.1629*</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Copilot</td>
<td align="center" colspan="1" rowspan="1">+0.2242*</td>
<td align="center" colspan="1" rowspan="1">−0.3353*</td>
<td align="center" colspan="1" rowspan="1">−0.0751</td>
<td align="center" colspan="1" rowspan="1">+0.0416</td>
<td align="center" colspan="1" rowspan="1">−0.0362</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">DeepSeek</td>
<td align="center" colspan="1" rowspan="1">−0.2079*</td>
<td align="center" colspan="1" rowspan="1">−0.3105*</td>
<td align="center" colspan="1" rowspan="1">+0.4952*</td>
<td align="center" colspan="1" rowspan="1">+0.0459</td>
<td align="center" colspan="1" rowspan="1">+0.0057</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Gemini</td>
<td align="center" colspan="1" rowspan="1">−0.0072</td>
<td align="center" colspan="1" rowspan="1">+0.0015</td>
<td align="center" colspan="1" rowspan="1">+0.0158</td>
<td align="center" colspan="1" rowspan="1">+0.0200</td>
<td align="center" colspan="1" rowspan="1">+0.0075</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GPT-4.1</td>
<td align="center" colspan="1" rowspan="1">−0.1299*</td>
<td align="center" colspan="1" rowspan="1">−0.1237*</td>
<td align="center" colspan="1" rowspan="1">+0.2250*</td>
<td align="center" colspan="1" rowspan="1">+0.0295</td>
<td align="center" colspan="1" rowspan="1">+0.0002</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/t0005/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="tfn0004"><p>Legend: This table displays the absolute change in Cohen’s Kappa values when moving from LLMs using their own criteria (A1) to using expert-provided criteria (A2). Positive values represent improvement in agreement with experts, while negative values indicate decreased agreement. Cohen’s Kappa is a unitless measure ranging from −1 to + 1, where + 1 indicates perfect agreement, 0 indicates agreement equivalent to chance, and negative values indicate agreement worse than chance. Asterisks (*) denote statistically significant differences (<em>p</em> &lt; 0.05) between A1 and A2 attempts.</p></div></div></section></section><section id="s0003-s2005"><h3 class="pmc_sec_title">Best performers by question type</h3>
<p>The optimal model varied by question type, and providing expert criteria did not consistently improve performance, as detailed in <a href="#t0006" class="usa-link">Table 6</a>. For SAQ1 (histology), GPT-4.1 performed best with its own criteria (Kappa: 0.39), while Claude achieved the highest agreement when using expert criteria (Kappa: 0.36). DeepSeek excelled in SAQ2 (physiology) in both conditions, though with better performance using its own criteria. SAQ3 (anatomy) saw the highest overall agreement levels, with Claude (A1) and Gemini (A2) both achieving substantial agreement with experts (Kappa: ~0.61). Despite having the highest expert agreement, SAQ4 (embryology) consistently showed the lowest LLM-expert agreement levels.</p>
<section class="tw xbox font-sm" id="t0006"><h4 class="obj_head">Table 6.</h4>
<div class="caption p"><p>Best performers by question type.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col width="1*" align="left" span="1">
<col width="1*" align="left" span="1">
<col width="1*" align="char" char="." span="1">
<col width="1*" align="left" span="1">
<col width="1*" align="char" char="." span="1">
</colgroup>
<thead><tr>
<th align="left" colspan="1" rowspan="1">Question</th>
<th align="center" colspan="1" rowspan="1">Best A1 Model</th>
<th align="center" colspan="1" rowspan="1">Kappa</th>
<th align="center" colspan="1" rowspan="1">Best A2 Model</th>
<th align="center" colspan="1" rowspan="1">Kappa</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">SAQ1 (0–2)</td>
<td align="left" colspan="1" rowspan="1">GPT-4.1</td>
<td align="center" colspan="1" rowspan="1">0.3851</td>
<td align="left" colspan="1" rowspan="1">Claude</td>
<td align="center" colspan="1" rowspan="1">0.3630</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">SAQ2 (0–2)</td>
<td align="left" colspan="1" rowspan="1">DeepSeek</td>
<td align="center" colspan="1" rowspan="1">0.5331</td>
<td align="left" colspan="1" rowspan="1">DeepSeek</td>
<td align="center" colspan="1" rowspan="1">0.2226</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">SAQ3 (0–3)</td>
<td align="left" colspan="1" rowspan="1">Claude</td>
<td align="center" colspan="1" rowspan="1">0.6100</td>
<td align="left" colspan="1" rowspan="1">Gemini</td>
<td align="center" colspan="1" rowspan="1">0.6142</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">SAQ4 (0–2)</td>
<td align="left" colspan="1" rowspan="1">Claude</td>
<td align="center" colspan="1" rowspan="1">0.2257</td>
<td align="left" colspan="1" rowspan="1">GPT-4.1</td>
<td align="center" colspan="1" rowspan="1">0.1574</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/t0006/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="tfn0005"><p>Legend: This table identifies the best-performing LLM for each question type under both conditions (A1: using their own criteria, A2: using expert-provided criteria) and shows their respective Cohen’s Kappa values.</p></div></div></section></section><section id="s0003-s2006"><h3 class="pmc_sec_title">Analysis of unsatisfactory responses</h3>
<p>Expert graders demonstrated remarkable consistency in identifying unsatisfactory responses, as shown in <a href="#t0007" class="usa-link">Table 7</a>. The expert consensus identified 13 unsatisfactory responses (6.5%) in SAQ1, 8 (4.0%) in SAQ2, 4 (2.0%) in SAQ3, and 3 (1.5%) in SAQ4. LLMs, however, showed substantial variation in their strictness. In SAQ1 (histology), DeepSeek A1 was notably stricter (17.4%) than experts, while Copilot A1 gave no ‘0’ scores. For SAQ2 (physiology), Gemini was much stricter (18.9% in A1, 19.4% in A2) than experts. Most dramatically, in SAQ4 (embryology), DeepSeek A1 identified far more unsatisfactory responses (36.3%) than experts (1.5%).</p>
<section class="tw xbox font-sm" id="t0007"><h4 class="obj_head">Table 7.</h4>
<div class="caption p"><p>Distribution of ‘0’ scores across all SAQs.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col width="1*" align="left" span="1">
<col width="1*" align="center" span="1">
<col width="1*" align="center" span="1">
<col width="1*" align="center" span="1">
<col width="1*" align="center" span="1">
</colgroup>
<thead><tr>
<th align="left" colspan="1" rowspan="1">Grader</th>
<th align="center" colspan="1" rowspan="1">SAQ1</th>
<th align="center" colspan="1" rowspan="1">SAQ2</th>
<th align="center" colspan="1" rowspan="1">SAQ3</th>
<th align="center" colspan="1" rowspan="1">SAQ4</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1"><strong>Experts</strong></td>
<td align="center" colspan="1" rowspan="1"> </td>
<td align="center" colspan="1" rowspan="1"> </td>
<td align="center" colspan="1" rowspan="1"> </td>
<td align="center" colspan="1" rowspan="1"> </td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Expert X</td>
<td align="center" colspan="1" rowspan="1">14 (7.0%)</td>
<td align="center" colspan="1" rowspan="1">8 (4.0%)</td>
<td align="center" colspan="1" rowspan="1">3 (1.5%)</td>
<td align="center" colspan="1" rowspan="1">3 (1.5%)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Expert Y</td>
<td align="center" colspan="1" rowspan="1">13 (6.5%)</td>
<td align="center" colspan="1" rowspan="1">8 (4.0%)</td>
<td align="center" colspan="1" rowspan="1">4 (2.0%)</td>
<td align="center" colspan="1" rowspan="1">3 (1.5%)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Expert Z</td>
<td align="center" colspan="1" rowspan="1">14 (7.0%)</td>
<td align="center" colspan="1" rowspan="1">9 (4.5%)</td>
<td align="center" colspan="1" rowspan="1">4 (2.0%)</td>
<td align="center" colspan="1" rowspan="1">3 (1.5%)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Expert Consensus</td>
<td align="center" colspan="1" rowspan="1">13 (6.5%)</td>
<td align="center" colspan="1" rowspan="1">8 (4.0%)</td>
<td align="center" colspan="1" rowspan="1">4 (2.0%)</td>
<td align="center" colspan="1" rowspan="1">3 (1.5%)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"><strong>LLMs (A1)</strong></td>
<td align="center" colspan="1" rowspan="1"> </td>
<td align="center" colspan="1" rowspan="1"> </td>
<td align="center" colspan="1" rowspan="1"> </td>
<td align="center" colspan="1" rowspan="1"> </td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Claude A1</td>
<td align="center" colspan="1" rowspan="1">5 (2.5%)</td>
<td align="center" colspan="1" rowspan="1">8 (4.0%)</td>
<td align="center" colspan="1" rowspan="1">1 (0.5%)</td>
<td align="center" colspan="1" rowspan="1">3 (1.5%)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Copilot A1</td>
<td align="center" colspan="1" rowspan="1">0 (0.0%)</td>
<td align="center" colspan="1" rowspan="1">8 (4.0%)</td>
<td align="center" colspan="1" rowspan="1">3 (1.5%)</td>
<td align="center" colspan="1" rowspan="1">12 (6.0%)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">DeepSeek A1</td>
<td align="center" colspan="1" rowspan="1">35 (17.4%)</td>
<td align="center" colspan="1" rowspan="1">8 (4.0%)</td>
<td align="center" colspan="1" rowspan="1">2 (1.0%)</td>
<td align="center" colspan="1" rowspan="1">73 (36.3%)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Gemini A1</td>
<td align="center" colspan="1" rowspan="1">6 (3.0%)</td>
<td align="center" colspan="1" rowspan="1">38 (18.9%)</td>
<td align="center" colspan="1" rowspan="1">2 (1.0%)</td>
<td align="center" colspan="1" rowspan="1">29 (14.4%)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GPT-4.1 A1</td>
<td align="center" colspan="1" rowspan="1">6 (3.0%)</td>
<td align="center" colspan="1" rowspan="1">10 (5.0%)</td>
<td align="center" colspan="1" rowspan="1">0 (0.0%)</td>
<td align="center" colspan="1" rowspan="1">1 (0.5%)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"><strong>LLMs (A2)</strong></td>
<td align="center" colspan="1" rowspan="1"> </td>
<td align="center" colspan="1" rowspan="1"> </td>
<td align="center" colspan="1" rowspan="1"> </td>
<td align="center" colspan="1" rowspan="1"> </td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Claude A2</td>
<td align="center" colspan="1" rowspan="1">3 (1.5%)</td>
<td align="center" colspan="1" rowspan="1">10 (5.0%)</td>
<td align="center" colspan="1" rowspan="1">4 (2.0%)</td>
<td align="center" colspan="1" rowspan="1">0 (0.0%)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Copilot A2</td>
<td align="center" colspan="1" rowspan="1">2 (1.0%)</td>
<td align="center" colspan="1" rowspan="1">21 (10.4%)</td>
<td align="center" colspan="1" rowspan="1">12 (6.0%)</td>
<td align="center" colspan="1" rowspan="1">7 (3.5%)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">DeepSeek A2</td>
<td align="center" colspan="1" rowspan="1">11 (5.5%)</td>
<td align="center" colspan="1" rowspan="1">10 (5.0%)</td>
<td align="center" colspan="1" rowspan="1">0 (0.0%)</td>
<td align="center" colspan="1" rowspan="1">12 (6.0%)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Gemini A2</td>
<td align="center" colspan="1" rowspan="1">4 (2.0%)</td>
<td align="center" colspan="1" rowspan="1">39 (19.4%)</td>
<td align="center" colspan="1" rowspan="1">2 (1.0%)</td>
<td align="center" colspan="1" rowspan="1">16 (8.0%)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GPT-4.1 A2</td>
<td align="center" colspan="1" rowspan="1">6 (3.0%)</td>
<td align="center" colspan="1" rowspan="1">23 (11.4%)</td>
<td align="center" colspan="1" rowspan="1">0 (0.0%)</td>
<td align="center" colspan="1" rowspan="1">6 (3.0%)</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/t0007/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="tfn0006"><p>Legend: This table presents the number and percentage of responses assigned a score of ‘0’ (unsatisfactory) by each expert grader and LLM across all four SAQs. Expert Consensus represents cases where at least two of the three experts assigned a ‘0’ score.</p></div></div></section><p>In identifying unsatisfactory responses, the agreement with expert consensus varied significantly across models and question types, as detailed in <a href="#t0008" class="usa-link">Table 8</a>. DeepSeek showed the highest overall agreement (77.9%) using its own criteria (A1), while Copilot demonstrated the most improvement (+22.6%) when provided with expert criteria (A2). SAQ2 (physiology) showed near-perfect agreement (97.5–100%) between LLMs and experts, while SAQ1 (histology) and SAQ3 (anatomy) had the lowest agreement (29.2–30.8%).</p>
<section class="tw xbox font-sm" id="t0008"><h4 class="obj_head">Table 8.</h4>
<div class="caption p"><p>Agreement with expert consensus on unsatisfactory responses.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col width="1*" align="left" span="1">
<col width="1*" align="left" span="1">
<col width="1*" align="center" span="1">
<col width="1*" align="center" span="1">
<col width="1*" align="center" span="1">
<col width="1*" align="center" span="1">
<col width="1*" align="char" char="." span="1">
</colgroup>
<thead><tr>
<th align="left" colspan="1" rowspan="1">LLM Model</th>
<th align="center" colspan="1" rowspan="1">Metric</th>
<th align="center" colspan="1" rowspan="1">SAQ1</th>
<th align="center" colspan="1" rowspan="1">SAQ2</th>
<th align="center" colspan="1" rowspan="1">SAQ3</th>
<th align="center" colspan="1" rowspan="1">SAQ4</th>
<th align="center" colspan="1" rowspan="1">Average</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Claude</td>
<td align="left" colspan="1" rowspan="1">A1 Agreement</td>
<td align="center" colspan="1" rowspan="1">3/13 (23.1%)</td>
<td align="center" colspan="1" rowspan="1">7/8 (87.5%)</td>
<td align="center" colspan="1" rowspan="1">1/4 (25.0%)</td>
<td align="center" colspan="1" rowspan="1">2/3 (66.7%)</td>
<td align="center" colspan="1" rowspan="1">50.6%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> </td>
<td align="left" colspan="1" rowspan="1">A2 Agreement</td>
<td align="center" colspan="1" rowspan="1">2/13 (15.4%)</td>
<td align="center" colspan="1" rowspan="1">8/8 (100.0%)</td>
<td align="center" colspan="1" rowspan="1">2/4 (50.0%)</td>
<td align="center" colspan="1" rowspan="1">0/3 (0.0%)</td>
<td align="center" colspan="1" rowspan="1">41.4%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> </td>
<td align="left" colspan="1" rowspan="1">Change</td>
<td align="center" colspan="1" rowspan="1">−7.7%</td>
<td align="center" colspan="1" rowspan="1">+12.5%</td>
<td align="center" colspan="1" rowspan="1">+25.0%</td>
<td align="center" colspan="1" rowspan="1">−66.7%*</td>
<td align="center" colspan="1" rowspan="1">−9.2%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Copilot</td>
<td align="left" colspan="1" rowspan="1">A1 Agreement</td>
<td align="center" colspan="1" rowspan="1">0/13 (0.0%)</td>
<td align="center" colspan="1" rowspan="1">8/8 (100.0%)</td>
<td align="center" colspan="1" rowspan="1">1/4 (25.0%)</td>
<td align="center" colspan="1" rowspan="1">2/3 (66.7%)</td>
<td align="center" colspan="1" rowspan="1">47.9%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> </td>
<td align="left" colspan="1" rowspan="1">A2 Agreement</td>
<td align="center" colspan="1" rowspan="1">2/13 (15.4%)</td>
<td align="center" colspan="1" rowspan="1">8/8 (100.0%)</td>
<td align="center" colspan="1" rowspan="1">4/4 (100.0%)</td>
<td align="center" colspan="1" rowspan="1">2/3 (66.7%)</td>
<td align="center" colspan="1" rowspan="1">70.5%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> </td>
<td align="left" colspan="1" rowspan="1">Change</td>
<td align="center" colspan="1" rowspan="1">+15.4%*</td>
<td align="center" colspan="1" rowspan="1">0.0%</td>
<td align="center" colspan="1" rowspan="1">+75.0%*</td>
<td align="center" colspan="1" rowspan="1">0.0%</td>
<td align="center" colspan="1" rowspan="1">+22.6%*</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">DeepSeek</td>
<td align="left" colspan="1" rowspan="1">A1 Agreement</td>
<td align="center" colspan="1" rowspan="1">8/13 (61.5%)</td>
<td align="center" colspan="1" rowspan="1">8/8 (100.0%)</td>
<td align="center" colspan="1" rowspan="1">2/4 (50.0%)</td>
<td align="center" colspan="1" rowspan="1">3/3 (100.0%)</td>
<td align="center" colspan="1" rowspan="1">77.9%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> </td>
<td align="left" colspan="1" rowspan="1">A2 Agreement</td>
<td align="center" colspan="1" rowspan="1">7/13 (53.8%)</td>
<td align="center" colspan="1" rowspan="1">8/8 (100.0%)</td>
<td align="center" colspan="1" rowspan="1">0/4 (0.0%)</td>
<td align="center" colspan="1" rowspan="1">3/3 (100.0%)</td>
<td align="center" colspan="1" rowspan="1">63.5%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> </td>
<td align="left" colspan="1" rowspan="1">Change</td>
<td align="center" colspan="1" rowspan="1">−7.7%</td>
<td align="center" colspan="1" rowspan="1">0.0%</td>
<td align="center" colspan="1" rowspan="1">−50.0%*</td>
<td align="center" colspan="1" rowspan="1">0.0%</td>
<td align="center" colspan="1" rowspan="1">−14.4%*</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Gemini</td>
<td align="left" colspan="1" rowspan="1">A1 Agreement</td>
<td align="center" colspan="1" rowspan="1">2/13 (15.4%)</td>
<td align="center" colspan="1" rowspan="1">8/8 (100.0%)</td>
<td align="center" colspan="1" rowspan="1">2/4 (50.0%)</td>
<td align="center" colspan="1" rowspan="1">3/3 (100.0%)</td>
<td align="center" colspan="1" rowspan="1">66.3%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> </td>
<td align="left" colspan="1" rowspan="1">A2 Agreement</td>
<td align="center" colspan="1" rowspan="1">4/13 (30.8%)</td>
<td align="center" colspan="1" rowspan="1">8/8 (100.0%)</td>
<td align="center" colspan="1" rowspan="1">2/4 (50.0%)</td>
<td align="center" colspan="1" rowspan="1">3/3 (100.0%)</td>
<td align="center" colspan="1" rowspan="1">70.2%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> </td>
<td align="left" colspan="1" rowspan="1">Change</td>
<td align="center" colspan="1" rowspan="1">+15.4%*</td>
<td align="center" colspan="1" rowspan="1">0.0%</td>
<td align="center" colspan="1" rowspan="1">0.0%</td>
<td align="center" colspan="1" rowspan="1">0.0%</td>
<td align="center" colspan="1" rowspan="1">+3.9%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">GPT-4.1</td>
<td align="left" colspan="1" rowspan="1">A1 Agreement</td>
<td align="center" colspan="1" rowspan="1">6/13 (46.2%)</td>
<td align="center" colspan="1" rowspan="1">8/8 (100.0%)</td>
<td align="center" colspan="1" rowspan="1">0/4 (0.0%)</td>
<td align="center" colspan="1" rowspan="1">1/3 (33.3%)</td>
<td align="center" colspan="1" rowspan="1">44.9%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> </td>
<td align="left" colspan="1" rowspan="1">A2 Agreement</td>
<td align="center" colspan="1" rowspan="1">5/13 (38.5%)</td>
<td align="center" colspan="1" rowspan="1">8/8 (100.0%)</td>
<td align="center" colspan="1" rowspan="1">0/4 (0.0%)</td>
<td align="center" colspan="1" rowspan="1">2/3 (66.7%)</td>
<td align="center" colspan="1" rowspan="1">51.3%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> </td>
<td align="left" colspan="1" rowspan="1">Change</td>
<td align="center" colspan="1" rowspan="1">−7.7%</td>
<td align="center" colspan="1" rowspan="1">0.0%</td>
<td align="center" colspan="1" rowspan="1">0.0%</td>
<td align="center" colspan="1" rowspan="1">+33.3%*</td>
<td align="center" colspan="1" rowspan="1">+6.4%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Average</td>
<td align="left" colspan="1" rowspan="1">A1 Agreement</td>
<td align="center" colspan="1" rowspan="1">29.2%</td>
<td align="center" colspan="1" rowspan="1">97.5%</td>
<td align="center" colspan="1" rowspan="1">30.0%</td>
<td align="center" colspan="1" rowspan="1">73.3%</td>
<td align="center" colspan="1" rowspan="1">57.5%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> </td>
<td align="left" colspan="1" rowspan="1">A2 Agreement</td>
<td align="center" colspan="1" rowspan="1">30.8%</td>
<td align="center" colspan="1" rowspan="1">100.0%</td>
<td align="center" colspan="1" rowspan="1">40.0%</td>
<td align="center" colspan="1" rowspan="1">66.7%</td>
<td align="center" colspan="1" rowspan="1">59.4%</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"> </td>
<td align="left" colspan="1" rowspan="1">Change</td>
<td align="center" colspan="1" rowspan="1">+1.5%</td>
<td align="center" colspan="1" rowspan="1">+2.5%</td>
<td align="center" colspan="1" rowspan="1">+10.0%*</td>
<td align="center" colspan="1" rowspan="1">−6.7%</td>
<td align="center" colspan="1" rowspan="1">+1.8%</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/t0008/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="tfn0007"><p>Legend: This table shows the number and percentage of expert-identified unsatisfactory responses that were also marked as unsatisfactory by each LLM. The format ’3/13 (23.1%)’ indicates that the LLM correctly identified 3 out of 13 responses that experts marked as unsatisfactory, representing 23.1% agreement. Asterisks (*) denote statistically significant differences (<em>p</em> &lt; 0.05) between A1 and A2 attempts.</p></div></div></section></section><section id="s0003-s2007"><h3 class="pmc_sec_title">Analysis of LLM-identified unsatisfactory responses not marked by experts</h3>
<p>Each LLM demonstrated distinct grading patterns:</p>
<p>Claude: Most balanced overall, but showed inconsistent alignment with experts across different subjects. Dramatic decline in performance on SAQ3 (−0.48) and SAQ4 (−0.20) when provided with expert criteria.</p>
<p>Copilot: Most improved with expert criteria (+22.6% for unsatisfactory responses), demonstrating strong adaptability to expert standards. Perfect detection of unsatisfactory responses in SAQ3 with expert criteria.</p>
<p>DeepSeek: Highest initial alignment with experts using its own criteria (77.9% for unsatisfactory responses) but less adaptable to expert rubrics. Exceptionally strict in SAQ4, marking 36.3% of responses as unsatisfactory compared to experts’ 1.5%.</p>
<p>Gemini: Most consistent performer with minimal changes between A1 and A2 attempts. Notably stricter in SAQ2, marking approximately 19% of responses as unsatisfactory compared to experts’ 4%.</p>
<p>GPT-4.1: Moderate overall performance with balanced results across different medical domains. Most consistent performer in the A1 attempt with the smallest range of Kappa values (0.13–0.39).</p></section><section id="s0003-s2008"><h3 class="pmc_sec_title">Model-specific performance patterns</h3>
<p>Each LLM demonstrated distinct grading patterns across the medical disciplines. Claude showed balanced overall performance but experienced a dramatic decline in agreement on SAQ3 (−0.48) and SAQ4 (−0.20) when provided with expert criteria. Copilot demonstrated the most improvement with expert criteria (+22.6% for unsatisfactory responses), achieving perfect detection of unsatisfactory responses in SAQ3 when using expert criteria. DeepSeek achieved the highest initial alignment with experts using its own criteria (77.9% for unsatisfactory responses) but was less adaptable to expert rubrics and was exceptionally strict in SAQ4, marking 36.3% of responses as unsatisfactory compared to experts’ 1.5%. Gemini maintained the most consistent performance with minimal changes between A1 and A2 attempts, though it was notably stricter in SAQ2, marking approximately 19% of responses as unsatisfactory compared to experts’ 4%. GPT-4.1 demonstrated moderate overall performance with balanced results across different medical domains and was the most consistent performer in the A1 attempt, with the smallest range of Kappa values (0.13–0.39).</p></section></section><section id="s0004"><h2 class="pmc_sec_title">Discussion</h2>
<p>Our analysis of 804 student responses across four medical SAQs revealed significant variations in how Large Language Models (LLMs) perform compared to expert human graders. The key finding was substantial inconsistency in LLM grading performance across different question types, medical domains, and grading criteria. While no LLM consistently matched expert agreement (average Kappa: 0.69, average ICC: 0.86) across all questions, certain models achieved substantial agreement in specific contexts, notably Claude on SAQ3 (Kappa: 0.61) and DeepSeek on SAQ2 (Kappa: 0.53). Surprisingly, providing expert-developed grading criteria did not consistently improve LLM performance, with some models showing significant decreases in accuracy when using expert rubrics.</p>
<p>Contrasting with our findings of variable LLM performance in SAQ grading, recent research in histology assessment has demonstrated high LLM accuracy, with all five major models (GPT-4.1, Claude 3.7 Sonnet, Gemini 2.0 Flash, Copilot, and DeepSeek R1) achieving a mean accuracy of 91.1% (SD 7.2) on USMLE-style multiple choice questions [<a href="#cit0021" class="usa-link" aria-describedby="cit0021">21</a>]. This study revealed minimal inter-system variability, with performance ranging from DeepSeek’s 90.3% to Gemini’s 92.0%, and no statistically significant differences between models (<em>p</em> &gt; 0.05), suggesting that the assessment format (MCQ vs. SAQ grading) may be a critical determinant of LLM reliability in medical education contexts.</p>
<p>Most LLMs during SAQ grading demonstrated high precision for fully correct answers and low rates of false positives, but struggled with partially correct responses and showed an overall tendency toward conservative grading. These findings suggest that while LLMs have promising capabilities for supporting medical education assessment, their application requires domain-specific considerations and continued human oversight.</p>
<section id="s0004-s2001"><h3 class="pmc_sec_title">Inter-rater agreement and consistency</h3>
<p>Expert agreement (Kappa 0.69, ICC 0.86) establishes a strong baseline against which to evaluate LLM performance. The substantial to almost perfect agreement among experts (Kappa ranging from 0.57 for SAQ2 to 0.87 for SAQ4) and good to excellent ICC values (ranging from 0.72 for SAQ1 to 0.92 for SAQ4) demonstrate the reliability of human expert grading in medical education. The dual measurement approach using both Cohen’s Kappa and ICC provides complementary insights into rater consistency, with Kappa focusing on categorical agreement and ICC capturing the overall pattern and magnitude of scoring. This robust measurement approach aligns with previous research on the importance of expert consensus in evaluating medical knowledge [<a href="#cit0005" class="usa-link" aria-describedby="cit0005">5</a>].</p>
<p>Notably, the divergence between Kappa and ICC values for certain questions (particularly SAQ2, with a moderate Kappa of 0.57 but an excellent ICC of 0.91) suggests that while experts may occasionally assign different categorical scores, their overall evaluation patterns remain highly consistent. This pattern indicates that even when specific scoring decisions differ, experts maintain reliable judgments about the relative quality of student responses, reinforcing the validity of the expert consensus as a benchmark for LLM evaluation.</p>
<p>A key finding is the considerable variability in LLM performance across different SAQs and between attempts. For instance, Claude performed exceptionally well on SAQ3 in the first attempt (Kappa 0.61) but showed a dramatic decrease in the second attempt (−0.48). Conversely, DeepSeek improved significantly on SAQ3 in the second attempt (+0.50) while declining on other questions. This variability suggests that LLM performance is highly context-dependent and can be influenced by factors such as question type, medical domain, and the specificity of grading criteria provided.</p>
<p>Our findings align with research showing that GPT-4 achieved high precision for fully correct answers but had challenges with partially correct ones [<a href="#cit0006" class="usa-link" aria-describedby="cit0006">6</a>]. In radiology assessment contexts, human experts have consistently demonstrated superior performance compared to LLMs, with residents achieving 63.33% and 57.5% accuracy compared to AI models (Bard: 44.17%, Bing: 53.33%, ChatGPT: 45%) on Fellowship of the Royal College of Radiologists examination-style questions [<a href="#cit0022" class="usa-link" aria-describedby="cit0022">22</a>]. Notably, this study revealed significant agreement among AI models (ICC = 0.628) but paradoxically poor agreement between human residents (Kappa = −0.376), suggesting that while AI models may converge on similar grading patterns, human expertise introduces valuable variability in assessment approaches. Similarly, Decision Trees in grading anatomical OSPEs have shown an average accuracy of 94.49%, suggesting that different AI approaches may be suitable for different assessment contexts [<a href="#cit0023" class="usa-link" aria-describedby="cit0023">23</a>].</p></section><section id="s0004-s2002"><h3 class="pmc_sec_title">Impact of expert criteria on LLM performance</h3>
<p>A striking observation is that providing expert grading criteria (A2) did not consistently improve LLM performance compared to their own criteria (A1). This contradicts the intuitive expectation that explicit expert guidance would enhance grading accuracy. For instance, Claude’s agreement with experts on SAQ3 decreased dramatically from 0.61 to 0.13 when provided with expert criteria. This suggests that LLMs may develop their own internal models of medical knowledge assessment that sometimes diverge from expert-defined criteria.</p>
<p>This phenomenon may reflect challenges in how LLMs interpret and apply complex rubrics, particularly in specialized medical domains. Research has noted that LLMs might struggle with nuanced interpretation of domain-specific evaluation criteria [<a href="#cit0005" class="usa-link" aria-describedby="cit0005">5</a>,<a href="#cit0024" class="usa-link" aria-describedby="cit0024">24</a>]. The variability in how LLMs respond to expert criteria highlights the need for careful prompt engineering and potentially model fine-tuning for specific assessment contexts.</p></section><section id="s0004-s2003"><h3 class="pmc_sec_title">Domain-specific performance</h3>
<p>Our results reveal substantial differences in LLM performance across medical disciplines. For example, all models performed better on SAQ3 than on SAQ4, despite SAQ4 having the highest expert agreement (Kappa: 0.87, ICC: 0.92). This suggests that the difficulty of a question for experts does not necessarily correlate with its difficulty for LLMs, pointing to fundamental differences in how human experts and AI models process and evaluate medical knowledge.</p>
<p>The high ICC values across all questions indicate that experts maintained consistent scoring patterns even for technically challenging questions like SAQ2. In contrast, LLMs showed wide performance variability on the same questions, suggesting they may lack the nuanced domain understanding that allows human experts to maintain scoring consistency across different types of responses.</p>
<p>These domain-specific variations align with findings reporting varying LLM performance across different topics in medical embryology, biochemistry, and anatomy [<a href="#cit0008" class="usa-link" aria-describedby="cit0008">8</a>,<a href="#cit0011" class="usa-link" aria-describedby="cit0011">11</a>,<a href="#cit0025" class="usa-link" aria-describedby="cit0025">25</a>], and similar variations in neuroscience and physiology topics [<a href="#cit0013" class="usa-link" aria-describedby="cit0013">13</a>,<a href="#cit0026" class="usa-link" aria-describedby="cit0026">26</a>]. The inconsistent performance across domains indicates that medical educators should consider domain-specific validation before implementing LLM-based grading in any particular subject area [<a href="#cit0002" class="usa-link" aria-describedby="cit0002">2</a>].</p></section><section id="s0004-s2004"><h3 class="pmc_sec_title">Analysis of unsatisfactory responses</h3>
<p>The analysis of responses graded as unsatisfactory (score of ‘0’) reveals important patterns in how LLMs evaluate incorrect answers. The significant variation in strictness across LLMs is notable, with some models (e.g., DeepSeek in SAQ4: 36.3%) being considerably more strict than experts (1.5%), while others (e.g., Copilot in SAQ1: 0%) were more lenient than experts (6.5%).</p>
<p>The high agreement on unsatisfactory responses for SAQ2 (lung compliance) across all models (97.5–100%) contrasts sharply with the lower agreement for SAQ1 (tissue types) and SAQ3 (ureter constrictions). This suggests that some medical concepts may have more clearly defined boundaries of correctness that are consistently recognizable by both humans and AI, while others have more nuanced or subjective assessment criteria.</p>
<p>LLMs demonstrated distinct grading patterns, with models like DeepSeek consistently being stricter while others like Claude more closely aligned with expert consensus. Research has found that ChatGPT could pass short answer assessments in undergraduate medical education but outperformed only underperforming students [<a href="#cit0015" class="usa-link" aria-describedby="cit0015">15</a>]. This suggests potential utility for LLMs in identifying clearly incorrect responses, potentially reducing the grading burden for educators.</p></section><section id="s0004-s2005"><h3 class="pmc_sec_title">False positives and false negatives</h3>
<p>Our analysis of false positives (incorrectly assigning a high score) and false negatives (incorrectly assigning a low score) provides critical insights for potential implementation. The relatively low rate of false positives, particularly for GPT-4.1 and Claude, is encouraging for using LLM in medical education, where avoiding the passing of incorrect knowledge is paramount. However, the higher rate of false negatives across all LLMs indicates a tendency toward conservative grading that might unfairly penalize some students.</p>
<p>This pattern aligns with observations that GPT-4 was significantly more conservative in grading than human evaluators in undergraduate medical education [<a href="#cit0005" class="usa-link" aria-describedby="cit0005">5</a>]. In high-stakes medical assessment, the consequences of false positives (incorrectly passing students) may be considered more serious than false negatives (incorrectly failing students), suggesting that a conservative bias might be acceptable in certain contexts, particularly for preliminary screening.</p></section><section id="s0004-s2006"><h3 class="pmc_sec_title">Explaining differences in LLM grading patterns</h3>
<p>LLMs provided various rationales for their grading decisions that offer insights into their evaluation processes. Common explanations for more lenient grading included recognizing partial understanding and valuing foundational knowledge over precise terminology. More strict grading was justified by identifying significant misunderstandings, particularly in treatment-related questions where precision is crucial [<a href="#cit0015" class="usa-link" aria-describedby="cit0015">15</a>,<a href="#cit0027" class="usa-link" aria-describedby="cit0027">27</a>].</p>
<p>These rationales suggest that LLMs apply a form of educational philosophy in their grading, sometimes prioritizing encouragement of student effort over strict adherence to technical precision. Research has noted that fine-tuned LLMs could adapt to different educational assessment philosophies [<a href="#cit0028" class="usa-link" aria-describedby="cit0028">28</a>]. The ability of LLMs to articulate grading rationales represents a potential advantage over traditional automated grading systems, offering transparency that could enhance trust and acceptance among educators and students.</p></section><section id="s0004-s2007"><h3 class="pmc_sec_title">Practical implications for medical education</h3>
<p>Our findings have several important implications for the potential implementation of LLM-based grading in medical education. The considerable variability in performance suggests that a one-size-fits-all approach would be inappropriate. Instead, educators might consider tailoring the use of LLMs to specific contexts:</p>
<p>- Model Selection by Domain: Different LLMs excelled in different domains, suggesting that optimal results might be achieved by selecting specific models for specific subject areas.</p>
<p>- Hybrid Grading Approaches: The high ICC values among experts (average 0.86) demonstrate the strong reliability standard that automated systems should aspire to match. Given the strong performance on identifying fully correct answers but inconsistencies with partially correct ones, a hybrid approach where LLMs provide initial screening followed by human review of borderline cases could maximize efficiency while maintaining assessment quality.</p>
<p>- Formative vs. Summative Assessment: The observed limitations suggest that LLMs may currently be more appropriate for formative assessment, where immediate feedback is valuable and stakes are lower, rather than high-stakes summative assessment where the high expert ICC values (0.72–0.92) set a reliability standard that current LLMs cannot consistently achieve across all domains.</p>
<p>- Prompt Engineering: The inconsistent impact of providing expert criteria suggests that careful design of prompts and grading instructions is crucial for effective LLM implementation.</p>
<p>These practical considerations align with recommendations emphasizing the need for domain-specific expertise in AI implementation for medical education [<a href="#cit0029" class="usa-link" aria-describedby="cit0029">29</a>,<a href="#cit0030" class="usa-link" aria-describedby="cit0030">30</a>], and guidelines for effective prompt engineering with ChatGPT in medical education [<a href="#cit0031" class="usa-link" aria-describedby="cit0031">31</a>,<a href="#cit0032" class="usa-link" aria-describedby="cit0032">32</a>].</p></section><section id="s0004-s2008"><h3 class="pmc_sec_title">Limitations and future directions</h3>
<p>This study has several limitations that should be acknowledged. First, our analysis focused on a limited set of four SAQs across specific medical disciplines, potentially limiting generalizability to other content areas. Second, we compared LLM performance to a consensus of three expert graders, which, while robust (as evidenced by high ICC values ranging from 0.72 to 0.92), may not capture the full range of acceptable grading approaches in medical education. Third, the study did not explore the potential impact of prompt engineering or model fine-tuning, which might significantly improve LLM performance. Fourth, while we followed established best practices for prompt development and conducted pilot testing to refine our prompts, we did not explore model-specific prompt optimization. Our deliberate choice to use standardized prompts across all LLMs ensured fair comparison of their capabilities, but model-specific optimization might yield improved individual performance. Future research should investigate how customized prompting strategies for each model could enhance LLM performance in medical assessment tasks.</p>
<p>Future research should extend this analysis to a broader range of medical disciplines and question types, investigate the impact of different prompting strategies and fine-tuning approaches, and explore student perceptions of LLM-generated feedback. Additionally, longitudinal studies examining how LLM-assisted grading affects learning outcomes would provide valuable insights into the educational impact of these technologies. Future studies could also examine alternative statistical approaches to measure LLM-expert agreement beyond Kappa and ICC, particularly methods that might better capture the nuanced differences in how humans and AI models evaluate partial understanding.</p>
<p>As LLM technology continues to evolve rapidly, the capabilities demonstrated in this study are likely to improve further. Models like GPT-4.1 and Claude, while showing promising performance in certain domains, still fall short of human expert consistency across all medical topics. However, the pace of advancement in AI suggests that the gap between human and AI performance in specialized domains like medical education may continue to narrow.</p></section></section><section id="s0005"><h2 class="pmc_sec_title">Conclusions</h2>
<p>This study demonstrates that LLMs show promising but variable performance in grading medical SAQs, wOB designed the research. IMF collected the questions and anonymous responses. PG, OB, and VM graded the questions. IMF collected and anonymized expert grading data. VM did the statistical analysis. All authors were involved in interpreting data, drafting the article, and revising it critically. All have approved the submitted and final versions.ith significant differences across models, medical domains, and question types. While no single LLM consistently matched expert-level performance across all questions, several models demonstrated substantial agreement with experts in specific contexts, particularly in identifying fully correct or incorrect responses.</p>
<p>Our dual analysis approach using both Cohen’s Kappa and Intraclass Correlation Coefficient (ICC) provided complementary insights into grading reliability. Expert graders maintained substantial agreement (average Kappa: 0.69) and excellent consistency (average ICC: 0.86) across all question types, establishing a robust benchmark for evaluating LLM performance. The high ICC values (ranging from 0.72 to 0.92) demonstrate the consistent scoring patterns that human experts achieve even for technically complex questions, a level of reliability that current LLMs cannot yet match across all medical domains.</p>
<p>The finding that providing expert-developed grading criteria did not consistently improve LLM performance (and in some cases significantly decreased it) reveals a complex relationship between explicit rubrics and LLM grading capabilities. This suggests that the successful implementation of LLM-based grading systems will require careful consideration of prompt engineering, domain-specific calibration, and understanding each model’s inherent grading tendencies.</p>
<p>The findings suggest that LLMs may have a valuable role to play in medical education assessment, particularly in reducing grading burden through preliminary screening or in providing immediate formative feedback. However, their current limitations, including inconsistent performance across domains, variability in response to expert rubrics, and domain-specific grading biases, indicate that human oversight remains essential, especially in high-stakes assessment contexts where the reliability standards established by expert ICC values must be maintained.</p>
<p>As we navigate the integration of AI into medical education, this study underscores the importance of a thoughtful, domain-specific approach that leverages the strengths of both human expertise and artificial intelligence. The future of medical assessment likely lies not in replacing human judgment with AI, but in developing synergistic approaches that enhance efficiency, consistency, and educational value through the thoughtful integration of these powerful tools, with careful attention to the reliability standards that expert graders consistently achieve.</p></section><section id="funding-statement1" lang="en"><h2 class="pmc_sec_title">Funding Statement</h2>
<p>The author(s) reported there is no funding associated with the work featured in this article.</p></section><section id="s0006"><h2 class="pmc_sec_title">Disclosure statement</h2>
<p>No potential conflict of interest was reported by the author(s).</p></section><section id="s0007"><h2 class="pmc_sec_title">Clinical trial number</h2>
<p>The clinical trial number is not pertinent to this study as it does not involve medicinal products or therapeutic interventions.</p></section><section id="s0008"><h2 class="pmc_sec_title">Data availability statement</h2>
<p>The data supporting this study’s findings are available on request from the corresponding author.</p></section><section id="s0009"><h2 class="pmc_sec_title">Ethics declarations</h2>
<p>This study was classified as educational quality improvement research using de-identified retrospective academic performance data, which falls outside the scope requiring formal ethics review. Ethics approval, Consent to Participate, and Consent to Publish declarations: not applicable.</p></section><section id="s0010"><h2 class="pmc_sec_title">Statement of contribution</h2>
<p>OB designed the research. IMF collected the questions and anonymous responses. PG, OB, and VM graded the questions. IMF collected and anonymized expert grading data. VM did the statistical analysis. All authors were involved in interpreting data, drafting the article, and revising it critically. All have approved the submitted and final versions.</p></section><section id="ref-list1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="ref-list1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="cit0001">
<span class="label">[1].</span><cite>Bala L, Westacott RJ, Brown C, et al. Twelve tips for introducing very short answer questions (VSAQs) into your medical curriculum. Med Teach. 2023;45(4):360–16. doi: 10.1080/0142159X.2022.2093706
</cite> [<a href="https://doi.org/10.1080/0142159X.2022.2093706" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35833915/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Med%20Teach&amp;title=Twelve%20tips%20for%20introducing%20very%20short%20answer%20questions%20(VSAQs)%20into%20your%20medical%20curriculum&amp;volume=45&amp;issue=4&amp;publication_year=2023&amp;pages=360-16&amp;pmid=35833915&amp;doi=10.1080/0142159X.2022.2093706&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0002">
<span class="label">[2].</span><cite>Nguyentan DC, Gruenberg K, Shin J.. 
Should multiple-choice questions get the SAQ? Development of a short-answer question writing rubric. Curr Pharm Teach Learn. 2022;14(5):591–596. doi: 10.1016/j.cptl.2022.04.004
</cite> [<a href="https://doi.org/10.1016/j.cptl.2022.04.004" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35715099/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Curr%20Pharm%20Teach%20Learn&amp;title=Should%20multiple-choice%20questions%20get%20the%20SAQ?%20Development%20of%20a%20short-answer%20question%20writing%20rubric&amp;volume=14&amp;issue=5&amp;publication_year=2022&amp;pages=591-596&amp;pmid=35715099&amp;doi=10.1016/j.cptl.2022.04.004&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0003">
<span class="label">[3].</span><cite>Witheridge A, Ferns G, Scott-Smith W. Revisiting miller’s pyramid in medical education: the gap between traditional assessment and diagnostic reasoning. Int J Med Educ. 2019;10:191–192. Published 2019 Oct 25. doi: 10.5116/ijme.5d9b.0c37
</cite> [<a href="https://doi.org/10.5116/ijme.5d9b.0c37" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7246123/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31655795/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Int%20J%20Med%20Educ&amp;title=Revisiting%20miller%E2%80%99s%20pyramid%20in%20medical%20education:%20the%20gap%20between%20traditional%20assessment%20and%20diagnostic%20reasoning&amp;volume=10&amp;publication_year=2019&amp;pages=191-192&amp;pmid=31655795&amp;doi=10.5116/ijme.5d9b.0c37&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0004">
<span class="label">[4].</span><cite>Olvet DM, Bird JB, Fulton TB, et al. A multi-institutional study of the feasibility and reliability of the implementation of constructed response exam questions. Teach Learn Med. 2023;35(5):609–622. doi: 10.1080/10401334.2022.2111571
</cite> [<a href="https://doi.org/10.1080/10401334.2022.2111571" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35989668/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Teach%20Learn%20Med&amp;title=A%20multi-institutional%20study%20of%20the%20feasibility%20and%20reliability%20of%20the%20implementation%20of%20constructed%20response%20exam%20questions&amp;volume=35&amp;issue=5&amp;publication_year=2023&amp;pages=609-622&amp;pmid=35989668&amp;doi=10.1080/10401334.2022.2111571&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0005">
<span class="label">[5].</span><cite>Grévisse C. LLM-based automatic short answer grading in undergraduate medical education. BMC Med Educ. 2024;24(1):1060. Published 2024 Sep 27. doi: 10.1186/s12909-024-06026-5
</cite> [<a href="https://doi.org/10.1186/s12909-024-06026-5" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11429088/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39334087/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=BMC%20Med%20Educ&amp;title=LLM-based%20automatic%20short%20answer%20grading%20in%20undergraduate%20medical%20education&amp;volume=24&amp;issue=1&amp;publication_year=2024&amp;pages=1060&amp;pmid=39334087&amp;doi=10.1186/s12909-024-06026-5&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0006">
<span class="label">[6].</span><cite>Fagbohun O, Iduwe NP, Abdullahi M, et al. Beyond traditional assessment: exploring the impact of large language models on grading practices. J Artif Intel, Mach Learn Data Sci. 2024;2(1):1–8. doi: 10.51219/JAIMLD/oluwole-fagbohun/19</cite> [<a href="https://doi.org/10.51219/JAIMLD/oluwole-fagbohun/19" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Artif%20Intel,%20Mach%20Learn%20Data%20Sci&amp;title=Beyond%20traditional%20assessment:%20exploring%20the%20impact%20of%20large%20language%20models%20on%20grading%20practices&amp;volume=2&amp;issue=1&amp;publication_year=2024&amp;pages=1-8&amp;doi=10.51219/JAIMLD/oluwole-fagbohun/19&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0007">
<span class="label">[7].</span><cite>Sridharan K, Sequeira RP. Artificial intelligence and medical education: application in classroom instruction and student assessment using a pharmacology &amp; therapeutics case study. BMC Med Educ. 2024;24(1):431. Published 2024 Apr 22. doi: 10.1186/s12909-024-05365-7
</cite> [<a href="https://doi.org/10.1186/s12909-024-05365-7" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11034110/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38649959/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=BMC%20Med%20Educ&amp;title=Artificial%20intelligence%20and%20medical%20education:%20application%20in%20classroom%20instruction%20and%20student%20assessment%20using%20a%20pharmacology%20&amp;%20therapeutics%20case%20study&amp;volume=24&amp;issue=1&amp;publication_year=2024&amp;pages=431&amp;pmid=38649959&amp;doi=10.1186/s12909-024-05365-7&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0008">
<span class="label">[8].</span><cite>Bolgova O, Shypilova I, Mavrych V. Large language models in biochemistry education: comparative evaluation of performance. JMIR Med Educ. 2025;11:e67244. Published 2025 Apr 10. doi: 10.2196/67244
</cite> [<a href="https://doi.org/10.2196/67244" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC12005600/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/40209205/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=JMIR%20Med%20Educ&amp;title=Large%20language%20models%20in%20biochemistry%20education:%20comparative%20evaluation%20of%20performance&amp;volume=11&amp;publication_year=2025&amp;pages=e67244&amp;pmid=40209205&amp;doi=10.2196/67244&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0009">
<span class="label">[9].</span><cite>Gilson A, Safranek CW, Huang T, et al. Correction: how does ChatGPT perform on the United States medical licensing examination (USMLE)? The implications of large language models for medical education and knowledge assessment. JMIR Med Educ. 2024. 
Feb
27;10:e57594. Published 2023 Feb 8. doi: 10.2196/57594
</cite> [<a href="https://doi.org/10.2196/57594" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10933712/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38412478/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=JMIR%20Med%20Educ&amp;title=Correction:%20how%20does%20ChatGPT%20perform%20on%20the%20United%20States%20medical%20licensing%20examination%20(USMLE)?%20The%20implications%20of%20large%20language%20models%20for%20medical%20education%20and%20knowledge%20assessment&amp;volume=10&amp;publication_year=2024&amp;pages=e57594&amp;pmid=38412478&amp;doi=10.2196/57594&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0010">
<span class="label">[10].</span><cite>Mavrych V, Ganguly P, Bolgova O. Using large language models (ChatGPT, Copilot, PaLM, Bard, and Gemini) in gross anatomy course: comparative analysis. Clin Anat. 2025;38(2):200–210. doi: 10.1002/ca.24244
</cite> [<a href="https://doi.org/10.1002/ca.24244" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39573871/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Clin%20Anat&amp;title=Using%20large%20language%20models%20(ChatGPT,%20Copilot,%20PaLM,%20Bard,%20and%20Gemini)%20in%20gross%20anatomy%20course:%20comparative%20analysis&amp;volume=38&amp;issue=2&amp;publication_year=2025&amp;pages=200-210&amp;pmid=39573871&amp;doi=10.1002/ca.24244&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0011">
<span class="label">[11].</span><cite>Bolgova O, Ganguly P, Mavrych V. Comparative analysis of LLMs performance in medical embryology: a cross-platform study of ChatGPT, claude, gemini, and copilot. Anat Sci Educ. 2025;18(7):718–726. Published online May 11, 2025. doi: 10.1002/ase.70044
</cite> [<a href="https://doi.org/10.1002/ase.70044" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/40350555/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Anat%20Sci%20Educ&amp;title=Comparative%20analysis%20of%20LLMs%20performance%20in%20medical%20embryology:%20a%20cross-platform%20study%20of%20ChatGPT,%20claude,%20gemini,%20and%20copilot&amp;volume=18&amp;issue=7&amp;publication_year=2025&amp;pages=718-726&amp;pmid=40350555&amp;doi=10.1002/ase.70044&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0012">
<span class="label">[12].</span><cite>Mavrych V, Yaqinuddin A, Claude BO. Claude, ChatGPT, Copilot, and Gemini performance versus students in different topics of neuroscience. Adv Physiol Educ. 2025;49(2):430–437. doi: 10.1152/advan.00093.2024
</cite> [<a href="https://doi.org/10.1152/advan.00093.2024" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39824512/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Adv%20Physiol%20Educ&amp;title=Claude,%20ChatGPT,%20Copilot,%20and%20Gemini%20performance%20versus%20students%20in%20different%20topics%20of%20neuroscience&amp;volume=49&amp;issue=2&amp;publication_year=2025&amp;pages=430-437&amp;pmid=39824512&amp;doi=10.1152/advan.00093.2024&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0013">
<span class="label">[13].</span><cite>Banerjee A, Chatterjee M, Goyal K, et al. Performance of ChatGPT-3.5 and ChatGPT-4 in solving questions based on core concepts in cardiovascular physiology. Cureus. 2025;17(5):e83552. doi: 10.7759/cureus.83552
</cite> [<a href="https://doi.org/10.7759/cureus.83552" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC12138729/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/40476113/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Cureus&amp;title=Performance%20of%20ChatGPT-3.5%20and%20ChatGPT-4%20in%20solving%20questions%20based%20on%20core%20concepts%20in%20cardiovascular%20physiology&amp;volume=17&amp;issue=5&amp;publication_year=2025&amp;pages=e83552&amp;pmid=40476113&amp;doi=10.7759/cureus.83552&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0014">
<span class="label">[14].</span><cite>Aljindan FK, Al Qurashi AA, Albalawi IAS, et al. ChatGPT conquers the saudi medical licensing exam: exploring the accuracy of artificial intelligence in medical knowledge assessment and implications for modern medical education. Cureus. 2023;15(9):e45043. Published 2023 Sep 11. doi: 10.7759/cureus.45043
</cite> [<a href="https://doi.org/10.7759/cureus.45043" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10566535/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37829968/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Cureus&amp;title=ChatGPT%20conquers%20the%20saudi%20medical%20licensing%20exam:%20exploring%20the%20accuracy%20of%20artificial%20intelligence%20in%20medical%20knowledge%20assessment%20and%20implications%20for%20modern%20medical%20education&amp;volume=15&amp;issue=9&amp;publication_year=2023&amp;pages=e45043&amp;pmid=37829968&amp;doi=10.7759/cureus.45043&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0015">
<span class="label">[15].</span><cite>Morjaria L, Burns L, Bracken K, et al. Examining the threat of ChatGPT to the validity of short answer assessments in an undergraduate medical program. J Med Educ Curric Dev. 2023;10:23821205231204178. Published 2023 Sep 28. doi: 10.1177/23821205231204178
</cite> [<a href="https://doi.org/10.1177/23821205231204178" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10540597/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37780034/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Med%20Educ%20Curric%20Dev&amp;title=Examining%20the%20threat%20of%20ChatGPT%20to%20the%20validity%20of%20short%20answer%20assessments%20in%20an%20undergraduate%20medical%20program&amp;volume=10&amp;publication_year=2023&amp;pages=23821205231204178&amp;pmid=37780034&amp;doi=10.1177/23821205231204178&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0016">
<span class="label">[16].</span><cite>Tolsgaard MG, Pusic MV, Sebok-Syer SS, et al. The fundamentals of artificial intelligence in medical education research: AMEE guide No. 156. Med Teach. 2023;45(6):565–573. doi: 10.1080/0142159X.2023.2180340
</cite> [<a href="https://doi.org/10.1080/0142159X.2023.2180340" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36862064/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Med%20Teach&amp;title=The%20fundamentals%20of%20artificial%20intelligence%20in%20medical%20education%20research:%20AMEE%20guide%20No.%20156&amp;volume=45&amp;issue=6&amp;publication_year=2023&amp;pages=565-573&amp;pmid=36862064&amp;doi=10.1080/0142159X.2023.2180340&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0017">
<span class="label">[17].</span><cite>Yan L, Sha L, Zhao L, et al. Practical and ethical challenges of large language models in education: a systematic scoping review. Brit J Educ Tech. 2024;55(1):90–112. doi: 10.1111/bjet.13370</cite> [<a href="https://doi.org/10.1111/bjet.13370" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Brit%20J%20Educ%20Tech&amp;title=Practical%20and%20ethical%20challenges%20of%20large%20language%20models%20in%20education:%20a%20systematic%20scoping%20review&amp;volume=55&amp;issue=1&amp;publication_year=2024&amp;pages=90-112&amp;doi=10.1111/bjet.13370&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0018">
<span class="label">[18].</span><cite>Kasneci E. ChatGPT for good? On opportunities and challenges of large language models for education. Learn And Individual Differences. 2023;103:102274.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Learn%20And%20Individual%20Differences&amp;title=ChatGPT%20for%20good?%20On%20opportunities%20and%20challenges%20of%20large%20language%20models%20for%20education&amp;volume=103&amp;publication_year=2023&amp;pages=102274&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0019">
<span class="label">[19].</span><cite>Triola MM, Burk-Rafel J. Precision medical education. Acad Med. 2023;98(7):775–781. doi: 10.1097/ACM.0000000000005227
</cite> [<a href="https://doi.org/10.1097/ACM.0000000000005227" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37027222/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Acad%20Med&amp;title=Precision%20medical%20education&amp;volume=98&amp;issue=7&amp;publication_year=2023&amp;pages=775-781&amp;pmid=37027222&amp;doi=10.1097/ACM.0000000000005227&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0020">
<span class="label">[20].</span><cite>Sarangi PK, Mondal H. Response generated by large language models depends on the structure of the prompt. Indian J Radiol Imaging. 2024;34(3):574–575. Published 2024 Mar 25. doi: 10.1055/s-0044-1782165
</cite> [<a href="https://doi.org/10.1055/s-0044-1782165" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11188729/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38912242/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Indian%20J%20Radiol%20Imaging&amp;title=Response%20generated%20by%20large%20language%20models%20depends%20on%20the%20structure%20of%20the%20prompt&amp;volume=34&amp;issue=3&amp;publication_year=2024&amp;pages=574-575&amp;pmid=38912242&amp;doi=10.1055/s-0044-1782165&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0021">
<span class="label">[21].</span><cite>Mavrych V, Yousef EM, Yaqinuddin A, et al. Large language models in medical education: a comparative cross-platform evaluation in answering histological questions. Med Educ Online. 2025;30(1):2534065. doi: 10.1080/10872981.2025.2534065
</cite> [<a href="https://doi.org/10.1080/10872981.2025.2534065" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC12258195/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/40651009/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Med%20Educ%20Online&amp;title=Large%20language%20models%20in%20medical%20education:%20a%20comparative%20cross-platform%20evaluation%20in%20answering%20histological%20questions&amp;volume=30&amp;issue=1&amp;publication_year=2025&amp;pages=2534065&amp;pmid=40651009&amp;doi=10.1080/10872981.2025.2534065&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0022">
<span class="label">[22].</span><cite>Sarangi PK, Narayan RK, Mohakud S, et al. Assessing the capability of ChatGPT, google bard, and microsoft bing in solving radiology case vignettes. Indian J Radiol Imaging. 2023;34(2):276–282. doi: 10.1055/s-0043-1777746
</cite> [<a href="https://doi.org/10.1055/s-0043-1777746" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10972658/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38549897/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Indian%20J%20Radiol%20Imaging&amp;title=Assessing%20the%20capability%20of%20ChatGPT,%20google%20bard,%20and%20microsoft%20bing%20in%20solving%20radiology%20case%20vignettes&amp;volume=34&amp;issue=2&amp;publication_year=2023&amp;pages=276-282&amp;pmid=38549897&amp;doi=10.1055/s-0043-1777746&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0023">
<span class="label">[23].</span><cite>Bernard J, Sonnadara R, Saraco AN, et al. Automated grading of anatomical objective structured practical examinations using decision trees: an artificial intelligence approach. Anat Sci Educ. 2024;17(5):967–978. doi: 10.1002/ase.2305
</cite> [<a href="https://doi.org/10.1002/ase.2305" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37322819/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Anat%20Sci%20Educ&amp;title=Automated%20grading%20of%20anatomical%20objective%20structured%20practical%20examinations%20using%20decision%20trees:%20an%20artificial%20intelligence%20approach&amp;volume=17&amp;issue=5&amp;publication_year=2024&amp;pages=967-978&amp;pmid=37322819&amp;doi=10.1002/ase.2305&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0024">
<span class="label">[24].</span><cite>Preiksaitis C, Rose C. Opportunities, challenges, and future directions of generative artificial intelligence in medical education: scoping review. JMIR Med Educ. 2023;9:e48785. Published 2023 Oct 20. doi: 10.2196/48785
</cite> [<a href="https://doi.org/10.2196/48785" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10625095/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37862079/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=JMIR%20Med%20Educ&amp;title=Opportunities,%20challenges,%20and%20future%20directions%20of%20generative%20artificial%20intelligence%20in%20medical%20education:%20scoping%20review&amp;volume=9&amp;publication_year=2023&amp;pages=e48785&amp;pmid=37862079&amp;doi=10.2196/48785&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0025">
<span class="label">[25].</span><cite>Bolgova O, Shypilova I, Sankova L, et al. How well did ChatGPT perform in answering questions on different topics in gross anatomy?
Eur J Med Health Sci. 2023;5(6):94–100. doi: 10.24018/ejmed.2023.5.6.1989</cite> [<a href="https://doi.org/10.24018/ejmed.2023.5.6.1989" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Eur%20J%20Med%20Health%20Sci&amp;title=How%20well%20did%20ChatGPT%20perform%20in%20answering%20questions%20on%20different%20topics%20in%20gross%20anatomy?&amp;volume=5&amp;issue=6&amp;publication_year=2023&amp;pages=94-100&amp;doi=10.24018/ejmed.2023.5.6.1989&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0026">
<span class="label">[26].</span><cite>Banerjee A, Ahmad A, Bhalla P, et al. Assessing the efficacy of ChatGPT in solving questions based on the core concepts in physiology. Cureus. 2023;15(8):e43314. Published 2023 Aug 10. doi: 10.7759/cureus.43314
</cite> [<a href="https://doi.org/10.7759/cureus.43314" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10492920/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37700949/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Cureus&amp;title=Assessing%20the%20efficacy%20of%20ChatGPT%20in%20solving%20questions%20based%20on%20the%20core%20concepts%20in%20physiology&amp;volume=15&amp;issue=8&amp;publication_year=2023&amp;pages=e43314&amp;pmid=37700949&amp;doi=10.7759/cureus.43314&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0027">
<span class="label">[27].</span><cite>Johnsson V, Søndergaard MB, Kulasegaram K, et al. Validity evidence supporting clinical skills assessment by artificial intelligence compared with trained clinician raters. Med Educ. 2024;58(1):105–117. doi: 10.1111/medu.15190
</cite> [<a href="https://doi.org/10.1111/medu.15190" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37615058/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Med%20Educ&amp;title=Validity%20evidence%20supporting%20clinical%20skills%20assessment%20by%20artificial%20intelligence%20compared%20with%20trained%20clinician%20raters&amp;volume=58&amp;issue=1&amp;publication_year=2024&amp;pages=105-117&amp;pmid=37615058&amp;doi=10.1111/medu.15190&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0028">
<span class="label">[28].</span><cite>Latif E, Zhai X. Fine-tuning ChatGPT for automatic scoring. Comput Educ: Artif Intel. 2024;6:100210. doi: 10.1016/j.caeai.2024.100210</cite> [<a href="https://doi.org/10.1016/j.caeai.2024.100210" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Comput%20Educ:%20Artif%20Intel&amp;title=Fine-tuning%20ChatGPT%20for%20automatic%20scoring&amp;volume=6&amp;publication_year=2024&amp;pages=100210&amp;doi=10.1016/j.caeai.2024.100210&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0029">
<span class="label">[29].</span><cite>Pearce J, Chiavaroli N. Rethinking assessment in response to generative artificial intelligence. Med Educ. 2023;57(10):889–891. doi: 10.1111/medu.15092
</cite> [<a href="https://doi.org/10.1111/medu.15092" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37042389/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Med%20Educ&amp;title=Rethinking%20assessment%20in%20response%20to%20generative%20artificial%20intelligence&amp;volume=57&amp;issue=10&amp;publication_year=2023&amp;pages=889-891&amp;pmid=37042389&amp;doi=10.1111/medu.15092&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0030">
<span class="label">[30].</span><cite>Indran IR, Paranthaman P, Gupta N, et al. Twelve tips to leverage AI for efficient and effective medical question generation: a guide for educators using chat GPT. Med Teach. 2024;46(8):1021–1026. doi: 10.1080/0142159X.2023.2294703
</cite> [<a href="https://doi.org/10.1080/0142159X.2023.2294703" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38146711/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Med%20Teach&amp;title=Twelve%20tips%20to%20leverage%20AI%20for%20efficient%20and%20effective%20medical%20question%20generation:%20a%20guide%20for%20educators%20using%20chat%20GPT&amp;volume=46&amp;issue=8&amp;publication_year=2024&amp;pages=1021-1026&amp;pmid=38146711&amp;doi=10.1080/0142159X.2023.2294703&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0031">
<span class="label">[31].</span><cite>Lertsakulbunlue S, Kantiwong A. Development and validation of immediate self-feedback very short answer questions for medical students: practical implementation of generalizability theory to estimate reliability in formative examination designs. BMC Med Educ. 2024;24(1):572. doi: 10.1186/s12909-024-05569-x
</cite> [<a href="https://doi.org/10.1186/s12909-024-05569-x" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11127299/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38789958/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=BMC%20Med%20Educ&amp;title=Development%20and%20validation%20of%20immediate%20self-feedback%20very%20short%20answer%20questions%20for%20medical%20students:%20practical%20implementation%20of%20generalizability%20theory%20to%20estimate%20reliability%20in%20formative%20examination%20designs&amp;volume=24&amp;issue=1&amp;publication_year=2024&amp;pages=572&amp;pmid=38789958&amp;doi=10.1186/s12909-024-05569-x&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="cit0032">
<span class="label">[32].</span><cite>Mastour H, Dehghani T, Jajroudi M, et al. Prediction of medical sciences students’ performance on high-stakes examinations using machine learning models: a protocol for a systematic review. BMJ Open. 2023.  [cited 2023 May
4];13(5):e064956. doi: 10.1136/bmjopen-2022-064956</cite> [<a href="https://doi.org/10.1136/bmjopen-2022-064956" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10163468/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37142312/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=BMJ%20Open&amp;title=Prediction%20of%20medical%20sciences%20students%E2%80%99%20performance%20on%20high-stakes%20examinations%20using%20machine%20learning%20models:%20a%20protocol%20for%20a%20systematic%20review&amp;volume=13&amp;issue=5&amp;publication_year=2023&amp;pages=e064956&amp;pmid=37142312&amp;doi=10.1136/bmjopen-2022-064956&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adda93_" lang="en" class="data-availability-statement"><h3 class="pmc_sec_title">Data Availability Statement</h3>
<p>The data supporting this study’s findings are available on request from the corresponding author.</p></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from Medical Education Online are provided here courtesy of <strong>Taylor & Francis</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1080/10872981.2025.2550751"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/ZMEO_30_2550751.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (4.7 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12377152/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12377152/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12377152%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12377152/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12377152/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12377152/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40849930/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12377152/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40849930/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12377152/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12377152/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="mFNc4YqYoXq0FxAm1ODG3h8A7Zd2q0WQMfGxruCGJoRh1ecSGLzPvcJaYMsESjwD">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
    

    </body>
</html>
