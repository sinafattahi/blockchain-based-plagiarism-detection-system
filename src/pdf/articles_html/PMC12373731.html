
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            Domain general noise reduction for time series signals with Noisereduce - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="AE53141E8AEF508305141E002D70021F.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="scirep">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373731/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="Scientific Reports">
<meta name="citation_title" content="Domain general noise reduction for time series signals with Noisereduce">
<meta name="citation_author" content="Tim Sainburg">
<meta name="citation_author_institution" content="Department of Neurobiology, Harvard Medical School, Boston, MA US">
<meta name="citation_author_institution" content="Department of Molecular and Cellular Biology, Harvard University, Cambridge, MA US">
<meta name="citation_author_institution" content="Department of Organismic and Evolutionary Biology, Harvard University, Cambridge, MA US">
<meta name="citation_author_institution" content="Museum of Comparative Zoology, Harvard University, Cambridge, MA USA">
<meta name="citation_author" content="Asaf Zorea">
<meta name="citation_publication_date" content="2025 Aug 22">
<meta name="citation_volume" content="15">
<meta name="citation_firstpage" content="30905">
<meta name="citation_doi" content="10.1038/s41598-025-13108-x">
<meta name="citation_pmid" content="40847024">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373731/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373731/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373731/pdf/41598_2025_Article_13108.pdf">
<meta name="description" content="Extracting signals from noisy backgrounds is a fundamental problem in signal processing across a variety of domains. In this paper, we introduce Noisereduce, an algorithm for minimizing noise across a variety of domains, including speech, ...">
<meta name="og:title" content="Domain general noise reduction for time series signals with Noisereduce">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="Extracting signals from noisy backgrounds is a fundamental problem in signal processing across a variety of domains. In this paper, we introduce Noisereduce, an algorithm for minimizing noise across a variety of domains, including speech, ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373731/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12373731">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1038/s41598-025-13108-x"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/41598_2025_Article_13108.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12373731%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12373731/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12373731/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373731/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-scirep.jpg" alt="Scientific Reports logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to Scientific Reports" title="Link to Scientific Reports" shape="default" href="http://www.nature.com/srep" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">Sci Rep</button></div>. 2025 Aug 22;15:30905. doi: <a href="https://doi.org/10.1038/s41598-025-13108-x" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1038/s41598-025-13108-x</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22Sci%20Rep%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sci%20Rep%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22Sci%20Rep%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22Sci%20Rep%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Domain general noise reduction for time series signals with Noisereduce</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sainburg%20T%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Tim Sainburg</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Tim Sainburg</span></h3>
<div class="p">
<sup>1</sup>Department of Neurobiology, Harvard Medical School, Boston, MA US </div>
<div class="p">
<sup>2</sup>Department of Molecular and Cellular Biology, Harvard University, Cambridge, MA US </div>
<div class="p">
<sup>3</sup>Department of Organismic and Evolutionary Biology, Harvard University, Cambridge, MA US </div>
<div class="p">
<sup>4</sup>Museum of Comparative Zoology, Harvard University, Cambridge, MA USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sainburg%20T%22%5BAuthor%5D" class="usa-link"><span class="name western">Tim Sainburg</span></a>
</div>
</div>
<sup>1,</sup><sup>2,</sup><sup>3,</sup><sup>4,</sup><sup>✉,</sup><sup>#</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Zorea%20A%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Asaf Zorea</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">Asaf Zorea</span></h3>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Zorea%20A%22%5BAuthor%5D" class="usa-link"><span class="name western">Asaf Zorea</span></a>
</div>
</div>
<sup>#</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="Aff1">
<sup>1</sup>Department of Neurobiology, Harvard Medical School, Boston, MA US </div>
<div id="Aff2">
<sup>2</sup>Department of Molecular and Cellular Biology, Harvard University, Cambridge, MA US </div>
<div id="Aff3">
<sup>3</sup>Department of Organismic and Evolutionary Biology, Harvard University, Cambridge, MA US </div>
<div id="Aff4">
<sup>4</sup>Museum of Comparative Zoology, Harvard University, Cambridge, MA USA </div>
<div class="author-notes p">
<div class="fn" id="_fncrsp93pmc__">
<sup>✉</sup><p class="display-inline">Corresponding author.</p>
</div>
<div class="fn" id="_eqcntrb93pmc__">
<sup>#</sup><p class="display-inline">Contributed equally.</p>
</div>
</div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2025 Jan 12; Accepted 2025 Jul 22; Collection date 2025.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© The Author(s) 2025</div>
<p><strong>Open Access</strong> This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://creativecommons.org/licenses/by-nc-nd/4.0/</a>.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12373731  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40847024/" class="usa-link">40847024</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="Abs1"><h2>Abstract</h2>
<p id="Par1">Extracting signals from noisy backgrounds is a fundamental problem in signal processing across a variety of domains. In this paper, we introduce Noisereduce, an algorithm for minimizing noise across a variety of domains, including speech, bioacoustics, neurophysiology, and seismology. Noisereduce uses spectral gating to estimate a frequency-domain mask that effectively separates signals from noise. It is fast, lightweight, requires no training data, and handles both stationary and non-stationary noise, making it both a versatile tool and a convenient baseline for comparison with domain-specific applications. We provide a detailed overview of Noisereduce and evaluate its performance on a variety of time-domain signals.</p>
<section id="kwd-group1" lang="en" class="kwd-group"><p><strong>Keywords:</strong> Noise reduction, Signal enhancement, Time-domain signals</p></section><section id="kwd-group2" class="kwd-group"><p><strong>Subject terms:</strong> Data processing, Software</p></section></section><section id="Sec1"><h2 class="pmc_sec_title">Introduction</h2>
<p id="Par2">Natural signals such as speech, electrophysiology, and bioacoustics are challenging to record in isolation. Sensors, both biological and artificial, tend to record these signals in the context of noisy environments. To record from a singing songbird in its natural environment, for example, a microphone will pick up not only the bird but the richness of its sensory environment—a babbling brook, chirping crickets, wind passing through leaves, and the croaks of a nearby frog. Such ’noise’ can both provide important context for the signal of interest and important confounds. For example, a classifier trained to predict bird species from song recordings can be biased by environmental context; a babbling brook in the background might cause a Wood Thresh to be classified as a Robin. That error would in turn lead to downstream inaccuracies in estimating the migratory patterns of both birds. These same technical challenges arise in a variety of domains, from detecting action potentials to distinguishing seismic events from human activity.</p>
<p id="Par3">Determining what constitutes noise versus signal is highly context-dependent. Consider two researchers: one focusing on the croaking of the American Bullfrog and the other analyzing the song of the Wood Thrush. They might approach the same audio recording yet define signal and noise in vastly different ways. Fortunately for these hypothetical researchers, the vocalizations of Bullfrogs and Wood Thrushes can be relatively easily distinguished from each other. Bullfrogs produce sounds in a frequency range of approximately 200-2000 Hz<sup><a href="#CR43" class="usa-link" aria-describedby="CR43">43</a></sup>, whereas Wood Thrushes vocalize in a higher spectrum, roughly 2000-9000 Hz<sup><a href="#CR22" class="usa-link" aria-describedby="CR22">22</a></sup>. Therefore, by applying a simple low-pass or high-pass filter, each researcher can effectively isolate the vocalizations of their respective species with minimal effort.</p>
<p id="Par4">Signal and noise events that overlap spectro-temporally pose a greater challenge but are not insurmountable. If the signal and noise retain identifiable structures, we can devise algorithms to exploit these structures and eliminate unwanted noise. For instance, the persistent 60-Hz hum from nearby electronics in a poorly grounded electrophysiology implant exhibits temporal structure. This constant hum can be identified and algorithmically removed from the signal. Noise reduction algorithms harness these structural differences to distinguish and separate noise from the signal.</p>
<p id="Par5">The challenge of separating signal from noise exists across many domains. While much focus in recent years has been on machine-learning based noise reduction algorithms, these algorithms are generally domain-specific; machine learning generally relies on large, often labeled, datasets that do not exist in all domains. These algorithms have been exhaustively reviewed for various signal domains in prior literature<sup><a href="#CR44" class="usa-link" aria-describedby="CR44">44</a>,<a href="#CR58" class="usa-link" aria-describedby="CR58">58</a>,<a href="#CR64" class="usa-link" aria-describedby="CR64">64</a></sup>. For domain general applications, out of the purview of any domain-specific machine learning models conventional approaches to noise reduction remain valuable<sup><a href="#CR58" class="usa-link" aria-describedby="CR58">58</a></sup>.</p>
<p id="Par6">Here, we survey the utility of our algorithm, Noisereduce, a fast, domain-general, spectral-subtraction-based algorithm available in Python. Noisereduce has already been available open-source for over five years and has found utility in a variety of different domains including bioacoustics<sup><a href="#CR17" class="usa-link" aria-describedby="CR17">17</a>,<a href="#CR41" class="usa-link" aria-describedby="CR41">41</a>,<a href="#CR42" class="usa-link" aria-describedby="CR42">42</a>,<a href="#CR45" class="usa-link" aria-describedby="CR45">45</a>,<a href="#CR48" class="usa-link" aria-describedby="CR48">48</a>,<a href="#CR51" class="usa-link" aria-describedby="CR51">51</a></sup>, brain-machine interfacing<sup><a href="#CR11" class="usa-link" aria-describedby="CR11">11</a>,<a href="#CR25" class="usa-link" aria-describedby="CR25">25</a>,<a href="#CR26" class="usa-link" aria-describedby="CR26">26</a></sup>, livestock welfare monitoring<sup><a href="#CR4" class="usa-link" aria-describedby="CR4">4</a>,<a href="#CR24" class="usa-link" aria-describedby="CR24">24</a></sup>, human emotion analysis<sup><a href="#CR29" class="usa-link" aria-describedby="CR29">29</a>,<a href="#CR40" class="usa-link" aria-describedby="CR40">40</a></sup>, medical and clinical diagnostics<sup><a href="#CR27" class="usa-link" aria-describedby="CR27">27</a>,<a href="#CR32" class="usa-link" aria-describedby="CR32">32</a>,<a href="#CR39" class="usa-link" aria-describedby="CR39">39</a>,<a href="#CR55" class="usa-link" aria-describedby="CR55">55</a>,<a href="#CR68" class="usa-link" aria-describedby="CR68">68</a></sup>, seismic monitoring<sup><a href="#CR38" class="usa-link" aria-describedby="CR38">38</a></sup>, and many other domains. Until now, its performance has not been rigorously validated. Here, we address this by validating Noisereduce on several time-domain signals and comparing it to other conventional algorithms. Our findings show Noisereduce is fast and performs well, making it a strong candidate for domain-general applications where large datasets are unavailable and a solid baseline for comparing machine-learning-based algorithms.</p>
<section id="Sec2"><h3 class="pmc_sec_title">Noisereduce algorithm</h3>
<p id="Par7">Noisereduce belongs to a class of noise reduction algorithms that perform spectral-subtraction in the time-frequency domain<sup><a href="#CR5" class="usa-link" aria-describedby="CR5">5</a></sup>. Spectral subtraction algorithms subtract an estimate of the noise spectrum from a noisy signal in an attempt to improve the signal-to-noise ratio of the signal. The challenge in developing a spectral subtraction algorithm is in determining what constitutes noise and how that estimate of noise should be subtracted from the signal. For example, in Stephan Boll’s original paper on spectral subtraction<sup><a href="#CR5" class="usa-link" aria-describedby="CR5">5</a></sup> a Fast Fourier Transform (FFT) is taken on a on a noise-only portion of speech recording. a Short-Time Fourier Transformation (STFT) is the computed over the signal and the estimated noise magnitude is subtracted from each frequency component (clamping values above zero). In practice, this approach can leave behind unwanted noise artifacts and several variants exist to overcome these issues<sup><a href="#CR60" class="usa-link" aria-describedby="CR60">60</a></sup>. Spectral gating, the approach Noisereduce takes, is one of several variants of spectral subtraction. Spectral gates merge the concept of noise gating. Spectral gates are noise gates that act in the time-frequency domain, by masking specific time-frequency components to be subtracted away, while leaving other time-frequency components unaltered. This approach is commonly used in auditory scene analysis, where an auditory mixture is decomposed into time-frequency components, and an Ideal Binary Mask<sup><a href="#CR28" class="usa-link" aria-describedby="CR28">28</a></sup> is estimated to determine which components to attenuate (zeros) and which to pass through unaffected (ones). In practice masks are rarely binary- but are used to determine what proportion of the signal to attenuate. The success of spectral gating in noise reduction can be seen in its adoption in professional audio analysis software such as Adobe Audition (Effects <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq1"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/3419b6f67981/d33e316.gif" loading="lazy" id="d33e316" alt="Inline graphic"></span> Noise Reduction/Restoration <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq2"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/3419b6f67981/d33e323.gif" loading="lazy" id="d33e323" alt="Inline graphic"></span> Noise Reduction in version 25.2), Audacity (Effects <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq3"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/3419b6f67981/d33e329.gif" loading="lazy" id="d33e329" alt="Inline graphic"></span> Noise Reduction in version 3.7.3), and iZotope RX (Spectral De-noise* in version RX11). Noisereduce represents an open-source, lightweight, Python approach to spectral gating.</p>
<p id="Par8">Noisereduce accepts two inputs: (1) <em>X</em>, the time-domain recording to be denoised and (2, optionally) <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq4"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/1f7a949a8017/d33e340.gif" loading="lazy" id="d33e340" alt="Inline graphic"></span>, a time-domain recording containing only noise, used to calculate noise statistics. Noisereduce operates through the following steps (Fig <a href="#Fig1" class="usa-link">1</a>). </p>
<ol class="list" style="list-style-type:decimal">
<li><div class="p" id="Par9">Estimate noise: <ul class="list" style="list-style-type:none">
<li>
<span class="label">1.1</span><div class="display-inline p" id="Par10">Compute a Short-Time Fourier Transform (STFT; <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq5"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/ca620dd5fdf8/d33e361.gif" loading="lazy" id="d33e361" alt="Inline graphic"></span>) on each channel of the noise recording (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq6"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/1f7a949a8017/d33e367.gif" loading="lazy" id="d33e367" alt="Inline graphic"></span>).</div>
</li>
<li>
<span class="label">1.2</span><div class="display-inline p" id="Par11">For each frequency channel, compute spectral statistics (mean <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq7"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/c8e6eddb16be/d33e378.gif" loading="lazy" id="d33e378" alt="Inline graphic"></span>, standard deviation <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq8"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/1dae6ff2cbdc/d33e384.gif" loading="lazy" id="d33e384" alt="Inline graphic"></span>) over the noise STFT (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq9"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/ca620dd5fdf8/d33e390.gif" loading="lazy" id="d33e390" alt="Inline graphic"></span>).</div>
</li>
<li>
<span class="label">1.3</span><div class="display-inline p" id="Par12">Compute a noise threshold based upon the statistics of the noise and the desired sensitivity.</div>
</li>
</ul>
</div></li>
<li><div class="p" id="Par13">Mask noise: <ul class="list" style="list-style-type:none">
<li>
<span class="label">2.1</span><div class="display-inline p" id="Par14">Compute a STFT (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq10"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/e345921000a1/d33e412.gif" loading="lazy" id="d33e412" alt="Inline graphic"></span>) over each channel of the recording (<em>X</em>).</div>
</li>
<li>
<span class="label">2.2</span><div class="display-inline p" id="Par15">Compute a mask (<em>M</em>) over the signal STFT (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq11"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/e345921000a1/d33e429.gif" loading="lazy" id="d33e429" alt="Inline graphic"></span>), based on the thresholds for each frequency channel.</div>
</li>
<li>
<span class="label">2.3</span><div class="display-inline p" id="Par16">(optional) smooth the mask (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq12"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/8dddde1670b3/d33e440.gif" loading="lazy" id="d33e440" alt="Inline graphic"></span>) with a filter over frequency and time</div>
</li>
<li>
<span class="label">2.4</span><div class="display-inline p" id="Par17">Apply the mask (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq13"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/8dddde1670b3/d33e451.gif" loading="lazy" id="d33e451" alt="Inline graphic"></span>) to the STFT of the signal (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq14"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/e345921000a1/d33e457.gif" loading="lazy" id="d33e457" alt="Inline graphic"></span>) to produce the masked STFT (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq15"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/4609b8b180b9/d33e463.gif" loading="lazy" id="d33e463" alt="Inline graphic"></span>).</div>
</li>
<li>
<span class="label">2.5</span><div class="display-inline p" id="Par18">Invert the masked STFT (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq16"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/4609b8b180b9/d33e474.gif" loading="lazy" id="d33e474" alt="Inline graphic"></span>) back into the time-domain (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq17"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/3ee5cdab5c19/d33e480.gif" loading="lazy" id="d33e480" alt="Inline graphic"></span>).</div>
</li>
</ul>
</div></li>
</ol>
<p>If the noise recording is not provided to the algorithm, the noise statistics are computed on directly on the recording (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq18"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/6298e2adad9e/d33e487.gif" loading="lazy" id="d33e487" alt="Inline graphic"></span>). A more detailed description of the algorithm and its parameters are given in <a href="#Sec14" class="usa-link">5.1</a>.</p>
<figure class="fig xbox font-sm" id="Fig1"><h4 class="obj_head">Fig. 1.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373731_41598_2025_13108_Fig1_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/58c55c003766/41598_2025_13108_Fig1_HTML.jpg" loading="lazy" id="MO1" height="799" width="750" alt="Fig. 1"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Basic outline of Noisereduce algorithm. (A) A block diagram of the steps of Noisereduce. The stationary version of the time-frequency mask is depicted. (B) An example waveform (U.S. President George W Bush stating “I know that human beings and fish can coexist peacefully”) passing through the Noisereduce pipeline. The non-stationary algorithm is not shown here.</p></figcaption></figure><section id="Sec3"><h4 class="pmc_sec_title">Nonstationary noise reduction</h4>
<p id="Par19">In natural settings, background noise often varies over extended periods. For example, in bioacoustics, weather can shift within minutes, while in electrophysiology, the activity rates of nearby neurons may increase as animals transition between states, such as sleeping and waking. Consequently, it is advantageous to enable Noisereduce to adapt its noise definition over time<sup><a href="#CR48" class="usa-link" aria-describedby="CR48">48</a></sup>. To address this, we introduced a non-stationary variant of Noisereduce, where mask statistics are calculated using a sliding window across the signal rather than relying solely on an isolated noise clip. This non-stationary approach is particularly beneficial for signals such as those from hydrophones in underwater bioacoustics, where the engine hum of a boat can fluctuate as the hydrophone drifts toward and away from the boat towing it. To decide whether non-stationary noise reduction is appropriate, one can test whether the signal is stationary either using formal testing<sup><a href="#CR6" class="usa-link" aria-describedby="CR6">6</a></sup> or by inspecting the signal manually for periods of fluctuating noise levels. Normalizing audio signals to channel-specific fluctuations in amplitude has proven useful for tasks like bioacoustic species identification<sup><a href="#CR35" class="usa-link" aria-describedby="CR35">35</a></sup>.</p>
<p id="Par20">The non-stationary algorithm omits the need for a noise recording (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq19"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/3c58266317ca/d33e522.gif" loading="lazy" id="d33e522" alt="Inline graphic"></span>) since noise statistics are directly derived from the signal recording (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq20"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/6298e2adad9e/d33e528.gif" loading="lazy" id="d33e528" alt="Inline graphic"></span>). In this revised approach, statistics for the noise threshold are computed over a sliding window for each frequency channel. This approach dynamically sets noise gate thresholds for each frequency channel, as opposed to static settings across the entire recording. For additional details, see Section <a href="#Sec14" class="usa-link">5.1</a>.</p>
<p id="Par21">Figure <a href="#Fig2" class="usa-link">2</a> illustrates the non-stationary algorithm’s utility. We took a one-minute recording of an American Robin (Macaulay Library 321642131; Fig <a href="#Fig2" class="usa-link">2</a>A) and added the non-stationary noise of an airplane passing overhead (Fig <a href="#Fig2" class="usa-link">2</a>B). We then applied both stationary and nonstationary Noisereduce (Fig <a href="#Fig2" class="usa-link">2</a>C-D). During the highest amplitude period of airplane noise, the stationary algorithm leaves additional noise artifacts in the recording, unlike the non-stationary version (Fig <a href="#Fig2" class="usa-link">2</a>E-G, Blue/Green, 20-30 seconds). Conversely, more of the signal is lost in sections with lower noise amplitude (e.g. 40-60 seconds, red/purple). We quantified this as the absolute error in dB, relative to the noise-free recording (Fig <a href="#Fig2" class="usa-link">2</a>H) exemplifting that the non-stationary algorithm performs consistently better with non-stationary noise in this case.</p>
<figure class="fig xbox font-sm" id="Fig2"><h5 class="obj_head">Fig. 2.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373731_41598_2025_13108_Fig2_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/6ae718bd49f9/41598_2025_13108_Fig2_HTML.jpg" loading="lazy" id="MO2" height="644" width="700" alt="Fig. 2"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Comparison of stationary and non-stationary noise reduction. (<strong>A</strong>) Spectrogram of clean recording of an American Robin (Macaulay Library 321642131). (<strong>B</strong>) Airplane noise imposed over Robin Recording. (<strong>C</strong>-<strong>D</strong>) Denoising of (<strong>B</strong>) with (<strong>C</strong>) stationary noisereduce and (<strong>D</strong>) nonstationary noisereduce (window size of 2 seconds) (E-F) Magnitude error in stationary noisereduce vs ground truth for (<strong>E</strong>) stationary noisereduce and (<strong>F</strong>) nonstationary noisereduce. (<strong>G</strong>) Magnitude difference between stationary and nonstationary noisereduce. (<strong>H</strong>) Error (in dB) from ground truth for stationary (green) and nonstationary (purple) noisereduce.</p></figcaption></figure></section></section></section><section id="Sec4"><h2 class="pmc_sec_title">Results</h2>
<p id="Par22">To evaluate the performance of Noisereduce, we tested it on a set of benchmark datasets across four domains: speech, bioacoustics, electrophysiology, and seismology (see <a href="#Sec16" class="usa-link">5.2</a>). We compared its results against several noise reduction algorithms (see <a href="#Sec17" class="usa-link">5.3</a>). The evaluation metrics used in the comparison are detailed in <a href="#Sec19" class="usa-link">5.5</a>.</p>
<section id="Sec5"><h3 class="pmc_sec_title">Speech</h3>
<p id="Par23">Speech is the best-established domain for enhancement and noise reduction<sup><a href="#CR33" class="usa-link" aria-describedby="CR33">33</a></sup>. Many speech noise reduction applications are well-suited to machine learning methods, especially deep neural networks like convolutional neural networks (CNNs)<sup><a href="#CR36" class="usa-link" aria-describedby="CR36">36</a>,<a href="#CR66" class="usa-link" aria-describedby="CR66">66</a></sup>, long short-term memory networks (LSTMs)<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a>,<a href="#CR19" class="usa-link" aria-describedby="CR19">19</a></sup>, and Generative Adversarial Network (GANs)<sup><a href="#CR18" class="usa-link" aria-describedby="CR18">18</a>,<a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup>, which outperform any conventional algorithm. We therefore submit that Noisereduce in this domain for two purposes. First, as a candidate “conventional algorithm” baseline. Second, Noisereduce may remain useful for speech applications where machine-learning based approaches might not be well suited, such as out-of-domain speech signals, very lightweight applications where computational costs of machine-learning based approaches are too cumbersome, or in creating new datasets with varying manipulations on noise levels.</p>
<p id="Par24">We evaluated Noisereduce against other noise reduction conventional algorithms on the NOIZEUS dataset<sup><a href="#CR21" class="usa-link" aria-describedby="CR21">21</a>,<a href="#CR34" class="usa-link" aria-describedby="CR34">34</a>,<a href="#CR65" class="usa-link" aria-describedby="CR65">65</a></sup> across various SNR levels (0, 5, 10, and 15 dB). Examples of speech spectrograms obtained with Noisereduce, Wiener<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup>, Iterative Wiener<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup>, Subspace<sup><a href="#CR16" class="usa-link" aria-describedby="CR16">16</a>,<a href="#CR20" class="usa-link" aria-describedby="CR20">20</a></sup>, Spectral Subtraction<sup><a href="#CR5" class="usa-link" aria-describedby="CR5">5</a></sup> and Savitzky-Golay<sup><a href="#CR52" class="usa-link" aria-describedby="CR52">52</a></sup> appear in Fig <a href="#Fig3" class="usa-link">3</a>. Particularly, Noisereduce preserves the speech signal without distortions, unlike other algorithms that add artifacts, particularly under low SNR. The performance metrics used were Short-Time Objective Intelligibility (STOI)<sup><a href="#CR57" class="usa-link" aria-describedby="CR57">57</a></sup> and Perceptual Evaluation of Speech Quality (PESQ)<sup><a href="#CR47" class="usa-link" aria-describedby="CR47">47</a></sup>, which assess speech intelligibility and quality, respectively. STOI and PESQ results are in Tables <a href="#Tab1" class="usa-link">1</a> and <a href="#Tab2" class="usa-link">2</a>, showing that Noisereduce outperforms other conventional algorithms at all tested SNR levels, for the hyperparameters we sampled (Table <a href="#Tab9" class="usa-link">9</a>).</p>
<figure class="fig xbox font-sm" id="Fig3"><h4 class="obj_head">Fig. 3.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373731_41598_2025_13108_Fig3_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/5790ead45b38/41598_2025_13108_Fig3_HTML.jpg" loading="lazy" id="MO3" height="322" width="794" alt="Fig. 3"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Noise reduction samples from different algorithms applied to the ’sp04’ sample from the NOIZEUS dataset (SNR: 10 dB, exhibition noise).</p></figcaption></figure><section class="tw xbox font-sm" id="Tab1"><h4 class="obj_head">Table 1.</h4>
<div class="caption p"><p>STOI performance metric on NOIZEUS dataset (mean ± SEM) for different algorithms across various SNR levels.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Algorithm</th>
<th align="left" colspan="1" rowspan="1">SNR 0</th>
<th align="left" colspan="1" rowspan="1">SNR 5</th>
<th align="left" colspan="1" rowspan="1">SNR 10</th>
<th align="left" colspan="1" rowspan="1">SNR 15</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Baseline</td>
<td align="left" colspan="1" rowspan="1">0.671 ± 0.004</td>
<td align="left" colspan="1" rowspan="1">0.783 ± 0.003</td>
<td align="left" colspan="1" rowspan="1">0.878 ± 0.003</td>
<td align="left" colspan="1" rowspan="1">0.937 ± 0.002</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Iterative Wiener</td>
<td align="left" colspan="1" rowspan="1">0.509 ± 0.004</td>
<td align="left" colspan="1" rowspan="1">0.594 ± 0.004</td>
<td align="left" colspan="1" rowspan="1">0.664 ± 0.005</td>
<td align="left" colspan="1" rowspan="1">0.704 ± 0.005</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">NoiseReduce (ours)</td>
<td align="left" colspan="1" rowspan="1">
<strong>0.683</strong> ± <strong>0.004</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>0.799</strong> ± <strong>0.003</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>0.893</strong> ± <strong>0.002</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>0.946</strong> ± <strong>0.002</strong>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Savitzky-Golay</td>
<td align="left" colspan="1" rowspan="1">0.668 ± 0.004</td>
<td align="left" colspan="1" rowspan="1">0.779 ± 0.003</td>
<td align="left" colspan="1" rowspan="1">0.875 ± 0.003</td>
<td align="left" colspan="1" rowspan="1">0.934 ± 0.002</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Spectral Subtraction</td>
<td align="left" colspan="1" rowspan="1">0.417 ± 0.003</td>
<td align="left" colspan="1" rowspan="1">0.451 ± 0.002</td>
<td align="left" colspan="1" rowspan="1">0.479 ± 0.002</td>
<td align="left" colspan="1" rowspan="1">0.493 ± 0.002</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Subspace</td>
<td align="left" colspan="1" rowspan="1">0.608 ± 0.004</td>
<td align="left" colspan="1" rowspan="1">0.682 ± 0.003</td>
<td align="left" colspan="1" rowspan="1">0.712 ± 0.004</td>
<td align="left" colspan="1" rowspan="1">0.724 ± 0.004</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Wiener</td>
<td align="left" colspan="1" rowspan="1">0.668 ± 0.004</td>
<td align="left" colspan="1" rowspan="1">0.766 ± 0.004</td>
<td align="left" colspan="1" rowspan="1">0.840 ± 0.003</td>
<td align="left" colspan="1" rowspan="1">0.879 ± 0.002</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><section class="tw xbox font-sm" id="Tab2"><h4 class="obj_head">Table 2.</h4>
<div class="caption p"><p>PESQ performance metric on NOIZEUS dataset (mean ± SEM) for different algorithms across various SNR levels.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Algorithm</th>
<th align="left" colspan="1" rowspan="1">SNR 0</th>
<th align="left" colspan="1" rowspan="1">SNR 5</th>
<th align="left" colspan="1" rowspan="1">SNR 10</th>
<th align="left" colspan="1" rowspan="1">SNR 15</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Baseline</td>
<td align="left" colspan="1" rowspan="1">1.421 ± 0.009</td>
<td align="left" colspan="1" rowspan="1">1.600 ± 0.010</td>
<td align="left" colspan="1" rowspan="1">1.878 ± 0.011</td>
<td align="left" colspan="1" rowspan="1">2.238 ± 0.013</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Iterative Wiener</td>
<td align="left" colspan="1" rowspan="1">1.374 ± 0.010</td>
<td align="left" colspan="1" rowspan="1">1.516 ± 0.011</td>
<td align="left" colspan="1" rowspan="1">1.687 ± 0.013</td>
<td align="left" colspan="1" rowspan="1">1.874 ± 0.017</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Noisereduce (ours)</td>
<td align="left" colspan="1" rowspan="1">
<strong>1.559</strong> ± <strong>0.008</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>1.854</strong> ± <strong>0.009</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>2.286</strong> ± <strong>0.011</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>2.778</strong> ± <strong>0.012</strong>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Savitzky-Golay</td>
<td align="left" colspan="1" rowspan="1">1.475 ± 0.010</td>
<td align="left" colspan="1" rowspan="1">1.672 ± 0.011</td>
<td align="left" colspan="1" rowspan="1">1.973 ± 0.012</td>
<td align="left" colspan="1" rowspan="1">2.353 ± 0.014</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Spectral Subtraction</td>
<td align="left" colspan="1" rowspan="1">1.493 ± 0.010</td>
<td align="left" colspan="1" rowspan="1">1.733 ± 0.009</td>
<td align="left" colspan="1" rowspan="1">2.064 ± 0.011</td>
<td align="left" colspan="1" rowspan="1">2.449 ± 0.012</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Subspace</td>
<td align="left" colspan="1" rowspan="1">1.415 ± 0.009</td>
<td align="left" colspan="1" rowspan="1">1.407 ± 0.008</td>
<td align="left" colspan="1" rowspan="1">1.380 ± 0.006</td>
<td align="left" colspan="1" rowspan="1">1.379 ± 0.007</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Wiener</td>
<td align="left" colspan="1" rowspan="1">1.458 ± 0.009</td>
<td align="left" colspan="1" rowspan="1">1.634 ± 0.009</td>
<td align="left" colspan="1" rowspan="1">1.858 ± 0.011</td>
<td align="left" colspan="1" rowspan="1">2.095 ± 0.012</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><section class="tw xbox font-sm" id="Tab9"><h4 class="obj_head">Table 9.</h4>
<div class="caption p"><p>Parameters for noise reduction.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1"><strong>Parameter</strong></th>
<th align="left" colspan="1" rowspan="1"><strong>Description</strong></th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">n_fft</td>
<td align="left" colspan="1" rowspan="1">Length of the windowed signal after padding with zeros, by default 1024.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">win_length</td>
<td align="left" colspan="1" rowspan="1">Each frame of audio is windowed by “window“ of length “win_length“ and then padded with zeros to match “n_fft“, by default None.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">hop_length</td>
<td align="left" colspan="1" rowspan="1">Number of audio samples between adjacent STFT columns, by default None.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">n_std_thresh</td>
<td align="left" colspan="1" rowspan="1">Number of standard deviations above mean to place the threshold between signal and noise, by default 1.5.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">noise_window_size_nonstationary_ms</td>
<td align="left" colspan="1" rowspan="1">The window size (in milliseconds) to compute the noise floor over in the non-stationary algorithm, by default 1.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">freq_mask_smooth_hz</td>
<td align="left" colspan="1" rowspan="1">The frequency range to smooth the mask over in Hz, by default 500.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">time_mask_smooth_ms</td>
<td align="left" colspan="1" rowspan="1">The time range to smooth the mask over in milliseconds, by default 50.</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">prop_decrease</td>
<td align="left" colspan="1" rowspan="1">The proportion to reduce the noise by (1.0 = 100%), by default 1.0.</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab9/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p id="Par25">To further evaluate its performance, we compared Noisereduce against a state-of-the-art deep learning-based model, Denoiser<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup>. While Denoiser had higher STOI and PESQ scores (Tables <a href="#Tab3" class="usa-link">3</a> and <a href="#Tab4" class="usa-link">4</a>), Noisereduce achieved competitive results with substantially lower computational overhead. Specifically, Denoiser requires over 33 million trainable parameters, whereas Noisereduce uses efficient signal processing techniques that require minimal computational resources and provide faster runtime (see Section <a href="#Sec9" class="usa-link">2.5</a>).</p>
<section class="tw xbox font-sm" id="Tab3"><h4 class="obj_head">Table 3.</h4>
<div class="caption p"><p>Comparison of STOI performance metric for Noisereduce and Denoiser across various SNR levels (mean ± SEM).</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Algorithm</th>
<th align="left" colspan="1" rowspan="1">SNR 0</th>
<th align="left" colspan="1" rowspan="1">SNR 5</th>
<th align="left" colspan="1" rowspan="1">SNR 10</th>
<th align="left" colspan="1" rowspan="1">SNR 15</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Noisereduce (ours)</td>
<td align="left" colspan="1" rowspan="1">0.683 ± 0.004</td>
<td align="left" colspan="1" rowspan="1">0.799 ± 0.003</td>
<td align="left" colspan="1" rowspan="1">0.893 ± 0.002</td>
<td align="left" colspan="1" rowspan="1">0.946 ± 0.002</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Denoiser</td>
<td align="left" colspan="1" rowspan="1">
<strong>0.796</strong> ± <strong>0.005</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>0.88</strong> ± <strong>0.003</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>0.927</strong> ± <strong>0.002</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>0.951</strong> ± <strong>0.002</strong>
</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><section class="tw xbox font-sm" id="Tab4"><h4 class="obj_head">Table 4.</h4>
<div class="caption p"><p>Comparison of PESQ performance metric for Noisereduce and Denoiser across various SNR levels (mean ± SEM).</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Algorithm</th>
<th align="left" colspan="1" rowspan="1">SNR 0</th>
<th align="left" colspan="1" rowspan="1">SNR 5</th>
<th align="left" colspan="1" rowspan="1">SNR 10</th>
<th align="left" colspan="1" rowspan="1">SNR 15</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Noisereduce (ours)</td>
<td align="left" colspan="1" rowspan="1">1.559 ± 0.008</td>
<td align="left" colspan="1" rowspan="1">1.854 ± 0.009</td>
<td align="left" colspan="1" rowspan="1">2.286 ± 0.011</td>
<td align="left" colspan="1" rowspan="1">
<strong>2.778</strong> ± <strong>0.012</strong>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Denoiser</td>
<td align="left" colspan="1" rowspan="1">
<strong>1.671</strong> ± <strong>0.015</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>2.04</strong> ± <strong>0.017</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>2.39</strong> ± <strong>0.018</strong>
</td>
<td align="left" colspan="1" rowspan="1">2.703 ± 0.023</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="Sec6"><h3 class="pmc_sec_title">Bioacoustics</h3>
<p id="Par26">Bioacoustic signals are recorded across Earth’s diverse bioregions, with conditions often unique to each dataset. Consequently, state-of-the-art machine-learning methods are rarely available<sup><a href="#CR64" class="usa-link" aria-describedby="CR64">64</a></sup>, making bioacoustics is an ideal domain for applying Noisereduce. To our knowledge, no benchmark dataset exists for bioacoustic noise reduction, unlike NOIZEUS<sup><a href="#CR34" class="usa-link" aria-describedby="CR34">34</a></sup> for speech. To fill this gap, we developed “NOIZEUS Birdsong”<sup><a href="#CR49" class="usa-link" aria-describedby="CR49">49</a></sup>, a benchmark dataset modeled after NOIZEUS’s methodology and structure. We sampled recordings from 14 European starlings, with five 40-second songs from each bird, all recorded in an acoustically isolated chamber<sup><a href="#CR2" class="usa-link" aria-describedby="CR2">2</a></sup>. To simulate realistic conditions, we added noise at four SNRs: 0, 5, 10, and 15 dB. Noise samples were taken from the “Soundscapes from around the world” dataset from Xeno Canto<sup><a href="#CR61" class="usa-link" aria-describedby="CR61">61</a></sup>. We selected eight distinct soundscape categories which we named: “rain”, “town”, “wind”, “waterfall”, “insects”, “swamp”, “frogscape”, and “forest”. Each soundscape contains various sources of noise and were sampled from the European Starling’s natural geographic range. The dataset exhibits diverse spectro-temporal noise characteristics, illustrated in <a href="#Sec16" class="usa-link">5.2</a> (Fig <a href="#Fig9" class="usa-link">9</a>).</p>
<figure class="fig xbox font-sm" id="Fig9"><h4 class="obj_head">Fig. 9.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373731_41598_2025_13108_Fig9_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/02c990fb4395/41598_2025_13108_Fig9_HTML.jpg" loading="lazy" id="MO9" height="808" width="642" alt="Fig. 9"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig9/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Spectrograms of a sample from the “Birdsong NOIZEUS” dataset at an SNR of 10 dB, showcasing the clean signal, the noisy signals with different types of environmental noise.</p></figcaption></figure><p id="Par27">We evaluated Noisereduce’s performance using the NOIZEUS Birdsong dataset and compared it with Savitzky-Golay and Wiener filtering, which are both domain-general noise reduction algorithms that performed well in the speech analysis. We measure improvements in Segmental Signal-to-Noise Ratio (SegSNR), which evaluates the quality of noise reduction across temporal segments, and Source-to-Distortion Ratio (SDR), which quantifies both signal degradation and residual noise. We find that Noisereduce outperforms the other conventional algorithms on both metrics (Tables <a href="#Tab5" class="usa-link">5</a>, <a href="#Tab6" class="usa-link">6</a>; Figure <a href="#Fig4" class="usa-link">4</a>).</p>
<section class="tw xbox font-sm" id="Tab5"><h4 class="obj_head">Table 5.</h4>
<div class="caption p"><p>SegSNR [dB] performance metric on Birdsong NOIZEUS dataset (mean ± SEM) for different algorithms across various SNR levels.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Algorithm</th>
<th align="left" colspan="1" rowspan="1">SNR 0</th>
<th align="left" colspan="1" rowspan="1">SNR 5</th>
<th align="left" colspan="1" rowspan="1">SNR 10</th>
<th align="left" colspan="1" rowspan="1">SNR 15</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Baseline</td>
<td align="left" colspan="1" rowspan="1">−0.38 ± 0.40</td>
<td align="left" colspan="1" rowspan="1">4.59 ± 0.40</td>
<td align="left" colspan="1" rowspan="1">9.58 ± 0.40</td>
<td align="left" colspan="1" rowspan="1">
<strong>14.58</strong> ± <strong>0.40</strong>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Noisereduce (ours)</td>
<td align="left" colspan="1" rowspan="1">
<strong>6.96</strong> ± <strong>0.31</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>9.61</strong> ± <strong>0.33</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>11.78</strong> ± <strong>0.33</strong>
</td>
<td align="left" colspan="1" rowspan="1">13.50 ± 0.39</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Savitzky-Golay</td>
<td align="left" colspan="1" rowspan="1">0.27 ± 0.48</td>
<td align="left" colspan="1" rowspan="1">4.45 ± 0.46</td>
<td align="left" colspan="1" rowspan="1">8.41 ± 0.43</td>
<td align="left" colspan="1" rowspan="1">11.91 ± 2.47</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Wiener</td>
<td align="left" colspan="1" rowspan="1">−0.09 ± 0.42</td>
<td align="left" colspan="1" rowspan="1">4.51 ± 0.41</td>
<td align="left" colspan="1" rowspan="1">8.61 ± 0.39</td>
<td align="left" colspan="1" rowspan="1">11.82 ± 0.37</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab5/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><section class="tw xbox font-sm" id="Tab6"><h4 class="obj_head">Table 6.</h4>
<div class="caption p"><p>SDR [dB] performance metric on Birdsong NOIZEUS dataset (mean ± SEM) for different algorithms across various SNR levels.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Algorithm</th>
<th align="left" colspan="1" rowspan="1">SNR 0</th>
<th align="left" colspan="1" rowspan="1">SNR 5</th>
<th align="left" colspan="1" rowspan="1">SNR 10</th>
<th align="left" colspan="1" rowspan="1">SNR 15</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Baseline</td>
<td align="left" colspan="1" rowspan="1">−6.37 ± 0.36</td>
<td align="left" colspan="1" rowspan="1">−1.43 ± 0.36</td>
<td align="left" colspan="1" rowspan="1">3.55 ± 0.37</td>
<td align="left" colspan="1" rowspan="1">8.56 ± 0.37</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Noisereduce (ours)</td>
<td align="left" colspan="1" rowspan="1">
<strong>0.79</strong> ± <strong>0.40</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>4.94</strong> ± <strong>0.37</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>8.69</strong> ± <strong>0.31</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>11.61</strong> ± <strong>0.25</strong>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Savitzky-Golay</td>
<td align="left" colspan="1" rowspan="1">−5.41 ± 0.49</td>
<td align="left" colspan="1" rowspan="1">−0.93 ± 0.49</td>
<td align="left" colspan="1" rowspan="1">3.61 ± 0.47</td>
<td align="left" colspan="1" rowspan="1">7.95 ± 0.44</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Wiener</td>
<td align="left" colspan="1" rowspan="1">−5.71 ± 0.43</td>
<td align="left" colspan="1" rowspan="1">−0.71 ± 0.44</td>
<td align="left" colspan="1" rowspan="1">4.18 ± 0.45</td>
<td align="left" colspan="1" rowspan="1">8.53 ± 0.38</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab6/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><figure class="fig xbox font-sm" id="Fig4"><h4 class="obj_head">Fig. 4.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373731_41598_2025_13108_Fig4_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/3e4b649f1922/41598_2025_13108_Fig4_HTML.jpg" loading="lazy" id="MO4" height="141" width="794" alt="Fig. 4"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Noise reduction samples from different algorithms applied to the ’B335’ sample from the NOIZEUS Birdsong dataset (SNR: 10 dB, waterfall noise).</p></figcaption></figure></section><section id="Sec7"><h3 class="pmc_sec_title">Electrophysiology</h3>
<p id="Par28">Extracellular electrophysiology is a key tool in recording single-neuron activity as animals interact with their environment. A challenge here is detecting extracellular spikes and assigning them to individual neurons, a process known as spikesorting. Current algorithms tackle this in steps: initially detecting spikes by thresholding amplitude or convolving the signal with spike templates, then iteratively clustering these putative spikes to estimate neuron identities, which provide templates for further detection. We tested whether Noisereduce could enhance initial spike detection by improving the SNR between spikes and background noise.</p>
<p id="Par29">We created a dataset of biophysically realistic neural recordings using the MEArec library<sup><a href="#CR9" class="usa-link" aria-describedby="CR9">9</a></sup>, simulating extracellular electrophysiology. Ground truth spikes were simulated from 10 neurons (8 excitatory, 2 inhibitory, Fig <a href="#Fig5" class="usa-link">5</a>A), with noise from 300 background neurons. Simulated data were used as real recordings lack ground truth.</p>
<figure class="fig xbox font-sm" id="Fig5"><h4 class="obj_head">Fig. 5.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373731_41598_2025_13108_Fig5_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/7a07ab580939/41598_2025_13108_Fig5_HTML.jpg" loading="lazy" id="MO5" height="822" width="750" alt="Fig. 5"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig5/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Noisereduce results on a simulated extracellular recording. (<strong>A</strong>) Sample neuron waveform templates. (<strong>B</strong>) A sample of 100ms of z-scored sampled neural data, with the original data in red and the denoised signal in black. (<strong>C</strong>-<strong>D</strong>) A spectrogram of the same data in B. (<strong>E</strong>) Amplitude of action potentials (blue) versus background noise (grey) in the original signal versus the denoised signal. (<strong>F</strong>) Reciever Operator Characteristic (ROC) curve of spike detection using the SpikeInterface detect_peaks algorithm to detect spikes.</p></figcaption></figure><p id="Par30">We applied a modified Noisereduce approach to this data (Fig <a href="#Fig5" class="usa-link">5</a>B), omitting the spectral mask smoothing step, which is computationally intensive and unnecessary for preliminary spike detection where spike shape is not used. We compared the output of Noisereduce to the untreated signal (bandpass filtered at 200-6000Hz; Fig <a href="#Fig5" class="usa-link">5</a>C-D). We found that the spike amplitude (z-scored; Fig <a href="#Fig5" class="usa-link">5</a>E) increased relative to background noise. To assess detection improvement, we used the SpikeInterface detection algorithm<sup><a href="#CR10" class="usa-link" aria-describedby="CR10">10</a></sup> and computed an ROC curve by varying the detection threshold. Noisereduce was compared against three conditions: baseline bandpass filtering, Wiener filtering, and Savitzky-Golay filtering (Fig <a href="#Fig5" class="usa-link">5</a>F). An Area Under the Curve (AUC) analysis found highest performance with Noisereduce (Noisereduce=0.97; Savitzky-Golay=0.96; Wiener = 0.94; Baseline=0.91), suggesting its suitability for initial spike detection. Given that spectral masking can alter spike shapes, we advise using Noisereduce solely for initial spike detection, not clustering.</p></section><section id="Sec8"><h3 class="pmc_sec_title">Seismology</h3>
<p id="Par31">Seismic event detection methods focus on identifying the onset of these events, a critical step for accurately locating and characterizing seismic activity<sup><a href="#CR1" class="usa-link" aria-describedby="CR1">1</a>,<a href="#CR15" class="usa-link" aria-describedby="CR15">15</a></sup>. A widely used approach is the Short-Time Average over Long-Time Average (STA/LTA) algorithm<sup><a href="#CR59" class="usa-link" aria-describedby="CR59">59</a>,<a href="#CR63" class="usa-link" aria-describedby="CR63">63</a></sup>, which calculates the ratio of short-term to long-term signal averages to detect events. However, background noise from the environment and equipment makes detection less reliable, resulting in missed detections and false alarms.</p>
<p id="Par32">Following Zhu et al. (2019)<sup><a href="#CR67" class="usa-link" aria-describedby="CR67">67</a></sup>, we tested Noisereduce on seismic waveforms from the ObsPy library<sup><a href="#CR3" class="usa-link" aria-describedby="CR3">3</a></sup> (see Fig <a href="#Fig6" class="usa-link">6</a>, top). To simulate realistic conditions, we added white and pink noise at SNRs ranging from 0 to 15 dB and evaluated detection accuracy by comparing STA/LTA-detected onset times between denoised and clean recordings. As with the spike-detection analysis, we applied a modified Noisereduce, omitting the smoothing step. In detecting the onset time of seismic activity, Noisereduce outperformed three baseline methods — no filtering, Wiener, and Savitzky-Golay - across all SNR levels, with the most significant improvements in low-SNR conditions (0 and 5 dB) for both noise types (see Tables <a href="#Tab7" class="usa-link">7</a> and <a href="#Tab8" class="usa-link">8</a>).</p>
<figure class="fig xbox font-sm" id="Fig6"><h4 class="obj_head">Fig. 6.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373731_41598_2025_13108_Fig6_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/e8b51415b091/41598_2025_13108_Fig6_HTML.jpg" loading="lazy" id="MO6" height="295" width="669" alt="Fig. 6"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig6/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>(Top) Seismic recording sample “ev0_6.a01.gse2” from ObsPy dataset. The trigger, determined using the STA/LTA algorithm, marks the signal onset (red line). Noise added (pink, SNR = 1dB) and Noisereduce and DeepDenoiser are compared. (Bottom) Performance metrics for the seismology dataset. DeepDenoiser comparisons were generated using the DeepDenoiser API at “<a href="https://ai4eps-deepdenoiser.hf.space" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://ai4eps-deepdenoiser.hf.space</a>”.</p></figcaption></figure><section class="tw xbox font-sm" id="Tab7"><h4 class="obj_head">Table 7.</h4>
<div class="caption p"><p>Onset detection error (mean ± SEM) for different algorithms across various SNR levels for white noise.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Algorithm</th>
<th align="left" colspan="1" rowspan="1">SNR 0</th>
<th align="left" colspan="1" rowspan="1">SNR 5</th>
<th align="left" colspan="1" rowspan="1">SNR 10</th>
<th align="left" colspan="1" rowspan="1">SNR 15</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Baseline</td>
<td align="left" colspan="1" rowspan="1">0.569 ± 0.106</td>
<td align="left" colspan="1" rowspan="1">0.385 ± 0.082</td>
<td align="left" colspan="1" rowspan="1">0.186 ± 0.042</td>
<td align="left" colspan="1" rowspan="1">0.090 ± 0.019</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Noisereduce (ours)</td>
<td align="left" colspan="1" rowspan="1">
<strong>0.192</strong> ± <strong>0.065</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>0.187</strong> ± <strong>0.058</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>0.124</strong> ± <strong>0.034</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>0.069</strong> ± <strong>0.019</strong>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Wiener</td>
<td align="left" colspan="1" rowspan="1">0.297 ± 0.063</td>
<td align="left" colspan="1" rowspan="1">0.237 ± 0.052</td>
<td align="left" colspan="1" rowspan="1">0.197 ± 0.054</td>
<td align="left" colspan="1" rowspan="1">0.080 ± 0.024</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Savitzky-Golay</td>
<td align="left" colspan="1" rowspan="1">0.242 ± 0.058</td>
<td align="left" colspan="1" rowspan="1">0.201 ± 0.045</td>
<td align="left" colspan="1" rowspan="1">0.169 ± 0.044</td>
<td align="left" colspan="1" rowspan="1">0.090 ± 0.023</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab7/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><section class="tw xbox font-sm" id="Tab8"><h4 class="obj_head">Table 8.</h4>
<div class="caption p"><p>Onset detection error (mean ± SEM) for different algorithms across various SNR levels for pink noise.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Algorithm</th>
<th align="left" colspan="1" rowspan="1">SNR 0</th>
<th align="left" colspan="1" rowspan="1">SNR 5</th>
<th align="left" colspan="1" rowspan="1">SNR 10</th>
<th align="left" colspan="1" rowspan="1">SNR 15</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Baseline</td>
<td align="left" colspan="1" rowspan="1">0.392 ± 0.102</td>
<td align="left" colspan="1" rowspan="1">0.308 ± 0.073</td>
<td align="left" colspan="1" rowspan="1">0.226 ± 0.052</td>
<td align="left" colspan="1" rowspan="1">0.111 ± 0.028</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Noisereduce (ours)</td>
<td align="left" colspan="1" rowspan="1">
<strong>0.129</strong> ± <strong>0.036</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>0.106</strong> ± <strong>0.025</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>0.074</strong> ± <strong>0.020</strong>
</td>
<td align="left" colspan="1" rowspan="1">
<strong>0.067</strong> ± <strong>0.017</strong>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Wiener</td>
<td align="left" colspan="1" rowspan="1">0.253 ± 0.085</td>
<td align="left" colspan="1" rowspan="1">0.244 ± 0.057</td>
<td align="left" colspan="1" rowspan="1">0.193 ± 0.039</td>
<td align="left" colspan="1" rowspan="1">0.093 ± 0.027</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Savitzky-Golay</td>
<td align="left" colspan="1" rowspan="1">0.134 ± 0.023</td>
<td align="left" colspan="1" rowspan="1">0.171 ± 0.034</td>
<td align="left" colspan="1" rowspan="1">0.160 ± 0.028</td>
<td align="left" colspan="1" rowspan="1">0.101 ± 0.027</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab8/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p id="Par33">To further assess Noisereduce’s quality in detecting seismic signals, we compared it to DeepDenoiser<sup><a href="#CR67" class="usa-link" aria-describedby="CR67">67</a></sup>, a deep neural network-based approach for denoising seismic waveforms. We compared the SNR of the signal post-denoising, the correlation coefficient between clean and denoised signals, and the change in maximum amplitude of the signal from the clean recording. While Noisereduce underperforms compared to the deep learning approach on all metrics, its performance is closer to the deep learning model than any of the other conventional algorithms, with the exception of the amplitude of the denoised signal, which is more greatly decreased in Noisereduce (Fig. <a href="#Fig6" class="usa-link">6</a>, bottom).</p></section><section id="Sec9"><h3 class="pmc_sec_title">Run-time analysis</h3>
<p id="Par34">Speed is a critical factor in selecting a noise reduction method, especially in applications requiring real-time or near-real-time analysis. Noise reduction algorithms are of limited use if they cannot process signals in a timely manner, as delays can become bottlenecks in analytical workflows. Noisereduce supports GPU parallelization, which significantly improves processing speed. To evaluate performance, we measured the average runtime across various signal lengths using an NVIDIA GeForce RTX 3070 GPU. The results (Fig <a href="#Fig7" class="usa-link">7</a>) demonstrate that GPU-accelerated Noisereduce outperforms other noise reduction algorithms, highlighting its potential for real-time applications.</p>
<figure class="fig xbox font-sm" id="Fig7"><h4 class="obj_head">Fig. 7.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/87dd0ea15b04/41598_2025_13108_Fig7_HTML.jpg" loading="lazy" id="MO7" height="356" width="644" alt="Fig. 7"></p>
<div class="p text-right font-secondary"><a href="figure/Fig7/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Runtime analysis comparing GPU-based Noisereduce, CPU-based Noisereduce, GPU-based Denoiser, CPU-based Denoiser, Wiener filter, and Savitzky-Golay filter on an RTX 3070 GPU with batch size of 32, and sample rate of 16 kHz.</p></figcaption></figure></section></section><section id="Sec10"><h2 class="pmc_sec_title">Selecting hyperparameters</h2>
<p id="Par35">Noisereduce relies on a small number of hyperparameters which impact how noise is detected and attenuated (Table <a href="#Tab9" class="usa-link">9</a>).</p>
<p id="Par36">The main two parameters to consider are n_std_thresh_stationary and prop_decrease. n_std_thresh_stationary sets the threshold for what to consider signal in terms of standard deviations of power above (or below) the mean power for each frequency channel. prop_decrease then determines the extent to which we remove the below-threshold noise. We additionally include noise_window_size_nonstationary_ms in the nonstationary version of the algorithm, which is the window over which threshold statistics are computed. freq_mask_smooth_hz and time_mask_smooth_ms, are used to smooth the mask using a Gaussian kernel, with the shape of the kernel defined by those parameters. A further implicit parameter is the duration of noise clip presented to the algorithm. For example, a very short noise clip may not accurately reflect the statistics of the noise profile in the full recording. Finally, n_fft, win_length, and hop_length are all parameters used to compute the spectrogram and should be set at values that would visibly capture spectrotemporal structure in your signal, if you were to plot the spectrogram.</p>
<p id="Par37">We performed an analysis of the robustness of this parameter selection on the Birdsong NOIZEUS dataset (Fig. <a href="#Fig8" class="usa-link">8</a>). Although the optimal parameters will be both dataset and downstream application specific, the analysis given here may provide some intuition for Noisereduce users. Broadly, we observe that a good range of choices for n_std_thresh_stationary is an intermediate range, between 1 and 5. prop_decrease generally improves in performance even at 1.0. Smooth mask is more variable on the metrics we analyzed (SDR and SegSNR). Finally, as we increase the duration of the noise clip thus performing a better estimate over noise, noise reduction improves (here maximum noise clip duration was the dataset maximum of 1 second). However, these metrics are an imperfect proxy for both perceptual quality and value in downstream tasks. To aid in intuiting the value of these parameters, we include supplementary audio clips of each of the sames in Fig. <a href="#Fig8" class="usa-link">8</a>.</p>
<figure class="fig xbox font-sm" id="Fig8"><h3 class="obj_head">Fig. 8.</h3>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373731_41598_2025_13108_Fig8_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/ad0843f7a6ed/41598_2025_13108_Fig8_HTML.jpg" loading="lazy" id="MO8" height="1122" width="750" alt="Fig. 8"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig8/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Visualization of parameters varied on the Birdsong NOIZEUS dataset (forest noise, SNR=0). (<strong>A</strong>) n_std_thresh (<strong>B</strong>) prop_decrease (<strong>C</strong>) freq_mask_smooth_hz and time_mask_smooth_ms (<strong>D</strong>) Noise clip length. (<strong>E</strong>) SDR values over a range of parameters for the Birdsong NOIZEUS dataset.</p></figcaption></figure></section><section id="Sec11"><h2 class="pmc_sec_title">Discussion</h2>
<p id="Par38">In this work we provide a validation for Noisereduce as a domain-general noise-reduction algorithm. Our findings demonstrate that Noisereduce can perform similarly to and often outperform traditional noise reduction algorithms, making it suitable for a number of applications such as in bioacoustics and electrophysiology. Additionally, it can be used as a baseline comparison in domains where extensive domain-general machine-learning based approaches already exist. An important advantage of Noisereduce is its support for GPU parallelization, which accelerates processing speed compared to CPU-only algorithms. The algorithm does not rely on training data, and its lightweight design makes it suitable for real-time use or resource-limited settings where deep learning may not be practical. Noisereduce is publicly available as a Python package, actively maintained, and easy to use.</p>
<section id="Sec12"><h3 class="pmc_sec_title">Limitations</h3>
<p id="Par39"><strong>Limitations to the Noisereduce algorithm</strong> We do not recommend Noisereduce for all applications. In many domains, including speech, domain-specific and often supervised approaches exist that will generally outperform Noisereduce. For example, the Denoiser algorithm we presented above. In other applications, we find that Noisereduce is a valuable starting place to improve signal to noise ratio. Even in domains where substantial domain-specific efforts exist, Noisereduce can remain a valuable tool. For example, Noisereduce can be used as an augmentation tool in creating training datasets, and it can be used in applications where a high-throughput low-latency approach is needed. Noisereduce is also subject to the challenges of spectral masking. When time-frequency components contain both signal and noise, a binary masking approach will not optimally separate the signal from noise. Noisereduce also operates by assuming that the highest amplitude components of the recording are signal, which is not always the case. Noisereduce also works best when noise is either stationary or nonstationary over timescales that are longer than the signal; when noise is intermittent over short timescales, particularly when the amplitude and frequency of the noise is similar, Noisereduce will not be able to differentiate signal from noise. In all cases, we recommend users carefully analyze the outputs of Noisereduce before blindly using it in an analysis pipeline.</p>
<p id="Par40"><strong>Limitations in comparisons</strong> The work presented here attempts to benchmark Noisereduce against a set of comparison algorithms on several noise-reduction quality metrics. However, these comparisons are neither complete not exhaustive. Each of the algorithms we presented here have applications which they are good at, and applications in which they fail. In the analyses we provided here, we tried to produce a good-faith attempt to parameterize each algorithm in such a way that it would perform well. However, the hyperparameters chosen for both Noisereduce and its comparisons (Table <a href="#Tab9" class="usa-link">9</a>) were neither exhaustively scanned, nor were they systematically optimized. There are also several other domain-general noise reduction approaches which have not been compared here, for example wavelet-based approaches<sup><a href="#CR13" class="usa-link" aria-describedby="CR13">13</a>,<a href="#CR14" class="usa-link" aria-describedby="CR14">14</a></sup> and Empirical Mode Decomposition<sup><a href="#CR7" class="usa-link" aria-describedby="CR7">7</a>,<a href="#CR8" class="usa-link" aria-describedby="CR8">8</a></sup>. We therefore ask that readers interpret these results as we have, i.e. that noisereduce performs very well on the metrics we have provided, and at least consistent with other approaches. It is also true that the ’metrics’ that we chose to make comparisons are themselves only a very rough proxy of what is wanted out of a noise reduction algorithm, which differ depending on application. There are no algorithms which perfectly reflect human perceptual judgement in any domain. Even if there were, noise reduction algorithms that optimized for human perception would not necessarily be optimized for the many possible downstream tasks that one might perform on the denoised signal.</p></section></section><section id="Sec13"><h2 class="pmc_sec_title">Methods</h2>
<section id="Sec14"><h3 class="pmc_sec_title">Implementation details</h3>
<section id="Sec15"><h4 class="pmc_sec_title">Algorithm</h4>
<p id="Par41">To reduce noise from time-series recordings, Noisereduce builds a mask over a time-frequency representation of the signal, which is used to mask noise from signal. The concept of spectral gating/subtraction/masking originates with Boll in 1979<sup><a href="#CR5" class="usa-link" aria-describedby="CR5">5</a></sup> and many variants of spectral gating have been developed since that time, ranging from simple statistics to more recent deep learning based approaches<sup><a href="#CR54" class="usa-link" aria-describedby="CR54">54</a></sup>. Noisereduce generates a spectral mask by computing descriptive statistics over the time-frequency representation of noise clip and comparing them to the signal. The spectral mask is generated using the following steps:</p>
<p id="Par42">Let <em>X</em> denote the noisy input signal. If an isolated noise clip <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq21"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/db5529017cc0/d33e1832.gif" loading="lazy" id="d33e1832" alt="Inline graphic"></span> is available, it is used for statistics; otherwise, we set <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq22"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/6e56d6ce6500/d33e1838.gif" loading="lazy" id="d33e1838" alt="Inline graphic"></span>. The noise Short-Time Fourier Transform (STFT), obtained with a Hann window of length <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq23"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/9bbda1f40110/d33e1844.gif" loading="lazy" id="d33e1844" alt="Inline graphic"></span> and hop <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq24"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/7cf6d48a64d3/d33e1850.gif" loading="lazy" id="d33e1850" alt="Inline graphic"></span>, is:</p>
<table class="disp-formula p" id="Equ1"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/64ee455ddab9/d33e1857.gif" loading="lazy" id="d33e1857" alt="graphic file with name d33e1857.gif"></td>
<td class="label">1</td>
</tr></table>
<p>where indices <em>i</em> and <em>j</em> denote time frames and frequency bins, respectively.</p>
<p id="Par43"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq25"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/ca620dd5fdf8/d33e1871.gif" loading="lazy" id="d33e1871" alt="Inline graphic"></span> is converted to magnitude spectrogram in decibels (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq26"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/5a52a5dcf76e/d33e1877.gif" loading="lazy" id="d33e1877" alt="Inline graphic"></span>):</p>
<table class="disp-formula p" id="Equ2"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/ecba8e92a4c8/d33e1883.gif" loading="lazy" id="d33e1883" alt="graphic file with name d33e1883.gif"></td>
<td class="label">2</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq27"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/cd8253eb5575/d33e1890.gif" loading="lazy" id="d33e1890" alt="Inline graphic"></span> is a small positive constant for stability.</p>
<p id="Par44">We next compute statistics over the noise spectrogram <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq28"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/5a52a5dcf76e/d33e1898.gif" loading="lazy" id="d33e1898" alt="Inline graphic"></span>. For every frequency bin <em>j</em>, we compute the mean (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq29"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/c8e6eddb16be/d33e1907.gif" loading="lazy" id="d33e1907" alt="Inline graphic"></span>) and standard deviation (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq30"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/1dae6ff2cbdc/d33e1913.gif" loading="lazy" id="d33e1913" alt="Inline graphic"></span>) across all time frames:</p>
<table class="disp-formula p" id="Equ3"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/853a2868dede/d33e1919.gif" loading="lazy" id="d33e1919" alt="graphic file with name d33e1919.gif"></td>
<td class="label">3</td>
</tr></table>
<table class="disp-formula p" id="Equ4"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/1f50b9f218d8/d33e1925.gif" loading="lazy" id="d33e1925" alt="graphic file with name d33e1925.gif"></td>
<td class="label">4</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq31"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/ac09e9445ade/d33e1933.gif" loading="lazy" id="d33e1933" alt="Inline graphic"></span> is the total number of time frames.</p>
<p id="Par45">These statistics are used to create a threshold for each frequency bin (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq32"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/f2027a17a589/d33e1941.gif" loading="lazy" id="d33e1941" alt="Inline graphic"></span>), from <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq33"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/c8e6eddb16be/d33e1947.gif" loading="lazy" id="d33e1947" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq34"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/1dae6ff2cbdc/d33e1953.gif" loading="lazy" id="d33e1953" alt="Inline graphic"></span>, and a hyperparameter (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq35"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/10c81be4a07d/d33e1959.gif" loading="lazy" id="d33e1959" alt="Inline graphic"></span>) which sets the number of standard deviations above the mean:</p>
<table class="disp-formula p" id="Equ5"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/b28fdcce42a6/d33e1965.gif" loading="lazy" id="d33e1965" alt="graphic file with name d33e1965.gif"></td>
<td class="label">5</td>
</tr></table>
<p>We can then create the mask for the signal. To do this, we need to compute the STFT (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq36"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/037c47cbd60d/d33e1973.gif" loading="lazy" id="d33e1973" alt="Inline graphic"></span>) of the signal clip (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq37"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/59df33db49d1/d33e1979.gif" loading="lazy" id="d33e1979" alt="Inline graphic"></span>).</p>
<table class="disp-formula p" id="Equ6"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/098d81178c28/d33e1985.gif" loading="lazy" id="d33e1985" alt="graphic file with name d33e1985.gif"></td>
<td class="label">6</td>
</tr></table>
<p><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq38"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/037c47cbd60d/d33e1991.gif" loading="lazy" id="d33e1991" alt="Inline graphic"></span> is converted to magnitude spectrogram in decibels (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq39"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/f845aa6ccebc/d33e1997.gif" loading="lazy" id="d33e1997" alt="Inline graphic"></span>):</p>
<table class="disp-formula p" id="Equ7"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/0298bd7bdd87/d33e2003.gif" loading="lazy" id="d33e2003" alt="graphic file with name d33e2003.gif"></td>
<td class="label">7</td>
</tr></table>
<p>The binary mask (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq40"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/665ac1c299c3/d33e2011.gif" loading="lazy" id="d33e2011" alt="Inline graphic"></span>) is then computed on the signal spectrogram (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq41"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/f845aa6ccebc/d33e2017.gif" loading="lazy" id="d33e2017" alt="Inline graphic"></span>), based on the thresholds for each frequency bin.</p>
<table class="disp-formula p" id="Equ8"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/9d2e0e847e44/d33e2023.gif" loading="lazy" id="d33e2023" alt="graphic file with name d33e2023.gif"></td>
<td class="label">8</td>
</tr></table>
<p>To reduce artifacts from sharp transitions, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq42"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/665ac1c299c3/d33e2030.gif" loading="lazy" id="d33e2030" alt="Inline graphic"></span> can optionally be smoothed using a 2-D filter <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq43"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/78b515de073d/d33e2036.gif" loading="lazy" id="d33e2036" alt="Inline graphic"></span>, characterized by <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq44"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/cdb7d93da3a6/d33e2042.gif" loading="lazy" id="d33e2042" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq45"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/85618b4cd46a/d33e2049.gif" loading="lazy" id="d33e2049" alt="Inline graphic"></span>, which define the half-width of the filter in frequency and time, respectively.</p>
<p id="Par46">The filter <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq46"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/826a4caa6481/d33e2057.gif" loading="lazy" id="d33e2057" alt="Inline graphic"></span> is expressed as a separable matrix:</p>
<table class="disp-formula p" id="Equ9"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/c3bca4835d4f/d33e2063.gif" loading="lazy" id="d33e2063" alt="graphic file with name d33e2063.gif"></td>
<td class="label">9</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq47"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/162c89db8886/d33e2070.gif" loading="lazy" id="d33e2070" alt="Inline graphic"></span> denotes the outer product, and the components are defined as:</p>
<table class="disp-formula p" id="Equ10"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/8f9272d62aa2/d33e2076.gif" loading="lazy" id="d33e2076" alt="graphic file with name d33e2076.gif"></td>
<td class="label">10</td>
</tr></table>
<table class="disp-formula p" id="Equ11"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/1a0b3da49c89/d33e2082.gif" loading="lazy" id="d33e2082" alt="graphic file with name d33e2082.gif"></td>
<td class="label">11</td>
</tr></table>
<p>The expressions are defined for <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq48"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/601004031ea9/d33e2089.gif" loading="lazy" id="d33e2089" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq49"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/5e68e040902f/d33e2096.gif" loading="lazy" id="d33e2096" alt="Inline graphic"></span>, effectively creating symmetric triangular windows. The normalization constant <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq50"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/61fb3b0751be/d33e2102.gif" loading="lazy" id="d33e2102" alt="Inline graphic"></span> is determined such that the sum of all elements in the 2-D filter satisfies <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq51"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/113a6ad0deb4/d33e2108.gif" loading="lazy" id="d33e2108" alt="Inline graphic"></span>.</p>
<p id="Par47">If smoothing is applied, the smoothed mask <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq52"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/fe4720244628/d33e2116.gif" loading="lazy" id="d33e2116" alt="Inline graphic"></span> is obtained by convolving the original mask <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq53"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/665ac1c299c3/d33e2122.gif" loading="lazy" id="d33e2122" alt="Inline graphic"></span> with the smoothing filter <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq54"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/78b515de073d/d33e2128.gif" loading="lazy" id="d33e2128" alt="Inline graphic"></span>.</p>
<table class="disp-formula p" id="Equ12"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/f8caf7b2b2ee/d33e2134.gif" loading="lazy" id="d33e2134" alt="graphic file with name d33e2134.gif"></td>
<td class="label">12</td>
</tr></table>
<p>We can then apply the mask to the STFT of the signal (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq55"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/e345921000a1/d33e2141.gif" loading="lazy" id="d33e2141" alt="Inline graphic"></span>) by multiplying <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq56"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/665ac1c299c3/d33e2148.gif" loading="lazy" id="d33e2148" alt="Inline graphic"></span> or <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq57"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/fe4720244628/d33e2154.gif" loading="lazy" id="d33e2154" alt="Inline graphic"></span> with <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq58"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/e345921000a1/d33e2160.gif" loading="lazy" id="d33e2160" alt="Inline graphic"></span> to produce the masked STFT (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq59"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/4609b8b180b9/d33e2166.gif" loading="lazy" id="d33e2166" alt="Inline graphic"></span>).</p>
<table class="disp-formula p" id="Equ13"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/fb4f02196604/d33e2172.gif" loading="lazy" id="d33e2172" alt="graphic file with name d33e2172.gif"></td>
<td class="label">13</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq60"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/3a27c7db809d/d33e2179.gif" loading="lazy" id="d33e2179" alt="Inline graphic"></span> is a scaling factor that controls the strength of the masking effect.</p>
<p id="Par48">The masked STFT (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq61"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/4609b8b180b9/d33e2187.gif" loading="lazy" id="d33e2187" alt="Inline graphic"></span>) is then inverted back into the time-domain <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq62"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/480fba673364/d33e2193.gif" loading="lazy" id="d33e2193" alt="Inline graphic"></span> using an inverse STFT.</p>
<table class="disp-formula p" id="Equ14"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/f0456ee59c7a/d33e2199.gif" loading="lazy" id="d33e2199" alt="graphic file with name d33e2199.gif"></td>
<td class="label">14</td>
</tr></table>
<p><strong>Non-stationary</strong> The non-stationary algorithm differs from the stationary version of Noisereduce in how the noise mask is computed. The central goal of the non-stationary algorithm is to compute a noise mask locally in time rather than globally across the entire recording or dataset, to account for fluctuations in the noise floor. To accomplish this, we simply compute the mean and standard deviation of the frequency components over a sliding window on <em>X</em> without a noise clip, and then proceed with the rest of the algorithm normally.</p>
<p id="Par49"><strong>Soft Mask</strong> While the current implementation uses a binary mask (0 or 1), future work could explore a soft mask with values between 0 and 1 to achieve smoother signal-noise separation.</p></section></section><section id="Sec16"><h3 class="pmc_sec_title">Datasets</h3>
<p id="Par50"><strong>Speech</strong> The evaluation included thirty phonetically balanced speech utterances from the “<em>Noisy Speech Corpus</em>” (NOIZEUS) database<sup><a href="#CR21" class="usa-link" aria-describedby="CR21">21</a>,<a href="#CR34" class="usa-link" aria-describedby="CR34">34</a>,<a href="#CR65" class="usa-link" aria-describedby="CR65">65</a></sup>, a database specifically designed for noisy speech research. These utterances were combined with eight distinct real-world noise types, including suburban train, babble, car, exhibition hall, restaurant, street, airport, and train station noises, at SNRs of 0 dB, 5 dB, 10 dB, and 15 dB, following Method B of the ITU-T P.56 standard<sup><a href="#CR23" class="usa-link" aria-describedby="CR23">23</a></sup>.</p>
<p id="Par51"><strong>Birdsong</strong> We created the Birdsong NOIZEUS dataset<sup><a href="#CR49" class="usa-link" aria-describedby="CR49">49</a></sup> in the likeness of the speech NOIZEUS dataset<sup><a href="#CR34" class="usa-link" aria-describedby="CR34">34</a></sup>. We selected 70 song samples from 14 European starlings (5 samples of 40 seconds each). These recordings were selected from a larger collection previously gathered by the authors for prior publications<sup><a href="#CR2" class="usa-link" aria-describedby="CR2">2</a>,<a href="#CR50" class="usa-link" aria-describedby="CR50">50</a></sup>. The original dataset contains several hundred 30 to 60 second recordings per bird, obtained from wild-caught European starlings in Southern California. Recordings were performed in acoustically isolated chambers to ensure high-quality audio capture. We sampled noise from the “Soundscapes from around the world” dataset from Xeno Canto<sup><a href="#CR61" class="usa-link" aria-describedby="CR61">61</a></sup>. We hand selected 8 soundscapes from this dataset which we named “rain”, “town”, “wind”, “waterfall”, “insects”, “swamp”, “frogscape”, and “forest”. Each soundscape contains various sources of noise and were sampled from the European Starling’s natural range. For each song, we selected a different segment of the soundscape (soundscapes were around 5-20 minutes each). An example of the dataset can be seen in Figue <a href="#Fig9" class="usa-link">9</a>. We set the SNR based on loudness measured using the pyloudnorm Python library<sup><a href="#CR56" class="usa-link" aria-describedby="CR56">56</a></sup>. Additionally, for each song and noise clip we included a 1-second clip of noise sampled randomly (at the same SNR of the audioclip). This dataset is publicly available on Zenodo (DOI: 10.5281/zenodo.13947444).</p>
<p id="Par52"><strong>Seismology</strong> The seismic data used in this study was obtained from the ObsPy Trigger/Picker Tutorial<sup><a href="#CR3" class="usa-link" aria-describedby="CR3">3</a></sup>, including waveform recordings from three seismic stations: EV, RJOB, and MANZ. The dataset, recorded in January 1970, contains natural seismic events specifically selected for evaluating triggering and picking algorithms. For our analysis, we used all available signals from the trigger dataset, excluding those with low SNR. To simulate realistic seismic and instrumental noise, we added both white noise and pink noise at varying SNR ratios (0, 5, 10, and 15 dB).</p>
<p id="Par53"><strong>Electrophysiology</strong> Electrophysiology datasets were generated using the MEArec<sup><a href="#CR9" class="usa-link" aria-describedby="CR9">9</a></sup> Python library so that we would have access to ground truth spiking events alongside electrophysiology. Some non-simulated ephys datasets record ground truth events, e.g. by pairing extracellular recordings with intracellular recordings<sup><a href="#CR37" class="usa-link" aria-describedby="CR37">37</a></sup>, but, since not all cells are recorded intracellularly, they are of limited value in differentiating between false positive and true positive detections of other cells. facilitates the generation of customizable extracellular spiking activity datasets by leveraging biophysically detailed simulations. It achieves this by first creating templates of extracellular action potentials using realistic cell models, positioned around electrode probes within a simulation environment. These cell models, drawn from established neuroscience databases, undergo intracellular simulation to compute transmembrane currents using tools like NEURON, while the extracellular potentials are calculated using methods such as the line-source approximation via the LFPy package. This process allows MEArec to accurately simulate various neural dynamics and probe configurations, offering a flexible framework for evaluating and developing spike sorting methods under controlled experimental conditions.</p>
<p id="Par54">We generated a dataset comprising a monotrode (single channel) recording 10 minutes in length. The recording had 10 neurons (8 excitatory and 2 inhibitory). Spikes ranged in amplitude from 75-150uV. Background noise was generated using 300 simulated neurons that were further away from the probe (each with a maximum amplitude of 75uV). Simulated data were bandpass filtered between 300 and 6000 Hz.</p></section><section id="Sec17"><h3 class="pmc_sec_title">Additional algorithms</h3>
<p id="Par55"><strong>Wiener Filter</strong> The Wiener filter, as implemented in<sup><a href="#CR31" class="usa-link" aria-describedby="CR31">31</a></sup>, is an adaptive noise reduction algorithm that analyze local statistics within a sliding window. The filter adapts to local signal characteristics by weighting the difference between the noisy observation and the local mean based on the local variance. The filter applies minimal smoothing in high-variance regions to preserve significant signal features, while employing more aggressive smoothing in low-variance areas presumed to be noise-dominated.</p>
<p id="Par56">The output signal <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq63"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/253a242beefc/d33e2310.gif" loading="lazy" id="d33e2310" alt="Inline graphic"></span> at index <em>n</em> is computed using:</p>
<table class="disp-formula p" id="Equ15"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/b6ec68972eb8/d33e2319.gif" loading="lazy" id="d33e2319" alt="graphic file with name d33e2319.gif"></td>
<td class="label">15</td>
</tr></table>
<p>where <em>y</em>[<em>n</em>] is the observed noisy signal, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq64"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/c8e6eddb16be/d33e2333.gif" loading="lazy" id="d33e2333" alt="Inline graphic"></span> is the local mean within a window centered around <em>n</em>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq65"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/a8efa017098c/d33e2342.gif" loading="lazy" id="d33e2342" alt="Inline graphic"></span> is the variance of the signal in that window, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq66"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/5f8c81e04aa8/d33e2348.gif" loading="lazy" id="d33e2348" alt="Inline graphic"></span> is the estimated noise variance calculated as the average of all local variances across the signal.</p>
<p id="Par57">We used the SciPy implementation<sup><a href="#CR62" class="usa-link" aria-describedby="CR62">62</a></sup> as a comparison.</p>
<p id="Par58"><strong>Iterative Wiener</strong> The Iterative Wiener<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup> performs noise reduction in the frequency domain by iteratively computing a Wiener filter for each frame. The Wiener filter for each frequency <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq67"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/0fa42dae2c49/d33e2368.gif" loading="lazy" id="d33e2368" alt="Inline graphic"></span> is defined as:</p>
<table class="disp-formula p" id="Equ16"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/ce8683f74a55/d33e2374.gif" loading="lazy" id="d33e2374" alt="graphic file with name d33e2374.gif"></td>
<td class="label">16</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq68"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/eddf9b67911c/d33e2381.gif" loading="lazy" id="d33e2381" alt="Inline graphic"></span> is the speech power spectral density, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq69"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/0ce70faf08fc/d33e2387.gif" loading="lazy" id="d33e2387" alt="Inline graphic"></span> is the noise variance.</p>
<p id="Par59">To determine if a frame contains speech, a simple energy threshold is used. When speech is detected, the algorithm refines the clean signal estimate by iteratively calculating Linear Predictive Coding (LPC) coefficients of the input frame, which model the vocal tract as an all-pole filter. These LPC coefficients help estimate the speech power spectrum and update the Wiener filter to reduce noise. After denoising, new LPC coefficients are calculated from the denoised signal, further improving the filter.</p>
<p id="Par60">When no speech is detected, the noise variance is updated. The algorithm uses an IIR filter to smooth the noise estimate. The noise variance <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq70"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/0ce70faf08fc/d33e2397.gif" loading="lazy" id="d33e2397" alt="Inline graphic"></span> is updated as follows:</p>
<table class="disp-formula p" id="Equ17"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/e9092425285e/d33e2403.gif" loading="lazy" id="d33e2403" alt="graphic file with name d33e2403.gif"></td>
<td class="label">17</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq71"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/73975112fc4a/d33e2410.gif" loading="lazy" id="d33e2410" alt="Inline graphic"></span> is the smoothing factor, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq72"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/2957166f1ebb/d33e2416.gif" loading="lazy" id="d33e2416" alt="Inline graphic"></span> is the energy of the input frame.</p>
<p id="Par61">We used the pyroomacoustics library<sup><a href="#CR53" class="usa-link" aria-describedby="CR53">53</a></sup> as a comparison.</p>
<p id="Par62"><strong>Savitzky-Golay Filter</strong> The Savitzky-Golay filter<sup><a href="#CR52" class="usa-link" aria-describedby="CR52">52</a></sup> is a smoothing technique that employs a polynomial fitting approach. By fitting low-degree polynomials to successive subsets of adjacent data points, it effectively reduces noise while preserving important signal features. The output signal <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq73"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/253a242beefc/d33e2436.gif" loading="lazy" id="d33e2436" alt="Inline graphic"></span> at index <em>n</em> is computed using:</p>
<table class="disp-formula p" id="Equ18"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/57d734703fe1/d33e2445.gif" loading="lazy" id="d33e2445" alt="graphic file with name d33e2445.gif"></td>
<td class="label">18</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq74"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/263ddacedfd7/d33e2452.gif" loading="lazy" id="d33e2452" alt="Inline graphic"></span> represents the window size, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq75"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/8d4c4f7873dd/d33e2459.gif" loading="lazy" id="d33e2459" alt="Inline graphic"></span> are the input data points within the window, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq76"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/322425df37b5/d33e2465.gif" loading="lazy" id="d33e2465" alt="Inline graphic"></span> are the convolution coefficients derived by the polynomial fitting.</p>
<p id="Par63">We used the SciPy implementation<sup><a href="#CR62" class="usa-link" aria-describedby="CR62">62</a></sup> as a comparison.</p>
<p id="Par64"><strong>Spectral Subtraction</strong> The Spectral Subtraction algorithm<sup><a href="#CR5" class="usa-link" aria-describedby="CR5">5</a></sup> performs noise reduction by subtracting an estimate of the noise spectrum from the spectrum of the noisy signal. It operates under the assumption that the noise is additive and uncorrelated with the signal. The output signal spectrum <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq77"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/628d44901e6d/d33e2485.gif" loading="lazy" id="d33e2485" alt="Inline graphic"></span> is computed as:</p>
<table class="disp-formula p" id="Equ19"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/c1c8bc76e4be/d33e2491.gif" loading="lazy" id="d33e2491" alt="graphic file with name d33e2491.gif"></td>
<td class="label">19</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq78"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/bb5ca6c4e548/d33e2498.gif" loading="lazy" id="d33e2498" alt="Inline graphic"></span> is the Fourier transform of the noisy signal, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq79"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/55b64d600513/d33e2504.gif" loading="lazy" id="d33e2504" alt="Inline graphic"></span> is the estimated noise spectrum. The <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq80"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/1b519ff5f818/d33e2511.gif" loading="lazy" id="d33e2511" alt="Inline graphic"></span> function ensures that the resulting magnitude is non-negative. The noise spectrum <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq81"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/55b64d600513/d33e2517.gif" loading="lazy" id="d33e2517" alt="Inline graphic"></span> is obtained during periods of silence in the signal, under the assumption that only noise is present.</p>
<p id="Par65">To reconstruct the clean signal, the inverse Fourier transform is applied to <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq82"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/4a7f6d27b3f9/d33e2526.gif" loading="lazy" id="d33e2526" alt="Inline graphic"></span> while using the phase information from the noisy signal <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq83"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/bb5ca6c4e548/d33e2532.gif" loading="lazy" id="d33e2532" alt="Inline graphic"></span>.</p>
<p id="Par66">We used the pyroomacoustics library<sup><a href="#CR53" class="usa-link" aria-describedby="CR53">53</a></sup> as a comparison.</p>
<p id="Par67"><strong>Subspace</strong> The Subspace algorithm<sup><a href="#CR16" class="usa-link" aria-describedby="CR16">16</a>,<a href="#CR20" class="usa-link" aria-describedby="CR20">20</a></sup> performs noise reduction by projecting the noisy signal <em>y</em>[<em>n</em>] onto a lower-dimensional subspace that primarily contains the clean signal, while the noise is assumed to be in the complementary subspace.</p>
<p id="Par68">An eigendecomposition is performed on the matrix,</p>
<table class="disp-formula p" id="Equ20"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/f03704a35073/d33e2563.gif" loading="lazy" id="d33e2563" alt="graphic file with name d33e2563.gif"></td>
<td class="label">20</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq84"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/74803a111ead/d33e2570.gif" loading="lazy" id="d33e2570" alt="Inline graphic"></span> is the noise covariance matrix, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq85"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/c9fbd1d8e24f/d33e2576.gif" loading="lazy" id="d33e2576" alt="Inline graphic"></span> is the covariance matrix of the input noisy signal, and <em>I</em> is the identity matrix. <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq86"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/74803a111ead/d33e2585.gif" loading="lazy" id="d33e2585" alt="Inline graphic"></span> is obtained during periods of silence in the signal, under the assumption that only noise is present.</p>
<p id="Par69">The cleaned signal <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq87"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/253a242beefc/d33e2593.gif" loading="lazy" id="d33e2593" alt="Inline graphic"></span> is obtained by projecting the noisy signal <em>y</em>[<em>n</em>] onto the signal subspace,</p>
<table class="disp-formula p" id="Equ21"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/556725ec881d/d33e2605.gif" loading="lazy" id="d33e2605" alt="graphic file with name d33e2605.gif"></td>
<td class="label">21</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq88"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/d07ccb8f2c59/d33e2612.gif" loading="lazy" id="d33e2612" alt="Inline graphic"></span> is the projection matrix, derived from the positive eigenvectors of <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq89"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/896cc7be8556/d33e2619.gif" loading="lazy" id="d33e2619" alt="Inline graphic"></span>.</p>
<p id="Par70">We used the pyroomacoustics library<sup><a href="#CR53" class="usa-link" aria-describedby="CR53">53</a></sup> as a comparison.</p>
<p id="Par71"><strong>DeepDenoiser</strong> The DeepDenoiser<sup><a href="#CR67" class="usa-link" aria-describedby="CR67">67</a></sup> is a deep neural network designed to denoise seismic signals by learning to separate the signal from noise. It is trained on datasets containing both noisy and clean waveform data. During the denoising process, the input seismic signal is first converted into the time-frequency domain. The network then uses a series of fully convolutional layers with skip connections to generate two masks: one for the signal and one for the noise. Finally, the denoised signal and the estimated noise are obtained by applying the inverse Short Time Fourier Transform.</p>
<p id="Par72"><strong>Denoiser</strong> Denoiser<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup> is a deep learning model designed to denoise speech signals. It processes raw audio waveforms using an encoder-decoder architecture with skip connections. The model is optimized across both time and frequency domains through multiple loss functions and is trained end-to-end on paired datasets of noisy and clean speech.</p></section><section id="Sec18"><h3 class="pmc_sec_title">Hyperparameters</h3>
<p id="Par73">We used the hyperparameters listed in Table <a href="#Tab10" class="usa-link">10</a> for comparison.</p>
<section class="tw xbox font-sm" id="Tab10"><h4 class="obj_head">Table 10.</h4>
<div class="caption p"><p>Noise reduction algorithms and their parameters.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1"><strong>Algorithm</strong></th>
<th align="left" colspan="1" rowspan="1"><strong>Parameters</strong></th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="6" colspan="1">Noisereduce</td>
<td align="left" colspan="1" rowspan="1">n_fft=1024,</td>
</tr>
<tr><td align="left" colspan="1" rowspan="1">win_length=256,</td></tr>
<tr><td align="left" colspan="1" rowspan="1">n_std_thresh_stationary=2,</td></tr>
<tr><td align="left" colspan="1" rowspan="1">prop_decrease=0.75,</td></tr>
<tr><td align="left" colspan="1" rowspan="1">freq_mask_smooth_hz=50,</td></tr>
<tr><td align="left" colspan="1" rowspan="1">time_mask_smooth_ms=32</td></tr>
<tr>
<td align="left" rowspan="5" colspan="1">Spectral Subtraction</td>
<td align="left" colspan="1" rowspan="1">nfft=512,</td>
</tr>
<tr><td align="left" colspan="1" rowspan="1">db_reduce=10,</td></tr>
<tr><td align="left" colspan="1" rowspan="1">lookback=5,</td></tr>
<tr><td align="left" colspan="1" rowspan="1">beta=20,</td></tr>
<tr><td align="left" colspan="1" rowspan="1">alpha=3</td></tr>
<tr>
<td align="left" rowspan="2" colspan="1">Savitzky-Golay</td>
<td align="left" colspan="1" rowspan="1">window_length=5,</td>
</tr>
<tr><td align="left" colspan="1" rowspan="1">polyorder=2</td></tr>
<tr>
<td align="left" rowspan="5" colspan="1">Subspace</td>
<td align="left" colspan="1" rowspan="1">frame_len=32,</td>
</tr>
<tr><td align="left" colspan="1" rowspan="1">mu=10,</td></tr>
<tr><td align="left" colspan="1" rowspan="1">lookback=10,</td></tr>
<tr><td align="left" colspan="1" rowspan="1">skip=2,</td></tr>
<tr><td align="left" colspan="1" rowspan="1">thresh=0.001</td></tr>
<tr>
<td align="left" rowspan="5" colspan="1">Iterative Wiener</td>
<td align="left" colspan="1" rowspan="1">frame_len=64,</td>
</tr>
<tr><td align="left" colspan="1" rowspan="1">lpc_order=20,</td></tr>
<tr><td align="left" colspan="1" rowspan="1">iterations=2,</td></tr>
<tr><td align="left" colspan="1" rowspan="1">alpha=0.8,</td></tr>
<tr><td align="left" colspan="1" rowspan="1">thresh=0.01</td></tr>
<tr>
<td align="left" colspan="1" rowspan="1">Wiener</td>
<td align="left" colspan="1" rowspan="1">window_size=5</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab10/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="Sec19"><h3 class="pmc_sec_title">Metrics</h3>
<p id="Par74"><strong>STOI</strong> Short-Time Objective Intelligibility (STOI)<sup><a href="#CR57" class="usa-link" aria-describedby="CR57">57</a></sup> is a widely used objective metric for assessing speech intelligibility, particularly in noisy environments. It functions by comparing short-time segments of clean reference and degraded speech signals, quantifying the level of degradation in terms of intelligibility. STOI calculates the correlation between the two signals over overlapping time windows, producing a score between 0 and 1. Higher scores indicate better intelligibility.</p>
<p id="Par75"><strong>PESQ</strong> Perceptual Evaluation of Speech Quality (PESQ)<sup><a href="#CR47" class="usa-link" aria-describedby="CR47">47</a></sup> is another objective metric designed to evaluate speech quality as perceived by human listeners. It incorporates a psychoacoustic model to simulate the human auditory system, comparing degraded or processed speech to a clean reference. PESQ captures both time-domain distortions and perceptual differences, generating a score between −0.5 and 4.5. Higher scores signify better perceived speech quality. Unlike STOI, which focuses on intelligibility, PESQ is more concerned with overall speech quality.</p>
<p id="Par76"><strong>SDR</strong> Source Distortion Ratio (SDR) evaluates the quality of source separation by measuring the logarithmic ratio of the power of the target source signal to the power of distortions, such as interference, noise, and artifacts. Higher SDR values indicate better separation performance, with fewer distortions. SDR is defined as follows:</p>
<table class="disp-formula p" id="Equ22"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/8797664ec738/d33e2847.gif" loading="lazy" id="d33e2847" alt="graphic file with name d33e2847.gif"></td>
<td class="label">22</td>
</tr></table>
<p>where <em>x</em> is the true clean signal, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq91"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/fabbc573bf60/d33e2857.gif" loading="lazy" id="d33e2857" alt="Inline graphic"></span> is the estimated signal.</p>
<p id="Par77"><strong>SegSNR</strong> Segmental Signal-to-Noise Ratio (SegSNR or SSNR), a modified version of Signal-to-Noise Ratio (SNR), provides a more localized assessment of signal quality. While traditional SNR evaluates signal-to-noise ratios across the entire signal, SegSNR calculates SNR within smaller segments and then averages these values. SegSNR is defined as follows:</p>
<table class="disp-formula p" id="Equ23"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/98c7/12373731/eff387e2bda4/d33e2867.gif" loading="lazy" id="d33e2867" alt="graphic file with name d33e2867.gif"></td>
<td class="label">23</td>
</tr></table>
<p>where <em>N</em> is the total number of segments, and <em>SNR</em>(<em>n</em>) is the SNR for the n-th segment.</p>
<p id="Par78"><strong>AUC</strong> The Receiver Operating Characteristic (ROC) curve is used to evaluate the performance of binary classifiers. The ROC curve plots true positive rate against false positive rate for various classification thresholds. The Area Under the Curve (AUC) quantifies the overall performance, ranging from 0.5 (random guessing) to 1.0 (perfect classification).</p></section></section><section id="ack1" class="ack"><h2 class="pmc_sec_title">Acknowledgements</h2>
<p>We thank David Burshtein for their feedback on an earlier version of this manuscript. Published by a grant from the Wetmore Colles fund.</p></section><section id="notes1"><h2 class="pmc_sec_title">Author contributions</h2>
<p>Both authors contributed equally to writing, software development, and experiments.</p></section><section id="notes2"><h2 class="pmc_sec_title">Data availability</h2>
<p>The Birdsong NOIZEUS dataset was generated for this publication. It is available at https://zenodo.org/records/13947444</p></section><section id="notes3"><h2 class="pmc_sec_title">Code availability</h2>
<p>The implementation of the Noisereduce algorithm is available at: <a href="https://github.com/timsainb/noisereduce" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/timsainb/noisereduce</a>. A future version of this software may be migrated to <a href="https://github.com/noisereduce/noisereduce" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/noisereduce/noisereduce</a>. The experimental results, including all necessary configuration files and scripts for reproducing the experiments, are provided at: <a href="https://github.com/noisereduce/paper_noisereduce" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/noisereduce/paper_noisereduce</a>.</p></section><section id="notes4"><h2 class="pmc_sec_title">Declarations</h2>
<section id="FPar2"><h3 class="pmc_sec_title">Competing interests</h3>
<p id="Par79">The authors declare no competing interests.</p></section></section><section id="fn-group1" class="fn-group"><h2 class="pmc_sec_title">Footnotes</h2>
<div class="fn-group p font-secondary-light font-sm">
<div class="fn p" id="fn1">
<p><strong>Publisher’s note</strong></p>
<p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</div>
<div class="fn p" id="fn2"><p>Tim Sainburg and Asaf Zorea contributed equally to this work.</p></div>
<div class="fn p" id="fn3"><p>Asaf Zorea is an independent researcher</p></div>
</div></section><section id="Bib1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="Bib1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="CR1">
<span class="label">1.</span><cite>Allen, R. V. Automatic earthquake recognition and timing from single traces. <em>Bulletin of the Seismological Society of America</em><strong>68</strong>(5), 1521–1532. 10.1785/BSSA0680051521 (1978).</cite> [<a href="https://scholar.google.com/scholar_lookup?Allen,%20R.%20V.%20Automatic%20earthquake%20recognition%20and%20timing%20from%20single%20traces.%20Bulletin%20of%20the%20Seismological%20Society%20of%20America68(5),%201521%E2%80%931532.%2010.1785/BSSA0680051521%20(1978)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR2">
<span class="label">2.</span><cite>Arneodo, Z., Sainburg, T., Jeanne, J. &amp; Gentner, T. An acoustically isolated european starling song library, (2019).</cite>
</li>
<li id="CR3">
<span class="label">3.</span><cite>Beyreuther, M. et al. ObsPy: A Python Toolbox for Seismology. <em>Seismological Research Letters</em><strong>81</strong>(3), 530–533. 10.1785/gssrl.81.3.530 (2010).</cite> [<a href="https://scholar.google.com/scholar_lookup?Beyreuther,%20M.%20et%20al.%20ObsPy:%20A%20Python%20Toolbox%20for%20Seismology.%20Seismological%20Research%20Letters81(3),%20530%E2%80%93533.%2010.1785/gssrl.81.3.530%20(2010)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR4">
<span class="label">4.</span><cite>Bhatt, R., Singh, S., Choudhary, P. &amp; Saini, M. An experimental study of the concept drift challenge in farm intrusion detection using audio. In <em>2022 18th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)</em>, pages 1–8. IEEE, (2022).</cite>
</li>
<li id="CR5">
<span class="label">5.</span><cite>Boll, S. Suppression of acoustic noise in speech using spectral subtraction. <em>IEEE Transactions on acoustics, speech, and signal processing</em><strong>27</strong>(2), 113–120 (1979).</cite> [<a href="https://scholar.google.com/scholar_lookup?Boll,%20S.%20Suppression%20of%20acoustic%20noise%20in%20speech%20using%20spectral%20subtraction.%20IEEE%20Transactions%20on%20acoustics,%20speech,%20and%20signal%20processing27(2),%20113%E2%80%93120%20(1979)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR6">
<span class="label">6.</span><cite>Borgnat, P., Flandrin, P., Honeine, P., Richard, C. &amp; Xiao, J. Testing stationarity with surrogates: A time-frequency approach. <em>IEEE Transactions on Signal Processing</em><strong>58</strong>(7), 3459–3470 (2010).</cite> [<a href="https://scholar.google.com/scholar_lookup?Borgnat,%20P.,%20Flandrin,%20P.,%20Honeine,%20P.,%20Richard,%20C.%20&amp;%20Xiao,%20J.%20Testing%20stationarity%20with%20surrogates:%20A%20time-frequency%20approach.%20IEEE%20Transactions%20on%20Signal%20Processing58(7),%203459%E2%80%933470%20(2010)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR7">
<span class="label">7.</span><cite>Boudraa, A.-O. &amp; Cexus, J.-C. Emd-based signal filtering. <em>IEEE transactions on instrumentation and measurement</em><strong>56</strong>(6), 2196–2202 (2007).</cite> [<a href="https://scholar.google.com/scholar_lookup?Boudraa,%20A.-O.%20&amp;%20Cexus,%20J.-C.%20Emd-based%20signal%20filtering.%20IEEE%20transactions%20on%20instrumentation%20and%20measurement56(6),%202196%E2%80%932202%20(2007)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR8">
<span class="label">8.</span><cite>Boudraa, A.-O. et al. Denoising via empirical mode decomposition. <em>Proc. IEEE ISCCSP</em><strong>4</strong>, 2006 (2006).</cite> [<a href="https://scholar.google.com/scholar_lookup?Boudraa,%20A.-O.%20et%20al.%20Denoising%20via%20empirical%20mode%20decomposition.%20Proc.%20IEEE%20ISCCSP4,%202006%20(2006)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR9">
<span class="label">9.</span><cite>Buccino, A. P. &amp; Einevoll, G. T. Mearec: a fast and customizable testbench simulator for ground-truth extracellular spiking activity. <em>Neuroinformatics</em><strong>19</strong>(1), 185–204 (2021).
</cite> [<a href="https://doi.org/10.1007/s12021-020-09467-7" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7782412/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32648042/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Buccino,%20A.%20P.%20&amp;%20Einevoll,%20G.%20T.%20Mearec:%20a%20fast%20and%20customizable%20testbench%20simulator%20for%20ground-truth%20extracellular%20spiking%20activity.%20Neuroinformatics19(1),%20185%E2%80%93204%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR10">
<span class="label">10.</span><cite>Buccino, A. P. et al. Spikeinterface, a unified framework for spike sorting. <em>Elife</em><strong>9</strong>, e61834 (2020).
</cite> [<a href="https://doi.org/10.7554/eLife.61834" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7704107/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33170122/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Buccino,%20A.%20P.%20et%20al.%20Spikeinterface,%20a%20unified%20framework%20for%20spike%20sorting.%20Elife9,%20e61834%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR11">
<span class="label">11.</span><cite>Chen, X., Wang, R., Khalilian-Gourtani, A., Yu, L., Dugan, P., Friedman, D., Doyle, W., Devinsky, O., Wang, Y. &amp; Flinker, A. A neural speech decoding framework leveraging deep learning and speech synthesis. <em>Nature Machine Intelligence</em>, pages 1–14, (2024).</cite>
</li>
<li id="CR12">
<span class="label">12.</span><cite>Defossez, A., Synnaeve, G. &amp; Adi, Y. Real time speech enhancement in the waveform domain, (2020). URL https://arxiv.org/abs/2006.12847.</cite>
</li>
<li id="CR13">
<span class="label">13.</span><cite>Donoho, D. L. &amp; Johnstone, I. M. Ideal spatial adaptation by wavelet shrinkage. <em>biometrika</em><strong>81</strong>(3), 425–455 (1994).</cite> [<a href="https://scholar.google.com/scholar_lookup?Donoho,%20D.%20L.%20&amp;%20Johnstone,%20I.%20M.%20Ideal%20spatial%20adaptation%20by%20wavelet%20shrinkage.%20biometrika81(3),%20425%E2%80%93455%20(1994)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR14">
<span class="label">14.</span><cite>Donoho, D. L., Johnstone, I. M., Kerkyacharian, G. &amp; Picard, D. Wavelet shrinkage: asymptopia?. <em>Journal of the Royal Statistical Society: Series B (Methodological)</em><strong>57</strong>(2), 301–337 (1995).</cite> [<a href="https://scholar.google.com/scholar_lookup?Donoho,%20D.%20L.,%20Johnstone,%20I.%20M.,%20Kerkyacharian,%20G.%20&amp;%20Picard,%20D.%20Wavelet%20shrinkage:%20asymptopia?.%20Journal%20of%20the%20Royal%20Statistical%20Society:%20Series%20B%20(Methodological)57(2),%20301%E2%80%93337%20(1995)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR15">
<span class="label">15.</span><cite>Earle, P. S. &amp; Shearer, P. M. Characterization of global seismograms using an automatic-picking algorithm. <em>Bulletin of the Seismological Society of America</em><strong>84</strong>(2), 366–376. 10.1785/BSSA0840020366 (1994).</cite> [<a href="https://scholar.google.com/scholar_lookup?Earle,%20P.%20S.%20&amp;%20Shearer,%20P.%20M.%20Characterization%20of%20global%20seismograms%20using%20an%20automatic-picking%20algorithm.%20Bulletin%20of%20the%20Seismological%20Society%20of%20America84(2),%20366%E2%80%93376.%2010.1785/BSSA0840020366%20(1994)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR16">
<span class="label">16.</span><cite>Ephraim, Y. &amp; Van Trees, H. A signal subspace approach for speech enhancement. <em>IEEE Transactions on Speech and Audio Processing</em><strong>3</strong>(4), 251–266. 10.1109/89.397090 (1995).</cite> [<a href="https://scholar.google.com/scholar_lookup?Ephraim,%20Y.%20&amp;%20Van%20Trees,%20H.%20A%20signal%20subspace%20approach%20for%20speech%20enhancement.%20IEEE%20Transactions%20on%20Speech%20and%20Audio%20Processing3(4),%20251%E2%80%93266.%2010.1109/89.397090%20(1995)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR17">
<span class="label">17.</span><cite>Fleishman, E. et al. Ecological inferences about marine mammals from passive acoustic data. <em>Biological Reviews</em><strong>98</strong>(5), 1633–1647 (2023).
</cite> [<a href="https://doi.org/10.1111/brv.12969" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37142263/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Fleishman,%20E.%20et%20al.%20Ecological%20inferences%20about%20marine%20mammals%20from%20passive%20acoustic%20data.%20Biological%20Reviews98(5),%201633%E2%80%931647%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR18">
<span class="label">18.</span><cite>Hao, X., Su, X., Wang, Z., Zhang, H. &amp; Unetgan, Batushiren. A robust speech enhancement approach in time domain for extremely low signal-to-noise ratio condition. In <em>Interspeech 2019</em>. ISCA, Sept. (2019). URL 10.21437/Interspeech.2019-1567.</cite>
</li>
<li id="CR19">
<span class="label">19.</span><cite>Hao, X., Su, X., Horaud, R. &amp; Li, X. Fullsubnet: A full-band and sub-band fusion model for real-time single-channel speech enhancement. In <em>ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>. IEEE, (June 2021). 10.1109/icassp39728.2021.9414177.</cite>
</li>
<li id="CR20">
<span class="label">20.</span><cite>Hu, Y. &amp; Loizou, P.C. A subspace approach for enhancing speech corrupted by colored noise. In <em>2002 IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, volume 1, pages I–573–I–576, (2002). 10.1109/ICASSP.2002.5743782.</cite>
</li>
<li id="CR21">
<span class="label">21.</span><cite>Hu, Y. &amp; Loizou, P. C. Evaluation of Objective Quality Measures for Speech Enhancement. <em>IEEE Transactions on Audio, Speech, and Language Processing</em><strong>16</strong>(1), 229–238. 10.1109/TASL.2007.911054 (2008).</cite> [<a href="https://scholar.google.com/scholar_lookup?Hu,%20Y.%20&amp;%20Loizou,%20P.%20C.%20Evaluation%20of%20Objective%20Quality%20Measures%20for%20Speech%20Enhancement.%20IEEE%20Transactions%20on%20Audio,%20Speech,%20and%20Language%20Processing16(1),%20229%E2%80%93238.%2010.1109/TASL.2007.911054%20(2008)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR22">
<span class="label">22.</span><cite>Injaian, A. S., Lane, E. D. &amp; Klinck, H. Aircraft events correspond with vocal behavior in a passerine. <em>Scientific Reports</em><strong>11</strong>(1), 1197 (2021).
</cite> [<a href="https://doi.org/10.1038/s41598-020-80380-4" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7806583/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33441920/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Injaian,%20A.%20S.,%20Lane,%20E.%20D.%20&amp;%20Klinck,%20H.%20Aircraft%20events%20correspond%20with%20vocal%20behavior%20in%20a%20passerine.%20Scientific%20Reports11(1),%201197%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR23">
<span class="label">23.</span><cite>International Telecommunication Union. P.56:Objective measurement of active speech level, (1993). URL <a href="https://www.itu.int/rec/T-REC-P.56" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.itu.int/rec/T-REC-P.56</a>.</cite>
</li>
<li id="CR24">
<span class="label">24.</span><cite>Jung, D.-H. et al. Deep learning-based cattle vocal classification model and real-time livestock monitoring system with noise filtering. <em>Animals</em><strong>11</strong>(2), 357 (2021).
</cite> [<a href="https://doi.org/10.3390/ani11020357" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7911430/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33535390/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Jung,%20D.-H.%20et%20al.%20Deep%20learning-based%20cattle%20vocal%20classification%20model%20and%20real-time%20livestock%20monitoring%20system%20with%20noise%20filtering.%20Animals11(2),%20357%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR25">
<span class="label">25.</span><cite>Lee, Y.-E., Kim, S.-H., Lee, S.-H., Lee, J.-S., Kim, S. &amp; Lee, S.-W. Speech synthesis from brain signals based on generative model. In <em>2023 11th International Winter Conference on Brain-Computer Interface (BCI)</em>, pages 1–4. IEEE, (2023a).</cite>
</li>
<li id="CR26">
<span class="label">26.</span><cite>Lee, Y.-E., Lee, S.-H., Kim, S.-H. &amp; Lee, S.-W. Towards voice reconstruction from eeg during imagined speech. <em>In Proceedings of the AAAI Conference on Artificial Intelligence</em><strong>37</strong>, 6030–6038 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Lee,%20Y.-E.,%20Lee,%20S.-H.,%20Kim,%20S.-H.%20&amp;%20Lee,%20S.-W.%20Towards%20voice%20reconstruction%20from%20eeg%20during%20imagined%20speech.%20In%20Proceedings%20of%20the%20AAAI%20Conference%20on%20Artificial%20Intelligence37,%206030%E2%80%936038%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR27">
<span class="label">27.</span><cite>Li, J.-H. et al. Multi-sensor fusion approach to drinking activity identification for improving fluid intake monitoring. <em>Applied Sciences</em><strong>14</strong>(11), 4480 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Li,%20J.-H.%20et%20al.%20Multi-sensor%20fusion%20approach%20to%20drinking%20activity%20identification%20for%20improving%20fluid%20intake%20monitoring.%20Applied%20Sciences14(11),%204480%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR28">
<span class="label">28.</span><cite>Li, N. &amp; Loizou, P. C. Factors influencing intelligibility of ideal binary-masked speech: Implications for noise reduction. <em>The Journal of the Acoustical Society of America</em><strong>123</strong>(3), 1673–1682 (2008).
</cite> [<a href="https://doi.org/10.1121/1.2832617" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC2696360/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/18345855/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Li,%20N.%20&amp;%20Loizou,%20P.%20C.%20Factors%20influencing%20intelligibility%20of%20ideal%20binary-masked%20speech:%20Implications%20for%20noise%20reduction.%20The%20Journal%20of%20the%20Acoustical%20Society%20of%20America123(3),%201673%E2%80%931682%20(2008)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR29">
<span class="label">29.</span><cite>Li, W. et al. Global-local-feature-fused driver speech emotion detection for intelligent cockpit in automated driving. <em>IEEE Transactions on Intelligent Vehicles</em><strong>8</strong>(4), 2684–2697 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Li,%20W.%20et%20al.%20Global-local-feature-fused%20driver%20speech%20emotion%20detection%20for%20intelligent%20cockpit%20in%20automated%20driving.%20IEEE%20Transactions%20on%20Intelligent%20Vehicles8(4),%202684%E2%80%932697%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR30">
<span class="label">30.</span><cite>Lim, J. &amp; Oppenheim, A. All-pole modeling of degraded speech. <em>IEEE Transactions on Acoustics, Speech, and Signal Processing</em><strong>26</strong>(3), 197–210. 10.1109/TASSP.1978.1163086 (1978).</cite> [<a href="https://scholar.google.com/scholar_lookup?Lim,%20J.%20&amp;%20Oppenheim,%20A.%20All-pole%20modeling%20of%20degraded%20speech.%20IEEE%20Transactions%20on%20Acoustics,%20Speech,%20and%20Signal%20Processing26(3),%20197%E2%80%93210.%2010.1109/TASSP.1978.1163086%20(1978)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR31">
<span class="label">31.</span><cite>Lim, J. S. <em>Two-Dimensional Signal and Image Processing</em> (Prentice Hall, 1990).</cite> [<a href="https://scholar.google.com/scholar_lookup?Lim,%20J.%20S.%20Two-Dimensional%20Signal%20and%20Image%20Processing%20(Prentice%20Hall,%201990)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR32">
<span class="label">32.</span><cite>Liu, Z. et al. Machine learning of transcripts and audio recordings of spontaneous speech for diagnosis of alzheimer’s disease. <em>Alzheimer’s &amp; Dementia</em><strong>17</strong>, e057556 (2021).</cite> [<a href="https://scholar.google.com/scholar_lookup?Liu,%20Z.%20et%20al.%20Machine%20learning%20of%20transcripts%20and%20audio%20recordings%20of%20spontaneous%20speech%20for%20diagnosis%20of%20alzheimer%E2%80%99s%20disease.%20Alzheimer%E2%80%99s%20&amp;%20Dementia17,%20e057556%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR33">
<span class="label">33.</span><cite>Loizou, P. <em>Speech Enhancement: Theory and Practice, Second Edition</em>. Taylor &amp; Francis, ISBN 9781466504219. (2013). URL <a href="https://books.google.co.il/books?id=ntXLfZkuGTwC" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://books.google.co.il/books?id=ntXLfZkuGTwC</a>.</cite>
</li>
<li id="CR34">
<span class="label">34.</span><cite>Loizou, P.C. NOIZEUS: Noisy speech corpus - Univ. Texas-Dallas, (2007). URL <a href="https://ecs.utdallas.edu/loizou/speech/noizeus/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://ecs.utdallas.edu/loizou/speech/noizeus/</a>.</cite>
</li>
<li id="CR35">
<span class="label">35.</span><cite>Lostanlen, V. et al. Per-channel energy normalization: Why and how. <em>IEEE Signal Processing Letters</em><strong>26</strong>(1), 39–43 (2018).</cite> [<a href="https://scholar.google.com/scholar_lookup?Lostanlen,%20V.%20et%20al.%20Per-channel%20energy%20normalization:%20Why%20and%20how.%20IEEE%20Signal%20Processing%20Letters26(1),%2039%E2%80%9343%20(2018)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR36">
<span class="label">36.</span><cite>Macartney, C. &amp; Weyde, T. Improved speech enhancement with the wave-u-net, (2018). URL https://arxiv.org/abs/1811.11307.</cite>
</li>
<li id="CR37">
<span class="label">37.</span><cite>Magland, J. et al. Spikeforest, reproducible web-facing ground-truth validation of automated neural spike sorters. <em>Elife</em><strong>9</strong>, e55167 (2020).
</cite> [<a href="https://doi.org/10.7554/eLife.55167" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7237210/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32427564/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Magland,%20J.%20et%20al.%20Spikeforest,%20reproducible%20web-facing%20ground-truth%20validation%20of%20automated%20neural%20spike%20sorters.%20Elife9,%20e55167%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR38">
<span class="label">38.</span><cite>Maher, S. P., Dawson, P. B., Hotovec-Ellis, A. J., Thelen, W. A. &amp; Matoza, R. S. Automated detection of volcanic seismicity using network covariance and image processing. <em>Seismological Research Letters</em><strong>95</strong>(5), 2580–2594 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Maher,%20S.%20P.,%20Dawson,%20P.%20B.,%20Hotovec-Ellis,%20A.%20J.,%20Thelen,%20W.%20A.%20&amp;%20Matoza,%20R.%20S.%20Automated%20detection%20of%20volcanic%20seismicity%20using%20network%20covariance%20and%20image%20processing.%20Seismological%20Research%20Letters95(5),%202580%E2%80%932594%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR39">
<span class="label">39.</span><cite>Mandala, S. et al. Enhanced myocardial infarction identification in phonocardiogram signals using segmented feature extraction and transfer learning-based classification. <em>IEEE Access</em><strong>11</strong>, 136654–136665 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Mandala,%20S.%20et%20al.%20Enhanced%20myocardial%20infarction%20identification%20in%20phonocardiogram%20signals%20using%20segmented%20feature%20extraction%20and%20transfer%20learning-based%20classification.%20IEEE%20Access11,%20136654%E2%80%93136665%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR40">
<span class="label">40.</span><cite>Mazzocconi, C., O’Brien, B. &amp; Chaminade, T. How do you laugh in an fmri scanner? laughter distribution, mimicry and acoustic analysis. In <em>Disfluency in Spontaneous Speech (DiSS) Workshop 2023</em>, (2023).</cite>
</li>
<li id="CR41">
<span class="label">41.</span><cite>McEwen, B. et al. Automatic noise reduction of extremely sparse vocalisations for bioacoustic monitoring. <em>Ecological Informatics</em><strong>77</strong>, 102280 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?McEwen,%20B.%20et%20al.%20Automatic%20noise%20reduction%20of%20extremely%20sparse%20vocalisations%20for%20bioacoustic%20monitoring.%20Ecological%20Informatics77,%20102280%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR42">
<span class="label">42.</span><cite>McGinn, K., Kahl, S., Peery, M. Z., Klinck, H. &amp; Wood, C. M. Feature embeddings from the birdnet algorithm provide insights into avian ecology. <em>Ecological Informatics</em><strong>74</strong>, 101995 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?McGinn,%20K.,%20Kahl,%20S.,%20Peery,%20M.%20Z.,%20Klinck,%20H.%20&amp;%20Wood,%20C.%20M.%20Feature%20embeddings%20from%20the%20birdnet%20algorithm%20provide%20insights%20into%20avian%20ecology.%20Ecological%20Informatics74,%20101995%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR43">
<span class="label">43.</span><cite>Megela Simmons, A., Simmons, J. A. &amp; Bates, M. E. Analyzing acoustic interactions in natural bullfrog (rana catesbeiana) choruses. <em>Journal of Comparative Psychology</em><strong>122</strong>(3), 274 (2008).
</cite> [<a href="https://doi.org/10.1037/0735-7036.122.3.274" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC2556862/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/18729655/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Megela%20Simmons,%20A.,%20Simmons,%20J.%20A.%20&amp;%20Bates,%20M.%20E.%20Analyzing%20acoustic%20interactions%20in%20natural%20bullfrog%20(rana%20catesbeiana)%20choruses.%20Journal%20of%20Comparative%20Psychology122(3),%20274%20(2008)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR44">
<span class="label">44.</span><cite>Mehrish, A., Majumder, N., Bharadwaj, R., Mihalcea, R. &amp; Poria, S. A review of deep learning techniques for speech processing. <em>Information Fusion</em><strong>99</strong>, 101869 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Mehrish,%20A.,%20Majumder,%20N.,%20Bharadwaj,%20R.,%20Mihalcea,%20R.%20&amp;%20Poria,%20S.%20A%20review%20of%20deep%20learning%20techniques%20for%20speech%20processing.%20Information%20Fusion99,%20101869%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR45">
<span class="label">45.</span><cite>Michaud, F., Sueur, J., Le Cesne, M. &amp; Haupert, S. Unsupervised classification to improve the quality of a bird song recording dataset. <em>Ecological Informatics</em><strong>74</strong>, 101952 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Michaud,%20F.,%20Sueur,%20J.,%20Le%20Cesne,%20M.%20&amp;%20Haupert,%20S.%20Unsupervised%20classification%20to%20improve%20the%20quality%20of%20a%20bird%20song%20recording%20dataset.%20Ecological%20Informatics74,%20101952%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR46">
<span class="label">46.</span><cite>Pascual, S., Bonafonte, A. &amp; Serrà, J. Segan: Speech enhancement generative adversarial network, (2017). URL https://arxiv.org/abs/1703.09452.</cite>
</li>
<li id="CR47">
<span class="label">47.</span><cite>Rix, A., Beerends, J., Hollier, M. &amp; Hekstra, A. Perceptual evaluation of speech quality (pesq)-a new method for speech quality assessment of telephone networks and codecs. In <em>2001 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.01CH37221)</em>, volume 2, pages 749–752 vol.2, (2001). 10.1109/ICASSP.2001.941023.</cite>
</li>
<li id="CR48">
<span class="label">48.</span><cite>Sainburg, T. &amp; Gentner, T. Q. Toward a computational neuroethology of vocal communication: from bioacoustics to neurophysiology, emerging tools and future directions. <em>Frontiers in Behavioral Neuroscience</em><strong>15</strong>, 811737 (2021).
</cite> [<a href="https://doi.org/10.3389/fnbeh.2021.811737" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8721140/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34987365/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Sainburg,%20T.%20&amp;%20Gentner,%20T.%20Q.%20Toward%20a%20computational%20neuroethology%20of%20vocal%20communication:%20from%20bioacoustics%20to%20neurophysiology,%20emerging%20tools%20and%20future%20directions.%20Frontiers%20in%20Behavioral%20Neuroscience15,%20811737%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR49">
<span class="label">49.</span><cite>Sainburg, T. &amp; Zorea, A. <em>Birdsong NOIZEUS: Bioacoustics noise reduction benchmark dataset</em>10.5281/zenodo.13947444 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Sainburg,%20T.%20&amp;%20Zorea,%20A.%20Birdsong%20NOIZEUS:%20Bioacoustics%20noise%20reduction%20benchmark%20dataset10.5281/zenodo.13947444%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR50">
<span class="label">50.</span><cite>Sainburg, T., Theilman, B., Thielk, M. &amp; Gentner, T. Q. Parallels in the sequential organization of birdsong and human speech. <em>Nature communications</em><strong>10</strong>(1), 3636 (2019).
</cite> [<a href="https://doi.org/10.1038/s41467-019-11605-y" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6690877/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31406118/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Sainburg,%20T.,%20Theilman,%20B.,%20Thielk,%20M.%20&amp;%20Gentner,%20T.%20Q.%20Parallels%20in%20the%20sequential%20organization%20of%20birdsong%20and%20human%20speech.%20Nature%20communications10(1),%203636%20(2019)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR51">
<span class="label">51.</span><cite>Sainburg, T., Thielk, M. &amp; Gentner, T. Q. Finding, visualizing, and quantifying latent structure across diverse animal vocal repertoires. <em>PLoS computational biology</em><strong>16</strong>(10), e1008228 (2020).
</cite> [<a href="https://doi.org/10.1371/journal.pcbi.1008228" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7591061/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33057332/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Sainburg,%20T.,%20Thielk,%20M.%20&amp;%20Gentner,%20T.%20Q.%20Finding,%20visualizing,%20and%20quantifying%20latent%20structure%20across%20diverse%20animal%20vocal%20repertoires.%20PLoS%20computational%20biology16(10),%20e1008228%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR52">
<span class="label">52.</span><cite>Savitzky, A. &amp; Golay, M. J. E. Smoothing and differentiation of data by simplified least squares procedures. <em>Analytical Chemistry</em><strong>36</strong>(8), 1627–1639. 10.1021/ac60214a047 (1964).</cite> [<a href="https://scholar.google.com/scholar_lookup?Savitzky,%20A.%20&amp;%20Golay,%20M.%20J.%20E.%20Smoothing%20and%20differentiation%20of%20data%20by%20simplified%20least%20squares%20procedures.%20Analytical%20Chemistry36(8),%201627%E2%80%931639.%2010.1021/ac60214a047%20(1964)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR53">
<span class="label">53.</span><cite>Scheibler, R., Bezzam, E. &amp; Dokmanić, I. Pyroomacoustics: A python package for audio room simulation and array processing algorithms. In <em>2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)</em>, pages 351–355. IEEE, (2018).</cite>
</li>
<li id="CR54">
<span class="label">54.</span><cite>Soni, MH., Shah, N. &amp; Patil, HA. Time-frequency masking-based speech enhancement using generative adversarial network. In <em>2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)</em>, pages 5039–5043. IEEE, (2018).</cite>
</li>
<li id="CR55">
<span class="label">55.</span><cite>Spiller, M., Esmaeili, N., Sühn, T., Boese, A., Turial, S., Gumbs, AA., Croner, R., Friebe, M. &amp; Illanes, A. Enhancing veress needle entry with proximal vibroacoustic sensing for automatic identification of peritoneum puncture. <em>Diagnostics</em>, 14 (15), (2024).</cite> [<a href="https://doi.org/10.3390/diagnostics14151698" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11311580/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39125574/" class="usa-link">PubMed</a>]</li>
<li id="CR56">
<span class="label">56.</span><cite>Steinmetz, C.J. &amp; Reiss, J. pyloudnorm: A simple yet flexible loudness meter in python. In <em>Audio Engineering Society Convention 150</em>. Audio Engineering Society, (2021).</cite>
</li>
<li id="CR57">
<span class="label">57.</span><cite>Taal, C.H., Hendriks, R.C., Heusdens, R. &amp; Jensen, J. A short-time objective intelligibility measure for time-frequency weighted noisy speech. In <em>2010 IEEE International Conference on Acoustics, Speech and Signal Processing</em>, pages 4214–4217, (Mar. 2010). 10.1109/ICASSP.2010.5495701. URL <a href="https://ieeexplore.ieee.org/abstract/document/5495701" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://ieeexplore.ieee.org/abstract/document/5495701</a>. ISSN: 2379-190X.</cite>
</li>
<li id="CR58">
<span class="label">58.</span><cite>Taha, T. M., Adeel, A. &amp; Hussain, A. A survey on techniques for enhancing speech. <em>International Journal of Computer Applications</em><strong>179</strong>(17), 1–14 (2018).</cite> [<a href="https://scholar.google.com/scholar_lookup?Taha,%20T.%20M.,%20Adeel,%20A.%20&amp;%20Hussain,%20A.%20A%20survey%20on%20techniques%20for%20enhancing%20speech.%20International%20Journal%20of%20Computer%20Applications179(17),%201%E2%80%9314%20(2018)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR59">
<span class="label">59.</span><cite>Trnkoczy, A. Understanding and parameter setting of sta/lta trigger algorithm. In P. Bormann, editor, <em>New Manual of Seismological Observatory Practice 2 (NMSOP-2)</em>. Deutsches GeoForschungsZentrum GFZ, (2009) 10.2312/GFZ.NMSOP-2_IS_8.1.</cite>
</li>
<li id="CR60">
<span class="label">60.</span><cite>Upadhyay, N. &amp; Karmakar, A. Spectral subtractive-type algorithms for enhancement of noisy speech: an integrative review. <em>International Journal of Image, Graphics and Signal Processing</em><strong>5</strong>(11), 13 (2013).</cite> [<a href="https://scholar.google.com/scholar_lookup?Upadhyay,%20N.%20&amp;%20Karmakar,%20A.%20Spectral%20subtractive-type%20algorithms%20for%20enhancement%20of%20noisy%20speech:%20an%20integrative%20review.%20International%20Journal%20of%20Image,%20Graphics%20and%20Signal%20Processing5(11),%2013%20(2013)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR61">
<span class="label">61.</span><cite>Vellinga, W. Xeno-canto - soundscapes from around the world10.15468/9u3zaq, (2024). Occurrence dataset accessed via GBIF.org on 2024-10-17.</cite>
</li>
<li id="CR62">
<span class="label">62.</span><cite>Virtanen, P. et al. Scipy 1.0: fundamental algorithms for scientific computing in python. <em>Nature methods</em><strong>17</strong>(3), 261–272 (2020).
</cite> [<a href="https://doi.org/10.1038/s41592-019-0686-2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7056644/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32015543/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Virtanen,%20P.%20et%20al.%20Scipy%201.0:%20fundamental%20algorithms%20for%20scientific%20computing%20in%20python.%20Nature%20methods17(3),%20261%E2%80%93272%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR63">
<span class="label">63.</span><cite>Weber, M. &amp; Davis, J. P. Evidence of a laterally variable lower mantle structure from P- and S-waves. <em>Geophysical Journal International</em><strong>102</strong>(1), 231–255. 10.1111/j.1365-246X.1990.tb00544.x (1990).</cite> [<a href="https://scholar.google.com/scholar_lookup?Weber,%20M.%20&amp;%20Davis,%20J.%20P.%20Evidence%20of%20a%20laterally%20variable%20lower%20mantle%20structure%20from%20P-%20and%20S-waves.%20Geophysical%20Journal%20International102(1),%20231%E2%80%93255.%2010.1111/j.1365-246X.1990.tb00544.x%20(1990)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR64">
<span class="label">64.</span><cite>Xie, J., Colonna, J. G. &amp; Zhang, J. Bioacoustic signal denoising: a review. <em>Artificial Intelligence Review</em><strong>54</strong>, 3575–3597 (2021).</cite> [<a href="https://scholar.google.com/scholar_lookup?Xie,%20J.,%20Colonna,%20J.%20G.%20&amp;%20Zhang,%20J.%20Bioacoustic%20signal%20denoising:%20a%20review.%20Artificial%20Intelligence%20Review54,%203575%E2%80%933597%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR65">
<span class="label">65.</span><cite>Hu, Yi, &amp; Loizou, P. Subjective Comparison of Speech Enhancement Algorithms. In <em>2006 IEEE International Conference on Acoustics Speed and Signal Processing Proceedings</em>, volume 1, pages I–153–I–156, Toulouse, France, (2006). IEEE. ISBN 9781424404698. 10.1109/ICASSP.2006.1659980. URL <a href="http://ieeexplore.ieee.org/document/1659980/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://ieeexplore.ieee.org/document/1659980/</a>.</cite>
</li>
<li id="CR66">
<span class="label">66.</span><cite>Zheng, N. &amp; Zhang, X.-L. Phase-aware speech enhancement based on deep neural networks. <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em><strong>27</strong>(1), 63–76. 10.1109/TASLP.2018.2870742 (2019).</cite> [<a href="https://scholar.google.com/scholar_lookup?Zheng,%20N.%20&amp;%20Zhang,%20X.-L.%20Phase-aware%20speech%20enhancement%20based%20on%20deep%20neural%20networks.%20IEEE/ACM%20Transactions%20on%20Audio,%20Speech,%20and%20Language%20Processing27(1),%2063%E2%80%9376.%2010.1109/TASLP.2018.2870742%20(2019)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR67">
<span class="label">67.</span><cite>Zhu, W., Mousavi, S. M. &amp; Beroza, G. C. Seismic signal denoising and decomposition using deep neural networks. <em>IEEE Transactions on Geoscience and Remote Sensing</em><strong>57</strong>(11), 9476–9488. 10.1109/TGRS.2019.2926772 (2019).</cite> [<a href="https://scholar.google.com/scholar_lookup?Zhu,%20W.,%20Mousavi,%20S.%20M.%20&amp;%20Beroza,%20G.%20C.%20Seismic%20signal%20denoising%20and%20decomposition%20using%20deep%20neural%20networks.%20IEEE%20Transactions%20on%20Geoscience%20and%20Remote%20Sensing57(11),%209476%E2%80%939488.%2010.1109/TGRS.2019.2926772%20(2019)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR68">
<span class="label">68.</span><cite>Zhu, Y., Smith, A. &amp; Hauser, K. Automated heart and lung auscultation in robotic physical examinations. <em>IEEE Robotics and Automation Letters</em><strong>7</strong>(2), 4204–4211 (2022).</cite> [<a href="https://scholar.google.com/scholar_lookup?Zhu,%20Y.,%20Smith,%20A.%20&amp;%20Hauser,%20K.%20Automated%20heart%20and%20lung%20auscultation%20in%20robotic%20physical%20examinations.%20IEEE%20Robotics%20and%20Automation%20Letters7(2),%204204%E2%80%934211%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adda93_" lang="en" class="data-availability-statement"><h3 class="pmc_sec_title">Data Availability Statement</h3>
<p>The Birdsong NOIZEUS dataset was generated for this publication. It is available at https://zenodo.org/records/13947444</p>
<p>The implementation of the Noisereduce algorithm is available at: <a href="https://github.com/timsainb/noisereduce" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/timsainb/noisereduce</a>. A future version of this software may be migrated to <a href="https://github.com/noisereduce/noisereduce" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/noisereduce/noisereduce</a>. The experimental results, including all necessary configuration files and scripts for reproducing the experiments, are provided at: <a href="https://github.com/noisereduce/paper_noisereduce" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/noisereduce/paper_noisereduce</a>.</p></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from Scientific Reports are provided here courtesy of <strong>Nature Publishing Group</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1038/s41598-025-13108-x"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/41598_2025_Article_13108.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (6.3 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12373731/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12373731/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12373731%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373731/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12373731/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12373731/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40847024/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12373731/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40847024/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12373731/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12373731/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="BkhW8Xt1yqNv28dU1WtytxWYrwi3U3rNvIafzwu7QXTmIsRNB1W1nWNmfYGoQbfR">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
    

    </body>
</html>
