
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            The potential of generative AI with prostate-specific membrane antigen (PSMA) PET/CT: challenges and future directions - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="AE532CF78AF1FC13052CF7001C9C4604.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="medrev">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12362063/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="Medical Review">
<meta name="citation_title" content="The potential of generative AI with prostate-specific membrane antigen (PSMA) PET/CT: challenges and future directions">
<meta name="citation_author" content="Md Zobaer Islam">
<meta name="citation_author_institution" content="Department of Radiology, University of North Carolina, Chapel Hill, NC, USA">
<meta name="citation_author_institution" content="Biomedical Research Imaging Center, University of North Carolina, Chapel Hill, NC, USA">
<meta name="citation_author" content="Ergi Spiro">
<meta name="citation_author_institution" content="The Center for Cognitive Neuroscience, Duke Institute for Brain Sciences, Durham, NC, USA">
<meta name="citation_author" content="Pew-Thian Yap">
<meta name="citation_author_institution" content="Department of Radiology, University of North Carolina, Chapel Hill, NC, USA">
<meta name="citation_author_institution" content="Biomedical Research Imaging Center, University of North Carolina, Chapel Hill, NC, USA">
<meta name="citation_author" content="Michael A Gorin">
<meta name="citation_author_institution" content="Department of Urology, Icahn School of Medicine at Mount Sinai, New York, NY, USA">
<meta name="citation_author" content="Steven P Rowe">
<meta name="citation_author_institution" content="Department of Radiology, University of North Carolina, Chapel Hill, NC, USA">
<meta name="citation_publication_date" content="2025 Jan 24">
<meta name="citation_volume" content="5">
<meta name="citation_issue" content="4">
<meta name="citation_firstpage" content="265">
<meta name="citation_doi" content="10.1515/mr-2024-0086">
<meta name="citation_pmid" content="40838104">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12362063/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12362063/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12362063/pdf/mr-5-4-mr-2024-0086.pdf">
<meta name="description" content="The diagnosis and prognosis of Prostate cancer (PCa) have undergone a significant transformation with the advent of prostate-specific membrane antigen (PSMA)-targeted positron emission tomography (PET) imaging. PSMA-PET imaging has demonstrated ...">
<meta name="og:title" content="The potential of generative AI with prostate-specific membrane antigen (PSMA) PET/CT: challenges and future directions">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="The diagnosis and prognosis of Prostate cancer (PCa) have undergone a significant transformation with the advent of prostate-specific membrane antigen (PSMA)-targeted positron emission tomography (PET) imaging. PSMA-PET imaging has demonstrated ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12362063/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12362063">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1515/mr-2024-0086"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/mr-5-4-mr-2024-0086.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12362063%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12362063/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12362063/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12362063/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-medrev.png" alt="Medical Review logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to Medical Review" title="Link to Medical Review" shape="default" href="https://www.degruyter.com/journal/key/mr/html" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">Med Rev (2021)</button></div>. 2025 Jan 24;5(4):265–276. doi: <a href="https://doi.org/10.1515/mr-2024-0086" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1515/mr-2024-0086</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22Med%20Rev%20(2021)%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Med%20Rev%20(2021)%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22Med%20Rev%20(2021)%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22Med%20Rev%20(2021)%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>The potential of generative AI with prostate-specific membrane antigen (PSMA) PET/CT: challenges and future directions</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Islam%20MZ%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Md Zobaer Islam</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Md Zobaer Islam</span></h3>
<div class="p">
<sup>1</sup>
Department of Radiology, University of North Carolina, Chapel Hill, NC, USA
</div>
<div class="p">
<sup>2</sup>
Biomedical Research Imaging Center, University of North Carolina, Chapel Hill, NC, USA
</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Islam%20MZ%22%5BAuthor%5D" class="usa-link"><span class="name western">Md Zobaer Islam</span></a>
</div>
</div>
<sup>1,</sup><sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Spiro%20E%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Ergi Spiro</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">Ergi Spiro</span></h3>
<div class="p">
<sup>3</sup>
The Center for Cognitive Neuroscience, Duke Institute for Brain Sciences, Durham, NC, USA
</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Spiro%20E%22%5BAuthor%5D" class="usa-link"><span class="name western">Ergi Spiro</span></a>
</div>
</div>
<sup>3</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Yap%20PT%22%5BAuthor%5D" class="usa-link" aria-describedby="id3"><span class="name western">Pew-Thian Yap</span></a><div hidden="hidden" id="id3">
<h3><span class="name western">Pew-Thian Yap</span></h3>
<div class="p">
<sup>1</sup>
Department of Radiology, University of North Carolina, Chapel Hill, NC, USA
</div>
<div class="p">
<sup>2</sup>
Biomedical Research Imaging Center, University of North Carolina, Chapel Hill, NC, USA
</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Yap%20PT%22%5BAuthor%5D" class="usa-link"><span class="name western">Pew-Thian Yap</span></a>
</div>
</div>
<sup>1,</sup><sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Gorin%20MA%22%5BAuthor%5D" class="usa-link" aria-describedby="id4"><span class="name western">Michael A Gorin</span></a><div hidden="hidden" id="id4">
<h3><span class="name western">Michael A Gorin</span></h3>
<div class="p">
<sup>4</sup>
Department of Urology, Icahn School of Medicine at Mount Sinai, New York, NY, USA
</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Gorin%20MA%22%5BAuthor%5D" class="usa-link"><span class="name western">Michael A Gorin</span></a>
</div>
</div>
<sup>4</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Rowe%20SP%22%5BAuthor%5D" class="usa-link" aria-describedby="id5"><span class="name western">Steven P Rowe</span></a><div hidden="hidden" id="id5">
<h3><span class="name western">Steven P Rowe</span></h3>
<div class="p">
<sup>1</sup>
Department of Radiology, University of North Carolina, Chapel Hill, NC, USA
</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Rowe%20SP%22%5BAuthor%5D" class="usa-link"><span class="name western">Steven P Rowe</span></a>
</div>
</div>
<sup>1,</sup><sup>✉</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="j_mr-2024-0086_aff_001">
<sup>1</sup>
Department of Radiology, University of North Carolina, Chapel Hill, NC, USA
</div>
<div id="j_mr-2024-0086_aff_002">
<sup>2</sup>
Biomedical Research Imaging Center, University of North Carolina, Chapel Hill, NC, USA
</div>
<div id="j_mr-2024-0086_aff_003">
<sup>3</sup>
The Center for Cognitive Neuroscience, Duke Institute for Brain Sciences, Durham, NC, USA
</div>
<div id="j_mr-2024-0086_aff_004">
<sup>4</sup>
Department of Urology, Icahn School of Medicine at Mount Sinai, New York, NY, USA
</div>
<div class="author-notes p">
<div class="fn" id="cor1">
<sup>✉</sup><p class="display-inline">
<strong>Corresponding author: Steven P. Rowe</strong>, Molecular Imaging and Therapeutics, Department of Radiology, University of North Carolina, Chapel Hill, NC, USA, E-mail: <span>steven_rowe@med.unc.edu</span>
</p>
</div>
<div class="fn" id="_fncrsp93pmc__">
<sup>✉</sup><p class="display-inline">Corresponding author.</p>
</div>
</div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2024 Oct 26; Accepted 2025 Jan 13; Collection date 2025 Aug.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© 2025 the author(s), published by De Gruyter, Berlin/Boston</div>
<p>This work is licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12362063  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40838104/" class="usa-link">40838104</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="abstract1"><h2>Abstract</h2>
<p>The diagnosis and prognosis of Prostate cancer (PCa) have undergone a significant transformation with the advent of prostate-specific membrane antigen (PSMA)-targeted positron emission tomography (PET) imaging. PSMA-PET imaging has demonstrated superior performance compared to conventional imaging methods by detecting PCa, its biochemical recurrence, and sites of metastasis with higher sensitivity and specificity. That transformation now intersects with rapid advances in artificial intelligence (AI) – including the emergence of generative AI. However, there are unique clinical challenges associated with PSMA-PET imaging that still need to be addressed to ensure its continued widespread integration into clinical care and research trials. Some of those challenges are the very wide dynamic range of lesion uptake, benign uptake in organs that may be adjacent to sites of disease, insufficient large datasets for training AI models, as well as artifacts in the images. Generative AI models, e.g., generative adversarial networks, variational autoencoders, diffusion models, and large language models have played crucial roles in overcoming many such challenges across various imaging modalities, including PET, computed tomography, magnetic resonance imaging, ultrasound, etc. In this review article, we delve into the potential role of generative AI in enhancing the robustness and widespread utilization of PSMA-PET imaging and image analysis, drawing insights from existing literature while also exploring current limitations and future directions in this domain.</p>
<section id="kwd-group1" class="kwd-group"><p><strong>Keywords:</strong> generative AI, molecular imaging; prostate-specific membrane antigen-targeted positron emission tomography</p></section></section><section id="j_mr-2024-0086_s_001"><h2 class="pmc_sec_title">Summary</h2>
<p>Generative AI techniques show promise in addressing clinical challenges in PSMA-PET imaging for prostate cancer, enhancing image quality, automating lesion detection and segmentation, and aiding radiologists in improving diagnosis and prognosis.</p></section><section id="j_mr-2024-0086_s_002"><h2 class="pmc_sec_title">Essentials</h2>
<ul id="j_mr-2024-0086_list_001" class="list" style="list-style-type:none">
<li id="j_mr-2024-0086_li_001">
<span class="label">1)</span><p class="display-inline">Prostate-specific membrane antigen (PSMA)-targeted positron emission tomography (PET) imaging significantly advances prostate cancer detection and management but faces numerous clinical challenges such as dynamic lesion uptake ranges, benign uptake issues, limited datasets, and image artifacts.</p>
</li>
<li id="j_mr-2024-0086_li_002">
<span class="label">2)</span><p class="display-inline">Generative artificial intelligence (AI) models have already demonstrated their value in performing tasks like image enhancement, lesion detection, segmentation, and data augmentation in medical imaging.</p>
</li>
<li id="j_mr-2024-0086_li_003">
<span class="label">3)</span><p class="display-inline">The application of generative AI in PSMA-PET imaging is still in its infancy but shows potential to address its clinical challenges by generating synthetic training images, improving image quality, automating lesion analysis, and mitigating artifacts.</p>
</li>
</ul></section><section id="j_mr-2024-0086_s_003"><h2 class="pmc_sec_title">Introduction</h2>
<p>The introduction of small-molecule positron emission tomography (PET) radiotracers targeted against prostate-specific membrane antigen (PSMA) initiated a radical change in the way men with prostate cancer (PCa) are staged, re-staged, and treated [<a href="#j_mr-2024-0086_ref_001" class="usa-link" aria-describedby="j_mr-2024-0086_ref_001">1</a>], [<a href="#j_mr-2024-0086_ref_002" class="usa-link" aria-describedby="j_mr-2024-0086_ref_002">2</a>]. PSMA is a transmembrane glycoprotein that is expressed in approximately 95% of PCa tumors [<a href="#j_mr-2024-0086_ref_003" class="usa-link" aria-describedby="j_mr-2024-0086_ref_003">3</a>]. Pivotal clinical trials have demonstrated the utility of PSMA radioligands in evaluating men with newly diagnosed PCa with high- or very-high-risk disease [<a href="#j_mr-2024-0086_ref_004" class="usa-link" aria-describedby="j_mr-2024-0086_ref_004">4</a>] and men with evidence of biochemical recurrence (BCR) on the basis of a rising prostate-specific antigen (PSA) level [<a href="#j_mr-2024-0086_ref_005" class="usa-link" aria-describedby="j_mr-2024-0086_ref_005">5</a>]. PSMA-PET imaging also holds promise for other indications, including patient selection for PSMA-targeted radioligand therapy [<a href="#j_mr-2024-0086_ref_006" class="usa-link" aria-describedby="j_mr-2024-0086_ref_006">6</a>] and identification of individuals with oligometastatic disease who may benefit from metastasis-directed therapy [<a href="#j_mr-2024-0086_ref_007" class="usa-link" aria-describedby="j_mr-2024-0086_ref_007">7</a>]. As research progresses, new applications for PSMA-targeted PET are likely to emerge.</p>
<p>However, the integration of targeted radiotracers like PSMA-PET into clinical practice presents unique challenges, including a wide dynamic range in lesion uptake, variability in lesion morphology, heterogeneity in image quality, and the intricate interplay between PSMA expression levels, initiation of androgen-axis-targeted therapies, and determination of progression of disease. The intersection of targeted radiotracers and artificial intelligence (AI) has been proposed as a potential solution, leveraging AI algorithms to enhance imaging quality, automate lesion detection, segmentation, and characterization, and facilitate PCa staging, restaging, and metastasis detection [<a href="#j_mr-2024-0086_ref_008" class="usa-link" aria-describedby="j_mr-2024-0086_ref_008">8</a>], [<a href="#j_mr-2024-0086_ref_009" class="usa-link" aria-describedby="j_mr-2024-0086_ref_009">9</a>], [<a href="#j_mr-2024-0086_ref_010" class="usa-link" aria-describedby="j_mr-2024-0086_ref_010">10</a>], [<a href="#j_mr-2024-0086_ref_011" class="usa-link" aria-describedby="j_mr-2024-0086_ref_011">11</a>]. Nonetheless, conventional AI approaches are constrained by their dependency on large, labeled datasets and predefined features, limiting their ability to address the challenges associated with PSMA-PET.</p>
<p>Generative AI offers a transformative alternative by overcoming several limitations inherent in conventional AI methods. Generative AI models, such as generative adversarial networks (GAN), variational autoencoders (VAEs), diffusion models, and large language models (LLM) possess the capability to generate synthetic data that closely resemble real-world objects. That ability is especially pertinent in PSMA-PET imaging, where labeled datasets may be scarce and difficult to generate, and variability among patient populations can pose challenges. In this manuscript, we will delve into the application of generative AI in diagnostic imaging and discuss its potential applications in PSMA-PET imaging, focusing on the ability to identify, automatically segment, and characterize individual lesions, as well as provide comprehensive tumor burden assessment and prognostication.</p>
<section id="j_mr-2024-0086_s_003_s_001"><h3 class="pmc_sec_title">Challenges in PSMA-PET imaging</h3>
<p>One of the prime clinical challenges associated with PSMA-PET imaging for PCa is the wide dynamic range of PSMA uptakes in lesions. PSMA expressions can vary among different lesions and within the same lesion. This variability can lead to limitations in accurately detecting and characterizing lesions. In advanced, metastatic castration-resistant prostate cancer (mCRPC), some metastatic lesions may have low PSMA expression. Additionally, in some cases with early-stage or low-volume disease, lesions may be missed, leading to <em>false-negative</em> results [<a href="#j_mr-2024-0086_ref_012" class="usa-link" aria-describedby="j_mr-2024-0086_ref_012">12</a>]. Overall, true-positive lesions can vary in their extent of uptake from barely perceptible above background [<a href="#j_mr-2024-0086_ref_013" class="usa-link" aria-describedby="j_mr-2024-0086_ref_013">13</a>] to having maximum standardized uptake values (SUV<sub>max</sub>) greater than 100 (i.e. approximately 4 orders of magnitude of radioactivity concentration) [<a href="#j_mr-2024-0086_ref_014" class="usa-link" aria-describedby="j_mr-2024-0086_ref_014">14</a>] (<a href="#j_mr-2024-0086_fig_001" class="usa-link">Figure 1</a>). As such, typical methods for whole-body tumor segmentation will tend to be either overly specific for high-uptake lesions and will miss subtle findings – or will be overly sensitive for subtle sites of uptake and will include regions of confluent noise or non-specific uptake.</p>
<figure class="fig xbox font-sm" id="j_mr-2024-0086_fig_001"><h4 class="obj_head">Figure 1:</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12362063_j_mr-2024-0086_fig_001.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2d5d/12362063/3366a98ee13a/j_mr-2024-0086_fig_001.jpg" loading="lazy" height="290" width="664" alt="Figure 1:"></a></p>
<div class="p text-right font-secondary"><a href="figure/j_mr-2024-0086_fig_001/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Demonstration of the wide dynamic range of PSMA PET uptake in two men with anatomically similar findings. (A) Fused PSMA PET/CT image from an 81-year-old man presenting for initial staging with Gleason 4+5 = 9 grade group 5 prostate cancer with serum PSA 3.6. (B) Fused PSMA PET/CT from a 73-year-old man who was found to have a serum PSA of 62.1 and then underwent a prostate biopsy that demonstrated Gleason 5+4 = 9, grade group 5 prostate cancer. Note the significant differences in uptake in metastatic left peri-aortic lymph nodes (arrows), especially in comparison to other areas of normal uptake on the images. PSMA, prostate-specific membrane antigen; PET, positron emission tomography; CT, computed tomography.</p></figcaption></figure><p>Distinguishing between benign and malignant lesions solely based on PSMA uptake can be challenging as well, especially in regions with physiological PSMA expression, such as the urinary bladder and kidneys. This can result in <em>false-positive</em> findings and unnecessary interventions or treatments [<a href="#j_mr-2024-0086_ref_012" class="usa-link" aria-describedby="j_mr-2024-0086_ref_012">12</a>]. In the context of existing phase II prospective data on the deleterious effects of leaving any true-positive lesions untreated, the definitive characterization of potential false-positive lesions is of paramount importance to avoid unnecessarily aggressive treatment plans [<a href="#j_mr-2024-0086_ref_007" class="usa-link" aria-describedby="j_mr-2024-0086_ref_007">7</a>]. However, definitive characterization often belies the radiologist’s interpretation as some types of lesions may be uncommonly true-positive [<a href="#j_mr-2024-0086_ref_015" class="usa-link" aria-describedby="j_mr-2024-0086_ref_015">15</a>].</p>
<p>While PSMA PET imaging is highly sensitive relative to conventional imaging in detecting BCR (rising PSA levels) after primary treatment, its performance may decrease at very low PSA levels [<a href="#j_mr-2024-0086_ref_005" class="usa-link" aria-describedby="j_mr-2024-0086_ref_005">5</a>]. This can limit its effectiveness in detecting recurrent disease in patients with minimal PSA elevation, potentially leading to <em>false-negative</em> results, as everything from the reconstruction algorithm to the imaging time can affect lesion detectability [<a href="#j_mr-2024-0086_ref_016" class="usa-link" aria-describedby="j_mr-2024-0086_ref_016">16</a>], [<a href="#j_mr-2024-0086_ref_017" class="usa-link" aria-describedby="j_mr-2024-0086_ref_017">17</a>].</p>
<p>Different PSMA-targeted PET tracers, i.e., <sup>68</sup>Ga- and <sup>18</sup>F-labeled tracers, introduce further challenges due to their distinct physiological uptake patterns and biodistributions. For instance, some of the recently introduced <sup>18</sup>F-labeled radiotracers can exhibit higher liver uptake, which may impact lesion detectability in mCRPC patients and also tend to lead to higher rates of non-specific uptake in non-cancer bone lesions [<a href="#j_mr-2024-0086_ref_018" class="usa-link" aria-describedby="j_mr-2024-0086_ref_018">18</a>]. Similarly, the available <sup>68</sup>Ga-labeled tracers demonstrate higher excretion into the urinary bladder, which can complicate uptake interpretation during primary staging or BCR [<a href="#j_mr-2024-0086_ref_019" class="usa-link" aria-describedby="j_mr-2024-0086_ref_019">19</a>], [<a href="#j_mr-2024-0086_ref_020" class="usa-link" aria-describedby="j_mr-2024-0086_ref_020">20</a>] . Those differences also result in varying distributions of false-positive lesions, such as in the skeleton, due to differences in radiotracer kinetics and off-target binding potential [<a href="#j_mr-2024-0086_ref_021" class="usa-link" aria-describedby="j_mr-2024-0086_ref_021">21</a>]. Consequently, AI models trained on data from one type of PSMA-targeted tracer may not generalize well to another tracer data without further adaptation. However, we should also bear in mind that many aspects of radiotracer distribution may still have commonalities (such as the locations of normal organs), potentially still allowing for significant overlap of data from different radiotracers and the effective use of transfer learning in this context [<a href="#j_mr-2024-0086_ref_022" class="usa-link" aria-describedby="j_mr-2024-0086_ref_022">22</a>].</p>
<p>Limited access to large-scale datasets containing annotated PSMA-PET images compared to other modalities makes it challenging to train robust deep-learning models for image analysis and decision-making. Moreover, PCa is a heterogeneous disease, exhibiting variability in tumor characteristics, morphology, and biological behavior [<a href="#j_mr-2024-0086_ref_023" class="usa-link" aria-describedby="j_mr-2024-0086_ref_023">23</a>]. Further, in current academic radiology, leadership decisions are often driven by productivity measures such as relative-value units (RVU), which quantify the value of medical services based on factors like time, expertise, and resources. These measures prioritize clinical productivity over tasks like detailed image annotation. As a result, sub-specialty trained radiologists and nuclear medicine physicians frequently face significant time constraints, creating an acute need for innovative solutions [<a href="#j_mr-2024-0086_ref_024" class="usa-link" aria-describedby="j_mr-2024-0086_ref_024">24</a>].</p>
<p>PSMA-PET images may not provide detailed-enough anatomic information of the patient, which is essential for accurate diagnosis and lesion localization [<a href="#j_mr-2024-0086_ref_023" class="usa-link" aria-describedby="j_mr-2024-0086_ref_023">23</a>], [<a href="#j_mr-2024-0086_ref_025" class="usa-link" aria-describedby="j_mr-2024-0086_ref_025">25</a>]. That dependency on additional imaging modalities such as diagnostic computed tomography (CT) or magnetic resonance imaging (MRI) presents significant challenges in accurately assessing and localizing abnormalities.</p>
<p>Noise and motion artifacts from different sources can affect PSMA-PET imaging quality, impacting the accuracy and reliability of diagnostic interpretation. Noise, stemming from factors such as lower injected radiation dose, reduced scan time, and scatter or attenuation from tissue can degrade image clarity and reduce the signal-to-noise ratio [<a href="#j_mr-2024-0086_ref_026" class="usa-link" aria-describedby="j_mr-2024-0086_ref_026">26</a>]. Given that primary tumors, local recurrences, and pelvic nodal involvement will often be in the same plane as the urinary bladder, scatter over-correction artifacts may be particularly bothersome to the interpreting physician [<a href="#j_mr-2024-0086_ref_027" class="usa-link" aria-describedby="j_mr-2024-0086_ref_027">27</a>]. Similarly, motion artifacts, caused by patient movements or physiological processes like respiratory or cardiac motion, can lead to blurring or misregistration of image structures [<a href="#j_mr-2024-0086_ref_028" class="usa-link" aria-describedby="j_mr-2024-0086_ref_028">28</a>].</p>
<p>Additionally, there is currently no consensus on the optimal threshold for segmenting metastatic lesions in PSMA-PET imaging. Commonly used approaches include relative thresholds like a percentage of SUV<sub>max</sub>, fixed thresholds, or pre-defined reference organ thresholds, such as the liver or spleen [<a href="#j_mr-2024-0086_ref_029" class="usa-link" aria-describedby="j_mr-2024-0086_ref_029">29</a>]. The choice of threshold can significantly affect lesion delineation and, consequently, the reliability of AI-based lesion detection and characterization. Moreover, conventional semi-automatic or threshold-based methods for tumor burden evaluation in mCRPC patients under RLT therapy are time-consuming and prone to inaccuracies. For example, para-aortic lymph node metastases located near physiological bowel activity often result in false positives, requiring labor-intensive manual corrections. Further, even in the context of primary PCa, where cubic-millimeter-level volumetric validation of tumors is possible, there seems to be significant interpatient variability in the most accurate segmentation method. That raises significant concerns that almost no segmentation method will have the widespread applicability to adequately delineate metastatic disease volumetrically. Instead, we suggest that the focus should be on the test-retest repeatability of tumor segmentations in the context of there being no ground-state truth of tumor volume (<a href="#j_mr-2024-0086_fig_002" class="usa-link">Figure 2</a>).</p>
<figure class="fig xbox font-sm" id="j_mr-2024-0086_fig_002"><h4 class="obj_head">Figure 2:</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12362063_j_mr-2024-0086_fig_002.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2d5d/12362063/0298f0bfaba5/j_mr-2024-0086_fig_002.jpg" loading="lazy" height="495" width="664" alt="Figure 2:"></a></p>
<div class="p text-right font-secondary"><a href="figure/j_mr-2024-0086_fig_002/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>A demonstration of the extent of metastatic prostate cancer that would preclude reasonable manual tumor segmentation. (A) Maximum intensity project image and (B) sagittal fused PSMA PET/CT images from a 63-year-old man with widespread metastatic prostate cancer. The accurate delineation of the extent of prostate cancer would be very time consuming for a human observer and there would be significant inter- and intra-reader variability in the assigned segmentations. Properly validated generative AI methods might improve both the accuracy and the repeatability of segmentations in this context. PSMA, prostate-specific membrane antigen; PET, positron emission tomography; CT, computed tomography; AI, artificial intelligence.</p></figcaption></figure><p>Efforts to harmonize PSMA-PET reporting standards have resulted in frameworks such as PROMISE (Prostate Cancer Molecular Imaging Standardized Evaluation), PSMA-RADS (PSMA Reporting and Data System), and E-PSMA (European PSMA Guidelines), which aim to ensure consistency and reliability in PSMA-PET interpretation [<a href="#j_mr-2024-0086_ref_030" class="usa-link" aria-describedby="j_mr-2024-0086_ref_030">30</a>]. These frameworks are particularly critical as PSMA-PET imaging is increasingly integrated into clinical trials, where validated methods are essential for assessing treatment responses and ensuring reproducibility. However, there can be significant trade-offs in terms of clinical applicability and complexity as shown by the E-PSMA effort to harmonize various approaches into a universally accepted system. One way to ensure continued clinical applicability while also allowing for nuance of clinical interpretation is to train models to provide decisions that are not always just “positive” or “negative”, but can also be “indeterminate”. There has been some progress made with traditional AI methods to incorporate that idea [<a href="#j_mr-2024-0086_ref_031" class="usa-link" aria-describedby="j_mr-2024-0086_ref_031">31</a>], although a more thorough incorporation of generative AI would likely lead to significant improvements in the reliability of such methods.</p>
<p>Lastly, the inherent complexity of PSMA-PET imagingin combination with poorly understood correlations between findings, impacts on patient management, and long-term patient outcomes – has led to the proposal of multiple different systematic approaches for lesion characterization [<a href="#j_mr-2024-0086_ref_032" class="usa-link" aria-describedby="j_mr-2024-0086_ref_032">32</a>], anatomic delineation of disease extent [<a href="#j_mr-2024-0086_ref_033" class="usa-link" aria-describedby="j_mr-2024-0086_ref_033">33</a>], confidence in findings of primary disease in the pre-cancer-diagnosis setting [<a href="#j_mr-2024-0086_ref_034" class="usa-link" aria-describedby="j_mr-2024-0086_ref_034">34</a>], and response to therapy [<a href="#j_mr-2024-0086_ref_035" class="usa-link" aria-describedby="j_mr-2024-0086_ref_035">35</a>]. Traditional AI has already been leveraged into a U.S. Food and Drug Administration-cleared product that can identify sites of abnormal radiotracer uptake – however, lesion characterization has proven more difficult, as will be discussed later.</p>
<p>Addressing all the challenges described is essential for ensuring high-quality, AI-driven PSMA-PET image analysis and accurate clinical assessments of the extent of PCa.</p></section><section id="j_mr-2024-0086_s_003_s_002"><h3 class="pmc_sec_title">Generative AI techniques</h3>
<p>Generative AI encompasses a variety of sophisticated models designed to create new data instances that resemble those in the training dataset. Among those models, GAN stands out as a widely recognized and powerful approach [<a href="#j_mr-2024-0086_ref_036" class="usa-link" aria-describedby="j_mr-2024-0086_ref_036">36</a>]. The architecture of a standard GAN comprises two key components: a generator and a discriminator. Both are typically implemented as deep neural networks, with the generator tasked with producing realistic samples and the discriminator learning to distinguish between genuine and generated data. This framework operates in a competitive manner, with the generator striving to improve its output while the discriminator seeks to become more discerning. Over time, this dynamic results in the generation of increasingly convincing data distributions. There are numerous variants of GANs depending on their architecture and the loss functions they utilize, such as deep convolutional GAN (DCGAN), conditional GAN (CGAN), cycle-consistent GAN (CycleGAN), auxiliary classifier GAN (ACGAN), etc. Various aspects of notable GAN variants in the context of medical imaging are summarized in <a href="#j_mr-2024-0086_tab_001" class="usa-link">Table 1</a>.</p>
<section class="tw xbox font-sm" id="j_mr-2024-0086_tab_001"><h4 class="obj_head">Table 1:</h4>
<div class="caption p"><p>Variants of generative adversarial networks.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" span="1">
<col align="left" span="1">
<col align="left" span="1">
<col align="left" span="1">
<col align="left" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">No.</th>
<th align="left" rowspan="1" colspan="1">GAN variants</th>
<th align="left" rowspan="1" colspan="1">Description</th>
<th align="left" rowspan="1" colspan="1">Use cases in medical imaging</th>
<th align="right" rowspan="1" colspan="1">References</th>
</tr></thead>
<tbody>
<tr>
<td rowspan="1" colspan="1">1</td>
<td rowspan="1" colspan="1">Vanilla GAN</td>
<td rowspan="1" colspan="1">The most typical GAN. Fully connected neural networks in generator and discriminator. Jensen-Shannon distance as discriminator loss function.</td>
<td rowspan="1" colspan="1">Image synthesis</td>
<td align="right" rowspan="1" colspan="1">[<a href="#j_mr-2024-0086_ref_052" class="usa-link" aria-describedby="j_mr-2024-0086_ref_052">52</a>], [<a href="#j_mr-2024-0086_ref_085" class="usa-link" aria-describedby="j_mr-2024-0086_ref_085">85</a>]</td>
</tr>
<tr>
<td rowspan="1" colspan="1">2</td>
<td rowspan="1" colspan="1">Deep convolutional GAN (DCGAN)</td>
<td rowspan="1" colspan="1">Convolutional neural networks in generator &amp; discriminator. Good training stability &amp; convergence, prevents mode collapse, generates diverse samples. May suffer from vanishing or exploding gradient problem.</td>
<td rowspan="1" colspan="1">Image synthesis of improved resolution, quality and diversity</td>
<td align="right" rowspan="1" colspan="1">[<a href="#j_mr-2024-0086_ref_042" class="usa-link" aria-describedby="j_mr-2024-0086_ref_042">42</a>], [<a href="#j_mr-2024-0086_ref_085" class="usa-link" aria-describedby="j_mr-2024-0086_ref_085">85</a>], [<a href="#j_mr-2024-0086_ref_086" class="usa-link" aria-describedby="j_mr-2024-0086_ref_086">86</a>], [<a href="#j_mr-2024-0086_ref_087" class="usa-link" aria-describedby="j_mr-2024-0086_ref_087">87</a>], [<a href="#j_mr-2024-0086_ref_088" class="usa-link" aria-describedby="j_mr-2024-0086_ref_088">88</a>]</td>
</tr>
<tr>
<td rowspan="1" colspan="1">3</td>
<td rowspan="1" colspan="1">Conditional GAN (cGAN)</td>
<td rowspan="1" colspan="1">Conditions provided to generator and discriminator. Generates images of desired properties, avoids mode collapse. Stable training. Requires annotated dataset for training, may suffer from vanishing or exploding gradient problem.</td>
<td rowspan="1" colspan="1">Conditional image synthesis, cross-modality image synthesis, image registration</td>
<td align="right" rowspan="1" colspan="1">[<a href="#j_mr-2024-0086_ref_086" class="usa-link" aria-describedby="j_mr-2024-0086_ref_086">86</a>]</td>
</tr>
<tr>
<td rowspan="1" colspan="1">4</td>
<td rowspan="1" colspan="1">Auxiliary classifier GAN (ACGAN)</td>
<td rowspan="1" colspan="1">One kind of cGAN. Discriminator works as a classifier to generate class labels, besides detecting real/fake data. May have low intra-class diversity in the generated data, requires labeled dataset for training.</td>
<td rowspan="1" colspan="1">Image synthesis and classification, anomaly detection</td>
<td align="right" rowspan="1" colspan="1">[<a href="#j_mr-2024-0086_ref_045" class="usa-link" aria-describedby="j_mr-2024-0086_ref_045">45</a>], [<a href="#j_mr-2024-0086_ref_088" class="usa-link" aria-describedby="j_mr-2024-0086_ref_088">88</a>]</td>
</tr>
<tr>
<td rowspan="1" colspan="1">5</td>
<td rowspan="1" colspan="1">Wasserstein GAN (WGAN)</td>
<td rowspan="1" colspan="1">Wasserstein distance loss in discriminator. Good training stability. Solves vanishing gradient and mode collapse problems. May suffer from slow training.</td>
<td rowspan="1" colspan="1">Image synthesis, feature representation learning</td>
<td align="right" rowspan="1" colspan="1">[<a href="#j_mr-2024-0086_ref_086" class="usa-link" aria-describedby="j_mr-2024-0086_ref_086">86</a>], [<a href="#j_mr-2024-0086_ref_087" class="usa-link" aria-describedby="j_mr-2024-0086_ref_087">87</a>], [<a href="#j_mr-2024-0086_ref_088" class="usa-link" aria-describedby="j_mr-2024-0086_ref_088">88</a>]</td>
</tr>
<tr>
<td rowspan="1" colspan="1">6</td>
<td rowspan="1" colspan="1">Boundary equilibrium GAN (BEGAN)</td>
<td rowspan="1" colspan="1">The generator and discriminator are autoencoders. Generates diverse samples, easier to train, fast and stable convergence. May suffer from vanishing or exploding gradient problem.</td>
<td rowspan="1" colspan="1">Image synthesis</td>
<td align="right" rowspan="1" colspan="1">[<a href="#j_mr-2024-0086_ref_086" class="usa-link" aria-describedby="j_mr-2024-0086_ref_086">86</a>], [<a href="#j_mr-2024-0086_ref_088" class="usa-link" aria-describedby="j_mr-2024-0086_ref_088">88</a>]</td>
</tr>
<tr>
<td rowspan="1" colspan="1">7</td>
<td rowspan="1" colspan="1">Cycle-consistent GAN (CycleGAN)</td>
<td rowspan="1" colspan="1">One kind of cGAN. The generator has an autoencoder architecture. Prevents mode collapse, good for image translation, doesn’t require paired or labeled dataset for training. High computational complexity.</td>
<td rowspan="1" colspan="1">Image denoising, multi-modality &amp; cross-modality image synthesis, conditional synthesis, image registration</td>
<td align="right" rowspan="1" colspan="1">[<a href="#j_mr-2024-0086_ref_044" class="usa-link" aria-describedby="j_mr-2024-0086_ref_044">44</a>], [<a href="#j_mr-2024-0086_ref_085" class="usa-link" aria-describedby="j_mr-2024-0086_ref_085">85</a>], [<a href="#j_mr-2024-0086_ref_086" class="usa-link" aria-describedby="j_mr-2024-0086_ref_086">86</a>], [<a href="#j_mr-2024-0086_ref_088" class="usa-link" aria-describedby="j_mr-2024-0086_ref_088">88</a>]</td>
</tr>
<tr>
<td rowspan="1" colspan="1">8</td>
<td rowspan="1" colspan="1">Pix2pix GAN</td>
<td rowspan="1" colspan="1">One kind of cGAN. Good for image translation. Requires paired and pixel-aligned dataset for training</td>
<td rowspan="1" colspan="1">Image denoising, cross-modality image synthesis, conditional synthesis</td>
<td align="right" rowspan="1" colspan="1">[<a href="#j_mr-2024-0086_ref_085" class="usa-link" aria-describedby="j_mr-2024-0086_ref_085">85</a>], [<a href="#j_mr-2024-0086_ref_088" class="usa-link" aria-describedby="j_mr-2024-0086_ref_088">88</a>]</td>
</tr>
<tr>
<td rowspan="1" colspan="1">9</td>
<td rowspan="1" colspan="1">Laplacian pyramid GAN (LAPGAN)</td>
<td rowspan="1" colspan="1">A stack of cGANs, each layer adds higher frequency to the generated images.</td>
<td rowspan="1" colspan="1">Image synthesis, super-resolution</td>
<td align="right" rowspan="1" colspan="1">[<a href="#j_mr-2024-0086_ref_085" class="usa-link" aria-describedby="j_mr-2024-0086_ref_085">85</a>]</td>
</tr>
<tr>
<td rowspan="1" colspan="1">10</td>
<td rowspan="1" colspan="1">Progressive-growing GAN (PGGAN)</td>
<td rowspan="1" colspan="1">Gradual training of generator with increasing resolutions. Good training stability, can synthesize high resolution images.</td>
<td rowspan="1" colspan="1">High resolution image synthesis</td>
<td align="right" rowspan="1" colspan="1">[<a href="#j_mr-2024-0086_ref_085" class="usa-link" aria-describedby="j_mr-2024-0086_ref_085">85</a>], [<a href="#j_mr-2024-0086_ref_087" class="usa-link" aria-describedby="j_mr-2024-0086_ref_087">87</a>]</td>
</tr>
<tr>
<td rowspan="1" colspan="1">11</td>
<td rowspan="1" colspan="1">Least-squares GAN (LSGAN)</td>
<td rowspan="1" colspan="1">Least-square loss function in discriminator. Stable training, solves vanishing gradient problem</td>
<td rowspan="1" colspan="1">Image reconstruction, feature representation learning</td>
<td align="right" rowspan="1" colspan="1">[<a href="#j_mr-2024-0086_ref_087" class="usa-link" aria-describedby="j_mr-2024-0086_ref_087">87</a>], [<a href="#j_mr-2024-0086_ref_088" class="usa-link" aria-describedby="j_mr-2024-0086_ref_088">88</a>]</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/j_mr-2024-0086_tab_001/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="fn1"><p>GAN, generative adversarial networks.</p></div></div></section><p>Another major generative AI model is a variant of the traditional autoencoder network, known as VAE [<a href="#j_mr-2024-0086_ref_037" class="usa-link" aria-describedby="j_mr-2024-0086_ref_037">37</a>]. An autoencoder consists of an encoder network, followed by a decoder network, both typically implemented through deep neural network technology. The encoder network learns the latent representation of the input data through some lower-dimensional latent variables. The decoder expands upon the latent representation to generate the same or similar data as its output. In a VAE, the encoder learns the probability distributions of the latent variables and thus captures the nature and uncertainty of the input data in a stochastic way. The generative aspect lies in the decoder taking samples from the learned distributions and generating novel and realistic data instances.</p>
<p>Diffusion models have emerged as another significant class of generative AI models, characterized by a two-step process involving forward and reverse transformations [<a href="#j_mr-2024-0086_ref_038" class="usa-link" aria-describedby="j_mr-2024-0086_ref_038">38</a>], [<a href="#j_mr-2024-0086_ref_039" class="usa-link" aria-describedby="j_mr-2024-0086_ref_039">39</a>]. In the forward diffusion process, Gaussian random noise is incrementally added over several steps, gradually degrading the data until it becomes indistinguishable from random noise. During the reverse process, a neural network, often referred to as the backbone or denoiser, is trained to predict the noise added during the forward process, given the noisy image and the noise level. This approach can indirectly generate images through an iterative process of feeding a noisy input and subtracting off the noise prediction output. Repeated for the same number of steps as the forward process, this allows the trained backbone model to generate novel, realistic data by denoising samples drawn from a Gaussian distribution.</p>
<p>In recent years, there has been a surge in the adoption of LLMs, primarily for tasks involving text generation and natural language processing. Those models are based on transformers, a deep learning architecture consisting of encoders and decoders [<a href="#j_mr-2024-0086_ref_040" class="usa-link" aria-describedby="j_mr-2024-0086_ref_040">40</a>]. Within the encoder module, each input word/token is transformed into a contextualized high-dimensional representation, capturing the semantic and syntactic information present in the input sequence through a ‘<em>self-attention</em>’ mechanism. Based on the encoder’s representations and preceding output tokens, the decoder module generates the output sequence such as translated sentence or next word predictions. LLMs leverage these transformers by pre-training them on extensive corpora of text data, followed by fine-tuning them for specific applications [<a href="#j_mr-2024-0086_ref_041" class="usa-link" aria-describedby="j_mr-2024-0086_ref_041">41</a>].</p></section><section id="j_mr-2024-0086_s_003_s_003"><h3 class="pmc_sec_title">Generative AI in medical imaging</h3>
<p>GAN variants have been extensively utilized to generate synthetic images that closely mimic real patient data, thereby facilitating more robust AI model training. This is particularly beneficial when dealing with rare diseases, where the number of available training cases may never allow for adequate use of traditional AI, or in the context of limited patient data from retrospective studies. For instance, DCGAN was utilized to generate artificial brain-MRI images that even experienced neuroradiologists struggled to distinguish from authentic scans [<a href="#j_mr-2024-0086_ref_042" class="usa-link" aria-describedby="j_mr-2024-0086_ref_042">42</a>]. Similarly, DCGAN found application in PET imaging by synthesizing brain images for different stages of Alzheimer’s disease [<a href="#j_mr-2024-0086_ref_043" class="usa-link" aria-describedby="j_mr-2024-0086_ref_043">43</a>]. Additionally, a variant of CycleGAN was employed to generate multi-modality MRI images to improve brain lesion segmentation accuracy [<a href="#j_mr-2024-0086_ref_044" class="usa-link" aria-describedby="j_mr-2024-0086_ref_044">44</a>]. Chest X-ray data augmentation using ACGAN raised Covid-19 detection accuracy from 85% to 95% [<a href="#j_mr-2024-0086_ref_045" class="usa-link" aria-describedby="j_mr-2024-0086_ref_045">45</a>].</p>
<p>Medical image quality can frequently be compromised by noise and artifacts stemming from various factors, including low radiation dosage, limited acquisition time, or patient motion during image acquisition. In such instances, generative AI, particularly GAN-based approaches, can rectify noise and add missing information, thus enabling safer and faster image acquisition [<a href="#j_mr-2024-0086_ref_046" class="usa-link" aria-describedby="j_mr-2024-0086_ref_046">46</a>]. A 3-dimensional (3D) CGAN network was employed to generate high-quality full-dose PET images of the human brain from their noisy low-dose counterparts [<a href="#j_mr-2024-0086_ref_047" class="usa-link" aria-describedby="j_mr-2024-0086_ref_047">47</a>], while CycleGAN was utilized for achieving similar outcome with full-body PET images [<a href="#j_mr-2024-0086_ref_048" class="usa-link" aria-describedby="j_mr-2024-0086_ref_048">48</a>]. Low-dose PET image denoising by GAN proved superior to traditional and deep learning-based denoising methods in regard to SUV<sub>mean</sub> and SUV<sub>max</sub> bias for lesions and normal tissues [<a href="#j_mr-2024-0086_ref_049" class="usa-link" aria-describedby="j_mr-2024-0086_ref_049">49</a>]. GANs have also found various other applications in medical imaging, including cross-modality image synthesis, attenuation and scatter correction, image fusion, image registration, super-resolution image generation and anomaly detection [<a href="#j_mr-2024-0086_ref_050" class="usa-link" aria-describedby="j_mr-2024-0086_ref_050">50</a>], [<a href="#j_mr-2024-0086_ref_051" class="usa-link" aria-describedby="j_mr-2024-0086_ref_051">51</a>], [<a href="#j_mr-2024-0086_ref_052" class="usa-link" aria-describedby="j_mr-2024-0086_ref_052">52</a>].</p>
<p>In addition to GANs, VAEs have found substantial utility in medical image analysis. The synthetic image generation capability of VAEs has been utilized to enhance deep AI model training for tumor identification and its impact analysis from MR images [<a href="#j_mr-2024-0086_ref_053" class="usa-link" aria-describedby="j_mr-2024-0086_ref_053">53</a>]. Data augmentation using the generative aspects of VAE proved crucial in improving the accuracies of classification and segmentation of medical image data across various modalities including CT, MR, X-ray and ultrasound [<a href="#j_mr-2024-0086_ref_054" class="usa-link" aria-describedby="j_mr-2024-0086_ref_054">54</a>]. Furthermore, VAEs were extensively utilized for <em>unsupervised</em> anomaly detection in medical images, through learning the latent representation of healthy images in a probabilistic way, followed by evaluating the reconstruction loss, which was typically higher for images depicting abnormal conditions [<a href="#j_mr-2024-0086_ref_055" class="usa-link" aria-describedby="j_mr-2024-0086_ref_055">55</a>], [<a href="#j_mr-2024-0086_ref_056" class="usa-link" aria-describedby="j_mr-2024-0086_ref_056">56</a>]. The capabilities of VAE and GAN were combined by implementing a VAE-GAN architecture, where a VAE network was used to learn the inherent representation of a limited number of chest X-ray image data and this representation was used by the generator network of a GAN to generate novel synthetic data instances [<a href="#j_mr-2024-0086_ref_057" class="usa-link" aria-describedby="j_mr-2024-0086_ref_057">57</a>]. By combining the probabilistic encoding capabilities of VAEs with the adversarial training strategy of GANs, VAE-GANs offer a powerful framework for generating high-fidelity medical images while preserving the underlying data distribution characteristics.</p>
<p>Diffusion models have recently demonstrated significant potential in various medical imaging tasks. They were employed to augment high-resolution 3D brain MRI image dataset for training neural networks effectively [<a href="#j_mr-2024-0086_ref_058" class="usa-link" aria-describedby="j_mr-2024-0086_ref_058">58</a>]. A denoising diffusion model with transformer-based network in the reverse generative process was proposed and evaluated to synthesize 2D medical images of various modalities, including X-ray, MRI and CT [<a href="#j_mr-2024-0086_ref_059" class="usa-link" aria-describedby="j_mr-2024-0086_ref_059">59</a>]. Besides data augmentation, diffusion models found application in medical image segmentation through generating denoised segmentation mask conditioned on the features of the input image [<a href="#j_mr-2024-0086_ref_060" class="usa-link" aria-describedby="j_mr-2024-0086_ref_060">60</a>], [<a href="#j_mr-2024-0086_ref_061" class="usa-link" aria-describedby="j_mr-2024-0086_ref_061">61</a>]. Furthermore, diffusion models were used in anomaly detection by generating anomaly maps through the translation of patient images to healthy images and then comparing the two [<a href="#j_mr-2024-0086_ref_062" class="usa-link" aria-describedby="j_mr-2024-0086_ref_062">62</a>]. Similar to GANs, diffusion models were employed in many other medical image analysis tasks, such as image reconstruction, registration, classification and enhancement [<a href="#j_mr-2024-0086_ref_063" class="usa-link" aria-describedby="j_mr-2024-0086_ref_063">63</a>].</p>
<p>Finally, LLMs have demonstrated remarkable adaptability and utility in analyzing and interpreting medical data. LLMs possess pre-trained knowledge of vast textual data that can be fine-tuned with medical and radiology literature to streamline, comprehend, and summarize radiology reports [<a href="#j_mr-2024-0086_ref_064" class="usa-link" aria-describedby="j_mr-2024-0086_ref_064">64</a>]. In addition to text-based inputs, LLMs can also accommodate medical images by encoding them into a format suitable for processing. The latest advancements in LLM technology have given rise to multimodal LLMs (M-LLMs), capable of handling and generating data across multiple modalities including text, image, audio, and video. These M-LLMs have been successfully deployed to generate descriptive captions and impressions from medical images [<a href="#j_mr-2024-0086_ref_065" class="usa-link" aria-describedby="j_mr-2024-0086_ref_065">65</a>]. Moreover, text-to-image transformers, often built on pre-trained LLM, have emerged as a significant innovation within this framework, demonstrating their ability to generate synthetic medical images from textual descriptions. These transformers have been effectively utilized to create synthetic chest X-ray [<a href="#j_mr-2024-0086_ref_066" class="usa-link" aria-describedby="j_mr-2024-0086_ref_066">66</a>] and brain MRI [<a href="#j_mr-2024-0086_ref_067" class="usa-link" aria-describedby="j_mr-2024-0086_ref_067">67</a>] images, which show their potential to enhance diagnostic processes and augment training datasets.</p></section><section id="j_mr-2024-0086_s_003_s_004"><h3 class="pmc_sec_title">Potential roles of generative AI in PSMA-PET imaging</h3>
<p>Although a great deal of work has been done to understand the pitfalls and limitations of PSMA-PET, and the field of generative AI is rapidly making inroads into solving near-impossible problems in image interpretation, to date the direct application of generative AI to PSMA-PET has been limited. However, some of the intrinsic difficulties with PSMA-PET are potentially addressable by generative AI in a manner that may not be possible with traditional AI. Of note, we should remember that generative AI algorithms do not “understand” the presence of the physical world – however, they are still able to provide conclusions that have applicability in the physical world.</p>
<p>The utilization of generative AI for the conditional and unconditional synthesis of data holds promise in addressing the challenges of PSMA-PET imaging associated with wide dynamic range of lesion uptake, benign and/or physiological uptake, BCR with very low PSA level, and cross-tracer variability. The synthetic images can incorporate the heterogeneity of PSMA uptake within the prostate gland and surrounding organs in the training data, thereby facilitating robust AI model training that minimizes false-positive and false-negative outcomes. This approach not only augments data in scenarios where images from specific tracers are scarce but also eliminates the need for additional image acquisition and manual annotation, offering time and cost savings. Additionally, generative AI models, such as GANs and VAEs, can perform domain translation between tracers, like <sup>68</sup>Ga and <sup>18</sup>F, enabling cross-tracer generalization without extensive retraining. These models can also adapt AI systems to extract invariant features across tracers, such as lesion morphology and PSMA expression, which leads to better accuracy and generalization. Furthermore, generative AI can also synthesize complementary imaging modalities, like CT, from PET data which can provide more comprehensive insights for lesion detection [<a href="#j_mr-2024-0086_ref_068" class="usa-link" aria-describedby="j_mr-2024-0086_ref_068">68</a>]. These advancements can lead to improved diagnostic precision, more effective lesion localization in PSMA-PET imaging, and a more integrated approach to multimodal imaging.</p>
<p>Similar to other imaging modalities, GAN holds the place of being the most utilized generative AI model in PSMA-PET imaging analysis. PSMA-PET image acquisition suffers from attenuation from epithelial tissue that can be corrected using corresponding CT images as an attenuation correction map. However, in PET/MRI systems, the MR images cannot serve as attenuation coefficient maps by themselves. PET/MRI has broad applicability in PCa as a “one-stop-shop” for initial staging and BCR. GAN was successfully utilized to generate the µ-map for attenuation and scatter correction in <sup>68</sup>Ga-PSMA-PET/MRI prostate imaging, which improved image quality and quantitative accuracy [<a href="#j_mr-2024-0086_ref_069" class="usa-link" aria-describedby="j_mr-2024-0086_ref_069">69</a>].</p>
<p>The lack of clarity in PSMA-PET images resulting from shorter scan duration can be compensated by GAN variants through utilizing their conditional synthesis capability. CycleGAN, for instance, has been utilized to predict standard scan <sup>18</sup>F-FDG and <sup>68</sup>Ga-PSMA-PET images using only 1/8 and 1/16 short-duration scans [<a href="#j_mr-2024-0086_ref_070" class="usa-link" aria-describedby="j_mr-2024-0086_ref_070">70</a>]. Combining such advances from GAN with the move towards long-z-axis field-of-view scanners could allow for transformative changes in decreasing the amount of injected radioactivity that is required and in reducing the scan time. Diffusion models often outperform GANs and VAEs by offering more stable training, avoiding mode collapse associated with adversarial training, and producing higher-quality image data. Their ability to capture complex data distributions and refine details progressively can make them a robust choice for PSMA-PET image analysis, especially since they have already been utilized in image reconstruction and enhancement [<a href="#j_mr-2024-0086_ref_071" class="usa-link" aria-describedby="j_mr-2024-0086_ref_071">71</a>], [<a href="#j_mr-2024-0086_ref_072" class="usa-link" aria-describedby="j_mr-2024-0086_ref_072">72</a>] as well as denoising [<a href="#j_mr-2024-0086_ref_073" class="usa-link" aria-describedby="j_mr-2024-0086_ref_073">73</a>] of traditional PET images.</p>
<p>Traditional deep learning methods have proven effective at identifying sites of PSMA uptake, delineating their anatomic locations, and providing information such as whole-body tumor burden and staging [<a href="#j_mr-2024-0086_ref_008" class="usa-link" aria-describedby="j_mr-2024-0086_ref_008">8</a>]. However, individual lesion characterization remains challenging, partly because of the rarity with which some types of lesions will arise and partly because of a lack of annotated data with pathologic confirmation. Important aspects of natural language processing, such as interpreting radiologists’ descriptions, could be leveraged for enhanced lesion characterization [<a href="#j_mr-2024-0086_ref_031" class="usa-link" aria-describedby="j_mr-2024-0086_ref_031">31</a>]. For example, solitary rib lesions have a small, but measurable, rate of being true positive metastases in patients presenting for initial staging or recurrent disease – and radiologists and nuclear medicine physicians may vary significantly in their interpretive approach [<a href="#j_mr-2024-0086_ref_015" class="usa-link" aria-describedby="j_mr-2024-0086_ref_015">15</a>]. A generative AI model that incorporates the language used to describe solitary rib lesions could serve as a decision aid for less experienced interpreters. Moreover, embedding statistical properties from radiology reports into text-to-image transformer models as conditionals during the generative AI training process could further improve the characterization of lesions in scans that are not included in the training images, thereby enriching the model’s ability to generate contextually relevant and accurate diagnostic insights.</p></section><section id="j_mr-2024-0086_s_003_s_005"><h3 class="pmc_sec_title">Limitations of generative AI</h3>
<p>Generative AI models can suffer from a few technical and clinical limitations when applied to PSMA-PET imaging. These models are highly data-intensive, as they require high-quality, unbiased, and sufficiently large training datasets to generalize effectively. Their effectiveness is contingent upon the quality and diversity of the training dataset, as they can only synthesize data within the statistical boundaries of the true data distribution represented by the training images. As discussed before, PSMA-PET images contain heterogeneity in tumor type, volume and uptake that may not be captured rigorously in the dataset used for training generative AI models. This limitation can lead to suboptimal model performance and reduced reliability in handling rare or complex cases. One example might be a rare tumor type that has PSMA radiotracer uptake but is present in a distribution that is incompatible with PCa; even a very large dataset would be unlikely to contain enough such examples to adequately train the model. Additionally, the ethical challenge of ensuring fairness and generalizability arises when training datasets lack adequate demographic representation, potentially leading to biased outcomes.</p>
<p>Further, the generation of large datasets might best be undertaken through shared repositories that include both the scan data and any available clinical data. While the inclusion of clinical data may or may not improve human interpretations of PSMA PET scan [<a href="#j_mr-2024-0086_ref_074" class="usa-link" aria-describedby="j_mr-2024-0086_ref_074">74</a>], it is likely that such data could be effectively leveraged for more accurate prognostic and predictive biomarker development through federated learning or ensemble approaches [<a href="#j_mr-2024-0086_ref_075" class="usa-link" aria-describedby="j_mr-2024-0086_ref_075">75</a>]. However, the more clinical data required by any repository, the more the treating institution is likely to place significant barriers to data sharing due to concerns regarding patient privacy. The policies for anonymizing data and methods for how the data will be stored must therefore be rock solid and incontrovertibly secure.</p>
<p>In the case of GANs, adversarial training can sometimes lead to mode collapse or mode-hopping, where the model generates a limited variety of outputs, reducing the diversity of synthetic images [<a href="#j_mr-2024-0086_ref_076" class="usa-link" aria-describedby="j_mr-2024-0086_ref_076">76</a>]. This is a critical issue for PSMA-PET imaging, where variability in lesion morphology and tracer uptake is essential for robust AI training. Additionally, deep generative models like GANs and VAEs are susceptible to vanishing or exploding gradient problems, which can result in slow learning or failure to converge during the training process [<a href="#j_mr-2024-0086_ref_050" class="usa-link" aria-describedby="j_mr-2024-0086_ref_050">50</a>].</p>
<p>Training and inference processes of generative AI models require substantial computational resources, especially for high-resolution 3D PSMA-PET images. This creates challenges for integrating these models into clinical workflows, particularly in resource-limited settings [<a href="#j_mr-2024-0086_ref_076" class="usa-link" aria-describedby="j_mr-2024-0086_ref_076">76</a>], [<a href="#j_mr-2024-0086_ref_077" class="usa-link" aria-describedby="j_mr-2024-0086_ref_077">77</a>]. The “black-box” nature of generative AI further raises concerns about their reliability and interpretability in clinical practice. Clinicians may hesitate to adopt such models without clear explanations of how synthesized images or features are derived [<a href="#j_mr-2024-0086_ref_076" class="usa-link" aria-describedby="j_mr-2024-0086_ref_076">76</a>]. Regulatory approval for the use of generative models in clinical practice also requires extensive validation, especially when synthetic images are used for diagnostic or therapeutic purposes [<a href="#j_mr-2024-0086_ref_078" class="usa-link" aria-describedby="j_mr-2024-0086_ref_078">78</a>].</p>
<p>A significant limitation of LLMs is their lack of contextual understanding in medical imaging. LLMs, trained primarily on textual data, do not fully grasp the nuances of PSMA-PET images and their clinical context which may lead to potential misinterpretations and lack of explainability of the data. This can be especially problematic when LLMs are used to generate or assist in interpreting synthetic images, where a deep understanding of the image’s clinical relevance is critical.</p></section><section id="j_mr-2024-0086_s_003_s_006"><h3 class="pmc_sec_title">Future research directions</h3>
<p>Addressing the limitations of generative AI in PSMA-PET imaging requires strategic advancements in model development and application. One promising approach is the use of transfer learning, which allows pre-trained generative models to be adapted to the specific requirements of PSMA-PET imaging [<a href="#j_mr-2024-0086_ref_079" class="usa-link" aria-describedby="j_mr-2024-0086_ref_079">79</a>]. By leveraging knowledge from existing datasets, these models can be fine-tuned to achieve more precise characterization of individual lesions, thereby supporting personalized treatment decisions.</p>
<p>Multi-center studies and federated learning offer two other viable pathways to overcome the challenges associated with limited PSMA-PET image data availability [<a href="#j_mr-2024-0086_ref_080" class="usa-link" aria-describedby="j_mr-2024-0086_ref_080">80</a>], [<a href="#j_mr-2024-0086_ref_081" class="usa-link" aria-describedby="j_mr-2024-0086_ref_081">81</a>]. Multi-center studies help build robust and generalized generative AI models through utilizing data from diverse patient populations and imaging protocols across multiple institutions stored in a centralized database. On the other hand, federated learning employs decentralized computing across multiple institutions to develop and train generative AI models collaboratively without explicitly sharing raw medical images, thus preserving patient privacy and data security. Both approaches can facilitate the creation of diverse and representative training datasets, which are essential for improving the generalizability of generative AI models.</p>
<p>To address training instabilities, commonly associated with GAN and VAE, stabilization techniques such as spectral normalization or the application of Wasserstein loss have shown promise [<a href="#j_mr-2024-0086_ref_068" class="usa-link" aria-describedby="j_mr-2024-0086_ref_068">68</a>], [<a href="#j_mr-2024-0086_ref_082" class="usa-link" aria-describedby="j_mr-2024-0086_ref_082">82</a>]. These methods can help reduce issues like mode collapse and improve the diversity of synthetic images, as demonstrated in advanced GAN variants outlined in <a href="#j_mr-2024-0086_tab_001" class="usa-link">Table 1</a>. Complementing these efforts, the development of hybrid models that combine the strengths of different generative AI architectures, such as integrating GANs with VAEs or incorporating attention mechanisms, can enhance model performance by focusing on clinically critical regions of interest within the images [<a href="#j_mr-2024-0086_ref_083" class="usa-link" aria-describedby="j_mr-2024-0086_ref_083">83</a>].</p>
<p>Finally, integrating synthetic data into radiomics pipelines could significantly enhance feature extraction and downstream clinical decision-making. By incorporating synthetic images into radiomic analysis workflows, researchers can evaluate the impact of generative AI on the robustness of feature extraction, crucial for PSMA-PET imaging. This approach can help improve the accuracy and repeatability of radiomic signatures used for early diagnosis, prognosis, and treatment response assessment, ultimately contributing to better patient outcomes. Of course, given the limitations in PET evaluation of high-frequency imaging features, the need for carefully chosen radiomic features that are centered around low-frequency, whole-tumor features is emphasized [<a href="#j_mr-2024-0086_ref_084" class="usa-link" aria-describedby="j_mr-2024-0086_ref_084">84</a>]. Collectively, these research directions aim to address the technical, computational, and clinical challenges of generative AI in PSMA-PET imaging to ensure its safe and effective adoption in clinical workflows.</p></section></section><section id="j_mr-2024-0086_s_004"><h2 class="pmc_sec_title">Conclusions</h2>
<p>In conclusion, the integration of generative AI techniques with PSMA-PET imaging holds tremendous potential to address the unique challenges associated with PCa diagnosis, staging, and treatment. While traditional AI methods have made significant strides in lesion detection and anatomic delineation, they often fall short in characterizing individual lesion and addressing the variability inherent in PSMA-PET images. Generative AI models, such as GANs, VAEs, diffusion models, and LLMs, can offer innovative solutions to these challenges by generating synthetic data, enhancing image quality, automating lesion detection, segmentation, and characterization, and augmenting radiologists’ interpretations.</p>
<p>Despite its promise, the application of generative AI in PSMA-PET imaging is still in its infancy, and several technical, clinical, and ethical challenges remain. Issues such as the need for large, unbiased datasets, computational resource demands, training instabilities, and the “black-box” nature of generative models must be addressed to facilitate clinical adoption. Moreover, ensuring fairness and generalizability across diverse patient populations and achieving regulatory approval are critical for translating these technologies into practice.</p>
<p>Looking ahead, future research directions at the intersection of generative AI and PSMA-PET imaging include the development of robust deep learning models with transfer learning capabilities, the creation of diverse, well-annotated datasets for training and validation through federated learning, the integration of multi-modal imaging for comprehensive lesion characterization, and the translation of generative AI-driven insights into clinical practice to improve patient outcomes. Additionally, regulatory frameworks must evolve to provide guidelines for validating and deploying generative AI models in clinical settings. In summary, the synergistic application of generative AI with PSMA-PET imaging represents a promising avenue for advancing precision medicine in management of PCa, paving the way for more accurate diagnosis, personalized treatment strategies, and improved patient care. Continued research and collaboration in this field will be crucial for realizing the full potential of generative AI in revolutionizing imaging and therapeutics of PCa.</p></section><section id="fn-group1" class="fn-group"><h2 class="pmc_sec_title">Footnotes</h2>
<div class="fn-group p font-secondary-light font-sm">
<div class="fn p" id="j_mr-2024-0086_fn_002"><p>
<strong>Research ethics:</strong> Not applicable. Review paper.</p></div>
<div class="fn p" id="j_mr-2024-0086_fn_003"><p>
<strong>Informed consent:</strong> Not applicable. Review paper.</p></div>
<div class="fn p" id="j_mr-2024-0086_fn_005"><p>
<strong>Author contributions:</strong> All authors have accepted responsibility for the entire content of this manuscript and approved its submission. MZI and SPR conceived the manuscript. MZI wrote the initial draft. ES, PTY, MAG, and SPR made critical edits to the manuscript.</p></div>
<div class="fn p" id="j_mr-2024-0086_fn_004"><p>
<strong>Use of Large Language Models, AI and Machine Learning Tools:</strong> There was no use of Large Language Models, AI or Machine Learning Tools.</p></div>
<div class="fn p" id="j_mr-2024-0086_fn_006"><p>
<strong>Conflict of interest:</strong> The authors states no conflict of interest.</p></div>
<div class="fn p" id="j_mr-2024-0086_fn_007"><p>
<strong>Research funding:</strong> None Declared.</p></div>
<div class="fn p" id="j_mr-2024-0086_fn_008"><p>
<strong>Data availability:</strong> Not Applicable.</p></div>
</div></section><section id="j_mr-2024-0086_reflist_001" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="j_mr-2024-0086_reflist_001_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="j_mr-2024-0086_ref_001">
<span class="label">1.</span><cite>Rowe SP, Pomper MG. Molecular imaging in oncology: current impact and future directions. CA Cancer J Clin. 2022;72:333–52. doi: 10.3322/caac.21713.</cite> [<a href="https://doi.org/10.3322/caac.21713" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9189244/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34902160/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=CA%20Cancer%20J%20Clin&amp;title=Molecular%20imaging%20in%20oncology:%20current%20impact%20and%20future%20directions&amp;author=SP%20Rowe&amp;author=MG%20Pomper&amp;volume=72&amp;publication_year=2022&amp;pages=333-52&amp;pmid=34902160&amp;doi=10.3322/caac.21713&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_002">
<span class="label">2.</span><cite>Rowe SP, Gorin MA, Pomper MG. Imaging of prostate-specific membrane antigen with small-molecule PET radiotracers: from the bench to advanced clinical applications. Annu Rev Med. 2019;70:461–77. doi: 10.1146/annurev-med-062117-073027.</cite> [<a href="https://doi.org/10.1146/annurev-med-062117-073027" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/30691373/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Annu%20Rev%20Med&amp;title=Imaging%20of%20prostate-specific%20membrane%20antigen%20with%20small-molecule%20PET%20radiotracers:%20from%20the%20bench%20to%20advanced%20clinical%20applications&amp;author=SP%20Rowe&amp;author=MA%20Gorin&amp;author=MG%20Pomper&amp;volume=70&amp;publication_year=2019&amp;pages=461-77&amp;pmid=30691373&amp;doi=10.1146/annurev-med-062117-073027&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_003">
<span class="label">3.</span><cite>Rasul S, Haug AR. Clinical applications of PSMA PET examination in patients with prostate cancer. Cancers. 2022;14:3768. doi: 10.3390/cancers14153768.</cite> [<a href="https://doi.org/10.3390/cancers14153768" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9367427/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35954432/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Cancers&amp;title=Clinical%20applications%20of%20PSMA%20PET%20examination%20in%20patients%20with%20prostate%20cancer&amp;author=S%20Rasul&amp;author=AR%20Haug&amp;volume=14&amp;publication_year=2022&amp;pages=3768&amp;pmid=35954432&amp;doi=10.3390/cancers14153768&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_004">
<span class="label">4.</span><cite>Pienta KJ, Gorin MA, Rowe SP, Carroll PR, Pouliot F, Probst S, et al.  A phase 2/3 prospective multicenter study of the diagnostic accuracy of prostate specific membrane antigen PET/CT with 18F-DCFPyL in prostate cancer patients (OSPREY) J Urol. 2021;206:52–61. doi: 10.1097/ju.0000000000001698.</cite> [<a href="https://doi.org/10.1097/ju.0000000000001698" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8556578/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33634707/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Urol&amp;title=A%20phase%202/3%20prospective%20multicenter%20study%20of%20the%20diagnostic%20accuracy%20of%20prostate%20specific%20membrane%20antigen%20PET/CT%20with%2018F-DCFPyL%20in%20prostate%20cancer%20patients%20(OSPREY)&amp;author=KJ%20Pienta&amp;author=MA%20Gorin&amp;author=SP%20Rowe&amp;author=PR%20Carroll&amp;author=F%20Pouliot&amp;volume=206&amp;publication_year=2021&amp;pages=52-61&amp;pmid=33634707&amp;doi=10.1097/ju.0000000000001698&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_005">
<span class="label">5.</span><cite>Morris MJ, Rowe SP, Gorin MA, Saperstein L, Pouliot F, Josephson D, et al.  Diagnostic performance of 18F-DCFPyL-PET/CT in men with biochemically recurrent prostate cancer: results from the CONDOR Phase III, multicenter study. Clin Cancer Res. 2021;27:3674–82. doi: 10.1158/1078-0432.ccr-20-4573.</cite> [<a href="https://doi.org/10.1158/1078-0432.ccr-20-4573" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8382991/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33622706/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Clin%20Cancer%20Res&amp;title=Diagnostic%20performance%20of%2018F-DCFPyL-PET/CT%20in%20men%20with%20biochemically%20recurrent%20prostate%20cancer:%20results%20from%20the%20CONDOR%20Phase%20III,%20multicenter%20study&amp;author=MJ%20Morris&amp;author=SP%20Rowe&amp;author=MA%20Gorin&amp;author=L%20Saperstein&amp;author=F%20Pouliot&amp;volume=27&amp;publication_year=2021&amp;pages=3674-82&amp;pmid=33622706&amp;doi=10.1158/1078-0432.ccr-20-4573&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_006">
<span class="label">6.</span><cite>Sartor O, de Bono J, Chi KN, Fizazi K, Herrmann K, Rahbar K, et al.  Lutetium-177–PSMA-617 for metastatic castration-resistant prostate cancer. N Engl J Med. 2021;385:1091–103. doi: 10.1056/nejmoa2107322.</cite> [<a href="https://doi.org/10.1056/nejmoa2107322" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8446332/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34161051/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=N%20Engl%20J%20Med&amp;title=Lutetium-177%E2%80%93PSMA-617%20for%20metastatic%20castration-resistant%20prostate%20cancer&amp;author=O%20Sartor&amp;author=J%20de%20Bono&amp;author=KN%20Chi&amp;author=K%20Fizazi&amp;author=K%20Herrmann&amp;volume=385&amp;publication_year=2021&amp;pages=1091-103&amp;pmid=34161051&amp;doi=10.1056/nejmoa2107322&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_007">
<span class="label">7.</span><cite>Phillips R, Shi WY, Deek M, Radwan N, Lim SJ, Antonarakis ES, et al.  Outcomes of observation vs stereotactic ablative radiation for oligometastatic prostate cancer: the ORIOLE phase 2 randomized clinical trial. JAMA Oncol. 2020;6:650–9. doi: 10.1001/jamaoncol.2020.0147.</cite> [<a href="https://doi.org/10.1001/jamaoncol.2020.0147" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7225913/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32215577/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=JAMA%20Oncol&amp;title=Outcomes%20of%20observation%20vs%20stereotactic%20ablative%20radiation%20for%20oligometastatic%20prostate%20cancer:%20the%20ORIOLE%20phase%202%20randomized%20clinical%20trial&amp;author=R%20Phillips&amp;author=WY%20Shi&amp;author=M%20Deek&amp;author=N%20Radwan&amp;author=SJ%20Lim&amp;volume=6&amp;publication_year=2020&amp;pages=650-9&amp;pmid=32215577&amp;doi=10.1001/jamaoncol.2020.0147&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_008">
<span class="label">8.</span><cite>Nickols N, Anand A, Johnsson K, Brynolfsson J, Borreli P, Parikh N, et al.  aPROMISE: a novel automated promise platform to standardize evaluation of tumor burden in 18F-DCFPyL images of veterans with prostate cancer. J Nucl Med. 2022;63:233–9. doi: 10.2967/jnumed.120.261863.</cite> [<a href="https://doi.org/10.2967/jnumed.120.261863" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34049980/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Nucl%20Med&amp;title=aPROMISE:%20a%20novel%20automated%20promise%20platform%20to%20standardize%20evaluation%20of%20tumor%20burden%20in%2018F-DCFPyL%20images%20of%20veterans%20with%20prostate%20cancer&amp;author=N%20Nickols&amp;author=A%20Anand&amp;author=K%20Johnsson&amp;author=J%20Brynolfsson&amp;author=P%20Borreli&amp;volume=63&amp;publication_year=2022&amp;pages=233-9&amp;pmid=34049980&amp;doi=10.2967/jnumed.120.261863&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_009">
<span class="label">9.</span><cite>Yi Z, Hu S, Lin X, Zou Q, Zou MH, Zhang Z, et al.  Machine learning-based prediction of invisible intraprostatic prostate cancer lesions on 68Ga-PSMA-11 PET/CT in patients with primary prostate cancer. Eur J Nucl Med Mol Imaging. 2022;49:1523–34. doi: 10.1007/s00259-021-05631-6.</cite> [<a href="https://doi.org/10.1007/s00259-021-05631-6" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34845536/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Eur%20J%20Nucl%20Med%20Mol%20Imaging&amp;title=Machine%20learning-based%20prediction%20of%20invisible%20intraprostatic%20prostate%20cancer%20lesions%20on%2068Ga-PSMA-11%20PET/CT%20in%20patients%20with%20primary%20prostate%20cancer&amp;author=Z%20Yi&amp;author=S%20Hu&amp;author=X%20Lin&amp;author=Q%20Zou&amp;author=MH%20Zou&amp;volume=49&amp;publication_year=2022&amp;pages=1523-34&amp;pmid=34845536&amp;doi=10.1007/s00259-021-05631-6&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_010">
<span class="label">10.</span><cite>Huang B, Yang Q, Li X, Wu Y, Liu Z, Pan Z, et al.  Deep learning–based whole-body characterization of prostate cancer lesions on [68Ga]Ga-PSMA-11 PET/CT in patients with post-prostatectomy recurrence. Eur J Nucl Med Mol Imaging. 2023;51:1173–84. doi: 10.1007/s00259-023-06551-3.</cite> [<a href="https://doi.org/10.1007/s00259-023-06551-3" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38049657/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Eur%20J%20Nucl%20Med%20Mol%20Imaging&amp;title=Deep%20learning%E2%80%93based%20whole-body%20characterization%20of%20prostate%20cancer%20lesions%20on%20%5B68Ga%5DGa-PSMA-11%20PET/CT%20in%20patients%20with%20post-prostatectomy%20recurrence&amp;author=B%20Huang&amp;author=Q%20Yang&amp;author=X%20Li&amp;author=Y%20Wu&amp;author=Z%20Liu&amp;volume=51&amp;publication_year=2023&amp;pages=1173-84&amp;pmid=38049657&amp;doi=10.1007/s00259-023-06551-3&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_011">
<span class="label">11.</span><cite>Rowe SP. Artificial intelligence in molecular imaging: at the crossroads of revolutions in medical diagnosis. Ann Transl Med. 2021;9:817. doi: 10.21037/atm-2020-mi-09.</cite> [<a href="https://doi.org/10.21037/atm-2020-mi-09" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8246207/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34268430/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Ann%20Transl%20Med&amp;title=Artificial%20intelligence%20in%20molecular%20imaging:%20at%20the%20crossroads%20of%20revolutions%20in%20medical%20diagnosis&amp;author=SP%20Rowe&amp;volume=9&amp;publication_year=2021&amp;pages=817&amp;pmid=34268430&amp;doi=10.21037/atm-2020-mi-09&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_012">
<span class="label">12.</span><cite>Oh SW, Cheon GJ. Prostate-specific membrane antigen PET imaging in prostate cancer: opportunities and challenges. Korean J Radiol. 2018;19:819–31. doi: 10.3348/kjr.2018.19.5.819.</cite> [<a href="https://doi.org/10.3348/kjr.2018.19.5.819" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6082771/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/30174470/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Korean%20J%20Radiol&amp;title=Prostate-specific%20membrane%20antigen%20PET%20imaging%20in%20prostate%20cancer:%20opportunities%20and%20challenges&amp;author=SW%20Oh&amp;author=GJ%20Cheon&amp;volume=19&amp;publication_year=2018&amp;pages=819-31&amp;pmid=30174470&amp;doi=10.3348/kjr.2018.19.5.819&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_013">
<span class="label">13.</span><cite>Yin Y, Werner RA, Higuchi T, Lapa C, Pienta KJ, Pomper MG, et al.  Follow-up of lesions with equivocal radiotracer uptake on PSMA-targeted PET in patients with prostate cancer: predictive values of the PSMA-RADS-3A and PSMA-RADS-3B categories. J Nucl Med. 2019;60:511–6. doi: 10.2967/jnumed.118.217653.</cite> [<a href="https://doi.org/10.2967/jnumed.118.217653" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6448464/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/30190303/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Nucl%20Med&amp;title=Follow-up%20of%20lesions%20with%20equivocal%20radiotracer%20uptake%20on%20PSMA-targeted%20PET%20in%20patients%20with%20prostate%20cancer:%20predictive%20values%20of%20the%20PSMA-RADS-3A%20and%20PSMA-RADS-3B%20categories&amp;author=Y%20Yin&amp;author=RA%20Werner&amp;author=T%20Higuchi&amp;author=C%20Lapa&amp;author=KJ%20Pienta&amp;volume=60&amp;publication_year=2019&amp;pages=511-6&amp;pmid=30190303&amp;doi=10.2967/jnumed.118.217653&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_014">
<span class="label">14.</span><cite>Szabo Z, Mena E, Rowe SP, Plyku D, Nidal R, Eisenberger MA, et al.  Initial evaluation of [18F]DCFPyL for prostate-specific membrane antigen (PSMA)-Targeted PET imaging of prostate cancer. Mol Imaging Biol. 2015;17:565–74. doi: 10.1007/s11307-015-0850-8.</cite> [<a href="https://doi.org/10.1007/s11307-015-0850-8" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4531836/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/25896814/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Mol%20Imaging%20Biol&amp;title=Initial%20evaluation%20of%20%5B18F%5DDCFPyL%20for%20prostate-specific%20membrane%20antigen%20(PSMA)-Targeted%20PET%20imaging%20of%20prostate%20cancer&amp;author=Z%20Szabo&amp;author=E%20Mena&amp;author=SP%20Rowe&amp;author=D%20Plyku&amp;author=R%20Nidal&amp;volume=17&amp;publication_year=2015&amp;pages=565-74&amp;pmid=25896814&amp;doi=10.1007/s11307-015-0850-8&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_015">
<span class="label">15.</span><cite>Chen MY, Franklin A, Yaxley J, Gianduzzo T, McBean R, Wong D, et al.  Solitary rib lesions showing prostate-specific membrane antigen (PSMA) uptake in pre‐treatment staging 68Ga-PSMA-11 positron emission tomography scans for men with prostate cancer: benign or malignant? BJU Int. 2020;126:396–401. doi: 10.1111/bju.15152.</cite> [<a href="https://doi.org/10.1111/bju.15152" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32592330/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=BJU%20Int&amp;title=Solitary%20rib%20lesions%20showing%20prostate-specific%20membrane%20antigen%20(PSMA)%20uptake%20in%20pre%E2%80%90treatment%20staging%2068Ga-PSMA-11%20positron%20emission%20tomography%20scans%20for%20men%20with%20prostate%20cancer:%20benign%20or%20malignant?&amp;author=MY%20Chen&amp;author=A%20Franklin&amp;author=J%20Yaxley&amp;author=T%20Gianduzzo&amp;author=R%20McBean&amp;volume=126&amp;publication_year=2020&amp;pages=396-401&amp;pmid=32592330&amp;doi=10.1111/bju.15152&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_016">
<span class="label">16.</span><cite>Khatri W, Chung HW, Werner RA, Leal JP, Pienta KJ, Lodge MA, et al.  Effect of point-spread function reconstruction for indeterminate PSMA-RADS-3A lesions on PSMA-targeted PET imaging of men with prostate cancer. Diagnostics. 2021;11 doi: 10.3390/diagnostics11040665.</cite> [<a href="https://doi.org/10.3390/diagnostics11040665" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8067967/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33917238/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Diagnostics&amp;title=Effect%20of%20point-spread%20function%20reconstruction%20for%20indeterminate%20PSMA-RADS-3A%20lesions%20on%20PSMA-targeted%20PET%20imaging%20of%20men%20with%20prostate%20cancer&amp;author=W%20Khatri&amp;author=HW%20Chung&amp;author=RA%20Werner&amp;author=JP%20Leal&amp;author=KJ%20Pienta&amp;volume=11&amp;publication_year=2021&amp;pmid=33917238&amp;doi=10.3390/diagnostics11040665&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_017">
<span class="label">17.</span><cite>Wondergem M, Van Der Zant FM, Knol RJJ, Lazarenko SV, Pruim J, De Jong IJ. 
18F-DCFPyL PET/CT in the detection of prostate cancer at 60 and 120 minutes: detection rate, image quality, activity kinetics, and biodistribution. J Nucl Med. 2017;58:1797–804. doi: 10.2967/jnumed.117.192658.</cite> [<a href="https://doi.org/10.2967/jnumed.117.192658" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/28450569/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Nucl%20Med&amp;title=18F-DCFPyL%20PET/CT%20in%20the%20detection%20of%20prostate%20cancer%20at%2060%20and%20120%C2%A0minutes:%20detection%20rate,%20image%20quality,%20activity%20kinetics,%20and%20biodistribution&amp;author=M%20Wondergem&amp;author=FM%20Van%20Der%20Zant&amp;author=RJJ%20Knol&amp;author=SV%20Lazarenko&amp;author=J%20Pruim&amp;volume=58&amp;publication_year=2017&amp;pages=1797-804&amp;pmid=28450569&amp;doi=10.2967/jnumed.117.192658&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_018">
<span class="label">18.</span><cite>Luo L, Wang Z, Wang X, Gao J, Zheng A, Duan X. Fluorine-18 prostate-specific membrane antigen-1007-avid indeterminate bone lesions in prostate cancer: clinical and PET/CT features to predict outcomes and prognosis. Clin Radiol. 2024;79:346–53. doi: 10.1016/j.crad.2023.12.008.</cite> [<a href="https://doi.org/10.1016/j.crad.2023.12.008" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38216370/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Clin%20Radiol&amp;title=Fluorine-18%20prostate-specific%20membrane%20antigen-1007-avid%20indeterminate%20bone%20lesions%20in%20prostate%20cancer:%20clinical%20and%20PET/CT%20features%20to%20predict%20outcomes%20and%20prognosis&amp;author=L%20Luo&amp;author=Z%20Wang&amp;author=X%20Wang&amp;author=J%20Gao&amp;author=A%20Zheng&amp;volume=79&amp;publication_year=2024&amp;pages=346-53&amp;pmid=38216370&amp;doi=10.1016/j.crad.2023.12.008&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_019">
<span class="label">19.</span><cite>Huang S, Ong S, McKenzie D, Mirabelli A, Chen DC, Chengodu T, et al.  Comparison of 18F-based PSMA radiotracers with [68Ga]Ga-PSMA-11 in PET/CT imaging of prostate cancer—a systematic review and meta-analysis. Prostate Cancer Prostatic Dis. 2023;27:654–64. doi: 10.1038/s41391-023-00755-2.</cite> [<a href="https://doi.org/10.1038/s41391-023-00755-2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11543591/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38017295/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Prostate%20Cancer%20Prostatic%20Dis&amp;title=Comparison%20of%2018F-based%20PSMA%20radiotracers%20with%20%5B68Ga%5DGa-PSMA-11%20in%20PET/CT%20imaging%20of%20prostate%20cancer%E2%80%94a%20systematic%20review%20and%20meta-analysis&amp;author=S%20Huang&amp;author=S%20Ong&amp;author=D%20McKenzie&amp;author=A%20Mirabelli&amp;author=DC%20Chen&amp;volume=27&amp;publication_year=2023&amp;pages=654-64&amp;pmid=38017295&amp;doi=10.1038/s41391-023-00755-2&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_020">
<span class="label">20.</span><cite>Popescu CE, Zhang B, Sartoretti T, Spielhofer N, Skawran S, Heimer J, et al.  Evaluating the biodistribution for [68Ga]Ga-PSMA-11 and [18F]F-PSMA-1007 PET/CT with an inter- and intrapatient based analysis. EJNMMI Res. 2024;14 doi: 10.1186/s13550-024-01097-3.</cite> [<a href="https://doi.org/10.1186/s13550-024-01097-3" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10997563/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38578516/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=EJNMMI%20Res&amp;title=Evaluating%20the%20biodistribution%20for%20%5B68Ga%5DGa-PSMA-11%20and%20%5B18F%5DF-PSMA-1007%20PET/CT%20with%20an%20inter-%20and%20intrapatient%20based%20analysis&amp;author=CE%20Popescu&amp;author=B%20Zhang&amp;author=T%20Sartoretti&amp;author=N%20Spielhofer&amp;author=S%20Skawran&amp;volume=14&amp;publication_year=2024&amp;pmid=38578516&amp;doi=10.1186/s13550-024-01097-3&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_021">
<span class="label">21.</span><cite>Rizzo A, Morbelli S, Albano D, Fornarini G, Cioffi M, Laudicella R, et al.  The Homunculus of unspecific bone uptakes associated with PSMA-targeted tracers: a systematic review-based definition. Eur J Nucl Med Mol Imaging. 2024;51 doi: 10.1007/s00259-024-06797-5.</cite> [<a href="https://doi.org/10.1007/s00259-024-06797-5" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11445318/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38884773/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Eur%20J%20Nucl%20Med%20Mol%20Imaging&amp;title=The%20Homunculus%20of%20unspecific%20bone%20uptakes%20associated%20with%20PSMA-targeted%20tracers:%20a%20systematic%20review-based%20definition&amp;author=A%20Rizzo&amp;author=S%20Morbelli&amp;author=D%20Albano&amp;author=G%20Fornarini&amp;author=M%20Cioffi&amp;volume=51&amp;publication_year=2024&amp;pmid=38884773&amp;doi=10.1007/s00259-024-06797-5&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_022">
<span class="label">22.</span><cite>Leung KH, Rowe SP, Sadaghiani MS, Leal JP, Mena E, Choyke PL, et al.  Deep semisupervised transfer learning for fully automated whole-body tumor quantification and prognosis of cancer on PET/CT. J Nucl Med. 2024;65:643–50. doi: 10.2967/jnumed.123.267048.</cite> [<a href="https://doi.org/10.2967/jnumed.123.267048" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10995523/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38423786/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Nucl%20Med&amp;title=Deep%20semisupervised%20transfer%20learning%20for%20fully%20automated%20whole-body%20tumor%20quantification%20and%20prognosis%20of%20cancer%20on%20PET/CT&amp;author=KH%20Leung&amp;author=SP%20Rowe&amp;author=MS%20Sadaghiani&amp;author=JP%20Leal&amp;author=E%20Mena&amp;volume=65&amp;publication_year=2024&amp;pages=643-50&amp;pmid=38423786&amp;doi=10.2967/jnumed.123.267048&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_023">
<span class="label">23.</span><cite>Zhao Y, Gafita A, Vollnberg B, Tetteh G, Haupt F, Afshar-Oromieh A, et al.  Deep neural network for automatic characterization of lesions on 68Ga-PSMA-11 PET/CT. Eur J Nucl Med Mol Imaging. 2020;47:603–13. doi: 10.1007/s00259-019-04606-y.</cite> [<a href="https://doi.org/10.1007/s00259-019-04606-y" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31813050/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Eur%20J%20Nucl%20Med%20Mol%20Imaging&amp;title=Deep%20neural%20network%20for%20automatic%20characterization%20of%20lesions%20on%2068Ga-PSMA-11%20PET/CT&amp;author=Y%20Zhao&amp;author=A%20Gafita&amp;author=B%20Vollnberg&amp;author=G%20Tetteh&amp;author=F%20Haupt&amp;volume=47&amp;publication_year=2020&amp;pages=603-13&amp;pmid=31813050&amp;doi=10.1007/s00259-019-04606-y&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_024">
<span class="label">24.</span><cite>Chu LC, Rowe SP, Fishman EK. Clinician-scientists: can they survive in the modern era? J Am Coll Radiol. 2021;18:192–7. doi: 10.1016/j.jacr.2020.09.023.</cite> [<a href="https://doi.org/10.1016/j.jacr.2020.09.023" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33413899/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Am%20Coll%20Radiol&amp;title=Clinician-scientists:%20can%20they%20survive%20in%20the%20modern%20era?&amp;author=LC%20Chu&amp;author=SP%20Rowe&amp;author=EK%20Fishman&amp;volume=18&amp;publication_year=2021&amp;pages=192-7&amp;pmid=33413899&amp;doi=10.1016/j.jacr.2020.09.023&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_025">
<span class="label">25.</span><cite>Capobianco N, Sibille L, Chantadisai M, Gafita A, Langbein T, Platsch G, et al.  Whole-body uptake classification and prostate cancer staging in 68Ga-PSMA-11 PET/CT using dual-tracer learning. Eur J Nucl Med Mol Imaging. 2022;49:517–26. doi: 10.1007/s00259-021-05473-2.</cite> [<a href="https://doi.org/10.1007/s00259-021-05473-2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8803695/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34232350/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Eur%20J%20Nucl%20Med%20Mol%20Imaging&amp;title=Whole-body%20uptake%20classification%20and%20prostate%20cancer%20staging%20in%2068Ga-PSMA-11%20PET/CT%20using%20dual-tracer%20learning&amp;author=N%20Capobianco&amp;author=L%20Sibille&amp;author=M%20Chantadisai&amp;author=A%20Gafita&amp;author=T%20Langbein&amp;volume=49&amp;publication_year=2022&amp;pages=517-26&amp;pmid=34232350&amp;doi=10.1007/s00259-021-05473-2&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_026">
<span class="label">26.</span><cite>Svirydenka H, Muehlematter UJ, Nagel HW, Delso G, Ferraro DA, Kudura K, et al.  
68Ga-PSMA-11 dose reduction for dedicated pelvic imaging with simultaneous PET/MR using TOF BSREM reconstructions. Eur Radiol. 2020;30:3188–97. doi: 10.1007/s00330-020-06667-2.</cite> [<a href="https://doi.org/10.1007/s00330-020-06667-2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32060711/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Eur%20Radiol&amp;title=68Ga-PSMA-11%20dose%20reduction%20for%20dedicated%20pelvic%20imaging%20with%20simultaneous%20PET/MR%20using%20TOF%20BSREM%20reconstructions&amp;author=H%20Svirydenka&amp;author=UJ%20Muehlematter&amp;author=HW%20Nagel&amp;author=G%20Delso&amp;author=DA%20Ferraro&amp;volume=30&amp;publication_year=2020&amp;pages=3188-97&amp;pmid=32060711&amp;doi=10.1007/s00330-020-06667-2&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_027">
<span class="label">27.</span><cite>Lindemann ME, Guberina N, Wetter A, Fendler WP, Jakoby B, Quick HH. Improving 68Ga-PSMA PET/MRI of the prostate with unrenormalized absolute scatter correction. J Nucl Med. 2019;60:1642–8. doi: 10.2967/jnumed.118.224139.</cite> [<a href="https://doi.org/10.2967/jnumed.118.224139" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/30979819/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Nucl%20Med&amp;title=Improving%2068Ga-PSMA%20PET/MRI%20of%20the%20prostate%20with%20unrenormalized%20absolute%20scatter%20correction&amp;author=ME%20Lindemann&amp;author=N%20Guberina&amp;author=A%20Wetter&amp;author=WP%20Fendler&amp;author=B%20Jakoby&amp;volume=60&amp;publication_year=2019&amp;pages=1642-8&amp;pmid=30979819&amp;doi=10.2967/jnumed.118.224139&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_028">
<span class="label">28.</span><cite>Rogasch JMM, Hofheinz F, van Heek L, Voltin CA, Boellaard R, Kobe C. Influences on PET quantification and interpretation. Diagnostics. 2022;12:451. doi: 10.3390/diagnostics12020451.</cite> [<a href="https://doi.org/10.3390/diagnostics12020451" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8871060/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35204542/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Diagnostics&amp;title=Influences%20on%20PET%20quantification%20and%20interpretation&amp;author=JMM%20Rogasch&amp;author=F%20Hofheinz&amp;author=L%20van%20Heek&amp;author=CA%20Voltin&amp;author=R%20Boellaard&amp;volume=12&amp;publication_year=2022&amp;pages=451&amp;pmid=35204542&amp;doi=10.3390/diagnostics12020451&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_029">
<span class="label">29.</span><cite>Mittlmeier LM, Brendel M, Beyer L, Albert NL, Todica A, Zacherl MJ, et al.  Feasibility of different tumor delineation approaches for 18F-PSMA-1007 PET/CT imaging in prostate cancer patients. Front Oncol. 2021;11 doi: 10.3389/fonc.2021.663631.</cite> [<a href="https://doi.org/10.3389/fonc.2021.663631" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8176856/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34094956/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Front%20Oncol&amp;title=Feasibility%20of%20different%20tumor%20delineation%20approaches%20for%2018F-PSMA-1007%20PET/CT%20imaging%20in%20prostate%20cancer%20patients&amp;author=LM%20Mittlmeier&amp;author=M%20Brendel&amp;author=L%20Beyer&amp;author=NL%20Albert&amp;author=A%20Todica&amp;volume=11&amp;publication_year=2021&amp;pmid=34094956&amp;doi=10.3389/fonc.2021.663631&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_030">
<span class="label">30.</span><cite>Swiha M, Ayati N, Oprea-Lager DE, Ceci F, Emmett L. How to report PSMA PET. Semin Nucl Med. 2024;54:14–29. doi: 10.1053/j.semnuclmed.2023.07.007.</cite> [<a href="https://doi.org/10.1053/j.semnuclmed.2023.07.007" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37558507/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Semin%20Nucl%20Med&amp;title=How%20to%20report%20PSMA%20PET&amp;author=M%20Swiha&amp;author=N%20Ayati&amp;author=DE%20Oprea-Lager&amp;author=F%20Ceci&amp;author=L%20Emmett&amp;volume=54&amp;publication_year=2024&amp;pages=14-29&amp;pmid=37558507&amp;doi=10.1053/j.semnuclmed.2023.07.007&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_031">
<span class="label">31.</span><cite>Leung KH, Rowe SP, Leal JP, Ashrafinia S, Sadaghiani MS, Chung HW, et al.  Deep learning and radiomics framework for PSMA-RADS classification of prostate cancer on PSMA PET. EJNMMI Res. 2022;12 doi: 10.1186/s13550-022-00948-1.</cite> [<a href="https://doi.org/10.1186/s13550-022-00948-1" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9800682/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36580220/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=EJNMMI%20Res&amp;title=Deep%20learning%20and%20radiomics%20framework%20for%20PSMA-RADS%20classification%20of%20prostate%20cancer%20on%20PSMA%20PET&amp;author=KH%20Leung&amp;author=SP%20Rowe&amp;author=JP%20Leal&amp;author=S%20Ashrafinia&amp;author=MS%20Sadaghiani&amp;volume=12&amp;publication_year=2022&amp;pmid=36580220&amp;doi=10.1186/s13550-022-00948-1&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_032">
<span class="label">32.</span><cite>Werner RA, Hartrampf PE, Fendler WP, Serfling SE, Derlin T, Higuchi T, et al.  Prostate-specific membrane antigen reporting and data system version 2.0. Eur Urol. 2023;84:491–502. doi: 10.1016/j.eururo.2023.06.008.</cite> [<a href="https://doi.org/10.1016/j.eururo.2023.06.008" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11981304/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37414701/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Eur%20Urol&amp;title=Prostate-specific%20membrane%20antigen%20reporting%20and%20data%20system%20version%202.0&amp;author=RA%20Werner&amp;author=PE%20Hartrampf&amp;author=WP%20Fendler&amp;author=SE%20Serfling&amp;author=T%20Derlin&amp;volume=84&amp;publication_year=2023&amp;pages=491-502&amp;pmid=37414701&amp;doi=10.1016/j.eururo.2023.06.008&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_033">
<span class="label">33.</span><cite>Seifert R, Emmett L, Rowe SP, Herrmann K, Hadaschik B, Calais J, et al.  Second version of the prostate cancer molecular imaging standardized evaluation framework including response evaluation for clinical trials (PROMISE V2) Eur Urol. 2023;83:405–12. doi: 10.1016/j.eururo.2023.02.002.</cite> [<a href="https://doi.org/10.1016/j.eururo.2023.02.002" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36935345/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Eur%20Urol&amp;title=Second%20version%20of%20the%20prostate%20cancer%20molecular%20imaging%20standardized%20evaluation%20framework%20including%20response%20evaluation%20for%20clinical%20trials%20(PROMISE%20V2)&amp;author=R%20Seifert&amp;author=L%20Emmett&amp;author=SP%20Rowe&amp;author=K%20Herrmann&amp;author=B%20Hadaschik&amp;volume=83&amp;publication_year=2023&amp;pages=405-12&amp;pmid=36935345&amp;doi=10.1016/j.eururo.2023.02.002&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_034">
<span class="label">34.</span><cite>Emmett L, Papa N, Buteau J, Ho B, Liu V, Roberts M, et al.  The PRIMARY score: using intraprostatic 68Ga-PSMA PET/CT patterns to optimize prostate cancer diagnosis. J Nucl Med. 2022;63:1644–50. doi: 10.2967/jnumed.121.263448.</cite> [<a href="https://doi.org/10.2967/jnumed.121.263448" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9635676/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35301240/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Nucl%20Med&amp;title=The%20PRIMARY%20score:%20using%20intraprostatic%2068Ga-PSMA%20PET/CT%20patterns%20to%20optimize%20prostate%20cancer%20diagnosis&amp;author=L%20Emmett&amp;author=N%20Papa&amp;author=J%20Buteau&amp;author=B%20Ho&amp;author=V%20Liu&amp;volume=63&amp;publication_year=2022&amp;pages=1644-50&amp;pmid=35301240&amp;doi=10.2967/jnumed.121.263448&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_035">
<span class="label">35.</span><cite>Gafita A, Rauscher I, Weber M, Hadaschik B, Wang H, Armstrong WR, et al.  Novel framework for treatment response evaluation using PSMA PET/CT in patients with metastatic castration-resistant prostate cancer (RECIP 1.0): an international multicenter study. J Nucl Med. 2022;63:1651–8. doi: 10.2967/jnumed.121.263072.</cite> [<a href="https://doi.org/10.2967/jnumed.121.263072" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9635677/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35422442/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Nucl%20Med&amp;title=Novel%20framework%20for%20treatment%20response%20evaluation%20using%20PSMA%20PET/CT%20in%20patients%20with%20metastatic%20castration-resistant%20prostate%20cancer%20(RECIP%201.0):%20an%20international%20multicenter%20study&amp;author=A%20Gafita&amp;author=I%20Rauscher&amp;author=M%20Weber&amp;author=B%20Hadaschik&amp;author=H%20Wang&amp;volume=63&amp;publication_year=2022&amp;pages=1651-8&amp;pmid=35422442&amp;doi=10.2967/jnumed.121.263072&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_036">
<span class="label">36.</span><cite>Goodfellow IJ, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D, Ozair S, et al.  Generative adversarial nets. Adv Neural Inf Process Syst. 2014;27</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Adv%20Neural%20Inf%20Process%20Syst&amp;title=Generative%20adversarial%20nets&amp;author=IJ%20Goodfellow&amp;author=J%20Pouget-Abadie&amp;author=M%20Mirza&amp;author=B%20Xu&amp;author=D%20Warde-Farley&amp;volume=27&amp;publication_year=2014&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_037">
<span class="label">37.</span><cite>Cemgil T, Ghaisas S, Dvijotham K, Gowal S, Kohli P. The autoencoding variational autoencoder. Adv Neural Inf Process Syst. 2020:15077–87.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Adv%20Neural%20Inf%20Process%20Syst&amp;title=The%20autoencoding%20variational%20autoencoder&amp;author=T%20Cemgil&amp;author=S%20Ghaisas&amp;author=K%20Dvijotham&amp;author=S%20Gowal&amp;author=P%20Kohli&amp;publication_year=2020&amp;pages=15077-87&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_038">
<span class="label">38.</span><cite>Ho J, Jain A, Abbeel P. Denoising diffusion probabilistic models. Adv Neural Inf Process Syst. 2020:6840–51.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Adv%20Neural%20Inf%20Process%20Syst&amp;title=Denoising%20diffusion%20probabilistic%20models&amp;author=J%20Ho&amp;author=A%20Jain&amp;author=P%20Abbeel&amp;publication_year=2020&amp;pages=6840-51&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_039">
<span class="label">39.</span><cite>Sohl-Dickstein J, Weiss EA, Maheswaranathan N, Ganguli S, Edu S. Deep unsupervised learning using nonequilibrium thermodynamics. Int Conf Mach Learn. 2015:2256–65.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Int%20Conf%20Mach%20Learn&amp;title=Deep%20unsupervised%20learning%20using%20nonequilibrium%20thermodynamics&amp;author=J%20Sohl-Dickstein&amp;author=EA%20Weiss&amp;author=N%20Maheswaranathan&amp;author=S%20Ganguli&amp;author=S%20Edu&amp;publication_year=2015&amp;pages=2256-65&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_040">
<span class="label">40.</span><cite>Vaswani A, Brain G, Shazeer N, Parmar N, Uszkoreit J, Jones L, et al.  Attention is all you need. Adv Neural Inf Process Syst. 2017;30</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Adv%20Neural%20Inf%20Process%20Syst&amp;title=Attention%20is%20all%20you%20need&amp;author=A%20Vaswani&amp;author=G%20Brain&amp;author=N%20Shazeer&amp;author=N%20Parmar&amp;author=J%20Uszkoreit&amp;volume=30&amp;publication_year=2017&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_041">
<span class="label">41.</span><cite>Akinci D’Antonoli T, Stanzione A, Bluethgen C, Vernuccio F, Ugga L, Klontzas ME, et al.  Large language models in radiology: fundamentals, applications, ethical considerations, risks, and future directions. Diagn Interv Radiol. 2024;30:80–90. doi: 10.4274/dir.2023.232417.</cite> [<a href="https://doi.org/10.4274/dir.2023.232417" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10916534/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37789676/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Diagn%20Interv%20Radiol&amp;title=Large%20language%20models%20in%20radiology:%20fundamentals,%20applications,%20ethical%20considerations,%20risks,%20and%20future%20directions&amp;author=T%20Akinci%20D%E2%80%99Antonoli&amp;author=A%20Stanzione&amp;author=C%20Bluethgen&amp;author=F%20Vernuccio&amp;author=L%20Ugga&amp;volume=30&amp;publication_year=2024&amp;pages=80-90&amp;pmid=37789676&amp;doi=10.4274/dir.2023.232417&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_042">
<span class="label">42.</span><cite>Kazuhiro K, Werner RA, Toriumi F, Javadi MS, Pomper MG, Solnes LB, et al.  Generative adversarial networks for the creation of realistic artificial brain magnetic resonance images. Tomography. 2018;4:159–63. doi: 10.18383/j.tom.2018.00042.</cite> [<a href="https://doi.org/10.18383/j.tom.2018.00042" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6299742/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/30588501/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Tomography&amp;title=Generative%20adversarial%20networks%20for%20the%20creation%20of%20realistic%20artificial%20brain%20magnetic%20resonance%20images&amp;author=K%20Kazuhiro&amp;author=RA%20Werner&amp;author=F%20Toriumi&amp;author=MS%20Javadi&amp;author=MG%20Pomper&amp;volume=4&amp;publication_year=2018&amp;pages=159-63&amp;pmid=30588501&amp;doi=10.18383/j.tom.2018.00042&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_043">
<span class="label">43.</span><cite>Islam J, Zhang Y. GAN-based synthetic brain PET image generation. Brain Inform. 2020;7:3. doi: 10.1186/s40708-020-00104-2.</cite> [<a href="https://doi.org/10.1186/s40708-020-00104-2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7105582/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32232602/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Brain%20Inform&amp;title=GAN-based%20synthetic%20brain%20PET%20image%20generation&amp;author=J%20Islam&amp;author=Y%20Zhang&amp;volume=7&amp;publication_year=2020&amp;pages=3&amp;pmid=32232602&amp;doi=10.1186/s40708-020-00104-2&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_044">
<span class="label">44.</span><cite>Zhu L, He Q, Huang Y, Zhang Z, Zeng J, Lu L, et al.  DualMMP-GAN: dual-scale multi-modality perceptual generative adversarial network for medical image segmentation. Comput Biol Med. 2022;144:105387. doi: 10.1016/j.compbiomed.2022.105387.</cite> [<a href="https://doi.org/10.1016/j.compbiomed.2022.105387" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35305502/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Comput%20Biol%20Med&amp;title=DualMMP-GAN:%20dual-scale%20multi-modality%20perceptual%20generative%20adversarial%20network%20for%20medical%20image%20segmentation&amp;author=L%20Zhu&amp;author=Q%20He&amp;author=Y%20Huang&amp;author=Z%20Zhang&amp;author=J%20Zeng&amp;volume=144&amp;publication_year=2022&amp;pages=105387&amp;pmid=35305502&amp;doi=10.1016/j.compbiomed.2022.105387&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_045">
<span class="label">45.</span><cite>Waheed A, Goyal M, Gupta D, Khanna A, Al-Turjman F, Pinheiro PR. CovidGAN: data augmentation using auxiliary classifier GAN for improved covid-19 detection. IEEE Access. 2020;8:91916–23. doi: 10.1109/access.2020.2994762.</cite> [<a href="https://doi.org/10.1109/access.2020.2994762" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8043420/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34192100/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Access&amp;title=CovidGAN:%20data%20augmentation%20using%20auxiliary%20classifier%20GAN%20for%20improved%20covid-19%20detection&amp;author=A%20Waheed&amp;author=M%20Goyal&amp;author=D%20Gupta&amp;author=A%20Khanna&amp;author=F%20Al-Turjman&amp;volume=8&amp;publication_year=2020&amp;pages=91916-23&amp;pmid=34192100&amp;doi=10.1109/access.2020.2994762&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_046">
<span class="label">46.</span><cite>Marcos L, Babyn P, Alirezaie J.  Applications of generative AI. Cham: Springer Int Publ; 2024. Generative AI in medical imaging and its application in low dose computed tomography (CT) image denoising; pp. 387–401.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=Applications%20of%20generative%20AI&amp;author=L%20Marcos&amp;author=P%20Babyn&amp;author=J%20Alirezaie&amp;publication_year=2024&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_047">
<span class="label">47.</span><cite>Wang Y, Yu B, Wang L, Zu C, Lalush DS, Lin W, et al.  3D conditional generative adversarial networks for high-quality PET image estimation at low dose. Neuroimage. 2018;174:550–62. doi: 10.1016/j.neuroimage.2018.03.045.</cite> [<a href="https://doi.org/10.1016/j.neuroimage.2018.03.045" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6410574/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/29571715/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Neuroimage&amp;title=3D%20conditional%20generative%20adversarial%20networks%20for%20high-quality%20PET%20image%20estimation%20at%20low%20dose&amp;author=Y%20Wang&amp;author=B%20Yu&amp;author=L%20Wang&amp;author=C%20Zu&amp;author=DS%20Lalush&amp;volume=174&amp;publication_year=2018&amp;pages=550-62&amp;pmid=29571715&amp;doi=10.1016/j.neuroimage.2018.03.045&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_048">
<span class="label">48.</span><cite>Lei Y, Dong X, Wang T, Higgins K, Liu T, Curran WJ, et al.   Medical imaging 2020: image processing. Houston, TX: SPIE; 2020. Estimating standard-dose PET from low-dose PET with deep learning; pp. 505–11.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=Medical%20imaging%202020:%20image%20processing&amp;author=Y%20Lei&amp;author=X%20Dong&amp;author=T%20Wang&amp;author=K%20Higgins&amp;author=T%20Liu&amp;publication_year=2020&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_049">
<span class="label">49.</span><cite>Zhou L, Schaefferkoetter JD, Tham IWK, Huang G, Yan J. Supervised learning with cyclegan for low-dose FDG PET image denoising. Med Image Anal. 2020;65 doi: 10.1016/j.media.2020.101770.</cite> [<a href="https://doi.org/10.1016/j.media.2020.101770" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32674043/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Med%20Image%20Anal&amp;title=Supervised%20learning%20with%20cyclegan%20for%20low-dose%20FDG%20PET%20image%20denoising&amp;author=L%20Zhou&amp;author=JD%20Schaefferkoetter&amp;author=IWK%20Tham&amp;author=G%20Huang&amp;author=J%20Yan&amp;volume=65&amp;publication_year=2020&amp;pmid=32674043&amp;doi=10.1016/j.media.2020.101770&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_050">
<span class="label">50.</span><cite>Apostolopoulos ID, Papathanasiou ND, Apostolopoulos DJ, Panayiotakis GS. Applications of generative adversarial networks (GANs) in positron emission tomography (PET) imaging: a review. Eur J Nucl Med Mol Imaging. 2022;49:3717–39. doi: 10.1007/s00259-022-05805-w.</cite> [<a href="https://doi.org/10.1007/s00259-022-05805-w" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35451611/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Eur%20J%20Nucl%20Med%20Mol%20Imaging&amp;title=Applications%20of%20generative%20adversarial%20networks%20(GANs)%20in%20positron%20emission%20tomography%20(PET)%20imaging:%20a%20review&amp;author=ID%20Apostolopoulos&amp;author=ND%20Papathanasiou&amp;author=DJ%20Apostolopoulos&amp;author=GS%20Panayiotakis&amp;volume=49&amp;publication_year=2022&amp;pages=3717-39&amp;pmid=35451611&amp;doi=10.1007/s00259-022-05805-w&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_051">
<span class="label">51.</span><cite>Zhang L, Dai H, Sang Y. Med-SRNet: GAN-based medical image super-resolution via high-resolution representation learning. Comput Intell Neurosci. 2022;2022:1744969. doi: 10.1155/2022/1744969.</cite> [<a href="https://doi.org/10.1155/2022/1744969" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9210125/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35747717/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Comput%20Intell%20Neurosci&amp;title=Med-SRNet:%20GAN-based%20medical%20image%20super-resolution%20via%20high-resolution%20representation%20learning&amp;author=L%20Zhang&amp;author=H%20Dai&amp;author=Y%20Sang&amp;volume=2022&amp;publication_year=2022&amp;pages=1744969&amp;pmid=35747717&amp;doi=10.1155/2022/1744969&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_052">
<span class="label">52.</span><cite>Yi X, Walia E, Babyn P. Generative adversarial network in medical imaging: a review. Med Image Anal. 2019;58 doi: 10.1016/j.media.2019.101552.</cite> [<a href="https://doi.org/10.1016/j.media.2019.101552" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31521965/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Med%20Image%20Anal&amp;title=Generative%20adversarial%20network%20in%20medical%20imaging:%20a%20review&amp;author=X%20Yi&amp;author=E%20Walia&amp;author=P%20Babyn&amp;volume=58&amp;publication_year=2019&amp;pmid=31521965&amp;doi=10.1016/j.media.2019.101552&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_053">
<span class="label">53.</span><cite>Naga Srinivasu P, Krishna TB, Ahmed S, Almusallam N, Khaled Alarfaj F, Allheeib N. Variational autoencoders-based self-learning model for tumor identification and impact analysis from 2-D MRI images. J Healthc Eng. 2023;2023 doi: 10.1155/2023/1566123.</cite> [<a href="https://doi.org/10.1155/2023/1566123" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9873460/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36704578/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Healthc%20Eng&amp;title=Variational%20autoencoders-based%20self-learning%20model%20for%20tumor%20identification%20and%20impact%20analysis%20from%202-D%20MRI%20images&amp;author=P%20Naga%20Srinivasu&amp;author=TB%20Krishna&amp;author=S%20Ahmed&amp;author=N%20Almusallam&amp;author=F%20Khaled%20Alarfaj&amp;volume=2023&amp;publication_year=2023&amp;pmid=36704578&amp;doi=10.1155/2023/1566123&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_054">
<span class="label">54.</span><cite>Kebaili A, Lapuyade-Lahorgue J, Ruan S. Deep learning approaches for data augmentation in medical imaging: a review. J Imaging. 2023;9:81. doi: 10.3390/jimaging9040081.</cite> [<a href="https://doi.org/10.3390/jimaging9040081" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10144738/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37103232/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Imaging&amp;title=Deep%20learning%20approaches%20for%20data%20augmentation%20in%20medical%20imaging:%20a%20review&amp;author=A%20Kebaili&amp;author=J%20Lapuyade-Lahorgue&amp;author=S%20Ruan&amp;volume=9&amp;publication_year=2023&amp;pages=81&amp;pmid=37103232&amp;doi=10.3390/jimaging9040081&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_055">
<span class="label">55.</span><cite>Guo X, Gichoya JW, Purkayastha S, Banerjee I. CVAD: a generic medical anomaly detector based on Cascade VAE. . 2021 arXiv preprint arXiv:2110.15811.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=.&amp;title=CVAD:%20a%20generic%20medical%20anomaly%20detector%20based%20on%20Cascade%20VAE&amp;author=X%20Guo&amp;author=JW%20Gichoya&amp;author=S%20Purkayastha&amp;author=I%20Banerjee&amp;publication_year=2021&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_056">
<span class="label">56.</span><cite>Chatterjee S, Sciarra A, Dünnwald M, Tummala P, Agrawal SK, Jauhari A, et al.  StRegA: unsupervised anomaly detection in brain MRIs using a compact context-encoding variational autoencoder. Comput Biol Med. 2022;149 doi: 10.1016/j.compbiomed.2022.106093.</cite> [<a href="https://doi.org/10.1016/j.compbiomed.2022.106093" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36116318/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Comput%20Biol%20Med&amp;title=StRegA:%20unsupervised%20anomaly%20detection%20in%20brain%20MRIs%20using%20a%20compact%20context-encoding%20variational%20autoencoder&amp;author=S%20Chatterjee&amp;author=A%20Sciarra&amp;author=M%20D%C3%BCnnwald&amp;author=P%20Tummala&amp;author=SK%20Agrawal&amp;volume=149&amp;publication_year=2022&amp;pmid=36116318&amp;doi=10.1016/j.compbiomed.2022.106093&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_057">
<span class="label">57.</span><cite>Rguibi Z, Hajami A, Zitouni D, Maleh Y, Elqaraoui A. Medical variational autoencoder and generative adversarial network for medical imaging. Indones J Electr Eng Comput Sci. 2023;32:494–505. doi: 10.11591/ijeecs.v32.i1.pp494-505.</cite> [<a href="https://doi.org/10.11591/ijeecs.v32.i1.pp494-505" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Indones%20J%20Electr%20Eng%20Comput%20Sci&amp;title=Medical%20variational%20autoencoder%20and%20generative%20adversarial%20network%20for%20medical%20imaging&amp;author=Z%20Rguibi&amp;author=A%20Hajami&amp;author=D%20Zitouni&amp;author=Y%20Maleh&amp;author=A%20Elqaraoui&amp;volume=32&amp;publication_year=2023&amp;pages=494-505&amp;doi=10.11591/ijeecs.v32.i1.pp494-505&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_058">
<span class="label">58.</span><cite>Pinaya WHL, Tudosiu PD, Dafflon J, Da Costa PF, Fernandez V, Nachev P, et al.   MICCAI workshop on deep generative models. Singapore: Springer; 2022. Brain imaging generation with latent diffusion models; pp. 117–26.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=MICCAI%20workshop%20on%20deep%20generative%20models&amp;author=WHL%20Pinaya&amp;author=PD%20Tudosiu&amp;author=J%20Dafflon&amp;author=PF%20Da%20Costa&amp;author=V%20Fernandez&amp;publication_year=2022&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_059">
<span class="label">59.</span><cite>Pan S, Wang T, Qiu RLJ, Axente M, Chang CW, Peng J, et al.  2D medical image synthesis using transformer-based denoising diffusion probabilistic model. Phys Med Biol. 2023;68 doi: 10.1088/1361-6560/acca5c.</cite> [<a href="https://doi.org/10.1088/1361-6560/acca5c" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10160739/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37015231/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Phys%20Med%20Biol&amp;title=2D%20medical%20image%20synthesis%20using%20transformer-based%20denoising%20diffusion%20probabilistic%20model&amp;author=S%20Pan&amp;author=T%20Wang&amp;author=RLJ%20Qiu&amp;author=M%20Axente&amp;author=CW%20Chang&amp;volume=68&amp;publication_year=2023&amp;pmid=37015231&amp;doi=10.1088/1361-6560/acca5c&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_060">
<span class="label">60.</span><cite>Wu J, Fu R, Fang H, Zhang Y, Yang Y, Xiong H, et al.  MedSegDiff: medical image segmentation with diffusion probabilistic model. Proc Mach Learn Res. 2023;227:1623–39.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Proc%20Mach%20Learn%20Res&amp;title=MedSegDiff:%20medical%20image%20segmentation%20with%20diffusion%20probabilistic%20model&amp;author=J%20Wu&amp;author=R%20Fu&amp;author=H%20Fang&amp;author=Y%20Zhang&amp;author=Y%20Yang&amp;volume=227&amp;publication_year=2023&amp;pages=1623-39&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_061">
<span class="label">61.</span><cite>Rahman A, Maria J, Valanarasu J, Hacihaliloglu I, Patel VM.  Proc IEEE/CVF conf comput vis pattern recognit. Vancouver, British Columbia: IEEE; 2023. Ambiguous medical image segmentation using diffusion models; pp. 11536–46.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=Proc%20IEEE/CVF%20conf%20comput%20vis%20pattern%20recognit&amp;author=A%20Rahman&amp;author=J%20Maria&amp;author=J%20Valanarasu&amp;author=I%20Hacihaliloglu&amp;author=VM%20Patel&amp;publication_year=2023&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_062">
<span class="label">62.</span><cite>Wolleb J, Bieder F, Sandkühler R, Cattin PC.  International Conference on Medical image computing and computer-assisted intervention. Singapore: Springer; 2022. Diffusion models for medical anomaly detection; pp. 35–45.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=International%20Conference%20on%20Medical%20image%20computing%20and%20computer-assisted%20intervention&amp;author=J%20Wolleb&amp;author=F%20Bieder&amp;author=R%20Sandk%C3%BChler&amp;author=PC%20Cattin&amp;publication_year=2022&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_063">
<span class="label">63.</span><cite>Kazerouni A, Aghdam EK, Heidari M, Azad R, Fayyaz M, Hacihaliloglu I, et al.  Diffusion models in medical imaging: a comprehensive survey. Med Image Anal. 2023;88:102846. doi: 10.1016/j.media.2023.102846.</cite> [<a href="https://doi.org/10.1016/j.media.2023.102846" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37295311/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Med%20Image%20Anal&amp;title=Diffusion%20models%20in%20medical%20imaging:%20a%20comprehensive%20survey&amp;author=A%20Kazerouni&amp;author=EK%20Aghdam&amp;author=M%20Heidari&amp;author=R%20Azad&amp;author=M%20Fayyaz&amp;volume=88&amp;publication_year=2023&amp;pages=102846&amp;pmid=37295311&amp;doi=10.1016/j.media.2023.102846&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_064">
<span class="label">64.</span><cite>Ma C, Wu Z, Wang J, Xu S, Wei Y, Liu Z, et al.  ImpressionGPT: an iterative optimizing framework for radiology report summarization with ChatGPT. . 2023 arXiv preprint arXiv:2304.08448.</cite>
</li>
<li id="j_mr-2024-0086_ref_065">
<span class="label">65.</span><cite>Meskó B. The impact of multimodal Large Language Models on health care’s future. J Med Internet Res. 2023;25:e52865. doi: 10.2196/52865.</cite> [<a href="https://doi.org/10.2196/52865" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10654899/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37917126/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Med%20Internet%20Res&amp;title=The%20impact%20of%20multimodal%20Large%20Language%20Models%20on%20health%20care%E2%80%99s%20future&amp;author=B%20Mesk%C3%B3&amp;volume=25&amp;publication_year=2023&amp;pages=e52865&amp;pmid=37917126&amp;doi=10.2196/52865&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_066">
<span class="label">66.</span><cite>Huang P, Gao X, Huang L, Jiao J, Li X, Wang Y, et al.  Chest-diffusion: a light-weight text-to-image model for report-to-CXR generation; 2024 IEEE international symposium on biomedical imaging (ISBI).; Athens: IEEE; 2024. pp. 1–5.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Chest-diffusion:%20a%20light-weight%20text-to-image%20model%20for%20report-to-CXR%20generation&amp;author=P%20Huang&amp;author=X%20Gao&amp;author=L%20Huang&amp;author=J%20Jiao&amp;author=X%20Li&amp;publication_year=2024&amp;pages=1-5&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_067">
<span class="label">67.</span><cite>Kim K, Na Y, Ye SJ, Lee J, Ahn SS, Park JE, et al.   Proc IEEE/CVF winter conf appl comput vis. Seattle, Washington: IEEE; 2024. Controllable text-to-image synthesis for multi-modality MR images; pp. 7936–45.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=Proc%20IEEE/CVF%20winter%20conf%20appl%20comput%20vis&amp;author=K%20Kim&amp;author=Y%20Na&amp;author=SJ%20Ye&amp;author=J%20Lee&amp;author=SS%20Ahn&amp;publication_year=2024&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_068">
<span class="label">68.</span><cite>Ibrahim M, Khalil YAl, Amirrajab S, Sun C, Breeuwer M, Pluim J, et al.  Generative AI for synthetic data across multiple medical modalities: a systematic review of recent developments and challenges. . 2024 doi: 10.1016/j.compbiomed.2025.109834. arXiv preprint arXiv:2407.00116.</cite> [<a href="https://doi.org/10.1016/j.compbiomed.2025.109834" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/40023073/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=.&amp;title=Generative%20AI%20for%20synthetic%20data%20across%20multiple%20medical%20modalities:%20a%20systematic%20review%20of%20recent%20developments%20and%20challenges&amp;author=M%20Ibrahim&amp;author=YAl%20Khalil&amp;author=S%20Amirrajab&amp;author=C%20Sun&amp;author=M%20Breeuwer&amp;publication_year=2024&amp;pmid=40023073&amp;doi=10.1016/j.compbiomed.2025.109834&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_069">
<span class="label">69.</span><cite>Pozaruk A, Pawar K, Li S, Carey A, Cheng J, Sudarshan VP, et al.  Augmented deep learning model for improved quantitative accuracy of MR-based PET attenuation correction in PSMA PET-MRI prostate imaging. Eur J Nucl Med Mol Imaging. 2021;48:9–20. doi: 10.1007/s00259-020-04816-9.</cite> [<a href="https://doi.org/10.1007/s00259-020-04816-9" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32394162/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Eur%20J%20Nucl%20Med%20Mol%20Imaging&amp;title=Augmented%20deep%20learning%20model%20for%20improved%20quantitative%20accuracy%20of%20MR-based%20PET%20attenuation%20correction%20in%20PSMA%20PET-MRI%20prostate%20imaging&amp;author=A%20Pozaruk&amp;author=K%20Pawar&amp;author=S%20Li&amp;author=A%20Carey&amp;author=J%20Cheng&amp;volume=48&amp;publication_year=2021&amp;pages=9-20&amp;pmid=32394162&amp;doi=10.1007/s00259-020-04816-9&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_070">
<span class="label">70.</span><cite>Ghafari A, Sheikhzadeh P, Seyyedi N, Abbasi M, Farzenefar S, Yousefirizi F, et al.  Generation of 18F-FDG PET standard scan images from short scans using cycle-consistent generative adversarial network. Phys Med Biol. 2022;67 doi: 10.1088/1361-6560/ac950a.</cite> [<a href="https://doi.org/10.1088/1361-6560/ac950a" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36162408/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Phys%20Med%20Biol&amp;title=Generation%20of%2018F-FDG%20PET%20standard%20scan%20images%20from%20short%20scans%20using%20cycle-consistent%20generative%20adversarial%20network&amp;author=A%20Ghafari&amp;author=P%20Sheikhzadeh&amp;author=N%20Seyyedi&amp;author=M%20Abbasi&amp;author=S%20Farzenefar&amp;volume=67&amp;publication_year=2022&amp;pmid=36162408&amp;doi=10.1088/1361-6560/ac950a&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_071">
<span class="label">71.</span><cite>Jiang C, Pan Y, Liu M, Ma L, Zhang X, Liu J, et al.   Lecture notes in computer science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) Vancouver: Springer Science and Business Media Deutschland GmbH; 2023. PET-diffusion: unsupervised PET enhancement based on the latent diffusion model; pp. 3–12.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=Lecture%20notes%20in%20computer%20science%20(including%20subseries%20Lecture%20Notes%20in%20Artificial%20Intelligence%20and%20Lecture%20Notes%20in%20Bioinformatics)&amp;author=C%20Jiang&amp;author=Y%20Pan&amp;author=M%20Liu&amp;author=L%20Ma&amp;author=X%20Zhang&amp;publication_year=2023&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_072">
<span class="label">72.</span><cite>Han Z, Wang Y, Zhou L, Wang P, Yan B, Zhou J, et al.   International conference on medical image computing and computer-assisted intervention. Springer; 2023. Contrastive diffusion model with auxiliary guidance for coarse-to-fine PET reconstruction l; pp. 239–49.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=International%20conference%20on%20medical%20image%20computing%20and%20computer-assisted%20intervention&amp;author=Z%20Han&amp;author=Y%20Wang&amp;author=L%20Zhou&amp;author=P%20Wang&amp;author=B%20Yan&amp;publication_year=2023&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_073">
<span class="label">73.</span><cite>Gong K, Johnson K, El Fakhri G, Li Q, Pan T. PET image denoising based on denoising diffusion probabilistic model. Eur J Nucl Med Mol Imaging. 2024;51:358–68. doi: 10.1007/s00259-023-06417-8.</cite> [<a href="https://doi.org/10.1007/s00259-023-06417-8" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10958486/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37787849/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Eur%20J%20Nucl%20Med%20Mol%20Imaging&amp;title=PET%20image%20denoising%20based%20on%20denoising%20diffusion%20probabilistic%20model&amp;author=K%20Gong&amp;author=K%20Johnson&amp;author=G%20El%20Fakhri&amp;author=Q%20Li&amp;author=T%20Pan&amp;volume=51&amp;publication_year=2024&amp;pages=358-68&amp;pmid=37787849&amp;doi=10.1007/s00259-023-06417-8&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_074">
<span class="label">74.</span><cite>Bundschuh RA, Lütje S, Bundschuh L, Lapa C, Higuchi T, Hartrampf PE, et al.  High interobserver agreement on PSMA PET/CT even in the absence of clinical data. Clin Nucl Med. 2023;48:207–12. doi: 10.1097/rlu.0000000000004524.</cite> [<a href="https://doi.org/10.1097/rlu.0000000000004524" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9907678/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36723879/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Clin%20Nucl%20Med&amp;title=High%20interobserver%20agreement%20on%20PSMA%20PET/CT%20even%20in%20the%20absence%20of%20clinical%20data&amp;author=RA%20Bundschuh&amp;author=S%20L%C3%BCtje&amp;author=L%20Bundschuh&amp;author=C%20Lapa&amp;author=T%20Higuchi&amp;volume=48&amp;publication_year=2023&amp;pages=207-12&amp;pmid=36723879&amp;doi=10.1097/rlu.0000000000004524&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_075">
<span class="label">75.</span><cite>Leung KH, Rowe SP, Pomper MG, Du Y. A three-stage, deep learning, ensemble approach for prognosis in patients with Parkinson’s disease. EJNMMI Res. 2021;11:52. doi: 10.1186/s13550-021-00795-6.</cite> [<a href="https://doi.org/10.1186/s13550-021-00795-6" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8184905/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34100134/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=EJNMMI%20Res&amp;title=A%20three-stage,%20deep%20learning,%20ensemble%20approach%20for%20prognosis%20in%20patients%20with%20Parkinson%E2%80%99s%20disease&amp;author=KH%20Leung&amp;author=SP%20Rowe&amp;author=MG%20Pomper&amp;author=Y%20Du&amp;volume=11&amp;publication_year=2021&amp;pages=52&amp;pmid=34100134&amp;doi=10.1186/s13550-021-00795-6&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_076">
<span class="label">76.</span><cite>Islam S, Aziz MT, Nabil HR, Jim JR, Mridha MF, Kabir MM, et al.  Generative adversarial networks (GANs) in medical imaging: advancements, applications, and challenges. IEEE Access. 2024;12:35728–53. doi: 10.1109/access.2024.3370848.</cite> [<a href="https://doi.org/10.1109/access.2024.3370848" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Access&amp;title=Generative%20adversarial%20networks%20(GANs)%20in%20medical%20imaging:%20advancements,%20applications,%20and%20challenges&amp;author=S%20Islam&amp;author=MT%20Aziz&amp;author=HR%20Nabil&amp;author=JR%20Jim&amp;author=MF%20Mridha&amp;volume=12&amp;publication_year=2024&amp;pages=35728-53&amp;doi=10.1109/access.2024.3370848&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_077">
<span class="label">77.</span><cite>Sai S, Gaur A, Sai R, Chamola V, Guizani M, Rodrigues JJPC. Generative AI for transformative healthcare: a comprehensive study of emerging models, applications, case studies, and limitations. IEEE Access. 2024;12:31078–106. doi: 10.1109/access.2024.3367715.</cite> [<a href="https://doi.org/10.1109/access.2024.3367715" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Access&amp;title=Generative%20AI%20for%20transformative%20healthcare:%20a%20comprehensive%20study%20of%20emerging%20models,%20applications,%20case%20studies,%20and%20limitations&amp;author=S%20Sai&amp;author=A%20Gaur&amp;author=R%20Sai&amp;author=V%20Chamola&amp;author=M%20Guizani&amp;volume=12&amp;publication_year=2024&amp;pages=31078-106&amp;doi=10.1109/access.2024.3367715&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_078">
<span class="label">78.</span><cite>Jha D, Rauniyar A, Hagos DH, Sharma V, Tomar NK, Zhang Z, et al.   MICCAI workshop on fairness of AI in medical imaging. Morocco: Springer; 2024. Practical and ethical considerations for generative AI in medical imaging; pp. 176–87.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=MICCAI%20workshop%20on%20fairness%20of%20AI%20in%20medical%20imaging&amp;author=D%20Jha&amp;author=A%20Rauniyar&amp;author=DH%20Hagos&amp;author=V%20Sharma&amp;author=NK%20Tomar&amp;publication_year=2024&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_079">
<span class="label">79.</span><cite>Teo CTH, Abdollahzadeh M, Cheung NM.  Proc AAAI conf artif intell. 2023. Fair generative models via transfer learning; pp. 2429–37.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=Proc%20AAAI%20conf%20artif%20intell&amp;author=CTH%20Teo&amp;author=M%20Abdollahzadeh&amp;author=NM%20Cheung&amp;publication_year=2023&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_080">
<span class="label">80.</span><cite>Guan H, Yap PT, Bozoki A, Liu M. Federated learning for medical image analysis: a survey. Pattern Recognit. 2024;151 doi: 10.1016/j.patcog.2024.110424.</cite> [<a href="https://doi.org/10.1016/j.patcog.2024.110424" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10976951/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38559674/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Pattern%20Recognit&amp;title=Federated%20learning%20for%20medical%20image%20analysis:%20a%20survey&amp;author=H%20Guan&amp;author=PT%20Yap&amp;author=A%20Bozoki&amp;author=M%20Liu&amp;volume=151&amp;publication_year=2024&amp;pmid=38559674&amp;doi=10.1016/j.patcog.2024.110424&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_081">
<span class="label">81.</span><cite>Holzschuh JC, Mix M, Freitag MT, Hölscher T, Braune A, Kotzerke J, et al.  The impact of multicentric datasets for the automated tumor delineation in primary prostate cancer using convolutional neural networks on 18F-PSMA-1007 PET. Radiat Oncol. 2024;19 doi: 10.1186/s13014-024-02491-w.</cite> [<a href="https://doi.org/10.1186/s13014-024-02491-w" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11304577/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39113123/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Radiat%20Oncol&amp;title=The%20impact%20of%20multicentric%20datasets%20for%20the%20automated%20tumor%20delineation%20in%20primary%20prostate%20cancer%20using%20convolutional%20neural%20networks%20on%2018F-PSMA-1007%20PET&amp;author=JC%20Holzschuh&amp;author=M%20Mix&amp;author=MT%20Freitag&amp;author=T%20H%C3%B6lscher&amp;author=A%20Braune&amp;volume=19&amp;publication_year=2024&amp;pmid=39113123&amp;doi=10.1186/s13014-024-02491-w&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_082">
<span class="label">82.</span><cite>Miyato T, Kataoka T, Koyama M, Yoshida Y. Spectral normalization for generative adversarial networks. . 2018 arXiv preprint arXiv:1802.05957.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=.&amp;title=Spectral%20normalization%20for%20generative%20adversarial%20networks&amp;author=T%20Miyato&amp;author=T%20Kataoka&amp;author=M%20Koyama&amp;author=Y%20Yoshida&amp;publication_year=2018&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_083">
<span class="label">83.</span><cite>Zhao J, Hou X, Pan M, Zhang H. Attention-based generative adversarial network in medical imaging: a narrative review. Comput Biol Med. 2022;149:105948. doi: 10.1016/j.compbiomed.2022.105948.</cite> [<a href="https://doi.org/10.1016/j.compbiomed.2022.105948" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35994931/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Comput%20Biol%20Med&amp;title=Attention-based%20generative%20adversarial%20network%20in%20medical%20imaging:%20a%20narrative%20review&amp;author=J%20Zhao&amp;author=X%20Hou&amp;author=M%20Pan&amp;author=H%20Zhang&amp;volume=149&amp;publication_year=2022&amp;pages=105948&amp;pmid=35994931&amp;doi=10.1016/j.compbiomed.2022.105948&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_084">
<span class="label">84.</span><cite>Werner RA, Habacha B, Lütje S, Bundschuh L, Kosmala A, Essler M, et al.  Lack of repeatability of radiomic features derived from PET scans: results from a 18F-DCFPyL test–retest cohort. Prostate. 2023;83:547–54. doi: 10.1002/pros.24483.</cite> [<a href="https://doi.org/10.1002/pros.24483" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36632656/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Prostate&amp;title=Lack%20of%20repeatability%20of%20radiomic%20features%20derived%20from%20PET%20scans:%20results%20from%20a%2018F-DCFPyL%20test%E2%80%93retest%20cohort&amp;author=RA%20Werner&amp;author=B%20Habacha&amp;author=S%20L%C3%BCtje&amp;author=L%20Bundschuh&amp;author=A%20Kosmala&amp;volume=83&amp;publication_year=2023&amp;pages=547-54&amp;pmid=36632656&amp;doi=10.1002/pros.24483&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_085">
<span class="label">85.</span><cite>Singh NK, Raza K. Medical image generation using generative adversarial networks: a review. Health Inform. 2021;932:77–96. doi: 10.1007/978-981-15-9735-0_5.</cite> [<a href="https://doi.org/10.1007/978-981-15-9735-0_5" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Health%20Inform&amp;title=Medical%20image%20generation%20using%20generative%20adversarial%20networks:%20a%20review&amp;author=NK%20Singh&amp;author=K%20Raza&amp;volume=932&amp;publication_year=2021&amp;pages=77-96&amp;doi=10.1007/978-981-15-9735-0_5&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_086">
<span class="label">86.</span><cite>Gong M, Chen S, Chen Q, Zeng Y, Zhang Y. Generative adversarial networks in medical image processing. Curr Pharm Des. 2020;27:1856–68. doi: 10.2174/1381612826666201125110710.</cite> [<a href="https://doi.org/10.2174/1381612826666201125110710" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33238866/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Curr%20Pharm%20Des&amp;title=Generative%20adversarial%20networks%20in%20medical%20image%20processing&amp;author=M%20Gong&amp;author=S%20Chen&amp;author=Q%20Chen&amp;author=Y%20Zeng&amp;author=Y%20Zhang&amp;volume=27&amp;publication_year=2020&amp;pages=1856-68&amp;pmid=33238866&amp;doi=10.2174/1381612826666201125110710&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_087">
<span class="label">87.</span><cite>Skandarani Y, Jodoin PM, Lalande A. GANs for medical image synthesis: an empirical study. J Imaging. 2023;9 doi: 10.3390/jimaging9030069.</cite> [<a href="https://doi.org/10.3390/jimaging9030069" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10055771/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36976120/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Imaging&amp;title=GANs%20for%20medical%20image%20synthesis:%20an%20empirical%20study&amp;author=Y%20Skandarani&amp;author=PM%20Jodoin&amp;author=A%20Lalande&amp;volume=9&amp;publication_year=2023&amp;pmid=36976120&amp;doi=10.3390/jimaging9030069&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="j_mr-2024-0086_ref_088">
<span class="label">88.</span><cite>Gonog L, Zhou Y.  2019 14th IEEE conf ind electron appl (ICIEA) Xi’an, China: IEEE; 2019. A review: generative adversarial networks; pp. 505–10.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=2019%2014th%20IEEE%20conf%20ind%20electron%20appl%20(ICIEA)&amp;author=L%20Gonog&amp;author=Y%20Zhou&amp;publication_year=2019&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
</ul></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from Medical Review are provided here courtesy of <strong>De Gruyter</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1515/mr-2024-0086"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/mr-5-4-mr-2024-0086.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (2.2 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12362063/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12362063/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12362063%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12362063/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12362063/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12362063/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40838104/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12362063/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40838104/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12362063/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12362063/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="Ft71bRZOc756XalpCE1R3jHvQRbmIhUM2vleKIjHmW8NzW5gp9ZA0LXeQCygRRac">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
    

    </body>
</html>
