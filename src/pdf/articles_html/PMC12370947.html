
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            Multimodal AI for risk stratification in autism spectrum disorder: integrating voice and screening tools - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="D2E4A4718AF224F305A47100391247FA.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="npjdigitmed">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370947/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="NPJ Digital Medicine">
<meta name="citation_title" content="Multimodal AI for risk stratification in autism spectrum disorder: integrating voice and screening tools">
<meta name="citation_author" content="Sookyung Bae">
<meta name="citation_author_institution" content="Department of Integrated Medicine, Yonsei University College of Medicine, Seoul, Republic of Korea">
<meta name="citation_author" content="Junho Hong">
<meta name="citation_author_institution" content="Department. of Artificial intelligence, Yonsei University, Seoul, Republic of Korea">
<meta name="citation_author" content="Sungji Ha">
<meta name="citation_author_institution" content="Department of Psychiatry, Institute of Behavioral Science in Medicine, Yonsei University College of Medicine, Seoul, Republic of Korea">
<meta name="citation_author" content="Jiwoo Moon">
<meta name="citation_author_institution" content="Department of Biomedical and Mechanical Engineering, Ewha Womans University, Seoul, Republic of Korea">
<meta name="citation_author" content="Jaeeun Yu">
<meta name="citation_author_institution" content="Department of Psychiatry, Institute of Behavioral Science in Medicine, Yonsei University College of Medicine, Seoul, Republic of Korea">
<meta name="citation_author" content="Hangnyoung Choi">
<meta name="citation_author_institution" content="Department of Children and Adolescent Psychiatry, Department of Psychiatry, Institute of Behavioral Science in Medicine, Yonsei University College of Medicine, Severance Hospital, Seoul, Republic of Korea">
<meta name="citation_author" content="Junghan Lee">
<meta name="citation_author_institution" content="Department of Children and Adolescent Psychiatry, Department of Psychiatry, Institute of Behavioral Science in Medicine, Yonsei University College of Medicine, Severance Hospital, Seoul, Republic of Korea">
<meta name="citation_author" content="Ryemi Do">
<meta name="citation_author_institution" content="Biomedical Research Institute, Seoul National University Hospital, Seoul, Republic of Korea">
<meta name="citation_author" content="Hewoen Sim">
<meta name="citation_author_institution" content="Biomedical Research Institute, Seoul National University Hospital, Seoul, Republic of Korea">
<meta name="citation_author" content="Hanna Kim">
<meta name="citation_author_institution" content="Biomedical Research Institute, Seoul National University Hospital, Seoul, Republic of Korea">
<meta name="citation_author" content="Hyojeong Lim">
<meta name="citation_author_institution" content="Biomedical Research Institute, Seoul National University Hospital, Seoul, Republic of Korea">
<meta name="citation_author" content="Min-Hyeon Park">
<meta name="citation_author_institution" content="Department of Psychiatry, Eunpyeong St. Mary’s Hospital, The Catholic University of Korea, Seoul, Republic of Korea">
<meta name="citation_author" content="Eunseol Ko">
<meta name="citation_author_institution" content="Department of Psychiatry, Eunpyeong St. Mary’s Hospital, College of Medicine, The Catholic University of Korea, Seoul, Republic of Korea">
<meta name="citation_author" content="Chan-Mo Yang">
<meta name="citation_author_institution" content="Department of Psychiatry, Wonkwang University Hospital, Iksan, Republic of Korea">
<meta name="citation_author_institution" content="Department of Psychiatry, School of Medicine, Wonkwang University, Iksan, Republic of Korea">
<meta name="citation_author" content="Dongho Lee">
<meta name="citation_author_institution" content="Department of Psychiatry, Wonkwang University Hospital, Iksan, Republic of Korea">
<meta name="citation_author" content="Heejeong Yoo">
<meta name="citation_author_institution" content="Department of Psychiatry, Seoul National University Bundang Hospital, Seongnam, Republic of Korea">
<meta name="citation_author_institution" content="Department of Psychiatry, Seoul National University College of Medicine, Seoul, Republic of Korea">
<meta name="citation_author" content="Yoojeong Lee">
<meta name="citation_author_institution" content="Department of Psychiatry, Seoul National University Bundang Hospital, Seongnam, Republic of Korea">
<meta name="citation_author" content="Guiyoung Bong">
<meta name="citation_author_institution" content="Department of Psychiatry, Seoul National University Bundang Hospital, Seongnam, Republic of Korea">
<meta name="citation_author" content="Johanna Inhyang Kim">
<meta name="citation_author_institution" content="Department of Psychiatry, Hanyang University College of Medicine, Seoul, Republic of Korea">
<meta name="citation_author" content="Haneul Sung">
<meta name="citation_author_institution" content="Institute of Mental Health, Hanyang University Industry-University Cooperation Foundation, Seoul, Republic of Korea">
<meta name="citation_author" content="Hyo-Won Kim">
<meta name="citation_author_institution" content="Department of Psychiatry, Asan Medical Center, University of Ulsan College of Medicine, Seoul, Republic of Korea">
<meta name="citation_author" content="Eunji Jung">
<meta name="citation_author_institution" content="Yonsei Jaram Psychiatry Clinic, Seoul, Republic of Korea">
<meta name="citation_author" content="Seungwon Chung">
<meta name="citation_author_institution" content="Department of Psychiatry, Chungbuk National University Hospital, Cheongju, Republic of Korea">
<meta name="citation_author" content="Jung-Woo Son">
<meta name="citation_author_institution" content="Department of Psychiatry, Chungbuk National University Hospital, Cheongju, Republic of Korea">
<meta name="citation_author" content="Jae Hyun Yoo">
<meta name="citation_author_institution" content="Department of Psychiatry, Seoul St. Mary’s Hospital, College of Medicine, The Catholic University of Korea, Seoul, Republic of Korea">
<meta name="citation_author" content="Sekye Jeon">
<meta name="citation_author_institution" content="Department of Psychiatry, Seoul St. Mary’s Hospital, College of Medicine, The Catholic University of Korea, Seoul, Republic of Korea">
<meta name="citation_author" content="Hwiyoung Kim">
<meta name="citation_author_institution" content="Department. of Artificial intelligence, Yonsei University, Seoul, Republic of Korea">
<meta name="citation_author_institution" content="Department of Neurosurgery, Yonsei University College of Medicine, Seoul, Republic of Korea">
<meta name="citation_author" content="Bung-Nyun Kim">
<meta name="citation_author_institution" content="Division of Children and Adolescent Psychiatry, Department of Psychiatry, Seoul National University Hospital, Seoul, Republic of Korea">
<meta name="citation_author" content="Keun-Ah Cheon">
<meta name="citation_author_institution" content="Department of Children and Adolescent Psychiatry, Department of Psychiatry, Institute of Behavioral Science in Medicine, Yonsei University College of Medicine, Severance Hospital, Seoul, Republic of Korea">
<meta name="citation_publication_date" content="2025 Aug 21">
<meta name="citation_volume" content="8">
<meta name="citation_firstpage" content="538">
<meta name="citation_doi" content="10.1038/s41746-025-01914-6">
<meta name="citation_pmid" content="40841482">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370947/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370947/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370947/pdf/41746_2025_Article_1914.pdf">
<meta name="description" content="Early Autism Spectrum Disorder (ASD) identification is crucial but resource-intensive. This study evaluated a novel two-stage multimodal AI framework for scalable ASD screening using data from 1242 children (18–48 months). A mobile application ...">
<meta name="og:title" content="Multimodal AI for risk stratification in autism spectrum disorder: integrating voice and screening tools">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="Early Autism Spectrum Disorder (ASD) identification is crucial but resource-intensive. This study evaluated a novel two-stage multimodal AI framework for scalable ASD screening using data from 1242 children (18–48 months). A mobile application ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370947/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12370947">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1038/s41746-025-01914-6"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/41746_2025_Article_1914.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12370947%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12370947/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12370947/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370947/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-npjdigitmed.jpg" alt="NPJ Digital Medicine logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to NPJ Digital Medicine" title="Link to NPJ Digital Medicine" shape="default" href="https://www.nature.com/npjdigitalmed/" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">NPJ Digit Med</button></div>. 2025 Aug 21;8:538. doi: <a href="https://doi.org/10.1038/s41746-025-01914-6" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1038/s41746-025-01914-6</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22NPJ%20Digit%20Med%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22NPJ%20Digit%20Med%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22NPJ%20Digit%20Med%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22NPJ%20Digit%20Med%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Multimodal AI for risk stratification in autism spectrum disorder: integrating voice and screening tools</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Bae%20S%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Sookyung Bae</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Sookyung Bae</span></h3>
<div class="p">
<sup>1</sup>Department of Integrated Medicine, Yonsei University College of Medicine, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Bae%20S%22%5BAuthor%5D" class="usa-link"><span class="name western">Sookyung Bae</span></a>
</div>
</div>
<sup>1</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Hong%20J%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Junho Hong</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">Junho Hong</span></h3>
<div class="p">
<sup>2</sup>Department. of Artificial intelligence, Yonsei University, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Hong%20J%22%5BAuthor%5D" class="usa-link"><span class="name western">Junho Hong</span></a>
</div>
</div>
<sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Ha%20S%22%5BAuthor%5D" class="usa-link" aria-describedby="id3"><span class="name western">Sungji Ha</span></a><div hidden="hidden" id="id3">
<h3><span class="name western">Sungji Ha</span></h3>
<div class="p">
<sup>3</sup>Department of Psychiatry, Institute of Behavioral Science in Medicine, Yonsei University College of Medicine, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Ha%20S%22%5BAuthor%5D" class="usa-link"><span class="name western">Sungji Ha</span></a>
</div>
</div>
<sup>3</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Moon%20J%22%5BAuthor%5D" class="usa-link" aria-describedby="id4"><span class="name western">Jiwoo Moon</span></a><div hidden="hidden" id="id4">
<h3><span class="name western">Jiwoo Moon</span></h3>
<div class="p">
<sup>4</sup>Department of Biomedical and Mechanical Engineering, Ewha Womans University, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Moon%20J%22%5BAuthor%5D" class="usa-link"><span class="name western">Jiwoo Moon</span></a>
</div>
</div>
<sup>4</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Yu%20J%22%5BAuthor%5D" class="usa-link" aria-describedby="id5"><span class="name western">Jaeeun Yu</span></a><div hidden="hidden" id="id5">
<h3><span class="name western">Jaeeun Yu</span></h3>
<div class="p">
<sup>3</sup>Department of Psychiatry, Institute of Behavioral Science in Medicine, Yonsei University College of Medicine, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Yu%20J%22%5BAuthor%5D" class="usa-link"><span class="name western">Jaeeun Yu</span></a>
</div>
</div>
<sup>3</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Choi%20H%22%5BAuthor%5D" class="usa-link" aria-describedby="id6"><span class="name western">Hangnyoung Choi</span></a><div hidden="hidden" id="id6">
<h3><span class="name western">Hangnyoung Choi</span></h3>
<div class="p">
<sup>5</sup>Department of Children and Adolescent Psychiatry, Department of Psychiatry, Institute of Behavioral Science in Medicine, Yonsei University College of Medicine, Severance Hospital, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Choi%20H%22%5BAuthor%5D" class="usa-link"><span class="name western">Hangnyoung Choi</span></a>
</div>
</div>
<sup>5</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Lee%20J%22%5BAuthor%5D" class="usa-link" aria-describedby="id7"><span class="name western">Junghan Lee</span></a><div hidden="hidden" id="id7">
<h3><span class="name western">Junghan Lee</span></h3>
<div class="p">
<sup>5</sup>Department of Children and Adolescent Psychiatry, Department of Psychiatry, Institute of Behavioral Science in Medicine, Yonsei University College of Medicine, Severance Hospital, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Lee%20J%22%5BAuthor%5D" class="usa-link"><span class="name western">Junghan Lee</span></a>
</div>
</div>
<sup>5</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Do%20R%22%5BAuthor%5D" class="usa-link" aria-describedby="id8"><span class="name western">Ryemi Do</span></a><div hidden="hidden" id="id8">
<h3><span class="name western">Ryemi Do</span></h3>
<div class="p">
<sup>6</sup>Biomedical Research Institute, Seoul National University Hospital, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Do%20R%22%5BAuthor%5D" class="usa-link"><span class="name western">Ryemi Do</span></a>
</div>
</div>
<sup>6</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sim%20H%22%5BAuthor%5D" class="usa-link" aria-describedby="id9"><span class="name western">Hewoen Sim</span></a><div hidden="hidden" id="id9">
<h3><span class="name western">Hewoen Sim</span></h3>
<div class="p">
<sup>6</sup>Biomedical Research Institute, Seoul National University Hospital, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sim%20H%22%5BAuthor%5D" class="usa-link"><span class="name western">Hewoen Sim</span></a>
</div>
</div>
<sup>6</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kim%20H%22%5BAuthor%5D" class="usa-link" aria-describedby="id10"><span class="name western">Hanna Kim</span></a><div hidden="hidden" id="id10">
<h3><span class="name western">Hanna Kim</span></h3>
<div class="p">
<sup>6</sup>Biomedical Research Institute, Seoul National University Hospital, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kim%20H%22%5BAuthor%5D" class="usa-link"><span class="name western">Hanna Kim</span></a>
</div>
</div>
<sup>6</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Lim%20H%22%5BAuthor%5D" class="usa-link" aria-describedby="id11"><span class="name western">Hyojeong Lim</span></a><div hidden="hidden" id="id11">
<h3><span class="name western">Hyojeong Lim</span></h3>
<div class="p">
<sup>6</sup>Biomedical Research Institute, Seoul National University Hospital, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Lim%20H%22%5BAuthor%5D" class="usa-link"><span class="name western">Hyojeong Lim</span></a>
</div>
</div>
<sup>6</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Park%20MH%22%5BAuthor%5D" class="usa-link" aria-describedby="id12"><span class="name western">Min-Hyeon Park</span></a><div hidden="hidden" id="id12">
<h3><span class="name western">Min-Hyeon Park</span></h3>
<div class="p">
<sup>7</sup>Department of Psychiatry, Eunpyeong St. Mary’s Hospital, The Catholic University of Korea, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Park%20MH%22%5BAuthor%5D" class="usa-link"><span class="name western">Min-Hyeon Park</span></a>
</div>
</div>
<sup>7</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Ko%20E%22%5BAuthor%5D" class="usa-link" aria-describedby="id13"><span class="name western">Eunseol Ko</span></a><div hidden="hidden" id="id13">
<h3><span class="name western">Eunseol Ko</span></h3>
<div class="p">
<sup>8</sup>Department of Psychiatry, Eunpyeong St. Mary’s Hospital, College of Medicine, The Catholic University of Korea, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Ko%20E%22%5BAuthor%5D" class="usa-link"><span class="name western">Eunseol Ko</span></a>
</div>
</div>
<sup>8</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Yang%20CM%22%5BAuthor%5D" class="usa-link" aria-describedby="id14"><span class="name western">Chan-Mo Yang</span></a><div hidden="hidden" id="id14">
<h3><span class="name western">Chan-Mo Yang</span></h3>
<div class="p">
<sup>9</sup>Department of Psychiatry, Wonkwang University Hospital, Iksan, Republic of Korea </div>
<div class="p">
<sup>10</sup>Department of Psychiatry, School of Medicine, Wonkwang University, Iksan, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Yang%20CM%22%5BAuthor%5D" class="usa-link"><span class="name western">Chan-Mo Yang</span></a>
</div>
</div>
<sup>9,</sup><sup>10</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Lee%20D%22%5BAuthor%5D" class="usa-link" aria-describedby="id15"><span class="name western">Dongho Lee</span></a><div hidden="hidden" id="id15">
<h3><span class="name western">Dongho Lee</span></h3>
<div class="p">
<sup>9</sup>Department of Psychiatry, Wonkwang University Hospital, Iksan, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Lee%20D%22%5BAuthor%5D" class="usa-link"><span class="name western">Dongho Lee</span></a>
</div>
</div>
<sup>9</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Yoo%20H%22%5BAuthor%5D" class="usa-link" aria-describedby="id16"><span class="name western">Heejeong Yoo</span></a><div hidden="hidden" id="id16">
<h3><span class="name western">Heejeong Yoo</span></h3>
<div class="p">
<sup>11</sup>Department of Psychiatry, Seoul National University Bundang Hospital, Seongnam, Republic of Korea </div>
<div class="p">
<sup>12</sup>Department of Psychiatry, Seoul National University College of Medicine, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Yoo%20H%22%5BAuthor%5D" class="usa-link"><span class="name western">Heejeong Yoo</span></a>
</div>
</div>
<sup>11,</sup><sup>12</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Lee%20Y%22%5BAuthor%5D" class="usa-link" aria-describedby="id17"><span class="name western">Yoojeong Lee</span></a><div hidden="hidden" id="id17">
<h3><span class="name western">Yoojeong Lee</span></h3>
<div class="p">
<sup>11</sup>Department of Psychiatry, Seoul National University Bundang Hospital, Seongnam, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Lee%20Y%22%5BAuthor%5D" class="usa-link"><span class="name western">Yoojeong Lee</span></a>
</div>
</div>
<sup>11</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Bong%20G%22%5BAuthor%5D" class="usa-link" aria-describedby="id18"><span class="name western">Guiyoung Bong</span></a><div hidden="hidden" id="id18">
<h3><span class="name western">Guiyoung Bong</span></h3>
<div class="p">
<sup>11</sup>Department of Psychiatry, Seoul National University Bundang Hospital, Seongnam, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Bong%20G%22%5BAuthor%5D" class="usa-link"><span class="name western">Guiyoung Bong</span></a>
</div>
</div>
<sup>11</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kim%20JI%22%5BAuthor%5D" class="usa-link" aria-describedby="id19"><span class="name western">Johanna Inhyang Kim</span></a><div hidden="hidden" id="id19">
<h3><span class="name western">Johanna Inhyang Kim</span></h3>
<div class="p">
<sup>13</sup>Department of Psychiatry, Hanyang University College of Medicine, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kim%20JI%22%5BAuthor%5D" class="usa-link"><span class="name western">Johanna Inhyang Kim</span></a>
</div>
</div>
<sup>13</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sung%20H%22%5BAuthor%5D" class="usa-link" aria-describedby="id20"><span class="name western">Haneul Sung</span></a><div hidden="hidden" id="id20">
<h3><span class="name western">Haneul Sung</span></h3>
<div class="p">
<sup>14</sup>Institute of Mental Health, Hanyang University Industry-University Cooperation Foundation, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sung%20H%22%5BAuthor%5D" class="usa-link"><span class="name western">Haneul Sung</span></a>
</div>
</div>
<sup>14</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kim%20HW%22%5BAuthor%5D" class="usa-link" aria-describedby="id21"><span class="name western">Hyo-Won Kim</span></a><div hidden="hidden" id="id21">
<h3><span class="name western">Hyo-Won Kim</span></h3>
<div class="p">
<sup>15</sup>Department of Psychiatry, Asan Medical Center, University of Ulsan College of Medicine, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kim%20HW%22%5BAuthor%5D" class="usa-link"><span class="name western">Hyo-Won Kim</span></a>
</div>
</div>
<sup>15</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Jung%20E%22%5BAuthor%5D" class="usa-link" aria-describedby="id22"><span class="name western">Eunji Jung</span></a><div hidden="hidden" id="id22">
<h3><span class="name western">Eunji Jung</span></h3>
<div class="p">
<sup>16</sup>Yonsei Jaram Psychiatry Clinic, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Jung%20E%22%5BAuthor%5D" class="usa-link"><span class="name western">Eunji Jung</span></a>
</div>
</div>
<sup>16</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Chung%20S%22%5BAuthor%5D" class="usa-link" aria-describedby="id23"><span class="name western">Seungwon Chung</span></a><div hidden="hidden" id="id23">
<h3><span class="name western">Seungwon Chung</span></h3>
<div class="p">
<sup>17</sup>Department of Psychiatry, Chungbuk National University Hospital, Cheongju, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Chung%20S%22%5BAuthor%5D" class="usa-link"><span class="name western">Seungwon Chung</span></a>
</div>
</div>
<sup>17</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Son%20JW%22%5BAuthor%5D" class="usa-link" aria-describedby="id24"><span class="name western">Jung-Woo Son</span></a><div hidden="hidden" id="id24">
<h3><span class="name western">Jung-Woo Son</span></h3>
<div class="p">
<sup>17</sup>Department of Psychiatry, Chungbuk National University Hospital, Cheongju, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Son%20JW%22%5BAuthor%5D" class="usa-link"><span class="name western">Jung-Woo Son</span></a>
</div>
</div>
<sup>17</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Yoo%20JH%22%5BAuthor%5D" class="usa-link" aria-describedby="id25"><span class="name western">Jae Hyun Yoo</span></a><div hidden="hidden" id="id25">
<h3><span class="name western">Jae Hyun Yoo</span></h3>
<div class="p">
<sup>18</sup>Department of Psychiatry, Seoul St. Mary’s Hospital, College of Medicine, The Catholic University of Korea, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Yoo%20JH%22%5BAuthor%5D" class="usa-link"><span class="name western">Jae Hyun Yoo</span></a>
</div>
</div>
<sup>18</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Jeon%20S%22%5BAuthor%5D" class="usa-link" aria-describedby="id26"><span class="name western">Sekye Jeon</span></a><div hidden="hidden" id="id26">
<h3><span class="name western">Sekye Jeon</span></h3>
<div class="p">
<sup>18</sup>Department of Psychiatry, Seoul St. Mary’s Hospital, College of Medicine, The Catholic University of Korea, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Jeon%20S%22%5BAuthor%5D" class="usa-link"><span class="name western">Sekye Jeon</span></a>
</div>
</div>
<sup>18</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kim%20H%22%5BAuthor%5D" class="usa-link" aria-describedby="id27"><span class="name western">Hwiyoung Kim</span></a><div hidden="hidden" id="id27">
<h3><span class="name western">Hwiyoung Kim</span></h3>
<div class="p">
<sup>2</sup>Department. of Artificial intelligence, Yonsei University, Seoul, Republic of Korea </div>
<div class="p">
<sup>19</sup>Department of Neurosurgery, Yonsei University College of Medicine, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kim%20H%22%5BAuthor%5D" class="usa-link"><span class="name western">Hwiyoung Kim</span></a>
</div>
</div>
<sup>2,</sup><sup>19,</sup><sup>✉</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kim%20BN%22%5BAuthor%5D" class="usa-link" aria-describedby="id28"><span class="name western">Bung-Nyun Kim</span></a><div hidden="hidden" id="id28">
<h3><span class="name western">Bung-Nyun Kim</span></h3>
<div class="p">
<sup>20</sup>Division of Children and Adolescent Psychiatry, Department of Psychiatry, Seoul National University Hospital, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kim%20BN%22%5BAuthor%5D" class="usa-link"><span class="name western">Bung-Nyun Kim</span></a>
</div>
</div>
<sup>20,</sup><sup>✉</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Cheon%20KA%22%5BAuthor%5D" class="usa-link" aria-describedby="id29"><span class="name western">Keun-Ah Cheon</span></a><div hidden="hidden" id="id29">
<h3><span class="name western">Keun-Ah Cheon</span></h3>
<div class="p">
<sup>5</sup>Department of Children and Adolescent Psychiatry, Department of Psychiatry, Institute of Behavioral Science in Medicine, Yonsei University College of Medicine, Severance Hospital, Seoul, Republic of Korea </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Cheon%20KA%22%5BAuthor%5D" class="usa-link"><span class="name western">Keun-Ah Cheon</span></a>
</div>
</div>
<sup>5,</sup><sup>✉</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="Aff1">
<sup>1</sup>Department of Integrated Medicine, Yonsei University College of Medicine, Seoul, Republic of Korea </div>
<div id="Aff2">
<sup>2</sup>Department. of Artificial intelligence, Yonsei University, Seoul, Republic of Korea </div>
<div id="Aff3">
<sup>3</sup>Department of Psychiatry, Institute of Behavioral Science in Medicine, Yonsei University College of Medicine, Seoul, Republic of Korea </div>
<div id="Aff4">
<sup>4</sup>Department of Biomedical and Mechanical Engineering, Ewha Womans University, Seoul, Republic of Korea </div>
<div id="Aff5">
<sup>5</sup>Department of Children and Adolescent Psychiatry, Department of Psychiatry, Institute of Behavioral Science in Medicine, Yonsei University College of Medicine, Severance Hospital, Seoul, Republic of Korea </div>
<div id="Aff6">
<sup>6</sup>Biomedical Research Institute, Seoul National University Hospital, Seoul, Republic of Korea </div>
<div id="Aff7">
<sup>7</sup>Department of Psychiatry, Eunpyeong St. Mary’s Hospital, The Catholic University of Korea, Seoul, Republic of Korea </div>
<div id="Aff8">
<sup>8</sup>Department of Psychiatry, Eunpyeong St. Mary’s Hospital, College of Medicine, The Catholic University of Korea, Seoul, Republic of Korea </div>
<div id="Aff9">
<sup>9</sup>Department of Psychiatry, Wonkwang University Hospital, Iksan, Republic of Korea </div>
<div id="Aff10">
<sup>10</sup>Department of Psychiatry, School of Medicine, Wonkwang University, Iksan, Republic of Korea </div>
<div id="Aff11">
<sup>11</sup>Department of Psychiatry, Seoul National University Bundang Hospital, Seongnam, Republic of Korea </div>
<div id="Aff12">
<sup>12</sup>Department of Psychiatry, Seoul National University College of Medicine, Seoul, Republic of Korea </div>
<div id="Aff13">
<sup>13</sup>Department of Psychiatry, Hanyang University College of Medicine, Seoul, Republic of Korea </div>
<div id="Aff14">
<sup>14</sup>Institute of Mental Health, Hanyang University Industry-University Cooperation Foundation, Seoul, Republic of Korea </div>
<div id="Aff15">
<sup>15</sup>Department of Psychiatry, Asan Medical Center, University of Ulsan College of Medicine, Seoul, Republic of Korea </div>
<div id="Aff16">
<sup>16</sup>Yonsei Jaram Psychiatry Clinic, Seoul, Republic of Korea </div>
<div id="Aff17">
<sup>17</sup>Department of Psychiatry, Chungbuk National University Hospital, Cheongju, Republic of Korea </div>
<div id="Aff18">
<sup>18</sup>Department of Psychiatry, Seoul St. Mary’s Hospital, College of Medicine, The Catholic University of Korea, Seoul, Republic of Korea </div>
<div id="Aff19">
<sup>19</sup>Department of Neurosurgery, Yonsei University College of Medicine, Seoul, Republic of Korea </div>
<div id="Aff20">
<sup>20</sup>Division of Children and Adolescent Psychiatry, Department of Psychiatry, Seoul National University Hospital, Seoul, Republic of Korea </div>
<div class="author-notes p"><div class="fn" id="_fncrsp93pmc__">
<sup>✉</sup><p class="display-inline">Corresponding author.</p>
</div></div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2025 Apr 4; Accepted 2025 Jul 29; Collection date 2025.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© The Author(s) 2025</div>
<p><strong>Open Access</strong> This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://creativecommons.org/licenses/by-nc-nd/4.0/</a>.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12370947  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40841482/" class="usa-link">40841482</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="Abs1"><h2>Abstract</h2>
<p id="Par1">Early Autism Spectrum Disorder (ASD) identification is crucial but resource-intensive. This study evaluated a novel two-stage multimodal AI framework for scalable ASD screening using data from 1242 children (18–48 months). A mobile application collected parent-child interaction audio and screening tool data (MCHAT, SCQ-L, SRS). Stage 1 differentiated typically developing from high-risk/ASD children, integrating MCHAT/SCQ-L text with audio features (AUROC 0.942). Stage 2 distinguished high-risk from ASD children by combining task success data with SRS text (AUROC 0.914, Accuracy 0.852). The model’s predicted risk categories strongly agreed with gold-standard ADOS-2 assessments (79.59% accuracy) and correlated significantly (Pearson <em>r</em> = 0.830, <em>p</em> &lt; 0.001). Leveraging mobile data and deep learning, this framework demonstrates potential for accurate, scalable early ASD screening and risk stratification, supporting timely interventions.</p>
<section id="kwd-group1" class="kwd-group"><p><strong>Subject terms:</strong> Autism spectrum disorders, Diagnosis</p></section></section><section id="Sec1"><h2 class="pmc_sec_title">Introduction</h2>
<p id="Par2">Autism Spectrum Disorder (ASD) presents a growing global health challenge, characterized by a complex interplay of social-communication challenges, repetitive behaviors, and sensory processing differences. These characteristics significantly impact on the quality of life and long-term outcomes for individuals with ASD<sup><a href="#CR1" class="usa-link" aria-describedby="CR1">1</a></sup>. The heterogeneous nature of the disorder, with various presentations and varying severities, underscores the need for innovative diagnostic approaches, including those capable of identifying distinct behavioral phenotypes within the spectrum<sup><a href="#CR2" class="usa-link" aria-describedby="CR2">2</a></sup>. Crucially, early identification and intervention have been consistently shown to optimize developmental trajectories, reduce symptom severity, and improve overall well-being<sup><a href="#CR3" class="usa-link" aria-describedby="CR3">3</a>,<a href="#CR4" class="usa-link" aria-describedby="CR4">4</a></sup>. However, widely accepted diagnostic tools such as the Autism Diagnostic Observation Schedule (ADOS-2)<sup><a href="#CR5" class="usa-link" aria-describedby="CR5">5</a></sup> and the Autism Diagnostic Interview-Revised (ADI-R) are resource-intensive, demanding substantial clinical expertise and extensive time<sup><a href="#CR6" class="usa-link" aria-describedby="CR6">6</a></sup>. This high resource requirement can delay or limit access to timely assessments, particularly in under-resourced areas, hindering the potential benefits of early intervention. Addressing this challenge, digital health innovations leveraging artificial intelligence (AI) offer a promising avenue for scalable, objective, and automated diagnostic support<sup><a href="#CR7" class="usa-link" aria-describedby="CR7">7</a>–<a href="#CR10" class="usa-link" aria-describedby="CR10">10</a></sup>.</p>
<p id="Par3">It is crucial, however, to clarify that these AI tools are intended to aid in detection and risk stratification, not to replace comprehensive clinical diagnosis. Many existing AI applications rely on a single data modality. For instance, screening questionnaires like the M-CHAT-R/F<sup><a href="#CR11" class="usa-link" aria-describedby="CR11">11</a></sup> and SCQ<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup>, while widely used, depend on subjective parent reports which may not fully capture the complexity or subtle signs of ASD<sup><a href="#CR11" class="usa-link" aria-describedby="CR11">11</a>,<a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup>. Moreover, traditional use of tools like the M-CHAT-R/F or SCQ often focuses primarily on the overall score, potentially overlooking the valuable semantic information contained within individual items. Drawing inspiration from work developing structured ASD phenotype descriptions using natural language processing (NLP)<sup><a href="#CR13" class="usa-link" aria-describedby="CR13">13</a></sup>, this study adopts a novel approach. We employ NLP techniques not just on the scores, but on the text of the screening questionnaires themselves, aiming to extract meaningful descriptions and identify specific behavioral traits associated with ASD-related terms used in the questions.</p>
<p id="Par4">Other AI approaches analyzing facial expressions<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a></sup> or neuroimaging data<sup><a href="#CR15" class="usa-link" aria-describedby="CR15">15</a>,<a href="#CR16" class="usa-link" aria-describedby="CR16">16</a></sup> show potential but may require specialized equipment or yield results comparable to human experts, limiting widespread practical application for initial screening<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a></sup>. Integrating AI-based aids into primary care shows promise for enhancing efficiency<sup><a href="#CR17" class="usa-link" aria-describedby="CR17">17</a></sup>, but there remains a need for tools that leverage easily accessible, yet rich, data sources.</p>
<p id="Par5">This study introduces and evaluates a novel multimodal AI framework designed to enhance the early screening and identification of ASD risk in young children. Crucially, this framework uniquely integrates two key data sources: (1) voice data extracted directly from videos capturing naturalistic parent-child interactions, and (2) semantically analyzed data derived from the text of standardized ASD screening questionnaires (e.g., M-CHAT-R/F, SCQ, SRS), processed using NLP. The clinical significance of this multimodal approach lies in its potential to create a more robust and reliable early detection signal. It combines objective, quantifiable vocal biomarkers related to language development and social communication, often altered in ASD<sup><a href="#CR18" class="usa-link" aria-describedby="CR18">18</a>,<a href="#CR19" class="usa-link" aria-describedby="CR19">19</a></sup> captured during everyday interactions, with nuanced behavioral trait information extracted from validated screening instruments<sup><a href="#CR11" class="usa-link" aria-describedby="CR11">11</a>,<a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup>. This synergy aims to improve the accuracy and reliability of early screening efforts compared to unimodal approaches, as discussed in related literature<sup><a href="#CR20" class="usa-link" aria-describedby="CR20">20</a>–<a href="#CR23" class="usa-link" aria-describedby="CR23">23</a></sup><sup>.</sup></p>
<p id="Par6">Furthermore, our approach aligns with recent advancements in multimodal fusion techniques, such as those seen in robust multimodal emotion recognition with transformers (e.g., Zhu et al.<sup><a href="#CR11" class="usa-link" aria-describedby="CR11">11</a></sup>), cross-modal fusion for utterance-level analysis<sup><a href="#CR24" class="usa-link" aria-describedby="CR24">24</a></sup> and contextual interaction-based multimodal emotion analysis with enhanced semantic information (e.g., Hazarika et al.<sup><a href="#CR25" class="usa-link" aria-describedby="CR25">25</a></sup>). Similarly, the use of contrastive learning for removing negative information in multimodal analysis (e.g., Wang et al.<sup><a href="#CR26" class="usa-link" aria-describedby="CR26">26</a></sup>) provides a foundation for developing more robust and reliable models.</p>
<p id="Par7">From a clinical perspective, providing a more accurate risk assessment earlier in a child’s development holds substantial utility. Such a tool can assist clinicians in identifying children who warrant prioritized referral for comprehensive diagnostic evaluation. This facilitates more efficient use of limited diagnostic resources, potentially reducing lengthy wait times and enabling quicker access to essential early intervention services⁸. By leveraging readily available data like interaction videos and screening questionnaires (analyzed for content), the framework aims for practical applicability in diverse clinical settings.</p>
<p id="Par8">Despite progress in AI for ASD<sup><a href="#CR7" class="usa-link" aria-describedby="CR7">7</a>,<a href="#CR9" class="usa-link" aria-describedby="CR9">9</a></sup>, and specific analyses of voice<sup><a href="#CR18" class="usa-link" aria-describedby="CR18">18</a>,<a href="#CR19" class="usa-link" aria-describedby="CR19">19</a>,<a href="#CR27" class="usa-link" aria-describedby="CR27">27</a></sup> or multimodal data<sup><a href="#CR8" class="usa-link" aria-describedby="CR8">8</a>,<a href="#CR21" class="usa-link" aria-describedby="CR21">21</a>–<a href="#CR23" class="usa-link" aria-describedby="CR23">23</a>,<a href="#CR28" class="usa-link" aria-describedby="CR28">28</a></sup><sup>,</sup> a research gap persists in developing and validating scalable AI tools that specifically integrate naturalistic voice recordings from interaction videos with semantically processed screening tool data for the explicit purpose of early ASD risk identification and stratification. This gap is particularly relevant in the context of ensuring trustworthy AI systems, as explored in fields like image super-resolution (e.g., Korkmaz et al.<sup><a href="#CR29" class="usa-link" aria-describedby="CR29">29</a></sup>), and leveraging advanced signal processing techniques, such as client-server based recognition systems for emotional and behavioral states (e.g., Zhu et al.<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup>) or WiFi-based non-contact human presence detection (e.g., Zhang et al.<sup><a href="#CR31" class="usa-link" aria-describedby="CR31">31</a></sup>), and dynamic spectral graph anomaly detection (e.g., Zheng et al.<sup><a href="#CR32" class="usa-link" aria-describedby="CR32">32</a></sup>). These advancements highlight the potential for more sophisticated data acquisition and analysis in clinical settings.</p>
<p id="Par9">To address this gap, this study introduces a novel two-stage multimodal AI framework that combines text data (e.g., MCHAT, SCQ, SRS), audio data from parent-child interactions, and hospital clinical information to enhance ASD screening and risk stratification. This framework builds upon prior work and addresses the limitations of unimodal approaches highlighted by Rahman et al. and others<sup><a href="#CR20" class="usa-link" aria-describedby="CR20">20</a></sup>. Specifically, the framework leverages advanced deep learning models like RoBERTa<sup><a href="#CR33" class="usa-link" aria-describedby="CR33">33</a></sup>, known for its strong performance in NLP tasks, and Whisper<sup><a href="#CR34" class="usa-link" aria-describedby="CR34">34</a></sup>, a state-of-the-art speech recognition model, to capture comprehensive information from text and audio data. Recent advances in speech processing, such as pre-trained speech embeddings, have further demonstrated the potential of leveraging audio data to understand spoken language development in children with ASD<sup><a href="#CR18" class="usa-link" aria-describedby="CR18">18</a></sup>. While other audio analysis methods, such as Audio Spectrogram Transformers (ASTs)<sup><a href="#CR35" class="usa-link" aria-describedby="CR35">35</a></sup>, have shown promise in various applications, the present framework utilizes Whisper for its superior speech recognition capabilities, particularly in handling the complexities of child speech and its demonstrated effectiveness in capturing subtle linguistic and prosodic features. The framework incorporates the following key innovations:</p>
<p id="Par10">This framework introduces several key innovations. First, it features multimodal integration by merging semantically processed text-based survey data (via RoBERTa) with audio-derived features from parent-child interactions (processed by Whisper). This allows for a more comprehensive capture of social communication, language, and behavioral indicators than single-modality or score-based approaches. Second, our approach focuses on risk stratification, mapping prediction probabilities to clinical benchmarks such as ADOS-2 scores for actionable risk categorization into “Low Risk,” “Moderate Risk,” and “High Risk” groups<sup><a href="#CR6" class="usa-link" aria-describedby="CR6">6</a></sup>, thereby providing more reliable probability estimates in line with the recommendations of Nixon et al. on the importance of model calibration in deep learning<sup><a href="#CR36" class="usa-link" aria-describedby="CR36">36</a></sup>. Finally, we designed the framework with the potential for scalability and clinical utility, keeping in mind the potential for integration into a Clinical Decision Support System (CDSS). Such integration could support clinical decision-making in screening pathways, improve accessibility, and potentially alleviate clinical workload<sup><a href="#CR3" class="usa-link" aria-describedby="CR3">3</a>,<a href="#CR37" class="usa-link" aria-describedby="CR37">37</a>,<a href="#CR38" class="usa-link" aria-describedby="CR38">38</a></sup>. The CDSS integration is inspired by successful implementations in other domains, as reviewed by Abdar et al.<sup><a href="#CR39" class="usa-link" aria-describedby="CR39">39</a></sup>, highlighting the potential of AI to assist in clinical decision-making<sup><a href="#CR39" class="usa-link" aria-describedby="CR39">39</a></sup>. It also offers the potential for personalized treatment planning, a significant advancement in neurorehabilitation as suggested by Chang et al.<sup><a href="#CR40" class="usa-link" aria-describedby="CR40">40</a></sup>.</p>
<p id="Par11">By integrating these specific multimodal data sources (semantically analyzed questionnaires and voice from videos), employing advanced deep learning tailored to each modality, explicitly addressing model calibration for reliable risk stratification, and considering practical clinical integration, this research aims to provide a scalable, automated tool. The goal is to significantly enhance the accuracy and efficiency of early ASD screening, thereby supporting clinicians in identifying at-risk children sooner. Demonstrating the feasibility and effectiveness of this AI-driven approach aims to pave the way for more accessible and timely support for ASD assessment pathways, ultimately contributing to improved developmental outcomes and quality of life for individuals with ASD and their families by facilitating earlier access to intervention.</p></section><section id="Sec2"><h2 class="pmc_sec_title">Results</h2>
<p id="Par12">This section presents the results of the two-stage AI framework for ASD risk stratification, focusing on model performance, calibration, risk stratification, and correlation with clinical measures.</p>
<section id="Sec3"><h3 class="pmc_sec_title">Stage 1 model performance: differentiating typically developing from at-risk children</h3>
<p id="Par13">The Stage 1 model, a multi-modal neural network based on the “RoBERTa-large” pre-trained model, was trained to distinguish between children with typical development (TD) and those in the combined High-Risk/ASD group. Performance was evaluated using 5-fold cross-validation, yielding an average AUROC of 0.942, accuracy of 0.86, precision of 0.85, recall of 0.85, and F1-score of 0.85 (Table <a href="#Tab1" class="usa-link">1</a>). The consistently high AUC scores across all folds, illustrated in the ROC curves (Fig. <a href="#Fig1" class="usa-link">1</a>), demonstrate the model’s strong and robust ability to discriminate between the groups.</p>
<section class="tw xbox font-sm" id="Tab1"><h4 class="obj_head">Table 1.</h4>
<div class="caption p"><p>Stage 1 model performance across folds (TD vs. High-Risk/ASD)</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th colspan="1" rowspan="1">Fold</th>
<th colspan="1" rowspan="1">AUC</th>
<th colspan="1" rowspan="1">Accuracy</th>
<th colspan="1" rowspan="1">Precision</th>
<th colspan="1" rowspan="1">Recall</th>
<th colspan="1" rowspan="1">F1-Score</th>
</tr></thead>
<tbody>
<tr>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0.95</td>
<td colspan="1" rowspan="1">0.91</td>
<td colspan="1" rowspan="1">0.90</td>
<td colspan="1" rowspan="1">0.90</td>
<td colspan="1" rowspan="1">0.90</td>
</tr>
<tr>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">0.93</td>
<td colspan="1" rowspan="1">0.82</td>
<td colspan="1" rowspan="1">0.81</td>
<td colspan="1" rowspan="1">0.78</td>
<td colspan="1" rowspan="1">0.79</td>
</tr>
<tr>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">0.95</td>
<td colspan="1" rowspan="1">0.85</td>
<td colspan="1" rowspan="1">0.84</td>
<td colspan="1" rowspan="1">0.87</td>
<td colspan="1" rowspan="1">0.84</td>
</tr>
<tr>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">0.96</td>
<td colspan="1" rowspan="1">0.89</td>
<td colspan="1" rowspan="1">0.88</td>
<td colspan="1" rowspan="1">0.89</td>
<td colspan="1" rowspan="1">0.88</td>
</tr>
<tr>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">0.92</td>
<td colspan="1" rowspan="1">0.84</td>
<td colspan="1" rowspan="1">0.82</td>
<td colspan="1" rowspan="1">0.82</td>
<td colspan="1" rowspan="1">0.82</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Average</td>
<td colspan="1" rowspan="1">0.942</td>
<td colspan="1" rowspan="1">0.86</td>
<td colspan="1" rowspan="1">0.85</td>
<td colspan="1" rowspan="1">0.85</td>
<td colspan="1" rowspan="1">0.85</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="_fn_p15">
<p>This table shows the performance of the Stage 1 model, which was trained to differentiate between typically developing (TD) children and the combined High-Risk/ASD group, evaluated using 5-fold cross-validation</p>
<p><strong>Area Under the Receiver Operating Characteristic Curve (AUROC):</strong> The average AUROC across the five folds was 0.942, with individual fold scores ranging from 0.92 to 0.96.</p>
<p><strong>Accuracy, Precision, Recall, F1-score:</strong> Balanced performance was also observed across other metrics, with an average accuracy of 0.86, precision of 0.85, recall of 0.85, and F1-score of 0.85.</p>
</div></div></section><figure class="fig xbox font-sm" id="Fig1"><h4 class="obj_head">Fig. 1. ROC curves for the Stage 1 model.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/167b/12370947/f196d9e45dff/41746_2025_1914_Fig1_HTML.jpg" loading="lazy" id="d33e935" height="500" width="666" alt="Fig. 1"></p>
<div class="p text-right font-secondary"><a href="figure/Fig1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>These curves display the model’s performance in discriminating between typically developing children and those at risk for ASD across five cross-validation folds. Each Receiver Operating Characteristic (ROC) curve represents the performance of the model on a different held-out test set. The Area Under the Curve (AUC) for each fold is displayed in the legend, and the consistently high AUC scores demonstrate the model’s robust discriminative ability.</p></figcaption></figure></section><section id="Sec4"><h3 class="pmc_sec_title">Auxiliary task: language delay prediction</h3>
<p id="Par14">The Stage 1 model also performed an auxiliary task of predicting language delay. The model achieved good performance on this task, with an average AUROC of 0.91, accuracy of 0.82, precision of 0.80, recall of 0.81, and F1-score of 0.80 across five folds (Table <a href="#Tab2" class="usa-link">2</a>, Fig. <a href="#Fig2" class="usa-link">2</a>). This further demonstrates its ability to extract meaningful clinical information from the input data.</p>
<section class="tw xbox font-sm" id="Tab2"><h4 class="obj_head">Table 2.</h4>
<div class="caption p"><p>Stage 1 model performance on language delay prediction across folds</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th colspan="1" rowspan="1">Fold</th>
<th colspan="1" rowspan="1">AUC</th>
<th colspan="1" rowspan="1">Accuracy</th>
<th colspan="1" rowspan="1">Precision</th>
<th colspan="1" rowspan="1">Recall</th>
<th colspan="1" rowspan="1">F1-Score</th>
</tr></thead>
<tbody>
<tr>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0.89</td>
<td colspan="1" rowspan="1">0.81</td>
<td colspan="1" rowspan="1">0.80</td>
<td colspan="1" rowspan="1">0.83</td>
<td colspan="1" rowspan="1">0.80</td>
</tr>
<tr>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">0.89</td>
<td colspan="1" rowspan="1">0.79</td>
<td colspan="1" rowspan="1">0.77</td>
<td colspan="1" rowspan="1">0.78</td>
<td colspan="1" rowspan="1">0.77</td>
</tr>
<tr>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">0.91</td>
<td colspan="1" rowspan="1">0.81</td>
<td colspan="1" rowspan="1">0.79</td>
<td colspan="1" rowspan="1">0.79</td>
<td colspan="1" rowspan="1">0.79</td>
</tr>
<tr>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">0.94</td>
<td colspan="1" rowspan="1">0.85</td>
<td colspan="1" rowspan="1">0.84</td>
<td colspan="1" rowspan="1">0.84</td>
<td colspan="1" rowspan="1">0.84</td>
</tr>
<tr>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">0.91</td>
<td colspan="1" rowspan="1">0.83</td>
<td colspan="1" rowspan="1">0.82</td>
<td colspan="1" rowspan="1">0.80</td>
<td colspan="1" rowspan="1">0.81</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Average</td>
<td colspan="1" rowspan="1">0.91</td>
<td colspan="1" rowspan="1">0.82</td>
<td colspan="1" rowspan="1">0.80</td>
<td colspan="1" rowspan="1">0.81</td>
<td colspan="1" rowspan="1">0.80</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="_fn_p21">
<p>This table presents the performance of the Stage 1 model on the auxiliary task of predicting language delay across five folds.</p>
<p><strong>Area Under the Receiver Operating Characteristic Curve (AUROC):</strong> The average AUROC across the five folds was 0.91, with individual fold scores ranging from 0.89 to 0.94.</p>
<p><strong>Accuracy, Precision, Recall, F1-score:</strong> Balanced performance was also observed across other metrics, with an average accuracy of 0.82, precision of 0.80, recall of 0.81, and F1-score of 0.80.</p>
</div></div></section><figure class="fig xbox font-sm" id="Fig2"><h4 class="obj_head">Fig. 2. ROC curves for the auxiliary language delay prediction task.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/167b/12370947/d18580427158/41746_2025_1914_Fig2_HTML.jpg" loading="lazy" id="d33e1068" height="500" width="666" alt="Fig. 2"></p>
<div class="p text-right font-secondary"><a href="figure/Fig2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>These plots show the performance of the Stage 1 model on the secondary task of identifying language delay. The Receiver Operating Characteristic (ROC) curves are shown for five cross-validation folds, with each curve representing the model’s performance on a different held-out test set and the Area Under the Curve (AUC) for each fold displayed in the legend.</p></figcaption></figure></section><section id="Sec5"><h3 class="pmc_sec_title">Stage 2 model performance: differentiating high-risk from ASD</h3>
<p id="Par15">The Stage 2 model, a fine-tuned RoBERTa-large model, was trained to differentiate between individuals at high risk (HR) for ASD and those diagnosed with ASD. This model integrated behavioral task success/failure data with textual data derived from the SRS.</p>
<p id="Par16">The model was trained and evaluated using five different random seeds (Folds 100, 42, 2021, 7, and 12345) to assess the robustness of its performance. The results on held-out test sets for each fold are presented in Table <a href="#Tab3" class="usa-link">3</a> and Fig. <a href="#Fig3" class="usa-link">3</a>.</p>
<section class="tw xbox font-sm" id="Tab3"><h4 class="obj_head">Table 3.</h4>
<div class="caption p"><p>Stage 2 Model Performance Across Folds</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th colspan="1" rowspan="1">Fold</th>
<th colspan="1" rowspan="1">Accuracy</th>
<th colspan="1" rowspan="1">AUC</th>
<th colspan="1" rowspan="1">Precision</th>
<th colspan="1" rowspan="1">Recall</th>
<th colspan="1" rowspan="1">F1</th>
</tr></thead>
<tbody>
<tr>
<td colspan="1" rowspan="1">Fold 100</td>
<td colspan="1" rowspan="1">0.86</td>
<td colspan="1" rowspan="1">0.92</td>
<td colspan="1" rowspan="1">0.89</td>
<td colspan="1" rowspan="1">0.92</td>
<td colspan="1" rowspan="1">0.91</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Fold 42</td>
<td colspan="1" rowspan="1">0.82</td>
<td colspan="1" rowspan="1">0.93</td>
<td colspan="1" rowspan="1">0.91</td>
<td colspan="1" rowspan="1">0.84</td>
<td colspan="1" rowspan="1">0.87</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Fold 2021</td>
<td colspan="1" rowspan="1">0.88</td>
<td colspan="1" rowspan="1">0.90</td>
<td colspan="1" rowspan="1">0.88</td>
<td colspan="1" rowspan="1">0.97</td>
<td colspan="1" rowspan="1">0.92</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Fold 7</td>
<td colspan="1" rowspan="1">0.86</td>
<td colspan="1" rowspan="1">0.92</td>
<td colspan="1" rowspan="1">0.92</td>
<td colspan="1" rowspan="1">0.89</td>
<td colspan="1" rowspan="1">0.90</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Fold 12345</td>
<td colspan="1" rowspan="1">0.84</td>
<td colspan="1" rowspan="1">0.90</td>
<td colspan="1" rowspan="1">0.89</td>
<td colspan="1" rowspan="1">0.89</td>
<td colspan="1" rowspan="1">0.89</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Average</td>
<td colspan="1" rowspan="1">0.85</td>
<td colspan="1" rowspan="1">0.91</td>
<td colspan="1" rowspan="1">0.90</td>
<td colspan="1" rowspan="1">0.90</td>
<td colspan="1" rowspan="1">0.90</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="_fn_p28"><p>This table details the performance of the Stage 2 model in differentiating between individuals at HR for ASD and those diagnosed with ASD. The evaluation was conducted on held-out test sets across five different random seeds to ensure robustness.</p></div></div></section><figure class="fig xbox font-sm" id="Fig3"><h4 class="obj_head">Fig. 3. ROC curves for the Stage 2 model.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/167b/12370947/78d696bee96d/41746_2025_1914_Fig3_HTML.jpg" loading="lazy" id="d33e1195" height="640" width="666" alt="Fig. 3"></p>
<div class="p text-right font-secondary"><a href="figure/Fig3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>The plots demonstrate the model’s robust ability to classify individuals as either High-Risk or diagnosed ASD across five separate evaluation runs. Each Receiver Operating Characteristic (ROC) curve shows the model’s performance when trained with a different random seed, with the Area Under the Curve (AUC) for each run displayed in the legend to confirm consistent, high performance.</p></figcaption></figure><p id="Par17">The Stage 2 model demonstrated strong performance in differentiating between individuals diagnosed with ASD and those identified as high-risk (HR) for ASD. Across five-fold cross-validation, the model achieved an average AUC of 0.91 (range: 0.90–0.93) (Table <a href="#Tab3" class="usa-link">3</a>). It also exhibited balanced overall performance, with average accuracy, precision, recall, and F1-score values of 0.85, 0.90, 0.90, and 0.90, respectively. Accuracy across folds ranged from 0.82 to 0.88, while AUC scores remained consistently high, ranging from 0.90 to 0.93, underscoring the model’s excellent discriminative ability. The ROC curves in Fig. <a href="#Fig3" class="usa-link">3</a> visually corroborate this strong performance, with all curves lying well above the chance line.</p>
<p id="Par18">The model consistently excelled at correctly identifying individuals diagnosed with ASD, indicated by a generally high recall for class 1 (ASD) across all folds, ranging from 0.84 to 0.97. Precision for class 1 was also consistently high, ranging from 0.88 to 0.92. Performance on the High-Risk group (class 0) exhibited more variability. Notably, Fold 2021 demonstrated the highest precision (0.90) but the lowest recall (0.64) for this group. This suggests a potential trade-off between correctly identifying all high-risk individuals (high recall) and minimizing false positives (high precision) within this specific group. These variations may be attributed to the inherent heterogeneity of the High-Risk group or potentially reflect some sensitivity to the specific random seed used during training. However, the consistently high average AUC of 0.91 indicates that the model is generally robust and effective in distinguishing between individuals diagnosed with ASD and those at HR.</p></section><section id="Sec6"><h3 class="pmc_sec_title">Calibration</h3>
<p id="Par19">To assess the reliability of the model’s predicted probabilities, calibration plots were generated. A perfectly calibrated model would produce a calibration plot with a diagonal line, indicating that the predicted probability matches the observed fraction of positive cases.</p>
<p id="Par20">As shown in Fig. <a href="#Fig4" class="usa-link">4</a>, the original model exhibits some degree of miscalibration, particularly in the higher probability range. To address this, isotonic regression was applied to calibrate the model’s predictions. Figure <a href="#Fig4" class="usa-link">4</a> (right panel) shows the calibration plot after applying isotonic regression. The calibrated model demonstrates improved calibration, with the curve aligning more closely to the ideal diagonal line.</p>
<figure class="fig xbox font-sm" id="Fig4"><h4 class="obj_head">Fig. 4. Calibration plots for the Stage 2 model before and after isotonic regression.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370947_41746_2025_1914_Fig4_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/167b/12370947/f55be299c0a2/41746_2025_1914_Fig4_HTML.jpg" loading="lazy" id="d33e1225" height="393" width="800" alt="Fig. 4"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>These reliability curves compare the model’s probabilistic predictions to actual outcomes, showing significant improvement after calibration. The left panel shows the original, uncalibrated model, while the right panel shows the model’s improved calibration after applying isotonic regression, where its predictions align more closely with the ideal diagonal line of perfect calibration.</p></figcaption></figure><p id="Par21">The Expected Calibration Error (ECE) for the original model was [0.14]. After isotonic regression calibration, the ECE was reduced to [&lt;0.0001], indicating improved calibration performance.</p>
<p id="Par22">These results suggest that calibration can enhance the reliability of the model’s predictions, making them more interpretable and clinically useful. The calibrated probabilities can be more confidently used to inform risk stratification and clinical decision-making.</p></section><section id="Sec7"><h3 class="pmc_sec_title">Correlation between model predictions and ADOS scores</h3>
<p id="Par23">To assess the validity of the Stage 2 model’s predictions, we evaluated the correlation between the model’s output (mean calibrated probabilities across the five folds) and the clinically administered ADOS-2 total(T) score. The analysis revealed a strong and statistically significant positive correlation, with a Pearson correlation coefficient of <em>r</em> = 0.830 (<em>p</em> &lt; 0.001) and a Spearman’s rank correlation of <em>ρ</em> = 0.889 (<em>p</em> &lt; 0.001).</p>
<p id="Par24">These results indicate a strong and statistically significant positive correlation (<em>p</em> &lt; 0.001, using an alpha level of 0.05 throughout the study) between the model’s predictions and the severity of ASD symptoms as measured by ADOS given by the Fig. <a href="#Fig5" class="usa-link">5</a>.</p>
<figure class="fig xbox font-sm" id="Fig5"><h4 class="obj_head">Fig. 5. Relationship between model predictions and ADOS-2 scores.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370947_41746_2025_1914_Fig5_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/167b/12370947/91af22944c9f/41746_2025_1914_Fig5_HTML.jpg" loading="lazy" id="d33e1261" height="324" width="800" alt="Fig. 5"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig5/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>These visualizations confirm a strong, statistically significant positive correlation between the model’s output and clinical measures of ASD symptom severity. The scatter plot (left) and pair plot (right) both depict the relationship between the Stage 2 model’s mean calibrated probabilities and the clinically administered ADOS-2 TOTAL(T) scores, with the pair plot also showing the marginal distributions of each variable.</p></figcaption></figure></section><section id="Sec8"><h3 class="pmc_sec_title">Risk stratification and threshold optimization</h3>
<p id="Par25">Building upon the strong correlation between model predictions and ADOS scores, we performed risk stratification to categorize participants into risk groups based on the model’s output and their ADOS-2 TOTAL(T) scores. Building upon the strong correlation with ADOS scores, we performed risk stratification to categorize participants into risk groups based on the model’s output and their ADOS-2 TOTAL(T) scores by optimizing thresholds for the model’s mean calibrated probability. The process aimed to best align the model’s output with clinical risk categories defined by ADOS-2 TOTAL(T) scores: Low Risk (score &lt; 7), Moderate Risk (score ≥ 7 and ≤13), and HR (score &gt; 13). The resulting optimized thresholds for the model’s probability were &lt;0.40 for Low Risk, between 0.40 and 0.85 for Moderate Risk, and &gt;0.85 for HR. As shown in Fig. <a href="#Fig6" class="usa-link">6</a>, applying these thresholds to the model’s predictions yielded a maximum agreement (Accuracy) of 0.80 with the ADOS-based categories.</p>
<figure class="fig xbox font-sm" id="Fig6"><h4 class="obj_head">Fig. 6. Optimization of thresholds for risk stratification.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370947_41746_2025_1914_Fig6_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/167b/12370947/2e72e336a25d/41746_2025_1914_Fig6_HTML.jpg" loading="lazy" id="d33e1276" height="401" width="700" alt="Fig. 6"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig6/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>This graph illustrates the data-driven process used to identify the optimal probability thresholds for categorizing individuals into risk groups. The plot shows the agreement scores (Accuracy) between model-predicted risk categories and ADOS-based risk categories across a grid search of different threshold combinations, with the peak of the curve indicating the optimized thresholds (0.40, 0.85) that yielded the highest agreement.</p></figcaption></figure><p id="Par26">This process of enhancing agreement from an uncalibrated state to an optimized one is detailed in Supplementary Fig. <a href="#MOESM1" class="usa-link">16</a> and Supplementary Fig. <a href="#MOESM1" class="usa-link">17</a>, which show the progression from the initial agreement heatmap to the final calibrated cross-tabulation. The cross-tabulation heatmaps in Fig. <a href="#Fig7" class="usa-link">7</a> visualize the agreement between the model-predicted risk categories (using the optimized thresholds) and the ADOS-based risk categories.</p>
<figure class="fig xbox font-sm" id="Fig7"><h4 class="obj_head">Fig. 7. Agreement between model-predicted and ADOS-based risk categories.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370947_41746_2025_1914_Fig7_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/167b/12370947/196b19bdb8cb/41746_2025_1914_Fig7_HTML.jpg" loading="lazy" id="d33e1295" height="280" width="800" alt="Fig. 7"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig7/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>The heatmaps provide a visual cross-tabulation of the model’s classification accuracy against the ground-truth risk categories defined by ADOS-2 scores. Using the optimized thresholds of 0.40 and 0.85, the left panel shows the classification results for individuals in the ADOS High Risk group, while the right panel shows the results for the ADOS Low and Moderate Risk groups.</p></figcaption></figure><p id="Par27">Overall, the model demonstrates good agreement with ADOS-based risk categories, particularly for the High-Risk group (23 out of 37 correctly identified). This suggests that the model’s predictions align well with established clinical assessments, particularly for identifying individuals with more severe ASD symptoms. The discrepancies observed in the Moderate Risk group may reflect the inherent challenges in categorizing individuals with borderline symptom severity and highlight the potential value of the model in providing supplementary information to aid clinical judgment in such cases.</p></section><section id="Sec9"><h3 class="pmc_sec_title">Comparison with existing literature</h3>
<p id="Par28">The Stage 1 model, designed to differentiate between typically developing (TD) children and those at HR for or diagnosed with ASD, achieved an impressive average AUROC of 0.942 across five folds. This performance surpasses many previous efforts that relied solely on traditional machine learning methods applied to parent-reported questionnaires, as highlighted in the review by Rahman et al.<sup><a href="#CR20" class="usa-link" aria-describedby="CR20">20</a></sup>. The high AUROC scores, consistently above 0.92 in each fold (Fig. <a href="#Fig1" class="usa-link">1</a>, Table <a href="#Tab1" class="usa-link">1</a>), indicate the model’s robustness and ability to generalize well to unseen data. Furthermore, the model’s strong performance on the auxiliary task of language delay prediction (average AUROC of 0.908, Fig. <a href="#Fig2" class="usa-link">2</a>, Table <a href="#Tab2" class="usa-link">2</a>) underscores its ability to extract meaningful and clinically relevant information from the multimodal input data. The successful integration of audio data, processed using the Whisper model, demonstrates the value of incorporating naturalistic observations of parent-child interactions, which capture subtle complexity in social communication and language development often missed by traditional assessment methods<sup><a href="#CR19" class="usa-link" aria-describedby="CR19">19</a>,<a href="#CR27" class="usa-link" aria-describedby="CR27">27</a></sup>.</p>
<p id="Par29">The Stage 2 model, a fine-tuned RoBERTa-large model, further refined the classification by distinguishing between individuals at HR for ASD and those with a confirmed diagnosis. This model achieved an average AUROC of 0.914 and an average accuracy of 0.852 across five different training runs (Table <a href="#Tab3" class="usa-link">3</a>, Fig. <a href="#Fig3" class="usa-link">3</a>). These results are particularly noteworthy given the challenging nature of this classification task. The consistently high AUC scores across all folds (0.90 to 0.93) demonstrate the model’s robust discriminative ability and its potential for clinical utility. The strong positive correlation between the model’s predicted probabilities and ADOS-2 TOTAL(T) scores (Pearson <em>r</em> = 0.830, <em>p</em> &lt; 0.001; Spearman <em>ρ</em> = 0.889, <em>p</em> &lt; 0.001) (Fig. <a href="#Fig5" class="usa-link">5</a>) further validates the clinical relevance of the model’s output, suggesting that it captures meaningful information about ASD symptom severity. These findings build upon prior work that has explored the use of AI in ASD diagnosis, such as those leveraging neuroimaging data or facial behavior analysis<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a>–<a href="#CR16" class="usa-link" aria-describedby="CR16">16</a></sup>, by demonstrating the power of combining textual and behavioral data within a deep learning framework.</p></section><section id="Sec10"><h3 class="pmc_sec_title">Overall model performance</h3>
<p id="Par30">Our two-stage multimodal AI framework demonstrated robust performance in ASD risk stratification. An initial 3-class classification model (TD vs. High-Risk vs. ASD) was also explored, with performance metrics detailed in Supplementary Table <a href="#MOESM1" class="usa-link">1</a> and corresponding confusion matrices and ROC curves in Supplementary Fig. <a href="#MOESM1" class="usa-link">1</a>. However, the two-stage binary classification approach was ultimately adopted for its superior performance and clinical interpretability.</p>
<p id="Par31">Stage 1 Classification (TD vs. [High+ASD]): As detailed in Supplementary Table <a href="#MOESM1" class="usa-link">2</a>, the multimodal “Audio + Text with language delay” model (our Stage 1 model) achieved an AUROC of 0.9551 (95% CI: 0.8247–0.9812). Unimodal baselines showed lower performance: “Audio only” achieved an AUROC of 0.7691 (95% CI: 0.6758–0.8521), while “Text only” achieved 0.9418 (95% CI: 0.9020–0.9726). This highlights the significant contribution of questionnaire text and the value of multimodal fusion. The model “Audio + Text w/o language delay” also maintained a high AUROC of 0.9496 (95% CI: 0.9143–0.9777).</p>
<p id="Par32">Stage 2 Classification (High-Risk vs. ASD): Performance metrics for Stage 2 models are presented in Supplementary Table <a href="#MOESM1" class="usa-link">3</a>. Our proposed Stage 2 model (“SRS + 5 Tasks S/F”) achieved an AUROC of 0.9317 (95% CI: 0.8585–0.9854). This multimodal approach significantly outperformed unimodal baselines: “Base SVM” (AUROC 0.8263), “SRS Only” (AUROC 0.8831), and “5 Tasks S/F Only” (AUROC 0.7607), confirming the synergistic effect of integrating both SRS and structured interaction task outcomes.</p></section><section id="Sec11"><h3 class="pmc_sec_title">Error analysis and risk stratification</h3>
<p id="Par33">The error analysis utilized two datasets: confusion matrices in Supplementary Figs. <a href="#MOESM1" class="usa-link">2</a>–<a href="#MOESM1" class="usa-link">3</a> were computed on our original held-out test set, while visualizations in Supplementary Figs. <a href="#MOESM1" class="usa-link">18</a>–<a href="#MOESM1" class="usa-link">20</a> were generated using an independent, newly collected external cohort to assess Stage 1 true-vs-predicted labels (Supplementary Fig. <a href="#MOESM1" class="usa-link">18</a>), Stage 1 calibrated risk levels (Supplementary Fig. <a href="#MOESM1" class="usa-link">19</a>), and Stage 2 calibrated risk levels (Supplementary Fig. <a href="#MOESM1" class="usa-link">20</a>).</p>
<p id="Par34">The first stage of the model (TD vs. non-TD) demonstrated high sensitivity on the original held-out set, achieving 100% sensitivity for non-TD detection. All true ASD (n = 11) and High-risk (n = 11) cases were correctly flagged as “Other,” while a 23% false-positive rate occurred among TD children (Supplementary Fig. <a href="#MOESM1" class="usa-link">2</a>). This performance held on the independent external cohort, where non-TD sensitivity remained at 100%. Crucially, these false positives almost exclusively mapped to the Low Risk category in the subsequent Stage 2 analysis (Supplementary Fig. <a href="#MOESM1" class="usa-link">18</a>). The risk calibration heatmap for the external cohort further showed that genuine non-TD cases occupied higher risk bins, while correctly classified TD children remained in the Low Risk bin (Supplementary Fig. <a href="#MOESM1" class="usa-link">19</a>).</p>
<p id="Par35">In the second stage of the model (High-risk vs. ASD), detailed results for the original test set are presented in Supplementary Fig. <a href="#MOESM1" class="usa-link">3</a>. On the external cohort, the risk calibration demonstrated strong sensitivity for ASD, with 10 of 11 ASD cases (91%) classified as either HR or Medium Risk. In contrast, TD children remained almost entirely in the Low Risk category (12/13), while the High-risk group spanned all risk bins (Supplementary Fig. <a href="#MOESM1" class="usa-link">20</a>). The overall binary prediction performance for Stage 2 on this cohort is summarized in the confusion matrix in Supplementary Fig. <a href="#MOESM1" class="usa-link">21</a>.</p>
<p id="Par36">In sum, by combining high-sensitivity binary classification with calibrated risk stratification—and validating on two independent cohorts—our two-stage framework offers a robust, clinically actionable pathway for early ASD screening with minimized unnecessary follow-ups and sustained accuracy.</p></section><section id="Sec12"><h3 class="pmc_sec_title">Interpretability analysis</h3>
<p id="Par37">Micro-level interpretability was performed for the Stage 2 model using SHAP values and CLS attention mechanisms, providing sample-specific insights. This analysis focused particularly on the SRS + 5 Tasks Success/Failure model due to its high reliability (AUROC 0.9317).</p>
<p id="Par38">Our SHAP analysis quantified the impact of specific features on model predictions. For predicting High-Risk (Class 0), task successes (e.g., “Success of Mimicked actions2” [+0.030], “Success of Reacted to snack” [+0.009]) consistently showed the largest positive contributions, while phrases indicating strong social skills like “usually looks up and pays attention when spoken to” (-0.006) decreased this likelihood (Supplementary Figs. <a href="#MOESM1" class="usa-link">4</a>, <a href="#MOESM1" class="usa-link">5</a>, <a href="#MOESM1" class="usa-link">10</a>, <a href="#MOESM1" class="usa-link">11</a>). Conversely, for predicting ASD (Class 1), these same task successes had negative SHAP values (e.g., “Success of Mimicked actions2” [-0.030]), actively decreasing the likelihood of an ASD diagnosis. Instead, phrases reflecting social-communication strengths such as “usually looks up and pays attention when spoken to” (+0.007) increased the ASD prediction (Supplementary Figs. <a href="#MOESM1" class="usa-link">6</a>, <a href="#MOESM1" class="usa-link">7</a>, <a href="#MOESM1" class="usa-link">12</a>, <a href="#MOESM1" class="usa-link">13</a>).</p>
<p id="Par39">To further investigate the model’s focus, we analyzed the [CLS] token’s attention patterns. This confirmed that the model places significant emphasis on both explicit task outcomes and critical behavioral descriptors. High attention scores were consistently observed for phrases related to direct task performance like “Success of Mimicked actions2” (≈0.010) and “Success of Played catch” (≈0.0035) (Supplementary Figs. <a href="#MOESM1" class="usa-link">8</a>, <a href="#MOESM1" class="usa-link">9</a>). The model also paid high attention to core ASD-related features such as “child always different” (≈0.005), “speech tone” (≈0.0045), “not attending to social approaches from adults” (≈0.003), and adaptive behaviors like “self-care behavior” (≈0.013) (Supplementary Figs. <a href="#MOESM1" class="usa-link">14</a>, <a href="#MOESM1" class="usa-link">15</a>).</p></section></section><section id="Sec13"><h2 class="pmc_sec_title">Discussion</h2>
<p id="Par40">This study introduces a novel two-stage multimodal AI framework for ASD screening and risk stratification, representing a significant advancement in early detection and intervention efforts. By integrating text-based parent-reported surveys, audio data from parent-child interactions, and clinical assessment data including ADOS module scores (utilized particularly for differentiating High-Risk and ASD groups in Stage 2), our framework addresses critical limitations of prior research that often relied on unimodal data sources³. To our knowledge, this is the first large-scale study (<em>n</em> = 1242) to employ such a comprehensive, AI-driven approach to systematically investigate the correlation between predictive phenotypes and ASD diagnostic outcomes. The results underscore the feasibility and effectiveness of leveraging advanced deep learning models, specifically RoBERTa<sup><a href="#CR33" class="usa-link" aria-describedby="CR33">33</a></sup> and Whisper<sup><a href="#CR34" class="usa-link" aria-describedby="CR34">34</a></sup>, to achieve accurate ASD screening and risk stratification.</p>
<p id="Par41">A key contribution of this research lies in developing a comprehensive ASD assessment framework that integrates the AI model’s predictions with ADOS-2 total(T) scores, which measure the severity of autism symptoms rather than ASD risk itself. This integration enables a clinically meaningful and fine-grained evaluation of symptom severity, aligning AI-driven assessments with established clinical scales. The framework demonstrated high agreement (79.59% accuracy) with ADOS-2-defined symptom severity categories, suggesting its potential to support clinical decision-making by providing structured insights into symptom presentation. Notably, the model exhibited high sensitivity in identifying individuals with elevated ADOS-2 total(T) scores (correctly identifying 23 out of 37 individuals in the highest severity category), underscoring its potential utility in prioritizing individuals for comprehensive diagnostic evaluations and addressing delays in ASD diagnosis.<sup><a href="#CR6" class="usa-link" aria-describedby="CR6">6</a>,<a href="#CR37" class="usa-link" aria-describedby="CR37">37</a></sup>.</p>
<p id="Par42">The severity stratification framework provides multi-level clinical insights by generating valuable information sequentially through its two-stage process. The initial Stage 1 classification identifies children likely needing further evaluation (non-TD), after which Stage 2 differentiates between a higher likelihood of ASD versus being High-Risk. This process enables reliable severity stratification, which in turn facilitates several key clinical applications. It supports early identification and prioritization by helping to identify children who warrant comprehensive diagnostic evaluation, a crucial benefit given extended waiting periods for specialized care¹. Furthermore, the objective outputs serve as valuable supplementary information for enhanced assessment, especially for individuals with borderline or ambiguous clinical presentations. Finally, the framework directly supports informing personalized intervention, as the detailed stratification allows clinicians to tailor the intensity and focus of early intervention plans more effectively based on the child’s specific assessed needs⁸.</p>
<p id="Par43">In any screening paradigm, misclassifications are inevitable, and understanding their downstream effects is crucial. The core workflow presented here utilizes two sequential binary models—Stage 1 (TD vs. [High-Risk + ASD]) and Stage 2 (High-Risk vs. ASD)—followed by calibrated risk stratification correlated with ADOS-2 scores. While misclassifying TD children as false positives can increase parental anxiety and follow-up burden, the two‐stage design cushions this impact. A TD child mistakenly flagged in Stage 1 is highly unlikely to receive a High‐Risk score in Stage 2, thereby reducing unnecessary diagnostic referrals. Clinicians can further use model confidence scores; for instance, children with borderline probabilities in Stage 2 may be monitored over time rather than being sent directly for a full evaluation. Conversely, missing an ASD diagnosis (a false negative) delays critical early intervention. Although the pipeline achieves &gt;90% ASD sensitivity, the small number of misses in Stage 2 (1/11 in the external cohort) underscores that no automated tool is infallible, reinforcing the need for continued developmental surveillance by primary care providers and the option for repeat screening if concerns persist.</p>
<p id="Par44">To build clinical trust and facilitate informed decision-making, micro-level interpretability features like SHAP values and attention maps are critical. These tools allow clinicians to peer into the model’s “reasoning” by revealing which specific phrases from questionnaires or structured task outcomes most strongly influenced a prediction. For example, if the model heavily weighted a phrase like “not attending to social approaches from adults” towards an ASD classification, it directly aligns with clinical diagnostic criteria, allowing the clinician to cross-reference this with their own observations. This transparency transforms the model from a black box into a collaborative partner, enabling clinicians to discuss complex or borderline cases by integrating the model’s evidence with their own clinical expertise.</p>
<p id="Par45">This study directly addresses several limitations of prior research. The multimodal approach, incorporating text and audio data, overcomes the constraints of unimodal methods that have dominated previous ASD classification studies<sup><a href="#CR13" class="usa-link" aria-describedby="CR13">13</a>,<a href="#CR20" class="usa-link" aria-describedby="CR20">20</a>,<a href="#CR41" class="usa-link" aria-describedby="CR41">41</a></sup>. By harnessing the power of deep learning models like RoBERTa<sup><a href="#CR33" class="usa-link" aria-describedby="CR33">33</a></sup> and Whisper<sup><a href="#CR34" class="usa-link" aria-describedby="CR34">34</a></sup>, the framework moves beyond traditional machine learning techniques that often struggle with the complexity and heterogeneity of ASD presentations. Furthermore, the focus on model calibration, drawing on principles from uncertainty quantification research<sup><a href="#CR42" class="usa-link" aria-describedby="CR42">42</a>–<a href="#CR44" class="usa-link" aria-describedby="CR44">44</a></sup> enhances the reliability and interpretability of the model’s predictions, addressing a crucial gap often overlooked in earlier work<sup><a href="#CR20" class="usa-link" aria-describedby="CR20">20</a>,<a href="#CR39" class="usa-link" aria-describedby="CR39">39</a></sup>. These findings align with the global shift toward scalable, accessible, and efficient digital health solutions, particularly in under-resourced settings. The app-based approach for data collection, coupled with automated AI-driven analysis, has the potential to significantly reduce the time and resources required for ASD screening, which is relevant given the increasing prevalence of ASD<sup><a href="#CR1" class="usa-link" aria-describedby="CR1">1</a></sup> and the development of other AI-based diagnostic tools<sup><a href="#CR10" class="usa-link" aria-describedby="CR10">10</a></sup>.</p>
<p id="Par46">Despite these advancements, the study has limitations. The initial sample sizes (<em>n</em> ≈ 35 per group) limit the precision of low-frequency error estimates, and the findings may not be generalizable to all populations, as the study was conducted in a specific Korean clinical setting. While the text-based component used English ASD terms for semantic processing of questionnaire data, the cultural and linguistic specificity of the context must be considered. The audio component, however, focused on more language-agnostic acoustic features, which may enhance transferability. A second limitation involves data collection and ground truth. The uncontrolled nature of audio recording, including ambient noise and variable child participation, impacted the quality of child vocalizations. Additionally, ADOS-2 scores were used as the ground truth for risk stratification; however, these scores do not always correspond with clinicians’ final judgments and represent only one of several diagnostic tools.</p>
<p id="Par47">Future research should focus on validating the framework in larger, more diverse populations with different linguistic, cultural, and socioeconomic backgrounds to assess fairness and robustness, including its performance in children with co-occurring developmental conditions. Further model optimization could be achieved by incorporating additional data modalities, such as video or physiological measures, and exploring adaptive thresholds to trade off false positives versus false negatives. Implementing standardized protocols for audio collection could also improve performance. Finally, longitudinal studies are needed to evaluate the long-term impact of this AI-driven approach on developmental trajectories, and investigating its integration with electronic health records could streamline clinical workflows.</p>
<p id="Par48">In sum, this study successfully developed and validated a novel multimodal AI framework that integrates voice data and semantically analyzed questionnaire responses for effective ASD screening and severity stratification in toddlers. The primary clinical implication lies in its potential to address critical bottlenecks in current care pathways by offering objective support for prioritizing assessments, enhancing clinical judgment, and informing the tailoring of early intervention intensity based on the initial severity level identified by the model<sup><a href="#CR3" class="usa-link" aria-describedby="CR3">3</a></sup>. By leveraging readily available data through a mobile application combined with advanced AI, this framework represents a scalable solution. Its implementation, following rigorous validation, could substantially enhance current ASD care pathways, reduce the burden on specialized services, and ultimately improve developmental outcomes for children with ASD and their families.</p></section><section id="Sec14"><h2 class="pmc_sec_title">Methods</h2>
<p id="Par49">This study employed a two-stage AI framework (Fig. <a href="#Fig8" class="usa-link">8</a>) for ASD risk stratification, integrating multimodal data from surveys, parent-child interactions, and clinical assessments.</p>
<figure class="fig xbox font-sm" id="Fig8"><h3 class="obj_head">Fig. 8. Schematic diagram of the two-stage multimodal AI framework for ASD risk stratification.</h3>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370947_41746_2025_1914_Fig8_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/167b/12370947/9766f8c4ea2e/41746_2025_1914_Fig8_HTML.jpg" loading="lazy" id="d33e1573" height="441" width="700" alt="Fig. 8"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig8/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>The framework shows a sequential process beginning with initial classification and culminating in actionable risk stratification. This diagram illustrates how Stage 1 (Model 1) uses voice and questionnaire data to classify individuals as Typically Developing (TD) or at-risk (High+ASD). Individuals flagged as at-risk proceed to Stage 2 (Model 2), which uses semantic features and task outcomes to further classify them as High-Risk or diagnosed ASD, leading to stratification into three clinical risk categories with recommended actions.</p></figcaption></figure><section id="Sec15"><h3 class="pmc_sec_title">Study design and participants</h3>
<p id="Par50">This study recruited 1242 children aged 18–48 months from clinical settings across 9 hospitals in the Republic of Korea. Data collection was primarily conducted using a mobile application, which gathered responses to key ASD screening questionnaires (including the M-CHAT-R/F, SCQ-L, and SRS) —with the M-CHAT-R/F administered for children aged 18–30 months and the SCQ-L for those aged 24–48 months— and recorded voice data from parent-child interaction videos during standardized tasks. Participants were categorized into three groups: TD, high-risk for ASD, and confirmed ASD. This categorization was based on results from these screening tools and clinical diagnoses performed according to DSM-5 criteria. Figure <a href="#Fig9" class="usa-link">9</a> details the participant flow through the study, illustrating the inclusion and exclusion criteria applied based on data availability and clearly delineating the sample sizes and specific data inputs for both Stage 1 and Stage 2 of the two-stage AI model analysis.</p>
<figure class="fig xbox font-sm" id="Fig9"><h4 class="obj_head">Fig. 9. Study flowchart and multimodal AI framework overview.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370947_41746_2025_1914_Fig9_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/167b/12370947/e978dd4fea86/41746_2025_1914_Fig9_HTML.jpg" loading="lazy" id="d33e1588" height="904" width="800" alt="Fig. 9"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig9/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>This flowchart details participant recruitment, exclusion criteria, and data allocation for the two-stage AI model. It shows how participants were selected based on the availability of mobile application data, including screening tool responses and voice recordings. Stage 1 included 818 participants to differentiate TD from non-TD individuals, while Stage 2 included 515 participants from the non-TD group to differentiate between High-Risk and ASD individuals. (MCHAT: Modified Checklist for Autism in Toddlers; SCQ-L: Social Communication Questionnaire-Lifetime; SRS: Social Responsiveness Scale; ASD: Autism Spectrum Disorder; TD: Typically Developing; non-TD: Non-Typically Developing).</p></figcaption></figure><p id="Par51">Participants in the study were categorized into three distinct groups: ASD, High-Risk (HR), and TD (TD). The ASD group included toddlers with a confirmed diagnosis based on a combination of screening tools and clinical diagnoses using DSM-5 criteria<sup><a href="#CR6" class="usa-link" aria-describedby="CR6">6</a></sup>. These diagnoses were further supported by comprehensive clinical evaluations utilizing standardized assessment tools, including the Autism Diagnostic Observation Schedule, Second Edition (ADOS-2)<sup><a href="#CR45" class="usa-link" aria-describedby="CR45">45</a></sup>, and the Korean Childhood Autism Rating Scale, Second Edition (K-CARS-2)<sup><a href="#CR5" class="usa-link" aria-describedby="CR5">5</a></sup>. The High-Risk (HR) group comprised toddlers identified through primary screening tools such as the Modified Checklist for Autism in Toddlers, Revised with Follow-Up (M-CHAT-R/F), Q-CHAT, SCQ, SRR, and Bedevel<sup><a href="#CR46" class="usa-link" aria-describedby="CR46">46</a>,<a href="#CR47" class="usa-link" aria-describedby="CR47">47</a></sup>. Toddlers with delayed language development, a family history of ASD, or preterm birth before 36 weeks were also classified into this group. These children exhibited potential ASD traits requiring follow-up evaluations but did not meet the full criteria for an ASD diagnosis. Finally, the TD group consisted of toddlers exhibiting typical developmental patterns without any indications of ASD traits, as determined by the M-CHAT-R/F<sup><a href="#CR47" class="usa-link" aria-describedby="CR47">47</a></sup>, and who had no family history of developmental disorders.</p></section><section id="Sec16"><h3 class="pmc_sec_title">Ethical considerations</h3>
<p id="Par52">This study was conducted in accordance with the Declaration of Helsinki. The study protocol was approved by the Institutional Review Board (IRB) of Severance Hospital, Yonsei University College of Medicine (IRB No. 4-2022-1468), and the IRBs of all participating hospitals in this multi-center study: Seoul National University Hospital (IRB No. 2209-096-1360), Eunpyeong St. Mary’s Hospital (IRB No. 2022-3419-0002), Wonkwang University Hospital (IRB No. 2022-12-023-001), Seoul National University Bundang Hospital (IRB No. 2305-829-401), Hanyang University Hospital (IRB No. 2022-12-007-001), Chungbuk National University Hospital (IRB No. 2023-04-034), and Seoul St. Mary’s Hospital (IRB No. KC24ENDI0198). Written informed consent was obtained from the legal guardian of every participant before any data collection.</p>
<p id="Par53">Procedures for data protection were implemented to uphold the highest ethical standards for collecting data from minors. Upon enrollment, each child was assigned a unique, non-identifiable “Study ID,” and no direct identifiers appear in analysis files. All data were stored on encrypted servers at Yonsei University, using AES-256 and HASH-256 encryption for sensitive information. Access to the database was restricted to authorized personnel through role-based permissions. Data management complied with the Personal Information Protection Act and the Bioethics and Safety Act. Raw audio recordings were deleted after feature extraction, and pseudonymized data will be stored for 10 years from the study’s conclusion before being securely destroyed, with any extension requiring further IRB review. All methods and procedures are described here in the main manuscript, not in <a href="#MOESM1" class="usa-link">Supplementary Information</a>.</p></section><section id="Sec17"><h3 class="pmc_sec_title">Recruitment</h3>
<p id="Par54">The study employed a multi-pronged recruitment strategy, partnering with clinical institutions, community childcare centers, and pediatric clinics specializing in developmental delays to reach a diverse population. Targeted outreach to high-risk groups was conducted through inclusive daycare centers and by distributing brochures in specialized clinics. Participant engagement was fostered by offering incentives like detailed developmental assessment reports.</p></section><section id="Sec18"><h3 class="pmc_sec_title">Data collection</h3>
<p id="Par55">Data collection for this study involved three primary sources: survey data, digital phenotyping data, and clinical data.</p>
<p id="Par56">Survey data was acquired through standardized questionnaires completed by parents, including the Modified Checklist for Autism in Toddlers (MCHAT)<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a>,<a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup>, the Social Communication Questionnaire Lifetime (SCQ-L)<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a>,<a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup>, and the Social Responsiveness Scale second edition (SRS-2)<sup><a href="#CR20" class="usa-link" aria-describedby="CR20">20</a>,<a href="#CR23" class="usa-link" aria-describedby="CR23">23</a></sup>. These surveys provided text-based data for the AI model. The initial sample based on MCHAT and SCQ-L scores consisted of 1242 children, including 434 TD, 331 High-Risk, and 477 with ASD. For the Stage 2 analysis requiring SRS and 5-task audio data, 32 participants were excluded, resulting in a sample of 162 High-Risk and 353 ASD children (Total = 515).</p>
<p id="Par57">Digital phenotyping data was collected from 897 children via a custom-developed mobile application. This included audio data from parent-child interactions, where the app guided parents through a series of standardized tasks designed to elicit specific behaviors relevant to ASD diagnosis (Table <a href="#Tab4" class="usa-link">4</a>). The number of interaction tasks varied by age, with children aged 18–23 months completing four tasks, those aged 24–35 months completing five, and those aged 36–48 months completing six. These tasks included Responding to Name, Imitation (one-step for 18–23 months, two-step for 24–48 months), Ball Play, Symbolic Play, Requesting Help, and Free Play. Audio from the Free Play task was analyzed for the Stage 1 model using data from 294 TD, 214 High-Risk, and 389 ASD children. Audio from 547 children was used in the Stage 2 model. Additionally, task success/failure data was collected for each of the five structured tasks (excluding Free Play), where caregivers evaluated and recorded the child’s performance based on predefined criteria; this binary information was used directly in the Stage 2 model.</p>
<section class="tw xbox font-sm" id="Tab4"><h4 class="obj_head">Table 4.</h4>
<div class="caption p"><p>Parent-Child Interaction Tasks</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th colspan="1" rowspan="1">Task</th>
<th colspan="1" rowspan="1">Age (months)</th>
<th colspan="1" rowspan="1">Description</th>
<th colspan="1" rowspan="1">Steps</th>
</tr></thead>
<tbody>
<tr>
<td colspan="1" rowspan="1">Responding to Name</td>
<td colspan="1" rowspan="1">18–48</td>
<td colspan="1" rowspan="1">Parent calls the child’s while out of sight.</td>
<td colspan="1" rowspan="1">
<p>1. Parent calls child’s name (1st attempt).</p>
<p>2. If no response after 5 s, parent calls again (2nd attempt).</p>
<p>3. If still no response, parent makes other familiar sounds (excluding physical contact).</p>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Imitation (Younger)</td>
<td colspan="1" rowspan="1">18–23</td>
<td colspan="1" rowspan="1">Parent instructs the child to imitate raising arms.</td>
<td colspan="1" rowspan="1">
<p>1. Parent says, “[Child’s name], imitate me,” and raises arms.</p>
<p>2. If no response after 5 s, repeat instruction and action. 3. If still no response, say “Raise your arms” while demonstrating.</p>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Imitation (Older)</td>
<td colspan="1" rowspan="1">24–48</td>
<td colspan="1" rowspan="1">Parent instructs the child to imitate clapping and raising arms.</td>
<td colspan="1" rowspan="1">1. Parent says, “[Child’s name], imitate me,” claps, and raises arms. 2. If no response after 5 s, repeat instruction and actions. 3. If still no response, say “Clap your hands, raise your arms” while demonstrating.</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Ball Play</td>
<td colspan="1" rowspan="1">24–48</td>
<td colspan="1" rowspan="1">Parent and child engage in a ball-playing activity.</td>
<td colspan="1" rowspan="1">
<p>1. Parent says, “Let’s play ball.”</p>
<p>2. Parent gestures as if to receive the ball.</p>
<p>3. If no response after 5 s, repeat gesture.</p>
<p>4. If still no response, say, “Roll the ball to me.”</p>
<p>5. Continue play if successful.</p>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Symbolic Play</td>
<td colspan="1" rowspan="1">36–48</td>
<td colspan="1" rowspan="1">Parent and child engage in pretend play with a doll and a cup.</td>
<td colspan="1" rowspan="1">
<p>1. Parent says, “The baby is thirsty. What should we do?”</p>
<p>2. If no response after 5 s, parent imitates the baby/animal, saying, “I’m thirsty.”</p>
<p>3. If no response, parent brings a cup to the doll, saying, “Let’s have a drink.”</p>
<p>4. Continue play with simple episodes.</p>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Requesting Help</td>
<td colspan="1" rowspan="1">18–48</td>
<td colspan="1" rowspan="1">Child is presented with a desirable object in a container they cannot open independently.</td>
<td colspan="1" rowspan="1">
<p>1. Parent says, “[Child’s name], have a snack.” 2. If no response after 5 s, partially open the lid.</p>
<p>3. If still no response, fully open the lid but keep it in hand.</p>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Free Play</td>
<td colspan="1" rowspan="1">18–48</td>
<td colspan="1" rowspan="1">Child engages in unstructured play, with the parent joining in later.</td>
<td colspan="1" rowspan="1">
<p>1. Child plays freely for 2 min.</p>
<p>2. Afterward, the parent joins child’s play for 1 min.</p>
<p>3. If no response, parent says, “Shall we play together?”</p>
</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="_fn_p97"><p>This table describes the standardized parent-child interaction tasks used to collect audio data via a mobile application. The tasks were designed to elicit behaviors relevant to ASD diagnosis and varied based on the child’s age.</p></div></div></section><p id="Par58">Finally, clinical data was collected, including assessments from ADOS-2 Module 1 (ADOS-2 Mod1), ADOS-2 Module 2 (ADOS-2 Mod2), and the ADOS-2 Toddler Module (ADOS-2 ModT). To ensure consistency across modules, a composite score—referred to as the ADOS-2 total(T) score—was calculated by summing the ADOS social affect (ADOS_SA) score and the ADOS restricted and repetitive behavior (ADOS_RRB) score. This ADOS-2 total(T) score served as the ground truth for model validation and risk stratification.</p></section><section id="Sec19"><h3 class="pmc_sec_title">Language delay definition and calculation</h3>
<p id="Par59">In this study, language delay was defined as a delay of 7 months or more in either receptive or expressive language age compared to the child’s chronological age. Language development was assessed using either the Preschool Receptive-Expressive Language Scale (PRES) or the Sequenced Language Scale for Infants (SELSI). For each child, the obtained receptive and expressive language ages were subtracted from their chronological age. If the receptive or expressive language delay was 7 months or greater, the child was classified as having a language delay.</p></section><section id="Sec20"><h3 class="pmc_sec_title">Stage 1 model development</h3>
<p id="Par60">The development of the AI model employed a two-stage approach. This section details the methodology used for Stage 1, focusing on distinguishing TD children from those at High-Risk (HR) for or diagnosed with ASD.</p>
<p id="Par61">The initial dataset comprised data from 1242 participants. Following the exclusion of 61 participants due to missing free-play audio data or the presence of specific confounding factors (high-risk ASD with family history or high-risk ASD with premature birth), the final dataset for Stage 1 analysis consisted of 818 children. This cohort included 273 TD children, 175 children identified as High-Risk for ASD, and 370 children diagnosed with ASD.</p></section><section id="Sec21"><h3 class="pmc_sec_title">Data preprocessing</h3>
<p id="Par62">Text-based analysis utilized responses from the Modified Checklist for Autism in Toddlers (MCHAT) and the Social Communication Questionnaire - Lifetime (SCQ-L). We employed a mapping strategy to enhance the extraction of ASD-relevant information from these questionnaires. Specifically, 1943 medical concepts derived from Zhao et al. (2022)<sup><a href="#CR13" class="usa-link" aria-describedby="CR13">13</a></sup> were used to map the survey items to a broader set of 3336 ASD-related terms, creating a richer textual representation for identifying high-risk individuals. Subsequently, a Sentence Transformer model (Reimers &amp; Gurevych, 2019) was implemented to calculate cosine similarity scores between each survey item and the expanded set of ASD terms. The top five matching terms for each item, based on cosine similarity, were identified. From this subset, 1–2 clinically relevant terms were carefully selected as keywords, guided by expert clinical judgment. These selected keywords served as the foundation for training a RoBERTa-based binary classification model. This model was designed to differentiate between TD children and the combined group of high-risk and ASD children, leveraging the textual information derived from the MCHAT and SCQ-L.</p>
<p id="Par63">The audio data consisted of recordings from parent-child interaction tasks. Each recording, with a total duration of 3 min, was segmented into 30-s intervals. These segments were then processed using a Multiple Instance Learning (MIL) framework (Ilse et al.)<sup><a href="#CR48" class="usa-link" aria-describedby="CR48">48</a></sup>, with the Whisper model (Radford et al.)<sup><a href="#CR34" class="usa-link" aria-describedby="CR34">34</a></sup> serving as the feature extraction backbone. To address the presence of language delay, children’s receptive and expressive language development ages were assessed. Children exhibiting a delay of 7 months or more compared to their chronological age were labeled as having a language delay. This language delay status was then predicted using the Whisper model (Radford et al.)<sup><a href="#CR34" class="usa-link" aria-describedby="CR34">34</a></sup> within the MIL framework (Ilse et al.)<sup><a href="#CR48" class="usa-link" aria-describedby="CR48">48</a></sup>, enabling effective feature extraction from the variable-length audio inputs.</p></section><section id="Sec22"><h3 class="pmc_sec_title">Model architecture</h3>
<p id="Par64">A multi-modal neural network was constructed to integrate both text and audio data. This network was based on the pre-trained ‘RoBERTa-large’ and Whisper Encoder models. The ‘RoBERTa-large’ model served as the text pathway, extracting features from the preprocessed textual data derived from the questionnaires. Concurrently, a pre-trained whisper Encoder model, which was fine-tuned as part of this study, formed the audio pathway, extracting features from the segmented audio data. The extracted text and audio features were then concatenated to form a unified representation. This combined feature vector was fed into a final classification layer, which produced logits for classifying children into either the TD group or the combined HR + ASD group. As an auxiliary task, a separate output layer was included to predict the presence or absence of language delay (Yes/No) based on the fused features. Finally, a hard ensemble approach was implemented to combine the predictions generated by the MCHAT/SCQ-L-based binary classification model and the language delay prediction model, ultimately classifying children into the TD or combined HR + ASD groups.</p>
<p id="Par65">The overall loss function for Stage 1 was a composite of losses from the main classification task and the auxiliary language delay prediction task. The total loss function, which equally weighted the classification loss and the language-delay prediction loss, is defined in Eq. (<a href="#Equ1" class="usa-link">1</a>).</p>
<table class="disp-formula p" id="Equ1"><tr>
<td class="formula"><math id="d33e1811" display="block"><mrow><mi>L</mi><mo>=</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mn>2</mn></mrow></mfrac><mrow><mo>(</mo><mrow><msub><mrow><mi>L</mi></mrow><mrow><mi>C</mi><mi>E</mi></mrow></msub><mo>+</mo><msub><mrow><mi>L</mi></mrow><mrow><mi>L</mi><mi>D</mi></mrow></msub></mrow><mo>)</mo></mrow></mrow></math></td>
<td class="label">1</td>
</tr></table>
<p>Here, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq1"><math id="d33e1844"><msub><mrow><mi mathvariant="normal">L</mi></mrow><mrow><mi mathvariant="normal">CE</mi></mrow></msub></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq2"><math id="d33e1859"><msub><mrow><mi>L</mi></mrow><mrow><mi mathvariant="italic">LD</mi></mrow></msub></math></span> represent the cross-entropy losses for the main classification task and the auxiliary language delay task, respectively.</p>
<p id="Par66">The classification error for the primary task (classifying TD vs. High-Risk/ASD) is computed using Eq. (<a href="#Equ2" class="usa-link">2</a>):</p>
<table class="disp-formula p" id="Equ2"><tr>
<td class="formula"><math id="d33e1879" display="block"><mrow><msub><mrow><mi>L</mi></mrow><mrow><mi>C</mi><mi>E</mi></mrow></msub><mo>=</mo><mo>−</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mi>N</mi></mrow></mfrac><munderover accent="false" accentunder="false"><mrow><mo>∑</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>N</mi></mrow></munderover><mfenced close="]" open="["><mrow><msub><mrow><mi>y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>⋅</mo><mi>log</mi><mrow><mo>(</mo><mrow><msub><mrow><mi>p</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow><mo>)</mo></mrow><mo>+</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>−</mo><msub><mrow><mi>y</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow><mo>)</mo></mrow><mo>⋅</mo><mi>log</mi><mrow><mo>(</mo><mrow><mn>1</mn><mo>−</mo><msub><mrow><mi>p</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow><mo>)</mo></mrow></mrow></mfenced></mrow></math></td>
<td class="label">2</td>
</tr></table>
<p id="Par67">In this equation, N is the total number of samples, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq3"><math id="d33e1954"><msub><mrow><mi>y</mi></mrow><mrow><mi>i</mi></mrow></msub></math></span> is the true class label for sample <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq4"><math id="d33e1967"><mi>i</mi></math></span> (0 for TD, 1 for High-Risk/ASD), and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq5"><math id="d33e1976"><msub><mrow><mi>p</mi></mrow><mrow><mi>i</mi></mrow></msub></math></span> is the predicted probability of the positive class (High-Risk/ASD) for sample <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq6"><math id="d33e1989"><mi>i</mi></math></span>.</p>
<p id="Par68">The classification error for predicting language delay is computed using Eq. (<a href="#Equ3" class="usa-link">3</a>):</p>
<table class="disp-formula p" id="Equ3"><tr>
<td class="formula"><math id="d33e2004" display="block"><mrow><msub><mrow><mi>L</mi></mrow><mrow><mi>L</mi><mi>D</mi></mrow></msub><mo>=</mo><mo>−</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mi>N</mi></mrow></mfrac><munderover accent="false" accentunder="false"><mrow><mo>∑</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>N</mi></mrow></munderover><mfenced close="]" open="["><mrow><msub><mrow><mi>z</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>⋅</mo><mi>log</mi><mrow><mo>(</mo><mrow><msub><mrow><mi>q</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow><mo>)</mo></mrow><mo>+</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>−</mo><msub><mrow><mi>z</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow><mo>)</mo></mrow><mo>⋅</mo><mi>log</mi><mrow><mo>(</mo><mrow><mn>1</mn><mo>−</mo><msub><mrow><mi>q</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow><mo>)</mo></mrow></mrow></mfenced></mrow></math></td>
<td class="label">3</td>
</tr></table>
<p>Here, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq7"><math id="d33e2078"><mi>N</mi></math></span> represents the total number of samples, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq8"><math id="d33e2087"><msub><mrow><mi>z</mi></mrow><mrow><mi>i</mi></mrow></msub></math></span> is the true binary label for language delay (1 for delay, 0 for no delay), and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq9"><math id="d33e2100"><msub><mrow><mi>q</mi></mrow><mrow><mi>i</mi></mrow></msub></math></span> is the predicted probability of language delay for sample <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq10"><math id="d33e2114"><mi>i</mi></math></span>.</p></section><section id="Sec23"><h3 class="pmc_sec_title">Model training and evaluation</h3>
<p id="Par69">The dataset used for training and evaluation for Stage 1 comprised data from 273 TD, 175 high-risk, and 370 ASD participants. Model training was conducted using 5-fold stratified cross-validation. For each fold, the data was split into ~70% training, 10% validation, and 20% held-out test set. The splits were stratified by class (TD, HR, ASD) to maintain class balance across all subsets. The same partitioning was used consistently across both training stages.</p>
<p id="Par70">The ‘RoBERTa-large’ model was initialized with pre-trained weights, serving as the text pathway for feature extraction from the preprocessed textual data. Concurrently, the Whisper model encoder was fine-tuned across all its layers on our dataset, rather than being used as a frozen feature extractor, to form the audio pathway. In addition to the primary classification task (distinguishing typically developing from high-risk/ASD children), an auxiliary classifier was included to predict language delay status, leveraging the model’s ability to capture clinically relevant vocal features. The model was trained using the cross-entropy loss function for both the main classification task and the auxiliary language delay task. No explicit data augmentation was applied to the audio recordings; this decision was based on the natural variability and ambient noise present in the real-world clinical and home environments, as preliminary experiments showed that artificial augmentation degraded performance.</p>
<p id="Par71">Features from the audio (Whisper encoder hidden states) and text (RoBERTa embeddings) models were concatenated at the feature level before being fed into a fully connected neural network for classification. This multimodal fusion allowed the model to jointly leverage both vocal and linguistic information. No ensemble methods were employed during inference; the final predictions were generated by this single integrated multimodal model.</p>
<p id="Par72">Hyperparameters were set as follows: a batch size of 4, trained for 10 epochs, a fixed learning rate of 1e-5, and a weight decay of 0.01. The AdamW optimizer was employed, and no learning rate scheduler was used. While explicit early stopping with patience was not applied, the model checkpoint with the lowest validation loss during training was selected and saved for evaluation. During inference, the trained model was set to evaluation mode and processed test data in batches of 64, without shuffling. Model performance was evaluated using AUC, accuracy, and loss, calculated on the held-out test set for each fold.</p></section><section id="Sec24"><h3 class="pmc_sec_title">Stage 2 model development</h3>
<p id="Par73">This stage integrated data from two sources: the outcomes of parent-child interaction tasks and responses from the Social Responsiveness Scale-2 (SRS-2). The success or failure of each of the six parent-child interaction tasks was recorded. The criteria for determining success or failure were based on clinically relevant behavioral markers. Examples of these markers include responding to a name within two attempts, correctly imitating at least one action, and engaging in symbolic play. The initial task success/failure labels were primarily provided by parents during the assessment. To ensure validity and quality control, these parent-reported labels for a stratified sample of 50 subjects (comprising 227 total task items) were rigorously validated against video-reviewed ground truth by experienced clinicians. A subset of 10 subjects (46 tasks) underwent re-review by clinicians to ensure clarity and consistency. Consistency was further ensured through a comprehensive inter-rater reliability analysis; Cohen’s kappa (κ) was calculated to quantify the agreement between parent-reported labels and clinician video reviews, yielding <em>κ</em> = 0.885 (95% CI: 0.85–0.92). This indicates “almost perfect agreement” according to Landis and Koch (1977)<sup><a href="#CR49" class="usa-link" aria-describedby="CR49">49</a></sup> benchmarks. The raw observed agreement was 94.27% (214 agreed items out of 227 total items), with only 13 discrepancies identified, representing an exceptionally low mismatch rate of 5.7% for clinical and behavioral studies. This robust reliability supports the validity and quality of the parent-reported task outcomes used in our study. Like the text preprocessing in Stage 1, SRS survey responses were mapped to ASD-related terms to enhance the extraction of relevant information. The task success/failure data, represented as binary outcomes for each task, and the mapped SRS terms were combined to train a RoBERTa-Large model using fine-tuning. The model was trained for 10 epochs with a batch size of 8 and a learning rate of 2e-5. A cross-entropy loss function and the AdamW optimizer were employed for training. To prevent overfitting, early stopping based on validation loss was implemented. This trained model achieved a promising AUC of 0.93.</p></section><section id="Sec25"><h3 class="pmc_sec_title">Stage 2 model training and evaluation</h3>
<p id="Par74">For Stage 2, model training and evaluation involved a dataset of 162 High-Risk and 353 ASD children. We employed StratifiedGroupKFold for all splits to ensure consistency in labels and subject grouping across the dataset. An initial approximate 80:10:10 (train:validation: test) split was performed, which was later updated following the inclusion of new subjects, resulting in final sample counts of Train (455), Validation (58), and Test (57). Fixed train/validation/test sets were used for evaluation, rather than explicit cross-validation folds in this stage.</p>
<p id="Par75">The RoBERTa-Large model was fine-tuned for 10 epochs. An effective batch size of 32 was used, achieved with a per-device train batch size of 8 and a gradient accumulation of 4 steps. The learning rate was fixed at 2e-5, and a weight decay of 1e-8 was used for regularization, with 0 warmup steps. Evaluation and model saving occurred per epoch, and the best model was loaded based on the lowest evaluation loss on the validation set (load_best_model_at_end = True, metric_for_best_model = “eval_loss”). No explicit hyperparameter search was performed, with the listed values being those used for fine-tuning. A cross-entropy loss function and the AdamW optimizer were employed for training.</p>
<p id="Par76">Model performance was comprehensively evaluated using several metrics. The Area Under the Receiver Operating Characteristic curve (AUROC) was used to assess the model’s ability to discriminate between classes. The F1-score, the harmonic mean of precision and recall, provided a balanced measure of accuracy, while overall accuracy measured the correctness of the model’s predictions. Precision, the proportion of accurate positive predictions among all positive predictions, and recall, the proportion of accurate positive predictions among all actual positive cases, were also calculated.</p></section><section id="Sec26"><h3 class="pmc_sec_title">Model calibration and correlation analysis</h3>
<p id="Par77">Furthermore, the ECE was computed to quantify the alignment between predicted probabilities and observed frequencies across multiple bins. The ECE is calculated using the formula shown in Eq. (<a href="#Equ4" class="usa-link">4</a>):</p>
<table class="disp-formula p" id="Equ4"><tr>
<td class="formula"><math id="d33e2161" display="block"><mrow><mi mathvariant="italic">ECE</mi><mo>=</mo><msubsup><mo>∑</mo><mrow><mfenced close="}" open="{"><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow></mfenced></mrow><mrow><msub><mrow><mi>N</mi></mrow><mrow><mi mathvariant="italic">bins</mi></mrow></msub></mrow></msubsup><mrow><mfrac><mrow><mfenced close="|" open="|"><mrow><msub><mrow><mi>B</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow></mfenced></mrow><mrow><mi>N</mi></mrow></mfrac></mrow><mo>*</mo><mi mathvariant="italic">|accuracy</mi><mrow><mfenced close=")" open="("><mrow><msub><mrow><mi>B</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow></mfenced></mrow><mo>−</mo><mi mathvariant="italic">confidence</mi><mrow><mfenced close=")" open="("><mrow><msub><mrow><mi>B</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow></mfenced></mrow><mi>|</mi></mrow></math></td>
<td class="label">4</td>
</tr></table>
<p id="Par78">In this equation, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq11"><math id="d33e2224"><msub><mrow><mi>B</mi></mrow><mrow><mi>i</mi></mrow></msub></math></span> represents the i-th bin containing predicted probabilities, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq12"><math id="d33e2237"><mrow><msub><mrow><mi mathvariant="italic">|B</mi></mrow><mrow><mi>i</mi></mrow></msub><mi>|</mi></mrow></math></span> is the number of predictions within that bin, and N is the total number of predictions. The term <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq13"><math id="d33e2253"><mrow><mi mathvariant="italic">accuracy</mi><mrow><mfenced close=")" open="("><mrow><msub><mrow><mi>B</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow></mfenced></mrow></mrow></math></span> refers to the fraction of true positives in bin i, while <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq14"><math id="d33e2272"><mrow><mi mathvariant="italic">confidence</mi><mrow><mfenced close=")" open="("><mrow><msub><mrow><mi>B</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow></mfenced></mrow></mrow></math></span> is the mean predicted probability for the predictions in that same bin.</p>
<p id="Par79">A lower ECE indicates better calibration, meaning the predicted probabilities more accurately reflect the actual likelihood of the outcome.</p>
<p id="Par80">Isotonic regression was employed for calibration to ensure that the model’s predicted probabilities aligned with clinically defined ADOS-2 risk categories. Isotonic regression is a non-parametric method that adjusts the predicted probabilities to better match the observed outcomes while preserving the original ranking of predictions (monotonicity).</p>
<p id="Par81">The calibrated probabilities <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq15"><math id="d33e2297"><msub><mrow><mi>p</mi></mrow><mrow><mi mathvariant="italic">cal</mi></mrow></msub></math></span> are obtained by solving the optimization problem shown in Eq. (<a href="#Equ5" class="usa-link">5</a>):</p>
<table class="disp-formula p" id="Equ5"><tr>
<td class="formula"><math id="d33e2315" display="block"><mrow><msub><mrow><mi>P</mi></mrow><mrow><mi mathvariant="italic">cal</mi></mrow></msub><mo>=</mo><mi mathvariant="italic">argmin</mi><msubsup><mo>∑</mo><mrow><mrow><mfenced close="}" open="{"><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow></mfenced></mrow><mo>,</mo><msub><mrow><mi>P</mi></mrow><mrow><mi mathvariant="italic">iso</mi></mrow></msub></mrow><mrow><mi>N</mi></mrow></msubsup><mrow><msup><mrow><mfenced close=")" open="("><mrow><msub><mrow><mi>P</mi></mrow><mrow><mi mathvariant="italic">iso</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>−</mo><msub><mrow><mi>y</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow></mfenced></mrow><mrow><mn>2</mn></mrow></msup><mi mathvariant="italic">subject to</mi><msub><mrow><mi>P</mi></mrow><mrow><mfenced close="}" open="{"><mrow><mi mathvariant="italic">iso</mi><mo>,</mo><mi mathvariant="italic"> i</mi></mrow></mfenced></mrow></msub></mrow><mo>≤</mo><msub><mrow><mi>P</mi></mrow><mrow><mi mathvariant="italic">iso</mi><mo>,</mo><mi>j</mi></mrow></msub><mi mathvariant="italic">for i</mi><mo>&lt;</mo><mi>j</mi><mo>)</mo></mrow></math></td>
<td class="label">5</td>
</tr></table>
<p id="Par82">In this equation, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq16"><math id="d33e2400"><msub><mrow><mi>P</mi></mrow><mrow><mi mathvariant="italic">iso</mi></mrow></msub></math></span> represents the isotonic probabilities, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq17"><math id="d33e2414"><msub><mrow><mi>y</mi></mrow><mrow><mi>i</mi></mrow></msub></math></span> is the true label for the <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq18"><math id="d33e2427"><msub><mrow><mi>i</mi></mrow><mrow><mi mathvariant="italic">th</mi></mrow></msub></math></span> sample, and N is the total number of samples.</p>
<p id="Par83">We used 10 equal-width bins (edges at 0.0, 0.1, …, 1.0) to compute ECE (Eq. <a href="#Equ4" class="usa-link">4</a>), and we fitted a scikit-learn Isotonic Regression (PAV algorithm, out_of_bounds = “clip”) to obtain calibrated probabilities under the monotonicity constraint (Eq. <a href="#Equ5" class="usa-link">5</a>).</p>
<p id="Par84">To investigate the relationship between the model’s predicted probabilities and ADOS scores, both Pearson and Spearman correlation analyses were conducted. The Pearson correlation coefficient (“r”), which measures the linear relationship between two variables, was calculated using the following formula.</p>
<p id="Par85">The Pearson correlation coefficient, which measures the linear relationship between two variables, is calculated using Eq. (<a href="#Equ6" class="usa-link">6</a>):</p>
<table class="disp-formula p" id="Equ6"><tr>
<td class="formula"><math id="d33e2457" display="block"><mrow><mi mathvariant="normal">r</mi><mo>=</mo><mfrac><mrow><msubsup><mrow><mo mathsize="big">∑</mo></mrow><mrow><mi mathvariant="normal">i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi mathvariant="normal">n</mi></mrow></msubsup><mfenced close=")" open="("><mrow><msub><mrow><mi mathvariant="normal">x</mi></mrow><mrow><mi mathvariant="normal">i</mi></mrow></msub><mo>−</mo><mover accent="true"><mrow><mi mathvariant="normal">x</mi></mrow><mo>¯</mo></mover></mrow></mfenced><mfenced close=")" open="("><mrow><msub><mrow><mi mathvariant="normal">y</mi></mrow><mrow><mi mathvariant="normal">i</mi></mrow></msub><mo>−</mo><mover accent="true"><mrow><mi mathvariant="normal">y</mi></mrow><mo>¯</mo></mover></mrow></mfenced></mrow><mrow><msqrt><mrow><munderover accent="false" accentunder="false"><mrow><mo>∑</mo></mrow><mrow><mi mathvariant="normal">i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi mathvariant="normal">n</mi></mrow></munderover><msup><mrow><mfenced close=")" open="("><mrow><msub><mrow><mi mathvariant="normal">x</mi></mrow><mrow><mi mathvariant="normal">i</mi></mrow></msub><mo>−</mo><mover accent="true"><mrow><mi mathvariant="normal">x</mi></mrow><mo>¯</mo></mover></mrow></mfenced></mrow><mrow><mn>2</mn></mrow></msup><munderover accent="false" accentunder="false"><mrow><mo>∑</mo></mrow><mrow><mi mathvariant="normal">i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi mathvariant="normal">n</mi></mrow></munderover><msup><mrow><mfenced close=")" open="("><mrow><msub><mrow><mi mathvariant="normal">y</mi></mrow><mrow><mi mathvariant="normal">i</mi></mrow></msub><mo>−</mo><mover accent="true"><mrow><mi mathvariant="normal">y</mi></mrow><mo>¯</mo></mover></mrow></mfenced></mrow><mrow><mn>2</mn></mrow></msup></mrow></msqrt></mrow></mfrac></mrow></math></td>
<td class="label">6</td>
</tr></table>
<p id="Par86">In this equation, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq19"><math id="d33e2577"><msub><mrow><mi mathvariant="normal">x</mi></mrow><mrow><mi mathvariant="normal">i</mi></mrow></msub></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq20"><math id="d33e2592"><msub><mrow><mi mathvariant="normal">y</mi></mrow><mrow><mi mathvariant="normal">i</mi></mrow></msub></math></span> are the values of the first variable (Mean Calibrated Probabilities) and the second variable (ADOS-2 total(T) score) respectively, while <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq21"><math id="d33e2607"><mover accent="true"><mrow><mi mathvariant="normal">x</mi></mrow><mo>®</mo></mover></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq22"><math id="d33e2620"><mover accent="true"><mrow><mi mathvariant="normal">y</mi></mrow><mo>®</mo></mover></math></span> are the means of each variable. The term n represents the total number of data points.</p>
<p id="Par87">The Spearman rank correlation coefficient ρ, a non-parametric measure of rank correlation, was also calculated using Eq. (<a href="#Equ7" class="usa-link">7</a>):</p>
<table class="disp-formula p" id="Equ7"><tr>
<td class="formula"><math id="d33e2640" display="block"><mrow><mi>ρ</mi><mo>=</mo><mn>1</mn><mo>−</mo><mfrac><mrow><mfenced close=")" open="("><mrow><mn>6</mn><mi mathvariant="normal">Σ</mi><msup><mrow><mi mathvariant="normal">di</mi></mrow><mrow><mn>2</mn></mrow></msup></mrow></mfenced></mrow><mrow><mi mathvariant="normal">n</mi><mrow><mfenced close=")" open="("><mrow><msup><mrow><mi mathvariant="normal">n</mi></mrow><mrow><mn>2</mn></mrow></msup><mo>−</mo><mn>1</mn></mrow></mfenced></mrow></mrow></mfrac></mrow></math></td>
<td class="label">7</td>
</tr></table>
<p id="Par88">Here, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq23"><math id="d33e2681"><msub><mrow><mi>d</mi></mrow><mrow><mi>i</mi></mrow></msub></math></span> is the difference in ranks between the two variables for each data point <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq24"><math id="d33e2694"><mi>i</mi></math></span> (i.e., <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq25"><math id="d33e2703"><mrow><mtext>Rank</mtext><mrow><mfenced close=")" open="("><mrow><msub><mrow><mi>x</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow></mfenced></mrow><mo>−</mo><mtext>Rank</mtext><mrow><mfenced close=")" open="("><mrow><msub><mrow><mi>y</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow></mfenced></mrow></mrow></math></span> and n is the number of data points.</p>
<p id="Par89">ADOS scores were scaled to a range of 0–1 for these analyses. For risk stratification, a data-driven threshold optimization procedure was employed to define thresholds for classifying individuals into “Low Risk,” “Moderate Risk,” and “High Risk” categories based on the calibrated predicted probabilities. The thresholds were optimized to maximize agreement (measured by accuracy) with ADOS-2 based risk categories. These ADOS-2 based risk categories were defined as follows: Low Risk: ADOS-2 TOTAL(T) &lt; 7; Moderate Risk: 7 ≤ ADOS-2 TOTAL(T) ≤ 13; and High Risk: ADOS-2 TOTAL(T) &gt; 13. The optimization process involved a grid search over a range of threshold values. The lower threshold (t1) varied from 0.1 to 0.45 in increments of 0.05, and the upper threshold (t2) ranged from t1 + 0.1 to 0.85 in increments of 0.05.</p></section><section id="Sec27"><h3 class="pmc_sec_title">Risk stratification and threshold optimization</h3>
<p id="Par90">As shown in Eq. (<a href="#Equ8" class="usa-link">8</a>), the predicted risk <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq26"><math id="d33e2740"><msub><mrow><mi>R</mi></mrow><mrow><mi>p</mi></mrow></msub></math></span> is classified based on the calibrated probability (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq27"><math id="d33e2753"><mi>P</mi></math></span>) using two thresholds <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq28"><math id="d33e2762"><msub><mrow><mi>T</mi></mrow><mrow><mn>1</mn></mrow></msub></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq29"><math id="d33e2775"><msub><mrow><mi>T</mi></mrow><mrow><mn>2</mn></mrow></msub></math></span>:</p>
<table class="disp-formula p" id="Equ8"><tr>
<td class="formula"><math id="d33e2790" display="block"><mrow><msub><mrow><mi>R</mi></mrow><mrow><mi>p</mi></mrow></msub><mo>=</mo><mfenced open="{"><mrow><mtable><mtr><mtd columnalign="left"><mi mathvariant="normal">Low</mi><mspace width="0.25em"></mspace><mi mathvariant="normal">Risk</mi><mo>,</mo><mi>P</mi><mo>&lt;</mo><msub><mrow><mi>T</mi></mrow><mrow><mn>1</mn></mrow></msub></mtd></mtr><mtr><mtd columnalign="left"><mi mathvariant="normal">Moderate</mi><mspace width="0.25em"></mspace><mi mathvariant="normal">Risk</mi><mo>,</mo><msub><mrow><mi>T</mi></mrow><mrow><mn>1</mn></mrow></msub><mo>≤</mo><mi>P</mi><mo>≤</mo><msub><mrow><mi>T</mi></mrow><mrow><mn>2</mn></mrow></msub></mtd></mtr><mtr><mtd columnalign="left"><mi mathvariant="normal">High</mi><mspace width="0.25em"></mspace><mi mathvariant="normal">Risk</mi><mo>,</mo><mi>P</mi><mo>&gt;</mo><msub><mrow><mi>T</mi></mrow><mrow><mn>2</mn></mrow></msub></mtd></mtr></mtable></mrow></mfenced></mrow></math></td>
<td class="label">8</td>
</tr></table>
<p id="Par91">In this equation, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq30"><math id="d33e2860"><mi>P</mi></math></span> represents the predicted probability (e.g., the mean calibrated probability for an individual), while <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq31"><math id="d33e2869"><msub><mrow><mi>T</mi></mrow><mrow><mn>1</mn></mrow></msub></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq32"><math id="d33e2882"><msub><mrow><mi>T</mi></mrow><mrow><mn>2</mn></mrow></msub></math></span> T2 are the thresholds that separate the risk groups.</p>
<p id="Par92">As defined in Eq. (<a href="#Equ9" class="usa-link">9</a>), the ADOS risk <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq33"><math id="d33e2900"><msub><mrow><mi>R</mi></mrow><mrow><mi>a</mi></mrow></msub></math></span> is determined using the ADOS-2 TOTAL(T) score(<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq34"><math id="d33e2913"><mi>S</mi></math></span>) with fixed thresholds <em>S</em><sub>1</sub> and <em>S</em><sub>2</sub>:</p>
<table class="disp-formula p" id="Equ9"><tr>
<td class="formula"><math id="d33e2932" display="block"><mrow><msub><mrow><mi>R</mi></mrow><mrow><mi>a</mi></mrow></msub><mo>=</mo><mfenced open="{"><mrow><mtable><mtr><mtd columnalign="left"><mi mathvariant="normal">Low</mi><mspace width="0.25em"></mspace><mi mathvariant="normal">Risk</mi><mo>,</mo><mi>S</mi><mo>&lt;</mo><msub><mrow><mi>S</mi></mrow><mrow><mn>1</mn></mrow></msub></mtd></mtr><mtr><mtd columnalign="left"><mi mathvariant="normal">Moderate</mi><mi mathvariant="normal">Risk</mi><mo>,</mo><msub><mrow><mi>S</mi></mrow><mrow><mn>1</mn></mrow></msub><mo>≤</mo><mi>S</mi><mo>≤</mo><msub><mrow><mi>S</mi></mrow><mrow><mn>2</mn></mrow></msub></mtd></mtr><mtr><mtd columnalign="left"><mi mathvariant="normal">High</mi><mspace width="0.25em"></mspace><mi mathvariant="normal">Risk</mi><mo>,</mo><mi>S</mi><mo>&gt;</mo><msub><mrow><mi>S</mi></mrow><mrow><mn>2</mn></mrow></msub></mtd></mtr></mtable></mrow></mfenced></mrow></math></td>
<td class="label">9</td>
</tr></table>
<p id="Par93">In this equation, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq35"><math id="d33e3001"><mi>S</mi></math></span> is the ADOS-2 TOTAL(T) score for an individual, while <em>S</em><sub>1</sub> and <em>S</em><sub>2</sub> are the thresholds for the ADOS risk categories (e.g.,<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq36"><math id="d33e3018"><msub><mrow><mi>S</mi></mrow><mrow><mn>1</mn></mrow></msub></math></span> = 7, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq37"><math id="d33e3032"><msub><mrow><mi>S</mi></mrow><mrow><mn>2</mn></mrow></msub></math></span> = 13).</p>
<p id="Par94">The combined risk <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq38"><math id="d33e3047"><msub><mrow><mi>R</mi></mrow><mrow><mi>c</mi></mrow></msub></math></span> is fusion of <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq39"><math id="d33e3060"><msub><mrow><mi>R</mi></mrow><mrow><mi>p</mi></mrow></msub></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq40"><math id="d33e3073"><msub><mrow><mi>R</mi></mrow><mrow><mi>a</mi></mrow></msub></math></span>, is defined as shown in Eq. (<a href="#Equ10" class="usa-link">10</a>):</p>
<table class="disp-formula p" id="Equ10"><tr>
<td class="formula"><math id="d33e3090" display="block"><mrow><msub><mrow><mi>R</mi></mrow><mrow><mi>c</mi></mrow></msub><mo>=</mo><mfenced open="{"><mrow><mtable><mtr><mtd columnalign="left"><mspace width="2.0em"></mspace><mspace width="2.0em"></mspace><mspace width="2.0em"></mspace><mspace width="2.0em"></mspace><mspace width="2.0em"></mspace><mstyle><mtext>High</mtext></mstyle><mspace width="0.25em"></mspace><mstyle><mtext>Risk</mtext></mstyle><mo>,</mo><mspace width="2.0em"></mspace><msub><mrow><mi>R</mi></mrow><mrow><mi>p</mi></mrow></msub><mo>=</mo><mi mathvariant="normal">High</mi><mspace width="0.16em"></mspace><mi mathvariant="normal">Risk</mi><mspace width="0.16em"></mspace><mi>a</mi><mi>n</mi><mi>d</mi><mspace width="0.25em"></mspace><msub><mrow><mi>R</mi></mrow><mrow><mi>a</mi></mrow></msub><mo>=</mo><mi mathvariant="normal">High</mi><mspace width="0.16em"></mspace><mi mathvariant="normal">Risk</mi></mtd></mtr><mtr><mtd columnalign="left"><mi mathvariant="normal">Moderate</mi><mspace width="0.16em"></mspace><mi mathvariant="normal">Risk</mi><mo>,</mo><mrow><mo>(</mo><mrow><msub><mrow><mi>R</mi></mrow><mrow><mi>p</mi></mrow></msub><mo>=</mo><mi mathvariant="normal">Moderate</mi><mspace width="0.16em"></mspace><mi mathvariant="normal">Risk</mi><mspace width="0.16em"></mspace><mi>a</mi><mi>n</mi><mi>d</mi><mspace width="0.25em"></mspace><msub><mrow><mi>R</mi></mrow><mrow><mi>a</mi></mrow></msub><mo>=</mo><mi mathvariant="normal">High</mi><mspace width="0.16em"></mspace><mi mathvariant="normal">Risk</mi></mrow><mo>)</mo></mrow><mspace width="0.25em"></mspace><mi mathvariant="normal">or</mi><mspace width="0.25em"></mspace><mrow><mo>(</mo><mrow><msub><mrow><mi>R</mi></mrow><mrow><mi>p</mi></mrow></msub><mo>=</mo><mi mathvariant="normal">High</mi><mspace width="0.16em"></mspace><mi mathvariant="normal">Risk</mi><mspace width="0.16em"></mspace><mi>a</mi><mi>n</mi><mi>d</mi><mspace width="0.25em"></mspace><msub><mrow><mi>R</mi></mrow><mrow><mi>a</mi></mrow></msub><mo>=</mo><mi mathvariant="normal">Moderate</mi><mspace width="0.16em"></mspace><mi mathvariant="normal">Risk</mi></mrow><mo>)</mo></mrow></mtd></mtr><mtr><mtd columnalign="left"><mspace width="2.0em"></mspace><mspace width="2.0em"></mspace><mspace width="2.0em"></mspace><mspace width="2.0em"></mspace><mspace width="2.0em"></mspace><mspace width="2.0em"></mspace><mspace width="2.0em"></mspace><mstyle><mtext>Low</mtext></mstyle><mspace width="0.25em"></mspace><mstyle><mtext>Risk</mtext></mstyle><mo>,</mo><mspace width="2.0em"></mspace><mstyle><mtext>otherwise</mtext></mstyle></mtd></mtr></mtable></mrow></mfenced></mrow></math></td>
<td class="label">10</td>
</tr></table>
<p id="Par95">The agreement metric (A) measures the similarity between <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq41"><math id="d33e3247"><msub><mrow><mi mathvariant="normal">R</mi></mrow><mrow><mi mathvariant="normal">p</mi></mrow></msub></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq42"><math id="d33e3262"><msub><mrow><mi mathvariant="normal">R</mi></mrow><mrow><mi mathvariant="normal">a</mi></mrow></msub></math></span>, can be computed using accuracy as defined in Eq. (<a href="#Equ11" class="usa-link">11</a>):</p>
<table class="disp-formula p" id="Equ11"><tr>
<td class="formula"><math id="d33e3281" display="block"><mrow><mi mathvariant="normal">A</mi><mo>=</mo><mfrac><mrow><mi mathvariant="normal">Number</mi><mspace width="0.25em"></mspace><mi mathvariant="normal">of</mi><mspace width="0.25em"></mspace><mi mathvariant="normal">Correct</mi><mspace width="0.25em"></mspace><mi mathvariant="normal">Matches</mi><mspace width="0.25em"></mspace><mi mathvariant="normal">Between</mi><mspace width="0.25em"></mspace><msub><mrow><mi mathvariant="normal">R</mi></mrow><mrow><mi mathvariant="normal">p</mi></mrow></msub><mi mathvariant="normal">and</mi><mspace width="0.25em"></mspace><msub><mrow><mi mathvariant="normal">R</mi></mrow><mrow><mi mathvariant="normal">a</mi></mrow></msub></mrow><mrow><mi mathvariant="normal">Total</mi><mspace width="0.25em"></mspace><mi mathvariant="normal">Number</mi><mspace width="0.25em"></mspace><mi mathvariant="normal">of</mi><mspace width="0.25em"></mspace><mi mathvariant="normal">Predictions</mi></mrow></mfrac></mrow></math></td>
<td class="label">11</td>
</tr></table>
<p id="Par96">Alternatively, Eq. (<a href="#Equ12" class="usa-link">12</a>) defines the agreement using a weighted F1 score formulation:</p>
<table class="disp-formula p" id="Equ12"><tr>
<td class="formula"><math id="d33e3345" display="block"><mrow><mtext>F</mtext><mn>1</mn><mtext> Score</mtext><mo>=</mo><mfrac><mrow><msubsup><mo>∑</mo><mrow><mi mathvariant="normal">i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi mathvariant="normal">n</mi></mrow></msubsup><mrow><msub><mrow><mi mathvariant="normal">W</mi></mrow><mrow><mi mathvariant="normal">i</mi></mrow></msub></mrow><mo>⋅</mo><mfrac><mrow><mn>2</mn><mo>⋅</mo><mi mathvariant="normal">T</mi><msub><mrow><mi mathvariant="normal">P</mi></mrow><mrow><mi mathvariant="normal">i</mi></mrow></msub></mrow><mrow><mn>2</mn><mo>⋅</mo><mi mathvariant="normal">T</mi><msub><mrow><mi mathvariant="normal">P</mi></mrow><mrow><mi mathvariant="normal">i</mi></mrow></msub><mo>+</mo><mi mathvariant="normal">F</mi><msub><mrow><mi mathvariant="normal">P</mi></mrow><mrow><mi mathvariant="normal">i</mi></mrow></msub><mo>+</mo><mi mathvariant="normal">F</mi><msub><mrow><mi mathvariant="normal">N</mi></mrow><mrow><mi mathvariant="normal">i</mi></mrow></msub></mrow></mfrac></mrow><mrow><msubsup><mo>∑</mo><mrow><mi mathvariant="normal">i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi mathvariant="normal">n</mi></mrow></msubsup><mrow><msub><mrow><mi mathvariant="normal">W</mi></mrow><mrow><mi mathvariant="normal">i</mi></mrow></msub></mrow></mrow></mfrac></mrow></math></td>
<td class="label">12</td>
</tr></table>
<p id="Par97">In this formula, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq43"><math id="d33e3444"><mrow><mi>T</mi><msub><mrow><mi>P</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow></math></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq44"><math id="d33e3459"><mrow><mi>F</mi><msub><mrow><mi>P</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow></math></span>, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq45"><math id="d33e3474"><mrow><mi>F</mi><msub><mrow><mi>N</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow></math></span> are the true positives, false positives, and false negatives for class <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq46"><math id="d33e3489"><mi>i</mi></math></span>, respectively. The term <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq47"><math id="d33e3498"><msub><mrow><mi>W</mi></mrow><mrow><mi>i</mi></mrow></msub></math></span> represents the weight for class <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq48"><math id="d33e3512"><mi>i</mi></math></span>, which is proportional to its representation in the dataset.</p>
<p id="Par98">The optimal thresholds <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq49"><math id="d33e3523"><mrow><mfenced close=")" open="("><mrow><msubsup><mrow><mi>T</mi></mrow><mrow><mn>1</mn></mrow><mrow><mo>*</mo></mrow></msubsup><mo>,</mo><msubsup><mrow><mi>T</mi></mrow><mrow><mn>2</mn></mrow><mrow><mo>*</mo></mrow></msubsup></mrow></mfenced></mrow></math></span>, which maximize the agreement metric, are determined by solving the optimization problem shown in Eq. (<a href="#Equ13" class="usa-link">13</a>):</p>
<table class="disp-formula p" id="Equ13"><tr>
<td class="formula"><math id="d33e3553" display="block"><mrow><mfenced close=")" open="("><mrow><msubsup><mrow><mi>T</mi></mrow><mrow><mn>1</mn></mrow><mrow><mo>*</mo></mrow></msubsup><mo>,</mo><msubsup><mrow><mi>T</mi></mrow><mrow><mn>2</mn></mrow><mrow><mo>*</mo></mrow></msubsup></mrow></mfenced></mrow><mo>=</mo><mtext>argmax</mtext><mi>A</mi><mrow><mfenced close=")" open="("><mrow><msub><mrow><mi>T</mi></mrow><mrow><mn>1</mn></mrow></msub><mo>,</mo><msub><mrow><mi>T</mi></mrow><mrow><mn>2</mn></mrow></msub></mrow></mfenced></mrow></math></td>
<td class="label">13</td>
</tr></table>
<p id="Par99">This optimization is performed by iterating the thresholds <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq50"><math id="d33e3597"><mrow><msub><mrow><mi>T</mi></mrow><mrow><mn>1</mn></mrow></msub><mi mathvariant="italic"> and</mi><msub><mrow><mi>T</mi></mrow><mrow><mn>2</mn></mrow></msub></mrow></math></span> over a defined range (e.g., <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq51"><math id="d33e3618"><mrow><msub><mrow><mi>T</mi></mrow><mrow><mn>1</mn></mrow></msub><mo>∈</mo><mrow><mfenced close="]" open="["><mrow><mn>0.1,0.5</mn></mrow></mfenced></mrow><mo>,</mo><msub><mrow><mi>T</mi></mrow><mrow><mn>2</mn></mrow></msub><mo>∈</mo><mrow><mfenced close="]" open="["><mrow><msub><mrow><mi>T</mi></mrow><mrow><mn>1</mn></mrow></msub><mo>+</mo><mn>0.1,0.9</mn></mrow></mfenced></mrow></mrow></math></span>), where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq52"><math id="d33e3654"><mrow><mi>A</mi><mrow><mfenced close=")" open="("><mrow><msub><mrow><mi>T</mi></mrow><mrow><mn>1</mn></mrow></msub><mo>,</mo><msub><mrow><mi>T</mi></mrow><mrow><mn>2</mn></mrow></msub></mrow></mfenced></mrow></mrow></math></span> is the agreement metric computed for each pair of thresholds.</p>
<p id="Par100">A combined risk assessment strategy was implemented by integrating both the model-predicted risk and the ADOS-2-based risk. This combined risk was determined according to the following criteria: An individual was classified as “High Risk” if either the model-predicted risk or the ADOS-2 risk was high. “Moderate Risk” was assigned if one of the risks was moderate and the other was high. Finally, an individual was classified as “Low Risk” if both the model-predicted risk and the ADOS-2 risk were either low or moderate. This combined approach aimed to leverage the strengths of the AI model and the established clinical assessment.</p></section><section id="Sec28"><h3 class="pmc_sec_title">Statistical analysis</h3>
<p id="Par101">Descriptive statistics summarized participant characteristics. Chi-square tests with post-hoc Bonferroni correction examined associations between categorical variables. Statistical significance was set at <em>p</em> &lt; 0.05. Analyses used Python (version 3.9) with pandas, NumPy, SciPy, scikit-learn, statsmodels, Matplotlib, torch, torchaudio, transformers, and Seaborn libraries. We trained the model using a Quadro RTX 8000. The model was implemented using PyTorch, utilizing a GPU with fixed random seeds for ensuring reproducibility.</p></section></section><section id="Sec29"><h2 class="pmc_sec_title">Supplementary information</h2>
<section class="sm xbox font-sm" id="MOESM1"><div class="media p"><div class="caption">
<a href="/articles/instance/12370947/bin/41746_2025_1914_MOESM1_ESM.pdf" data-ga-action="click_feat_suppl" class="usa-link">Supplementary Information</a><sup> (1.6MB, pdf) </sup>
</div></div></section></section><section id="ack1" class="ack"><h2 class="pmc_sec_title">Acknowledgements</h2>
<p>This study was supported by funding from the National Center for Mental Health (grant number: MHER22A01) and the Digital Healthcare Center at Severance Hospital, Yonsei University College of Medicine. We thank the clinicians and research staff at the nine participating hospitals for their assistance with data collection and validation. We are also grateful to the children and families who participated in this study.</p></section><section id="notes1"><h2 class="pmc_sec_title">Author contributions</h2>
<p>Concept and Design: S.B., J.H., H.K. Data Acquisition, Preprocessing, Cleaning and Validation: S.H., J.Y., H.C., J.L., R.D., H.S., H.K., H.L., M.P., E.K., C.Y., D.L., H.Y., Y.L., G.B., J.I.K., H.S., H.K., E.J., S.C., J.S., J.H.Y., S.J. Model Development and Analysis: S.B., J.H. Data Interpretation and Clinical Inference: S.H., R.D., B.K., K.C.•Drafting of the Manuscript: S.B. Critical Revision for Intellectual Content: J.H., S.H., J.M., H.K., R.D. •Statistical Analysis: S.B., J.H., J.M. Supervision: H.K., B.K., K.C. All authors have read and approved the final manuscript.</p></section><section id="notes2"><h2 class="pmc_sec_title">Data availability</h2>
<p>The raw datasets generated and analyzed during the current study are not publicly available due to their sensitive nature, which includes identifiable clinical information and audio recordings of child participants. Public dissemination of this data would breach patient privacy and violate the terms of the Institutional Review Board (IRB) approval under which it was collected. To facilitate reproducibility, a comprehensive data schema defining the structure and variables of the minimal dataset is provided in Supplementary Data <a href="#MOESM1" class="usa-link">1</a>. This schema details all variables derived from clinical assessments (ADOS-2, PRES, SELSI), screening questionnaires (MCHAT, SCQ-L, SRS-2), and audio feature extraction, as used in the final analyses. The processed data itself cannot be shared. However, the provided schema allows other researchers to structure their own datasets in the same format, enabling them to replicate our methodology and analyses.</p></section><section id="notes3"><h2 class="pmc_sec_title">Code availability</h2>
<p>The complete source code used for data preprocessing, model development, training, and analysis is openly available in a GitHub repository: <a href="https://github.com/skwgbobf/Multimodal-AI-ASD-Risk-ScreeningF" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/skwgbobf/Multimodal-AI-ASD-Risk-ScreeningF</a>. The repository includes the Jupyter notebooks used to generate the final datasets for both stages of the model (e.g., Stage1_model/notebooks/1.Preprocess_git.ipynb and stage2_model/notebooks/1_Data_Preprocessing/model2_data preprocess_Final.ipynb), the implementation of the two-stage deep learning framework, and all scripts required to reproduce the results presented in the manuscript.</p></section><section id="FPar1"><h2 class="pmc_sec_title">Competing interests</h2>
<p id="Par102">The authors declare no competing interests.</p></section><section id="fn-group1" class="fn-group"><h2 class="pmc_sec_title">Footnotes</h2>
<div class="fn-group p font-secondary-light font-sm"><div class="fn p" id="fn1"><p><strong>Publisher’s note</strong> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div></section><section id="_ci93_" lang="en" class="contrib-info"><h2 class="pmc_sec_title">Contributor Information</h2>
<p>Hwiyoung Kim, Email: hykim82@yuhs.ac.</p>
<p>Bung-Nyun Kim, Email: kbn1@snu.ac.kr.</p>
<p>Keun-Ah Cheon, Email: kacheon@yuhs.ac.</p></section><section id="sec30"><h2 class="pmc_sec_title">Supplementary information</h2>
<p>The online version contains supplementary material available at 10.1038/s41746-025-01914-6.</p></section><section id="Bib1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="Bib1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="CR1">
<span class="label">1.</span><cite>Perochon, S. et al. Early detection of autism using digital behavioral phenotyping. <em>Nat. Med.</em><strong>29</strong>, 2489–2497 (2023).
</cite> [<a href="https://doi.org/10.1038/s41591-023-02574-3" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10579093/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37783967/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Perochon,%20S.%20et%20al.%20Early%20detection%20of%20autism%20using%20digital%20behavioral%20phenotyping.%20Nat.%20Med.29,%202489%E2%80%932497%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR2">
<span class="label">2.</span><cite>Stevens, E. et al. Identification and analysis of behavioral phenotypes in autism spectrum disorder via unsupervised machine learning. Int. J. Med. Inform. <strong>129</strong>, 29–36 (2019).</cite> [<a href="https://doi.org/10.1016/j.ijmedinf.2019.05.006" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31445269/" class="usa-link">PubMed</a>]</li>
<li id="CR3">
<span class="label">3.</span><cite>Qin, L. et al. New advances in the diagnosis and treatment of autism spectrum disorders. <em>Eur. J. Med. Res.</em><strong>29</strong>, 322 (2024).
</cite> [<a href="https://doi.org/10.1186/s40001-024-01916-2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11163702/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38858682/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Qin,%20L.%20et%20al.%20New%20advances%20in%20the%20diagnosis%20and%20treatment%20of%20autism%20spectrum%20disorders.%20Eur.%20J.%20Med.%20Res.29,%20322%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR4">
<span class="label">4.</span><cite>Ilias, L., Mouzakitis, S. &amp; Askounis, D. Calibration of transformer-based models for identifying stress and depression in social media. <em>IEEE Trans. Comput. Soc. Syst.</em><strong>1</strong>, 12 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Ilias,%20L.,%20Mouzakitis,%20S.%20&amp;%20Askounis,%20D.%20Calibration%20of%20transformer-based%20models%20for%20identifying%20stress%20and%20depression%20in%20social%20media.%20IEEE%20Trans.%20Comput.%20Soc.%20Syst.1,%2012%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR5">
<span class="label">5.</span><cite>Kim, S. W. &amp; Yoo, H. J. <em>Korean Childhood Autism Rating Scale</em> 2nd edn (K-CARS-2) (Hakjisa Publisher, 2020).</cite>
</li>
<li id="CR6">
<span class="label">6.</span><cite>Christiansz, J. A. et al. Autism spectrum disorder in the DSM-5: diagnostic sensitivity and specificity in early childhood. <em>J. Autism Dev. Disord.</em><strong>46</strong>, 2054–2063 (2016).
</cite> [<a href="https://doi.org/10.1007/s10803-016-2734-4" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/26861716/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Christiansz,%20J.%20A.%20et%20al.%20Autism%20spectrum%20disorder%20in%20the%20DSM-5:%20diagnostic%20sensitivity%20and%20specificity%20in%20early%20childhood.%20J.%20Autism%20Dev.%20Disord.46,%202054%E2%80%932063%20(2016)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR7">
<span class="label">7.</span><cite>Kohli, M., Kar, A. K. &amp; Sinha, S. The role of intelligent technologies in early detection of autism spectrum disorder (ASD): a scoping review. <em>IEEE Access</em><strong>10</strong>, 104887–104913 (2022).</cite> [<a href="https://scholar.google.com/scholar_lookup?Kohli,%20M.,%20Kar,%20A.%20K.%20&amp;%20Sinha,%20S.%20The%20role%20of%20intelligent%20technologies%20in%20early%20detection%20of%20autism%20spectrum%20disorder%20(ASD):%20a%20scoping%20review.%20IEEE%20Access10,%20104887%E2%80%93104913%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR8">
<span class="label">8.</span><cite>Zhu, F. L. et al. A multimodal machine learning system in early screening for toddlers with autism spectrum disorders based on the response to name. <em>Front. Psychiatry</em><strong>14</strong>, 1039293 (2023).
</cite> [<a href="https://doi.org/10.3389/fpsyt.2023.1039293" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9909188/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36778637/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Zhu,%20F.%20L.%20et%20al.%20A%20multimodal%20machine%20learning%20system%20in%20early%20screening%20for%20toddlers%20with%20autism%20spectrum%20disorders%20based%20on%20the%20response%20to%20name.%20Front.%20Psychiatry14,%201039293%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR9">
<span class="label">9.</span><cite>Anagnostopoulou, P. et al. Artificial intelligence in autism assessment. <em>Int. J. Emerg. Technol. Learn.</em><strong>15</strong>, 95–107 (2020).</cite> [<a href="https://scholar.google.com/scholar_lookup?Anagnostopoulou,%20P.%20et%20al.%20Artificial%20intelligence%20in%20autism%20assessment.%20Int.%20J.%20Emerg.%20Technol.%20Learn.15,%2095%E2%80%93107%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR10">
<span class="label">10.</span><cite>Megerian, J. T. et al. An artificial intelligence-based medical device to aid the diagnosis of autism spectrum disorder. <em>npj Digit. Med.</em><strong>5</strong>, 57 (2022).
</cite> [<a href="https://doi.org/10.1038/s41746-022-00598-6" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9072329/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35513550/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Megerian,%20J.%20T.%20et%20al.%20An%20artificial%20intelligence-based%20medical%20device%20to%20aid%20the%20diagnosis%20of%20autism%20spectrum%20disorder.%20npj%20Digit.%20Med.5,%2057%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR11">
<span class="label">11.</span><cite>Zhu, X. et al. RMER-DT: robust multimodal emotion recognition in conversational contexts based on diffusion and transformers. <em>Inf. Fusion</em><strong>123</strong>, 103268 (2025)</cite>
</li>
<li id="CR12">
<span class="label">12.</span><cite>Rubio-Martín, S. et al. Enhancing ASD detection accuracy: a combined approach of machine learning and deep learning models with natural language processing. <em>Health Inf. Sci. Syst.</em><strong>12</strong>, 20 (2024).
</cite> [<a href="https://doi.org/10.1007/s13755-024-00281-y" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10917721/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38455725/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Rubio-Mart%C3%ADn,%20S.%20et%20al.%20Enhancing%20ASD%20detection%20accuracy:%20a%20combined%20approach%20of%20machine%20learning%20and%20deep%20learning%20models%20with%20natural%20language%20processing.%20Health%20Inf.%20Sci.%20Syst.12,%2020%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR13">
<span class="label">13.</span><cite>Zhao, M. et al. Development of a phenotype ontology for autism spectrum disorder by natural language processing on electronic health records. <em>J. Neurodev. Disord.</em><strong>14</strong>, 32 (2022).
</cite> [<a href="https://doi.org/10.1186/s11689-022-09442-0" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9128253/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35606697/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Zhao,%20M.%20et%20al.%20Development%20of%20a%20phenotype%20ontology%20for%20autism%20spectrum%20disorder%20by%20natural%20language%20processing%20on%20electronic%20health%20records.%20J.%20Neurodev.%20Disord.14,%2032%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR14">
<span class="label">14.</span><cite>Sariyanidi, E. et al. Comparison of human experts and AI in predicting autism from facial behavior. <em>CEUR Workshop Proc.</em><strong>3359</strong>, 48–57 (2023).
</cite> [<a href="/articles/PMC10687770/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38037663/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Sariyanidi,%20E.%20et%20al.%20Comparison%20of%20human%20experts%20and%20AI%20in%20predicting%20autism%20from%20facial%20behavior.%20CEUR%20Workshop%20Proc.3359,%2048%E2%80%9357%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR15">
<span class="label">15.</span><cite>Moridian, P. et al. Automatic autism spectrum disorder detection using artificial intelligence methods with MRI neuroimaging: a review. <em>Front. Mol. Neurosci.</em><strong>15</strong>, 999605 (2022).
</cite> [<a href="https://doi.org/10.3389/fnmol.2022.999605" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9577321/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36267703/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Moridian,%20P.%20et%20al.%20Automatic%20autism%20spectrum%20disorder%20detection%20using%20artificial%20intelligence%20methods%20with%20MRI%20neuroimaging:%20a%20review.%20Front.%20Mol.%20Neurosci.15,%20999605%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR16">
<span class="label">16.</span><cite>Helmy, E. et al. Role of artificial intelligence for autism diagnosis using DTI and fMRI: a survey. <em>Biomedicines</em><strong>11</strong>, 1858 (2023).
</cite> [<a href="https://doi.org/10.3390/biomedicines11071858" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10376963/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37509498/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Helmy,%20E.%20et%20al.%20Role%20of%20artificial%20intelligence%20for%20autism%20diagnosis%20using%20DTI%20and%20fMRI:%20a%20survey.%20Biomedicines11,%201858%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR17">
<span class="label">17.</span><cite>Sohl, K. et al. Feasibility and impact of integrating an artificial intelligence–based diagnosis aid for autism into the extension for community health outcomes autism primary care model: protocol for a prospective observational study. <em>JMIR Res. Protoc.</em><strong>11</strong>, e37576 (2022).
</cite> [<a href="https://doi.org/10.2196/37576" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9346562/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35852831/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Sohl,%20K.%20et%20al.%20Feasibility%20and%20impact%20of%20integrating%20an%20artificial%20intelligence%E2%80%93based%20diagnosis%20aid%20for%20autism%20into%20the%20extension%20for%20community%20health%20outcomes%20autism%20primary%20care%20model:%20protocol%20for%20a%20prospective%20observational%20study.%20JMIR%20Res.%20Protoc.11,%20e37576%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR18">
<span class="label">18.</span><cite>Xu, A. et al. Understanding spoken language development of children with ASD using pre-trained speech embeddings. arXiv <a href="https://arxiv.org/abs/2305.14117" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2305.14117</a> (2023).</cite>
</li>
<li id="CR19">
<span class="label">19.</span><cite>Eni, M. et al. Estimating autism severity in young children from speech signals using a deep neural network. <em>IEEE Access</em><strong>8</strong>, 139489–139500 (2020).</cite> [<a href="https://scholar.google.com/scholar_lookup?Eni,%20M.%20et%20al.%20Estimating%20autism%20severity%20in%20young%20children%20from%20speech%20signals%20using%20a%20deep%20neural%20network.%20IEEE%20Access8,%20139489%E2%80%93139500%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR20">
<span class="label">20.</span><cite>Rahman, M. M. et al. A review of machine learning methods of feature selection and classification for autism spectrum disorder. <em>Brain Sci.</em><strong>10</strong>, 949 (2020).
</cite> [<a href="https://doi.org/10.3390/brainsci10120949" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7762227/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33297436/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Rahman,%20M.%20M.%20et%20al.%20A%20review%20of%20machine%20learning%20methods%20of%20feature%20selection%20and%20classification%20for%20autism%20spectrum%20disorder.%20Brain%20Sci.10,%20949%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR21">
<span class="label">21.</span><cite>Han, J., Jiang, G., Ouyang, G. &amp; Li, X. A multimodal approach for identifying autism spectrum disorders in children. <em>IEEE Trans. Neural Syst. Rehabil. Eng.</em><strong>30</strong>, 2003–2011 (2022).
</cite> [<a href="https://doi.org/10.1109/TNSRE.2022.3192431" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35853070/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Han,%20J.,%20Jiang,%20G.,%20Ouyang,%20G.%20&amp;%20Li,%20X.%20A%20multimodal%20approach%20for%20identifying%20autism%20spectrum%20disorders%20in%20children.%20IEEE%20Trans.%20Neural%20Syst.%20Rehabil.%20Eng.30,%202003%E2%80%932011%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR22">
<span class="label">22.</span><cite>Dcouto, S. S. &amp; Pradeepkandhasamy, J. Multimodal deep learning in early autism detection—recent advances and challenges. <em>Eng. Proc.</em><strong>59</strong>, 205 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Dcouto,%20S.%20S.%20&amp;%20Pradeepkandhasamy,%20J.%20Multimodal%20deep%20learning%20in%20early%20autism%20detection%E2%80%94recent%20advances%20and%20challenges.%20Eng.%20Proc.59,%20205%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR23">
<span class="label">23.</span><cite>Tamizhmalar, D., Subbiah, S. &amp; Premkumar, R. A multimodal diagnostic framework for autism spectrum disorder using deep learning: an in-depth exploration. In <em>Proc. 2024 International Conference on. Power, Energy, Control and Transmission Systems</em><em>(ICPECTS)</em> 1–5 (IEEE, 2024).</cite>
</li>
<li id="CR24">
<span class="label">24.</span><cite>Luo, J., Phan, H. &amp; Reiss, J. Cross-modal fusion techniques for utterance-level emotion recognition from text and speech. In <em>Proc. 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> 1–5 (IEEE, 2023).</cite>
</li>
<li id="CR25">
<span class="label">25.</span><cite>Hazarika, D., Poria, S., Majumder, N., &amp; Cambria, E. CIME: contextual interaction-based multimodal emotion analysis with enhanced semantic information. In <em>Proc. 2018 Conference on Empirical Methods in Natural Language Processing</em> 4467–4477 (2018).</cite>
</li>
<li id="CR26">
<span class="label">26.</span><cite>Wang, R., Wang, Y., Cambria, E., Zhu, X. &amp; Liu, Z. Contrastive-based removal of negative information in multimodal emotion analysis. <em>Cogn. Comput.</em><strong>17</strong>, 107–118 (2025).</cite> [<a href="https://scholar.google.com/scholar_lookup?Wang,%20R.,%20Wang,%20Y.,%20Cambria,%20E.,%20Zhu,%20X.%20&amp;%20Liu,%20Z.%20Contrastive-based%20removal%20of%20negative%20information%20in%20multimodal%20emotion%20analysis.%20Cogn.%20Comput.17,%20107%E2%80%93118%20(2025)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR27">
<span class="label">27.</span><cite>Milling, M. et al. Evaluating the impact of voice activity detection on speech emotion recognition for autistic children. <em>Front. Comput. Sci.</em><strong>4</strong>, 837269 (2022).</cite> [<a href="https://scholar.google.com/scholar_lookup?Milling,%20M.%20et%20al.%20Evaluating%20the%20impact%20of%20voice%20activity%20detection%20on%20speech%20emotion%20recognition%20for%20autistic%20children.%20Front.%20Comput.%20Sci.4,%20837269%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR28">
<span class="label">28.</span><cite>Lee, J. H. et al. Deep-learning-based detection of infants with autism spectrum disorder using auto-encoder feature representation. <em>Sensors</em><strong>20</strong>, 6762 (2020).
</cite> [<a href="https://doi.org/10.3390/s20236762" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7731374/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33256061/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Lee,%20J.%20H.%20et%20al.%20Deep-learning-based%20detection%20of%20infants%20with%20autism%20spectrum%20disorder%20using%20auto-encoder%20feature%20representation.%20Sensors20,%206762%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR29">
<span class="label">29.</span><cite>Korkmaz, C., Cirakman, E., Tekalp, A. M., &amp; Dogan, Z. Trustworthy SR: Resolving Ambiguity in Image Super-resolution via Diffusion Models and Human Feedback. arXiv preprint arXiv:2402.07597 (2024).</cite>
</li>
<li id="CR30">
<span class="label">30.</span><cite>Zhu, X. et al. A client-server based recognition system: non-contact single/multiple emotional and behavioral state assessment methods. <em>Comput. Biol. Med</em>. <strong>260</strong>, 108564 (2025).</cite> [<a href="https://doi.org/10.1016/j.cmpb.2024.108564" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39732086/" class="usa-link">PubMed</a>]</li>
<li id="CR31">
<span class="label">31.</span><cite>Zhang, Y., Wang, X., Wen, J. &amp; Zhu, X. WiFi-based non-contact human presence detection technology. <em>Sci. Rep.</em><strong>14</strong>, 3605 (2024).
</cite> [<a href="https://doi.org/10.1038/s41598-024-54077-x" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10864388/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38351067/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Zhang,%20Y.,%20Wang,%20X.,%20Wen,%20J.%20&amp;%20Zhu,%20X.%20WiFi-based%20non-contact%20human%20presence%20detection%20technology.%20Sci.%20Rep.14,%203605%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR32">
<span class="label">32.</span><cite>Zheng, J. et al. Dynamic spectral graph anomaly detection. In <em>Proc. AAAI Conference on Artificial Intelligence</em> Vol. 39, 13410–13418 (2025).</cite>
</li>
<li id="CR33">
<span class="label">33.</span><cite>Liu, Y. et al. RoBERTa: a robustly optimized BERT pretraining approach. arXiv preprint arXiv:1907.11692 364 (2019).</cite>
</li>
<li id="CR34">
<span class="label">34.</span><cite>Radford, A. et al. Robust speech recognition via large-scale weak supervision. In <em>Proc. 40th International Conference on Machine Learning (ICML)</em> Vol. 202, 28492–28518 (PMLR, 2023).</cite>
</li>
<li id="CR35">
<span class="label">35.</span><cite>Gong, Y. et al. AST: audio spectrogram transformer. <a href="https://arxiv.org/abs/2104.01778" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2104.01778</a> (2021).</cite>
</li>
<li id="CR36">
<span class="label">36.</span><cite>Nixon, J. et al. Measuring calibration in deep learning. In <em>Proc. CVPR Workshops</em> Vol. 2, 7 (2019).</cite>
</li>
<li id="CR37">
<span class="label">37.</span><cite>Buddenkotte, T. et al. Calibrating ensembles for scalable uncertainty quantification in deep learning-based medical image segmentation. <em>Comput. Biol. Med.</em><strong>163</strong>, 107096 (2023).
</cite> [<a href="https://doi.org/10.1016/j.compbiomed.2023.107096" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37302375/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Buddenkotte,%20T.%20et%20al.%20Calibrating%20ensembles%20for%20scalable%20uncertainty%20quantification%20in%20deep%20learning-based%20medical%20image%20segmentation.%20Comput.%20Biol.%20Med.163,%20107096%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR38">
<span class="label">38.</span><cite>Choi, E. S. et al. Applying artificial intelligence for diagnostic classification of Korean autism spectrum disorder. <em>Psychiatry Investig.</em><strong>17</strong>, 1090–1095 (2020).
</cite> [<a href="https://doi.org/10.30773/pi.2020.0211" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7711119/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33099989/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Choi,%20E.%20S.%20et%20al.%20Applying%20artificial%20intelligence%20for%20diagnostic%20classification%20of%20Korean%20autism%20spectrum%20disorder.%20Psychiatry%20Investig.17,%201090%E2%80%931095%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR39">
<span class="label">39.</span><cite>Abdar, M. et al. A review of uncertainty quantification in deep learning: techniques, applications and challenges. <em>Inf. Fusion</em><strong>76</strong>, 243–297 (2021).</cite> [<a href="https://scholar.google.com/scholar_lookup?Abdar,%20M.%20et%20al.%20A%20review%20of%20uncertainty%20quantification%20in%20deep%20learning:%20techniques,%20applications%20and%20challenges.%20Inf.%20Fusion76,%20243%E2%80%93297%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR40">
<span class="label">40.</span><cite>Chang, M. C. et al. The use of artificial intelligence to predict the prognosis of patients undergoing central nervous system rehabilitation: a narrative review. <em>Healthcare</em><strong>11</strong>, 2687 (2023).
</cite> [<a href="https://doi.org/10.3390/healthcare11192687" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10572243/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37830724/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Chang,%20M.%20C.%20et%20al.%20The%20use%20of%20artificial%20intelligence%20to%20predict%20the%20prognosis%20of%20patients%20undergoing%20central%20nervous%20system%20rehabilitation:%20a%20narrative%20review.%20Healthcare11,%202687%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR41">
<span class="label">41.</span><cite>Huang, S. C. et al. Fusion of medical imaging and electronic health records using deep learning: a systematic review and implementation guidelines. <em>npj Digit. Med.</em><strong>3</strong>, 136 (2020).
</cite> [<a href="https://doi.org/10.1038/s41746-020-00341-z" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7567861/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33083571/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Huang,%20S.%20C.%20et%20al.%20Fusion%20of%20medical%20imaging%20and%20electronic%20health%20records%20using%20deep%20learning:%20a%20systematic%20review%20and%20implementation%20guidelines.%20npj%20Digit.%20Med.3,%20136%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR42">
<span class="label">42.</span><cite>Lakshminarayanan, B., Pritzel, A. &amp; Blundell, C. Simple and scalable predictive uncertainty estimation using deep ensembles. <em>Advances in Neural Information Processing Systems</em><strong>30</strong> (2017).</cite>
</li>
<li id="CR43">
<span class="label">43.</span><cite>Wilson, A. G. &amp; Izmailov, P. Bayesian deep learning and a probabilistic perspective of generalization. <em>Adv. Neural Inf. Process. Syst.</em><strong>33</strong>, 4697–4708 (2020).</cite> [<a href="https://scholar.google.com/scholar_lookup?Wilson,%20A.%20G.%20&amp;%20Izmailov,%20P.%20Bayesian%20deep%20learning%20and%20a%20probabilistic%20perspective%20of%20generalization.%20Adv.%20Neural%20Inf.%20Process.%20Syst.33,%204697%E2%80%934708%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR44">
<span class="label">44.</span><cite>Hüllermeier, E. &amp; Waegeman, W. Aleatoric and epistemic uncertainty in machine learning: an introduction to concepts and methods. <em>Mach. Learn</em><strong>110</strong>, 457–506 (2021).</cite> [<a href="https://scholar.google.com/scholar_lookup?H%C3%BCllermeier,%20E.%20&amp;%20Waegeman,%20W.%20Aleatoric%20and%20epistemic%20uncertainty%20in%20machine%20learning:%20an%20introduction%20to%20concepts%20and%20methods.%20Mach.%20Learn110,%20457%E2%80%93506%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR45">
<span class="label">45.</span><cite>Western Psychological Services. <em>Autism Diagnostic Observation Schedule</em> 2nd edn (ADOS-2) (Western Psychological Services, 2013).</cite>
</li>
<li id="CR46">
<span class="label">46.</span><cite>Mujeeb Rahman, K. K. &amp; Subashini, M. A deep neural network-based model for screening autism spectrum disorder using the quantitative checklist for autism in toddlers (QCHAT). <em>J. Autism Dev. Disord.</em><strong>52</strong>, 1–15 (2022).
</cite> [<a href="https://doi.org/10.1007/s10803-021-05141-2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34191261/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Mujeeb%20Rahman,%20K.%20K.%20&amp;%20Subashini,%20M.%20A%20deep%20neural%20network-based%20model%20for%20screening%20autism%20spectrum%20disorder%20using%20the%20quantitative%20checklist%20for%20autism%20in%20toddlers%20(QCHAT).%20J.%20Autism%20Dev.%20Disord.52,%201%E2%80%9315%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR47">
<span class="label">47.</span><cite>Robins, D. L., Deborah Fein, and Marianne Barton. Modified checklist for autism in toddlers, revised, with follow-up (M-CHAT-R/F) TM. LineageN (2009).</cite> [<a href="https://doi.org/10.1542/peds.2013-1813" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3876182/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/24366990/" class="usa-link">PubMed</a>]</li>
<li id="CR48">
<span class="label">48.</span><cite>Ilse, M. et al. Attention-based deep multiple instance learning. In <em>Proc. 35th International conference on machine (ICML)</em> Vol. 80, 2127–2136 (PMLR, 2018).</cite>
</li>
<li id="CR49">
<span class="label">49.</span><cite>Landis, J. R. &amp; Koch, G. G. The measurement of observer agreement for categorical data. <em>Biometrics</em><strong>33</strong>, 159–174 (1977).
</cite> [<a href="https://pubmed.ncbi.nlm.nih.gov/843571/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Landis,%20J.%20R.%20&amp;%20Koch,%20G.%20G.%20The%20measurement%20of%20observer%20agreement%20for%20categorical%20data.%20Biometrics33,%20159%E2%80%93174%20(1977)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adsm93_" lang="en" class="supplementary-materials"><h3 class="pmc_sec_title">Supplementary Materials</h3>
<section class="sm xbox font-sm" id="db_ds_supplementary-material1_reqid_"><div class="media p"><div class="caption">
<a href="/articles/instance/12370947/bin/41746_2025_1914_MOESM1_ESM.pdf" data-ga-action="click_feat_suppl" class="usa-link">Supplementary Information</a><sup> (1.6MB, pdf) </sup>
</div></div></section></section><section id="_adda93_" lang="en" class="data-availability-statement"><h3 class="pmc_sec_title">Data Availability Statement</h3>
<p>The raw datasets generated and analyzed during the current study are not publicly available due to their sensitive nature, which includes identifiable clinical information and audio recordings of child participants. Public dissemination of this data would breach patient privacy and violate the terms of the Institutional Review Board (IRB) approval under which it was collected. To facilitate reproducibility, a comprehensive data schema defining the structure and variables of the minimal dataset is provided in Supplementary Data <a href="#MOESM1" class="usa-link">1</a>. This schema details all variables derived from clinical assessments (ADOS-2, PRES, SELSI), screening questionnaires (MCHAT, SCQ-L, SRS-2), and audio feature extraction, as used in the final analyses. The processed data itself cannot be shared. However, the provided schema allows other researchers to structure their own datasets in the same format, enabling them to replicate our methodology and analyses.</p>
<p>The complete source code used for data preprocessing, model development, training, and analysis is openly available in a GitHub repository: <a href="https://github.com/skwgbobf/Multimodal-AI-ASD-Risk-ScreeningF" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/skwgbobf/Multimodal-AI-ASD-Risk-ScreeningF</a>. The repository includes the Jupyter notebooks used to generate the final datasets for both stages of the model (e.g., Stage1_model/notebooks/1.Preprocess_git.ipynb and stage2_model/notebooks/1_Data_Preprocessing/model2_data preprocess_Final.ipynb), the implementation of the two-stage deep learning framework, and all scripts required to reproduce the results presented in the manuscript.</p></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from NPJ Digital Medicine are provided here courtesy of <strong>Nature Publishing Group</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1038/s41746-025-01914-6"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/41746_2025_Article_1914.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (2.0 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12370947/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12370947/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12370947%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370947/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12370947/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12370947/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40841482/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12370947/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40841482/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12370947/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12370947/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="guo3G5fMLGjyshOLh4MKMXHe411nEk6S01eHHUzVPBsfnoXIXKHXVqOVpDeKH18O">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
        <script type="module" crossorigin="" src="/static/assets/math-574fdcc6.js"></script>
    
    

    </body>
</html>
