
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            Deep-learning-based endoscopic single-shot fringe projection profilometry - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="15254D4C8AF3DAC3054D4C00454DCBA9.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="jbiomedopt">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12364446/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="Journal of Biomedical Optics">
<meta name="citation_title" content="Deep-learning-based endoscopic single-shot fringe projection profilometry">
<meta name="citation_author" content="Ruizhi Zuo">
<meta name="citation_author_institution" content="Johns Hopkins University, Department of Electrical and Computer Engineering, Baltimore, Maryland, United States">
<meta name="citation_author" content="Shuwen Wei">
<meta name="citation_author_institution" content="Johns Hopkins University, Department of Electrical and Computer Engineering, Baltimore, Maryland, United States">
<meta name="citation_author" content="Yaning Wang">
<meta name="citation_author_institution" content="Johns Hopkins University, Department of Electrical and Computer Engineering, Baltimore, Maryland, United States">
<meta name="citation_author" content="Ruichen Huang">
<meta name="citation_author_institution" content="Johns Hopkins University, Department of Mechanical Engineering, Baltimore, Maryland, United States">
<meta name="citation_author" content="Wayne Wonseok Rodgers">
<meta name="citation_author_institution" content="Johns Hopkins University, Department of Electrical and Computer Engineering, Baltimore, Maryland, United States">
<meta name="citation_author" content="Jinglun Yu">
<meta name="citation_author_institution" content="Johns Hopkins University, Department of Electrical and Computer Engineering, Baltimore, Maryland, United States">
<meta name="citation_author" content="Michael H Hsieh">
<meta name="citation_author_institution" content="Children’s National Hospital, Division of Urology, Washington, DC, United States">
<meta name="citation_author" content="Axel Krieger">
<meta name="citation_author_institution" content="Johns Hopkins University, Department of Mechanical Engineering, Baltimore, Maryland, United States">
<meta name="citation_author" content="Jin U Kang">
<meta name="citation_author_institution" content="Johns Hopkins University, Department of Electrical and Computer Engineering, Baltimore, Maryland, United States">
<meta name="citation_author_institution" content="Johns Hopkins University, School of Medicine, Baltimore, Maryland, United States">
<meta name="citation_publication_date" content="2025 Aug 19">
<meta name="citation_volume" content="30">
<meta name="citation_issue" content="8">
<meta name="citation_firstpage" content="086003">
<meta name="citation_doi" content="10.1117/1.JBO.30.8.086003">
<meta name="citation_pmid" content="40837448">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12364446/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12364446/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12364446/pdf/JBO-030-086003.pdf">
<meta name="description" content="Conventional fringe projection profilometry (FPP) requires multiple image acquisitions and therefore long acquisition times that make it slow for high-speed dynamic measurements. We propose and demonstrate a deep-learning-based single-shot FPP ...">
<meta name="og:title" content="Deep-learning-based endoscopic single-shot fringe projection profilometry">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="Conventional fringe projection profilometry (FPP) requires multiple image acquisitions and therefore long acquisition times that make it slow for high-speed dynamic measurements. We propose and demonstrate a deep-learning-based single-shot FPP ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12364446/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12364446">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1117/1.JBO.30.8.086003"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/JBO-030-086003.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12364446%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12364446/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12364446/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12364446/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-jbiomedopt.jpg" alt="Journal of Biomedical Optics logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to Journal of Biomedical Optics" title="Link to Journal of Biomedical Optics" shape="default" href="http://biomedicaloptics.spiedigitallibrary.org/journal.aspx" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">J Biomed Opt</button></div>. 2025 Aug 19;30(8):086003. doi: <a href="https://doi.org/10.1117/1.JBO.30.8.086003" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1117/1.JBO.30.8.086003</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22J%20Biomed%20Opt%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22J%20Biomed%20Opt%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22J%20Biomed%20Opt%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22J%20Biomed%20Opt%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Deep-learning-based endoscopic single-shot fringe projection profilometry</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Zuo%20R%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Ruizhi Zuo</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Ruizhi Zuo</span></h3>
<div class="p">
<sup>a</sup>Johns Hopkins University, Department of Electrical and Computer Engineering, Baltimore, Maryland, United States</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Zuo%20R%22%5BAuthor%5D" class="usa-link"><span class="name western">Ruizhi Zuo</span></a>
</div>
</div>
<sup>a,</sup><sup>*</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Wei%20S%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Shuwen Wei</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">Shuwen Wei</span></h3>
<div class="p">
<sup>a</sup>Johns Hopkins University, Department of Electrical and Computer Engineering, Baltimore, Maryland, United States</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Wei%20S%22%5BAuthor%5D" class="usa-link"><span class="name western">Shuwen Wei</span></a>
</div>
</div>
<sup>a</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Wang%20Y%22%5BAuthor%5D" class="usa-link" aria-describedby="id3"><span class="name western">Yaning Wang</span></a><div hidden="hidden" id="id3">
<h3><span class="name western">Yaning Wang</span></h3>
<div class="p">
<sup>a</sup>Johns Hopkins University, Department of Electrical and Computer Engineering, Baltimore, Maryland, United States</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Wang%20Y%22%5BAuthor%5D" class="usa-link"><span class="name western">Yaning Wang</span></a>
</div>
</div>
<sup>a</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Huang%20R%22%5BAuthor%5D" class="usa-link" aria-describedby="id4"><span class="name western">Ruichen Huang</span></a><div hidden="hidden" id="id4">
<h3><span class="name western">Ruichen Huang</span></h3>
<div class="p">
<sup>b</sup>Johns Hopkins University, Department of Mechanical Engineering, Baltimore, Maryland, United States</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Huang%20R%22%5BAuthor%5D" class="usa-link"><span class="name western">Ruichen Huang</span></a>
</div>
</div>
<sup>b</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Rodgers%20WW%22%5BAuthor%5D" class="usa-link" aria-describedby="id5"><span class="name western">Wayne Wonseok Rodgers</span></a><div hidden="hidden" id="id5">
<h3><span class="name western">Wayne Wonseok Rodgers</span></h3>
<div class="p">
<sup>a</sup>Johns Hopkins University, Department of Electrical and Computer Engineering, Baltimore, Maryland, United States</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Rodgers%20WW%22%5BAuthor%5D" class="usa-link"><span class="name western">Wayne Wonseok Rodgers</span></a>
</div>
</div>
<sup>a</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Yu%20J%22%5BAuthor%5D" class="usa-link" aria-describedby="id6"><span class="name western">Jinglun Yu</span></a><div hidden="hidden" id="id6">
<h3><span class="name western">Jinglun Yu</span></h3>
<div class="p">
<sup>a</sup>Johns Hopkins University, Department of Electrical and Computer Engineering, Baltimore, Maryland, United States</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Yu%20J%22%5BAuthor%5D" class="usa-link"><span class="name western">Jinglun Yu</span></a>
</div>
</div>
<sup>a</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Hsieh%20MH%22%5BAuthor%5D" class="usa-link" aria-describedby="id7"><span class="name western">Michael H Hsieh</span></a><div hidden="hidden" id="id7">
<h3><span class="name western">Michael H Hsieh</span></h3>
<div class="p">
<sup>c</sup>Children’s National Hospital, Division of Urology, Washington, DC, United States</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Hsieh%20MH%22%5BAuthor%5D" class="usa-link"><span class="name western">Michael H Hsieh</span></a>
</div>
</div>
<sup>c</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Krieger%20A%22%5BAuthor%5D" class="usa-link" aria-describedby="id8"><span class="name western">Axel Krieger</span></a><div hidden="hidden" id="id8">
<h3><span class="name western">Axel Krieger</span></h3>
<div class="p">
<sup>b</sup>Johns Hopkins University, Department of Mechanical Engineering, Baltimore, Maryland, United States</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Krieger%20A%22%5BAuthor%5D" class="usa-link"><span class="name western">Axel Krieger</span></a>
</div>
</div>
<sup>b</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kang%20JU%22%5BAuthor%5D" class="usa-link" aria-describedby="id9"><span class="name western">Jin U Kang</span></a><div hidden="hidden" id="id9">
<h3><span class="name western">Jin U Kang</span></h3>
<div class="p">
<sup>a</sup>Johns Hopkins University, Department of Electrical and Computer Engineering, Baltimore, Maryland, United States</div>
<div class="p">
<sup>d</sup>Johns Hopkins University, School of Medicine, Baltimore, Maryland, United States</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kang%20JU%22%5BAuthor%5D" class="usa-link"><span class="name western">Jin U Kang</span></a>
</div>
</div>
<sup>a,</sup><sup>d</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="aff1">
<sup>a</sup>Johns Hopkins University, Department of Electrical and Computer Engineering, Baltimore, Maryland, United States</div>
<div id="aff2">
<sup>b</sup>Johns Hopkins University, Department of Mechanical Engineering, Baltimore, Maryland, United States</div>
<div id="aff3">
<sup>c</sup>Children’s National Hospital, Division of Urology, Washington, DC, United States</div>
<div id="aff4">
<sup>d</sup>Johns Hopkins University, School of Medicine, Baltimore, Maryland, United States</div>
<div class="author-notes p"><div class="fn" id="cor1">
<sup>*</sup><p class="display-inline">Address all correspondence to Ruizhi Zuo, <span>rzuo3@jhu.edu</span></p>
</div></div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2025 Feb 9; Revised 2025 Jul 29; Accepted 2025 Aug 1; Issue date 2025 Aug.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© 2025 The Authors</div>
<p>Published by SPIE under a Creative Commons Attribution 4.0 International License. Distribution or reproduction of this work in whole or in part requires full attribution of the original publication, including its DOI.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12364446  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40837448/" class="usa-link">40837448</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="abstract1"><h2>Abstract.</h2>
<section id="sec1_pmc"><h3 class="pmc_sec_title">Significance</h3>
<p>Conventional fringe projection profilometry (FPP) requires multiple image acquisitions and therefore long acquisition times that make it slow for high-speed dynamic measurements. We propose and demonstrate a deep-learning-based single-shot FPP system utilizing a single endoscope for surgical guidance.</p></section><section id="sec2_pmc"><h3 class="pmc_sec_title">Aim</h3>
<p>We aim to achieve real-time depth map generation of target tissues with high accuracy for robotic surgical guidance.</p></section><section id="sec3_pmc"><h3 class="pmc_sec_title">Approach</h3>
<p>We proposed an endoscopic single-shot FPP system based on a deep learning network to generate real-time accurate tissue depth maps for surgical guidance. The system utilizes a dual-channel endoscope, where one channel projects fringe patterns from a projector and the other channel collects images using a camera. In addition, we developed a data synthesis method to generate a large number of diverse training datasets. The network consists of MaskNet, which segments the tissue from the background, and DepthNet, which predicts the depth map of the image. The results from both networks are combined to generate the final depth map.</p></section><section id="sec4_pmc"><h3 class="pmc_sec_title">Results</h3>
<p>We tested our algorithm using fringe patterns with different frequencies and found that the optimal frequency for single-shot FPP in our setup is 20 Hz. The algorithm has been tested on both synthetic and experimental data, achieving a maximum depth prediction error of <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math1" display="inline" overflow="linebreak"><mrow><mo form="prefix">∼</mo><mn>2</mn><mtext>  </mtext><mi>mm</mi></mrow></math></span> and a processing time of about 12.75 ms per frame.</p></section><section id="sec5_pmc"><h3 class="pmc_sec_title">Conclusion</h3>
<p>A deep-learning-based single-shot FPP endoscopic system was shown to be highly effective in real-time depth map generation with millimeter-scale error. Implementing such a system has the potential to improve the reliability of image-guided robotic surgery.</p></section><section id="kwd-group1" class="kwd-group"><p><strong>Keywords:</strong> 3D optical imaging, fringe projection profilometry, endoscope, deep learning, surgery guidance</p></section></section><section id="sec1"><h2 class="pmc_sec_title">1. Introduction</h2>
<p>Fringe projection profilometry (FPP) is a camera-based three-dimensional (3D) optical imaging technique that uses structured light illumination to generate a dense and accurate depth map and 3D point cloud. Because of its precision, we have been developing FPP as a machine vision system for robotic surgery.<a href="#r1" class="usa-link" aria-describedby="r1"><sup>1</sup></a><em></em><em><sup>–</sup></em><a href="#r4" class="usa-link" aria-describedby="r4"><sup>4</sup></a> In this context, the surgical robot utilizes point cloud data to plan, control, and adjust its task trajectory, enabling autonomous surgery.<a href="#r1" class="usa-link" aria-describedby="r1"><sup>1</sup></a><sup>,</sup><a href="#r2" class="usa-link" aria-describedby="r2"><sup>2</sup></a> When combined as a laparoscopic imaging system, FPP can be used to guide minimally invasive surgery, which is increasingly preferred in modern clinical practice for their ability to minimize surgical trauma and expedite recovery.<a href="#r3" class="usa-link" aria-describedby="r3"><sup>3</sup></a><sup>,</sup><a href="#r4" class="usa-link" aria-describedby="r4"><sup>4</sup></a> Conventional FPP techniques use a projector to project a set of sinusoidal fringe patterns with multiple frequencies and phase shifts on the target, where the surface depth information is naturally encoded into the images captured by a camera at a different view from the projector. After retrieving the phase of the captured images using a phase unwrapping algorithm, a depth map can be determined, and the corresponding point cloud can be reconstructed.<a href="#r5" class="usa-link" aria-describedby="r5"><sup>5</sup></a> However, the need to capture multiple images in FPP results in slow measurement speeds, at around 7 frames per second (FPS),<a href="#r3" class="usa-link" aria-describedby="r3"><sup>3</sup></a> and is prone to motion distortion in living tissue.<a href="#r6" class="usa-link" aria-describedby="r6"><sup>6</sup></a> Moreover, the required synchronization of the camera and projector adds to the system’s complexity.</p>
<p>To accelerate the speed and therefore enable dynamic measurements based on FPP, integrating a single-shot endoscopic fringe image and a deep learning scheme for accurate depth reconstruction is proposed and demonstrated in this work. In prior work, U-Net<a href="#r7" class="usa-link" aria-describedby="r7"><sup>7</sup></a> has been demonstrated as an end-to-end network to obtain a depth map utilizing a single-shot fringe-pattern grayscale image<a href="#r8" class="usa-link" aria-describedby="r8"><sup>8</sup></a> or a red-green-blue (RGB)<a href="#r9" class="usa-link" aria-describedby="r9"><sup>9</sup></a> image as input. Relatedly, Wang et al.<a href="#r10" class="usa-link" aria-describedby="r10"><sup>10</sup></a> have used a generative adversarial network (GAN) architecture, i.e., pix2pix, as this can also be considered to be an image translation problem. A transformer-based model has also been reported to be an end-to-end depth prediction method.<a href="#r11" class="usa-link" aria-describedby="r11"><sup>11</sup></a> Conversely, another approach is to combine deep learning with the conventional FPP algorithm. Yang et al.<a href="#r12" class="usa-link" aria-describedby="r12"><sup>12</sup></a> and Yu et al.<a href="#r13" class="usa-link" aria-describedby="r13"><sup>13</sup></a> have used deep learning to extract the phase information from an input fringe pattern image. A constraint-based phase unwrapping network has also been proposed for FPP,<a href="#r14" class="usa-link" aria-describedby="r14"><sup>14</sup></a> from which the depth is then calculated. Nguyen and Wang<a href="#r9" class="usa-link" aria-describedby="r9"><sup>9</sup></a> have developed networks using single-shot images to generate multiple images with different frequencies and phases and then reconstructed the depth map with a conventional workflow. However, though most of these methods have been evaluated on synthetic data<a href="#r15" class="usa-link" aria-describedby="r15"><sup>15</sup></a> to showcase the concept, the real clinical data are more challenging because the image backgrounds are noisier and more intricate. Furthermore, these approaches have mainly concentrated on the depth reconstruction algorithm, with a limited focus on hardware considerations. Optical designs, such as those employing separate endoscopes for projection and imaging,<a href="#r16" class="usa-link" aria-describedby="r16"><sup>16</sup></a> are complex and heavy, which reduce the system’s usability in clinical settings. In addition, most fringe-based techniques use sinusoidal pattern projections. The sinusoidal pattern provides finer phase information than the binary patterns,<a href="#r17" class="usa-link" aria-describedby="r17"><sup>17</sup></a><em></em><em><sup>–</sup></em><a href="#r19" class="usa-link" aria-describedby="r19"><sup>19</sup></a> thus a more accurate depth reconstruction. However, a well-designed sinusoidal pattern requires a complex optical setup, such as fiber-optic interference<a href="#r20" class="usa-link" aria-describedby="r20"><sup>20</sup></a><sup>,</sup><a href="#r21" class="usa-link" aria-describedby="r21"><sup>21</sup></a> or a single, expensive mask.<a href="#r22" class="usa-link" aria-describedby="r22"><sup>22</sup></a> In addition, the precise detection of the phase information of the pattern depends heavily on the dynamic range of the camera and the associated optical system.</p>
<p>In this work, an endoscopic single-shot FPP system with a modified two-path neural network depth reconstruction algorithm was developed and demonstrated. First, we designed a dual-channel endoscope optical setup to image the intestinal phantom samples. The system’s compact design improves its deployment efficiency and integrability with a robotics surgical system. Second, we developed a depth reconstruction neural network having two paths: one for segmenting the sample from the background (MaskNet) and the other for predicting the depth map (DepthNet). The results from both paths were combined to produce the final depth reconstruction result. The algorithm was evaluated on both the synthetic dataset and intestinal phantom samples. Third, the method was tested using both sinusoidal and binary patterns, and the results indicated that binary patterns yield better reconstruction outputs. This conclusion suggested that a single-shot FPP system can be achieved using binary patterns generated from a low-cost mask with high accuracy.</p></section><section id="sec2"><h2 class="pmc_sec_title">2. Method</h2>
<section id="sec2.1"><h3 class="pmc_sec_title">2.1. Overview</h3>
<p><a href="#f1" class="usa-link">Figure 1</a> illustrates the workflow of the proposed method. First, we developed a single-shot endoscope FPP system to capture pattern-projected images of two cut ends of the intestine during the creation of an intestinal anastomosis. To assess and optimize network performance, we also implemented a data synthesis program to generate additional training datasets. The captured images were fed into two networks: MaskNet segmented the sample from the background, and DepthNet predicted the sample’s depth map. The results from both networks were then combined via pixel-wise multiplication to generate the final depth map. In addition, corresponding point clouds were created for surgical guidance.</p>
<figure class="fig xbox font-sm" id="f1"><h4 class="obj_head">Fig. 1.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12364446_JBO-030-086003-g001.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8e7f/12364446/1f26a5c28ac4/JBO-030-086003-g001.jpg" loading="lazy" height="256" width="735" alt="Fig. 1"></a></p>
<div class="p text-right font-secondary"><a href="figure/f1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Workflow of the deep-learning-based endoscopic FPP system: the pattern-distorted image acquired from the endoscopic FPP system is input into both MaskNet and DepthNet. The segmentation output from MaskNet and the depth prediction from DepthNet are combined via pixel-wise multiplication to produce the final depth map.</p></figcaption></figure></section><section id="sec2.2"><h3 class="pmc_sec_title">2.2. Endoscope FPP System</h3>
<p>The endoscope FPP system is illustrated in <a href="#f2" class="usa-link">Fig. 2(a)</a>. The fringe pattern was generated from a projector (DLP3010EVM-LC, Texas Instruments). The projector has an output resolution of <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math2" display="inline" overflow="linebreak"><mrow><mn>1280</mn><mo>×</mo><mn>720</mn><mrow><mtext>  </mtext></mrow><mrow><mtext>pixels</mtext></mrow></mrow></math></span>, which enables a clear phase gradient in the projected patterns. We selected the green channel with high intensity to enhance contrast in surgical scenarios, where the scene is often dominated by red tones. The light from the projector was collimated by two lenses (L1: AC254-030-A-ML <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math3" display="inline" overflow="linebreak"><mrow><mi>f</mi><mo>=</mo><mn>30</mn><mtext>  </mtext><mi>mm</mi></mrow></math></span>, L2: AC254-075-A-ML <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math4" display="inline" overflow="linebreak"><mrow><mi>f</mi><mo>=</mo><mn>75</mn><mtext>  </mtext><mi>mm</mi></mrow></math></span>, Thorlabs) and was guided by the illumination channel of the dual-channel endoscope (311464-05, Intuitive). The distorted patterns on sample surfaces were imaged through the imaging channel of the dual-channel endoscope and focused onto a camera (GS3-U3-51S5M-C FLIR) by an imaging lens (L3: LA1608, <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math5" display="inline" overflow="linebreak"><mrow><mi>f</mi><mo>=</mo><mn>75</mn><mtext>  </mtext><mi>mm</mi></mrow></math></span>, Thorlabs) as shown in <a href="#f2" class="usa-link">Fig. 2(b)</a>. The camera and projector were synchronized using the programmable interface and a custom-designed circuit to ensure that image acquisitions are accurately aligned with the projected patterns. We chose an intestinal phantom tissue as a sample. The sample was pulled into a diamond shape using strings, with the four corners selected as landmarks to guide the surgical robotic arm during intestine anastomosis procedures.<a href="#r16" class="usa-link" aria-describedby="r16"><sup>16</sup></a>
<a href="#f2" class="usa-link">Figure 2(c)</a> shows a photograph of the optical setup.</p>
<figure class="fig xbox font-sm" id="f2"><h4 class="obj_head">Fig. 2.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12364446_JBO-030-086003-g002.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8e7f/12364446/c6d5cce23253/JBO-030-086003-g002.jpg" loading="lazy" height="328" width="735" alt="Fig. 2"></a></p>
<div class="p text-right font-secondary"><a href="figure/f2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>(a) Schematic representation of the endoscope FPP system optical setup. L1 to L3, lenses. (b) Grayscale image acquired from the camera. (c) Photograph of the optical system setup.</p></figcaption></figure></section><section id="sec2.3"><h3 class="pmc_sec_title">2.3. Data Synthesis Program</h3>
<p>In the single-shot setup, several parameters need to be optimized. The most important parameter is the frequency of the fringe pattern. Lower frequencies provide more accurate phase measurements but are less sensitive to sample details, whereas higher frequencies are more sensitive to sample details but less accurate for phase measurement in the sample. Thus, finding an optimal frequency for the single-shot FPP system is essential. In addition, the difference in reconstruction accuracy between sinusoidal and binary patterns is also investigated. Due to the long acquisition time of the FPP system and the limited surgical data set, we had a limited amount of training data. To increase the training data size and diversity, we developed a data synthesis program based on Blender, an open-source 3D creation software, to efficiently generate the training data with different projection parameters for the model.</p>
<p><a href="#f3" class="usa-link">Figure 3(a)</a> shows the simulation setup we built in Blender. We created a diamond-shaped sample object to simulate intestinal samples as observed in <a href="#f2" class="usa-link">Fig. 2(b)</a>. The projector was positioned in front of the sample to project the different sinusoidal or binary patterns with various frequencies. The distances between the projector, camera, and sample tissue were configured to replicate the real setup. The camera was used to capture the image of the sample with random positions, orientations, and distortions. Because Blender did not provide ray-tracing-based optical modeling or a dedicated lens module, the camera lens was manually set to be 30 mm in Blender to ensure that the magnification closely matches that of the physical system. The output image resolution was also configured to match that of the actual endoscopic system. However, as a simulation environment, Blender did not account for physical optical aberrations or sensor noise. To better mimic real-world imaging conditions, Poisson noise was added to the generated images during post-processing. The sample, with an original side length of 4 cm, underwent random translations (<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math6" display="inline" overflow="linebreak"><mrow><mo form="prefix">−</mo><mn>1</mn></mrow></math></span> to 1 cm), rotations (<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math7" display="inline" overflow="linebreak"><mrow><mo form="prefix">−</mo><mn>15</mn><mtext>  </mtext><mi>deg</mi></mrow></math></span> to <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math8" display="inline" overflow="linebreak"><mrow><mo form="prefix">+</mo><mn>15</mn><mtext>  </mtext><mi>deg</mi></mrow></math></span>), and scaling factors (0.85 to 1.15) along all three axes. A large rectangular cuboid was placed behind the sample to avoid the background being infinite. The software had built-in functionality to generate the depth map for every image.</p>
<figure class="fig xbox font-sm" id="f3"><h4 class="obj_head">Fig. 3.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12364446_JBO-030-086003-g003.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8e7f/12364446/1a18c1208924/JBO-030-086003-g003.jpg" loading="lazy" height="345" width="735" alt="Fig. 3"></a></p>
<div class="p text-right font-secondary"><a href="figure/f3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>(a) Schematic of the data synthesis program. The projector and camera are placed in front of the diamond-shaped sample. The sample has a random position and rotation during data acquisition. A rectangular cuboid is placed behind the sample to avoid the background being infinite. We show some examples generated from the synthesis program with binary pattern frequencies of (b) 4 Hz and (c) 24 Hz, and with sinusoidal pattern frequencies of rows (d) 4 Hz and (e) 24 Hz.</p></figcaption></figure><p>For each sample at a certain fixed translation, rotation, and scaling, we collected 22 grayscale images as a group, with frequencies ranging from 4 to 24 Hz with a 2-Hz increment, for both binary and sinusoidal patterns. To model the noise during image acquisition, we added noise based on the photon shot noise characteristics inherent to optical imaging systems. Specifically, we used the Poisson distribution to simulate the shot noise stochastic nature of photon arrival at the sensor. The noise for each pixel was not assigned a fixed value; instead, it is calculated individually based on the pixel intensity, ensuring that regions with lower intensity are affected by higher noise levels. This approach allowed us to realistically replicate the spatially varying noise observed in practice, thereby validating the feasibility and robustness of our method under representative imaging conditions. The mean peak signal-to-noise (PSNR) between the noisy images and the original images was 27.56. <a href="#f3" class="usa-link">Figure 3</a> shows sample image data for binary patterns of the frequency of (b) 4 Hz and (c) 24 Hz and for sinusoidal patterns of (d) 4 Hz and (e) 24 Hz.</p></section><section id="sec2.4"><h3 class="pmc_sec_title">2.4. Data Preparation</h3>
<p>The network was first trained on the synthetic dataset using both sinusoidal and binary patterns at different frequencies to obtain the optimized pattern parameters. For each pattern, we generated 1200 pairs of pattern-projected images and corresponding depth maps with a size of <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math9" display="inline" overflow="linebreak"><mrow><mn>256</mn><mo>×</mo><mn>256</mn></mrow></math></span>. We split the data into a training set of 800, a validation set of 200, and a testing set of 200. The ground truth for MaskNet is easily generated because the background is located much deeper than the sample.</p>
<p>After determining the optimal pattern, we used it for collecting the real dataset and trained the network. We collected 307 groups of images by manually adjusting the sample’s position and orientation. We used 250 for training, 27 for validation, and 30 for testing. The original size of the image was <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math10" display="inline" overflow="linebreak"><mrow><mn>1024</mn><mo>×</mo><mn>1024</mn></mrow></math></span>. Initially, we employed a Gaussian filter with a window size <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math11" display="inline" overflow="linebreak"><mrow><mn>11</mn><mo>×</mo><mn>11</mn></mrow></math></span> and a standard deviation of 2 to denoise the image.</p>
<p>Each group included 18 images: 16 images (<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math12" display="inline" overflow="linebreak"><mrow><msub><mrow><mi>I</mi></mrow><mrow><mn>1</mn></mrow></msub><mo>∼</mo><msub><mrow><mi>I</mi></mrow><mrow><mn>16</mn></mrow></msub></mrow></math></span>) with 4 frequencies (1, 4, 16, 64 Hz) and 4 phase shifts (<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math13" display="inline" overflow="linebreak"><mrow><mn>0</mn><mo>,</mo><mfrac><mi>π</mi><mn>2</mn></mfrac><mo>,</mo><mtext>  </mtext><mi>π</mi><mo>,</mo><mfrac><mrow><mn>3</mn><mi>π</mi></mrow><mn>2</mn></mfrac></mrow></math></span>) that were used to generate the depth map (<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math14" display="inline" overflow="linebreak"><mrow><mi>D</mi></mrow></math></span>) from the conventional FPP algorithm. In addition, the remaining two images in sinusoidal (<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math15" display="inline" overflow="linebreak"><mrow><msub><mrow><mi>I</mi></mrow><mrow><mi>S</mi></mrow></msub></mrow></math></span>) and binary (<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math16" display="inline" overflow="linebreak"><mrow><msub><mrow><mi>I</mi></mrow><mrow><mi>B</mi></mrow></msub></mrow></math></span>) were utilized for training. The depth map (<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math17" display="inline" overflow="linebreak"><mrow><mi>D</mi></mrow></math></span>) was computed by </p>
<table class="disp-formula p" id="e001"><tr>
<td class="formula"><math id="math18" display="block" overflow="linebreak"><mrow><mi>z</mi><mo>=</mo><mfrac><mrow><msub><mrow><mi>c</mi></mrow><mrow><mn>0</mn></mrow></msub><mo>+</mo><msub><mrow><mi>c</mi></mrow><mrow><mn>1</mn></mrow></msub><mi>ϕ</mi><mo>+</mo><mo stretchy="false">(</mo><msub><mrow><mi>c</mi></mrow><mrow><mn>2</mn></mrow></msub><mo>+</mo><msub><mrow><mi>c</mi></mrow><mrow><mn>3</mn></mrow></msub><mi>ϕ</mi><mo stretchy="false">)</mo><mi>u</mi><mo>+</mo><mo stretchy="false">(</mo><msub><mrow><mi>c</mi></mrow><mrow><mn>4</mn></mrow></msub><mo>+</mo><msub><mrow><mi>c</mi></mrow><mrow><mn>5</mn></mrow></msub><mi>ϕ</mi><mo stretchy="false">)</mo><mi>v</mi></mrow><mrow><msub><mrow><mi>d</mi></mrow><mrow><mn>0</mn></mrow></msub><mo>+</mo><msub><mrow><mi>d</mi></mrow><mrow><mn>1</mn></mrow></msub><mi>ϕ</mi><mo>+</mo><mo stretchy="false">(</mo><msub><mrow><mi>d</mi></mrow><mrow><mn>2</mn></mrow></msub><mo>+</mo><msub><mrow><mi>d</mi></mrow><mrow><mn>3</mn></mrow></msub><mi>ϕ</mi><mo stretchy="false">)</mo><mi>u</mi><mo>+</mo><mo stretchy="false">(</mo><msub><mrow><mi>d</mi></mrow><mrow><mn>4</mn></mrow></msub><mo>+</mo><msub><mrow><mi>d</mi></mrow><mrow><mn>5</mn></mrow></msub><mi>ϕ</mi><mo stretchy="false">)</mo><mi>v</mi></mrow></mfrac><mo>,</mo></mrow></math></td>
<td class="label">(1)</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math19" display="inline" overflow="linebreak"><mrow><mi>z</mi></mrow></math></span> is the depth of the sample, <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math20" display="inline" overflow="linebreak"><mrow><msub><mrow><mi>c</mi></mrow><mrow><mn>0</mn><mo>∼</mo><mn>5</mn></mrow></msub></mrow></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math21" display="inline" overflow="linebreak"><mrow><msub><mrow><mi>d</mi></mrow><mrow><mn>0</mn><mo>∼</mo><mn>5</mn></mrow></msub></mrow></math></span> are the system calibration parameters,<a href="#r23" class="usa-link" aria-describedby="r23"><sup>23</sup></a>
<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math22" display="inline" overflow="linebreak"><mrow><mo stretchy="false">(</mo><mi>u</mi><mo>,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></math></span> are pixel index, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math23" display="inline" overflow="linebreak"><mrow><mi>ϕ</mi></mrow></math></span> is unwrapped phase calculated from the image set (<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math24" display="inline" overflow="linebreak"><mrow><msub><mrow><mi>I</mi></mrow><mrow><mn>1</mn></mrow></msub><mo>∼</mo><msub><mrow><mi>I</mi></mrow><mrow><mn>16</mn></mrow></msub></mrow></math></span>).<a href="#r16" class="usa-link" aria-describedby="r16"><sup>16</sup></a> For MaskNet, the binary ground truth (<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math25" display="inline" overflow="linebreak"><mrow><mi>M</mi></mrow></math></span>) was generated by calculating the pixel variance of the images <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math26" display="inline" overflow="linebreak"><mrow><msub><mrow><mi>I</mi></mrow><mrow><mn>1</mn></mrow></msub><mo>∼</mo><msub><mrow><mi>I</mi></mrow><mrow><mn>16</mn></mrow></msub></mrow></math></span> using the formula below, </p>
<table class="disp-formula p" id="e002"><tr>
<td class="formula"><math id="math27" display="block" overflow="linebreak"><mrow><msub><mrow><mi>M</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>=</mo><mo>{</mo><mtable><mtr><mtd><mn>0</mn><mo>,</mo></mtd><mtd><mi>Var</mi><mo stretchy="false">(</mo><msub><mrow><mi>I</mi></mrow><mrow><mn>1</mn><mi>i</mi></mrow></msub><mo>,</mo><msub><mrow><mi>I</mi></mrow><mrow><mn>2</mn><mi>i</mi></mrow></msub><mo>,</mo><mo>…</mo><msub><mrow><mi>I</mi></mrow><mrow><mn>16</mn><mi>i</mi></mrow></msub><mo stretchy="false">)</mo><mo>&lt;</mo><mi>γ</mi><mo>,</mo></mtd></mtr><mtr><mtd><mn>1</mn><mo>,</mo></mtd><mtd><mi>Var</mi><mo stretchy="false">(</mo><msub><mrow><mi>I</mi></mrow><mrow><mn>1</mn><mi>i</mi></mrow></msub><mo>,</mo><msub><mrow><mi>I</mi></mrow><mrow><mn>2</mn><mi>i</mi></mrow></msub><mo>,</mo><mo>…</mo><msub><mrow><mi>I</mi></mrow><mrow><mn>16</mn><mi>i</mi></mrow></msub><mo stretchy="false">)</mo><mo>≥</mo><mi>γ</mi><mo>,</mo></mtd></mtr></mtable></mrow></math></td>
<td class="label">(2)</td>
</tr></table>
<p>in which <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math28" display="inline" overflow="linebreak"><mrow><mi>i</mi></mrow></math></span> represents the pixel index in the image and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math29" display="inline" overflow="linebreak"><mrow><mi>γ</mi></mrow></math></span> denotes the variance threshold value. The background is typically located farther from the sample, resulting in lower reflectivity compared to the biological tissue sample. This makes pixel intensity in the background less sensitive to the projection pattern phase, leading to lower intensity variance. <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math30" display="inline" overflow="linebreak"><mrow><mi>γ</mi></mrow></math></span> is set to 30 in our case, but it can vary depending on the optical setup. Next, morphological opening and closing operations were applied to remove small noise and fill small holes in the mask image to generate the final mask. All images used for training <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math31" display="inline" overflow="linebreak"><mrow><mo stretchy="false">(</mo><msub><mrow><mi>I</mi></mrow><mrow><mi>S</mi></mrow></msub><mo>,</mo><msub><mrow><mi>I</mi></mrow><mrow><mi>B</mi></mrow></msub><mo>,</mo><mi>D</mi><mo>,</mo><mi>M</mi><mo stretchy="false">)</mo></mrow></math></span> were downsampled to <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math32" display="inline" overflow="linebreak"><mrow><mn>256</mn><mo>×</mo><mn>256</mn></mrow></math></span> to ensure consistency with the synthetic data and to accelerate training.</p></section><section id="sec2.5"><h3 class="pmc_sec_title">2.5. Network Architecture</h3>
<p>The proposed architecture consisted of two networks: MaskNet and DepthNet. MaskNet segmented the sample from the background, and DepthNet predicted the depth map. The outputs of both networks were multiplied to produce the final depth map of the sample.</p>
<p>Both MaskNet and DepthNet were based on a modified five-level U-Net, as shown in <a href="#f4" class="usa-link">Fig. 4</a>, which leverages the advantage of multiresolution analysis. The blue arrows represent convolutional layers with a <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math33" display="inline" overflow="linebreak"><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow></math></span> window size, followed by a rectified linear unit (ReLU) activation function. The red arrows represent max pooling operations, with a fixed window size. Zero-padding is applied to all convolution layers to prevent image cropping. The green arrows indicate <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math34" display="inline" overflow="linebreak"><mrow><mn>2</mn><mo>×</mo><mn>2</mn></mrow></math></span> bicubic upsampling operations, whereas the black dotted arrows represent skip connections from the encoder to the decoder. Unlike the conventional U-Net architecture, our multilevel network extracts information directly from the different levels of the decoder and sums them to generate the final output. It has been demonstrated that the multilevel information in U-Net can accelerate network convergence and improve output accuracy.<a href="#r24" class="usa-link" aria-describedby="r24"><sup>24</sup></a> The yellow arrows represent convolutions with a <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math35" display="inline" overflow="linebreak"><mrow><mn>1</mn><mo>×</mo><mn>1</mn></mrow></math></span> window size, followed by an activation function with n-channel output. For MaskNet, we applied the softmax function as the activation, with a 2-channel output. For DepthNet, the sigmoid function was used as the activation to limit the output range, with a single output layer as depth prediction.</p>
<figure class="fig xbox font-sm" id="f4"><h4 class="obj_head">Fig. 4.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12364446_JBO-030-086003-g004.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8e7f/12364446/c685a77c615e/JBO-030-086003-g004.jpg" loading="lazy" height="437" width="700" alt="Fig. 4"></a></p>
<div class="p text-right font-secondary"><a href="figure/f4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Network architecture of the MaskNet and DepthNet. The network is a modified U-Net with multilevel information. The MaskNet used softmax as an activation function with <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math36" display="inline" overflow="linebreak"><mrow><mi>n</mi><mo>=</mo><mn>2</mn></mrow></math></span>, and the DepthNet used sigmoid as an activation function with <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math37" display="inline" overflow="linebreak"><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow></math></span>.</p></figcaption></figure></section><section id="sec2.6"><h3 class="pmc_sec_title">2.6. Loss Function</h3>
<p>MaskNet and DepthNet were trained separately with different loss functions. The trainable parameters of the utilized networks were optimized based on our depth reconstruction loss function <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math38" display="inline" overflow="linebreak"><mrow><msub><mi>L</mi><mi>d</mi></msub></mrow></math></span> and mask segmentation loss function <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math39" display="inline" overflow="linebreak"><mrow><msub><mi>L</mi><mi>m</mi></msub></mrow></math></span>.</p>
<section id="sec2.6.1"><h4 class="pmc_sec_title">2.6.1. Depth reconstruction loss</h4>
<p>The output of DepthNet ranges from 0 to 1 due to the sigmoid activation. To align this output with physical distance, we applied a linear function. For instance, in our endoscope setup, the distance between the endoscope and the sample ranges from 70 to 140 mm. If we define the output of DepthNet as <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math40" display="inline" overflow="linebreak"><mrow><mi>d</mi><mo>∈</mo><mo stretchy="false">(</mo><mn>0,1</mn><mo stretchy="false">)</mo></mrow></math></span>, the final depth prediction (<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math41" display="inline" overflow="linebreak"><mrow><mover accent="true"><mi>D</mi><mo stretchy="false">˜</mo></mover></mrow></math></span>) is given by the equation <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math42" display="inline" overflow="linebreak"><mrow><mover accent="true"><mi>D</mi><mo stretchy="false">˜</mo></mover><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>d</mi><mo stretchy="false">)</mo><mo>=</mo><mn>150</mn><mo>×</mo><mi>d</mi><mo>+</mo><mn>30</mn></mrow></math></span> in millimeters ensuring the prediction covers the real-world distance. To ensure the network focuses on sample prediction, we applied a mask to the depth map during loss calculation, preventing background depth predictions from influencing the training process.</p>
<p>We used the depth reconstruction loss to calculate the difference between the predicted depth values (<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math43" display="inline" overflow="linebreak"><mrow><mover accent="true"><mi>D</mi><mo stretchy="false">˜</mo></mover></mrow></math></span>) and the ground truth (<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math44" display="inline" overflow="linebreak"><mrow><mi>D</mi></mrow></math></span>) with the assistance of a mask (<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math45" display="inline" overflow="linebreak"><mrow><mi>M</mi></mrow></math></span>), which included <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math46" display="inline" overflow="linebreak"><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow></math></span> loss and structured similarity index measure (SSIM)<a href="#r25" class="usa-link" aria-describedby="r25"><sup>25</sup></a> loss as follows: </p>
<table class="disp-formula p" id="e003"><tr>
<td class="formula"><math id="math47" display="block" overflow="linebreak"><mrow><msub><mrow><mi>L</mi></mrow><mrow><mi>d</mi></mrow></msub><mo stretchy="false">(</mo><mover accent="true"><mrow><mi>D</mi></mrow><mrow><mo stretchy="false">˜</mo></mrow></mover><mo>,</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mi>α</mi><mo>·</mo><msub><mrow><mo stretchy="false">‖</mo><mover accent="true"><mrow><mi>D</mi></mrow><mrow><mo stretchy="false">˜</mo></mrow></mover><mo>⊗</mo><mi>M</mi><mo>−</mo><mi>D</mi><mo>⊗</mo><mi>M</mi><mo stretchy="false">‖</mo></mrow><mrow><mn>1</mn></mrow></msub><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy="false">)</mo><mo>·</mo><mfrac><mrow><mn>1</mn><mo>−</mo><mi>SSIM</mi><mo stretchy="false">(</mo><mover accent="true"><mrow><mi>D</mi></mrow><mrow><mo stretchy="false">˜</mo></mrow></mover><mo>⊗</mo><mi>M</mi><mo>,</mo><mi>D</mi><mo>⊗</mo><mi>M</mi><mo stretchy="false">)</mo></mrow><mrow><mn>2</mn></mrow></mfrac><mo>,</mo></mrow></math></td>
<td class="label">(3)</td>
</tr></table>
<p>in which <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math48" display="inline" overflow="linebreak"><mrow><mi>α</mi><mo>=</mo><mn>0.85</mn></mrow></math></span> is the weighting parameter and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math49" display="inline" overflow="linebreak"><mrow><mo>⊗</mo></mrow></math></span> denotes the pixel-wise multiplication. The first term in <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math50" display="inline" overflow="linebreak"><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow></math></span> loss was used to minimize the overall error, and the second term was used to calculate the SSIM loss between the prediction and ground truth to optimize the sample structure.</p></section><section id="sec2.6.2"><h4 class="pmc_sec_title">2.6.2. Segmentation loss</h4>
<p>We used Dice loss<a href="#r26" class="usa-link" aria-describedby="r26"><sup>26</sup></a> as the segmentation loss function due to its effectiveness in handling the class imbalance between background and sample regions in the images. We define the prediction result of MaskNet as <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math51" display="inline" overflow="linebreak"><mrow><mover accent="true"><mi>M</mi><mo stretchy="false">˜</mo></mover></mrow></math></span>, and the segmentation loss is noted as follows: </p>
<table class="disp-formula p" id="e004"><tr>
<td class="formula"><math id="math52" display="block" overflow="linebreak"><mrow><msub><mi>L</mi><mi>m</mi></msub><mo stretchy="false">(</mo><mover accent="true"><mi>M</mi><mo stretchy="false">˜</mo></mover><mo>,</mo><mi>M</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>−</mo><mi>DSC</mi><mo stretchy="false">(</mo><mi>M</mi><mo>,</mo><mover accent="true"><mi>M</mi><mo stretchy="false">˜</mo></mover><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>−</mo><mfrac><mn>1</mn><mi>C</mi></mfrac><munderover><mo>∑</mo><mi>j</mi><mi>C</mi></munderover><mfrac><mrow><msubsup><mo>∑</mo><mi>i</mi><mi>N</mi></msubsup><mn>2</mn><msub><mi>M</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msub><mover accent="true"><mi>M</mi><mo stretchy="false">˜</mo></mover><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mi>β</mi></mrow><mrow><msubsup><mo>∑</mo><mi>i</mi><mi>N</mi></msubsup><msub><mi>M</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><msubsup><mo>∑</mo><mi>i</mi><mi>N</mi></msubsup><msub><mover accent="true"><mi>M</mi><mo stretchy="false">˜</mo></mover><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mi>β</mi></mrow></mfrac><mo>,</mo></mrow></math></td>
<td class="label">(4)</td>
</tr></table>
<p>in which DSC denotes the Dice score, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math53" display="inline" overflow="linebreak"><mrow><mi>C</mi></mrow></math></span> is the total number of classes of the image, <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math54" display="inline" overflow="linebreak"><mrow><mi>j</mi></mrow></math></span> is the class category index, <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math55" display="inline" overflow="linebreak"><mrow><mi>i</mi></mrow></math></span> denotes the pixel index, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math56" display="inline" overflow="linebreak"><mrow><mi>N</mi></mrow></math></span> is the total number of pixels. In our case, we had one class of background and one class of sample, and we set <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math57" display="inline" overflow="linebreak"><mrow><mi>C</mi><mo>=</mo><mn>2</mn></mrow></math></span>. It is common to add a <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math58" display="inline" overflow="linebreak"><mrow><mi>β</mi></mrow></math></span> factor to both the numerator and denominator for numerical stability. We set <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math59" display="inline" overflow="linebreak"><mrow><mi>β</mi><mo>=</mo><mn>0.001</mn></mrow></math></span> in the network training.</p></section></section><section id="sec2.7"><h3 class="pmc_sec_title">2.7. Training Details</h3>
<p>The proposed method was implemented using the PyTorch<a href="#r27" class="usa-link" aria-describedby="r27"><sup>27</sup></a> framework. The network was trained for 150 epochs with a multistep decay learning rate schedule. The initial learning rate was set to 0.0001, with decay milestones at epochs 20 and 60, each applying a decay factor of 0.2. Training was conducted using the Adam<a href="#r28" class="usa-link" aria-describedby="r28"><sup>28</sup></a> optimizer on an NVIDIA RTX A2000 GPU with 12 GB VRAM.</p></section></section><section id="sec3"><h2 class="pmc_sec_title">3. Results</h2>
<p>To demonstrate the performance of the proposed method, we evaluated it using both synthetic data and experimental data collected from the endoscope FPP system. For the quantitative analysis, we used three metrics introduced by Eigen et al.,<a href="#r29" class="usa-link" aria-describedby="r29"><sup>29</sup></a> which have been widely employed for the performance evaluation of depth estimation: Mean absolute error (MAE), absolute relative error (Abs Rel), and accuracy. They are defined as follows: </p>
<table class="disp-formula p" id="e005"><tr>
<td class="formula"><math id="math60" display="block" overflow="linebreak"><mrow><mi>MAE</mi><mo>=</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mo stretchy="false">|</mo><mi>V</mi><mo stretchy="false">|</mo></mrow></mfrac><munder><mrow><mo>∑</mo></mrow><mrow><mi>i</mi><mo>∈</mo><mi>V</mi></mrow></munder><mo stretchy="false">|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>−</mo><msub><mrow><mover accent="true"><mrow><mi>Y</mi></mrow><mrow><mo stretchy="false">˜</mo></mrow></mover></mrow><mrow><mi>i</mi></mrow></msub><mo stretchy="false">|</mo><mo>,</mo></mrow></math></td>
<td class="label">(5)</td>
</tr></table>
<table class="disp-formula p" id="e006"><tr>
<td class="formula"><math id="math61" display="block" overflow="linebreak"><mrow><mi>Abs</mi><mtext> </mtext><mi>Rel</mi><mo>=</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mo stretchy="false">|</mo><mi>V</mi><mo stretchy="false">|</mo></mrow></mfrac><munder><mrow><mo>∑</mo></mrow><mrow><mi>i</mi><mo>∈</mo><mi>V</mi></mrow></munder><mfrac><mrow><mo stretchy="false">|</mo><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>−</mo><msub><mrow><mover accent="true"><mrow><mi>Y</mi></mrow><mrow><mo stretchy="false">˜</mo></mrow></mover></mrow><mrow><mi>i</mi></mrow></msub><mo stretchy="false">|</mo></mrow><mrow><mover><mrow><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow><mrow><mo stretchy="false">˜</mo></mrow></mover></mrow></mfrac><mo>,</mo></mrow></math></td>
<td class="label">(6)</td>
</tr></table>
<table class="disp-formula p" id="e007"><tr>
<td class="formula"><math id="math62" display="block" overflow="linebreak"><mrow><mtext>Accurancy</mtext><mo>=</mo><mrow><mtext>percentage of</mtext></mrow><mrow><mtext> </mtext></mrow><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub><mtext>  </mtext><mi mathvariant="normal">s.t.</mi><mtext>  </mtext><mi>max</mi><mo>(</mo><mfrac><mrow><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow><mrow><msub><mrow><mover accent="true"><mrow><mi>Y</mi></mrow><mrow><mo stretchy="false">˜</mo></mrow></mover></mrow><mrow><mi>i</mi></mrow></msub></mrow></mfrac><mo>,</mo><mfrac><mrow><msub><mrow><mover accent="true"><mrow><mi>Y</mi></mrow><mrow><mo stretchy="false">˜</mo></mrow></mover></mrow><mrow><mi>i</mi></mrow></msub></mrow><mrow><msub><mrow><mi>Y</mi></mrow><mrow><mi>i</mi></mrow></msub></mrow></mfrac><mo>)</mo><mo>&lt;</mo><mi>δ</mi><mo>,</mo></mrow></math></td>
<td class="label">(7)</td>
</tr></table>
<p>in which <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math63" display="inline" overflow="linebreak"><mrow><mi>Y</mi><mo>=</mo><mi>D</mi><mo>⊗</mo><mi>M</mi></mrow></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math64" display="inline" overflow="linebreak"><mrow><mover accent="true"><mrow><mi>Y</mi></mrow><mrow><mo stretchy="false">˜</mo></mrow></mover><mo>=</mo><mover accent="true"><mrow><mi>D</mi></mrow><mrow><mo stretchy="false">˜</mo></mrow></mover><mo>⊗</mo><mover accent="true"><mrow><mi>M</mi></mrow><mrow><mo stretchy="false">˜</mo></mrow></mover></mrow></math></span> denote the final depth map from the ground truth and the network prediction, respectively. <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math65" display="inline" overflow="linebreak"><mrow><mi>i</mi></mrow></math></span> is the index of the pixels. <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math66" display="inline" overflow="linebreak"><mrow><mi>V</mi><mo>=</mo><mo stretchy="false">{</mo><mi>i</mi><mo>∈</mo><mo stretchy="false">{</mo><mn>0,1</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo stretchy="false">}</mo><mo stretchy="false">|</mo><msub><mrow><mi>M</mi></mrow><mrow><mi>i</mi></mrow></msub><mo>=</mo><mn>1</mn><mo stretchy="false">}</mo></mrow></math></span> represents the set of valid pixels, defined as the pixels belonging to the sample. <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math67" display="inline" overflow="linebreak"><mrow><mo stretchy="false">|</mo><mi>V</mi><mo stretchy="false">|</mo></mrow></math></span> denotes the number of elements in <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math68" display="inline" overflow="linebreak"><mrow><mi>V</mi></mrow></math></span>. Background pixels are excluded to avoid skewing the model’s assessment, as a high proportion of background pixels could negatively impact the evaluation. <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math69" display="inline" overflow="linebreak"><mrow><mi>δ</mi></mrow></math></span> is the thresholding value set for accuracy.</p>
<p>We evaluated the MaskNet using the Dice score and mean intersection over union (mIoU). The IoU is defined by dividing the number of overlapping pixels (intersection) by the total number of pixels that belong to either the predicted (<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math70" display="inline" overflow="linebreak"><mrow><mover accent="true"><mi>M</mi><mo stretchy="false">˜</mo></mover></mrow></math></span>) or ground truth (<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math71" display="inline" overflow="linebreak"><mrow><mi>M</mi></mrow></math></span>) regions for that class (union). The formula is written as </p>
<table class="disp-formula p" id="e008"><tr>
<td class="formula"><math id="math72" display="block" overflow="linebreak"><mrow><mi>IoU</mi><mo>=</mo><mfrac><mrow><mi>M</mi><mo>∩</mo><mover accent="true"><mrow><mi>M</mi></mrow><mrow><mo stretchy="false">˜</mo></mrow></mover></mrow><mrow><mi>M</mi><mo>∪</mo><mover accent="true"><mrow><mi>M</mi></mrow><mrow><mo stretchy="false">˜</mo></mrow></mover></mrow></mfrac><mo>.</mo></mrow></math></td>
<td class="label">(8)</td>
</tr></table>
<p>The IoUs of all 2 classes (background and tissue in our case) were averaged to compute the mIoU.</p>
<section id="sec3.1"><h3 class="pmc_sec_title">3.1. Validation Using Synthetic Data</h3>
<p>The synthetic dataset with two patterns and multiple frequencies was used for training, and a selection of depth reconstruction results is presented. We chose 8, 12, 16, 20, and 24 Hz as examples, which are shown in <a href="#f5" class="usa-link">Fig. 5</a>. In this figure, the original images with binary patterns, the corresponding depth reconstruction results, and the absolute error maps are shown in rows (a), (b), and (c), respectively. The original images with sinusoidal patterns, the corresponding depth reconstruction results, and the absolute error maps are shown in rows (d), (e), and (f), respectively. The MAE is displayed on each error map to quantitatively indicate the error level. Note that the image with 20 Hz shows the least error and produces better results on smooth surfaces in both patterns. The error primarily occurs at the sharp edges of the sample but does not affect our system’s ability to detect the sample’s corners.</p>
<figure class="fig xbox font-sm" id="f5"><h4 class="obj_head">Fig. 5.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12364446_JBO-030-086003-g005.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8e7f/12364446/8c89273f96ea/JBO-030-086003-g005.jpg" loading="lazy" height="813" width="735" alt="Fig. 5"></a></p>
<div class="p text-right font-secondary"><a href="figure/f5/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Depth reconstruction result and error map of synthetic data with pattern frequencies of 8, 12, 16, 20, and 24 Hz. Rows (a) and (d) are the original images with binary patterns and sinusoidal patterns, respectively. Rows (b) and (e) are the corresponding depth reconstruction results, and rows (c) and (f) are the corresponding absolute error maps, respectively (depth unit: millimeter).</p></figcaption></figure><p>We used MAE as a metric to quantitatively analyze the relationship between depth reconstruction and frequency, as shown in <a href="#f6" class="usa-link">Fig. 6</a>. For both binary and sinusoidal patterns, the best result shows a similar trend, with the optimal result occurring at 20 Hz. This can be explained by the fact that images with lower pattern frequencies cannot accurately detect shape details due to the low phase gradient. Conversely, higher frequencies often result in aliasing problems because of the finite sampling rate of the camera, leading to ambiguities in surface and depth reconstruction. Thus, 20 Hz appears to be a compromise between low and high frequency quantification effects.</p>
<figure class="fig xbox font-sm" id="f6"><h4 class="obj_head">Fig. 6.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12364446_JBO-030-086003-g006.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8e7f/12364446/ef0e55042738/JBO-030-086003-g006.jpg" loading="lazy" height="350" width="735" alt="Fig. 6"></a></p>
<div class="p text-right font-secondary"><a href="figure/f6/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>MAE of depth reconstruction from the synthetic dataset with (blue) binary pattern and (yellow) sinusoidal patterns.</p></figcaption></figure><p>A detailed quantitative evaluation of the synthetic dataset, using both depth prediction and segmentation metrics, is presented in <a href="#t001" class="usa-link">Table 1</a>. For images with binary patterns, the optimal values for each metric range from 16 to 24 Hz, but the differences are minimal. Moreover, the best results for sinusoidal patterns consistently occur at 20 Hz. Therefore, we conclude that for our setup, 20 Hz should be considered the optimal frequency for single fringe patterns to generate the depth map.</p>
<section class="tw xbox font-sm" id="t001"><h4 class="obj_head">Table 1.</h4>
<div class="caption p"><p>Quantitative evaluations on the synthetic dataset with different patterns and frequencies. Bold values represent the best performance in each metric.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" span="1">
<col align="center" span="1">
<col align="center" span="1">
<col align="center" span="1">
<col align="center" span="1">
<col align="center" span="1">
<col align="center" span="1">
<col align="center" span="1">
</colgroup>
<thead>
<tr>
<th colspan="2" align="center" valign="top" rowspan="1">Patterns</th>
<th colspan="4" align="center" valign="top" rowspan="1">Depth metrics</th>
<th colspan="2" align="center" valign="top" rowspan="1">Segmentation metrics</th>
</tr>
<tr>
<th align="left" valign="top" colspan="1" rowspan="1">Type</th>
<th align="center" valign="top" colspan="1" rowspan="1">Freq (Hz)</th>
<th align="center" valign="top" colspan="1" rowspan="1">MAE ↓</th>
<th align="center" valign="top" colspan="1" rowspan="1">Abs Rel ↓</th>
<th align="center" valign="top" colspan="1" rowspan="1">
<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math73" display="inline" overflow="linebreak"><mrow><mi>δ</mi><mo>=</mo><mn>1.1</mn></mrow></math></span> ↑</th>
<th align="center" valign="top" colspan="1" rowspan="1">
<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math74" display="inline" overflow="linebreak"><mrow><mi>δ</mi><mo>=</mo><msup><mrow><mn>1.1</mn></mrow><mrow><mn>2</mn></mrow></msup></mrow></math></span> ↑</th>
<th align="center" valign="top" colspan="1" rowspan="1">DSC ↑</th>
<th align="center" valign="top" colspan="1" rowspan="1">mIoU ↑</th>
</tr>
</thead>
<tbody>
<tr>
<td rowspan="11" align="left" valign="middle" colspan="1">Binary pattern<hr>
</td>
<td align="center" colspan="1" rowspan="1">4</td>
<td align="center" colspan="1" rowspan="1">1.35</td>
<td align="center" colspan="1" rowspan="1">0.0227</td>
<td align="center" colspan="1" rowspan="1">0.9677</td>
<td align="center" colspan="1" rowspan="1">0.9922</td>
<td align="center" colspan="1" rowspan="1">0.9944</td>
<td align="center" colspan="1" rowspan="1">0.9740</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">6</td>
<td align="center" colspan="1" rowspan="1">1.39</td>
<td align="center" colspan="1" rowspan="1">0.0231</td>
<td align="center" colspan="1" rowspan="1">0.9636</td>
<td align="center" colspan="1" rowspan="1">0.9907</td>
<td align="center" colspan="1" rowspan="1">0.9954</td>
<td align="center" colspan="1" rowspan="1">0.9781</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">8</td>
<td align="center" colspan="1" rowspan="1">1.37</td>
<td align="center" colspan="1" rowspan="1">0.0231</td>
<td align="center" colspan="1" rowspan="1">0.9687</td>
<td align="center" colspan="1" rowspan="1">0.9922</td>
<td align="center" colspan="1" rowspan="1">0.9976</td>
<td align="center" colspan="1" rowspan="1">0.9885</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">10</td>
<td align="center" colspan="1" rowspan="1">1.27</td>
<td align="center" colspan="1" rowspan="1">0.0214</td>
<td align="center" colspan="1" rowspan="1">0.9703</td>
<td align="center" colspan="1" rowspan="1">0.9925</td>
<td align="center" colspan="1" rowspan="1">0.9973</td>
<td align="center" colspan="1" rowspan="1">0.9872</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">12</td>
<td align="center" colspan="1" rowspan="1">1.15</td>
<td align="center" colspan="1" rowspan="1">0.0193</td>
<td align="center" colspan="1" rowspan="1">0.9732</td>
<td align="center" colspan="1" rowspan="1">0.9929</td>
<td align="center" colspan="1" rowspan="1">0.9973</td>
<td align="center" colspan="1" rowspan="1">0.9872</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">14</td>
<td align="center" colspan="1" rowspan="1">1.24</td>
<td align="center" colspan="1" rowspan="1">0.0206</td>
<td align="center" colspan="1" rowspan="1">0.9720</td>
<td align="center" colspan="1" rowspan="1">0.9924</td>
<td align="center" colspan="1" rowspan="1">0.9975</td>
<td align="center" colspan="1" rowspan="1">0.9881</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">16</td>
<td align="center" colspan="1" rowspan="1">1.10</td>
<td align="center" colspan="1" rowspan="1">0.0184</td>
<td align="center" colspan="1" rowspan="1">
<strong>0.9774</strong>
</td>
<td align="center" colspan="1" rowspan="1">0.9940</td>
<td align="center" colspan="1" rowspan="1">0.9975</td>
<td align="center" colspan="1" rowspan="1">0.9879</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">18</td>
<td align="center" colspan="1" rowspan="1">1.12</td>
<td align="center" colspan="1" rowspan="1">0.0188</td>
<td align="center" colspan="1" rowspan="1">0.9755</td>
<td align="center" colspan="1" rowspan="1">0.9938</td>
<td align="center" colspan="1" rowspan="1">0.9975</td>
<td align="center" colspan="1" rowspan="1">0.9881</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">20</td>
<td align="center" colspan="1" rowspan="1">
<strong>1.09</strong>
</td>
<td align="center" colspan="1" rowspan="1">
<strong>0.0183</strong>
</td>
<td align="center" colspan="1" rowspan="1">0.9760</td>
<td align="center" colspan="1" rowspan="1">0.9938</td>
<td align="center" colspan="1" rowspan="1">
<strong>0.9977</strong>
</td>
<td align="center" colspan="1" rowspan="1">
<strong>0.9888</strong>
</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">22</td>
<td align="center" colspan="1" rowspan="1">1.16</td>
<td align="center" colspan="1" rowspan="1">0.0192</td>
<td align="center" colspan="1" rowspan="1">0.9752</td>
<td align="center" colspan="1" rowspan="1">0.9937</td>
<td align="center" colspan="1" rowspan="1">0.9974</td>
<td align="center" colspan="1" rowspan="1">0.9875</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">24<hr>
</td>
<td align="center" colspan="1" rowspan="1">1.13<hr>
</td>
<td align="center" colspan="1" rowspan="1">0.0190<hr>
</td>
<td align="center" colspan="1" rowspan="1">0.9763<hr>
</td>
<td align="center" colspan="1" rowspan="1">
<strong>0.9941</strong>
<hr>
</td>
<td align="center" colspan="1" rowspan="1">0.9970<hr>
</td>
<td align="center" colspan="1" rowspan="1">0.9864<hr>
</td>
</tr>
<tr>
<td rowspan="11" align="left" valign="middle" colspan="1">Sinusoidal pattern</td>
<td align="center" colspan="1" rowspan="1">4</td>
<td align="center" colspan="1" rowspan="1">1.55</td>
<td align="center" colspan="1" rowspan="1">0.0259</td>
<td align="center" colspan="1" rowspan="1">0.9592</td>
<td align="center" colspan="1" rowspan="1">0.9907</td>
<td align="center" colspan="1" rowspan="1">0.9960</td>
<td align="center" colspan="1" rowspan="1">0.9808</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">6</td>
<td align="center" colspan="1" rowspan="1">1.34</td>
<td align="center" colspan="1" rowspan="1">0.0223</td>
<td align="center" colspan="1" rowspan="1">0.9678</td>
<td align="center" colspan="1" rowspan="1">0.9927</td>
<td align="center" colspan="1" rowspan="1">0.9964</td>
<td align="center" colspan="1" rowspan="1">0.9826</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">8</td>
<td align="center" colspan="1" rowspan="1">1.39</td>
<td align="center" colspan="1" rowspan="1">0.0235</td>
<td align="center" colspan="1" rowspan="1">0.9662</td>
<td align="center" colspan="1" rowspan="1">0.9923</td>
<td align="center" colspan="1" rowspan="1">0.9966</td>
<td align="center" colspan="1" rowspan="1">0.9837</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">10</td>
<td align="center" colspan="1" rowspan="1">1.31</td>
<td align="center" colspan="1" rowspan="1">0.0219</td>
<td align="center" colspan="1" rowspan="1">0.9684</td>
<td align="center" colspan="1" rowspan="1">0.9924</td>
<td align="center" colspan="1" rowspan="1">0.9970</td>
<td align="center" colspan="1" rowspan="1">0.9855</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">12</td>
<td align="center" colspan="1" rowspan="1">1.29</td>
<td align="center" colspan="1" rowspan="1">0.0217</td>
<td align="center" colspan="1" rowspan="1">0.9688</td>
<td align="center" colspan="1" rowspan="1">0.9926</td>
<td align="center" colspan="1" rowspan="1">0.9974</td>
<td align="center" colspan="1" rowspan="1">0.9873</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">14</td>
<td align="center" colspan="1" rowspan="1">1.15</td>
<td align="center" colspan="1" rowspan="1">0.0192</td>
<td align="center" colspan="1" rowspan="1">0.9759</td>
<td align="center" colspan="1" rowspan="1">0.9943</td>
<td align="center" colspan="1" rowspan="1">0.9971</td>
<td align="center" colspan="1" rowspan="1">0.9861</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">16</td>
<td align="center" colspan="1" rowspan="1">1.17</td>
<td align="center" colspan="1" rowspan="1">0.0196</td>
<td align="center" colspan="1" rowspan="1">0.9723</td>
<td align="center" colspan="1" rowspan="1">0.9937</td>
<td align="center" colspan="1" rowspan="1">
<strong>0.9975</strong>
</td>
<td align="center" colspan="1" rowspan="1">
<strong>0.9880</strong>
</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">18</td>
<td align="center" colspan="1" rowspan="1">1.17</td>
<td align="center" colspan="1" rowspan="1">0.0198</td>
<td align="center" colspan="1" rowspan="1">0.9736</td>
<td align="center" colspan="1" rowspan="1">0.9933</td>
<td align="center" colspan="1" rowspan="1">0.9973</td>
<td align="center" colspan="1" rowspan="1">0.9867</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">20</td>
<td align="center" colspan="1" rowspan="1">
<strong>0.97</strong>
</td>
<td align="center" colspan="1" rowspan="1">
<strong>0.0163</strong>
</td>
<td align="center" colspan="1" rowspan="1">
<strong>0.9793</strong>
</td>
<td align="center" colspan="1" rowspan="1">
<strong>0.9951</strong>
</td>
<td align="center" colspan="1" rowspan="1">0.9970</td>
<td align="center" colspan="1" rowspan="1">0.9852</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">22</td>
<td align="center" colspan="1" rowspan="1">1.18</td>
<td align="center" colspan="1" rowspan="1">0.0198</td>
<td align="center" colspan="1" rowspan="1">0.9762</td>
<td align="center" colspan="1" rowspan="1">0.9943</td>
<td align="center" colspan="1" rowspan="1">0.9973</td>
<td align="center" colspan="1" rowspan="1">0.9868</td>
</tr>
<tr>
<td align="center" colspan="1" rowspan="1">24</td>
<td align="center" colspan="1" rowspan="1">1.19</td>
<td align="center" colspan="1" rowspan="1">0.0200</td>
<td align="center" colspan="1" rowspan="1">0.9789</td>
<td align="center" colspan="1" rowspan="1">0.9948</td>
<td align="center" colspan="1" rowspan="1">0.9974</td>
<td align="center" colspan="1" rowspan="1">0.9875</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/t001/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="sec3.2"><h3 class="pmc_sec_title">3.2. Validation Using Endoscope FPP System Data</h3>
<p>Based on the conclusions from the synthetic data, we conducted our endoscope FPP experiments using both sinusoidal and binary fringe patterns at 20 Hz. <a href="#f7" class="usa-link">Figure 7</a> presents and compares the depth reconstruction results from both patterns across five example cases. <a href="#f7" class="usa-link">Figure 7</a> rows (a) and (d) show the original images with binary and sinusoidal patterns, respectively. Rows (b) and (e) display the corresponding depth reconstruction results, whereas rows (c) and (f) present the error map and MAE for comparison.</p>
<figure class="fig xbox font-sm" id="f7"><h4 class="obj_head">Fig. 7.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12364446_JBO-030-086003-g007.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8e7f/12364446/756b13abe865/JBO-030-086003-g007.jpg" loading="lazy" height="805" width="735" alt="Fig. 7"></a></p>
<div class="p text-right font-secondary"><a href="figure/f7/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Depth reconstruction results and error maps across five example cases collected from the endoscope system. Rows (a) and (d) are original images with binary and sinusoidal patterns, respectively. Rows (b) and (e) are the corresponding depth reconstruction results. Rows (c) and (f) are error maps for comparison (depth unit: millimeter).</p></figcaption></figure><p>We observed that the algorithm produces similar results for both types of fringe patterns. The ground truth, calculated using the conventional method, is highly sensitive to image intensity, leading to a noisy depth map. By contrast, the proposed method not only predicts the depth accurately but also generates a smoother image, demonstrating its robustness to low SNR images.</p>
<p>The detailed quantitative results are listed in <a href="#t002" class="usa-link">Table 2</a>. We observed that fringe images with both patterns produced similar results, with the binary pattern performing slightly better. To evaluate the performance differences between the two types of patterns, we conducted two-tailed paired <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math75" display="inline" overflow="linebreak"><mrow><mi>t</mi></mrow></math></span>-tests on their respective metrics. All <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math76" display="inline" overflow="linebreak"><mrow><mi>p</mi></mrow></math></span> values calculated were below 0.05, indicating that the depth reconstruction results of the binary pattern are statistically better. The images collected from the experimental setup often suffer from motion blur and low signal-to-noise ratio during real-time measurements. Consequently, the intensity of sinusoidal patterns is less accurate compared to synthetic data, resulting in higher depth prediction errors. By contrast, binary patterns are more effective in resolving phase ambiguities over larger depth ranges,<a href="#r30" class="usa-link" aria-describedby="r30"><sup>30</sup></a> leading to improved depth prediction accuracy.</p>
<section class="tw xbox font-sm" id="t002"><h4 class="obj_head">Table 2.</h4>
<div class="caption p"><p>Quantitative evaluations on the experimental dataset with two patterns.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" span="1">
<col align="center" span="1">
<col align="center" span="1">
<col align="center" span="1">
<col align="center" span="1">
<col align="center" span="1">
<col align="center" span="1">
</colgroup>
<thead>
<tr>
<th rowspan="2" align="left" valign="top" colspan="1">Pattern</th>
<th colspan="4" align="center" valign="top" rowspan="1">Depth metrics</th>
<th colspan="2" align="center" valign="top" rowspan="1">Segmentation metrics</th>
</tr>
<tr>
<th align="center" valign="top" colspan="1" rowspan="1">MAE (mm) ↓</th>
<th align="center" valign="top" colspan="1" rowspan="1">Abs Rel ↓</th>
<th align="center" valign="top" colspan="1" rowspan="1">
<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math77" display="inline" overflow="linebreak"><mrow><mi>δ</mi><mo>=</mo><mn>1.1</mn></mrow></math></span> ↑</th>
<th align="center" valign="top" colspan="1" rowspan="1">
<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math78" display="inline" overflow="linebreak"><mrow><mi>δ</mi><mo>=</mo><msup><mrow><mn>1.1</mn></mrow><mrow><mn>2</mn></mrow></msup></mrow></math></span> ↑</th>
<th align="center" valign="top" colspan="1" rowspan="1">DSC ↑</th>
<th align="center" valign="top" colspan="1" rowspan="1">mIoU ↑</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Binary pattern</td>
<td align="center" colspan="1" rowspan="1">2.28</td>
<td align="center" colspan="1" rowspan="1">0.0219</td>
<td align="center" colspan="1" rowspan="1">0.9726</td>
<td align="center" colspan="1" rowspan="1">0.9863</td>
<td align="center" colspan="1" rowspan="1">0.9944</td>
<td align="center" colspan="1" rowspan="1">0.9776</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Sinusoidal pattern</td>
<td align="center" colspan="1" rowspan="1">2.38</td>
<td align="center" colspan="1" rowspan="1">0.0231</td>
<td align="center" colspan="1" rowspan="1">0.9716</td>
<td align="center" colspan="1" rowspan="1">0.9860</td>
<td align="center" colspan="1" rowspan="1">0.9950</td>
<td align="center" colspan="1" rowspan="1">0.9801</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/t002/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="sec3.3"><h3 class="pmc_sec_title">3.3. Algorithm Efficiency</h3>
<p>The entire network has a parameter size of 175.42 MB, with DepthNet and MaskNet each using 87.71 MB due to their similar structures. The memory usage throughout the training process was 6.85 GB. To analyze GPU usage and explore the potential improvements in time consumption, we utilized PyTorch Profiler to obtain detailed execution and efficiency metrics. The results presented in <a href="#t003" class="usa-link">Table 3</a>, demonstrate that for a single frame depth prediction, the total processing time was 12.75 ms, where the GPU kernel, memory copy, CPU execution, and other operations accounted for 87.93%, 0.07%, 8.34%, and 3.66% of that time, respectively. Note that the acquisition time for each frame was 50 ms. The network depth prediction was faster than the image acquisition, and the system has the potential for acceleration through further optical optimization.</p>
<section class="tw xbox font-sm" id="t003"><h4 class="obj_head">Table 3.</h4>
<div class="caption p"><p>Network execution time summary.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" span="1">
<col align="center" span="1">
<col align="center" span="1">
</colgroup>
<thead><tr>
<th align="left" valign="top" colspan="1" rowspan="1">Category</th>
<th align="center" valign="top" colspan="1" rowspan="1">Time duration (ms)</th>
<th align="center" valign="top" colspan="1" rowspan="1">Percentage (%)</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">GPU Kernel</td>
<td align="center" colspan="1" rowspan="1">12.75</td>
<td align="center" colspan="1" rowspan="1">87.93</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Memory copy</td>
<td align="center" colspan="1" rowspan="1">0.01</td>
<td align="center" colspan="1" rowspan="1">0.07</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">CPU execution</td>
<td align="center" colspan="1" rowspan="1">1.21</td>
<td align="center" colspan="1" rowspan="1">8.34</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Other</td>
<td align="center" colspan="1" rowspan="1">0.53</td>
<td align="center" colspan="1" rowspan="1">3.66</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Total</td>
<td align="center" colspan="1" rowspan="1">14.50</td>
<td align="center" colspan="1" rowspan="1">100</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/t003/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="sec3.4"><h3 class="pmc_sec_title">3.4. Ablation Study</h3>
<p>To demonstrate the benefits of the two-path design of the network, we conducted an ablation study by removing the MaskNet. The synthesized dataset with 20 Hz sinusoidal and binary patterns was used for testing. The images were only fed into DepthNet for depth prediction training, with the same training strategies utilized as described in Sec. <a href="#sec2.7" class="usa-link">2.7</a>. The depth reconstruction results and corresponding error maps from network with and without MaskNet are shown in <a href="#f8" class="usa-link">Fig. 8</a>. <a href="#f8" class="usa-link">Figures 8(a)</a> and <a href="#f8" class="usa-link">8(f)</a> show the original image with binary patterns and sinusoidal patterns, respectively. <a href="#f8" class="usa-link">Figures 8(b)</a> and <a href="#f8" class="usa-link">8(g)</a> are the depth reconstruction results of the proposed method with MaskNet, whereas rows (d) and (i) are the depth reconstruction results without MaskNet, respectively. The corresponding error map and MAE of <a href="#f8" class="usa-link">Figs. 8(b)</a>, <a href="#f8" class="usa-link">8(d)</a>, <a href="#f8" class="usa-link">8(g)</a>, and <a href="#f8" class="usa-link">8(i)</a> are shown as <a href="#f8" class="usa-link">Figs. 8(c)</a>, <a href="#f8" class="usa-link">8(e)</a>, <a href="#f8" class="usa-link">8(h)</a>, and <a href="#f8" class="usa-link">8(j)</a>. The results show that removing MaskNet leads to a noticeable decrease in depth-map prediction accuracy in both patterns. This is primarily because, without MaskNet, the network is required to also learn the depth prediction for background regions, especially those at the edge of the sample. Although the background in our dataset is relatively simple, it still introduces unnecessary complexity that can slow down the learning process and reduce overall accuracy. By explicitly segmenting the object of interest, MaskNet helps the network focus on relevant foreground features, thereby improving both training efficiency and prediction performance.</p>
<figure class="fig xbox font-sm" id="f8"><h4 class="obj_head">Fig. 8.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12364446_JBO-030-086003-g008.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8e7f/12364446/ac794700caad/JBO-030-086003-g008.jpg" loading="lazy" height="293" width="735" alt="Fig. 8"></a></p>
<div class="p text-right font-secondary"><a href="figure/f8/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Depth reconstruction results and error map from (top) binary and (bottom) sinusoidal pattern image. Panels (a) and (f) are the original images with binary patterns and sinusoidal patterns, respectively. Panels (b) and (g) are the corresponding depth reconstruction results from the original network with MaskNet; (c) and (h) are the corresponding absolute error maps, respectively. Panels (d) and (i) are the corresponding depth reconstruction results from the network without MaskNet; (e) and (j) are the corresponding absolute error maps, respectively. Depth unit: millimeter.</p></figcaption></figure></section></section><section id="sec4"><h2 class="pmc_sec_title">4. Discussion</h2>
<p>In this paper, we successfully proposed and demonstrated an endoscopic single-shot fringe projection profilometry (FPP) system using a novel neural network designed to predict depth maps. The data acquisition system employed a dual-channel endoscope to project patterns and capture data through separate channels in one endoscope. The network was composed of two parts: the MaskNet to segment the sample and the DepthNet to generate the corresponding depth map. The network was trained and evaluated using both synthetic data and endoscopic FPP data. The system achieved real-time 20 FPS depth measurements within millimeter-level error using both binary and sinusoidal patterns.</p>
<p>Our novel approach is based on a dual-channel endoscope using a single-shot network algorithm. The conventional FPP system is constrained by its lengthy acquisition and processing times and requires a synchronization device between the projector and fringe patterns to align the camera exposure time with different fringe patterns. By contrast, the presented method eliminates the need for synchronization, reducing the system’s weight and complexity and facilitating easier integration with robotic systems.</p>
<p>The separate design of MaskNet and DepthNet was essential for the depth prediction task for several reasons. First, although the sample was easily distinguishable from the background in our experimental and synthetic data, real clinical scenarios have more complex backgrounds, where the texture and color may closely resemble the target tissue. An independent segmentation path is thus highly beneficial. The presented experiments primarily involved relatively simple tissue structures; the network’s ability to preserve the fine details of the tissue shows potential for generalizing to more complex surface topological structures. Second, using a single network would result in the error of training being dominated by background prediction, due to the large proportion of background pixels. Utilizing separate networks and loss functions helped our network focus on the depth prediction task for the sample as described in Sec. <a href="#sec3.4" class="usa-link">3.4</a>.</p>
<p>The conventional FPP based on a binary pattern mask with N stripes can encode the image up to <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math79" display="inline" overflow="linebreak"><mrow><msup><mn>2</mn><mi>N</mi></msup></mrow></math></span> combination of stripes in sequences.<a href="#r17" class="usa-link" aria-describedby="r17"><sup>17</sup></a> It is reliable to remove phase ambiguities, but less sensitive to surface characteristics than sinusoidal patterns due to the lack of a smooth phase gradient. Thus, the sinusoidal pattern is ideal for applications requiring fine surface detail. There is also a method that uses combined sinusoidal and binary patterns<a href="#r31" class="usa-link" aria-describedby="r31"><sup>31</sup></a> for accurate phase retrieval. In our proposed algorithm, the images of binary fringe patterns produced more accurate depth prediction. Because the pattern phase/intensity-depth mapping is highly sensitive to the image quality and motion blur, the binary fringe has the potential to be more robust for dynamic measurements of living tissue.</p>
<p>The proposed endoscope FPP optical setup can be considered to be an approximate coaxial structure. Its compact design minimizes optical aberrations, simplifies the mechanical layout, system calibration, and facilitates integration with robotic surgical systems as a 3D imaging system. However, one significant disadvantage of the system is that, due to space constraints, only a portion of the camera’s field of view is utilized, resulting in a lower numerical aperture and increased image noise. It may also decrease phase retrieval sensitivity to height variations compared to noncoaxial setups. This reduction in sensitivity can lead to slightly lower depth resolution. On the contrary, it improves the robustness of phase measurements against noise, due to the simplified mapping between image coordinates and surface points. In summary, our approximate coaxial system has a trade-off between sensitivity and robustness. Although it may slightly compromise depth sensitivity, it offers advantages in measurement stability and system alignment, particularly beneficial for real-time applications. Another key factor is that the ground truth is generated using the conventional FPP algorithm, which relies on the image quality from the camera. The non-uniform lighting could distort the fringe patterns and reduce the phase estimation accuracy and limit the network’s prediction capabilities. Several optimizations can be made to further improve the optical setup. The DMD chip in the projector adopts a diamond layout and exhibits diagonal flipping behavior, which can introduce spatial non-uniformity and aliasing artifacts. These effects often lead to fringe distortion and phase retrieval errors. To address these issues, we implemented the following strategies. First, we applied low-pass filtering and bicubic downsampling to the input image to suppress aliasing from the diamond grid while preserving the necessary fringe frequencies. Second, our single-shot network employed binary patterns, which inherently avoid phase noise induced by mirror flipping. This is because the DMD mirrors operate in fully ON/OFF states, eliminating partial-angle settling artifacts and ensuring both intensity uniformity and temporal consistency, which are critical for accurate phase and height retrieval. Moreover, by leveraging the single-shot network, in the future, we can replace the projector with a simple LED light source and a fixed binary mask to generate the required fringe patterns. This substitution will eliminate the projector’s influence entirely, further improving system stability and performance. In addition, the decreased size of the illumination section could save space for the camera and provide for better image quality, also allowing for more adaptive optical configuration.</p>
<p>In addition, the accuracy discrepancy between the synthetic and experimental data stems from the differing methods of ground truth generation. Using a more accurate approach, such as a computed tomography<a href="#r32" class="usa-link" aria-describedby="r32"><sup>32</sup></a> or optical coherence tomography<a href="#r33" class="usa-link" aria-describedby="r33"><sup>33</sup></a> system, could significantly improve the results. Due to the limitation of projector intensity, the acquisition time for each frame was 50 ms (20 FPS), which is a longer exposure time than what is achievable otherwise. The algorithm achieved a processing time of 12.75 ms (<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math80" display="inline" overflow="linebreak"><mrow><mo form="prefix">≈</mo><mn>78</mn></mrow></math></span> FPS) for each frame. A higher frame rate is feasible with improvements in the light source and optical design.</p>
<p>The current experiments focused on intestinal tissue imaging due to its relevance in task-specific, constrained surgical environments where rapid and compact 3D sensing is essential.<a href="#r4" class="usa-link" aria-describedby="r4"><sup>4</sup></a> In clinical scenarios, more complex tissue structures and various forms of tissue deformation may pose challenges to both depth prediction and tissue segmentation. To enhance clinical applicability, future studies will focus on extending the system to a broader range of anatomical structures, such as layered tissues.<a href="#r34" class="usa-link" aria-describedby="r34"><sup>34</sup></a></p></section><section id="sec5"><h2 class="pmc_sec_title">5. Conclusion</h2>
<p>In summary, we described an endoscopic single-shot FPP system to achieve real-time depth map generation using a deep learning network. The network was tested on both synthetic and our experimental phantom sample data to assess model generalization. The system was evaluated using both the binary and sinusoidal fringe patterns. Both patterns achieved an absolute depth measurement error less than <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math81" display="inline" overflow="linebreak"><mrow><mo form="prefix">∼</mo><mn>2</mn><mtext>  </mtext><mi>mm</mi></mrow></math></span> (absolute relative error <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="math82" display="inline" overflow="linebreak"><mrow><mn>2</mn><mo>%</mo><mo>∼</mo><mn>3</mn><mo>%</mo></mrow></math></span>) at an acquisition and processing speed of 20 frames per second, thus establishing the feasibility of a low-cost single-shot system based on a binary pattern.</p></section><section id="ack1" class="ack"><h2 class="pmc_sec_title">Acknowledgments</h2>
<p>
<em>This work was supported by the US National Institutes of Health (NIH Award No. 1R56EB033807).</em>
</p></section><section id="d8860e3659" class="bio"><h2 class="pmc_sec_title">Biography</h2>
<p>Biographies of the authors are not available.</p></section><section id="funding-statement1" lang="en"><h2 class="pmc_sec_title">Funding Statement</h2>
<p>This work was supported by the US National Institutes of Health (NIH Award No. 1R56EB033807).</p></section><section id="_ci93_" lang="en" class="contrib-info"><h2 class="pmc_sec_title">Contributor Information</h2>
<p>Ruizhi Zuo, Email: rzuo3@jhu.edu.</p>
<p>Shuwen Wei, Email: swei14@jhu.edu.</p>
<p>Yaning Wang, Email: ywang511@jhu.edu.</p>
<p>Ruichen Huang, Email: rhuang41@jhu.edu.</p>
<p>Wayne Wonseok Rodgers, Email: wrodger2@jh.edu.</p>
<p>Jinglun Yu, Email: jyu146@jhu.edu.</p>
<p>Michael H. Hsieh, Email: mhsieh@childrensnational.org.</p>
<p>Axel Krieger, Email: axel@jhu.edu.</p>
<p>Jin U. Kang, Email: jkang@jhu.edu.</p></section><section id="sec24"><h2 class="pmc_sec_title">Disclosures</h2>
<p>The authors declare no conflicts of interest.</p></section><section id="sec25"><h2 class="pmc_sec_title">Code and Data Availability</h2>
<p>Available upon reasonable request to the corresponding author.</p></section><section id="ref-list1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="ref-list1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="r1">
<span class="label">1.</span><cite>Le H. N. D., et al. , “Semi-autonomous laparoscopic robotic electro-surgery with a novel 3D endoscope,” IEEE Int. Conf. Robot. Autom.
2018, 6637–6644 (2018). 10.1109/ICRA.2018.8461060
</cite> [<a href="https://doi.org/10.1109/ICRA.2018.8461060" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6716798/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31475074/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Int.%20Conf.%20Robot.%20Autom.&amp;title=Semi-autonomous%20laparoscopic%20robotic%20electro-surgery%20with%20a%20novel%203D%20endoscope&amp;author=H.%20N.%20D.%20Le&amp;volume=2018&amp;publication_year=2018&amp;pages=6637-6644&amp;pmid=31475074&amp;doi=10.1109/ICRA.2018.8461060&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r2">
<span class="label">2.</span><cite>Le H. N. D., et al. , “Suture maps based on structural enhanced imaging endoscope for laparoscopic robotic surgery,” in Conf. Lasers Electro Opt. 2018, p. JTu2A.106 (2018). 10.1364/CLEO_AT.2018.JTu2A.106</cite> [<a href="https://doi.org/10.1364/CLEO_AT.2018.JTu2A.106" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7841646/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33521796/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Le%20H.%20N.%20D.,%20et%20al.%20,%20%E2%80%9CSuture%20maps%20based%20on%20structural%20enhanced%20imaging%20endoscope%20for%20laparoscopic%20robotic%20surgery,%E2%80%9D%20in%20Conf.%20Lasers%20Electro%20Opt.%202018,%20p.%C2%A0JTu2A.106%20(2018).%2010.1364/CLEO_AT.2018.JTu2A.106" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r3">
<span class="label">3.</span><cite>Le H. N. D., et al. , “Demonstration of a laparoscopic structured-illumination three-dimensional imaging system for guiding reconstructive bowel anastomosis,” J. Biomed. Opt.
23(5), 1 (2018). 10.1117/1.JBO.23.5.056009</cite> [<a href="https://doi.org/10.1117/1.JBO.23.5.056009" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC5964336/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/29797865/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J.%20Biomed.%20Opt.&amp;title=Demonstration%20of%20a%20laparoscopic%20structured-illumination%20three-dimensional%20imaging%20system%20for%20guiding%20reconstructive%20bowel%20anastomosis&amp;author=H.%20N.%20D.%20Le&amp;volume=23&amp;issue=5&amp;publication_year=2018&amp;pages=1&amp;issn=1083-3668&amp;pmid=29797865&amp;doi=10.1117/1.JBO.23.5.056009&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r4">
<span class="label">4.</span><cite>Saeidi H., et al. , “Autonomous robotic laparoscopic surgery for intestinal anastomosis,” Sci. Robot.
7(62), eabj2908 (2022). 10.1126/scirobotics.abj2908
</cite> [<a href="https://doi.org/10.1126/scirobotics.abj2908" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8992572/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35080901/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Sci.%20Robot.&amp;title=Autonomous%20robotic%20laparoscopic%20surgery%20for%20intestinal%20anastomosis&amp;author=H.%20Saeidi&amp;volume=7&amp;issue=62&amp;publication_year=2022&amp;pages=eabj2908&amp;pmid=35080901&amp;doi=10.1126/scirobotics.abj2908&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r5">
<span class="label">5.</span><cite>Du H., Wang Z., “Three-dimensional shape measurement with an arbitrarily arranged fringe projection profilometry system,” Opt. Lett.
32(16), 2438 (2007). 10.1364/OL.32.002438
</cite> [<a href="https://doi.org/10.1364/OL.32.002438" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/17700811/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Opt.%20Lett.&amp;title=Three-dimensional%20shape%20measurement%20with%20an%20arbitrarily%20arranged%20fringe%20projection%20profilometry%20system&amp;author=H.%20Du&amp;author=Z.%20Wang&amp;volume=32&amp;issue=16&amp;publication_year=2007&amp;pages=2438&amp;issn=0146-9592&amp;pmid=17700811&amp;doi=10.1364/OL.32.002438&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r6">
<span class="label">6.</span><cite>Zuo R., Irsch K., Kang J. U., “Higher-order regression three-dimensional motion-compensation method for real-time optical coherence tomography volumetric imaging of the cornea,” J. Biomed. Opt.
27(6), 066006 (2022). 10.1117/1.JBO.27.6.066006
</cite> [<a href="https://doi.org/10.1117/1.JBO.27.6.066006" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9232272/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35751143/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J.%20Biomed.%20Opt.&amp;title=Higher-order%20regression%20three-dimensional%20motion-compensation%20method%20for%20real-time%20optical%20coherence%20tomography%20volumetric%20imaging%20of%20the%20cornea&amp;author=R.%20Zuo&amp;author=K.%20Irsch&amp;author=J.%20U.%20Kang&amp;volume=27&amp;issue=6&amp;publication_year=2022&amp;pages=066006&amp;issn=1083-3668&amp;pmid=35751143&amp;doi=10.1117/1.JBO.27.6.066006&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r7">
<span class="label">7.</span><cite>Ronneberger O., Fischer P., Brox T., “U-Net: convolutional networks for biomedical image segmentation,” Lect. Notes Comput. Sci.
9351, 234–241 (2015). 10.1007/978-3-319-24574-4_28</cite> [<a href="https://doi.org/10.1007/978-3-319-24574-4_28" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Lect.%20Notes%20Comput.%20Sci.&amp;title=U-Net:%20convolutional%20networks%20for%20biomedical%20image%20segmentation&amp;author=O.%20Ronneberger&amp;author=P.%20Fischer&amp;author=T.%20Brox&amp;volume=9351&amp;publication_year=2015&amp;pages=234-241&amp;issn=0302-9743&amp;doi=10.1007/978-3-319-24574-4_28&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r8">
<span class="label">8.</span><cite>Nguyen H., Wang Y., Wang Z., “Single-shot 3D shape reconstruction using structured light and deep convolutional neural networks,” Sensors
20(13), 3718 (2020). 10.3390/s20133718
</cite> [<a href="https://doi.org/10.3390/s20133718" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7374384/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32635144/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Sensors&amp;title=Single-shot%203D%20shape%20reconstruction%20using%20structured%20light%20and%20deep%20convolutional%20neural%20networks&amp;author=H.%20Nguyen&amp;author=Y.%20Wang&amp;author=Z.%20Wang&amp;volume=20&amp;issue=13&amp;publication_year=2020&amp;pages=3718&amp;issn=0746-9462&amp;pmid=32635144&amp;doi=10.3390/s20133718&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r9">
<span class="label">9.</span><cite>Nguyen H., Wang Z., “Accurate 3D shape reconstruction from single structured-light image via fringe-to-fringe network,” Photonics
8(11), 459 (2021). 10.3390/photonics8110459</cite> [<a href="https://doi.org/10.3390/photonics8110459" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Photonics&amp;title=Accurate%203D%20shape%20reconstruction%20from%20single%20structured-light%20image%20via%20fringe-to-fringe%20network&amp;author=H.%20Nguyen&amp;author=Z.%20Wang&amp;volume=8&amp;issue=11&amp;publication_year=2021&amp;pages=459&amp;doi=10.3390/photonics8110459&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r10">
<span class="label">10.</span><cite>Wang F., Wang C., Guan Q., “Single-shot fringe projection profilometry based on deep learning and computer graphics,” Opt. Express
29(6), 8024 (2021). 10.1364/OE.418430
</cite> [<a href="https://doi.org/10.1364/OE.418430" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33820257/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Opt.%20Express&amp;title=Single-shot%20fringe%20projection%20profilometry%20based%20on%20deep%20learning%20and%20computer%20graphics&amp;author=F.%20Wang&amp;author=C.%20Wang&amp;author=Q.%20Guan&amp;volume=29&amp;issue=6&amp;publication_year=2021&amp;pages=8024&amp;issn=1094-4087&amp;pmid=33820257&amp;doi=10.1364/OE.418430&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r11">
<span class="label">11.</span><cite>Zuo R., et al. , “Deep learning-based single-shot fringe projection profilometry,” Proc. SPIE
12831, 1283106 (2024). 10.1117/12.3001837</cite> [<a href="https://doi.org/10.1117/12.3001837" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Proc.%20SPIE&amp;title=Deep%20learning-based%20single-shot%20fringe%20projection%20profilometry&amp;author=R.%20Zuo&amp;volume=12831&amp;publication_year=2024&amp;pages=1283106&amp;issn=0277-786X&amp;doi=10.1117/12.3001837&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r12">
<span class="label">12.</span><cite>Yang T., et al. , “Single-shot phase extraction for fringe projection profilometry using deep convolutional generative adversarial network,” Meas. Sci. Technol.
32(1), 015007 (2020). 10.1088/1361-6501/aba5c5</cite> [<a href="https://doi.org/10.1088/1361-6501/aba5c5" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Meas.%20Sci.%20Technol.&amp;title=Single-shot%20phase%20extraction%20for%20fringe%20projection%20profilometry%20using%20deep%20convolutional%20generative%20adversarial%20network&amp;author=T.%20Yang&amp;volume=32&amp;issue=1&amp;publication_year=2020&amp;pages=015007&amp;issn=0957-0233&amp;doi=10.1088/1361-6501/aba5c5&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r13">
<span class="label">13.</span><cite>Yu H., et al. , “Dynamic 3-D measurement based on fringe-to-fringe transformation using deep learning,” Opt. Express
28(7), 9405 (2020). 10.1364/OE.387215
</cite> [<a href="https://doi.org/10.1364/OE.387215" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32225548/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Opt.%20Express&amp;title=Dynamic%203-D%20measurement%20based%20on%20fringe-to-fringe%20transformation%20using%20deep%20learning&amp;author=H.%20Yu&amp;volume=28&amp;issue=7&amp;publication_year=2020&amp;pages=9405&amp;issn=1094-4087&amp;pmid=32225548&amp;doi=10.1364/OE.387215&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r14">
<span class="label">14.</span><cite>Yu H., et al. , “Untrained deep learning-based fringe projection profilometry,” APL Photonics
7(1), 016102 (2022). 10.1063/5.0069386</cite> [<a href="https://doi.org/10.1063/5.0069386" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=APL%20Photonics&amp;title=Untrained%20deep%20learning-based%20fringe%20projection%20profilometry&amp;author=H.%20Yu&amp;volume=7&amp;issue=1&amp;publication_year=2022&amp;pages=016102&amp;doi=10.1063/5.0069386&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r15">
<span class="label">15.</span><cite>Zheng Y., et al. , “Fringe projection profilometry by conducting deep learning from its digital twin,” Opt. Express
28(24), 36568 (2020). 10.1364/OE.410428
</cite> [<a href="https://doi.org/10.1364/OE.410428" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33379748/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Opt.%20Express&amp;title=Fringe%20projection%20profilometry%20by%20conducting%20deep%20learning%20from%20its%20digital%20twin&amp;author=Y.%20Zheng&amp;volume=28&amp;issue=24&amp;publication_year=2020&amp;pages=36568&amp;issn=1094-4087&amp;pmid=33379748&amp;doi=10.1364/OE.410428&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r16">
<span class="label">16.</span><cite>Wei S., et al. , “Deep point cloud landmark localization for fringe projection profilometry,” J. Opt. Soc. Am. A
39(4), 655 (2022). 10.1364/JOSAA.450225</cite> [<a href="https://doi.org/10.1364/JOSAA.450225" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35471389/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J.%20Opt.%20Soc.%20Am.%20A&amp;title=Deep%20point%20cloud%20landmark%20localization%20for%20fringe%20projection%20profilometry&amp;author=S.%20Wei&amp;volume=39&amp;issue=4&amp;publication_year=2022&amp;pages=655&amp;issn=0740-3232&amp;pmid=35471389&amp;doi=10.1364/JOSAA.450225&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r17">
<span class="label">17.</span><cite>Ishii I., et al. , “High-speed 3D image acquisition using coded structured light projection,” in IEEE/RSJ Int. Conf. Intell. Robot. Syst., IEEE, San Diego, California, pp. 925–930 (2007). 10.1109/IROS.2007.4399180</cite> [<a href="https://doi.org/10.1109/IROS.2007.4399180" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?Ishii%20I.,%20et%20al.%20,%20%E2%80%9CHigh-speed%203D%20image%20acquisition%20using%20coded%20structured%20light%20projection,%E2%80%9D%20in%20IEEE/RSJ%20Int.%20Conf.%20Intell.%20Robot.%20Syst.,%20IEEE,%20San%20Diego,%20California,%20pp.%C2%A0925%E2%80%93930%20(2007).%2010.1109/IROS.2007.4399180" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r18">
<span class="label">18.</span><cite>Geng J., “Structured-light 3D surface imaging: a tutorial,” Adv. Opt. Photonics
3(2), 128 (2011). 10.1364/AOP.3.000128</cite> [<a href="https://doi.org/10.1364/AOP.3.000128" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Adv.%20Opt.%20Photonics&amp;title=Structured-light%203D%20surface%20imaging:%20a%20tutorial&amp;author=J.%20Geng&amp;volume=3&amp;issue=2&amp;publication_year=2011&amp;pages=128&amp;issn=1943-8206&amp;doi=10.1364/AOP.3.000128&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r19">
<span class="label">19.</span><cite>Xiao-jie D., Fa-jie D., Chang-rong L., “Phase stabilizing method based on PTAC for fiber-optic interference fringe projection profilometry,” Opt. Laser Technol.
47, 137–143 (2013). 10.1016/j.optlastec.2012.08.032</cite> [<a href="https://doi.org/10.1016/j.optlastec.2012.08.032" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Opt.%20Laser%20Technol.&amp;title=Phase%20stabilizing%20method%20based%20on%20PTAC%20for%20fiber-optic%20interference%20fringe%20projection%20profilometry&amp;author=D.%20Xiao-jie&amp;author=D.%20Fa-jie&amp;author=L.%20Chang-rong&amp;volume=47&amp;publication_year=2013&amp;pages=137-143&amp;issn=0030-3992&amp;doi=10.1016/j.optlastec.2012.08.032&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r20">
<span class="label">20.</span><cite>Chu C., et al. , “An optimized fringe generator of 3D pavement profilometry based on laser interference fringe,” Opt. Lasers Eng.
136, 106142 (2021). 10.1016/j.optlaseng.2020.106142</cite> [<a href="https://doi.org/10.1016/j.optlaseng.2020.106142" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Opt.%20Lasers%20Eng.&amp;title=An%20optimized%20fringe%20generator%20of%203D%20pavement%20profilometry%20based%20on%20laser%20interference%20fringe&amp;author=C.%20Chu&amp;volume=136&amp;publication_year=2021&amp;pages=106142&amp;doi=10.1016/j.optlaseng.2020.106142&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r21">
<span class="label">21.</span><cite>Schaffer M., et al. , “Coherent two-beam interference fringe projection for highspeed three-dimensional shape measurements,” Appl. Opt.
52(11), 2306 (2013). 10.1364/AO.52.002306
</cite> [<a href="https://doi.org/10.1364/AO.52.002306" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/23670759/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Appl.%20Opt.&amp;title=Coherent%20two-beam%20interference%20fringe%20projection%20for%20highspeed%20three-dimensional%20shape%20measurements&amp;author=M.%20Schaffer&amp;volume=52&amp;issue=11&amp;publication_year=2013&amp;pages=2306&amp;issn=0003-6935&amp;pmid=23670759&amp;doi=10.1364/AO.52.002306&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r22">
<span class="label">22.</span><cite>Liang J., et al. , “Grayscale laser image formation using a programmable binary mask,” Opt. Eng.
51(10), 108201 (2012). 10.1117/1.OE.51.10.108201</cite> [<a href="https://doi.org/10.1117/1.OE.51.10.108201" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Opt.%20Eng.&amp;title=Grayscale%20laser%20image%20formation%20using%20a%20programmable%20binary%20mask&amp;author=J.%20Liang&amp;volume=51&amp;issue=10&amp;publication_year=2012&amp;pages=108201&amp;doi=10.1117/1.OE.51.10.108201&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r23">
<span class="label">23.</span><cite>Nguyen H., et al. , “Real-time, high-accuracy 3D imaging and shape measurement,” Appl. Opt.
54(1), A9 (2015). 10.1364/AO.54.0000A9
</cite> [<a href="https://doi.org/10.1364/AO.54.0000A9" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/25967028/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Appl.%20Opt.&amp;title=Real-time,%20high-accuracy%203D%20imaging%20and%20shape%20measurement&amp;author=H.%20Nguyen&amp;volume=54&amp;issue=1&amp;publication_year=2015&amp;pages=A9&amp;issn=0003-6935&amp;pmid=25967028&amp;doi=10.1364/AO.54.0000A9&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r24">
<span class="label">24.</span><cite>Zuo R., et al. , “High-resolution in vivo 4D-OCT fish-eye imaging using 3D-UNet with multi-level residue decoder,” Biomed. Opt. Express
15(9), 5533 (2024). 10.1364/BOE.532258
</cite> [<a href="https://doi.org/10.1364/BOE.532258" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11407266/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39296392/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Biomed.%20Opt.%20Express&amp;title=High-resolution%20in%20vivo%204D-OCT%20fish-eye%20imaging%20using%203D-UNet%20with%20multi-level%20residue%20decoder&amp;author=R.%20Zuo&amp;volume=15&amp;issue=9&amp;publication_year=2024&amp;pages=5533&amp;issn=2156-7085&amp;pmid=39296392&amp;doi=10.1364/BOE.532258&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r25">
<span class="label">25.</span><cite>Wang Z., et al. , “Image quality assessment: from error visibility to structural similarity,” IEEE Trans. Image Process.
13(4), 600–612 (2004). 10.1109/TIP.2003.819861
</cite> [<a href="https://doi.org/10.1109/TIP.2003.819861" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/15376593/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans.%20Image%20Process.&amp;title=Image%20quality%20assessment:%20from%20error%20visibility%20to%20structural%20similarity&amp;author=Z.%20Wang&amp;volume=13&amp;issue=4&amp;publication_year=2004&amp;pages=600-612&amp;issn=1057-7149&amp;pmid=15376593&amp;doi=10.1109/TIP.2003.819861&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r26">
<span class="label">26.</span><cite>Sudre C. H., et al. , “Generalised dice overlap as a deep learning loss function for highly unbalanced segmentations,” Lect. Notes Comput. Sci.
10553, 240–248 (2017). 10.1007/978-3-319-67558-9_28</cite> [<a href="https://doi.org/10.1007/978-3-319-67558-9_28" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7610921/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34104926/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Lect.%20Notes%20Comput.%20Sci.&amp;title=Generalised%20dice%20overlap%20as%20a%20deep%20learning%20loss%20function%20for%20highly%20unbalanced%20segmentations&amp;author=C.%20H.%20Sudre&amp;volume=10553&amp;publication_year=2017&amp;pages=240-248&amp;issn=0302-9743&amp;pmid=34104926&amp;doi=10.1007/978-3-319-67558-9_28&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r27">
<span class="label">27.</span><cite>Paszke A., et al. , “PyTorch: an imperative style, high-performance deep learning library,” arXiv:1912.01703 (2019).</cite>
</li>
<li id="r28">
<span class="label">28.</span><cite>Kingma D. P., Ba J., “Adam: a method for stochastic optimization,” arXiv:1412.6980 (2017).</cite>
</li>
<li id="r29">
<span class="label">29.</span><cite>Eigen D., Puhrsch C., Fergus R., “Depth map prediction from a single image using a multi-scale deep network,” arXiv:1406.2283 (2014).</cite>
</li>
<li id="r30">
<span class="label">30.</span><cite>Wu Z., Guo W., Zhang Q., “High-speed three-dimensional shape measurement based on shifting gray-code light,” Opt. Express
27(16), 22631 (2019). 10.1364/OE.27.022631
</cite> [<a href="https://doi.org/10.1364/OE.27.022631" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31510550/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Opt.%20Express&amp;title=High-speed%20three-dimensional%20shape%20measurement%20based%20on%20shifting%20gray-code%20light&amp;author=Z.%20Wu&amp;author=W.%20Guo&amp;author=Q.%20Zhang&amp;volume=27&amp;issue=16&amp;publication_year=2019&amp;pages=22631&amp;issn=1094-4087&amp;pmid=31510550&amp;doi=10.1364/OE.27.022631&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r31">
<span class="label">31.</span><cite>Zhou C., et al. , “An improved stair phase encoding method for absolute phase retrieval,” Opt. Lasers Eng.
66, 269–278 (2015). 10.1016/j.optlaseng.2014.09.011</cite> [<a href="https://doi.org/10.1016/j.optlaseng.2014.09.011" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Opt.%20Lasers%20Eng.&amp;title=An%20improved%20stair%20phase%20encoding%20method%20for%20absolute%20phase%20retrieval&amp;author=C.%20Zhou&amp;volume=66&amp;publication_year=2015&amp;pages=269-278&amp;doi=10.1016/j.optlaseng.2014.09.011&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r32">
<span class="label">32.</span><cite>Mangulabnan J. E., et al. , “A quantitative evaluation of dense 3D reconstruction of sinus anatomy from monocular endoscopic video,” arXiv:2310.14364 (2023).</cite>
</li>
<li id="r33">
<span class="label">33.</span><cite>Li X., Huang Y., Hao Q., “Automated robot-assisted wide-field optical coherence tomography using structured light camera,” Biomed. Opt. Express
14(8), 4310 (2023). 10.1364/BOE.496710
</cite> [<a href="https://doi.org/10.1364/BOE.496710" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10549741/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37799682/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Biomed.%20Opt.%20Express&amp;title=Automated%20robot-assisted%20wide-field%20optical%20coherence%20tomography%20using%20structured%20light%20camera&amp;author=X.%20Li&amp;author=Y.%20Huang&amp;author=Q.%20Hao&amp;volume=14&amp;issue=8&amp;publication_year=2023&amp;pages=4310&amp;issn=2156-7085&amp;pmid=37799682&amp;doi=10.1364/BOE.496710&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="r34">
<span class="label">34.</span><cite>Wang Y., et al. , “Automatic and real-time tissue sensing for autonomous intestinal anastomosis using hybrid MLP-DC-CNN classifier-based optical coherence tomography,” Biomed. Opt. Express
15(4), 2543 (2024). 10.1364/BOE.521652
</cite> [<a href="https://doi.org/10.1364/BOE.521652" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11019703/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38633079/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Biomed.%20Opt.%20Express&amp;title=Automatic%20and%20real-time%20tissue%20sensing%20for%20autonomous%20intestinal%20anastomosis%20using%20hybrid%20MLP-DC-CNN%20classifier-based%20optical%20coherence%20tomography&amp;author=Y.%20Wang&amp;volume=15&amp;issue=4&amp;publication_year=2024&amp;pages=2543&amp;issn=2156-7085&amp;pmid=38633079&amp;doi=10.1364/BOE.521652&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adda93_" lang="en" class="data-availability-statement"><h3 class="pmc_sec_title">Data Availability Statement</h3>
<p>Available upon reasonable request to the corresponding author.</p></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from Journal of Biomedical Optics are provided here courtesy of <strong>Society of Photo-Optical Instrumentation Engineers</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1117/1.JBO.30.8.086003"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/JBO-030-086003.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (8.5 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12364446/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12364446/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12364446%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12364446/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12364446/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12364446/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40837448/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12364446/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40837448/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12364446/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12364446/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="ZDS79H7GhZ5bJWjwgH6sc7Ic0EQGevPJDXys2lmd9Mqujn84bbyfqmUrwyMYGPNS">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
        <script type="module" crossorigin="" src="/static/assets/math-574fdcc6.js"></script>
    
    

    </body>
</html>
