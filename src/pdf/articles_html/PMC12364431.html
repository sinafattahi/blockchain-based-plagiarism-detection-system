
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            A Multimodal Large Language Model as an End-to-End Classifier of Thyroid Nodule Malignancy Risk: Usability Study - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="D2E4B8ED8AF3F75305B8ED002C3CA7CE.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="formative">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12364431/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="JMIR Formative Research">
<meta name="citation_title" content="A Multimodal Large Language Model as an End-to-End Classifier of Thyroid Nodule Malignancy Risk: Usability Study">
<meta name="citation_author" content="Gerald Gui Ren Sng">
<meta name="citation_author_institution" content="Department of Endocrinology, Singapore General Hospital, 20 College Road, Academia Level 3, Singapore, 169856, Singapore, 65 63214377">
<meta name="citation_author_institution" content="Data Science and Artificial Intelligence Laboratory, Singapore General Hospital, Singapore, Singapore">
<meta name="citation_author" content="Yi Xiang">
<meta name="citation_author_institution" content="Office of Insights and Analytics, SingHealth, Singapore, Singapore">
<meta name="citation_author" content="Daniel Yan Zheng Lim">
<meta name="citation_author_institution" content="Data Science and Artificial Intelligence Laboratory, Singapore General Hospital, Singapore, Singapore">
<meta name="citation_author_institution" content="Department of Gastroenterology, Singapore General Hospital, Singapore, Singapore">
<meta name="citation_author" content="Joshua Yi Min Tung">
<meta name="citation_author_institution" content="Data Science and Artificial Intelligence Laboratory, Singapore General Hospital, Singapore, Singapore">
<meta name="citation_author_institution" content="Department of Urology, Singapore General Hospital, Singapore, Singapore">
<meta name="citation_author" content="Jen Hong Tan">
<meta name="citation_author_institution" content="Data Science and Artificial Intelligence Laboratory, Singapore General Hospital, Singapore, Singapore">
<meta name="citation_author" content="Chiaw Ling Chng">
<meta name="citation_author_institution" content="Department of Endocrinology, Singapore General Hospital, 20 College Road, Academia Level 3, Singapore, 169856, Singapore, 65 63214377">
<meta name="citation_publication_date" content="2025 Aug 19">
<meta name="citation_volume" content="9">
<meta name="citation_firstpage" content="e70863">
<meta name="citation_doi" content="10.2196/70863">
<meta name="citation_pmid" content="40829145">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12364431/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12364431/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12364431/pdf/formative-v9-e70863.pdf">
<meta name="description" content="Thyroid nodules are common, with ultrasound imaging as the primary modality for their assessment. Risk stratification systems like the American College of Radiology Thyroid Imaging Reporting and Data System (ACR TI-RADS) have been developed but ...">
<meta name="og:title" content="A Multimodal Large Language Model as an End-to-End Classifier of Thyroid Nodule Malignancy Risk: Usability Study">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="Thyroid nodules are common, with ultrasound imaging as the primary modality for their assessment. Risk stratification systems like the American College of Radiology Thyroid Imaging Reporting and Data System (ACR TI-RADS) have been developed but ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12364431/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12364431">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.2196/70863"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/formative-v9-e70863.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12364431%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12364431/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12364431/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12364431/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-formative.png" alt="JMIR Formative Research logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to JMIR Formative Research" title="Link to JMIR Formative Research" shape="default" href="https://formative.jmir.org/" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">JMIR Form Res</button></div>. 2025 Aug 19;9:e70863. doi: <a href="https://doi.org/10.2196/70863" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.2196/70863</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22JMIR%20Form%20Res%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22JMIR%20Form%20Res%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22JMIR%20Form%20Res%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22JMIR%20Form%20Res%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>A Multimodal Large Language Model as an End-to-End Classifier of Thyroid Nodule Malignancy Risk: Usability Study</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sng%20GGR%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Gerald Gui Ren Sng</span></a><div hidden="hidden" id="id1">
<h3>
<span class="name western">Gerald Gui Ren Sng</span>, <span class="degrees">MBBS, MRCP(UK), MMed (Int Med), MPH</span>
</h3>
<div class="p">
<sup>1</sup>Department of Endocrinology, Singapore General Hospital, 20 College Road, Academia Level 3, Singapore, 169856, Singapore, 65 63214377</div>
<div class="p">
<sup>2</sup>Data Science and Artificial Intelligence Laboratory, Singapore General Hospital, Singapore, Singapore</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sng%20GGR%22%5BAuthor%5D" class="usa-link"><span class="name western">Gerald Gui Ren Sng</span></a>
</div>
</div>
<sup>1,</sup><sup>2,</sup><sup>✉</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Xiang%20Y%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Yi Xiang</span></a><div hidden="hidden" id="id2">
<h3>
<span class="name western">Yi Xiang</span>, <span class="degrees">BEng, MTech</span>
</h3>
<div class="p">
<sup>3</sup>Office of Insights and Analytics, SingHealth, Singapore, Singapore</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Xiang%20Y%22%5BAuthor%5D" class="usa-link"><span class="name western">Yi Xiang</span></a>
</div>
</div>
<sup>3</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Lim%20DYZ%22%5BAuthor%5D" class="usa-link" aria-describedby="id3"><span class="name western">Daniel Yan Zheng Lim</span></a><div hidden="hidden" id="id3">
<h3>
<span class="name western">Daniel Yan Zheng Lim</span>, <span class="degrees">MBBS, MRCP(UK), MMed (Int Med), MTech</span>
</h3>
<div class="p">
<sup>2</sup>Data Science and Artificial Intelligence Laboratory, Singapore General Hospital, Singapore, Singapore</div>
<div class="p">
<sup>4</sup>Department of Gastroenterology, Singapore General Hospital, Singapore, Singapore</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Lim%20DYZ%22%5BAuthor%5D" class="usa-link"><span class="name western">Daniel Yan Zheng Lim</span></a>
</div>
</div>
<sup>2,</sup><sup>4</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Tung%20JYM%22%5BAuthor%5D" class="usa-link" aria-describedby="id4"><span class="name western">Joshua Yi Min Tung</span></a><div hidden="hidden" id="id4">
<h3>
<span class="name western">Joshua Yi Min Tung</span>, <span class="degrees">MBBS, MPH</span>
</h3>
<div class="p">
<sup>2</sup>Data Science and Artificial Intelligence Laboratory, Singapore General Hospital, Singapore, Singapore</div>
<div class="p">
<sup>5</sup>Department of Urology, Singapore General Hospital, Singapore, Singapore</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Tung%20JYM%22%5BAuthor%5D" class="usa-link"><span class="name western">Joshua Yi Min Tung</span></a>
</div>
</div>
<sup>2,</sup><sup>5</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Tan%20JH%22%5BAuthor%5D" class="usa-link" aria-describedby="id5"><span class="name western">Jen Hong Tan</span></a><div hidden="hidden" id="id5">
<h3>
<span class="name western">Jen Hong Tan</span>, <span class="degrees">BEng, PhD</span>
</h3>
<div class="p">
<sup>2</sup>Data Science and Artificial Intelligence Laboratory, Singapore General Hospital, Singapore, Singapore</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Tan%20JH%22%5BAuthor%5D" class="usa-link"><span class="name western">Jen Hong Tan</span></a>
</div>
</div>
<sup>2,</sup><sup>*</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Chng%20CL%22%5BAuthor%5D" class="usa-link" aria-describedby="id6"><span class="name western">Chiaw Ling Chng</span></a><div hidden="hidden" id="id6">
<h3>
<span class="name western">Chiaw Ling Chng</span>, <span class="degrees">MBBS, MRCP(UK)</span>
</h3>
<div class="p">
<sup>1</sup>Department of Endocrinology, Singapore General Hospital, 20 College Road, Academia Level 3, Singapore, 169856, Singapore, 65 63214377</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Chng%20CL%22%5BAuthor%5D" class="usa-link"><span class="name western">Chiaw Ling Chng</span></a>
</div>
</div>
<sup>1,</sup><sup>*</sup>
</div>
<div class="cg p">Editor: <span class="name western">Javad Sarvestan</span>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="aff1">
<sup>1</sup>Department of Endocrinology, Singapore General Hospital, 20 College Road, Academia Level 3, Singapore, 169856, Singapore, 65 63214377</div>
<div id="aff2">
<sup>2</sup>Data Science and Artificial Intelligence Laboratory, Singapore General Hospital, Singapore, Singapore</div>
<div id="aff3">
<sup>3</sup>Office of Insights and Analytics, SingHealth, Singapore, Singapore</div>
<div id="aff4">
<sup>4</sup>Department of Gastroenterology, Singapore General Hospital, Singapore, Singapore</div>
<div id="aff5">
<sup>5</sup>Department of Urology, Singapore General Hospital, Singapore, Singapore</div>
<div class="author-notes p">
<div class="fn" id="equal-contrib1">
<sup>*</sup><p class="display-inline">these authors contributed equally</p>
</div>
<div class="fn" id="cor1">
<sup>✉</sup><p class="display-inline">Gerald Gui Ren Sng, MBBS, MRCP(UK), MMed (Int Med), MPH, Department of Endocrinology, Singapore General Hospital, 20 College Road, Academia Level 3, Singapore, 169856, Singapore, 65 63214377; <span>gerald.sng.g.r@singhealth.com.sg</span></p>
</div>
</div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2025 Jan 3; Revised 2025 Jun 19; Accepted 2025 Jun 20; Collection date 2025.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>Copyright © Gerald Gui Ren Sng, Yi Xiang, Daniel Yan Zheng Lim, Joshua Yi Min Tung, Jen Hong Tan, Chiaw Ling Chng. Originally published in JMIR Formative Research (https://formative.jmir.org)</div>
<p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (<a href="https://creativecommons.org/licenses/by/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://creativecommons.org/licenses/by/4.0/</a>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in JMIR Formative Research, is properly cited. The complete bibliographic information, a link to the original publication on <a href="https://formative.jmir.org" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://formative.jmir.org</a>, as well as this copyright and license information must be included.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12364431  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40829145/" class="usa-link">40829145</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="abstract1"><h2>Abstract</h2>
<section id="sec1"><h3 class="pmc_sec_title">Background</h3>
<p>Thyroid nodules are common, with ultrasound imaging as the primary modality for their assessment. Risk stratification systems like the American College of Radiology Thyroid Imaging Reporting and Data System (ACR TI-RADS) have been developed but suffer from interobserver variability and low specificity. Artificial intelligence, particularly large language models (LLMs) with multimodal capabilities, presents opportunities for efficient end-to-end diagnostic processes. However, their clinical utility remains uncertain.</p></section><section id="sec2"><h3 class="pmc_sec_title">Objective</h3>
<p>This study evaluates the accuracy and consistency of multimodal LLMs for thyroid nodule risk stratification using the ACR TI-RADS system, examining the effects of model fine-tuning, image annotation, prompt engineering, and comparing open-source versus commercial models.</p></section><section id="sec3"><h3 class="pmc_sec_title">Methods</h3>
<p>In total, 3 multimodal vision-language models were evaluated: Microsoft’s open-source Large Language and Visual Assistant (LLaVA) model, its medically fine-tuned variant (Large Language and Vision Assistant for bioMedicine [LLaVA-Med]), and OpenAI’s commercial o3 model. A total of 192 thyroid nodules from publicly available ultrasound image datasets were assessed. Each model was evaluated using 2 prompts (basic and modified) and 2 image scenarios (unlabeled vs radiologist-annotated), yielding 6912 responses. Model outputs were compared with expert ratings for accuracy and consistency. Statistical comparisons included Chi-square tests, Mann-Whitney <em>U</em> tests, and Fleiss’ kappa for interrater reliability.</p></section><section id="sec4"><h3 class="pmc_sec_title">Results</h3>
<p>Overall, 88.4% (6110/6912) of responses were valid, with the o3 model producing the highest validity rate (2273/2304, 98.6%), followed by LLaVA (2108/2304, 91.5%) and LLaVA-Med (1729/2304, 75%; <em>P</em>&lt;.001). The o3 model demonstrated the highest accuracy overall, achieving up to 57.3% accuracy in Thyroid Imaging Reporting and Data System (TI-RADS) classification, although still remaining suboptimal. Labeled images improved accuracy marginally in nodule margin assessment only when evaluating LLaVA models (407/768, 53% to 447/768, 58.2%; <em>P</em>=.04). Prompt engineering improved accuracy for composition (649/1,152, 56.3% vs 483/1152, 41.9%; <em>P</em>&lt;.001), but significantly reduced accuracy for shape, margins, and overall classification. Consistency was the highest with the o3 model (up to 85.4%), but was comparable for LLaVA and significantly improved with image labeling and modified prompts across multiple TI-RADS categories (<em>P</em>&lt;.001). Subgroup analysis for o3 alone showed prompt engineering did not affect accuracy significantly but markedly improved consistency across all TI-RADS categories (up to 97.1% for shape, <em>P</em>&lt;.001). Interrater reliability was consistently poor across all combinations (Fleiss’ kappa&lt;0.60).</p></section><section id="sec5"><h3 class="pmc_sec_title">Conclusions</h3>
<p>The study demonstrates the comparative advantages and limitations of multimodal LLMs for thyroid nodule risk stratification. While the commercial model (o3) consistently outperformed open-source models in accuracy and consistency, even the best-performing model outputs remained suboptimal for direct clinical deployment. Prompt engineering significantly enhanced output consistency, particularly in the commercial model. These findings underline the importance of strategic model optimization techniques and highlight areas requiring further development before multimodal LLMs can be reliably used in clinical thyroid imaging workflows.</p></section></section><section id="s1"><h2 class="pmc_sec_title">Introduction</h2>
<p>Thyroid nodules are highly prevalent, with as many as 35% of individuals having thyroid nodules on imaging [<a href="#R1" class="usa-link" aria-describedby="R1">1</a>]. Ultrasound is the first-line and most accurate imaging modality to assess thyroid nodules. The high prevalence of predominantly benign thyroid nodules in the general population led to the development of ultrasound risk stratification systems [<a href="#R2" class="usa-link" aria-describedby="R2">2-4</a>]. The American College of Radiology Thyroid Imaging Reporting and Data System (ACR TI-RADS) [<a href="#R4" class="usa-link" aria-describedby="R4">4</a>] was established to determine which nodules should have fine-needle aspiration or ultrasound follow-up by using 5 ultrasound feature categories and the maximum size of the nodule to derive a Thyroid Imaging Reporting and Data System (TI-RADS) classification ranging from 1 (benign) to 5 (highly suspicious). This system requires the assessment of 5 categories, or descriptors, of ultrasound features: composition, echogenicity, shape, margin, and calcifications (echogenic foci). While the ACR TI-RADS aims to enable the objective assessment of malignancy risk, significant real-life interobserver variability due to a lack of agreement in assigning these features has been reported [<a href="#R5" class="usa-link" aria-describedby="R5">5</a>,<a href="#R6" class="usa-link" aria-describedby="R6">6</a>]. In addition, the ACR TI-RADS suffers from low diagnostic specificity [<a href="#R7" class="usa-link" aria-describedby="R7">7</a>].</p>
<p>Large language models (LLMs) are artificial intelligence (AI) models using deep learning and artificial neural networks to handle large amounts of data, offering high-level predictive performance for varied tasks, including knowledge synthesis and health outcome prediction [<a href="#R8" class="usa-link" aria-describedby="R8">8</a>]. They are pretrained on large sets of extant human-generated information to learn patterns and probabilities that allow the synthesis of de novo content.</p>
<p>LLMs have been shown to perform well in medical question-answering tasks [<a href="#R9" class="usa-link" aria-describedby="R9">9</a>]. Performance can be further improved by fine-tuning on specific medical datasets [<a href="#R10" class="usa-link" aria-describedby="R10">10</a>], producing models such as Google’s MedPaLM-2. To date, most research in this field has focused on question-answering problems [<a href="#R8" class="usa-link" aria-describedby="R8">8</a>], with use for clinical decision support being a more recent but equally promising area of study [<a href="#R11" class="usa-link" aria-describedby="R11">11</a>].</p>
<p>Beyond text-based tasks, there has been a growing interest in the use of vision-language multimodal LLMs, such as Microsoft’s Large Language and Visual Assistant (LLaVA), which combines a visual encoder with a general LLM to allow it to synthesize both image and text data [<a href="#R12" class="usa-link" aria-describedby="R12">12</a>]. Like text-based LLMs, they can be further fine-tuned with domain-specific knowledge. For instance, LLaVA has been fine-tuned with a large-scale biomedical figure-caption dataset to create the medicine domain–specific Large Language and Vision Assistant for bioMedicine (LLaVA-Med) model [<a href="#R13" class="usa-link" aria-describedby="R13">13</a>]. As opposed to purely text-based interpretation of human-generated ultrasound reports, in which the main time-consuming task is still the radiologist’s report, this can allow seamless or end-to-end image interpretation and classification tasks, offering both time and process improvements in image-based clinical diagnostic tasks.</p>
<p>Many commercial AI apps have been developed to perform image segmentation and risk stratification for thyroid nodules [<a href="#R14" class="usa-link" aria-describedby="R14">14</a>,<a href="#R15" class="usa-link" aria-describedby="R15">15</a>]. However, these typically use traditional machine-learning models, which require extensive training and testing, and are furthermore limited in scope to only a single clinical problem. The use of LLMs offers the possibility of an “out-of-the-box” solution with less development time and expense. One previous approach has combined a distinct visual encoder model developed using classical machine learning methods with a set of commercial LLMs with comparable performance to human evaluators [<a href="#R16" class="usa-link" aria-describedby="R16">16</a>]. However, this approach is computationally demanding and has the risk of information degradation between steps, affecting overall output quality.</p>
<p>More recently, Cabezas et al [<a href="#R17" class="usa-link" aria-describedby="R17">17</a>] performed the first study evaluating OpenAI’s GPT-4 and 4o in performing the same task, but reported suboptimal accuracy, particularly for higher-risk nodules. However, the authors did not attempt optimization of the performance of these models, nor assess the consistency of outputs. LLM output is known to be inherently stochastic, with variability between the outputs. Clearly, a model that produced varying outputs for a single scenario would not be suitable for reliable clinical use. Hence, assessment of consistency is equally important as accuracy in evaluating the performance of such models. Finally, the use of commercial LLMs (such as OpenAI) for these tasks can be hampered by concerns about cost, patient privacy, and data protection. Open-source LLMs can be housed within health care institutions themselves, run with existing compute, and may be an alternative to address these concerns [<a href="#R18" class="usa-link" aria-describedby="R18">18</a>]. Furthermore, they typically have much fewer parameters and are hence less computationally demanding to run.</p>
<p>Therefore, we sought to explore the following objectives. First, to determine the accuracy and consistency of an open-source end-to-end vision-language model in the assessment of thyroid nodules using a standardized risk assessment system (ACR TI-RADS). Second, to study whether fine-tuning on medical domain knowledge improved the performance of the vision-language model for this task. Third, to evaluate whether the vision-language models were able to produce similar output without explicit human-labeled image segmentation. Fourth, to examine the effect of prompt engineering—a simple but effective method for improving the quality of LLM responses [<a href="#R19" class="usa-link" aria-describedby="R19">19</a>]—on the output of the model. Finally, we sought to evaluate the performance of this open-source model against a commercial LLM.</p></section><section id="s2"><h2 class="pmc_sec_title">Methods</h2>
<section id="s2-1"><h3 class="pmc_sec_title">Materials</h3>
<p>In total, 3 different models were evaluated in this study. First, Microsoft’s LLaVA model—which, while being putatively less powerful than other commercial multimodal LLMs [<a href="#R20" class="usa-link" aria-describedby="R20">20</a>], has the advantage of being open-source and can be easily instruction-tuned in a resource-efficient manner for medical domain knowledge [<a href="#R13" class="usa-link" aria-describedby="R13">13</a>]. Instruction tuning is a method of supervised fine-tuning in which models are trained on extant input-output pairs, as opposed to classical fine-tuning, which typically involves training a base model on a dataset of domain-specific parameters [<a href="#R21" class="usa-link" aria-describedby="R21">21</a>]. This instruction-tuned model, known as LLaVA-Med, was used as the second model for the study. The details of the instruction-tuning for LLaVA-Med have been described in the original article by Li et al [<a href="#R13" class="usa-link" aria-describedby="R13">13</a>]. Finally, the final model was the commercial OpenAI o3, which has been described by the company as their “most powerful reasoning model” in production [<a href="#R22" class="usa-link" aria-describedby="R22">22</a>].</p>
<p>Ultrasound cine-clip images, radiologist-annotated segmentations, and ACR TI-RADS descriptors for 192 different thyroid nodules from 167 patients were obtained from the publicly available dataset published by Yamashita et al [<a href="#R23" class="usa-link" aria-describedby="R23">23</a>]. This dataset is comprised of 175 benign and 17 malignant nodules, with an overall mean nodule size of 2.5 (SD 1.4) cm. The nodule characteristics, including breakdown of ACR TI-RADS level in each group, and image acquisition techniques have been described in detail in the original article.</p>
<p>All models were queried with a prompt and individual ultrasound cine-clip images using an action-programming interface. The models were provided with unlabeled images and images labeled with radiologist-annotated regions of interest (ROI) as separate scenarios (<a href="#F1" class="usa-link">Figure 1</a>), for a total of 384 scenarios. As the models are only able to parse static images, only static images were provided, and the full cine-clips of each nodule were not used for this study.</p>
<figure class="fig xbox font-sm" id="F1"><h4 class="obj_head">Figure 1.  (A) Original unlabeled thyroid nodule ultrasound image. (B) Radiologist-annotated region of interest. (C) Composite overlay forming the submitted “labeled” image [<a href="#R23" class="usa-link" aria-describedby="R23">23</a>].</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8689/12364431/c85cb262626e/formative-v9-e70863-g001.jpg" loading="lazy" height="236" width="600" alt="Figure 1."></p>
<div class="p text-right font-secondary"><a href="figure/F1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure></section><section id="s2-2"><h3 class="pmc_sec_title">Data Collection</h3>
<p>The first evaluation used a simple standardized prompt (“Basic Prompt”) detailing the scenario, task, and a summary of the ACR TI-RADS components. To improve the performance and reliability of the output, we repeated the evaluation after prompt engineering (“Modified Prompt”) with the following strategies. First, by contextualizing the task by including the descriptors of each component of the ACR TI-RADS, associated component point scores, and the overall point scores associated with each TI-RADS classification level. Second, by using task decomposition to break down the task into a series of ordered steps, in this case, by instructing the models to score each individual component, add up the sum of components, and finally translate the overall score to a TI-RADS classification level. Third, by constraining the model output into a specific format to minimize the rate of invalid responses. Both the basic and modified prompts are illustrated in <a href="#T1" class="usa-link">Table 1</a>.</p>
<section class="tw xbox font-sm" id="T1"><h4 class="obj_head">Table 1. Basic and modified prompts.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th valign="bottom" rowspan="1" colspan="1">Prompt</th>
<th valign="bottom" rowspan="1" colspan="1">Text</th>
</tr></thead>
<tbody>
<tr>
<td valign="top" rowspan="1" colspan="1">Basic Prompt</td>
<td valign="top" rowspan="1" colspan="1">Assume you are an assistant to a radiologist. This is an ultrasound image of the thyroid. The radiologist would like to know the points for each of the 5 components in Thyroid Imaging Reporting and Data System (TI-RADS) criteria for this image.<br><br>Here are the 5 components:<ul class="list" style="list-style-type:disc">
<li><p>Composition. The point value ranges from 0 to 2</p></li>
<li><p>Echogenicity. The point value ranges from 0 to 3</p></li>
<li><p>Shape. It has only two point values: 0 or 3</p></li>
<li><p>Margin. The point value ranges from 0 to 3</p></li>
<li><p>Echogenic Foci. The point value ranges from 0 to 3</p></li>
</ul>
</td>
</tr>
<tr>
<td valign="top" rowspan="1" colspan="1">Modified Prompt</td>
<td valign="top" rowspan="1" colspan="1">I would like you to assume the role of a radiologist’s assistant. This is an ultrasound image of a thyroid nodule. The radiologist would like to know the points of each of the 5 components of the Thyroid Imaging Reporting and Data System (TI-RADS), the total TI-RADS score, and the TI-RADS classification for this image.<br>The 5 components and their points are as follows:<ul class="list" style="list-style-type:disc">
<li>
<p>Composition (choose one):</p>
<ul class="list" style="list-style-type:disc">
<li><p>Cystic or completely cystic: 0</p></li>
<li><p>Spongiform: 0</p></li>
<li><p>Mixed cystic and solid: 1</p></li>
<li><p>Solid or almost completely solid: 2</p></li>
</ul>
</li>
<li>
<p>Echogenicity (choose one):</p>
<ul class="list" style="list-style-type:disc">
<li><p>Anechoic: 0</p></li>
<li><p>Hyper- or isoechoic: 1</p></li>
<li><p>Hypoechoic: 2</p></li>
<li><p>Very hypoechoic: 3</p></li>
</ul>
</li>
<li>
<p>Shape (choose one):</p>
<ul class="list" style="list-style-type:disc">
<li><p>Wider than tall: 0</p></li>
<li><p>Taller than wide: 3</p></li>
</ul>
</li>
<li>
<p>Margin (choose one):</p>
<ul class="list" style="list-style-type:disc">
<li><p>Smooth: 0</p></li>
<li><p>Ill-defined: 0</p></li>
<li><p>Lobulated/irregular: 2</p></li>
<li><p>Extra-thyroidal extension: 3</p></li>
</ul>
</li>
<li>
<p>Echogenic foci (choose one or more):</p>
<ul class="list" style="list-style-type:disc">
<li><p>None: 0</p></li>
<li><p>Large comet-tail artifact: 0</p></li>
<li><p>Macrocalcifications: 1</p></li>
<li><p>Peripheral/rim calcifications: 2</p></li>
<li><p>Punctate echogenic foci: 3</p></li>
</ul>
</li>
</ul>
<br>Add up the points of each individual component to give the total points.<br><br>Using the total points, the TI-RADS classification is as follows:<ul class="list" style="list-style-type:disc">
<li><p>0 points: TI-RADS 1</p></li>
<li><p>2 points: TI-RADS 2</p></li>
<li><p>3 points: TI-RADS 3</p></li>
<li><p>4 to 6 points: TI-RADS 4</p></li>
<li><p>7 points or more: TI-RADS 5</p></li>
</ul>
<br>Provide your output in the following format:<ul class="list" style="list-style-type:disc">
<li><p>Composition: Single integer</p></li>
<li><p>Echogenicity: Single integer</p></li>
<li><p>Shape: Single integer</p></li>
<li><p>Margin: Single integer</p></li>
<li><p>Echogenic foci: Single integer</p></li>
<li><p>Total points: Single integer</p></li>
<li><p>TI-RADS classification: String</p></li>
</ul>
</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/T1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p>A schematic of the study design is shown in <a href="#F2" class="usa-link">Figure 2</a>. Using each prompt, 3 sets of responses from each model were obtained for each of the 384 scenarios, for a total of 6912 responses. Each response generated by the LLM consisted of 6 components—the 5 individual component scores (composition, echogenicity, shape, margin, and echogenic foci) and the overall TI-RADS classification level. However, as LLMs are known to be poor at basic arithmetic tasks [<a href="#R24" class="usa-link" aria-describedby="R24">24</a>], the study team separately added up the individual component scores manually to derive the overall TI-RADS classification level. While the modified prompt generated an additional seventh item – the sum of the individual component scores – this was designed purely as an intermediary step and was not included in the evaluation. Discrepancies between the LLM-generated and manually-calculated TI-RADS classification level were resolved by selecting the manually-calculated value for the analysis.</p>
<figure class="fig xbox font-sm" id="F2"><h4 class="obj_head">Figure 2. Schematic diagram of study design. LLaVA: Large Language and Visual Assistant; LLaVA-Med: Large Language and Vision Assistant for bioMedicine.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12364431_formative-v9-e70863-g002.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8689/12364431/5f6bd51bf437/formative-v9-e70863-g002.jpg" loading="lazy" height="487" width="777" alt="Figure 2."></a></p>
<div class="p text-right font-secondary"><a href="figure/F2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p>Evaluation using just the overall TI-RADS classification level alone may not be sufficiently robust, as nodules with different imaging characteristics may still derive the same overall classification. Take, for example, 2 nodules, both of which are solid, have regular margins, and are hypoechogenic. The first nodule may be taller than -wide (3 points) without echogenic foci (0 points), while the second nodule may be wider than tall (0 points) with punctate echogenic foci (3 points). However, both would still arrive at the same TI-RADS classification level. Therefore, each item in the response was analyzed individually for accuracy and consistency to demonstrate the models’ performance in evaluating each component of the TI-RADS classification, in addition to the overall TI-RADS classification level.</p></section><section id="s2-3"><h3 class="pmc_sec_title">Statistical Analysis</h3>
<p>Accuracy of output was defined by comparison with the human-rated TI-RADS classification level obtained from the original dataset. Considering the intrinsic variability of human raters [<a href="#R5" class="usa-link" aria-describedby="R5">5</a>,<a href="#R6" class="usa-link" aria-describedby="R6">6</a>], the aggregate output was deemed to be “accurate” if at least 1 of the 3 sets of output was concordant with the human-rated score. This “best-of-three” approach has been proposed as a strategy to mitigate LLM output variability [<a href="#R25" class="usa-link" aria-describedby="R25">25</a>], and has been used in other studies evaluating the clinical performance of LLMs for a variety of medical tasks [<a href="#R26" class="usa-link" aria-describedby="R26">26-29</a>]. Model and human-rated median score distributions were compared in 2 ways. First, it was categorically based on whether the median score underestimated, equaled, or overestimated the TI-RADS classification level. Second, as the score distributions of both model and human-rated scores were determined to be nonparametric using the one-sample Kolmogorov-Smirnov test, they were therefore compared continuously using the Mann-Whitney <em>U</em> Test. Consistency of the output was assessed using 2 measures. First, the output was deemed “consistent” if all 3 sets produced the same result. Second, interrater reliability was compared using Fleiss’ kappa.</p>
<p>Differences in these metrics were analyzed by groups, namely, across all 3 models, unlabeled versus labeled scenarios, and basic prompt versus modified prompt. Differences in proportions were compared using the chi-square test.</p>
<p>Due to inherent model stochasticity, the models occasionally produced inappropriate or uninterpretable responses. Responses with any missing components, or where the output was a noninteger value (for instance, text or letters), were deemed invalid. As the purpose of this study was to evaluate the real-world model output, these invalid responses were still included in the final analyses for accuracy and consistency but were uniformly treated as inaccurate responses. Similarly, missing and noninteger values were still included in the calculation of interrater reliability.</p>
<p>Statistical analysis was conducted using the Python 3.10 environment, with the pandas 2.2.0 package for table processing, scipy 1.13.1 package for statistical analysis, and seaborn 0.13.2 for data visualization.</p></section><section id="s2-4"><h3 class="pmc_sec_title">Ethical Considerations</h3>
<p>As the data used in this study were completely deidentified and freely available in the public domain, no ethical approval was required for this study.</p></section></section><section id="s3"><h2 class="pmc_sec_title">Results</h2>
<section id="s3-1"><h3 class="pmc_sec_title">Overview</h3>
<p>Out of the 6912 generated responses, 6110 (88.4%) were deemed valid. Use of the modified prompt improved the frequency of valid responses slightly from 87.6% to 89.2% (<em>P</em>=.04). The OpenAI o3 model produced the highest proportion of valid responses (2273/2304, 98.6%), followed by the LLaVA model (2108/2304, 91.5%), then the LLaVA-Med model (1729/2304, 75%, <em>P</em>&lt;.001 for overall comparison). Most invalid responses were due to the inability of the LLM to interpret the provided image (“I am unable to view the image itself”). Some invalid responses were also due to the output of noninteger values (for instance, letter values ranging from a-e instead), or hallucinations that caused it to deviate from the assigned task (“In this particular image, the Ultrasound Institute of New York grading scale is used to assess the thyroid nodule”).</p></section><section id="s3-2"><h3 class="pmc_sec_title">Accuracy</h3>
<p>The effect of the various combinations of model, type of prompt, and type of image on the accuracy of output for each component and the overall TI-RADS classification level is visualized as a heatmap in <a href="#F3" class="usa-link">Figure 3</a>. In general, the o3 model had the highest accuracy for most categories except echogenicity and echogenic foci (<a href="#T2" class="usa-link">Table 2</a>). LLaVA-Med appeared to be more accurate than o3 for these 2 categories, although the difference between the 2 models was not significant when compared pairwise (59% vs 54%, <em>P</em>=.06 for echogenicity; 60.7% vs 57.6%, <em>P</em>=.23 for echogenic foci). The best accuracy obtained for overall TI-RADS classification level was still only 57.3%.</p>
<figure class="fig xbox font-sm" id="F3"><h4 class="obj_head">Figure 3. Heatmap showing the distribution of accuracy scores across all combinations of model, prompt, and labeling. LLaVA: Large Language and Visual Assistant.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12364431_formative-v9-e70863-g003.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8689/12364431/eece85d337bb/formative-v9-e70863-g003.jpg" loading="lazy" height="379" width="723" alt="Figure 3."></a></p>
<div class="p text-right font-secondary"><a href="figure/F3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><section class="tw xbox font-sm" id="T2"><h4 class="obj_head">Table 2.  Accuracy of aggregate model output comparing between – Large Language and Vision Assistant, Large Language and Vision Assistant for biomedicine, and o3 models, unlabeled versus labeled scenarios, and base versus modified prompts.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead>
<tr>
<th valign="bottom" rowspan="1" colspan="1">Variable</th>
<th colspan="4" valign="bottom" rowspan="1">Model selection</th>
<th colspan="3" valign="bottom" rowspan="1">Image annotation</th>
<th colspan="3" valign="bottom" rowspan="1">Prompt engineering</th>
</tr>
<tr>
<th valign="top" rowspan="1" colspan="1">TI-RADS<a href="#T2_FN1" class="usa-link"><sup>a</sup></a> component</th>
<th align="left" valign="top" rowspan="1" colspan="1">LLaVA<a href="#T2_FN2" class="usa-link"><sup>b</sup></a>
</th>
<th align="left" valign="top" rowspan="1" colspan="1">LLaVA-Med<a href="#T2_FN3" class="usa-link"><sup>c</sup></a>
</th>
<th align="left" valign="top" rowspan="1" colspan="1">GPT-o3</th>
<th align="left" valign="top" rowspan="1" colspan="1">
<em>P</em> value</th>
<th align="left" valign="top" rowspan="1" colspan="1">Unlabeled</th>
<th align="left" valign="top" rowspan="1" colspan="1">Labeled</th>
<th align="left" valign="top" rowspan="1" colspan="1">
<em>P</em> value</th>
<th align="left" valign="top" rowspan="1" colspan="1">Basic</th>
<th align="left" valign="top" rowspan="1" colspan="1">Modified</th>
<th align="left" valign="top" rowspan="1" colspan="1">
<em>P</em> value</th>
</tr>
</thead>
<tbody>
<tr>
<td valign="top" rowspan="1" colspan="1">Composition</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.10</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.53</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.85</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.49</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.50</td>
<td align="left" valign="top" rowspan="1" colspan="1">.71</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.42</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.56</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
</tr>
<tr>
<td valign="top" rowspan="1" colspan="1">Echogenicity</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.48</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.59</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.54</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.54</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.54</td>
<td align="left" valign="top" rowspan="1" colspan="1">.90</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.52</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.55</td>
<td align="left" valign="top" rowspan="1" colspan="1">.12</td>
</tr>
<tr>
<td valign="top" rowspan="1" colspan="1">Shape</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.50</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.62</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.90</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.67</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.68</td>
<td align="left" valign="top" rowspan="1" colspan="1">.53</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.85</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.50</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
</tr>
<tr>
<td valign="top" rowspan="1" colspan="1">Margin</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.45</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.66</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.84</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.64</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.67</td>
<td align="left" valign="top" rowspan="1" colspan="1">.12</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.80</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.50</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
</tr>
<tr>
<td valign="top" rowspan="1" colspan="1">Echogenic Foci</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.53</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.61</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.58</td>
<td align="left" valign="top" rowspan="1" colspan="1">.01</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.58</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.56</td>
<td align="left" valign="top" rowspan="1" colspan="1">.27</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.58</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.57</td>
<td align="left" valign="top" rowspan="1" colspan="1">.67</td>
</tr>
<tr>
<td valign="top" rowspan="1" colspan="1">Overall TI-RADS<a href="#T2_FN1" class="usa-link"><sup>a</sup></a> classification level</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.36</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.35</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.56</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.43</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.42</td>
<td align="left" valign="top" rowspan="1" colspan="1">.47</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.45</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.40</td>
<td align="left" valign="top" rowspan="1" colspan="1">.01</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/T2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p">
<div class="fn" id="T2_FN1">
<sup>a</sup><p class="display-inline">TI-RADS: Thyroid Imaging Reporting and Data System.</p>
</div>
<div class="fn" id="T2_FN2">
<sup>b</sup><p class="display-inline">LLaVA: Large Language and Vision Assistant.</p>
</div>
<div class="fn" id="T2_FN3">
<sup>c</sup><p class="display-inline">LLaVA-Med: Large Language and Vision Assistant for bioMedicine.</p>
</div>
</div></section><p>There was no one best combination of input variables in determining overall accuracy, with different combinations yielding the highest accuracy scores for each component as well as the overall TI-RADS classification level. Interestingly, the basic LLaVA model without prompt engineering or nodule annotation achieved the closest overall accuracy to the worst-performing combination using o3 (44.8% v 54.2%, respectively), despite very poor accuracy for composition and echogenicity.</p>
<p>When combining the output of all 3 models, the use of labeled (radiologist-annotated) images instead of unlabeled images (<a href="#T2" class="usa-link">Table 2</a>) did not make a significant difference to the accuracy of all component scores, nor the overall TI-RADS classification. However, secondary analysis done with output from just the LLaVA and LLaVA-Med models showed that there was a significant improvement in accuracy for margin classification from 53% to 58.2% (<em>P</em>=.04).</p>
<p>Use of the modified prompt as compared with the basic prompt (<a href="#T2" class="usa-link">Table 2</a>) significantly improved accuracy in classifying nodule composition (56.3% vs 41.9%, <em>P</em>&lt;.001). However, there was worse accuracy in classifying nodule shape (49.6% vs 84.9%, <em>P</em>&lt;.001) and margins (0.5% vs 80.3%, <em>P</em>&lt;.001). Accuracy for the overall TI-RADS classification level was also worse (45% vs 39.8%, <em>P</em>=.01) using the modified prompt. There was no significant difference in the accuracy of classifying echogenicity and echogenic foci using either prompt.</p>
<p>There were no significant differences in median score distributions between the model output and human raters. However, when evaluated categorically, all 3 models appeared to consistently overestimate the scores for echogenicity and underestimate echogenic foci (<a href="#SAP1" class="usa-link">Multimedia Appendix 1</a>).</p></section><section id="s3-3"><h3 class="pmc_sec_title">Consistency</h3>
<p>The effect of the various combinations of model, type of prompt, and type of image on the consistency of output for each component and the overall TI-RADS classification level is visualized as a heatmap in <a href="#F4" class="usa-link">Figure 4</a>. The consistency of both o3 and LLaVA models was largely comparable across all categories except that of margins (80% vs 54.6% respectively, <em>P</em>&lt;.001), while that of LLaVA-Med was significantly poorer than both across all categories (<a href="#T3" class="usa-link">Table 3</a>). The highest overall consistency of 85.4% was obtained from the combination of the o3 model with prompt engineering and annotated images.</p>
<figure class="fig xbox font-sm" id="F4"><h4 class="obj_head">Figure 4. Heatmap showing the distribution of accuracy scores across all combinations of model, prompt, and labeling. LLaVA: Large Language and Visual Assistant.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12364431_formative-v9-e70863-g004.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8689/12364431/1c929537c863/formative-v9-e70863-g004.jpg" loading="lazy" height="379" width="723" alt="Figure 4."></a></p>
<div class="p text-right font-secondary"><a href="figure/F4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><section class="tw xbox font-sm" id="T3"><h4 class="obj_head">Table 3. Consistency of aggregate model output comparing between – Large Language and Vision Assistant, Large Language and Vision Assistant for biomedicine, and o3 models, unlabeled versus labeled scenarios, and base versus modified prompts.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead>
<tr>
<th valign="bottom" rowspan="1" colspan="1">Variable</th>
<th colspan="4" valign="bottom" rowspan="1">Model selection</th>
<th colspan="3" valign="bottom" rowspan="1">Image annotation</th>
<th colspan="3" valign="bottom" rowspan="1">Prompt engineering</th>
</tr>
<tr>
<th valign="top" rowspan="1" colspan="1">TI-RADS<a href="#T3_FN1" class="usa-link"><sup>a</sup></a> component</th>
<th align="left" valign="top" rowspan="1" colspan="1">LLaVA<a href="#T3_FN2" class="usa-link"><sup>b</sup></a>
</th>
<th align="left" valign="top" rowspan="1" colspan="1">LLaVA-Med<a href="#T3_FN3" class="usa-link"><sup>c</sup></a>
</th>
<th align="left" valign="top" rowspan="1" colspan="1">GPT-o3</th>
<th align="left" valign="top" rowspan="1" colspan="1">
<em>P</em> value</th>
<th align="left" valign="top" rowspan="1" colspan="1">Unlabeled</th>
<th align="left" valign="top" rowspan="1" colspan="1">Labeled</th>
<th align="left" valign="top" rowspan="1" colspan="1">
<em>P</em> value</th>
<th align="left" valign="top" rowspan="1" colspan="1">Basic</th>
<th align="left" valign="top" rowspan="1" colspan="1">Modified</th>
<th align="left" valign="top" rowspan="1" colspan="1">
<em>P</em> value</th>
</tr>
</thead>
<tbody>
<tr>
<td valign="top" rowspan="1" colspan="1">Composition</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.85</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.10</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.82</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.56</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.62</td>
<td align="left" valign="top" rowspan="1" colspan="1">.001</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.62</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.56</td>
<td align="left" valign="top" rowspan="1" colspan="1">.008</td>
</tr>
<tr>
<td valign="top" rowspan="1" colspan="1">Echogenicity</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.88</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.10</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.80</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.56</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.63</td>
<td align="left" valign="top" rowspan="1" colspan="1">.003</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.61</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.58</td>
<td align="left" valign="top" rowspan="1" colspan="1">.29</td>
</tr>
<tr>
<td valign="top" rowspan="1" colspan="1">Shape</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.88</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.10</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.93</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.62</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.65</td>
<td align="left" valign="top" rowspan="1" colspan="1">.14</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.65</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.63</td>
<td align="left" valign="top" rowspan="1" colspan="1">.39</td>
</tr>
<tr>
<td valign="top" rowspan="1" colspan="1">Margin</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.55</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.10</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.80</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.46</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.50</td>
<td align="left" valign="top" rowspan="1" colspan="1">.03</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.39</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.58</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
</tr>
<tr>
<td valign="top" rowspan="1" colspan="1">Echogenic foci</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.88</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.07</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.88</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.60</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.62</td>
<td align="left" valign="top" rowspan="1" colspan="1">.22</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.59</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.63</td>
<td align="left" valign="top" rowspan="1" colspan="1">.04</td>
</tr>
<tr>
<td valign="top" rowspan="1" colspan="1">Overall TI-RADS<a href="#T3_FN1" class="usa-link"><sup>a</sup></a> classification level</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.52</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.27</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.65</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.44</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.52</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.36</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.60</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/T3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p">
<div class="fn" id="T3_FN1">
<sup>a</sup><p class="display-inline">TI-RADS: Thyroid Imaging Reporting and Data System.</p>
</div>
<div class="fn" id="T3_FN2">
<sup>b</sup><p class="display-inline">LLaVA: Large Language and Vision Assistant.</p>
</div>
<div class="fn" id="T3_FN3">
<sup>c</sup><p class="display-inline">LLaVA-Med: Large Language and Vision Assistant for bioMedicine.</p>
</div>
</div></section><p>When combining the output of all 3 models, use of labeled images instead of unlabeled images improved consistency of outputs for composition (62.3% vs 55.6%, <em>P</em>=.001), echogenicity (62.6% vs 56.3%, <em>P</em>=.003), margins (50.3% vs 45.7%, <em>P</em>=.03), and overall TI-RADS classification level (52% vs 43.8%, <em>P</em>&lt;.001). There was no significant difference in consistency of outputs for shape and echogenic foci (<a href="#T3" class="usa-link">Table 3</a>).</p>
<p>Surprisingly, there was a mixed effect from use of the modified prompt as compared with the basic prompt (<a href="#T3" class="usa-link">Table 3</a>), with poorer consistency for composition (56.2% vs 61.7%, <em>P</em>=.008), but higher consistency for margins (57.5% vs 38.5%, <em>P</em>&lt;.001), echogenic foci (62.9% vs 58.6%, <em>P</em>=.04), and overall TI-RADS classification level (59.5% vs 36%, <em>P</em>&lt;.001). There was no significant difference between the type of prompt used for the consistency of rating echogenicity or shape.</p>
<p>Due to the relatively high frequency of invalid responses, interrater reliability was poor across all combinations of input variables, ranging between −0.15 and 0.49. No combination achieved a Fleiss’ Kappa above 0.60.</p></section><section id="s3-4"><h3 class="pmc_sec_title">Subgroup Analysis</h3>
<p>As the o3 model appeared to perform the best for accuracy as well as consistency, subgroup analysis was performed on output from just the o3 model alone. Neither prompt engineering nor image labeling appeared to affect the accuracy of the output from o3 across all categories and for the overall TI-RADS classification level (<a href="#T4" class="usa-link">Table 4</a>).</p>
<section class="tw xbox font-sm" id="T4"><h4 class="obj_head">Table 4. Accuracy and consistency of aggregate o3 model output comparing unlabeled versus labeled scenarios, and base versus modified prompts.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead>
<tr>
<th valign="bottom" rowspan="1" colspan="1">Metric</th>
<th colspan="6" valign="bottom" rowspan="1">Accuracy</th>
<th colspan="6" valign="bottom" rowspan="1">Consistency</th>
</tr>
<tr>
<th valign="top" rowspan="1" colspan="1">Variable</th>
<th colspan="3" align="left" valign="top" rowspan="1">Image annotation</th>
<th colspan="3" align="left" valign="top" rowspan="1">Prompt engineering</th>
<th colspan="3" align="left" valign="top" rowspan="1">Image annotation</th>
<th colspan="3" align="left" valign="top" rowspan="1">Prompt engineering</th>
</tr>
<tr>
<th valign="top" rowspan="1" colspan="1">TI-RADS<a href="#T4_FN1" class="usa-link"><sup>a</sup></a> component</th>
<th align="left" valign="top" rowspan="1" colspan="1">Unlabeled</th>
<th align="left" valign="top" rowspan="1" colspan="1">Labeled</th>
<th align="left" valign="top" rowspan="1" colspan="1">
<em>P</em> value</th>
<th align="left" valign="top" rowspan="1" colspan="1">Basic</th>
<th align="left" valign="top" rowspan="1" colspan="1">Modified</th>
<th align="left" valign="top" rowspan="1" colspan="1">
<em>P</em> value</th>
<th align="left" valign="top" rowspan="1" colspan="1">Unlabeled</th>
<th align="left" valign="top" rowspan="1" colspan="1">Labeled</th>
<th align="left" valign="top" rowspan="1" colspan="1">
<em>P</em> value</th>
<th align="left" valign="top" rowspan="1" colspan="1">Basic</th>
<th align="left" valign="top" rowspan="1" colspan="1">Modified</th>
<th align="left" valign="top" rowspan="1" colspan="1">
<em>P</em> value</th>
</tr>
</thead>
<tbody>
<tr>
<td valign="top" rowspan="1" colspan="1">Composition</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.84</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.87</td>
<td align="left" valign="top" rowspan="1" colspan="1">.31</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.85</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.85</td>
<td align="left" valign="top" rowspan="1" colspan="1">≥.99</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.76</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.89</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.79</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.85</td>
<td align="left" valign="top" rowspan="1" colspan="1">.04</td>
</tr>
<tr>
<td valign="top" rowspan="1" colspan="1">Echogenicity</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.54</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.54</td>
<td align="left" valign="top" rowspan="1" colspan="1">.89</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.57</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.52</td>
<td align="left" valign="top" rowspan="1" colspan="1">.19</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.75</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.85</td>
<td align="left" valign="top" rowspan="1" colspan="1">.001</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.72</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.88</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
</tr>
<tr>
<td valign="top" rowspan="1" colspan="1">Shape</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.90</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.90</td>
<td align="left" valign="top" rowspan="1" colspan="1">≥.99</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.90</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.90</td>
<td align="left" valign="top" rowspan="1" colspan="1">≥.99</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.92</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.94</td>
<td align="left" valign="top" rowspan="1" colspan="1">.39</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.90</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.97</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
</tr>
<tr>
<td valign="top" rowspan="1" colspan="1">Margin</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.85</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.84</td>
<td align="left" valign="top" rowspan="1" colspan="1">.84</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.85</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.84</td>
<td align="left" valign="top" rowspan="1" colspan="1">.69</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.74</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.86</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.55</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.75</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
</tr>
<tr>
<td valign="top" rowspan="1" colspan="1">Echogenic foci</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.59</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.57</td>
<td align="left" valign="top" rowspan="1" colspan="1">.61</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.57</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.58</td>
<td align="left" valign="top" rowspan="1" colspan="1">.94</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.86</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.90</td>
<td align="left" valign="top" rowspan="1" colspan="1">.10</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.84</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.92</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
</tr>
<tr>
<td valign="top" rowspan="1" colspan="1">Overall TI-RADS<a href="#T4_FN1" class="usa-link"><sup>a</sup></a> classification level</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.56</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.53</td>
<td align="left" valign="top" rowspan="1" colspan="1">.47</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.57</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.52</td>
<td align="left" valign="top" rowspan="1" colspan="1">.15</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.57</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.73</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.55</td>
<td align="left" valign="top" rowspan="1" colspan="1">0.75</td>
<td align="left" valign="top" rowspan="1" colspan="1">&lt;.001</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/T4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="T4_FN1">
<sup>a</sup><p class="display-inline">TI-RADS: Thyroid Imaging Reporting and Data System.</p>
</div></div></section><p>Significant differences were, however, still observed for consistency. Use of the modified prompt instead of the basic prompt improved consistency across all categories for echogenicity (85.4% vs 79.4%, <em>P</em>=.04), echogenicity (88.3% vs 71.9%, <em>P</em>&lt;.001), shape (97.1% vs 89.6%, <em>P</em>&lt;.001), margins (83.3% vs 76.6%, <em>P</em>=.02), echogenic foci (91.9% vs 83.6%, <em>P</em>&lt;.001), and overall TI-RADS classification level (74.5% vs 54.9%, <em>P</em>&lt;.001). Use of labeled images instead of unlabeled images improved consistency for composition (88.8% vs 76%, <em>P</em>&lt;.001), echogenicity (85.2% vs 75%, <em>P</em>=.001), margins (86.2% vs 73.7%, <em>P</em>&lt;.001), and overall TI-RADS classification level (72.7% vs 56.8%, <em>P</em>&lt;.001), but did not make a difference for shape and echogenic foci. These findings are illustrated in <a href="#T4" class="usa-link">Table 4</a>.</p></section></section><section id="s4"><h2 class="pmc_sec_title">Discussion</h2>
<section id="s4-1"><h3 class="pmc_sec_title">Principal Findings</h3>
<p>To our knowledge, this is the first study to evaluate the use of an open-source multimodal vision-language model alongside a commercial multimodal LLM for the end-to-end risk stratification of thyroid nodules. Furthermore, this is also the first study to consider the important parameter of inter-output variability in assessing model performance for thyroid nodule assessment.</p>
<p>We believe our evaluation of both an open-source smaller model and a more powerful commercial model is important, as it provides a helpful guide for model selection for future development of clinically deployable apps. The putatively most powerful model may not always be the most suitable for a given task, due to reasons of cost, data privacy protection, or compute access. For instance, OpenAI o3 has a token cost of US $10 per 1 million input tokens and US $40 per 1 million output tokens. We consumed a total of 2.79 million input and 1.75 million output tokens to generate the 2304 outputs for this study, incurring a total cost of approximately US $98. By contrast, the LLaVA and LLaVA-Med models were run off a single GPU with no cost beyond the marginal cost of utilities. Furthermore, we were unable to test real-world clinical images on the commercial LLM in this study as our national data privacy regulations prevent us from sharing patient-derived data outside the secure health care computing environment, even if fully anonymized, whereas the LLaVA and LLaVA-Med models could potentially be run using existing hardware within our secure environment.</p>
<p>Use of an end-to-end vision-language model is likely to be more efficient and translatable to other clinical tasks as compared with traditional machine learning predictive models. However, while the newer, more powerful commercial model outperformed the older, smaller open-source model on most metrics of assessment, even the best model output was suboptimal despite optimization. We offer some suggestions for why this may be the case.</p>
<p>First, input of image data directly into a vision-language model can be technically challenging. Modern medical imaging is typically high-resolution and therefore feature-rich. However, current-generation multimodal LLMs struggle with visual identification when feature counts are high [<a href="#R30" class="usa-link" aria-describedby="R30">30</a>], with a consequent detrimental impact on performance. Even classical machine learning models perform optimally at lower image resolutions [<a href="#R31" class="usa-link" aria-describedby="R31">31</a>]. Conceptually, the assessment of thyroid nodule composition, echogenicity, and the presence of echogenic foci requires the ability to segment the nodule into multiple ROIs, and thereafter, differentiate between the characteristics of each ROI. For instance, to determine if a nodule is part-solid, a human evaluator would first distinguish that multiple areas of acoustic impedance exist within the nodule, then determine that some are more echogenic than others. Similarly, determination of hyper- or hypoechogenicity requires comparison with normal thyroid parenchyma. As this requires the processing of many features, it is perhaps unsurprising that model accuracy was generally poor for these components. Conversely, when evaluating shape or margins, the nodule can be treated as a whole ROI, which may have been why model accuracy was generally higher for these components. In addition, the different models in this study process images differently. LLaVA [<a href="#R12" class="usa-link" aria-describedby="R12">12</a>] and LLaVA-Med [<a href="#R13" class="usa-link" aria-describedby="R13">13</a>] tokenize images based on fixed token counts for image area before input into the LLM, whereas o3 can process images dynamically using a unified encoder [<a href="#R32" class="usa-link" aria-describedby="R32">32</a>]. This may explain in part the improved (but still suboptimal) accuracy of o3 for echogenicity and echogenic foci.</p>
<p>Second, vision-language models have reduced sensitivity to black-white contrast and have difficulty distinguishing between black and noise [<a href="#R30" class="usa-link" aria-describedby="R30">30</a>]. This is a limitation particularly relevant to ultrasound imaging, where regions that appear black can be anechoic or reflect the presence of acoustic shadowing. Distinguishing these can have a significant difference in the evaluation of thyroid nodules, as anechoic nodules are characterized as cystic and require no further evaluation, but acoustic shadowing typically signifies significant calcification, which is a risk feature for malignancy. An example of this is illustrated in <a href="#F5" class="usa-link">Figure 5</a>. In addition, nodule margins are typically recognized by differences in voxel density, which the models may struggle with if differences are small, and therefore use of images with human-annotated margins improved the classification of nodule margins for the LLaVA and LLaVA-Med models and consistency for all 3 models. An example of this is similarly demonstrated in <a href="#F6" class="usa-link">Figure 6</a>.</p>
<figure class="fig xbox font-sm" id="F5"><h4 class="obj_head">Figure 5. Ultrasound image from case 3 in the original dataset, showing a nodule with partial rim calcifications and consequent posterior acoustic shadowing (red circles). The nodule composition was erroneously classified as cystic (0 points) or mixed solid and cystic (1 point) in 19 out of 24 outputs, as opposed to almost completely solid (2 points) by the human rater.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8689/12364431/3211aea46e1a/formative-v9-e70863-g005.jpg" loading="lazy" height="835" width="628" alt="Figure 5."></p>
<div class="p text-right font-secondary"><a href="figure/F5/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><figure class="fig xbox font-sm" id="F6"><h4 class="obj_head">Figure 6. Unlabeled (left) and labeled (right) images from Case 132 in the original dataset. In total, 10 out of 12 outputs, using the unlabeled image, overestimated the nodule margins as irregular (2 points), while 6 out of 12 outputs using the labeled image overestimated the nodule margins as irregular (2 points). The human rater classified the nodule margin as ill-defined (0 points).</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/8689/12364431/51ec9e0bba30/formative-v9-e70863-g006.jpg" loading="lazy" height="318" width="786" alt="Figure 6."></p>
<div class="p text-right font-secondary"><a href="figure/F6/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p>Intuitively, fine-tuning a general LLM with medical domain–specific knowledge should improve its performance for medical-specific tasks [<a href="#R33" class="usa-link" aria-describedby="R33">33</a>]. However, the nature of the data used for fine-tuning matters. LLaVA-Med did appear to have higher accuracy than LLaVA for all TI-RADS components evaluated in this study. Despite this, it was not more accurate than LLaVA in determining the overall TI-RADS classification level. To explain this, we noted that ultrasound images were not included in the LLaVA-Med fine-tuning figure-caption dataset. Furthermore, fine-tuning may have led to the poorer LLaVA-Med model consistency observed, as it would have been forced to sample from a probability distribution more skewed toward information irrelevant to its task and therefore produce a wider range of responses as a result.</p>
<p>Finally, prompt engineering significantly improved the consistency of output across all categories, including the overall TI-RADS classification level. This improvement was consistently observed regardless of the model used. This suggests that prompt engineering can still be a useful technique to optimize the output of “higher-performance” current-generation commercial models and should still be considered as a simple optimization technique in studies performed using these models.</p>
<p>However, prompt engineering had a mixed effect on accuracy. Furthermore, in the subgroup analysis on o3 output alone, there was no difference in accuracy, suggesting that the main effect of prompt engineering on accuracy was only seen in the open-source models. Prompt engineering in text-only LLMs can be highly effective as the text prompt is the only determinant of the output [<a href="#R34" class="usa-link" aria-describedby="R34">34</a>]. In this case, the main limiting step in accuracy was likely not the knowledge of the individual categories of the TI-RADS classification system, but the knowledge of what the categories meant. To illustrate this, a human trainee looking at a thyroid nodule image for the first time would not be expected to know the meaning of “hyperechogenic” or “hypoechogenic.” He or she could refer to sample images showing the differences between these and extrapolate these observations to classify other nodules. Similarly, it might be unrealistic to expect the base vision-language model to intrinsically understand and translate the meaning of these classifiers.</p>
<p>Conversely, as O3 has a parameter count that is likely a few orders of magnitude higher than that of the open-source model (exact count not disclosed by OpenAI), it is conceivable that this “knowledge” is part of its pretraining set, hence also contributing to the better performance. Expanding on that hypothesis, a possible approach to further improve the output of smaller models could be to use few-shot prompting to provide it with the requisite examples to assist in subsequent classification. However, there are 19 different classifiers across the 5 TI-RADS components, and providing 19 example images in every prompt is costly and inefficient. Further work is required to explore the development of more efficient techniques of few-shot prompting to improve model performance for visual classification tasks, particularly for complex risk scores like this one.</p>
<p>This study has some limitations. LLM output is stochastic, or random, due to the inherent randomness of sampling techniques (such as top-k or nucleus sampling) used to derive the output. Stochasticity of output can be controlled by setting the “temperature” of the model, which is a measure ranging from 0 to 1 with 0 representing the least stochastic and 1 representing the most stochastic output ranges. We did not vary the base temperature in this study, as part of the objective was to measure the intrinsic model consistency. Using a low-to-zero temperature in future approaches is likely to improve consistency and consequently reproducibility of results.</p>
<p>Furthermore, the models used were only able to parse static images and not cine-clip images. It is arguable that certain features, such as punctate echogenic foci, are better appreciated on cine-clip images. However, real-world radiologists still appear to perform more consistently on static images rather than cine-clip images [<a href="#R35" class="usa-link" aria-describedby="R35">35</a>]. Therefore, the extent to which this limitation affects performance is unclear and should be evaluated further in other studies.</p>
<p>Next, the use of AI in health care is desirable because it may help to improve automation and productivity. Human calculations were still required in some cases in this study, which may have inflated the performance of the LLM. Rather than relying on the LLM alone to perform calculations, providing simple arithmetic tools to the LLM in an agentic framework may be an alternative solution to overcome this limitation.</p>
<p>Furthermore, human labeling was still used as an optimization strategy in this study. However, recent studies have explored the combination of LLM-generated prompts with a vision foundation model to perform zero-shot image segmentation, such as in the text-visual-prompt segment anything model (TV-SAM) algorithm incorporating GPT-4, the grounded language-imaging pre-training model, and the segment anything vision language model [<a href="#R36" class="usa-link" aria-describedby="R36">36</a>]. Image segmentation using such an algorithm, followed by interpretation of the segmented image with a classical multimodal LLM, may be a promising way to deliver a truly integrated end-to-end automated workflow in clinical practice and merits further exploration.</p>
<p>In addition, the test set used for evaluation in this study was from a single open-source dataset, which had a class imbalance between benign and malignant nodules (175 vs. 17, respectively). While this approximates the real-life distribution of thyroid nodules, whereby the vast majority are benign, it is possible that model performance on malignant cases may have been underpowered. Exploring these factors is beyond the scope of this exploratory study. This should be evaluated further in follow-on studies, which can also explore the generalizability to other datasets.</p>
<p>Finally, explainability (or the lack thereof) is a frequent criticism of end-to-end machine learning solutions, particularly in medicine, where safety and generalizability are concerns [<a href="#R8" class="usa-link" aria-describedby="R8">8</a>]. One method to improve explainability is to ask the LLM for explanations of how its output was derived [<a href="#R37" class="usa-link" aria-describedby="R37">37</a>]. We did not address this in our study as it was felt to be a moot point since overall performance was suboptimal.</p>
<p>LLMs are unique AI models because they are generally trained and can be easily repurposed for a variety of similar tasks. The major limitation for use in ultrasound image classification at present is in image processing and encoding, which can potentially be improved by relevant fine-tuning and improving feature extraction. This offers an alternative to resource-intensive model-building or fine-tuning and potentially retains flexibility for application in other imaging classification tasks. By addressing these limitations, we believe that computer-vision–assisted LLMs may eventually have the potential to augment human vision for visual-based classification tasks in medicine.</p></section><section id="s4-2"><h3 class="pmc_sec_title">Conclusions</h3>
<p>With the rapidly evolving nature of the field of AI and LLMs in health care, we believe that no one fixed model can be expected to balance all the competing demands of performance, cost, deployability, and security. The findings from this study highlight the potential benefits of simple processes, such as prompt engineering and basic image preprocessing, to model performance. We further demonstrate that some of these techniques remain applicable even with the release of new, more powerful models. Overall, we believe the findings from this study provide formative insights for developers and researchers for further work in this area.</p></section></section><section id="s5"><h2 class="pmc_sec_title">Supplementary material</h2>
<section class="sm xbox font-sm" id="SAP1"><div class="caption p"><span>Multimedia Appendix 1. Categorical comparison of median model-generated scores against human-rated scores for each of the TI-RADS components and the overall TI-RADS classification. (A) Output from LLaVA and LLaVA-Med. (B) Output from OpenAI o3. (C) Output from all three models combined.</span></div>
<div class="media p" id="d67e1450">
<div class="caption">
<a href="/articles/instance/12364431/bin/formative-v9-e70863-s001.png" data-ga-action="click_feat_suppl" class="usa-link">formative-v9-e70863-s001.png</a><sup> (49.8KB, png) </sup>
</div>
<div class="object-id font-xs text-base-dark">DOI: 10.2196/70863</div>
</div></section></section><section id="ack1" class="ack"><h2 class="pmc_sec_title">Acknowledgments</h2>
<p>This project is supported by Singhealth Duke-NUS AMC under the Clinical &amp; Systems Innovation (Main) Grant (grant 03/FY2024/P2/03-A125).</p></section><section id="notes1"><h3>Abbreviations</h3>
<dl class="def-list">
<dt>ACR TI-RADS</dt>
<dd><p>American College of Radiology Thyroid Imaging Reporting and Data System</p></dd>
<dt>AI</dt>
<dd><p>artificial intelligence</p></dd>
<dt>LLaVA</dt>
<dd><p>Large Language and Visual Assistant</p></dd>
<dt>LLaVA-Med</dt>
<dd><p>Large Language and Vision Assistant for bioMedicine</p></dd>
<dt>LLM</dt>
<dd><p>large language model</p></dd>
<dt>ROI</dt>
<dd><p>regions of interest</p></dd>
<dt>TI-RADS</dt>
<dd><p>Thyroid Imaging Reporting and Data System</p></dd>
</dl></section><section id="fn-group1" class="fn-group"><h2 class="pmc_sec_title">Footnotes</h2>
<div class="fn-group p font-secondary-light font-sm">
<div class="fn p" id="fn9"><p><strong>Authors’ Contributions:</strong> The authors confirm contribution to the paper as follows. Study conception and design were contributed by GGRS, TJH, and CCL. Data collection was contributed by XY. Analysis and interpretation of results was contributed by XY, GGRS, DYZL, and JYMT. Draft manuscript preparation was managed by GGRS. Reviewing manuscript was handled by XY, DYZL, JYMT, TJH, and CCL. All authors reviewed the results and approved the final version of the manuscript.</p></div>
<div class="fn p" id="fn10"><p><strong>Conflicts of Interest:</strong> None declared.</p></div>
</div></section><section id="ref-list1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="ref-list1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="R1">
<span class="label">1.</span><cite>Dean DS, Gharib H. Epidemiology of thyroid nodules. Best Pract Res Clin Endocrinol Metab. 2008 Dec;22(6):901–911. doi: 10.1016/j.beem.2008.09.019. doi. Medline.</cite> [<a href="https://doi.org/10.1016/j.beem.2008.09.019" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/19041821/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Best%20Pract%20Res%20Clin%20Endocrinol%20Metab&amp;title=Epidemiology%20of%20thyroid%20nodules&amp;author=DS%20Dean&amp;author=H%20Gharib&amp;volume=22&amp;issue=6&amp;publication_year=2008&amp;pages=901-911&amp;pmid=19041821&amp;doi=10.1016/j.beem.2008.09.019&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R2">
<span class="label">2.</span><cite>Lee JY, Baek JH, Ha EJ, et al.  2020 imaging guidelines for thyroid nodules and differentiated thyroid cancer: Korean Society of Thyroid Radiology. Korean J Radiol. 2021 May;22(5):840–860. doi: 10.3348/kjr.2020.0578. doi. Medline.</cite> [<a href="https://doi.org/10.3348/kjr.2020.0578" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8076832/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33660459/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Korean%20J%20Radiol&amp;title=2020%20imaging%20guidelines%20for%20thyroid%20nodules%20and%20differentiated%20thyroid%20cancer:%20Korean%20Society%20of%20Thyroid%20Radiology&amp;author=JY%20Lee&amp;author=JH%20Baek&amp;author=EJ%20Ha&amp;volume=22&amp;issue=5&amp;publication_year=2021&amp;pages=840-860&amp;pmid=33660459&amp;doi=10.3348/kjr.2020.0578&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R3">
<span class="label">3.</span><cite>Haugen BR, Alexander EK, Bible KC, et al.  2015 American Thyroid Association management guidelines for adult patients with thyroid nodules and differentiated thyroid cancer: The American Thyroid Association Guidelines Task Force on thyroid nodules and differentiated thyroid cancer. Thyroid. 2016 Jan;26(1):1–133. doi: 10.1089/thy.2015.0020. doi. Medline.</cite> [<a href="https://doi.org/10.1089/thy.2015.0020" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4739132/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/26462967/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Thyroid&amp;title=2015%20American%20Thyroid%20Association%20management%20guidelines%20for%20adult%20patients%20with%20thyroid%20nodules%20and%20differentiated%20thyroid%20cancer:%20The%20American%20Thyroid%20Association%20Guidelines%20Task%20Force%20on%20thyroid%20nodules%20and%20differentiated%20thyroid%20cancer&amp;author=BR%20Haugen&amp;author=EK%20Alexander&amp;author=KC%20Bible&amp;volume=26&amp;issue=1&amp;publication_year=2016&amp;pages=1-133&amp;pmid=26462967&amp;doi=10.1089/thy.2015.0020&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R4">
<span class="label">4.</span><cite>Tessler FN, Middleton WD, Grant EG, et al.  ACR Thyroid Imaging, Reporting and Data System (TI-RADS): White Paper of the ACR TI-RADS Committee. J Am Coll Radiol. 2017 May;14(5):587–595. doi: 10.1016/j.jacr.2017.01.046. doi. Medline.</cite> [<a href="https://doi.org/10.1016/j.jacr.2017.01.046" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/28372962/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Am%20Coll%20Radiol&amp;title=ACR%20Thyroid%20Imaging,%20Reporting%20and%20Data%20System%20(TI-RADS):%20White%20Paper%20of%20the%20ACR%20TI-RADS%20Committee&amp;author=FN%20Tessler&amp;author=WD%20Middleton&amp;author=EG%20Grant&amp;volume=14&amp;issue=5&amp;publication_year=2017&amp;pages=587-595&amp;pmid=28372962&amp;doi=10.1016/j.jacr.2017.01.046&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R5">
<span class="label">5.</span><cite>Hoang JK, Middleton WD, Farjat AE, et al.  Interobserver variability of sonographic features used in the American College of Radiology Thyroid Imaging Reporting and Data System. AJR Am J Roentgenol. 2018 Jul;211(1):162–167. doi: 10.2214/AJR.17.19192. doi. Medline.</cite> [<a href="https://doi.org/10.2214/AJR.17.19192" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/29702015/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=AJR%20Am%20J%20Roentgenol&amp;title=Interobserver%20variability%20of%20sonographic%20features%20used%20in%20the%20American%20College%20of%20Radiology%20Thyroid%20Imaging%20Reporting%20and%20Data%20System&amp;author=JK%20Hoang&amp;author=WD%20Middleton&amp;author=AE%20Farjat&amp;volume=211&amp;issue=1&amp;publication_year=2018&amp;pages=162-167&amp;pmid=29702015&amp;doi=10.2214/AJR.17.19192&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R6">
<span class="label">6.</span><cite>Grani G, Lamartina L, Cantisani V, Maranghi M, Lucia P, Durante C. Interobserver agreement of various thyroid imaging reporting and data systems. Endocr Connect. 2018 Jan;7(1):1–7. doi: 10.1530/EC-17-0336. doi. Medline.</cite> [<a href="https://doi.org/10.1530/EC-17-0336" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC5744624/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/29196301/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Endocr%20Connect&amp;title=Interobserver%20agreement%20of%20various%20thyroid%20imaging%20reporting%20and%20data%20systems&amp;author=G%20Grani&amp;author=L%20Lamartina&amp;author=V%20Cantisani&amp;author=M%20Maranghi&amp;author=P%20Lucia&amp;volume=7&amp;issue=1&amp;publication_year=2018&amp;pages=1-7&amp;pmid=29196301&amp;doi=10.1530/EC-17-0336&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R7">
<span class="label">7.</span><cite>Li W, Wang Y, Wen J, Zhang L, Sun Y. Diagnostic performance of American College of Radiology TI-RADS: a systematic review and meta-analysis. AJR Am J Roentgenol. 2021 Jan;216(1):38–47. doi: 10.2214/AJR.19.22691. doi. Medline.</cite> [<a href="https://doi.org/10.2214/AJR.19.22691" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32603229/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=AJR%20Am%20J%20Roentgenol&amp;title=Diagnostic%20performance%20of%20American%20College%20of%20Radiology%20TI-RADS:%20a%20systematic%20review%20and%20meta-analysis&amp;author=W%20Li&amp;author=Y%20Wang&amp;author=J%20Wen&amp;author=L%20Zhang&amp;author=Y%20Sun&amp;volume=216&amp;issue=1&amp;publication_year=2021&amp;pages=38-47&amp;pmid=32603229&amp;doi=10.2214/AJR.19.22691&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R8">
<span class="label">8.</span><cite>Thirunavukarasu AJ, Ting DSJ, Elangovan K, Gutierrez L, Tan TF, Ting DSW. Large language models in medicine. Nat Med. 2023 Aug;29(8):1930–1940. doi: 10.1038/s41591-023-02448-8. doi. Medline.</cite> [<a href="https://doi.org/10.1038/s41591-023-02448-8" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37460753/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Nat%20Med&amp;title=Large%20language%20models%20in%20medicine&amp;author=AJ%20Thirunavukarasu&amp;author=DSJ%20Ting&amp;author=K%20Elangovan&amp;author=L%20Gutierrez&amp;author=TF%20Tan&amp;volume=29&amp;issue=8&amp;publication_year=2023&amp;pages=1930-1940&amp;pmid=37460753&amp;doi=10.1038/s41591-023-02448-8&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R9">
<span class="label">9.</span><cite>Maitland A, Fowkes R, Maitland S. Can ChatGPT pass the MRCP (UK) written examinations? Analysis of performance and errors using a clinical decision-reasoning framework. BMJ Open. 2024 Mar 15;14(3):e080558.  doi: 10.1136/bmjopen-2023-080558. doi. Medline.</cite> [<a href="https://doi.org/10.1136/bmjopen-2023-080558" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10946340/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38490655/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=BMJ%20Open&amp;title=Can%20ChatGPT%20pass%20the%20MRCP%20(UK)%20written%20examinations?%20Analysis%20of%20performance%20and%20errors%20using%20a%20clinical%20decision-reasoning%20framework&amp;author=A%20Maitland&amp;author=R%20Fowkes&amp;author=S%20Maitland&amp;volume=14&amp;issue=3&amp;publication_year=2024&amp;pages=e080558&amp;pmid=38490655&amp;doi=10.1136/bmjopen-2023-080558&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R10">
<span class="label">10.</span><cite>Li Q, Yang X, Wang H, et al.  From beginner to expert: modeling medical knowledge into general llms.  [11-08-2025];arXiv. 2023  <a href="http://arxiv.org/abs/2312.01040" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://arxiv.org/abs/2312.01040</a> Preprint posted online on. URL. Accessed.</cite>
</li>
<li id="R11">
<span class="label">11.</span><cite>Sandmann S, Riepenhausen S, Plagwitz L, Varghese J. Systematic analysis of ChatGPT, Google search and Llama 2 for clinical decision support tasks. Nat Commun. 2024 Mar 6;15(1):2050.  doi: 10.1038/s41467-024-46411-8. doi. Medline.</cite> [<a href="https://doi.org/10.1038/s41467-024-46411-8" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10917796/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38448475/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Nat%20Commun&amp;title=Systematic%20analysis%20of%20ChatGPT,%20Google%20search%20and%20Llama%202%20for%20clinical%20decision%20support%20tasks&amp;author=S%20Sandmann&amp;author=S%20Riepenhausen&amp;author=L%20Plagwitz&amp;author=J%20Varghese&amp;volume=15&amp;issue=1&amp;publication_year=2024&amp;pages=2050&amp;pmid=38448475&amp;doi=10.1038/s41467-024-46411-8&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R12">
<span class="label">12.</span><cite>Liu H, Li C, Wu Q, Lee YJ. Visual instruction tuning.  [11-08-2025];arXiv. 2023  <a href="http://arxiv.org/abs/2304.08485" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://arxiv.org/abs/2304.08485</a> Preprint posted online on. URL. Accessed.</cite>
</li>
<li id="R13">
<span class="label">13.</span><cite>Li C, Wong C, Zhang S, et al.  LLaVA-med: training a large language-and-vision assistant for biomedicine in one day.  [11-08-2025];arXiv. 2023  <a href="http://arxiv.org/abs/2306.00890" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://arxiv.org/abs/2306.00890</a> Preprint posted online on. URL. Accessed.</cite>
</li>
<li id="R14">
<span class="label">14.</span><cite>Tessler FN, Thomas J. Artificial intelligence for evaluation of thyroid nodules: a primer. Thyroid. 2023 Feb;33(2):150–158. doi: 10.1089/thy.2022.0560. doi. Medline.</cite> [<a href="https://doi.org/10.1089/thy.2022.0560" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36424829/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Thyroid&amp;title=Artificial%20intelligence%20for%20evaluation%20of%20thyroid%20nodules:%20a%20primer&amp;author=FN%20Tessler&amp;author=J%20Thomas&amp;volume=33&amp;issue=2&amp;publication_year=2023&amp;pages=150-158&amp;pmid=36424829&amp;doi=10.1089/thy.2022.0560&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R15">
<span class="label">15.</span><cite>Wildman-Tobriner B, Taghi-Zadeh E, Mazurowski MA. Artificial intelligence (AI) tools for thyroid nodules on ultrasound, from the AJR Special Series on AI applications. AJR Am J Roentgenol. 2022 Oct;219(4):1–8. doi: 10.2214/AJR.22.27430. doi. Medline.</cite> [<a href="https://doi.org/10.2214/AJR.22.27430" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35383487/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=AJR%20Am%20J%20Roentgenol&amp;title=Artificial%20intelligence%20(AI)%20tools%20for%20thyroid%20nodules%20on%20ultrasound,%20from%20the%20AJR%20Special%20Series%20on%20AI%20applications&amp;author=B%20Wildman-Tobriner&amp;author=E%20Taghi-Zadeh&amp;author=MA%20Mazurowski&amp;volume=219&amp;issue=4&amp;publication_year=2022&amp;pages=1-8&amp;pmid=35383487&amp;doi=10.2214/AJR.22.27430&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R16">
<span class="label">16.</span><cite>Wu SH, Tong WJ, Li MD, et al.  Collaborative enhancement of consistency and accuracy in US diagnosis of thyroid nodules using large language models. Radiology. 2024 Mar;310(3):e232255.  doi: 10.1148/radiol.232255. doi. Medline.</cite> [<a href="https://doi.org/10.1148/radiol.232255" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38470237/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Radiology&amp;title=Collaborative%20enhancement%20of%20consistency%20and%20accuracy%20in%20US%20diagnosis%20of%20thyroid%20nodules%20using%20large%20language%20models&amp;author=SH%20Wu&amp;author=WJ%20Tong&amp;author=MD%20Li&amp;volume=310&amp;issue=3&amp;publication_year=2024&amp;pages=e232255&amp;pmid=38470237&amp;doi=10.1148/radiol.232255&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R17">
<span class="label">17.</span><cite>Cabezas E, Toro-Tobon D, Johnson T, et al.  ChatGPT-4’s accuracy in estimating thyroid nodule features and cancer risk from ultrasound images. Endocr Pract. 2025 Jun;31(6):716–723. doi: 10.1016/j.eprac.2025.03.008. doi. Medline.</cite> [<a href="https://doi.org/10.1016/j.eprac.2025.03.008" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/40139461/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Endocr%20Pract&amp;title=ChatGPT-4%E2%80%99s%20accuracy%20in%20estimating%20thyroid%20nodule%20features%20and%20cancer%20risk%20from%20ultrasound%20images&amp;author=E%20Cabezas&amp;author=D%20Toro-Tobon&amp;author=T%20Johnson&amp;volume=31&amp;issue=6&amp;publication_year=2025&amp;pages=716-723&amp;pmid=40139461&amp;doi=10.1016/j.eprac.2025.03.008&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R18">
<span class="label">18.</span><cite>Qiu J, Yuan W, Lam K. The application of multimodal large language models in medicine. Lancet Reg Health West Pac. 2024 Apr;45:101048.  doi: 10.1016/j.lanwpc.2024.101048. doi. Medline.</cite> [<a href="https://doi.org/10.1016/j.lanwpc.2024.101048" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10958473/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38524685/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Lancet%20Reg%20Health%20West%20Pac&amp;title=The%20application%20of%20multimodal%20large%20language%20models%20in%20medicine&amp;author=J%20Qiu&amp;author=W%20Yuan&amp;author=K%20Lam&amp;volume=45&amp;publication_year=2024&amp;pages=101048&amp;pmid=38524685&amp;doi=10.1016/j.lanwpc.2024.101048&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R19">
<span class="label">19.</span><cite>Meskó B. Prompt engineering as an important emerging skill for medical professionals: tutorial. J Med Internet Res. 2023 Oct 4;25(1):e50638.  doi: 10.2196/50638. doi. Medline.</cite> [<a href="https://doi.org/10.2196/50638" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10585440/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37792434/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Med%20Internet%20Res&amp;title=Prompt%20engineering%20as%20an%20important%20emerging%20skill%20for%20medical%20professionals:%20tutorial&amp;author=B%20Mesk%C3%B3&amp;volume=25&amp;issue=1&amp;publication_year=2023&amp;pages=e50638&amp;pmid=37792434&amp;doi=10.2196/50638&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R20">
<span class="label">20.</span><cite>Han T, Adams LC, Nebelung S, Kather JN, Bressem KK, Truhn D. Multimodal large language models are generalist medical image interpreters. Health Informatics.  doi: 10.1101/2023.12.21.23300146. doi.</cite> [<a href="https://doi.org/10.1101/2023.12.21.23300146" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>]</li>
<li id="R21">
<span class="label">21.</span><cite>Zhang S, Dong L, Li X, et al.  Instruction tuning for large language models: a survey.  [11-08-2025];arXiv. 2023  <a href="http://arxiv.org/abs/2308.10792" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://arxiv.org/abs/2308.10792</a> Preprint posted online on. URL. Accessed.</cite>
</li>
<li id="R22">
<span class="label">22.</span><cite>Introducing o3 and o4-mini. OpenAI.  [30-07-2025]. <a href="https://openai.com/index/introducing-o3-and-o4-mini" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://openai.com/index/introducing-o3-and-o4-mini</a> URL. Accessed.</cite>
</li>
<li id="R23">
<span class="label">23.</span><cite>Yamashita R, Kapoor T, Alam MN, et al.  Toward reduction in false-positive thyroid nodule biopsies with a deep learning-based risk stratification system using US cine-clip images. Radiol Artif Intell. 2022 May;4(3):e210174.  doi: 10.1148/ryai.210174. doi. Medline.</cite> [<a href="https://doi.org/10.1148/ryai.210174" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9152684/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35652118/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Radiol%20Artif%20Intell&amp;title=Toward%20reduction%20in%20false-positive%20thyroid%20nodule%20biopsies%20with%20a%20deep%20learning-based%20risk%20stratification%20system%20using%20US%20cine-clip%20images&amp;author=R%20Yamashita&amp;author=T%20Kapoor&amp;author=MN%20Alam&amp;volume=4&amp;issue=3&amp;publication_year=2022&amp;pages=e210174&amp;pmid=35652118&amp;doi=10.1148/ryai.210174&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R24">
<span class="label">24.</span><cite>Imani S, Du L, Shrivastava H. MathPrompter: mathematical reasoning using large language models.  [11-08-2025];arXiv. 2023  <a href="http://arxiv.org/abs/2303.05398" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://arxiv.org/abs/2303.05398</a> Preprint posted online on. URL. Accessed.</cite>
</li>
<li id="R25">
<span class="label">25.</span><cite>See YKC, Lim KSA, Au WY, Chia SYC, Fan X, Li ZK. The use of large language models in ophthalmology: a scoping review on current use-cases and considerations for future works in this field. BDCC. 2025;9(6):151. doi: 10.3390/bdcc9060151. doi.</cite> [<a href="https://doi.org/10.3390/bdcc9060151" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=BDCC&amp;title=The%20use%20of%20large%20language%20models%20in%20ophthalmology:%20a%20scoping%20review%20on%20current%20use-cases%20and%20considerations%20for%20future%20works%20in%20this%20field&amp;author=YKC%20See&amp;author=KSA%20Lim&amp;author=WY%20Au&amp;author=SYC%20Chia&amp;author=X%20Fan&amp;volume=9&amp;issue=6&amp;publication_year=2025&amp;pages=151&amp;doi=10.3390/bdcc9060151&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R26">
<span class="label">26.</span><cite>Rydzewski NR, Dinakaran D, Zhao SG, et al.  Comparative evaluation of LLMs in clinical oncology. NEJM AI. 2024 May;1(5) doi: 10.1056/aioa2300151. doi. Medline.</cite> [<a href="https://doi.org/10.1056/aioa2300151" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11315428/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39131700/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=NEJM%20AI&amp;title=Comparative%20evaluation%20of%20LLMs%20in%20clinical%20oncology&amp;author=NR%20Rydzewski&amp;author=D%20Dinakaran&amp;author=SG%20Zhao&amp;volume=1&amp;issue=5&amp;publication_year=2024&amp;pmid=39131700&amp;doi=10.1056/aioa2300151&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R27">
<span class="label">27.</span><cite>Huang J, Yang R, Huang X, et al.  Feasibility of large language models for CEUS LI-RADS categorization of small liver nodules in patients at risk for hepatocellular carcinoma. Front Oncol. 2024;14 doi: 10.3389/fonc.2024.1513608. doi.</cite> [<a href="https://doi.org/10.3389/fonc.2024.1513608" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11688206/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39744002/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Front%20Oncol&amp;title=Feasibility%20of%20large%20language%20models%20for%20CEUS%20LI-RADS%20categorization%20of%20small%20liver%20nodules%20in%20patients%20at%20risk%20for%20hepatocellular%20carcinoma&amp;author=J%20Huang&amp;author=R%20Yang&amp;author=X%20Huang&amp;volume=14&amp;publication_year=2024&amp;pmid=39744002&amp;doi=10.3389/fonc.2024.1513608&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R28">
<span class="label">28.</span><cite>Balduzzi A, Pastena M, Tondato S, et al.  Exploring chatbot applications in pancreatic disease treatment: potential and pitfalls. Scierxiv. 2025 doi: 10.20517/scierxiv202506.040.v1. Preprint posted online on. doi.</cite> [<a href="https://doi.org/10.20517/scierxiv202506.040.v1" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>]</li>
<li id="R29">
<span class="label">29.</span><cite>Ríos-Hoyo A, Shan NL, Li A, Pearson AT, Pusztai L, Howard FM. Evaluation of large language models as a diagnostic aid for complex medical cases. Front Med (Lausanne) 2024;11:1380148.  doi: 10.3389/fmed.2024.1380148. doi. Medline.</cite> [<a href="https://doi.org/10.3389/fmed.2024.1380148" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11222590/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38966538/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Front%20Med%20(Lausanne)&amp;title=Evaluation%20of%20large%20language%20models%20as%20a%20diagnostic%20aid%20for%20complex%20medical%20cases&amp;author=A%20R%C3%ADos-Hoyo&amp;author=NL%20Shan&amp;author=A%20Li&amp;author=AT%20Pearson&amp;author=L%20Pusztai&amp;volume=11&amp;publication_year=2024&amp;pages=1380148&amp;pmid=38966538&amp;doi=10.3389/fmed.2024.1380148&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R30">
<span class="label">30.</span><cite>Qi S, Cao Z, Rao J, Wang L, Xiao J, Wang X. What is the limitation of multimodal LLMs? A deeper look into multimodal LLMs through prompt probing. Inf Process Manag. 2023 Nov;60(6):103510. doi: 10.1016/j.ipm.2023.103510. doi.</cite> [<a href="https://doi.org/10.1016/j.ipm.2023.103510" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Inf%20Process%20Manag&amp;title=What%20is%20the%20limitation%20of%20multimodal%20LLMs?%20A%20deeper%20look%20into%20multimodal%20LLMs%20through%20prompt%20probing&amp;author=S%20Qi&amp;author=Z%20Cao&amp;author=J%20Rao&amp;author=L%20Wang&amp;author=J%20Xiao&amp;volume=60&amp;issue=6&amp;publication_year=2023&amp;pages=103510&amp;doi=10.1016/j.ipm.2023.103510&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R31">
<span class="label">31.</span><cite>Lakhani P. The importance of image resolution in building deep learning models for medical imaging. Radiol Artif Intell. 2020 Jan;2(1):e190177.  doi: 10.1148/ryai.2019190177. doi. Medline.</cite> [<a href="https://doi.org/10.1148/ryai.2019190177" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8017377/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33939779/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Radiol%20Artif%20Intell&amp;title=The%20importance%20of%20image%20resolution%20in%20building%20deep%20learning%20models%20for%20medical%20imaging&amp;author=P%20Lakhani&amp;volume=2&amp;issue=1&amp;publication_year=2020&amp;pages=e190177&amp;pmid=33939779&amp;doi=10.1148/ryai.2019190177&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R32">
<span class="label">32.</span><cite>Thinking with images. OpenAI.  [30-07-2025]. <a href="https://openai.com/index/thinking-with-images" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://openai.com/index/thinking-with-images</a> URL. Accessed.</cite>
</li>
<li id="R33">
<span class="label">33.</span><cite>Singhal K, Tu T, Gottweis J, et al.  Towards expert-level medical question answering with large language models.  [11-08-2025];arXiv. 2023  doi: 10.1038/s41591-024-03423-7. <a href="http://arxiv.org/abs/2305.09617" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://arxiv.org/abs/2305.09617</a> Preprint posted online on. URL. Accessed.</cite> [<a href="https://doi.org/10.1038/s41591-024-03423-7" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11922739/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39779926/" class="usa-link">PubMed</a>]</li>
<li id="R34">
<span class="label">34.</span><cite>Maharjan J, Garikipati A, Singh NP, et al.  OpenMedLM: prompt engineering can out-perform fine-tuning in medical question-answering with open-source large language models. Sci Rep. 2024;14(1) doi: 10.1038/s41598-024-64827-6. doi.</cite> [<a href="https://doi.org/10.1038/s41598-024-64827-6" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11187169/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38898116/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Sci%20Rep&amp;title=OpenMedLM:%20prompt%20engineering%20can%20out-perform%20fine-tuning%20in%20medical%20question-answering%20with%20open-source%20large%20language%20models&amp;author=J%20Maharjan&amp;author=A%20Garikipati&amp;author=NP%20Singh&amp;volume=14&amp;issue=1&amp;publication_year=2024&amp;pmid=38898116&amp;doi=10.1038/s41598-024-64827-6&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R35">
<span class="label">35.</span><cite>Schenke SA, Petersen M, Görges R, et al.  Interobserver agreement in ultrasound risk stratification systems for thyroid nodules on static images versus cine-loop video sequences. Diagnostics (Basel) 2024 Sep 26;14(19):2138.  doi: 10.3390/diagnostics14192138. doi. Medline.</cite> [<a href="https://doi.org/10.3390/diagnostics14192138" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11475346/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39410542/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Diagnostics%20(Basel)&amp;title=Interobserver%20agreement%20in%20ultrasound%20risk%20stratification%20systems%20for%20thyroid%20nodules%20on%20static%20images%20versus%20cine-loop%20video%20sequences&amp;author=SA%20Schenke&amp;author=M%20Petersen&amp;author=R%20G%C3%B6rges&amp;volume=14&amp;issue=19&amp;publication_year=2024&amp;pages=2138&amp;pmid=39410542&amp;doi=10.3390/diagnostics14192138&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R36">
<span class="label">36.</span><cite>Jiang Z, Cheng D, Qin Z, et al.  TV-SAM: increasing zero-shot segmentation performance on multimodal medical images using GPT-4 generated descriptive prompts without human annotation. Big Data Min Anal. 2024;7(4):1199–1211. doi: 10.26599/BDMA.2024.9020058. doi.</cite> [<a href="https://doi.org/10.26599/BDMA.2024.9020058" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Big%20Data%20Min%20Anal&amp;title=TV-SAM:%20increasing%20zero-shot%20segmentation%20performance%20on%20multimodal%20medical%20images%20using%20GPT-4%20generated%20descriptive%20prompts%20without%20human%20annotation&amp;author=Z%20Jiang&amp;author=D%20Cheng&amp;author=Z%20Qin&amp;volume=7&amp;issue=4&amp;publication_year=2024&amp;pages=1199-1211&amp;doi=10.26599/BDMA.2024.9020058&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R37">
<span class="label">37.</span><cite>Zhao H, Chen H, Yang F, et al.  Explainability for large language models: a survey.  [11-08-2025];arXiv. 2023  <a href="http://arxiv.org/abs/2309.01029" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://arxiv.org/abs/2309.01029</a> URL. Accessed.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=arXiv&amp;title=Explainability%20for%20large%20language%20models:%20a%20survey&amp;author=H%20Zhao&amp;author=H%20Chen&amp;author=F%20Yang&amp;publication_year=2023&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adsm93_" lang="en" class="supplementary-materials"><h3 class="pmc_sec_title">Supplementary Materials</h3>
<section class="sm xbox font-sm" id="db_ds_supplementary-material1_reqid_"><div class="caption p"><span>Multimedia Appendix 1. Categorical comparison of median model-generated scores against human-rated scores for each of the TI-RADS components and the overall TI-RADS classification. (A) Output from LLaVA and LLaVA-Med. (B) Output from OpenAI o3. (C) Output from all three models combined.</span></div>
<div class="media p">
<div class="caption">
<a href="/articles/instance/12364431/bin/formative-v9-e70863-s001.png" data-ga-action="click_feat_suppl" class="usa-link">formative-v9-e70863-s001.png</a><sup> (49.8KB, png) </sup>
</div>
<div class="object-id font-xs text-base-dark">DOI: 10.2196/70863</div>
</div></section></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from JMIR Formative Research are provided here courtesy of <strong>JMIR Publications Inc.</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.2196/70863"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/formative-v9-e70863.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (946.7 KB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12364431/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12364431/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12364431%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12364431/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12364431/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12364431/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40829145/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12364431/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40829145/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12364431/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12364431/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="cbAN8lBVo6exmDS4paPM1xrclhR6fVuEIOQNGafd2fL5TSYN8GJDxH3KUV27apYJ">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
    

    </body>
</html>
