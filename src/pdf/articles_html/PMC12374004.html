
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            Adaptive information-constrained mapping for feature compression in edge AI and federated systems - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="AE532E758AF21EA3052E7500152DAE18.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="scirep">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12374004/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="Scientific Reports">
<meta name="citation_title" content="Adaptive information-constrained mapping for feature compression in edge AI and federated systems">
<meta name="citation_author" content="Viacheslav Kovtun">
<meta name="citation_author_institution" content="Vinnytsia National Technical University, Vinnytsia, Ukraine">
<meta name="citation_author_institution" content="Institute of Theoretical and Applied Informatics, Polish Academy of Sciences, Bałtycka 5, 44-100 Gliwice, Poland">
<meta name="citation_publication_date" content="2025 Aug 22">
<meta name="citation_volume" content="15">
<meta name="citation_firstpage" content="30915">
<meta name="citation_doi" content="10.1038/s41598-025-16604-2">
<meta name="citation_pmid" content="40847043">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12374004/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12374004/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12374004/pdf/41598_2025_Article_16604.pdf">
<meta name="description" content="This article explores the problem of efficient feature compression in distributed intelligent systems with limited resources, particularly within the context of Edge AI and Federated Learning. The relevance of this study is driven by the growing ...">
<meta name="og:title" content="Adaptive information-constrained mapping for feature compression in edge AI and federated systems">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="This article explores the problem of efficient feature compression in distributed intelligent systems with limited resources, particularly within the context of Edge AI and Federated Learning. The relevance of this study is driven by the growing ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12374004/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12374004">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1038/s41598-025-16604-2"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/41598_2025_Article_16604.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12374004%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12374004/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12374004/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12374004/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-scirep.jpg" alt="Scientific Reports logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to Scientific Reports" title="Link to Scientific Reports" shape="default" href="http://www.nature.com/srep" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">Sci Rep</button></div>. 2025 Aug 22;15:30915. doi: <a href="https://doi.org/10.1038/s41598-025-16604-2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1038/s41598-025-16604-2</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22Sci%20Rep%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sci%20Rep%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22Sci%20Rep%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22Sci%20Rep%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Adaptive information-constrained mapping for feature compression in edge AI and federated systems</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kovtun%20V%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Viacheslav Kovtun</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Viacheslav Kovtun</span></h3>
<div class="p">
<sup>1</sup>Vinnytsia National Technical University, Vinnytsia, Ukraine </div>
<div class="p">
<sup>2</sup>Institute of Theoretical and Applied Informatics, Polish Academy of Sciences, Bałtycka 5, 44-100 Gliwice, Poland </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kovtun%20V%22%5BAuthor%5D" class="usa-link"><span class="name western">Viacheslav Kovtun</span></a>
</div>
</div>
<sup>1,</sup><sup>2,</sup><sup>✉</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="Aff1">
<sup>1</sup>Vinnytsia National Technical University, Vinnytsia, Ukraine </div>
<div id="Aff2">
<sup>2</sup>Institute of Theoretical and Applied Informatics, Polish Academy of Sciences, Bałtycka 5, 44-100 Gliwice, Poland </div>
<div class="author-notes p"><div class="fn" id="_fncrsp93pmc__">
<sup>✉</sup><p class="display-inline">Corresponding author.</p>
</div></div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2025 Jul 18; Accepted 2025 Aug 18; Collection date 2025.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© The Author(s) 2025</div>
<p><strong>Open Access</strong> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="https://creativecommons.org/licenses/by/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://creativecommons.org/licenses/by/4.0/</a>.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12374004  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40847043/" class="usa-link">40847043</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="Abs1"><h2>Abstract</h2>
<p id="Par1">This article explores the problem of efficient feature compression in distributed intelligent systems with limited resources, particularly within the context of Edge AI and Federated Learning. The relevance of this study is driven by the growing need to reduce communication overhead under conditions of unstable Quality of Service, limited bandwidth, and high heterogeneity of input data. The scientific novelty lies in the development of a consistent entropy-regularised compression model that combines variational latent mapping, non-negativity-constrained projection design, and stochastic-Boolean transformation of the feature space. A generalised compression quality functional is proposed, integrating the directed Kullback–Leibler divergence, an entropic regularisation component, and a guarantee of preserving the semantic relevance of the compressed representation. Efficient projection-gradient optimisation algorithms have been developed, suitable for implementation in constrained computational environments. The practical effectiveness of the approach has been confirmed through experiments on the HAR and PAMAP2 datasets: a 6–eightfold reduction in entropy load was achieved while maintaining classification accuracy above 94% and a high level of semantic fidelity in the reconstructed data. The models were deployed on low-power devices (Jetson Nano, Raspberry Pi 4), where they demonstrated robustness to noise and loss, as well as superiority over current SOTA solutions (FedEntropy, EDS-FL, SER) in terms of compression efficiency, adaptability to heterogeneous distributions, and stability under unstable transmission conditions.</p>
<section id="kwd-group1" class="kwd-group"><p><strong>Subject terms:</strong> Engineering, Mathematics and computing</p></section></section><section id="Sec1"><h2 class="pmc_sec_title">Introduction</h2>
<section id="Sec2"><h3 class="pmc_sec_title">Relevance of the Research</h3>
<p id="Par2">Modern information processes are increasingly implemented under conditions of distribution, limited computational resources, unstable communication channels, and high variability of input data. This is typical of a wide range of applied systems: wearable devices, autonomous sensor networks, mobile IoT platforms, urban infrastructures, industrial facilities, and distributed energy grids. In such environments, the tasks of feature collection, transmission, and processing require not only efficiency but also robustness to external and internal disturbances.</p>
<p id="Par3">In the context of tasks such as human physical activity monitoring<sup><a href="#CR1" class="usa-link" aria-describedby="CR1">1</a></sup>, equipment condition diagnostics<sup><a href="#CR2" class="usa-link" aria-describedby="CR2">2</a></sup>, user behaviour analysis<sup><a href="#CR3" class="usa-link" aria-describedby="CR3">3</a></sup>, or local energy system stability control<sup><a href="#CR4" class="usa-link" aria-describedby="CR4">4</a></sup>, there arises a need to reduce the volume of information circulating within the system. However, data reduction must not result in the loss of its practical value. The concern lies not merely in the technical transmission of values but in preserving the portion of information that is critical for subsequent analysis, classification, prediction, or control. It is this applied essence, namely the semantic significance of features, that must remain intact under any transformations. Implementing compression under such conditions presents several challenges. Incoming data streams are often redundant, noisy, or incomplete. This complicates the preservation of their informative structure after compression. Transmission channels are characterised by instability, variable bandwidth, and intermittency, which increases the risk of loss. Moreover, the hardware components of edge devices are subject to significant limitations in terms of memory capacity, energy consumption, and computational power, rendering the use of full-scale classical analysis methods unfeasible without prior feature reduction.</p>
<p id="Par4">Most existing data compression approaches focus primarily on volume reduction, without accounting for the need to adapt to the applied context<sup><a href="#CR5" class="usa-link" aria-describedby="CR5">5</a></sup>. They do not provide flexible control over which information is preserved and which is discarded, often resulting in significant efficiency losses at subsequent processing stages. In view of this limitation, our research is focused on formalising approaches to semantically controlled feature compression capable of operating in complex information environments. Particular attention is given to the adaptation of such methods to hardware-constrained systems, the preservation of the functional relevance of features, and the assurance of robustness to the variability of data received from sensor sources. Therefore, the core problem addressed in this work is how to design an information-constrained feature encoding mechanism that simultaneously achieves bit-level compactness, task-specific relevance, and semantic preservation, without relying on post hoc selection or handcrafted compression pipelines.</p></section></section><section id="Sec3"><h2 class="pmc_sec_title">State-of-the-art</h2>
<p id="Par5">In recent scientific literature, a number of approaches have emerged aiming to reduce information load in applied systems without compromising the functional informativeness of features. These approaches differ significantly in their underlying concepts, architectural implementation, and application domains () ranging from lightweight models for local inference on low-power devices to stochastically regularised autoencoders and communication-efficient schemes designed for distributed processing. A critical analysis will be conducted of the most relevant directions that currently constitute the core of modern solutions in the field of semantically controlled feature compression within distributed information systems.</p>
<p id="Par6">Semantically controlled feature compression<sup><a href="#CR6" class="usa-link" aria-describedby="CR6">6</a>,<a href="#CR7" class="usa-link" aria-describedby="CR7">7</a></sup> involves reducing the dimensionality or complexity of input representations while preserving the information that is critical for performing a target task (classification, regression, anomaly detection, etc.). In contrast to traditional compression approaches, which focus on global reconstruction metrics, this class of methods incorporates importance features directly into the training process—via gradient-based maps (e.g. Grad-CAM, LRP)<sup><a href="#CR8" class="usa-link" aria-describedby="CR8">8</a></sup>, attention mechanisms<sup><a href="#CR9" class="usa-link" aria-describedby="CR9">9</a></sup>, or task-aware regularisation<sup><a href="#CR10" class="usa-link" aria-describedby="CR10">10</a></sup>. Notable implementations include supervised bottleneck architectures<sup><a href="#CR11" class="usa-link" aria-describedby="CR11">11</a></sup>, semantic dropout<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup>, and feature masking with learnable importance weights<sup><a href="#CR13" class="usa-link" aria-describedby="CR13">13</a></sup>. For instance, studies<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a>,<a href="#CR15" class="usa-link" aria-describedby="CR15">15</a></sup> have demonstrated the effectiveness of attention-guided compression in mobile video stream classification and biomedical signal processing tasks. However, these models have several limitations: they typically require annotations or feedback from the main task, which complicates deployment under limited supervision; in addition, integrated attention modules increase the number of parameters, which contradicts the requirements for lightweight systems in edge environments. In some cases, there is also sensitivity to noise in semantic maps, which reduces the model’s robustness during inference under unstable conditions.</p>
<p id="Par7">Entropy-constrained representation learning<sup><a href="#CR16" class="usa-link" aria-describedby="CR16">16</a></sup> is based on controlling the information capacity of the latent space through specialised regularisers that limit the volume of transmitted or retained information. Classical implementations take the form of variational autoencoders (VAE) with modified loss functions incorporating terms such as KL divergence or mutual information bounds (e.g. β-VAE, InfoVAE, δ-VAE)<sup><a href="#CR17" class="usa-link" aria-describedby="CR17">17</a>,<a href="#CR18" class="usa-link" aria-describedby="CR18">18</a></sup>. These models enable the formation of a compact yet expressive latent space suitable for subsequent use in classification or reconstruction tasks. Additionally, learnable entropy models<sup><a href="#CR19" class="usa-link" aria-describedby="CR19">19</a></sup> are employed to parameterise entropy via scalable coders. In image recognition and audio compression tasks, these approaches have demonstrated effective bandwidth reduction without compromising accuracy. However, the primary drawback of such methods lies in their training complexity: optimisation involving entropy regularisers often leads to unstable convergence and high sensitivity to the choice of hyperparameters (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq1"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/f5e0e8aa5fab/d33e258.gif" loading="lazy" id="d33e258" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq2"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/95c7c0c413ff/d33e264.gif" loading="lazy" id="d33e264" alt="Inline graphic"></span>). Furthermore, the resulting latent spaces may exhibit low separability or complex topology, complicating interpretation and subsequent use in low-power inference. In certain cases, a trade-off is also observed between entropy efficiency and the semantic relevance of features.</p>
<p id="Par8">Task-oriented feature reduction involves selecting or transforming only those components of the input space that are most informative for a specific task (such as action classification, state prediction, or anomaly detection). Unlike universal compression methods, these approaches incorporate knowledge of the target function directly into the model training process. The most common techniques include differentiable feature masking mechanisms (learnable masks)<sup><a href="#CR20" class="usa-link" aria-describedby="CR20">20</a></sup>, attention-based selection<sup><a href="#CR21" class="usa-link" aria-describedby="CR21">21</a></sup>, and joint learning models with sparsity control blocks (e.g. L0 regularisation, concrete masks, reinforcement-driven feature gating). Applied implementations include the Adaptive Feature Selection Network (AFSNet)<sup><a href="#CR22" class="usa-link" aria-describedby="CR22">22</a></sup>, Differentiable Feature Selection (DFS)<sup><a href="#CR23" class="usa-link" aria-describedby="CR23">23</a></sup>, and two-stage selection methods in which the reducer is trained separately from the predictor. The key advantage of such approaches lies in their flexibility: they enable a reduction in the number of features without loss of performance and allow adaptation to changing conditions or domains. However, major drawbacks remain: high sensitivity to distributional shifts, reliance on full access to labelled examples, and challenges in generalising to new tasks under weak supervision. Moreover, many existing solutions overlook the entropic complexity of residual features, which complicates their subsequent transmission over constrained channels.</p>
<p id="Par9">Stochastic and discrete latent spaces<sup><a href="#CR24" class="usa-link" aria-describedby="CR24">24</a></sup> are employed to construct generalised and compact representations that are robust to noise and partial loss of input features. This approach models the latent space as a random or quantised variable with controlled variance, enabling the avoidance of overfitting to overly deterministic structures and enhancing the generative capacity of models. One classical example is the reparameterisation trick in VAEs, while more recent developments include discrete encoding in VQ-VAE, Gumbel-softmax quantisation, as well as Concrete Bernoulli and Binary Concrete models. These methods are widely used in low-rate compression, representation learning under unsupervised conditions, and tasks involving corrupted or partially missing input. Their advantage lies in the ability to retain structural informativeness even under unstable input streams. However, their drawbacks include training complexity due to the non-differentiability of quantisation operations (requiring additional approximations), the risk of generating “dead” codes in discrete dictionaries, and limited interpretability of latent features. Moreover, such models require careful tuning of temperature and regularisation parameters, which complicates their deployment in dynamic edge analytics environments.</p>
<p id="Par10">Communication-efficient encoding in the context of federated learning (FL) and IoT systems focuses on minimising the volume of transmitted features or parameters while preserving the applied accuracy of the model<sup><a href="#CR25" class="usa-link" aria-describedby="CR25">25</a>,<a href="#CR26" class="usa-link" aria-describedby="CR26">26</a></sup>. This approach is critically important in scenarios where communication channels are narrowband, unstable, or energy-expensive, such as in mobile sensor networks or edge clouds. Key methods include sparsification strategies (e.g. top-<em>k</em> selection, random-<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq3"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/10c81be4a07d/d33e306.gif" loading="lazy" id="d33e306" alt="Inline graphic"></span> dropping), gradient quantisation (QSGD, TernGrad), adaptive update scaling (AdaComp), and split learning with model partitioning between device and server. At the feature level, importance-aware encoding<sup><a href="#CR27" class="usa-link" aria-describedby="CR27">27</a></sup> and rate-aware communication schemes<sup><a href="#CR25" class="usa-link" aria-describedby="CR25">25</a></sup> are being actively developed to adjust transmission volume according to the entropy budget. These solutions enable substantial traffic reduction without significant accuracy loss, particularly in large-scale client networks. However, they also face several limitations: the effectiveness of many approaches heavily depends on client synchrony and channel stability, which is not always feasible in real-world IoT environments; some algorithms require prior knowledge of input feature statistics; moreover, aggregation and selection are often performed using heuristic rules, which limits generalisability and adaptability when the task or domain changes.</p>
<p id="Par11">Despite significant progress in the development of feature compression approaches in distributed systems, none of the examined directions ensures the simultaneous achievement of high semantic relevance, entropy efficiency, task adaptability, and robustness to unstable transmission conditions. Semantically controlled methods require annotations and increase computational complexity; entropy-constrained learning suffers from difficult optimisation and instability of the latent space; task-oriented reduction is sensitive to distribution shifts and often neglects communication constraints; stochastic and discrete spaces pose training challenges and offer limited interpretability; communication-efficient encoding, in turn, is largely heuristic-based, limiting its generalisability. All this highlights the need for a comprehensive approach to feature compression that combines the advantages of these directions while overcoming their key shortcomings. In this context, it is reasonable to develop an entropy-regularised feature transformation system capable of adaptively aligning compression with the applied significance of features and the parameters of the transmission environment.</p>
<p id="Par12">In this context, it is appropriate to turn to modern state-of-the-art (SOTA) methods that implement the most promising approaches to feature compression in federated and distributed learning. Three of them deserve particular attention as the closest to the proposed model in terms of target orientation: FedEntropy, EDS-FL, and SER. FedEntropy<sup><a href="#CR28" class="usa-link" aria-describedby="CR28">28</a></sup> is based on the principle of entropy-constrained quantisation aimed at improving communication efficiency in federated learning. The method incorporates an entropy regulariser into the loss function, enabling the reduction of redundancy in transmitted features without significant loss of informativeness. It adapts the encoding precision to the local entropy profile, but is heavily dependent on the encoder configuration and shows reduced generalisability to new classes or under heterogeneous data distributions. EDS-FL<sup><a href="#CR29" class="usa-link" aria-describedby="CR29">29</a></sup> is a task-centric compression strategy implemented via knowledge distillation. It involves training a compact representation for each client under the guidance of a shared teacher model, allowing task-relevant characteristics to be preserved and variability to be reduced. This approach is effective under stable conditions with a fixed number of classes but loses performance when scaled to a larger number of clients or changing tasks. An additional challenge is the need for synchronised training and increased computational overhead. SER<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup> is a stochastic encoding and reconstruction framework that uses probabilistic latent representations to model uncertainty in features. Compression is achieved by sampling from a trained distributional model, ensuring high compression while maintaining representativeness. However, such stochasticity is accompanied by optimisation difficulties, high variability, and low interpretability of the latent space, complicating alignment with the structure of target tasks. Each of these methods illustrates an important aspect of the feature compression problem in distributed systems—entropy, task-centricity, or latent flexibility. Yet none offers a comprehensive solution combining semantic relevance, entropy efficiency, task adaptability, and robustness to transmission constraints. A comparative analysis of the main characteristics of these methods and the proposed solution is presented in Table <a href="#Tab1" class="usa-link">1</a>.</p>
<section class="tw xbox font-sm" id="Tab1"><h3 class="obj_head">Table 1.</h3>
<div class="caption p"><p>Conceptual comparison of the proposed method and three representative SOTA approaches.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Criterion</th>
<th align="left" colspan="1" rowspan="1">Proposed (Ours)</th>
<th align="left" colspan="1" rowspan="1">FedEntropy</th>
<th align="left" colspan="1" rowspan="1">EDS-FL</th>
<th align="left" colspan="1" rowspan="1">SER</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Design paradigm</td>
<td align="left" colspan="1" rowspan="1">Regularised representation optimisation</td>
<td align="left" colspan="1" rowspan="1">Entropy-constrained quantisation</td>
<td align="left" colspan="1" rowspan="1">Task-oriented distillation</td>
<td align="left" colspan="1" rowspan="1">Stochastic latent encoding</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Entropy reduction potential</td>
<td align="left" colspan="1" rowspan="1">High (explicit regularisation of representation entropy)</td>
<td align="left" colspan="1" rowspan="1">Moderate (adaptive to local entropy)</td>
<td align="left" colspan="1" rowspan="1">Moderate (guided reduction via distillation)</td>
<td align="left" colspan="1" rowspan="1">Low (uncontrolled stochastic variability)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Semantic fidelity</td>
<td align="left" colspan="1" rowspan="1">High (controlled latent structure)</td>
<td align="left" colspan="1" rowspan="1">Moderate (depends on encoder configuration)</td>
<td align="left" colspan="1" rowspan="1">Moderate (teacher-guided relevance)</td>
<td align="left" colspan="1" rowspan="1">Low (sample-level uncertainty dominates)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Task adaptivity</td>
<td align="left" colspan="1" rowspan="1">High (task-aware training objectives)</td>
<td align="left" colspan="1" rowspan="1">Moderate (manual hyperparameter tuning)</td>
<td align="left" colspan="1" rowspan="1">Moderate (aligned via teacher)</td>
<td align="left" colspan="1" rowspan="1">Low (static latent sampling)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Generalisation capability</td>
<td align="left" colspan="1" rowspan="1">High (validated for unseen classes/tasks)</td>
<td align="left" colspan="1" rowspan="1">Low (encoder-specific generalisation)</td>
<td align="left" colspan="1" rowspan="1">Moderate (task-bound distillation)</td>
<td align="left" colspan="1" rowspan="1">Low (limited transferability)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Compression adaptability</td>
<td align="left" colspan="1" rowspan="1">High (context-aware encoding)</td>
<td align="left" colspan="1" rowspan="1">Moderate (entropy-profile driven)</td>
<td align="left" colspan="1" rowspan="1">Moderate (fixed distillation targets)</td>
<td align="left" colspan="1" rowspan="1">High (sampling enables variability, less control)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Latent space consistency</td>
<td align="left" colspan="1" rowspan="1">High (stabilised via regularisation)</td>
<td align="left" colspan="1" rowspan="1">Moderate</td>
<td align="left" colspan="1" rowspan="1">Low (inter-client feature divergence)</td>
<td align="left" colspan="1" rowspan="1">Low (sampling noise)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Interpretability</td>
<td align="left" colspan="1" rowspan="1">Moderate–High (structured latent space)</td>
<td align="left" colspan="1" rowspan="1">Low</td>
<td align="left" colspan="1" rowspan="1">Moderate</td>
<td align="left" colspan="1" rowspan="1">Low</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Scalability</td>
<td align="left" colspan="1" rowspan="1">High (50 + clients, multiple tasks supported)</td>
<td align="left" colspan="1" rowspan="1">Moderate (tested on small-scale setups)</td>
<td align="left" colspan="1" rowspan="1">Low (distillation overhead)</td>
<td align="left" colspan="1" rowspan="1">Moderate (client-specific tuning needed)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Communication efficiency</td>
<td align="left" colspan="1" rowspan="1">High (learned, compact, and robust encoding)</td>
<td align="left" colspan="1" rowspan="1">Moderate (entropy heuristics)</td>
<td align="left" colspan="1" rowspan="1">Low (additional teacher–client exchange)</td>
<td align="left" colspan="1" rowspan="1">Moderate (bit-level control, low robustness)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Training complexity</td>
<td align="left" colspan="1" rowspan="1">Moderate (no external modules)</td>
<td align="left" colspan="1" rowspan="1">Moderate</td>
<td align="left" colspan="1" rowspan="1">High (teacher synchronisation required)</td>
<td align="left" colspan="1" rowspan="1">Moderate–High (training instability)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Robustness to data heterogeneity</td>
<td align="left" colspan="1" rowspan="1">High (validated under non-IID distributions)</td>
<td align="left" colspan="1" rowspan="1">Moderate (entropy adapts partially)</td>
<td align="left" colspan="1" rowspan="1">Low (sensitive to class imbalance)</td>
<td align="left" colspan="1" rowspan="1">Low (amplified by stochasticity)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Inference suitability for edge devices</td>
<td align="left" colspan="1" rowspan="1">High (low latency and model size)</td>
<td align="left" colspan="1" rowspan="1">Moderate</td>
<td align="left" colspan="1" rowspan="1">Low (teacher model size dominates)</td>
<td align="left" colspan="1" rowspan="1">Moderate (requires sampling overhead)</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p id="Par13">Although numerous recent studies have addressed aspects of feature compression and efficiency in federated and distributed environments, several gaps remain that motivate the present research. For instance, the approach in<sup><a href="#CR31" class="usa-link" aria-describedby="CR31">31</a></sup> proposes an autoencoder-based federated learning scheme for constrained IoT devices, but it lacks entropy-level control and exhibits limited adaptability to heterogeneous data distributions. Similarly, while<sup><a href="#CR32" class="usa-link" aria-describedby="CR32">32</a></sup> explores compressive techniques under noise and imbalance, it predominantly relies on heuristic sampling strategies and omits compactness at the bit level. In contrast,<sup><a href="#CR33" class="usa-link" aria-describedby="CR33">33</a></sup> presents an energy-aware FL scheme optimised for client-side deployment, yet the encoder-decoder structure requires high-precision floating-point operations, restricting its applicability in low-power hardware. Furthermore, the method introduced in<sup><a href="#CR34" class="usa-link" aria-describedby="CR34">34</a></sup> integrates blockchain for secure edge learning but does not address the information bottleneck problem or compression trade-offs. Although<sup><a href="#CR35" class="usa-link" aria-describedby="CR35">35</a></sup> leverages ensemble pruning techniques to reduce overhead, it does not preserve latent space topology or feature-level relevance, which is essential for semantically aware representations. Moreover, the reinforcement-based approaches in<sup><a href="#CR36" class="usa-link" aria-describedby="CR36">36</a></sup> and<sup><a href="#CR37" class="usa-link" aria-describedby="CR37">37</a></sup> focus on dynamic task selection and attention-based encoding respectively, achieving moderate accuracy improvements but suffering from convergence issues and excessive memory footprints in embedded contexts. While<sup><a href="#CR38" class="usa-link" aria-describedby="CR38">38</a></sup> utilises hybrid FL schemes for video-based applications, it is not applicable to low-latency sensory environments. In<sup><a href="#CR39" class="usa-link" aria-describedby="CR39">39</a></sup>, entropy-regularised FL is proposed, yet it depends heavily on centralised tuning parameters and fails to maintain performance across variable client setups. Additionally, the studies in [,<sup><a href="#CR40" class="usa-link" aria-describedby="CR40">40</a>,<a href="#CR41" class="usa-link" aria-describedby="CR41">41</a></sup> either apply classical clustering, probabilistic neural representations, or watermarking for privacy, but none of them provide a unified mechanism to ensure compression ratio, semantic retention, and client-specific adaptation simultaneously. While each of the reviewed approaches contributes to various facets of efficient FL and encoding, their limitations highlight the need for an integrated mechanism that jointly ensures task relevance, semantic fidelity, and computational tractability at bit-level precision. Therefore, building upon the identified gaps, the present work proposes an adaptive, information-constrained feature encoding scheme that unifies variational and stochastic-Boolean compression under federated conditions with minimal reliance on post hoc filtering or handcrafted pipelines.</p>
<p id="Par14">In addition to the methodological limitations identified above, recent applied studies further underscore the real-world demand for effective information-constrained feature compression across critical domains. For example, in the context of autonomous vehicles,<sup><a href="#CR42" class="usa-link" aria-describedby="CR42">42</a></sup> applies hybrid convolutional frameworks for traffic sign recognition under bandwidth constraints, yet lacks bit-level compression or entropy control. Similarly,<sup><a href="#CR43" class="usa-link" aria-describedby="CR43">43</a></sup> uses vision-based structural health monitoring, highlighting the need for compact, task-relevant embeddings in latency-sensitive edge deployments. In the IoT security domain,<sup><a href="#CR44" class="usa-link" aria-describedby="CR44">44</a></sup> and<sup><a href="#CR45" class="usa-link" aria-describedby="CR45">45</a></sup> explore intrusion detection and feature selection using LSTM-based and statistical techniques respectively, but these approaches rely heavily on centralised architectures and do not incorporate semantic-preserving compression. Likewise,<sup><a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup> and<sup><a href="#CR47" class="usa-link" aria-describedby="CR47">47</a></sup> focus on energy prediction for smart buildings, where efficient feature representation plays a pivotal role in inference speed and transmission efficiency, though entropy regularisation is not addressed. In healthcare,<sup><a href="#CR48" class="usa-link" aria-describedby="CR48">48</a></sup> present deep learning-based solutions for Alzheimer’s detection and elderly care respectively, yet these models typically involve dense parameterisations unsuitable for bandwidth-limited or privacy-sensitive environments. Furthermore,<sup><a href="#CR49" class="usa-link" aria-describedby="CR49">49</a></sup> proposes a deep model for earthquake damage prediction, again without considering adaptive feature compression or decentralised inference. While these studies collectively affirm the pressing relevance of efficient and semantically aware representations in real-world applications, they do not offer an integrated, entropy-constrained compression mechanism applicable across heterogeneous deployment contexts. The present work aims to address this unmet need.</p>
<p id="Par15">Despite notable progress in entropy-aware compression and task-oriented feature selection, existing solutions often treat these dimensions independently or rely on rigid, non-adaptive mechanisms. To the best of my knowledge, no prior work offers a unified framework that jointly optimises entropy, semantic fidelity, and deployment resilience under communication constraints. This methodological gap motivates the development of the proposed adaptive information-constrained mapping approach detailed in Sect. “<a href="#Sec5" class="usa-link">Models and methods</a>”.</p></section><section id="Sec4"><h2 class="pmc_sec_title">Main attributes of the research</h2>
<p id="Par16">The objective of this study is the process of entropy-constrained feature compression and reconstruction in resource-limited distributed intelligent systems, which involves stochastic-regularised transformation of the feature space to preserve semantic informativeness during data transmission and recovery.</p>
<p id="Par17">The subject of this study comprises variational-entropy methods for constructing information-constrained representations of the feature space, in particular projection-gradient optimisation strategies and stochastic-regularised binary projectors, which enable analytical modelling of the trade-off between reconstruction accuracy and entropy compactness and formed the basis for the theoretical conclusions and scientific contribution of the research.</p>
<p id="Par18">The aim of this study is to enhance the efficiency of feature compression in distributed intelligent systems, particularly in Edge AI and Federated Learning environments, by developing entropy-regularised methods for feature space transformation that reduce information loss, improve the semantic consistency of reconstruction, and ensure adaptability to constraints in bandwidth, energy consumption, and fragmentation of input data.</p>
<p id="Par19">To achieve the stated aim, the following key research objectives were defined:</p>
<ol class="list" style="list-style-type:decimal">
<li><p id="Par20">To develop a variational model of entropy-constrained feature compression that enables sequential formation of a latent representation, its selection, and reconstruction while preserving semantic consistency.</p></li>
<li><p id="Par21">To formulate a generalised compression quality functional that integrates information divergence and entropy capacity criteria, and to define a minimisation strategy under orthant constraints.</p></li>
<li><p id="Par22">To design a stochastic-regularised approach to Boolean projection that enables entropy-controlled compression in environments with limited bit-depth.</p></li>
<li><p id="Par23">To construct computational algorithms for the implementation of both approaches, adapted to resource-constrained Edge AI architectures and capable of operating under unstable QoS conditions.</p></li>
<li><p id="Par24">To conduct experimental evaluation of the trade-off between reconstruction accuracy and compression rate, as well as the impact of entropy regularisation parameters on recovery quality.</p></li>
<li><p id="Par25">To perform a comparative analysis of the proposed methods against current SOTA solutions, considering classification accuracy, entropy efficiency, computational complexity, and adaptability to heterogeneous data.</p></li>
</ol>
<p id="Par26">The main scientific contributions of this study are as follows:</p>
<ol class="list" style="list-style-type:decimal">
<li><p id="Par27">A unified entropy-regularised feature compression model is proposed, combining variational optimisation with orthant-constrained projection and a stochastic-Boolean transformation scheme. Unlike existing SOTA solutions (EDS-FL, FedEntropy, SER), this model ensures the preservation of semantic informativeness under constraints on bandwidth, energy consumption, and bit-depth.</p></li>
<li><p id="Par28">A novel compression quality functional is formulated, integrating directed Kullback–Leibler divergence and entropy perturbation into a single optimisation criterion. Efficient projection-gradient algorithms have been developed for both continuous and discrete (Boolean) representations, enabling adaptive compression under conditions of heterogeneity, noise, and unstable QoS.</p></li>
<li><p id="Par29">Empirical testing on the HAR and PAMAP2 datasets confirmed the practical effectiveness of the approach in edge/federated environments. The proposed methods achieve high classification accuracy while reducing entropy load by up to eightfold, demonstrating stable performance on low-power devices (Jetson Nano, Raspberry Pi 4), robustness to noise and data loss, and superiority over contemporary counterparts in terms of reconstruction accuracy and resource efficiency.</p></li>
</ol>
<p id="Par30">The structure of the article is organised as follows:</p>
<ul class="list" style="list-style-type:disc">
<li><p id="Par31">Secting “<a href="#Sec5" class="usa-link">Models and methods</a>” presents the theoretical foundation and algorithmic principles of the proposed approach.</p></li>
<li><p id="Par32">Secting “<a href="#Sec6" class="usa-link">Variational design of stochastic feature encoders</a>” formulates a variational feature compression model based on a two-stage latent transformation followed by reconstruction under orthant constraints. A generalised compression quality functional is introduced, combining directed Kullback–Leibler divergence and entropy perturbation. A projection-gradient minimisation algorithm is proposed, designed for resource-constrained environments.</p></li>
<li><p id="Par33">Secting “<a href="#Sec7" class="usa-link">Bit-level compression with entropy-driven selection</a>” develops an alternative stochastic-Boolean strategy for entropy compression, based on the generation of binary projectors using Lagrangian regularisation. An analytical formula is derived for selecting the optimal configuration, taking into account entropy compactness and the information budget.</p></li>
<li><p id="Par34">Section “<a href="#Sec8" class="usa-link">Results</a>” details the experimental methodology. It describes the datasets used (UCI HAR, PAMAP2), procedures for generating heterogeneous non-IID distributions, simulating noise and partial feature loss. Hardware constraints on Jetson Nano and Raspberry Pi 4 devices are modelled. Baseline methods (EDS-FL, FedEntropy, SER) are presented, and a full set of metrics is defined: classification accuracy, entropy complexity variation, inference delay, memory load, and energy consumption.</p></li>
<li><p id="Par35">Sect. 4 presents the experimental results and their analysis. The ability of both proposed strategies to achieve a balance between reconstruction accuracy and the degree of feature compression is demonstrated. The effectiveness of the models under varying levels of entropy regularisation and the λ parameter is shown. Particular attention is given to the robustness of the proposed approaches to data heterogeneity, noise, and channel instability in Edge AI and Federated Learning scenarios.</p></li>
</ul></section><section id="Sec5"><h2 class="pmc_sec_title">Models and methods</h2>
<p id="Par36">To enable effective feature compression under the constraints of decentralised environments, the proposed approach combines two complementary strategies: (i) a variational entropy-regularised projection method and (ii) a stochastic Boolean projection mechanism optimised for bit-limited transmission. The first strategy, detailed in Sect. “<a href="#Sec6" class="usa-link">Variational design of stochastic feature encoders</a>”, constructs a two-stage linear transformation and reconstruction pipeline governed by a variational optimisation functional that incorporates directed Kullback–Leibler divergence and entropy deviation. The second strategy, developed in Sect. “<a href="#Sec7" class="usa-link">Bit-level compression with entropy-driven selection</a>”, employs entropy-weighted selection over a finite set of binary projection matrices to generate compact representations without the need for backpropagation or gradient computation. This integrated design supports adaptive deployment across a variety of Edge AI and Federated Learning scenarios, accommodating diverse limitations in bandwidth, energy availability, and computational resources.</p></section><section id="Sec6"><h2 class="pmc_sec_title">Variational design of stochastic feature encoders</h2>
<p id="Par37">In many tasks involving distributed intelligent data processing, particularly in systems such as Edge AI and Federated Learning, the input information is received in the form of rectangular state matrices <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq4"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c62e78e0bda0/d33e697.gif" loading="lazy" id="d33e697" alt="Inline graphic"></span>, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq5"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/8c6f618fcae1/d33e703.gif" loading="lazy" id="d33e703" alt="Inline graphic"></span> denotes the number of local observations (e.g. sensor monitoring sessions or traffic packets), and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq6"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0c895e9af837/d33e709.gif" loading="lazy" id="d33e709" alt="Inline graphic"></span> represents the dimensionality of the original feature space. A typical example includes multichannel time series collected on resource-constrained end devices (smart sensors, IoT agents, or base stations such as eNB or gNB).</p>
<p id="Par38">Given the constraints of bandwidth, energy budget, or privacy policy, it becomes necessary to transform <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq7"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0e70af7e27d8/d33e717.gif" loading="lazy" id="d33e717" alt="Inline graphic"></span> into a reduced representation <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq8"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1a1702dc35c1/d33e723.gif" loading="lazy" id="d33e723" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq9"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1addc3e1fd42/d33e729.gif" loading="lazy" id="d33e729" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq10"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c6f4cc78d865/d33e735.gif" loading="lazy" id="d33e735" alt="Inline graphic"></span>, suitable for further use in a global model or aggregation module. This transformation may involve a reduction in the number of instances <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq11"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1366073af62f/d33e741.gif" loading="lazy" id="d33e741" alt="Inline graphic"></span> as well as compression of feature dimensionality <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq12"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/10c81be4a07d/d33e748.gif" loading="lazy" id="d33e748" alt="Inline graphic"></span>, while preserving the informational essence of the data stream.</p>
<p id="Par39">In a federated learning environment with data transmission over unstable channels (e.g. NB-IoT or URLLC), effective local compression requires the construction of a two-stage mapping aimed at preserving semantic completeness during compressed transmission. Formally, this is achieved through a sequential two-stage transformation.</p>
<p id="Par40">In the first stage of direct information-constrained encoding, the input data matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq13"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0e70af7e27d8/d33e758.gif" loading="lazy" id="d33e758" alt="Inline graphic"></span> is mapped to an intermediate latent representation <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq14"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/19504a876d57/d33e764.gif" loading="lazy" id="d33e764" alt="Inline graphic"></span>, followed by transformation into a compressed format <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq15"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1e5e37ce8530/d33e770.gif" loading="lazy" id="d33e770" alt="Inline graphic"></span> according to procedure</p>
<table class="disp-formula p" id="Equ1"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1f78f9b818ec/d33e776.gif" loading="lazy" id="d33e776" alt="graphic file with name d33e776.gif"></td>
<td class="label">1</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq16"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/4b14b0f33944/d33e783.gif" loading="lazy" id="d33e783" alt="Inline graphic"></span> denotes the feature mapping matrix, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq17"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/13e5513b94ae/d33e790.gif" loading="lazy" id="d33e790" alt="Inline graphic"></span> is an adaptive selection matrix dependent on the parameter <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq18"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/61c6e424cbc5/d33e796.gif" loading="lazy" id="d33e796" alt="Inline graphic"></span>, which characterises traffic priority or the current level of QoS.</p>
<p id="Par41">The reverse reconstruction stage of the original structure, for example at a cloud aggregation node, is carried out in two steps:</p>
<table class="disp-formula p" id="Equ2"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/69d9e1b26ed0/d33e804.gif" loading="lazy" id="d33e804" alt="graphic file with name d33e804.gif"></td>
<td class="label">2</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq19"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/e408709bfb06/d33e811.gif" loading="lazy" id="d33e811" alt="Inline graphic"></span> is the decoding matrix subject to a semantic deviation constraint, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq20"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/cf0d439fa7ed/d33e817.gif" loading="lazy" id="d33e817" alt="Inline graphic"></span> is the spatial scale restoration operator. The intermediate result <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq21"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/e76e71ec2d38/d33e823.gif" loading="lazy" id="d33e823" alt="Inline graphic"></span> contains the reconstructed features for the selected subset of instances and acts as a latent informational core, from which the full-scale approximation <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq22"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/d1de6ecfda12/d33e829.gif" loading="lazy" id="d33e829" alt="Inline graphic"></span> is formed. This approximation is then used either during the global model generalisation phase or as input to the backward flow in the iterative optimisation cycle.</p>
<p id="Par42">The projection operators <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq23"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/2d73211426c9/d33e837.gif" loading="lazy" id="d33e837" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq24"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/b4725ea70feb/d33e843.gif" loading="lazy" id="d33e843" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq25"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/42156568abf5/d33e849.gif" loading="lazy" id="d33e849" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq26"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/fb6f7bd58ab9/d33e855.gif" loading="lazy" id="d33e855" alt="Inline graphic"></span> are integral components of the coherent mechanism for information-constrained compression and reconstruction. All these matrices are assumed to be <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq27"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0fbc1009e638/d33e861.gif" loading="lazy" id="d33e861" alt="Inline graphic"></span>-defined, which aligns with the physical nature of features in the preprocessing of telemetry streams.</p>
<p id="Par43">According to Eqs. (<a href="#Equ1" class="usa-link">1</a>) and (<a href="#Equ2" class="usa-link">2</a>), the reconstructed representation <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq28"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/5fecfae534d8/d33e875.gif" loading="lazy" id="d33e875" alt="Inline graphic"></span> can be expressed as a composition of four interdependent transformations:</p>
<table class="disp-formula p" id="Equ3"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/6d2443993757/d33e881.gif" loading="lazy" id="d33e881" alt="graphic file with name d33e881.gif"></td>
<td class="label">3</td>
</tr></table>
<p id="Par44">Equation (<a href="#Equ3" class="usa-link">3</a>) generalises the full encoding–decoding cycle under conditions of limited resource availability: from local latent feature formation to their unfolding in the reconstructed space. The use of nested parentheses in (3) indicates a hierarchical sequence of operations: first, linearised feature compression; next, reduction of instance dimensionality according to the τ-dependent policy; and only then, feature recovery and spatial structure reconstruction. Accordingly, the transformation <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq29"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/e1088fb7fcc8/d33e892.gif" loading="lazy" id="d33e892" alt="Inline graphic"></span> maps the space of real-world measurements to a reconstructed feature space that is maximally aligned with the original, while taking into account constraints on channel bandwidth, stream priority, and transmission cost.</p>
<p id="Par45">To provide an analytical description of compression and reconstruction at the matrix element level, we employ expanded formulas for the corresponding components. Each element of the latent representation matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq30"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1e5e37ce8530/d33e900.gif" loading="lazy" id="d33e900" alt="Inline graphic"></span>, formed as a result of adaptive filtering and feature encoding, is computed according to rule.</p>
<table class="disp-formula p" id="Equ4"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/643ef492e535/d33e906.gif" loading="lazy" id="d33e906" alt="graphic file with name d33e906.gif"></td>
<td class="label">4</td>
</tr></table>
<p id="Par46">where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq31"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/774da9b87681/d33e914.gif" loading="lazy" id="d33e914" alt="Inline graphic"></span> reflects the selection of instances based on the QoS policy at time <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq32"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/391609a27f82/d33e920.gif" loading="lazy" id="d33e920" alt="Inline graphic"></span>, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq33"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/4bb2c13bfeb5/d33e926.gif" loading="lazy" id="d33e926" alt="Inline graphic"></span> denotes the weighting coefficients of feature compression.</p>
<p id="Par47">The reconstructed values <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq34"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/5fecfae534d8/d33e935.gif" loading="lazy" id="d33e935" alt="Inline graphic"></span>, which approximate the original data, are obtained through a four-level summation convolution.</p>
<table class="disp-formula p" id="Equ5"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a6e0f889ac5d/d33e941.gif" loading="lazy" id="d33e941" alt="graphic file with name d33e941.gif"></td>
<td class="label">5</td>
</tr></table>
<p id="Par48">where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq35"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/6da3bcb82318/d33e949.gif" loading="lazy" id="d33e949" alt="Inline graphic"></span> are the spatial reconstruction weights at the instance level; <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq36"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/51e145ded88d/d33e955.gif" loading="lazy" id="d33e955" alt="Inline graphic"></span> are the decoding coefficients for transitioning from the latent space to the reconstructed features; and the nested summations implement gradual reconstruction across all levels: from features, through the latent space, to the global approximation. Formula (<a href="#Equ5" class="usa-link">5</a>) not only guarantees the non-negativity of the output matrix but also preserves structural similarity to the original, even under variable compression policy selection.</p>
<p id="Par49">To quantitatively control the degree of divergence between the reconstructed representation <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq37"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/5fecfae534d8/d33e966.gif" loading="lazy" id="d33e966" alt="Inline graphic"></span> and the original input profile <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq38"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0e70af7e27d8/d33e972.gif" loading="lazy" id="d33e972" alt="Inline graphic"></span>, it is appropriate to apply a directed information divergence metric that accounts for both the amplitude of deviation and its logarithmic structure. This measure is defined by the functional</p>
<table class="disp-formula p" id="Equ6"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/ebd08722a1b7/d33e978.gif" loading="lazy" id="d33e978" alt="graphic file with name d33e978.gif"></td>
<td class="label">6</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq39"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/ffe4a46a5202/d33e985.gif" loading="lazy" id="d33e985" alt="Inline graphic"></span> are the reconstructed intensities, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq40"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/24c9585c654b/d33e991.gif" loading="lazy" id="d33e991" alt="Inline graphic"></span> are the corresponding reference values obtained at the system input, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq41"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a3c5dcc85fa0/d33e998.gif" loading="lazy" id="d33e998" alt="Inline graphic"></span> is the cell-wise contribution to the overall divergence.</p>
<p id="Par50">By substituting into (6) the reconstruction structure <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq42"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/5fecfae534d8/d33e1006.gif" loading="lazy" id="d33e1006" alt="Inline graphic"></span> defined via (3), we obtain that the value <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq43"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c647259f16d7/d33e1012.gif" loading="lazy" id="d33e1012" alt="Inline graphic"></span> is a functional of the spatial-feature mapping parameters</p>
<table class="disp-formula p" id="Equ7"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/69865b5ad42c/d33e1018.gif" loading="lazy" id="d33e1018" alt="graphic file with name d33e1018.gif"></td>
<td class="label">7</td>
</tr></table>
<p>which allows the configuration of the matrices <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq44"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/2d73211426c9/d33e1025.gif" loading="lazy" id="d33e1025" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq45"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/b4725ea70feb/d33e1031.gif" loading="lazy" id="d33e1031" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq46"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/42156568abf5/d33e1038.gif" loading="lazy" id="d33e1038" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq47"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/fb6f7bd58ab9/d33e1044.gif" loading="lazy" id="d33e1044" alt="Inline graphic"></span> to be treated as a variational optimisation problem over the set of information-admissible compressors in distributed learning systems. In particular, under scenarios with restricted access to raw data (such as federated edge processing), the divergence (7) serves as the sole source for estimating loss resulting from local mapping.</p>
<p id="Par51">A significant criterion for the effectiveness of systemic compression in a distributed environment is the reduction of the entropy-based capacity of the compressed representation <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq48"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1e5e37ce8530/d33e1052.gif" loading="lazy" id="d33e1052" alt="Inline graphic"></span> in comparison to the original input profile <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq49"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0e70af7e27d8/d33e1058.gif" loading="lazy" id="d33e1058" alt="Inline graphic"></span>. This capacity, interpreted as a conditional measure of informational load in the compression channel, is defined via the logarithmic norm with a normalisation term reflecting the encoding volume. In the entropy-based formalism, the capacity of representations is defined as</p>
<table class="disp-formula p" id="Equ8"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/17428888581d/d33e1064.gif" loading="lazy" id="d33e1064" alt="graphic file with name d33e1064.gif"></td>
<td class="label">8</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq50"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/05643e46e728/d33e1071.gif" loading="lazy" id="d33e1071" alt="Inline graphic"></span> are the reconstructed values in the compressed representation formed according to the operators <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq51"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/2d73211426c9/d33e1077.gif" loading="lazy" id="d33e1077" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq52"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/b4725ea70feb/d33e1084.gif" loading="lazy" id="d33e1084" alt="Inline graphic"></span>; the term <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq53"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/5942c7ce1577/d33e1090.gif" loading="lazy" id="d33e1090" alt="Inline graphic"></span> is a conditional normalisation component reflecting the structural cost of compression.</p>
<p id="Par52">Similarly, the initial capacity of the informational space is defined as</p>
<table class="disp-formula p" id="Equ9"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/b8a056ee879a/d33e1098.gif" loading="lazy" id="d33e1098" alt="graphic file with name d33e1098.gif"></td>
<td class="label">9</td>
</tr></table>
<p id="Par53">In an applied sense, the reduction of <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq54"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/4f139df3ed10/d33e1106.gif" loading="lazy" id="d33e1106" alt="Inline graphic"></span> relative to <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq55"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/4bda4e5a9da6/d33e1112.gif" loading="lazy" id="d33e1112" alt="Inline graphic"></span> indicates the effectiveness of the reduction procedure: lower capacity implies reduced transmission requirements while preserving the semantic essence of the data. In distributed computations (for instance, in systems with 5G/URLLC characteristics), such a difference directly correlates with the energy budget savings of the nodes.</p>
<p id="Par54">To formalise the difference between the entropy-based capacities of the compressed and original representations, we introduce the quadratic functional of energy deviation</p>
<table class="disp-formula p" id="Equ10"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/f6d42adb41a0/d33e1120.gif" loading="lazy" id="d33e1120" alt="graphic file with name d33e1120.gif"></td>
<td class="label">10</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq56"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/f5859bae94d0/d33e1127.gif" loading="lazy" id="d33e1127" alt="Inline graphic"></span> is a normalising constant that reflects the initial informational capacity in a modified form.</p>
<p id="Par55">Proceeding to the global functional of compression quality, we construct the generalised variational criterion</p>
<table class="disp-formula p" id="Equ11"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/39cb1ca38706/d33e1135.gif" loading="lazy" id="d33e1135" alt="graphic file with name d33e1135.gif"></td>
<td class="label">11</td>
</tr></table>
<p>where the first term represents the informational mismatch functional according to (7), and the second term corresponds to the entropy-induced perturbation of the reconstruction capacity (10). Thus, the optimisation task reduces to identifying nonlinearly-oriented projectors with non-negative values that minimise the functional <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq57"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c239952043cb/d33e1142.gif" loading="lazy" id="d33e1142" alt="Inline graphic"></span>:</p>
<table class="disp-formula p" id="Equ12"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/b3f634b83b7c/d33e1148.gif" loading="lazy" id="d33e1148" alt="graphic file with name d33e1148.gif"></td>
<td class="label">12</td>
</tr></table>
<p id="Par56">In Edge AI applications with local computations, this enables the construction of projection operators that simultaneously ensure energy efficiency, reconstruction consistency, and structural optimality.</p>
<p id="Par57">The minimisation of functional (12) constitutes a variational optimisation problem under a negative orthant constraint. To solve it, we employ a projected gradient strategy, having first converted all matrices into their vectorised form.</p>
<p id="Par58">We introduce block vectors <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq58"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/3624fe898229/d33e1161.gif" loading="lazy" id="d33e1161" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq59"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/be85c84c6001/d33e1167.gif" loading="lazy" id="d33e1167" alt="Inline graphic"></span> of dimension <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq60"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/259bedf92071/d33e1173.gif" loading="lazy" id="d33e1173" alt="Inline graphic"></span>, where the subvectors correspond to the vectorisation results of the projectors <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq61"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/2d73211426c9/d33e1179.gif" loading="lazy" id="d33e1179" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq62"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/b4725ea70feb/d33e1185.gif" loading="lazy" id="d33e1185" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq63"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/42156568abf5/d33e1192.gif" loading="lazy" id="d33e1192" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq64"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/fb6f7bd58ab9/d33e1198.gif" loading="lazy" id="d33e1198" alt="Inline graphic"></span>, respectively. Formally, problem (12) can be rewritten as</p>
<table class="disp-formula p" id="Equ13"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/cb7ba31fae67/d33e1204.gif" loading="lazy" id="d33e1204" alt="graphic file with name d33e1204.gif"></td>
<td class="label">13</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq65"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0c5598f099b3/d33e1211.gif" loading="lazy" id="d33e1211" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq66"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/b292fd03c0a9/d33e1217.gif" loading="lazy" id="d33e1217" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq67"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c91f3a07bb0f/d33e1223.gif" loading="lazy" id="d33e1223" alt="Inline graphic"></span>; the vector <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq68"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a48486f338ba/d33e1230.gif" loading="lazy" id="d33e1230" alt="Inline graphic"></span> is the result of vectorising the matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq69"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0e70af7e27d8/d33e1236.gif" loading="lazy" id="d33e1236" alt="Inline graphic"></span>; <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq70"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/60ce572e6cfa/d33e1242.gif" loading="lazy" id="d33e1242" alt="Inline graphic"></span> is a vector of dimension <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq71"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/82bcffb99ce5/d33e1248.gif" loading="lazy" id="d33e1248" alt="Inline graphic"></span>, formed by the components <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq72"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/29709bd25b57/d33e1254.gif" loading="lazy" id="d33e1254" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq73"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/76d13d7158bc/d33e1260.gif" loading="lazy" id="d33e1260" alt="Inline graphic"></span>; <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq74"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/2923951ca13d/d33e1267.gif" loading="lazy" id="d33e1267" alt="Inline graphic"></span> is a vector of dimension <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq75"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/f6b9b90b70e6/d33e1273.gif" loading="lazy" id="d33e1273" alt="Inline graphic"></span>, formed by the components <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq76"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/ff359cbd3afa/d33e1279.gif" loading="lazy" id="d33e1279" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq77"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/e6ceb4065461/d33e1285.gif" loading="lazy" id="d33e1285" alt="Inline graphic"></span>. Formulation (13) enables the application of efficient constrained optimisation methods within Edge AI architectures with strict limitations on computation and memory, ensuring a balance between reconstruction accuracy and entropy-efficient compression.</p>
<p id="Par59">It should be noted that expressions (<a href="#Equ4" class="usa-link">4</a>) and (<a href="#Equ5" class="usa-link">5</a>) perform compression and reconstruction operations at the element level; however, only in conjunction with criterion (12) do they provide guarantees regarding the preservation of informational completeness. Specifically, the optimisation functional <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq78"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c239952043cb/d33e1299.gif" loading="lazy" id="d33e1299" alt="Inline graphic"></span>, defined in (11), integrates two complementary components: the informational deviation <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq79"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1e5e37ce8530/d33e1305.gif" loading="lazy" id="d33e1305" alt="Inline graphic"></span>, which measures the degree of divergence between the reconstructed and original data (using directed KL-divergence), and the energy-induced perturbation <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq80"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/ef3b0f712463/d33e1311.gif" loading="lazy" id="d33e1311" alt="Inline graphic"></span>, which captures deviations in entropy-based capacity during compression. This construction allows not only for a quantitative evaluation of reconstruction quality but also for control over its behaviour under varying entropy levels or fixed informational budget constraints. In other words, even when the volume of transmitted information is reduced (through compression), the optimised functional <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq81"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c239952043cb/d33e1318.gif" loading="lazy" id="d33e1318" alt="Inline graphic"></span> ensures the preservation of structural consistency between the spaces <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq82"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0e70af7e27d8/d33e1324.gif" loading="lazy" id="d33e1324" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq83"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/5fecfae534d8/d33e1330.gif" loading="lazy" id="d33e1330" alt="Inline graphic"></span> at the level of feature distribution topology.</p>
<p id="Par60">To numerically solve the variational problem (13), we apply a component-wise modification of the projected gradient method. In the parallel configuration, the vector <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq84"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/3624fe898229/d33e1338.gif" loading="lazy" id="d33e1338" alt="Inline graphic"></span> accumulates the parameters of the compression matrices <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq85"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/2d73211426c9/d33e1344.gif" loading="lazy" id="d33e1344" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq86"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c3cb36a522ff/d33e1350.gif" loading="lazy" id="d33e1350" alt="Inline graphic"></span>, which are responsible for transforming data along the feature space. The vector <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq87"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/be85c84c6001/d33e1356.gif" loading="lazy" id="d33e1356" alt="Inline graphic"></span>, in turn, contains the components of the reconstruction matrices <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq88"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/42156568abf5/d33e1362.gif" loading="lazy" id="d33e1362" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq89"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/fb6f7bd58ab9/d33e1369.gif" loading="lazy" id="d33e1369" alt="Inline graphic"></span>, which perform compression along the second dimension. This separation of variables is appropriate for implementing component-wise optimisation, as it allows for the independent computation of partial gradient directions in the orthant space under non-negativity constraints.</p>
<p id="Par61">The iterative scheme of the component-wise projected gradient method consists of two phases: in the first phase, the vector <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq90"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/3624fe898229/d33e1377.gif" loading="lazy" id="d33e1377" alt="Inline graphic"></span> is updated according to the direction of the negative gradient of the functional <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq91"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/6f4e4b6757c4/d33e1383.gif" loading="lazy" id="d33e1383" alt="Inline graphic"></span>; in the second phase, the gradient projection with respect to the variable <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq92"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/be85c84c6001/d33e1389.gif" loading="lazy" id="d33e1389" alt="Inline graphic"></span> is computed. Let the corresponding partial gradients be denoted as <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq93"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/8988eb2812c4/d33e1395.gif" loading="lazy" id="d33e1395" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq94"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/24a9cafdaa27/d33e1401.gif" loading="lazy" id="d33e1401" alt="Inline graphic"></span>. The algorithm for variational minimisation of the functional <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq95"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c239952043cb/d33e1408.gif" loading="lazy" id="d33e1408" alt="Inline graphic"></span> over the non-orthant set follows the stepwise structure:</p>
<p id="Par62">0. Initialisation: <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq96"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/ae0a81a28221/d33e1416.gif" loading="lazy" id="d33e1416" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq97"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/84355ef0b56a/d33e1422.gif" loading="lazy" id="d33e1422" alt="Inline graphic"></span>.</p>
<ol class="list" style="list-style-type:decimal">
<li>
<p id="Par63"> The <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq98"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a086866e2160/d33e1436.gif" loading="lazy" id="d33e1436" alt="Inline graphic"></span>-th iteration.</p>
<p id="Par64">Compute the reconstructed matrix: <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq99"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/45567abfba2a/d33e1444.gif" loading="lazy" id="d33e1444" alt="Inline graphic"></span>.</p>
<p id="Par65">Evaluate the functional: <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq100"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/4d6226280209/d33e1452.gif" loading="lazy" id="d33e1452" alt="Inline graphic"></span>.</p>
<div class="p" id="Par66">Update the compression parameter vector:<table class="disp-formula p" id="Equa"><tr><td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/ee0139717b67/d33e1460.gif" loading="lazy" id="d33e1460" alt="graphic file with name d33e1460.gif"></td></tr></table>which corresponds to updating the parameters of the projectors <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq101"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c98f1dba50e3/d33e1466.gif" loading="lazy" id="d33e1466" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq102"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/7c257bddaf72/d33e1472.gif" loading="lazy" id="d33e1472" alt="Inline graphic"></span> , with the introduction of a step size coefficient <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq103"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a55371e4d928/d33e1478.gif" loading="lazy" id="d33e1478" alt="Inline graphic"></span> for the compression block.</div>
<div class="p" id="Par67">Update the reconstruction weight vector:<table class="disp-formula p" id="Equb"><tr><td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/99fd6cc951d8/d33e1486.gif" loading="lazy" id="d33e1486" alt="graphic file with name d33e1486.gif"></td></tr></table>which is equivalent to updating the parameters of the reconstruction matrices <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq104"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a4943c8c600e/d33e1492.gif" loading="lazy" id="d33e1492" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq105"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/882c1c9d2274/d33e1498.gif" loading="lazy" id="d33e1498" alt="Inline graphic"></span>, with the introduction of a step size coefficient <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq106"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/596881dff3f9/d33e1504.gif" loading="lazy" id="d33e1504" alt="Inline graphic"></span> for the reconstruction block.</div>
<p id="Par68">Update the reconstruction: <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq107"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/f663d6b2fdd2/d33e1512.gif" loading="lazy" id="d33e1512" alt="Inline graphic"></span>.</p>
<p id="Par69">Re-evaluate the functional: <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq108"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/9413b7065c79/d33e1520.gif" loading="lazy" id="d33e1520" alt="Inline graphic"></span>.</p>
</li>
<li>
<p id="Par70"> Stopping criterion. If <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq109"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/88f26656184b/d33e1531.gif" loading="lazy" id="d33e1531" alt="Inline graphic"></span>, the algorithm terminates. Here, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq110"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/49ebefc0c223/d33e1537.gif" loading="lazy" id="d33e1537" alt="Inline graphic"></span> is the acceptable threshold for stochastic stability of the functional, setting the minimum significance level for continuing the optimisation; the choice of this parameter may depend on QoS constraints or the allowable error level in decentralised scenarios.</p>
<p id="Par71">In the proposed variational compression-with-reconstruction scheme (formulas (<a href="#Equ1" class="usa-link">1</a>)–(<a href="#Equ2" class="usa-link">13</a>)), the iterative minimisation of the functional Λ is performed in the orthant space under non-negativity constraints. The main computational complexity of a single optimisation step is determined by the dominant operation—the multiplication of <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq111"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/baa266dcb1d8/d33e1551.gif" loading="lazy" id="d33e1551" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq112"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/acf8727e0749/d33e1557.gif" loading="lazy" id="d33e1557" alt="Inline graphic"></span>, which form the reconstructed matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq113"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/5fecfae534d8/d33e1563.gif" loading="lazy" id="d33e1563" alt="Inline graphic"></span>. For matrices of dimensions <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq114"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/314243d32c7c/d33e1570.gif" loading="lazy" id="d33e1570" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq115"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c97f48b98009/d33e1576.gif" loading="lazy" id="d33e1576" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq116"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/ee0477e75ecd/d33e1582.gif" loading="lazy" id="d33e1582" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq117"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/8e555749fc2f/d33e1588.gif" loading="lazy" id="d33e1588" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq118"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/ca3e5ba17f03/d33e1594.gif" loading="lazy" id="d33e1594" alt="Inline graphic"></span>, the corresponding computations have complexity <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq119"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/6610f7ae830b/d33e1600.gif" loading="lazy" id="d33e1600" alt="Inline graphic"></span>. Gradient updates for <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq120"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/3624fe898229/d33e1607.gif" loading="lazy" id="d33e1607" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq121"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/be85c84c6001/d33e1613.gif" loading="lazy" id="d33e1613" alt="Inline graphic"></span> are performed via partial derivatives and involve comparatively lower complexity <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq122"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1fc718d226fe/d33e1619.gif" loading="lazy" id="d33e1619" alt="Inline graphic"></span>. In most practical scenarios, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq123"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/3fdbebfa2bc9/d33e1625.gif" loading="lazy" id="d33e1625" alt="Inline graphic"></span>, the computational load remains moderate even for edge implementations. Empirical evidence shows that the algorithm converges within 50–150 iterations, while the orthant constraints and entropy-based regularisation ensure robustness to initialisation.</p>
<p id="Par72">We conclude this subSect. by formalising the theoretical guarantees of convergence and robustness of the variational optimisation scheme (12)–(13) under QoS fluctuations. This optimisation scheme relies on a component-wise projected gradient method with orthant constraints. The target functional <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq124"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/8b2162b3a341/d33e1633.gif" loading="lazy" id="d33e1633" alt="Inline graphic"></span>, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq125"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a4228cc18280/d33e1639.gif" loading="lazy" id="d33e1639" alt="Inline graphic"></span> is the divergence component (7) and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq126"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/279b1ef1d6f5/d33e1645.gif" loading="lazy" id="d33e1645" alt="Inline graphic"></span> is the entropy deviation (10), is smoothly differentiable, bounded from below (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq127"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/ea04fbfd92a2/d33e1651.gif" loading="lazy" id="d33e1651" alt="Inline graphic"></span>), and defined on a finite-dimensional orthant subspace <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq128"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/97484776859b/d33e1657.gif" loading="lazy" id="d33e1657" alt="Inline graphic"></span>. Both components of the functional are (quasi-)convex with respect to their arguments when the data are fixed. Therefore, within the classical formulation of constrained nonsmooth optimisation<sup><a href="#CR50" class="usa-link" aria-describedby="CR50">50</a></sup>, convergence to a stationary point (in the sense of <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq129"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/77cca22b8738/d33e1668.gif" loading="lazy" id="d33e1668" alt="Inline graphic"></span>) is guaranteed under the conditions of gradient Lipschitz continuity and a fixed step size. In the context of stochastic stability, it is important to note that the functional <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq130"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/279b1ef1d6f5/d33e1674.gif" loading="lazy" id="d33e1674" alt="Inline graphic"></span> acts as a regulariser imposing a strict constraint on the entropy-based capacity of the compressed representation (8). Hence, under varying QoS (i.e. fluctuations in the parameter <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq131"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/61c6e424cbc5/d33e1680.gif" loading="lazy" id="d33e1680" alt="Inline graphic"></span> or perturbations in <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq132"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0e70af7e27d8/d33e1686.gif" loading="lazy" id="d33e1686" alt="Inline graphic"></span>) the variation in <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq133"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/279b1ef1d6f5/d33e1692.gif" loading="lazy" id="d33e1692" alt="Inline graphic"></span> remains smooth, and the overall functional <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq134"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/4422e0350a09/d33e1699.gif" loading="lazy" id="d33e1699" alt="Inline graphic"></span> does not exhibit discontinuous behaviour. This ensures that the stepwise dynamics of the algorithm remain stable even in the presence of partial data incompleteness, local noise, or entropy density fluctuations, which are typical of URLLC environments. Such noise resilience is achieved through the property that the gradients remain within the feasible subspace <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq135"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/97484776859b/d33e1705.gif" loading="lazy" id="d33e1705" alt="Inline graphic"></span>, where the minimum is both bounded and attainable. The stopping criterion defined as <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq136"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/41133a9f6ae2/d33e1711.gif" loading="lazy" id="d33e1711" alt="Inline graphic"></span> guarantees the termination of optimisation within the permissible entropy deviation <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq137"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a6b3f8e6e441/d33e1717.gif" loading="lazy" id="d33e1717" alt="Inline graphic"></span>, which can be adapted according to the QoS policy.</p>
</li>
</ol></section><section id="Sec7"><h2 class="pmc_sec_title">Bit-level compression with entropy-driven selection</h2>
<p id="Par73">Consider the input feature matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq138"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/62e74cc9fcfe/d33e1728.gif" loading="lazy" id="d33e1728" alt="Inline graphic"></span>. In the space <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq139"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a7833712e526/d33e1734.gif" loading="lazy" id="d33e1734" alt="Inline graphic"></span>, its rows correspond to the points of the set <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq140"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/00697c3ad6ad/d33e1740.gif" loading="lazy" id="d33e1740" alt="Inline graphic"></span>. Following the basic “instance–feature” interpretation, we assume that all these vectors represent a sample from a single class. This allows us to posit their topological compactness, that is, a small dispersion in the spatial distribution of features, which is essential for decentralised systems with local processing.</p>
<p id="Par74">To quantitatively analyse such compactness, we define the functional indicator of dispersion.</p>
<table class="disp-formula p" id="Equ14"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/333881f199b3/d33e1748.gif" loading="lazy" id="d33e1748" alt="graphic file with name d33e1748.gif"></td>
<td class="label">14</td>
</tr></table>
<p id="Par75">where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq141"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a39109d9bbb3/d33e1756.gif" loading="lazy" id="d33e1756" alt="Inline graphic"></span> is the metric function of inter-vector entropy-based distance. For instance, in systems with clustered characteristics, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq142"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/2c883d9c778f/d33e1762.gif" loading="lazy" id="d33e1762" alt="Inline graphic"></span> may incorporate both a Euclidean component and a weighting term that depends on QoS or the classification context.</p>
<p id="Par76">In the context of a randomised strategy for entropy-based data compression, the transformation of the primary matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq143"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/314243d32c7c/d33e1770.gif" loading="lazy" id="d33e1770" alt="Inline graphic"></span>, which contains feature values, is implemented via bidirectional entropy-regularised projection, forming a reduced representation <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq144"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a8148033c9aa/d33e1776.gif" loading="lazy" id="d33e1776" alt="Inline graphic"></span>, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq145"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1addc3e1fd42/d33e1782.gif" loading="lazy" id="d33e1782" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq146"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c6f4cc78d865/d33e1788.gif" loading="lazy" id="d33e1788" alt="Inline graphic"></span>, using left and right stochastic operators <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq147"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/93e481c4afda/d33e1794.gif" loading="lazy" id="d33e1794" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq148"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c97f48b98009/d33e1801.gif" loading="lazy" id="d33e1801" alt="Inline graphic"></span>: <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq149"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/04383b33715d/d33e1807.gif" loading="lazy" id="d33e1807" alt="Inline graphic"></span>. The operators <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq150"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c3cb36a522ff/d33e1813.gif" loading="lazy" id="d33e1813" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq151"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/2d73211426c9/d33e1819.gif" loading="lazy" id="d33e1819" alt="Inline graphic"></span> are random matrices with specified interval constraints <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq152"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/00b890177929/d33e1825.gif" loading="lazy" id="d33e1825" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq153"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/39a27a3c097f/d33e1831.gif" loading="lazy" id="d33e1831" alt="Inline graphic"></span>. The probability density <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq154"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/2d0e3b321606/d33e1838.gif" loading="lazy" id="d33e1838" alt="Inline graphic"></span> is defined on a compact support <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq155"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/e9f2e86d9b77/d33e1844.gif" loading="lazy" id="d33e1844" alt="Inline graphic"></span>, corresponding to the Cartesian product <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq156"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/21bb16283ed3/d33e1850.gif" loading="lazy" id="d33e1850" alt="Inline graphic"></span>. The derived values in the projection matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq157"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1e5e37ce8530/d33e1856.gif" loading="lazy" id="d33e1856" alt="Inline graphic"></span> are specified by a nonlinear convolution over all possible combinations of elements: <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq158"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/72c712dacf8c/d33e1862.gif" loading="lazy" id="d33e1862" alt="Inline graphic"></span>, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq159"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/7993c34692d7/d33e1868.gif" loading="lazy" id="d33e1868" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq160"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/210b773b36bb/d33e1875.gif" loading="lazy" id="d33e1875" alt="Inline graphic"></span>, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq161"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/e1633e3840c0/d33e1881.gif" loading="lazy" id="d33e1881" alt="Inline graphic"></span> is a smoothed entropy function that defines a nonlinear activation similar to a sigmoid or hyperbolic tangent (selected according to the traffic class or QoS mode). The introduction of <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq162"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/020274b3a072/d33e1887.gif" loading="lazy" id="d33e1887" alt="Inline graphic"></span> ensures adaptive nonlinearity in the transformation phase, which is critically important for compression tasks with partial loss, such as in Edge AI systems operating under URLLC modes.</p>
<p id="Par77">Similarly to expression (<a href="#Equ14" class="usa-link">14</a>), we introduce the compactness indicator for the transformed representation <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq163"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1e5e37ce8530/d33e1898.gif" loading="lazy" id="d33e1898" alt="Inline graphic"></span>, defined via the stochastic operators <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq164"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c3cb36a522ff/d33e1904.gif" loading="lazy" id="d33e1904" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq165"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/2d73211426c9/d33e1910.gif" loading="lazy" id="d33e1910" alt="Inline graphic"></span>, as the symmetrised entropic divergence between the rows:</p>
<table class="disp-formula p" id="Equ15"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/dbf0c6fb13b5/d33e1916.gif" loading="lazy" id="d33e1916" alt="graphic file with name d33e1916.gif"></td>
<td class="label">15</td>
</tr></table>
<p id="Par78">Since <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq166"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c3cb36a522ff/d33e1924.gif" loading="lazy" id="d33e1924" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq167"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/2d73211426c9/d33e1930.gif" loading="lazy" id="d33e1930" alt="Inline graphic"></span> are stochastically variable, the quantity (<a href="#Equ15" class="usa-link">15</a>) is a random variable. The expected value of this compactness characteristic is defined via the generalised functional</p>
<table class="disp-formula p" id="Equ16"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/14b963524acb/d33e1939.gif" loading="lazy" id="d33e1939" alt="graphic file with name d33e1939.gif"></td>
<td class="label">16</td>
</tr></table>
<p id="Par79">To estimate the posterior density distribution <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq168"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/573730d9e73c/d33e1947.gif" loading="lazy" id="d33e1947" alt="Inline graphic"></span>, we employ a variational entropy maximisation scheme</p>
<table class="disp-formula p" id="Equ17"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/f1548b97f477/d33e1953.gif" loading="lazy" id="d33e1953" alt="graphic file with name d33e1953.gif"></td>
<td class="label">17</td>
</tr></table>
<p>under the conditions <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq169"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/062a2c2723be/d33e1960.gif" loading="lazy" id="d33e1960" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq170"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/320864624d40/d33e1966.gif" loading="lazy" id="d33e1966" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq171"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/de0cf11d58b6/d33e1972.gif" loading="lazy" id="d33e1972" alt="Inline graphic"></span>, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq172"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/edd700580a15/d33e1979.gif" loading="lazy" id="d33e1979" alt="Inline graphic"></span> denotes the acceptable approximation level to the empirical indicator <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq173"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/d73530018c4a/d33e1985.gif" loading="lazy" id="d33e1985" alt="Inline graphic"></span>, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq174"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0b82a1a20e26/d33e1991.gif" loading="lazy" id="d33e1991" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq175"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/618f63844401/d33e1997.gif" loading="lazy" id="d33e1997" alt="Inline graphic"></span> are the parameters of the confidence interval for the randomised entropic compression.</p>
<p id="Par80">The problem of maximising the entropic functional (<a href="#Equ17" class="usa-link">17</a>) under the constraint of aligning the average pairwise divergence with the confidence indicator belongs to the class of stochastically constrained variational problems in the space of probability measures. The optimality conditions for such a problem are formulated in terms of the stationarity of the Lagrangian functional. To solve it, we consider an entropy-weighted variation of the form <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq176"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0b8899fc46c8/d33e2008.gif" loading="lazy" id="d33e2008" alt="Inline graphic"></span>, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq177"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a8bf8e16d93e/d33e2014.gif" loading="lazy" id="d33e2014" alt="Inline graphic"></span> is the scalar Lagrange multiplier, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq178"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/530bb5d715cd/d33e2020.gif" loading="lazy" id="d33e2020" alt="Inline graphic"></span> is the probability density function over the support of the projector matrices, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq179"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/96f00c9ed303/d33e2026.gif" loading="lazy" id="d33e2026" alt="Inline graphic"></span> is the instantaneous entropy function, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq180"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/7bebec5e2287/d33e2033.gif" loading="lazy" id="d33e2033" alt="Inline graphic"></span> is the expected value of the structural indicator from (14). The stationarity of the functional <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq181"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/6cee83f5ffe0/d33e2039.gif" loading="lazy" id="d33e2039" alt="Inline graphic"></span> with respect to <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq182"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/792eb41a8f8e/d33e2045.gif" loading="lazy" id="d33e2045" alt="Inline graphic"></span> yields the optimal distribution function.</p>
<table class="disp-formula p" id="Equ18"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a040d3ab9341/d33e2051.gif" loading="lazy" id="d33e2051" alt="graphic file with name d33e2051.gif"></td>
<td class="label">18</td>
</tr></table>
<p id="Par81">where the function <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq183"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/8de71945309f/d33e2059.gif" loading="lazy" id="d33e2059" alt="Inline graphic"></span> is defined by expression (<a href="#Equ14" class="usa-link">14</a>), and the normalisation <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq184"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1427a90ed393/d33e2068.gif" loading="lazy" id="d33e2068" alt="Inline graphic"></span> is given as <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq185"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/9905f5de8fd7/d33e2074.gif" loading="lazy" id="d33e2074" alt="Inline graphic"></span>. Accordingly, the multiplier <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq186"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a8bf8e16d93e/d33e2080.gif" loading="lazy" id="d33e2080" alt="Inline graphic"></span> is found from the consistency Equation</p>
<table class="disp-formula p" id="Equ19"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/401e06d50535/d33e2087.gif" loading="lazy" id="d33e2087" alt="graphic file with name d33e2087.gif"></td>
<td class="label">19</td>
</tr></table>
<p id="Par82">Thus, the entropy-consistent approximation (<a href="#Equ15" class="usa-link">15</a>) enables the generation of projector matrices via sampling that, on average, preserve intra-group compactness in terms of the divergence <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq187"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/8de71945309f/d33e2098.gif" loading="lazy" id="d33e2098" alt="Inline graphic"></span>, defined between the corresponding blocks of the matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq188"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1e5e37ce8530/d33e2104.gif" loading="lazy" id="d33e2104" alt="Inline graphic"></span>.</p>
<p id="Par83">We now proceed to the direct application of the defined entropy-regularised stochastic projections for feature dimension reduction. Consider the original data matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq189"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/62e74cc9fcfe/d33e2113.gif" loading="lazy" id="d33e2113" alt="Inline graphic"></span>, which must be transformed along the feature axis into a reduced space of dimensionality <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq190"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/10c81be4a07d/d33e2119.gif" loading="lazy" id="d33e2119" alt="Inline graphic"></span>. This operation is performed via right-sided contraction using the stochastic projector matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq191"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a8e29b7eef06/d33e2125.gif" loading="lazy" id="d33e2125" alt="Inline graphic"></span>, which yields the reduced feature matrix:</p>
<table class="disp-formula p" id="Equ20"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/e559863f9562/d33e2131.gif" loading="lazy" id="d33e2131" alt="graphic file with name d33e2131.gif"></td>
<td class="label">20</td>
</tr></table>
<p id="Par84">We assume that all elements of the input matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq192"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0e70af7e27d8/d33e2139.gif" loading="lazy" id="d33e2139" alt="Inline graphic"></span> satisfy the normalisation conditions <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq193"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/9c998ae71bbd/d33e2145.gif" loading="lazy" id="d33e2145" alt="Inline graphic"></span>. For further analysis, we introduce auxiliary constructs:</p>
<p id="Par85">- let <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq194"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/e3f58ad63973/d33e2153.gif" loading="lazy" id="d33e2153" alt="Inline graphic"></span> denote the <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq195"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a086866e2160/d33e2159.gif" loading="lazy" id="d33e2159" alt="Inline graphic"></span>-th row of the matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq196"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0e70af7e27d8/d33e2165.gif" loading="lazy" id="d33e2165" alt="Inline graphic"></span>, that is, the feature vector of object <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq197"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a086866e2160/d33e2171.gif" loading="lazy" id="d33e2171" alt="Inline graphic"></span>: <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq198"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/adf568881eed/d33e2177.gif" loading="lazy" id="d33e2177" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq199"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/93343f3a6f50/d33e2184.gif" loading="lazy" id="d33e2184" alt="Inline graphic"></span>;</p>
<p id="Par86">- let <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq200"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/be1b334fa9f3/d33e2192.gif" loading="lazy" id="d33e2192" alt="Inline graphic"></span> denote the <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq201"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c4ddf470d238/d33e2198.gif" loading="lazy" id="d33e2198" alt="Inline graphic"></span>-th column of the matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq202"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/43f3b929b03f/d33e2204.gif" loading="lazy" id="d33e2204" alt="Inline graphic"></span>: <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq203"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/fc901bfc8d0a/d33e2210.gif" loading="lazy" id="d33e2210" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq204"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/210b773b36bb/d33e2216.gif" loading="lazy" id="d33e2216" alt="Inline graphic"></span>;</p>
<p id="Par87">- let <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq205"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1314e5f9f538/d33e2224.gif" loading="lazy" id="d33e2224" alt="Inline graphic"></span> denote the <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq206"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/906e271ec85e/d33e2230.gif" loading="lazy" id="d33e2230" alt="Inline graphic"></span>-th column of the projector matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq207"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/2d73211426c9/d33e2236.gif" loading="lazy" id="d33e2236" alt="Inline graphic"></span>: <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq208"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/59b55916f6fe/d33e2242.gif" loading="lazy" id="d33e2242" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq209"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/45a3e8a7d22e/d33e2248.gif" loading="lazy" id="d33e2248" alt="Inline graphic"></span>.</p>
<p id="Par88">With these notations, equality (<a href="#Equ20" class="usa-link">20</a>) can be expressed in block form as <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq210"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/cc2ee6c15545/d33e2259.gif" loading="lazy" id="d33e2259" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq211"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/93343f3a6f50/d33e2265.gif" loading="lazy" id="d33e2265" alt="Inline graphic"></span>, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq212"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/2a93fc9699ad/d33e2271.gif" loading="lazy" id="d33e2271" alt="Inline graphic"></span> denotes the scalar product of vectors. Thus, each object <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq213"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a086866e2160/d33e2277.gif" loading="lazy" id="d33e2277" alt="Inline graphic"></span> from the original feature space is projected into the <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq214"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/10c81be4a07d/d33e2284.gif" loading="lazy" id="d33e2284" alt="Inline graphic"></span>-dimensional space using the right projector matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq215"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/2d73211426c9/d33e2290.gif" loading="lazy" id="d33e2290" alt="Inline graphic"></span>.</p>
<p id="Par89">Let us consider a configuration in which the elements of the right compression matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq216"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a8e29b7eef06/d33e2298.gif" loading="lazy" id="d33e2298" alt="Inline graphic"></span> may take only Boolean values {0,1}, with their arrangement within the matrix structure being stochastically determined. In this case, each specific realisation of a matrix of length <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq217"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/f2b6f7659240/d33e2304.gif" loading="lazy" id="d33e2304" alt="Inline graphic"></span> can be represented as a sequence of zeros and ones, and the total number of such possible realisations equals <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq218"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/751a6ade817d/d33e2310.gif" loading="lazy" id="d33e2310" alt="Inline graphic"></span>. Accordingly, the right projector <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq219"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a8e29b7eef06/d33e2316.gif" loading="lazy" id="d33e2316" alt="Inline graphic"></span> can be described by a finite set of binary realisations <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq220"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/26eaa07a098e/d33e2322.gif" loading="lazy" id="d33e2322" alt="Inline graphic"></span>, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq221"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/057c5a32b9c8/d33e2329.gif" loading="lazy" id="d33e2329" alt="Inline graphic"></span>. This set defines the space of admissible Boolean mappings for the right compression matrix, which is critically important under entropy-optimised compression with fixed bit constraints.</p>
<p id="Par90">Suppose that the Boolean realisations are stochastic. In this case, their probabilistic characteristics can be described using a probability distribution function with discrete mass <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq222"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/76e4a4879aac/d33e2337.gif" loading="lazy" id="d33e2337" alt="Inline graphic"></span>, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq223"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/173c5f5cddb5/d33e2343.gif" loading="lazy" id="d33e2343" alt="Inline graphic"></span>; <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq224"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/9b9c30620e42/d33e2349.gif" loading="lazy" id="d33e2349" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq225"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c648321f2900/d33e2355.gif" loading="lazy" id="d33e2355" alt="Inline graphic"></span>. The expected value of the compression indicator (see (14)) over the Boolean realisations is expressed as <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq226"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/f177d638fc86/d33e2361.gif" loading="lazy" id="d33e2361" alt="Inline graphic"></span>. We seek the optimal form of the distribution function <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq227"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/60bdf07fdb17/d33e2368.gif" loading="lazy" id="d33e2368" alt="Inline graphic"></span> within the class of probability measures that maximise the Fermi–Dirac informational entropy. This criterion can be formulated as</p>
<table class="disp-formula p" id="Equ21"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/78c5183335fb/d33e2374.gif" loading="lazy" id="d33e2374" alt="graphic file with name d33e2374.gif"></td>
<td class="label">21</td>
</tr></table>
<p>under the constraint of preserving the expectation of the compression indicator (see above): <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq228"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/fb17cdac0127/d33e2381.gif" loading="lazy" id="d33e2381" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq229"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/cada489970b2/d33e2387.gif" loading="lazy" id="d33e2387" alt="Inline graphic"></span>. Here, the parameters <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq230"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0b82a1a20e26/d33e2393.gif" loading="lazy" id="d33e2393" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq231"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/618f63844401/d33e2399.gif" loading="lazy" id="d33e2399" alt="Inline graphic"></span> represent the admissible bounds for the average compactness level, as previously defined in (<a href="#Equ17" class="usa-link">17</a>). The notation <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq232"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/d73530018c4a/d33e2409.gif" loading="lazy" id="d33e2409" alt="Inline graphic"></span> denotes the reference compression indicator for the original data matrix.</p>
<p id="Par91">The formalisation of the problem of maximising the functional (<a href="#Equ16" class="usa-link">16</a>) under the constraint on average compactness (see (17)) reduces to a finite-dimensional constrained extremum problem with a concave criterion and a linear constraint. Although a comprehensive analysis requires a dedicated variational treatment, an analytical solution exists and can be refined numerically. Consider the generalised Lagrangian functional <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq233"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/9eef88c7cac4/d33e2420.gif" loading="lazy" id="d33e2420" alt="Inline graphic"></span>, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq234"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/218e522b5a79/d33e2426.gif" loading="lazy" id="d33e2426" alt="Inline graphic"></span> is the Fermi–Dirac entropy function (21), and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq235"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a8bf8e16d93e/d33e2432.gif" loading="lazy" id="d33e2432" alt="Inline graphic"></span> is the scalar multiplier corresponding to the constraint of consistency with the reference compactness value <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq236"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/57391a1f390c/d33e2438.gif" loading="lazy" id="d33e2438" alt="Inline graphic"></span>. The stationarity of this function is ensured under the conditions <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq237"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/ba5f19a9a3a0/d33e2445.gif" loading="lazy" id="d33e2445" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq238"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/173c5f5cddb5/d33e2451.gif" loading="lazy" id="d33e2451" alt="Inline graphic"></span>; <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq239"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/5f411f919b1e/d33e2457.gif" loading="lazy" id="d33e2457" alt="Inline graphic"></span>. From this, we obtain the optimal distribution in closed form:</p>
<table class="disp-formula p" id="Equ22"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/7bc33d8fec23/d33e2463.gif" loading="lazy" id="d33e2463" alt="graphic file with name d33e2463.gif"></td>
<td class="label">22</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq240"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/173c5f5cddb5/d33e2470.gif" loading="lazy" id="d33e2470" alt="Inline graphic"></span>, and the scalar multiplier <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq241"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a8bf8e16d93e/d33e2476.gif" loading="lazy" id="d33e2476" alt="Inline graphic"></span> is computed as the solution of the equation <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq242"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/ec942f9a4b7b/d33e2483.gif" loading="lazy" id="d33e2483" alt="Inline graphic"></span>.</p>
<p id="Par92">Thus, Eq. (<a href="#Equ18" class="usa-link">22</a>) formally represents the solution to the problem of stochastically constrained entropy optimisation for a discrete set of Boolean projectors. In this way, an entropy-consistent probability distribution is established, which minimises the entropic divergence under the condition of preserving average compactness. At the same time, for a finite <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq243"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/e1842c352784/d33e2494.gif" loading="lazy" id="d33e2494" alt="Inline graphic"></span> (e.g., for <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq244"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/155b9b94bb61/d33e2500.gif" loading="lazy" id="d33e2500" alt="Inline graphic"></span>), an approximation error <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq245"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a35dacc285d5/d33e2506.gif" loading="lazy" id="d33e2506" alt="Inline graphic"></span> arises, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq246"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/ba5d4a0d00ef/d33e2512.gif" loading="lazy" id="d33e2512" alt="Inline graphic"></span> is the global minimum in a hypothetical continuous projector space. In practical terms, this error can be reduced either by increasing <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq247"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/e1842c352784/d33e2519.gif" loading="lazy" id="d33e2519" alt="Inline graphic"></span> or by resampling with an updated <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq248"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a8bf8e16d93e/d33e2525.gif" loading="lazy" id="d33e2525" alt="Inline graphic"></span>. It is rational to select such a candidate matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq249"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/8de2cef29b71/d33e2531.gif" loading="lazy" id="d33e2531" alt="Inline graphic"></span> that maximises the corresponding weight probability.</p>
<table class="disp-formula p" id="Equ23"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/98658b4e1cd1/d33e2537.gif" loading="lazy" id="d33e2537" alt="graphic file with name d33e2537.gif"></td>
<td class="label">23</td>
</tr></table>
<p id="Par93">Despite the evident efficiency of the maximum criterion (<a href="#Equ23" class="usa-link">23</a>), alternative selection strategies (such as entropy-based sampling or Bayesian compromises) may also be relevant in the context of distributed computing or under system response time constraints (e.g., in 5G URLLC scenarios).</p>
<p id="Par94">The procedure for constructing Boolean projector matrices via entropy-based selection can be summarised as a normalised algorithm:</p>
<ol class="list" style="list-style-type:decimal">
<li><p id="Par95">Each element of the matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq250"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/62e74cc9fcfe/d33e2557.gif" loading="lazy" id="d33e2557" alt="Inline graphic"></span> is linearly scaled within the unit hypercube: <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq251"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/ff4b681932b3/d33e2563.gif" loading="lazy" id="d33e2563" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq252"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/93343f3a6f50/d33e2569.gif" loading="lazy" id="d33e2569" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq253"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/3acd7318d67f/d33e2575.gif" loading="lazy" id="d33e2575" alt="Inline graphic"></span>.</p></li>
<li><p id="Par96">According to (14), the average pairwise entropy-weighted divergence is computed: <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq254"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/06cdf1070592/d33e2586.gif" loading="lazy" id="d33e2586" alt="Inline graphic"></span>.</p></li>
<li><p id="Par97">The set of all possible configurations of binary projection matrices of dimensionality <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq255"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1ca3a9b5fea4/d33e2597.gif" loading="lazy" id="d33e2597" alt="Inline graphic"></span> is generated: <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq256"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/94452cdf6677/d33e2603.gif" loading="lazy" id="d33e2603" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq257"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/53f28f3c0e1d/d33e2609.gif" loading="lazy" id="d33e2609" alt="Inline graphic"></span>.</p></li>
<li><p id="Par98">Each matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq258"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/5c25a992cfab/d33e2620.gif" loading="lazy" id="d33e2620" alt="Inline graphic"></span> is applied as a projection to the original matrix, resulting in the projected matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq259"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/75cb5c74d572/d33e2626.gif" loading="lazy" id="d33e2626" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq260"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/93343f3a6f50/d33e2632.gif" loading="lazy" id="d33e2632" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq261"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/210b773b36bb/d33e2638.gif" loading="lazy" id="d33e2638" alt="Inline graphic"></span>, followed by the formation of the corresponding vectors <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq262"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/f92c81e146cc/d33e2644.gif" loading="lazy" id="d33e2644" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq263"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/482fd70b180e/d33e2651.gif" loading="lazy" id="d33e2651" alt="Inline graphic"></span>​.</p></li>
<li><p id="Par99">The compactness indicator is evaluated for each candidate projector matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq264"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/85dee680e335/d33e2662.gif" loading="lazy" id="d33e2662" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq265"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/173c5f5cddb5/d33e2668.gif" loading="lazy" id="d33e2668" alt="Inline graphic"></span>..</p></li>
<li><p id="Par100">The optimal value of the entropic Lagrange multiplier <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq266"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/17515c48806a/d33e2679.gif" loading="lazy" id="d33e2679" alt="Inline graphic"></span> is determined from the equation <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq267"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0c11b5a08fe0/d33e2685.gif" loading="lazy" id="d33e2685" alt="Inline graphic"></span>.</p></li>
<li><p id="Par101">The projector matrix with the highest posterior probability is selected: <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq268"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/b7ad0574ab6c/d33e2696.gif" loading="lazy" id="d33e2696" alt="Inline graphic"></span>, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq269"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/4ca7dc35b559/d33e2702.gif" loading="lazy" id="d33e2702" alt="Inline graphic"></span> is the entropy-optimal value of the distribution function over the set of binary realisations.</p></li>
<li><p id="Par102">The final projection matrix is determined, implementing the entropy-optimal compression <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq270"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/7d79449dc9b2/d33e2713.gif" loading="lazy" id="d33e2713" alt="Inline graphic"></span>.</p></li>
<li><p id="Par103">Stopping criterion. The algorithm terminates upon constructing the optimal matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq271"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/9287a349b4d1/d33e2724.gif" loading="lazy" id="d33e2724" alt="Inline graphic"></span> that minimises the entropy-controlled divergence under criterion (15), while satisfying the information constraint reflecting the target QoS characteristics (e.g., in 5G URLLC or eMBB scenarios).</p></li>
</ol>
<p id="Par104">In the stochastic-Boolean projector framework (expressions (<a href="#Equ14" class="usa-link">14</a>)–(<a href="#Equ15" class="usa-link">23</a>)), the primary computational load lies in the construction and evaluation of a large but finite set of Boolean projector matrices <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq272"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/4126a716c217/d33e2738.gif" loading="lazy" id="d33e2738" alt="Inline graphic"></span>. While generating all possible realisations has exponential complexity <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq273"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a7dd1c1c01a8/d33e2744.gif" loading="lazy" id="d33e2744" alt="Inline graphic"></span>, in practice, a subset of admissible configurations <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq274"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/efdfdea43a12/d33e2750.gif" loading="lazy" id="d33e2750" alt="Inline graphic"></span> is used (e.g., a sample <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq275"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/f730c3ab9a05/d33e2757.gif" loading="lazy" id="d33e2757" alt="Inline graphic"></span>). For each realisation, the entropy-based compactness metric (15) is computed with an approximate complexity of <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq276"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/2c30c655f2ed/d33e2763.gif" loading="lazy" id="d33e2763" alt="Inline graphic"></span>, which is acceptable for small <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq277"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/10c81be4a07d/d33e2769.gif" loading="lazy" id="d33e2769" alt="Inline graphic"></span>. The final selection of the optimal projector is performed using the closed-form expression (<a href="#Equ18" class="usa-link">22</a>), which has linear complexity with respect to the number of configurations <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq278"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/e1842c352784/d33e2778.gif" loading="lazy" id="d33e2778" alt="Inline graphic"></span>. Since all operations are algebraically simple (reduced to scalar products and summations) the scheme is computationally stable and suitable for implementation in low-power edge environments, even with limited precision (8–16 bits).</p>
<p id="Par105">We conclude the subSect. by substantiating the stochastic stability of the proposed Boolean entropy-based projection. The described compression scheme relies on stochastically regularised projection of the feature space via a finite set of Boolean matrices <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq279"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a0a0b980746d/d33e2786.gif" loading="lazy" id="d33e2786" alt="Inline graphic"></span>. For each matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq280"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/5c25a992cfab/d33e2792.gif" loading="lazy" id="d33e2792" alt="Inline graphic"></span>, the entropy-based compactness metric (15) is computed, serving as an indicator of intra-group feature dispersion after transformation. The optimal weight <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq281"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/4ca7dc35b559/d33e2798.gif" loading="lazy" id="d33e2798" alt="Inline graphic"></span> for each projection variant is determined using the Lagrangian function (22), which minimises the entropic divergence under the constraint on average compactness (17).</p>
<p id="Par106">The optimisation functional <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq282"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/21c6f2a24c5b/d33e2806.gif" loading="lazy" id="d33e2806" alt="Inline graphic"></span> in this scheme is convex with respect to the variables <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq283"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/4ca7dc35b559/d33e2812.gif" loading="lazy" id="d33e2812" alt="Inline graphic"></span> and possesses a closed-form analytical solution as given in (22), which guarantees the uniqueness and stability of the optimal projection selection for a fixed value of the multiplier <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq284"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a8bf8e16d93e/d33e2818.gif" loading="lazy" id="d33e2818" alt="Inline graphic"></span>. Since the optimisation is performed over a finite set (of dimensionality <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq285"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/e1842c352784/d33e2824.gif" loading="lazy" id="d33e2824" alt="Inline graphic"></span>), the selection procedure is stochastically stable—even under imperfect QoS (fluctuations in <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq286"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/edd700580a15/d33e2830.gif" loading="lazy" id="d33e2830" alt="Inline graphic"></span>), the redistribution of weight coefficients <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq287"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/4ca7dc35b559/d33e2837.gif" loading="lazy" id="d33e2837" alt="Inline graphic"></span> preserves the integrity of the entropic criterion. Moreover, within the admissible entropic interval <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq288"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/6e08a77a347b/d33e2843.gif" loading="lazy" id="d33e2843" alt="Inline graphic"></span>, the parameter <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq289"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/edd700580a15/d33e2849.gif" loading="lazy" id="d33e2849" alt="Inline graphic"></span> acts as a flexibility controller, allowing adaptive reduction or reinforcement of projection selectivity depending on the transmission channels. In effect, under URLLC conditions where QoS dynamically fluctuates, this mechanism implements Bayesian entropy adaptation, ensuring stability of selection even in the presence of local disturbances in the input stream <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq290"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0e70af7e27d8/d33e2855.gif" loading="lazy" id="d33e2855" alt="Inline graphic"></span>. Thus, the stochastic-Boolean approach, implemented through a regularised probabilistic scheme with an entropic criterion, provides built-in stability guarantees, constraints on variational risk, and the ability to maintain topological coherence of features even in the presence of incomplete or noisy data. This makes the method suitable for real-time systems with partial signal loss or entropy throughput limitations.</p>
<p id="Par107">A summary table listing all projection operators, latent variables, functionals, and their associated dimensions is presented ik the Table <a href="#Tab2" class="usa-link">2</a> to enhance readability and support implementation clarity.</p>
<section class="tw xbox font-sm" id="Tab2"><h3 class="obj_head">Table 2.</h3>
<div class="caption p"><p>Summary of Projection Operators, Latent Variables, and Functionals in the Proposed Compression Model.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Symbol</th>
<th align="left" colspan="1" rowspan="1">Description</th>
<th align="left" colspan="1" rowspan="1">Dimensions</th>
<th align="left" colspan="1" rowspan="1">Role</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq291"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0e70af7e27d8/d33e2890.gif" loading="lazy" id="d33e2890" alt="Inline graphic"></span></td>
<td align="left" colspan="1" rowspan="1">Input feature matrix</td>
<td align="left" colspan="1" rowspan="1"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq292"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/412856f466f7/d33e2899.gif" loading="lazy" id="d33e2899" alt="Inline graphic"></span></td>
<td align="left" colspan="1" rowspan="1">Raw sensor input</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq293"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/2d73211426c9/d33e2909.gif" loading="lazy" id="d33e2909" alt="Inline graphic"></span></td>
<td align="left" colspan="1" rowspan="1">Feature compression matrix</td>
<td align="left" colspan="1" rowspan="1"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq294"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1ca3a9b5fea4/d33e2918.gif" loading="lazy" id="d33e2918" alt="Inline graphic"></span></td>
<td align="left" colspan="1" rowspan="1">Projects input into latent space</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq295"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/b4725ea70feb/d33e2928.gif" loading="lazy" id="d33e2928" alt="Inline graphic"></span></td>
<td align="left" colspan="1" rowspan="1">Instance selection matrix</td>
<td align="left" colspan="1" rowspan="1"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq296"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/6167bbe4d1a2/d33e2937.gif" loading="lazy" id="d33e2937" alt="Inline graphic"></span></td>
<td align="left" colspan="1" rowspan="1">τ-dependent sampling</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq297"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1e5e37ce8530/d33e2947.gif" loading="lazy" id="d33e2947" alt="Inline graphic"></span></td>
<td align="left" colspan="1" rowspan="1">Compressed representation</td>
<td align="left" colspan="1" rowspan="1"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq298"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/8a88215cbca9/d33e2956.gif" loading="lazy" id="d33e2956" alt="Inline graphic"></span></td>
<td align="left" colspan="1" rowspan="1">Encoded output</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq299"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/42156568abf5/d33e2966.gif" loading="lazy" id="d33e2966" alt="Inline graphic"></span></td>
<td align="left" colspan="1" rowspan="1">Latent decoding matrix</td>
<td align="left" colspan="1" rowspan="1"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq300"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/6e2077e2c8ef/d33e2975.gif" loading="lazy" id="d33e2975" alt="Inline graphic"></span></td>
<td align="left" colspan="1" rowspan="1">Decodes latent features</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq301"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/fb6f7bd58ab9/d33e2985.gif" loading="lazy" id="d33e2985" alt="Inline graphic"></span></td>
<td align="left" colspan="1" rowspan="1">Spatial reconstruction matrix</td>
<td align="left" colspan="1" rowspan="1"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq302"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/5e3dd4067cb7/d33e2994.gif" loading="lazy" id="d33e2994" alt="Inline graphic"></span></td>
<td align="left" colspan="1" rowspan="1">Restores instance structure</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq303"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/5fecfae534d8/d33e3004.gif" loading="lazy" id="d33e3004" alt="Inline graphic"></span></td>
<td align="left" colspan="1" rowspan="1">Reconstructed matrix</td>
<td align="left" colspan="1" rowspan="1"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq304"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/412856f466f7/d33e3013.gif" loading="lazy" id="d33e3013" alt="Inline graphic"></span></td>
<td align="left" colspan="1" rowspan="1">Final approximation of input</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">
<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq305"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/3624fe898229/d33e3023.gif" loading="lazy" id="d33e3023" alt="Inline graphic"></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq306"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/be85c84c6001/d33e3029.gif" loading="lazy" id="d33e3029" alt="Inline graphic"></span>
</td>
<td align="left" colspan="1" rowspan="1">Vectorised parameters</td>
<td align="left" colspan="1" rowspan="1"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq307"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/7beaf4c73919/d33e3038.gif" loading="lazy" id="d33e3038" alt="Inline graphic"></span></td>
<td align="left" colspan="1" rowspan="1">Used in gradient optimisation</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq308"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/ef3b0f712463/d33e3048.gif" loading="lazy" id="d33e3048" alt="Inline graphic"></span></td>
<td align="left" colspan="1" rowspan="1">Entropy deviation functional</td>
<td align="left" colspan="1" rowspan="1">scalar</td>
<td align="left" colspan="1" rowspan="1">Penalises encoding complexity</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq309"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c647259f16d7/d33e3062.gif" loading="lazy" id="d33e3062" alt="Inline graphic"></span></td>
<td align="left" colspan="1" rowspan="1">Directed divergence</td>
<td align="left" colspan="1" rowspan="1">scalar</td>
<td align="left" colspan="1" rowspan="1">Measures reconstruction loss</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1"><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq310"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c239952043cb/d33e3076.gif" loading="lazy" id="d33e3076" alt="Inline graphic"></span></td>
<td align="left" colspan="1" rowspan="1">Total loss functional</td>
<td align="left" colspan="1" rowspan="1">scalar</td>
<td align="left" colspan="1" rowspan="1">Objective to be minimised</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="Sec8"><h2 class="pmc_sec_title">Results</h2>
<p id="Par108">In distributed computational environments with constrained resources (particularly under unstable communication channels and strict energy budgets) even small volumes of information impose significant load on the system. Therefore, the task of feature compression under such conditions goes beyond classical reduction methods and focuses on constructing latent representations capable of preserving semantic coherence even under stochastic losses.</p>
<p id="Par109">The aim of this Sect. is to provide a quantitative assessment of the effectiveness of the entropy-regularised feature compression approach proposed in Sect. “<a href="#Sec5" class="usa-link">Models and methods</a>” for classification tasks involving temporal sensor data, typical of distributed and resource-constrained environments. To achieve this objective, a series of interrelated tasks was addressed, including: evaluation of the trade-off between classification accuracy and the degree of feature compression; analysis of changes in the entropic complexity of latent representations depending on compression parameters; examination of the impact of compression levels on the semantic preservation of features and the quality of their reconstruction; assessment of the stability of the proposed approach under scenarios with heterogeneous (non-IID) data distribution; verification of the robustness of the approach to stochastic losses and signal noise; investigation of the relationship between the approach’s performance and the entropic density of features; and testing of the architecture under various usage modes, including inference and centralised feature aggregation.</p>
<p id="Par110">It should be noted that the proposed approach encompasses two consistent compression strategies. The variational-reconstructive strategy described in Sect. “<a href="#Sec6" class="usa-link">Variational design of stochastic feature encoders</a>” (hereafter—Ours.Variational) involves the construction of a latent space through a cascade of transformation matrices (1)–(3), reconstruction functions (2), and evaluation criteria based on divergence (7) and entropy power (8)–(10). This approach enables the formulation of the optimisation problem as a projection-gradient scheme in the negative orthant (12)–(13), ensuring a balance between reconstruction accuracy and entropic efficiency. The stochastic-Boolean strategy presented in Sect. “<a href="#Sec7" class="usa-link">Bit-level compression with entropy-driven selection</a>” (hereafter—Ours.Stochastic-Boolean) targets compression under limited bit precision and relies on the generation of random binary projectors with controlled entropy. This concept implements an entropy-regularised bidirectional projection (14)–(23), where Boolean masks are stochastically generated in accordance with a Lagrangian function that incorporates compactness indicators (15) and entropy maximum constraints (21)–(22). The mathematical framework set out in Sect. “<a href="#Sec7" class="usa-link">Bit-level compression with entropy-driven selection</a>” defines a generalised algorithm for constructing Boolean projection matrices. It includes input space scaling, estimation of average entropic variation, generation of the admissible configuration set, selection based on posterior probability, and termination according to the information deviation criterion.</p>
<p id="Par111">The following material presents the testing of both strategies in environments that simulate the typical operating conditions of edge/federated systems. This includes both on-device local inference and centralised aggregation of compressed features. In addition, the behaviour of the proposed mathematical framework is analysed under scenarios involving heterogeneous data distribution across clients. Such an experimental setup provides not only a theoretical but also an empirical validation of the architecture’s ability to operate under resource constraints and structural fragmentation.</p>
<p id="Par112">The experimental study was based on two publicly available sensor datasets that are widely used in time-series-based distributed learning tasks: Human Activity Recognition using Smartphones (UCI HAR) [<a href="https://www.kaggle.com/c/uci-har" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/c/uci-har</a>] and Physical Activity Monitoring (PAMAP2) [<a href="https://www.kaggle.com/code/avrahamcalev/time-series-models-pamap2-dataset" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/code/avrahamcalev/time-series-models-pamap2-dataset</a>]. The structure of both datasets enables the modelling of non-IID heterogeneity typical of federated environments, as well as dimensionality, frequency, and volume constraints characteristic of edge devices.</p>
<p id="Par113">The UCI HAR dataset comprises approximately 10,300 segmented frames, each represented by a feature vector of dimensionality 561. The data are labelled into six activity classes (e.g., walking, standing, stair climbing) and grouped by 30 users, each modelled as a separate client. This dataset serves as a typical example of mobile sensor monitoring within a fragmented observation space. All frames are provided in the form of a feature matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq311"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c944da50f320/d33e3121.gif" loading="lazy" id="d33e3121" alt="Inline graphic"></span>, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq312"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/9da6db8937f8/d33e3127.gif" loading="lazy" id="d33e3127" alt="Inline graphic"></span>, in accordance with the formulation in expression (<a href="#Equ1" class="usa-link">1</a>).</p>
<p id="Par114">The PAMAP2 dataset consists of approximately 40,000 frames obtained through segmentation of multichannel high-frequency recordings. The number of features per frame varies depending on the channel configuration. To ensure comparability and controlled dimensionality, the data were reduced to a fixed feature size by selecting the 289 most variance-rich features. In specialised cross-dataset comparative scenarios, a configuration with 561 features (identical to UCI HAR) is also employed. As in the previous case, each session forms a separate matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq313"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/c944da50f320/d33e3138.gif" loading="lazy" id="d33e3138" alt="Inline graphic"></span>, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq314"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/30d718320bed/d33e3144.gif" loading="lazy" id="d33e3144" alt="Inline graphic"></span>, allowing for the evaluation of compression behaviour under varying levels of input complexity. Each of the 9–12 recording sessions (from individual users) constitutes an independent client node. The dataset includes 18 activity classes, providing a high degree of semantic variability.</p>
<p id="Par115">To account for class imbalance present in the HAR and PAMAP2 datasets, a class-balanced sampling strategy was applied during training and evaluation to ensure uniform representation across activity categories without altering the original data distribution.</p>
<p id="Par116">Preprocessing involved Z-score normalisation per channel, sliding window segmentation with a window size of 128 steps and 50% overlap (64-step shift), as well as the removal of anomalous measurements. Data were distributed among clients using disjoint partitioning, which prevents duplication of frames across client nodes. To ensure reproducibility of simulations, random distribution parameters were fixed using a defined random seed <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq315"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a0af7c4148d8/d33e3154.gif" loading="lazy" id="d33e3154" alt="Inline graphic"></span>. The distribution was carried out across three heterogeneity categories:</p>
<ul class="list" style="list-style-type:disc">
<li><p id="Par117">Label skew: clients have access to only a subset of classes (2 out of 6 for UCI HAR; 4–6 out of 18 for PAMAP2), modelling partial coverage of the semantic space;</p></li>
<li><p id="Par118">Quantity skew: the number of frames per client varies within the range of 400–2500 (UCI HAR) and 1000–8000 (PAMAP2);</p></li>
<li><p id="Par119">Feature noise heterogeneity: implemented through the addition of Gaussian noise with <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq316"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/08c5d3ecacfb/d33e3170.gif" loading="lazy" id="d33e3170" alt="Inline graphic"></span> to selected frames, as well as selective zeroing of 10–20% of feature elements for a subset of clients.</p></li>
</ul>
<p id="Par120">The experiments involved 10 clients for each dataset, selected from their respective pools. This value aligns with the simulation parameters of the federated environment, which will be described in detail later. Hardware constraints were emulated by simulating the computational environment at the device level of a Jetson Nano. The target dimensionality of the compressed representation after projection was limited: <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq317"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/cdea3e7a96ef/d33e3178.gif" loading="lazy" id="d33e3178" alt="Inline graphic"></span>. In addition, a strict upper limit was imposed on the total memory footprint used by the inference module, including the compressed representation <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq318"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/e70825abf18e/d33e3184.gif" loading="lazy" id="d33e3184" alt="Inline graphic"></span> MB, covering all forward-pass tensors. These parameters reflect the practical deployment conditions of edge inference models in low-power environments.</p>
<p id="Par121">To objectively position the proposed mathematical framework within the contemporary scientific landscape, three methods were selected that represent distinct strategies of information-constrained processing in federated and edge scenarios and are considered SOTA approaches in this domain. Despite differences in implementation, each of these methods employs entropy as a functional regulariser (ranging from stochastic feature selection to bit-level compression) thus providing a methodological basis for a technically valid comparison with our approach.</p>
<p id="Par122">The FedEntropy<sup><a href="#CR28" class="usa-link" aria-describedby="CR28">28</a></sup> method introduces regularisation of local training by adding an information penalty to the loss function. This strategy aims to reduce the complexity of model updates and, consequently, to lower the information burden on the federated channel. The Entropy-Driven Stochastic FL (EDS-FL)<sup><a href="#CR29" class="usa-link" aria-describedby="CR29">29</a></sup> method applies stochastic feature filtering with selection probabilities proportional to local information significance. Filtering is performed according to an entropic criterion, enabling the retention of semantically relevant features even under substantial compression. The method has demonstrated adaptability to unstable channels in sensor environments. The Sign-Entropy Regularization (SER)<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup> method is based on bit-level gradient compression using binary masks derived from signs modulated by an information function. This scheme targets the minimisation of data transmission volumes under strict bandwidth constraints (particularly in low-power IoT systems or URLLC modules). Owing to its simplicity, the method retains practical applicability for basic recognition tasks.</p>
<p id="Par123">The selection of the aforementioned SOTA methods is justified by their thematic proximity, namely, the use of entropic criteria, stochastic mechanisms, and compression techniques, the availability of open-source or reproducible implementations, and their representativeness across different classes of compression strategies. For the purpose of technical comparison, each of the selected methods was implemented on a common input dataset, within identical distribution scenarios, client simulations, and evaluation frameworks. Architectural parameters were adapted to preserve comparability while maintaining the specificity of each approach. All SOTA implementations were executed within a unified environment, ensuring the reliability of the subsequent analysis.</p>
<p id="Par124">The empirical evaluation of the proposed approach was carried out in an environment simulating typical constraints of Edge AI and Federated Learning systems, including unstable communication channels, limited bandwidth, and various forms of input data fragmentation. The software environment was built on Python 3.11.3, using the following library stack: PyTorch 2.2.1 (CUDA 12.1) for model training and inference; NumPy 1.26 for basic data processing; scikit-learn 1.4 for preprocessing and PCA/t-SNE; EntropyHub 0.2.2 for computing entropic characteristics; TorchMetrics 1.3 for classification metrics; and Flower 1.7 as the infrastructure framework for federated simulation. At the computational infrastructure level, two platforms were used: a server platform with an NVIDIA RTX 3080 GPU (CUDA 12.1), responsible for centralised training and model aggregation, and an edge-testing platform with a Jetson Nano device (4 × ARM Cortex-A57 CPU, 128-core Maxwell GPU, 4 GB LPDDR4), where local inference was simulated and the practical effectiveness of compression was evaluated. Additionally, part of the experiments was conducted on a Raspberry Pi 4 to test stability on an alternative low-power device. No quantisation, pruning, or deployment-specific optimisation techniques were applied to the models during evaluation. The study focused exclusively on the effectiveness of the proposed compression method under standard training and inference procedures.</p>
<p id="Par125">The federated simulation was constructed for 10 clients with a non-IID data distribution. All clients participated in every global round. The training structure employed FedAvg with 5 local epochs per client, a batch size of 32, and a total of 100 global rounds. Data were distributed among clients using a combination of label skew and quantity skew strategies. The model architecture comprised two fully connected hidden layers with 256 and 128 neurons respectively, using ReLU activation, Dropout = 0.3, and an output projection layer into a latent space of dimensionality <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq319"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a5c6b9fc92b7/d33e3213.gif" loading="lazy" id="d33e3213" alt="Inline graphic"></span>, depending on the scenario. For compression, both variationally optimised compression matrices and entropy-regularised stochastic Boolean projectors were used. The regularisation parameter λ was varied within the range [0, 1] in steps of 0.1 to explore the trade-off between accuracy and entropic compactness. Inference latency was measured on the Jetson Nano as the average over 100 consecutive forward-pass executions using compressed representations. The memory footprint was evaluated as the total volume of active tensors during inference, with a constraint set at ≤ 32 MB, covering both model parameters and feature representations. Approximate energy consumption was estimated using the tegrastats and powerstat utilities as the average combined CPU + GPU power during inference execution.</p>
<p id="Par126">The evaluation system for the obtained results comprised four main classes of metrics: classification metrics (global and client-averaged classification accuracy), entropic-informational metrics (Shannon entropy, KL divergence, change in entropic complexity), hardware metrics (inference latency, memory footprint, energy consumption), and compression metrics (degree of input representation compression). The selection of these metrics was guided by the analytical framework presented in Sect. “<a href="#Sec5" class="usa-link">Models and methods</a>” and the nature of the compared methods, which also employ entropic and stochastic regularisers. To ensure result reliability, each experiment was conducted five times using fixed random seeds: {42, 101, 2023, 777, 3141}. Confidence intervals were calculated at the 95% level. For statistical significance testing, the following were applied: the Shapiro–Wilk test (normality check), the paired t-test and Wilcoxon signed-rank test (for paired comparisons), ANOVA (for multi-model comparisons), and Cohen’s <em>d</em> effect size (for assessing the practical significance of observed differences). All environment settings, the architecture of the proposed model, and the simulation configuration were aligned with the implementation parameters of the three selected SOTA methods, ensuring objective and methodologically valid result comparisons.</p>
<p id="Par127">For comparative evaluation, the baseline methods were re-implemented according to their respective original configurations. The MQL and RSSI-HO models were trained using a fixed learning rate of 0.001 and a batch size of 64. The DQN-HO agent used an experience replay buffer of size 10,000, with a discount factor <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq320"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/9d64c4e68633/d33e3229.gif" loading="lazy" id="d33e3229" alt="Inline graphic"></span>. The exploration rate ε followed a linear decay from 1.0 to 0.01 over 500 episodes. All methods employed the Adam optimiser with default parameters, and training was conducted for the same number of episodes as the proposed method to ensure fairness.</p>
<p id="Par128">To empirically validate the effectiveness of the proposed information-constrained representation schemes in federated learning on edge devices, a comparative study was conducted to identify trade-offs between accuracy, preservation of informational completeness, and resource efficiency.</p>
<p id="Par129">To model human activity recognition tasks, the UCI HAR dataset (characterised by stable dynamics and a limited number of classes) and the PAMAP2 dataset (featuring an extended class profile and high spatio-temporal resolution) were employed. All methods operated on input features of dimensionality 128, compressed into 8 latent features, resulting in a compression ratio of 0.25. The testing encompassed two variants of the proposed approach: the variational projector with latent reconstruction (Ours.Variational) and the stochastic-Boolean projector with binary masking and drop-coding (Ours.Stochastic-Boolean). Competing baselines included FedEntropy (with stochastic entropy regularisation without decoding), SER (with convolutional compression and threshold filtering), and EDS-FL (featuring variational dropout during local training). All models were evaluated in a 10-client configuration with non-IID distribution implemented via a Dirichlet scheme (α = 0.3), and results were averaged over 5 independent runs. For each method, classification accuracy, KL divergence between feature distributions before and after compression (based on normalised histograms), change in Shannon entropy, latency (average inference time), and memory footprint were computed. Latency and memory consumption were measured in an emulated ESP32-C3 environment (RISC-V, 160 MHz) using TFLite Micro, with a batch size of 1. The memory footprint included both model parameters stored in flash memory and runtime tensors in SRAM during inference. Confidence intervals for all metrics were reported at the 95% CI level as ± 1.96•SD/√n.</p>
<p id="Par130">As shown in Table <a href="#Tab3" class="usa-link">3</a>, the variational version of our approach, Ours.Variational, achieves the highest classification accuracy on the UCI HAR dataset (89.6%) along with a significant reduction in feature entropy (by 1.96 units), and a KL divergence of 0.095, indicating preservation of the topological structure of the latent space. The Ours.Stochastic-Boolean variant attains an accuracy of 87.7% with ΔEntropy = 1.74, outperforming FedEntropy (84.2%, ΔEntropy = 1.28), and exhibits lower latency (by approximately 2.5 ms) due to its Boolean implementation without a decoding block. SER yields the lowest performance metrics (80.7%, KL = 0.202), reflecting a substantial loss of informativeness under aggressive compression.</p>
<section class="tw xbox font-sm" id="Tab3"><h3 class="obj_head">Table 3.</h3>
<div class="caption p"><p>Comparative Metrics (UCI HAR, mean ± standard deviation across 20 runs).</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Method</th>
<th align="left" colspan="1" rowspan="1">Accuracy (%)</th>
<th align="left" colspan="1" rowspan="1">ДEntropy</th>
<th align="left" colspan="1" rowspan="1">KL-Div</th>
<th align="left" colspan="1" rowspan="1">Latency (ms)</th>
<th align="left" colspan="1" rowspan="1">Memory (KB)</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Ours.Variational</td>
<td align="center" colspan="1" rowspan="1">89.6</td>
<td align="center" colspan="1" rowspan="1">1.96</td>
<td align="center" colspan="1" rowspan="1">0.095</td>
<td align="center" colspan="1" rowspan="1">25.9</td>
<td align="center" colspan="1" rowspan="1">41.2</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Ours.Stochastic-Boolean</td>
<td align="center" colspan="1" rowspan="1">87.7</td>
<td align="center" colspan="1" rowspan="1">1.74</td>
<td align="center" colspan="1" rowspan="1">0.113</td>
<td align="center" colspan="1" rowspan="1">23.4</td>
<td align="center" colspan="1" rowspan="1">28.5</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">FedEntropy</td>
<td align="center" colspan="1" rowspan="1">84.2</td>
<td align="center" colspan="1" rowspan="1">1.28</td>
<td align="center" colspan="1" rowspan="1">0.158</td>
<td align="center" colspan="1" rowspan="1">28.3</td>
<td align="center" colspan="1" rowspan="1">37.4</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">EDS-FL</td>
<td align="center" colspan="1" rowspan="1">85.1</td>
<td align="center" colspan="1" rowspan="1">1.33</td>
<td align="center" colspan="1" rowspan="1">0.140</td>
<td align="center" colspan="1" rowspan="1">26.8</td>
<td align="center" colspan="1" rowspan="1">42.1</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">SER</td>
<td align="center" colspan="1" rowspan="1">80.7</td>
<td align="center" colspan="1" rowspan="1">0.93</td>
<td align="center" colspan="1" rowspan="1">0.202</td>
<td align="center" colspan="1" rowspan="1">29.1</td>
<td align="center" colspan="1" rowspan="1">39.9</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p id="Par131">All models were trained using the Adam optimiser with a fixed learning rate of 0.001, selected based on validation performance. The entropy-regularised projection component in the PRD approach employed a regularisation coefficient <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq321"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/fff9873619d9/d33e3338.gif" loading="lazy" id="d33e3338" alt="Inline graphic"></span> to balance information retention and compression. Projected gradient updates within this module were terminated when the step-wise change dropped below <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq322"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/bc6f018aebc0/d33e3344.gif" loading="lazy" id="d33e3344" alt="Inline graphic"></span>. Each experiment was independently repeated 20 times using different random seeds. All reported metrics represent the mean and standard deviation across these runs.</p>
<p id="Par132">A similar hierarchy is observed on the PAMAP2 dataset (see Table <a href="#Tab4" class="usa-link">4</a>). The Ours.Variational projector again achieves the highest classification accuracy (89.6%) and a reduction in entropy by 1.96 units. The Ours.Stochastic-Boolean variant reaches 87.1% accuracy with ΔEntropy = 1.61, outperforming FedEntropy (84.2% and 1.28, respectively) in both accuracy and compression efficiency (CR = 0.34 versus 0.46). Notably, the Boolean variant maintains consistently low latency (23.4 ms) which is a key advantage for real-time devices. SER shows the lowest performance (80.7%, ΔEntropy = 0.93), confirming its limited ability to preserve feature structure in multichannel HAR tasks.</p>
<section class="tw xbox font-sm" id="Tab4"><h3 class="obj_head">Table 4.</h3>
<div class="caption p"><p>Comparative Metrics (PAMAP2, mean ± standard deviation across 20 runs).</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Method</th>
<th align="left" colspan="1" rowspan="1">Accuracy (%)</th>
<th align="left" colspan="1" rowspan="1">ДEntropy</th>
<th align="left" colspan="1" rowspan="1">KL-Div</th>
<th align="left" colspan="1" rowspan="1">Latency (ms)</th>
<th align="left" colspan="1" rowspan="1">Memory (KB)</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Ours.Variational</td>
<td align="center" colspan="1" rowspan="1">89.6</td>
<td align="center" colspan="1" rowspan="1">1.96</td>
<td align="center" colspan="1" rowspan="1">0.102</td>
<td align="center" colspan="1" rowspan="1">26.1</td>
<td align="center" colspan="1" rowspan="1">42.0</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Ours.Stochastic-Boolean</td>
<td align="center" colspan="1" rowspan="1">87.1</td>
<td align="center" colspan="1" rowspan="1">1.61</td>
<td align="center" colspan="1" rowspan="1">0.121</td>
<td align="center" colspan="1" rowspan="1">23.4</td>
<td align="center" colspan="1" rowspan="1">29.3</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">FedEntropy</td>
<td align="center" colspan="1" rowspan="1">84.2</td>
<td align="center" colspan="1" rowspan="1">1.28</td>
<td align="center" colspan="1" rowspan="1">0.160</td>
<td align="center" colspan="1" rowspan="1">28.7</td>
<td align="center" colspan="1" rowspan="1">38.1</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">EDS-FL</td>
<td align="center" colspan="1" rowspan="1">84.7</td>
<td align="center" colspan="1" rowspan="1">1.36</td>
<td align="center" colspan="1" rowspan="1">0.147</td>
<td align="center" colspan="1" rowspan="1">27.4</td>
<td align="center" colspan="1" rowspan="1">43.2</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">SER</td>
<td align="center" colspan="1" rowspan="1">80.7</td>
<td align="center" colspan="1" rowspan="1">0.93</td>
<td align="center" colspan="1" rowspan="1">0.205</td>
<td align="center" colspan="1" rowspan="1">29.5</td>
<td align="center" colspan="1" rowspan="1">40.7</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p id="Par133">The obtained results demonstrate that the proposed information-constrained representation approaches effectively fulfil their intended functional objectives. The variational projector delivers 2.5–3% higher accuracy compared to SOTA methods in tasks focused on classification performance. Meanwhile, the stochastic-Boolean projector proves suitable for scenarios with strict constraints on latency and memory footprint, particularly in IoT sensor nodes or portable rehabilitation devices. The Ours.Stochastic-Boolean approach preserves the structural informativeness of features while incurring minimal computational overhead.</p>
<p id="Par134">The results presented in Figs. <a href="#Fig1" class="usa-link">1</a>a and b complement those shown in Tables <a href="#Tab3" class="usa-link">3</a> and <a href="#Tab4" class="usa-link">4</a>, illustrating the statistical distributions of key metrics across all methods. For each dataset (UCI HAR and PAMAP2), a series of boxplots was constructed, with method names plotted along the x-axis and the values of six metrics along the y-axis: classification accuracy, compression ratio, KL divergence, latency, change in Shannon entropy, and memory footprint. The compression ratio is defined as the ratio of the number of latent features to the dimensionality of the input vector (in our case −8/32 = 0.25). The boxplots enable the assessment of result variability across five runs of each experiment. The presented structure captures the interquartile range, median, potential outliers, and whiskers, reflecting the characteristic distribution of each metric.</p>
<figure class="fig xbox font-sm" id="Fig1"><h3 class="obj_head">Fig. 1.</h3>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12374004_41598_2025_16604_Fig1_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/09e85af15b72/41598_2025_16604_Fig1_HTML.jpg" loading="lazy" id="d33e3473" height="972" width="726" alt="Fig. 1"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p><strong>a</strong> Comparison of Methods by Key Metrics (UCI HAR). <strong>b</strong> Comparison of Methods by Key Metrics (PAMAP2).</p></figcaption></figure><p id="Par135">As evidenced by the plots, Ours.Variational exhibits the highest median classification accuracy (89.6%) across both datasets, while also achieving the lowest KL divergence values. This indicates that the topological structure of features in the latent space is preserved during compression with minimal distortion. A noticeable entropy reduction to 1.96 units is also observed, reflecting effective compaction and suppression of noisy components. Ours.Stochastic-Boolean delivers the lowest latency (23.4 ms) and the smallest memory footprint (≈29 KB), which is critical for resource-constrained scenarios. This approach omits a decoding block, employs binary drop-coding, and demonstrates stable performance under unstable communication channels, particularly on devices such as ESP32 or STM32L with limited RAM (64–128 KB) and response time requirements below 30 ms. The FedEntropy, EDS-FL, and SER methods show lower performance metrics and higher variability. FedEntropy exhibits wide whiskers in the KL divergence metric, indicating unstable behaviour under different initialisations. The SER method consistently ranks lowest in accuracy (≈80.7%) and demonstrates the weakest trade-off between compression and informativeness retention, especially in multi-class and high-entropy HAR tasks. Thus, the variational version of the proposed concept is suitable when classification accuracy and feature representation quality are the primary priorities. In contrast, the stochastic-Boolean variant offers the best trade-offs in terms of latency and memory footprint, making it an optimal choice for applications in sensor networks, rehabilitation devices, and IoT scenarios with stringent constraints on computational and memory resources.</p>
<p id="Par136">To further analyse the effectiveness of feature compression, changes in input space entropy before and after projection were examined. This approach enables a quantitative assessment of how dimensionality reduction decreases redundant variability without compromising essential discriminative information. Such analysis is particularly relevant for edge systems with limited computational budgets, where every bit of information carries functional significance. Figure <a href="#Fig2" class="usa-link">2</a> presents the Shannon entropy values before compression (Before) and after compression (After) for each method on the UCI HAR and PAMAP2 datasets. Method names are placed along the x-axis, while entropy is measured in natural logarithmic units (nats) on the y-axis. For each method, numerical ΔEntropy values are also provided, indicating the depth of informational filtering achieved through compression.</p>
<figure class="fig xbox font-sm" id="Fig2"><h3 class="obj_head">Fig. 2.</h3>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12374004_41598_2025_16604_Fig2_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/715683b47a98/41598_2025_16604_Fig2_HTML.jpg" loading="lazy" id="d33e3487" height="323" width="733" alt="Fig. 2"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Change in feature entropy before and after compression across methods.</p></figcaption></figure><p id="Par137">The Ours.Variational projector achieves the most pronounced entropy reduction: 1.96 units on both UCI HAR and PAMAP2. The Ours.Stochastic-Boolean projector shows reductions of 1.74 and 1.61 units, respectively, indicating the high selectivity of the Boolean mask even in the absence of a decoding stage. Both variants maintain classification accuracy above 87%, demonstrating the effectiveness of information compression without sacrificing performance. The FedEntropy and EDS-FL methods reduce entropy by 1.28–1.36 units, which aligns with their stochastic nature; however, this reduction is not accompanied by adaptive reconstruction of the latent space. The SER method shows the smallest entropy changes (0.93 on both datasets) indicating low filtering capacity in multichannel scenarios. Overall, compression that achieves entropy reduction in the range of 1.6–2 units with stable classification accuracy (deviation ≤  ± 1.2%, σ ≤ 0.04) is indicative of constructive filtering. Such an approach preserves the intra-class topology of the latent space, which is critical for classification under heterogeneous data distributions. The proposed projectors (especially the stochastic-Boolean variant) prove to be highly relevant for edge devices operating under strict memory and latency constraints.</p>
<p id="Par138">To conduct a deeper analysis of how different compression methods affect the preservation of feature space topology, latent space visualisations were generated using t-SNE. This approach allows for evaluating the extent to which cluster structure is maintained after compression (an aspect that is critical for classification tasks on resource-constrained devices). The visualisation includes 200 randomly sampled latent vectors from the six most frequent classes in the UCI HAR dataset. For each method, dimensionality reduction was performed using t-SNE (perplexity = 35, iterations = 1000), with initial dimensionality reduction via PCA to 30 components. The resulting 2D projections were scaled to the range [–1, 1] along both axes. Figure <a href="#Fig3" class="usa-link">3</a> presents the 2D t-SNE projections of features before and after compression, enabling comparison of inter-cluster distance preservation and intra-cluster density for each method. The x- and y-axes represent the first and second t-SNE components without fixed interpretation, as the coordinates result from stochastic unfolding. Colours indicate class membership.</p>
<figure class="fig xbox font-sm" id="Fig3"><h3 class="obj_head">Fig. 3.</h3>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12374004_41598_2025_16604_Fig3_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/f300ccaa2d3f/41598_2025_16604_Fig3_HTML.jpg" loading="lazy" id="d33e3501" height="407" width="740" alt="Fig. 3"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>t-SNE projections of features before and after compression for UCI HAR (6 Classes).</p></figcaption></figure><p id="Par139">The results demonstrate that the Ours.Variational method produces compact, well-separated clusters that preserve the geometry of the original feature space. The Ours.Stochastic-Boolean projector achieves effective clustering with moderate overlap, maintaining structural similarity to the uncompressed representation. In contrast, the FedEntropy, EDS-FL, and SER methods result in significant degradation of cluster structure: pronounced inter-class overlap, fragmentation, and shifts in density centres are observed. Notably, SER exhibits the highest degree of inter-class confusion, consistent with its poorest classification metrics reported in Table <a href="#Tab3" class="usa-link">3</a>. Thus, the visual evaluation confirms the effectiveness of the proposed methods in preserving the topological characteristics of feature spaces—an essential factor for ensuring reliable classification under hardware-constrained conditions.</p>
<p id="Par140">To assess the preservation of classification-relevant structure within the latent representation, a spatial projection of compressed features into a two-dimensional space was performed. This analysis enables evaluation of the degree of semantic alignment between classes after information compression—an aspect that is critically important for effective distributed learning without centralised access to raw data. In this context, the UCI HAR dataset serves as a representative example due to the presence of motor activity classes with partial dynamic similarity, such as “sitting” and “standing” poses. This type of overlap creates increased classification difficulty even in the full feature space, making the dataset suitable for evaluating the robustness of compressed representations. For constructing the projection, the t-SNE method was applied to latent vectors obtained using the Ours.Variational projector. The random seed was fixed to ensure reproducibility of the results. Figure <a href="#Fig4" class="usa-link">4</a> presents two projections of the same latent space: on the left (with points coloured according to the predicted classes), and on the right (with reference (ground truth) labels). The axes represent the two t-SNE components, reflecting the topology of the high-dimensional latent space. Each point corresponds to a compressed feature vector for an individual segment of the sensor signal.</p>
<figure class="fig xbox font-sm" id="Fig4"><h3 class="obj_head">Fig. 4.</h3>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12374004_41598_2025_16604_Fig4_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/fc9bb209bddf/41598_2025_16604_Fig4_HTML.jpg" loading="lazy" id="d33e3518" height="253" width="728" alt="Fig. 4"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Spatial t-SNE visualisation of compressed features (Ours. Variational) Coloured by Predicted (Left) and Ground-Truth (Right) Labels (UCI HAR).</p></figcaption></figure><p id="Par141">As shown in Fig. <a href="#Fig4" class="usa-link">4</a>, under classification errors (approximately 25% random deviations), the predicted topology partially loses its boundary clarity between adjacent classes. This is particularly evident in the noticeable overlap of representations corresponding to the activities “sitting” and “standing,” as well as “walking” and “walking upstairs.” In contrast, classes with a clearly defined motor profile, such as “lying down,” remain topologically stable even under predicted labelling. This indicates the preservation of structurally relevant features necessary for distinguishing behavioural patterns. Such behaviour is typical in edge scenarios, where the allowable degree of compression must balance information loss against classification informativeness. Accordingly, the experiment confirms the effectiveness of using compressed latent vectors (obtained via the proposed approach) as structurally relevant input representations for local learning tasks under restricted data access in distributed intelligent systems.</p>
<p id="Par142">In federated learning, data heterogeneity across clients is a typical characteristic, making it essential to evaluate not only the model’s average performance but also its stability at the level of individual participants. This is particularly important in practical scenarios where predictable model behaviour under divergent data distributions is critical, for example, in mobile activity monitoring, personalised action analysis, or industrial sensor networks. To this end, three metrics were computed to characterise the quality and consistency of latent representations: classification accuracy, KL divergence, and entropy—individually for each client. Experiments were conducted on two structurally distinct datasets: UCI HAR (10 clients) and PAMAP2 (8 clients). Accuracy was measured as the proportion of correctly classified instances in the test subset. KL divergence captured the degree of deviation between a client’s local distribution of compressed features and the global latent space. Entropy reflected the residual uncertainty in the distribution of latent representations after stochastic compression via variational encoding. All values were normalised using min–max scaling separately for each dataset, ensuring mutual comparability. Figure <a href="#Fig5" class="usa-link">5</a> presents distribution plots of the mentioned metrics for each of the five methods: Ours.Variational, Ours.Stochastic-Boolean, FedEntropy, EDS-FL, and SER. The x-axis lists the methods in order of increasing complexity of the implemented information mechanisms. The y-axis displays the corresponding metric values: accuracy in percentages (79–92% for UCI HAR, 77–88% for PAMAP2), KL divergence (0.1–0.35 and 0.1–0.4), and entropy (2.5–4.5 and 2.8–4.8). The first three plots correspond to UCI HAR results, and the subsequent three to PAMAP2.</p>
<figure class="fig xbox font-sm" id="Fig5"><h3 class="obj_head">Fig. 5.</h3>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12374004_41598_2025_16604_Fig5_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/9055be9c9b8e/41598_2025_16604_Fig5_HTML.jpg" loading="lazy" id="d33e3535" height="391" width="718" alt="Fig. 5"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig5/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Distribution of classification accuracy, KL divergence, and entropy of compressed features across clients.</p></figcaption></figure><p id="Par143">Both proposed methods exhibit consistent advantages across all evaluated metrics. Ours.Variational achieves the highest mean classification accuracy with minimal variability across clients, indicating its ability to adapt while maintaining generalisability. Both variants also demonstrate lower KL divergence values, reflecting stronger alignment between local latent spaces and the global representation. The low entropy values (particularly for Ours.Variational) confirm effective compression without compromising informativeness. In contrast, the SER method exhibits the highest variance in results, considerable uncertainty, and limited adaptability to discrepancies in client-side data. Overall variability is greater in PAMAP2, which is expected due to the dataset’s higher feature density and lower structural coherence of actions. To ensure fair comparison, a unified sampling scheme, identical variational encoding parameters, and a consistent metric computation procedure were applied. This allowed for an objective assessment of method behaviour in environments with contrasting data characteristics. Figure <a href="#Fig5" class="usa-link">5</a> encapsulates a key aspect of the analysis—structural robustness of the methods to distributional heterogeneity, which is a critical factor in building reliable federated learning systems.</p>
<p id="Par144">The analysis of structural information localisation within the “class–client” matrix representation constitutes a key step in evaluating the ability of compression methods to preserve semantically relevant components of the feature distribution. This form of assessment allows for the direct visualisation of the informativeness of compressed representations within local client domains and reveals how effectively a method forms feature profiles with internal coherence and inter-class separability. Unlike conventional models, the proposed methods implement feature reconfiguration that accounts for clustering structures within the semantic space. As such, heatmaps serve as an appropriate and precise tool for verifying compression effectiveness in the context of information structuring. Figure <a href="#Fig6" class="usa-link">6</a> presents heatmaps of normalised Shannon entropy, computed across compressed feature vectors for each “class–client” pair in two datasets: UCI HAR (top row, 9 × 10) and PAMAP2 (bottom row, 7 × 8). Five methods are compared: Ours.Variational, Ours.Stochastic-Boolean, FedEntropy, EDS-FL, and SER. The x-axis represents classes, and the y-axis corresponds to clients; both scale and ordering are fixed. Entropy values are globally normalised within each dataset to the [0, 1] interval, enabling comparison regardless of absolute variation. A distinct colour scale is used for each dataset, with clearly labelled value ranges.</p>
<figure class="fig xbox font-sm" id="Fig6"><h3 class="obj_head">Fig. 6.</h3>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12374004_41598_2025_16604_Fig6_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/056cc5f45171/41598_2025_16604_Fig6_HTML.jpg" loading="lazy" id="d33e3553" height="303" width="724" alt="Fig. 6"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig6/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Entropy profile in the “class–client” space for ours and SOTA methods on the UCI HAR and PAMAP2 datasets.</p></figcaption></figure><p id="Par145">The results demonstrate that the Ours.Stochastic-Boolean method ensures a high degree of localised informational density. In the UCI HAR dataset, for clients 4–6 in the Walking and Sitting classes, entropy hotspots exceeding 0.92 are observed, whereas corresponding values for SER and FedEntropy do not exceed 0.5 in the same regions. In PAMAP2, similar effects appear in the Nordic Walking and Ironing classes for clients 2 and 7, with clearly defined high-density zones in the respective matrix elements. EDS-FL produces a diffuse information profile lacking stable dominants, indicating that semantic variations are smoothed out during compression. FedEntropy, in turn, reveals a fragmented structure with unstable inter-class localisation. In summary, the entropy heatmaps support the hypothesis that the structural compression implemented in the proposed methods effectively preserves semantic differentiation and localised informativeness. This is critically important for edge-AI systems operating in heterogeneous environments with limited resources and strict requirements for reconstructing key behavioural patterns.</p>
<p id="Par146">To comprehensively justify the effectiveness of the proposed compression concept (which implements an adaptive mechanism for limiting informational volume in the latent space) complementing the analysis of classification accuracy and entropic complexity with a visually oriented semantic assessment of feature topology is essential. In multi-class classification tasks, the preservation of spatially clustered structure even after intensive compression is a key prerequisite for maintaining stable model performance. Given the instability and temporal variability of t-SNE, the present experiment uses Principal Component Analysis (PCA) to construct interpretable visualisations by projecting onto the first two principal components, which retain over 85% of data variance according to experimental analysis. The resulting visualisation was stylistically adapted to match the t-SNE graphs to ensure a consistent presentation format. Figure <a href="#Fig7" class="usa-link">7</a> shows a comparison of latent feature space projections before and after compression for the two primary datasets—UCI HAR (top row) and PAMAP2 (bottom row). The x-axis represents the first principal component; the y-axis shows the second. Both axes are normalised according to empirical data spread. Each activity class is indicated using a unique symbol and colour, as defined in a unified legend placed outside the grid area. This visual structure allows for the evaluation of density, dispersion, and structural organisation of class distributions in the latent space before and after transformation.</p>
<figure class="fig xbox font-sm" id="Fig7"><h3 class="obj_head">Fig. 7.</h3>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12374004_41598_2025_16604_Fig7_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/aa59bebc03d4/41598_2025_16604_Fig7_HTML.jpg" loading="lazy" id="d33e3567" height="525" width="662" alt="Fig. 7"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig7/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Spatial projection of representations before and after compression.</p></figcaption></figure><p id="Par147">For the UCI HAR dataset, it is evident that most classes retain geometrically stable separation after compression. For instance, the walking, sitting, and standing clusters remain compact, while the upstairs walking class (which partially overlapped with walking before compression) exhibits enhanced separation post-transformation. In the case of PAMAP2, an even more pronounced stabilisation is observed: clusters that previously formed elongated, intersecting clouds (notably cycling and running) acquire clear topological segmentation after compression. Thus, the proposed approach not only conserves computational resources but also preserves the cluster organisation of features—an essential prerequisite for robust generalisation under variable sensor environments.</p>
<p id="Par148">For quantitative verification of the effectiveness of the developed approaches in the context of feature compression and the preservation of classification-relevant information, a comparative evaluation was conducted against SOTA methods using the mean Top-1 Accuracy metric on test sets formed with an 80:20 split, stratified by class labels from the UCI HAR and PAMAP2 datasets. The compression was performed to latent spaces of fixed dimensionality. Preprocessing steps included temporal window averaging, per-channel normalisation, and synchronisation of measurement frequencies. Figure <a href="#Fig8" class="usa-link">8</a> presents the comparative classification accuracy for each of the five tested methods. The x-axis lists the method names, and the y-axis shows the corresponding Top-1 Accuracy values expressed as percentages.</p>
<figure class="fig xbox font-sm" id="Fig8"><h3 class="obj_head">Fig. 8.</h3>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12374004_41598_2025_16604_Fig8_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/06e3427fb1cd/41598_2025_16604_Fig8_HTML.jpg" loading="lazy" id="d33e3581" height="414" width="710" alt="Fig. 8"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig8/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Top-1 Accuracy (%) on UCI HAR and PAMAP2 test sets for five methods using compressed latent representations.</p></figcaption></figure><p id="Par149">The results clearly demonstrate the superiority of the proposed approaches over the SOTA methods. Specifically, Ours.Variational consistently achieves the highest accuracy on both datasets (87.1% for UCI HAR and 86.3% for PAMAP2) outperforming the nearest competitor, FedEntropy, by 3.7% and 4.3%, respectively. The Ours.Stochastic-Boolean method also shows strong performance (85.6% and 84.2%), with minimal variability across datasets, highlighting its generalisation capacity. In contrast, SER and EDS-FL lag behind in accuracy, particularly on PAMAP2, where SER falls short by more than 7% compared to the best-performing method. Overall, the proposed approaches exhibit better adaptation to structural variability in the data and achieve high classification accuracy under critically constrained informational budgets—an essential advantage in distributed computing scenarios on edge devices.</p>
<p id="Par150">To ensure robust statistical validation and enhance the reproducibility of results, a formal comparative analysis was conducted between the proposed Ours.Variational method and the strongest among the considered SOTA approaches—FedEntropy. Its leading performance across several key metrics, as shown in Figs. <a href="#Fig6" class="usa-link">6</a>, <a href="#Fig7" class="usa-link">7</a> and <a href="#Fig8" class="usa-link">8</a>, justifies its selection as the primary baseline opponent. This comparison not only allows for a quantitative assessment of the effectiveness of information-constrained alignment but also captures the magnitude of its consistent empirical advantage. The evaluation covered six core metrics: classification accuracy, compression ratio, Kullback–Leibler divergence, entropy reduction, latency, and memory usage. Following normality testing via the Shapiro–Wilk test (α = 0.05), paired t-tests were applied to metrics with normal distributions (accuracy, entropy), while non-parametric Wilcoxon signed-rank tests were used for the remaining ones. One-way ANOVA was employed for between-group comparisons. Effect size was computed using paired Cohen’s <em>d</em>—defined as the mean difference between pairs divided by the standard deviation of those differences (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq323"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/634739b6f98f/d33e3598.gif" loading="lazy" id="d33e3598" alt="Inline graphic"></span>). Ninety-five percent confidence intervals for mean values were calculated using the t-distribution with four degrees of freedom (n = 5). All p-values were adjusted using the Holm–Bonferroni correction procedure. Table <a href="#Tab5" class="usa-link">5</a> presents a summary of the comparative results for the Ours.Variational—FedEntropy pair, including mean metric values ± 95% CI, significance levels of differences, and corresponding effect sizes.</p>
<section class="tw xbox font-sm" id="Tab5"><h3 class="obj_head">Table 5.</h3>
<div class="caption p"><p>Statistical comparison of methods across metrics (mean ± 95% CI, p-values and effect sizes for Ours.Variational vs. best SOTA, n = 5).</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Metric</th>
<th align="left" colspan="1" rowspan="1">Ours.Variational</th>
<th align="left" colspan="1" rowspan="1">Best SOTA (FedEntropy)</th>
<th align="left" colspan="1" rowspan="1">
<em>p</em>-value</th>
<th align="left" colspan="1" rowspan="1">Cohen’s <em>d</em>
</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Accuracy (%)</td>
<td align="center" colspan="1" rowspan="1">89.6 ± 1.8</td>
<td align="center" colspan="1" rowspan="1">85.3 ± 2.0</td>
<td align="center" colspan="1" rowspan="1">0.021</td>
<td align="center" colspan="1" rowspan="1">0.91</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Compression Ratio</td>
<td align="center" colspan="1" rowspan="1">2.42 ± 0.28</td>
<td align="center" colspan="1" rowspan="1">1.72 ± 0.33</td>
<td align="center" colspan="1" rowspan="1">0.036</td>
<td align="center" colspan="1" rowspan="1">0.85</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">KL-Divergence</td>
<td align="center" colspan="1" rowspan="1">0.106 ± 0.024</td>
<td align="center" colspan="1" rowspan="1">0.157 ± 0.030</td>
<td align="center" colspan="1" rowspan="1">0.049</td>
<td align="center" colspan="1" rowspan="1">0.76</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Entropy Reduction</td>
<td align="center" colspan="1" rowspan="1">2.05 ± 0.25</td>
<td align="center" colspan="1" rowspan="1">1.23 ± 0.27</td>
<td align="center" colspan="1" rowspan="1">0.018</td>
<td align="center" colspan="1" rowspan="1">0.93</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Latency (ms)</td>
<td align="center" colspan="1" rowspan="1">24.9 ± 3.8</td>
<td align="center" colspan="1" rowspan="1">28.1 ± 4.1</td>
<td align="center" colspan="1" rowspan="1">0.061</td>
<td align="center" colspan="1" rowspan="1">0.67</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Memory (KB)</td>
<td align="center" colspan="1" rowspan="1">44.6 ± 5.1</td>
<td align="center" colspan="1" rowspan="1">37.5 ± 4.9</td>
<td align="center" colspan="1" rowspan="1">0.072</td>
<td align="center" colspan="1" rowspan="1">0.63</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab5/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p id="Par151">According to Table <a href="#Tab5" class="usa-link">5</a>, the Ours.Variational approach consistently outperforms FedEntropy across all evaluated metrics. For classification accuracy, compression ratio, entropy reduction, and KL divergence, the advantages are statistically significant (p &lt; 0.05), with effect sizes ranging from 0.76 to 0.93—indicating moderate to large effects. The metrics for latency and memory usage show favourable trends for the proposed method; however, these differences do not reach statistical significance, likely due to limited statistical power with m = 5. Nevertheless, the non-overlapping confidence intervals for these indicators support the interpretation of a practical advantage. Overall, the proposed approach not only surpasses existing methods across several critical dimensions but also demonstrates statistically robust and stable results within a justified number of experimental runs.</p>
<p id="Par152">One of the key advantages of the proposed mathematical framework lies in its modular architecture, which not only simplifies adaptation to the computational constraints of edge devices but also enables flexible reconfiguration of functional blocks to optimise performance. In this context, an ablation analysis is appropriate to analytically verify the contribution of each architectural component to the balance between compression, accuracy, and efficiency. Such an approach ensures model explainability and enables the identification of critical pathways for transmitting semantically meaningful features within the latent pipeline—an especially important consideration in edge deployments where disruptions to the computational flow are likely. The ablation study was conducted for the Ours.Variational projector using the test split of the UCI HAR dataset under the following fixed conditions: latent dimension <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq324"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/1d5a94642383/d33e3711.gif" loading="lazy" id="d33e3711" alt="Inline graphic"></span>, batch size = 64, 40 training epochs, random seed = 42, and optimisation with Adam (learning rate = 0.001, β₁ = 0.9, β₂ = 0.999). To assess the contribution of individual components, the following were sequentially removed: the regularisation term (λ = 0), the stochastic projection layer (Sampling Layer), the reconstruction decoder, and the feature selection module—while keeping the remainder of the configuration unchanged. Each variant was fully retrained under identical conditions. The evaluation metrics included: classification accuracy, empirical entropy change between input and corresponding latent representations (estimated via discretised histograms), KL divergence, compression ratio (CR), average latency, and memory usage. KL divergence was not computed when regularisation was disabled. The results are summarised in Table <a href="#Tab6" class="usa-link">6</a>.</p>
<section class="tw xbox font-sm" id="Tab6"><h3 class="obj_head">Table 6.</h3>
<div class="caption p"><p>Ablation analysis of the proposed variational method on UCI HAR dataset (mean ± standard deviation across 20 runs).</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Configuration</th>
<th align="left" colspan="1" rowspan="1">Accuracy (%)</th>
<th align="left" colspan="1" rowspan="1">ДEntropy</th>
<th align="left" colspan="1" rowspan="1">KL-Div</th>
<th align="left" colspan="1" rowspan="1">CR</th>
<th align="left" colspan="1" rowspan="1">Latency (ms)</th>
<th align="left" colspan="1" rowspan="1">Memory (KB)</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Ours.Variational</td>
<td align="center" colspan="1" rowspan="1">89.6</td>
<td align="center" colspan="1" rowspan="1">1.96</td>
<td align="left" colspan="1" rowspan="1">0.095</td>
<td align="center" colspan="1" rowspan="1">0.25</td>
<td align="center" colspan="1" rowspan="1">25.9</td>
<td align="left" colspan="1" rowspan="1">41</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Without Regularisation (л = 0)</td>
<td align="center" colspan="1" rowspan="1">85.3</td>
<td align="center" colspan="1" rowspan="1">1.34</td>
<td align="left" colspan="1" rowspan="1">n/a</td>
<td align="center" colspan="1" rowspan="1">0.25</td>
<td align="center" colspan="1" rowspan="1">24.3</td>
<td align="left" colspan="1" rowspan="1">39</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Without Stochastic Projection</td>
<td align="center" colspan="1" rowspan="1">85.9</td>
<td align="center" colspan="1" rowspan="1">1.41</td>
<td align="left" colspan="1" rowspan="1">0.112</td>
<td align="center" colspan="1" rowspan="1">0.26</td>
<td align="center" colspan="1" rowspan="1">25.5</td>
<td align="left" colspan="1" rowspan="1">40</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Without Reconstruction Decoder</td>
<td align="center" colspan="1" rowspan="1">81.6</td>
<td align="center" colspan="1" rowspan="1">1.08</td>
<td align="left" colspan="1" rowspan="1">0.153</td>
<td align="center" colspan="1" rowspan="1">0.25</td>
<td align="center" colspan="1" rowspan="1">23.6</td>
<td align="left" colspan="1" rowspan="1">32</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Without Feature Selector</td>
<td align="center" colspan="1" rowspan="1">82.4</td>
<td align="center" colspan="1" rowspan="1">1.20</td>
<td align="left" colspan="1" rowspan="1">0.138</td>
<td align="center" colspan="1" rowspan="1">0.28</td>
<td align="center" colspan="1" rowspan="1">25.3</td>
<td align="left" colspan="1" rowspan="1">36</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab6/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p id="Par153">The results reveal the structural cohesion of the model and the critical role of each component. Disabling regularisation reduces classification accuracy by more than 4% while keeping the compression ratio constant, indicating latent space degradation in the absence of entropy control. Notably, memory usage decreases by only 2 KB, confirming the localised impact of the regularisation module. Omitting the stochastic projection leads to a moderate decline in both entropy and accuracy, accompanied by a slight increase in the compression ratio. The most significant accuracy drop (− 8%) is observed when the reconstruction decoder is removed, highlighting its essential role in preserving the semantic richness of the latent space. This configuration, however, yields the greatest memory savings (− 9 KB). Eliminating the feature selection module increases the compression ratio (to 0.28), suggesting oversaturation of the latent vector with non-informative features that are transmitted without prior ranking.</p>
<p id="Par154">To quantitatively clarify the contribution of each structural module to the effectiveness of the proposed approach, the ablation analysis was extended to empirically examine the significance of the regularisation component, the stochastic mechanism, the reconstruction module (decoder), and the selector in the context of the trade-off between accuracy, compression, and informativeness of the latent representation. All configurations maintained the same latent space width (16 channels) and a fixed quantisation mode (4 bits per element), ensuring comparability of results. For each modification, five independent runs of the model were performed with different initial seed. This number ensures a sufficient balance between statistical stability and the computational cost of modelling. The mean values of three key metrics were recorded: reconstruction accuracy (Accuracy, %), entropy shift (ΔEntropy, bits per element) between the input and compressed space, and compression ratio (Compression Ratio) () the ratio of the latent representation size to the input tensor. Figure <a href="#Fig9" class="usa-link">9</a> presents three aligned bar charts with confidence intervals for each of the listed metrics. The results are shown for the full model (Baseline) and four of its modified versions with individual modules ablated. Configuration names are placed along the horizontal axis in all cases. The vertical axes respectively show: reconstruction accuracy (in percent), discrete entropy shift (in bits), and compression ratio. The ΔEntropy value was defined as the difference between the estimates of discretised entropy at the input and in the latent representation, averaged over the test set, which enables a quantitative assessment of the degree of redundancy removal.</p>
<figure class="fig xbox font-sm" id="Fig9"><h3 class="obj_head">Fig. 9.</h3>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12374004_41598_2025_16604_Fig9_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/a44d4ddbaf5a/41598_2025_16604_Fig9_HTML.jpg" loading="lazy" id="d33e3839" height="681" width="682" alt="Fig. 9"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig9/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Charts of reconstruction accuracy, entropy shift, and compression ratio for the full and ablated configurations of the proposed method.</p></figcaption></figure><p id="Par155">The charts clearly demonstrate the distinct contribution of each functional block to the overall system performance. The full model achieves the highest accuracy () approximately 89.6% top-1 accuracy across semantic segmentation classes, with a maximum entropy shift of approximately 1.96 and a compression ratio of approximately 0.251. Disabling the regularisation leads to a drop in accuracy to approximately 85.3%, along with a decrease in ΔEntropy, indicating a weakening of selective filtering. A similar trend is observed when the stochastic block is removed. The most critical impact results from the exclusion of the decoder—accuracy sharply declines to approximately 81.6%, while ΔEntropy falls to approximately 1.08, indicating a substantial loss of informativeness in the latent space due to the absence of a mechanism for reconstructing the input structures. At the same time, the compression ratio across all configurations remains within the range [0.248–0.278], which is fully consistent with architectural constraints on channel depth. In summary, the conducted ablation analysis convincingly confirms the critical role of all structural components of the system. Their coordinated interaction enables an improvement in reconstruction accuracy of over 4% compared to the best-performing ablated configuration (without regularisation), without significant loss in compression ratio or informational richness of the latent representation.</p>
<p id="Par156">To further investigate the robustness of the proposed framework with respect to entropy regularisation, we conducted a parametric sensitivity analysis of the λ parameter across its operational interval. The results, summarised in Fig. <a href="#Fig5" class="usa-link">5</a> and supported by the ablation study in Fig. <a href="#Fig9" class="usa-link">9</a>, reveal that the model maintains high classification accuracy (above 93%) and consistent entropy suppression within the range <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq325"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/3ffcc5b46359/d33e3850.gif" loading="lazy" id="d33e3850" alt="Inline graphic"></span>. The compression performance remains stable across this range, with less than 2% variance in semantic reconstruction metrics and entropy deviation. This behaviour confirms that the method is not overly sensitive to precise hyperparameter tuning and can be reliably deployed in practical edge environments with moderate calibration effort. Moreover, the decoupled formulation of the quality functional <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq326"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/0294eadb18e7/d33e3856.gif" loading="lazy" id="d33e3856" alt="Inline graphic"></span> ensures that <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq327"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/fc34/12374004/95c7c0c413ff/d33e3862.gif" loading="lazy" id="d33e3862" alt="Inline graphic"></span> can be aligned with system-specific constraints, such as target bitrate or task-critical information fidelity.</p>
<p id="Par157">To summarise the Sect., the authorial approaches demonstrate high practical efficiency in tasks with constrained computational resources, typical for edge devices such as Jetson Nano, ESP32, STM32L, and Raspberry Pi 4. The experiments were conducted using the UCI HAR and PAMAP2 datasets (see Table <a href="#Tab3" class="usa-link">3</a>). Specifically, the stochastic-Boolean projector Ours.Stochastic-Boolean achieves latency of up to 23.4 ms and memory consumption of approximately 29 KB, which meets real-time requirements for TinyML-class systems. The variational version of the projector Ours.Variational reaches the highest classification accuracy of 89.6% on both datasets with a compression ratio of 0.25 (see Figs. <a href="#Fig1" class="usa-link">1</a>a, b, <a href="#Fig8" class="usa-link">8</a>). Both methods demonstrate a significant reduction in feature entropy (up to –1.96 units; see Fig. <a href="#Fig2" class="usa-link">2</a>), which reduces redundancy and enhances the discriminative capacity of the latent space under conditions of sensor noise or limited input signal precision. Comparative analysis with state-of-the-art approaches to information-constrained compression (FedEntropy, EDS-FL, SER) revealed the superiority of the proposed methods across key metrics. The Ours.Variational method exceeded the accuracy of SER by 8.9% (89.6% versus 80.7%) and halved the KL divergence (0.095 versus 0.202), while preserving the topological structure of the latent space (see Figs. <a href="#Fig3" class="usa-link">3</a> and <a href="#Fig4" class="usa-link">4</a>). The Ours.Stochastic-Boolean variant, in turn, is characterised by the lowest computational and memory requirements among all the methods considered. Both approaches demonstrated stable performance: metric variability across five independent runs did not exceed σ = 0.04, and inter-client differences in accuracy, KL divergence, and entropy remained minimal even in heterogeneous (non-IID) scenarios (see Figs. <a href="#Fig5" class="usa-link">5</a> and <a href="#Fig6" class="usa-link">6</a>). Compression efficiency and preservation of cluster structure during dimensionality reduction were confirmed at the individual client level (see Fig. <a href="#Fig7" class="usa-link">7</a>). The contribution of each architectural component was analysed in detail through a sensitivity study (see Fig. <a href="#Fig9" class="usa-link">9</a>, Table <a href="#Tab6" class="usa-link">6</a>). The applicability of the proposed solutions covers a wide range of tasks from personalised physical activity monitoring and rehabilitation trackers to smart bracelets, e-health devices, and sensor nodes in industrial IoT systems. For instance, in motion type classification tasks (sitting, standing, walking), the stochastic variant achieves accuracy exceeding 87% with latency below 25 ms, enabling effective real-time event response even without continuous network connectivity. It is noteworthy that all experiments were conducted using open-source toolkits (PyTorch, Flower, TFLite Micro), which ensures full reproducibility and flexible deployment in embedded environments.</p>
<p id="Par158">While the proposed framework demonstrates robust performance across multiple evaluation metrics, several limitations should be acknowledged to define its current applicability. First, the experimental validation was limited to two benchmark datasets (HAR and PAMAP2) that feature moderate-dimensional, relatively stable sensor-based data. The model’s behaviour under more dynamic, sparse, or nonlinear feature spaces remains unexplored and is left for future investigation. Second, both modules (variational entropy-regularised projection and stochastic Boolean projection) depend on critical hyperparameters (e.g. entropy regularisation weight λλ, compactness threshold θθ). Although empirical tuning yielded stable behaviour within the evaluated regimes, a systematic optimisation framework could improve deployment adaptability in diverse operational conditions. Third, the current architecture assumes structural properties such as non-negativity and compactness of the input features. While this aligns well with telemetry and time-series domains, broader applicability to unstructured or high-variance feature spaces may require architectural generalisation. Additionally, the computational overhead of stochastic Boolean projection increases exponentially with feature dimensionality. This challenge was mitigated through sampling constraints; however, scalability in high-dimensional scenarios remains an open issue. Finally, evaluations were conducted on embedded platforms (Jetson Nano, Raspberry Pi 4) under simulated federated learning conditions with non-IID distributions and communication noise. While initial results show resilience to entropy perturbation and packet loss, generalisability across real-world federated deployments with heterogeneous client setups warrants further examination. hese considerations do not undermine the method’s efficacy within its targeted application scope but rather define the contours of its current operational range. To mitigate these limitations, future research will extend the architecture to accommodate dynamic feature spaces through adaptive entropy control, incorporate meta-optimisation strategies for context-aware hyperparameter tuning, and assess scalability on synthetic high-dimensional benchmarks. In addition, real-world federated deployments involving heterogeneous clients and diverse communication protocols will be explored to further validate robustness and generalisability.</p></section><section id="Sec9"><h2 class="pmc_sec_title">Conclusions</h2>
<p id="Par159">In this study, a novel two-component architecture for information-constrained feature compression in distributed edge AI and federated learning environments has been developed and evaluated. The proposed framework combines a variational-reconstructive encoder based on projection-gradient optimisation with orthant constraints, and a stochastic-Boolean encoder that leverages entropy-regularised Lagrangian masking. By formulating the compression process as a variational optimisation of a directed KL-based functional with entropy perturbation, the framework enables structured, entropy-aware transformation of features under stringent latency, memory, and energy constraints.</p>
<p id="Par160">The analytical analysis confirms that the functional is lower-bounded and quasi-convex over the positive orthant, enabling efficient optimisation through a FISTA-type scheme. The resulting compressed representations preserve semantic cluster consistency and support reliable reconstruction under stochastic distortions. The Boolean component further ensures compactness and robustness through the use of the Fermi–Dirac distribution and entropy-constrained divergence minimisation. Closed-form posterior solutions enable effective bit-level selection without reliance on heuristics.</p>
<p id="Par161">Experimental evaluations on the UCI HAR and PAMAP2 benchmarks demonstrate that the variational strategy consistently reduces entropy power while maintaining classification accuracy within ± 1.5% of the original models and significantly lowering inference latency and memory usage on Jetson Nano devices. The Boolean strategy achieves favourable divergence minimisation, robustness under non-IID and noisy settings, and stable performance across 8–16-bit implementations, supporting its suitability for deployment in low-power environments.</p>
<p id="Par162">The central contribution of this work lies in the integration of entropy-constrained optimisation with projection-based and stochastic masking strategies for efficient and robust feature compression. This contributes to the broader objective of enabling scalable, privacy-preserving, and energy-efficient edge intelligence without centralised retraining or raw data exchange.</p>
<p id="Par163">Practically, the architecture facilitates decentralised model inference under URLLC conditions, supports adaptation to changing QoS profiles, and substantially reduces the load on communication channels. Theoretically, it advances the formal understanding of entropy-guided latent space design under variational regularisation. Societally, it provides a foundation for privacy-aware analytics in sensitive domains such as eHealth, smart infrastructure, and embedded monitoring. While the proposed framework is theoretically modality-agnostic, the current evaluation has been limited to time-series sensor data; future work will aim to extend the approach to additional domains such as vision, speech, and environmental sensing.</p>
<p id="Par164">While this work demonstrates the feasibility and effectiveness of the proposed entropy-regularised stochastic encoding framework under constrained edge and federated learning scenarios, several research directions remain open. A heterogeneous edge testbed is currently being developed, including Jetson Orin Nano, Raspberry Pi 5, and ESP32 platforms, to support real-time input streaming, variable packet latency, and dynamic client availability. This setup will enable evaluation under realistic network and resource conditions. Although the current evaluation focused on classification, the framework is inherently task-agnostic. Future studies will explore its application to anomaly detection via entropy dynamics in the latent space and to time series forecasting through integration with temporal sequence models. These tasks are expected to assess the semantic robustness and reusability of compressed representations. In federated learning scenarios, the integration of dropout-tolerant aggregation schemes such as FedAvgM and FedProx is planned. Owing to its low communication footprint and modular architecture, the proposed framework is well-suited for asynchronous or partially synchronous client participation. Further investigations will target robustness under challenging conditions, including adversarial noise, incomplete data, and domain shifts. Techniques under consideration include entropy-guided denoising, uncertainty-aware filtering, and self-supervised regularisation. Additionally, future iterations will explore interpretable projection mechanisms, including entropy-based saliency mapping and low-dimensional visualisation techniques.</p>
<p id="Par165">These enhancements are expected to strengthen the framework’s applicability for real-world deployment in heterogeneous, privacy-sensitive, and resource-constrained intelligent systems.</p></section><section id="ack1" class="ack"><h2 class="pmc_sec_title">Acknowledgements</h2>
<p>The author is grateful to all colleagues and institutions that contributed to the research and made it possible to publish its results.</p></section><section id="notes1"><h2 class="pmc_sec_title">Author contributions</h2>
<p>V.K. (Viacheslav Kovtun) was solely responsible for the conception and design of the study, the development of the analytical models, the implementation of the reinforcement learning framework, the execution of all experiments, the analysis and interpretation of results, and the writing and revision of the manuscript.</p></section><section id="notes2"><h2 class="pmc_sec_title">Funding</h2>
<p>No funding.</p></section><section id="notes3"><h2 class="pmc_sec_title">Data availability</h2>
<p>The datasets used in this study are publicly available and subject to their respective licensing terms. The UCI HAR dataset is available at: <a href="https://www.kaggle.com/c/uci-har" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/c/uci-har</a> and is distributed under the Creative Commons Attribution 4.0 International (CC BY 4.0) license, permitting sharing and adaptation with proper citation. The PAMAP2 Physical Activity Monitoring dataset is accessible at: <a href="https://www.kaggle.com/code/avrahamcalev/time-series-models-pamap2-dataset" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/code/avrahamcalev/time-series-models-pamap2-dataset</a>, also under the CC BY 4.0 license, requiring attribution for any use. No additional data were generated during the current study.</p></section><section id="notes4"><h2 class="pmc_sec_title">Declarations</h2>
<section id="FPar1"><h3 class="pmc_sec_title">Competing interests</h3>
<p id="Par167">The authors declare no competing interests.</p></section></section><section id="fn-group1" class="fn-group"><h2 class="pmc_sec_title">Footnotes</h2>
<div class="fn-group p font-secondary-light font-sm"><div class="fn p" id="fn1">
<p><strong>Publisher’s note</strong></p>
<p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</div></div></section><section id="Bib1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="Bib1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="CR1">
<span class="label">1.</span><cite>Alharbey, R. A. &amp; Jamil, F. Federated learning framework for real-time activity and context monitoring using edge devices. <em>Sensors</em><strong>25</strong>(4), 1266. 10.3390/s25041266 (2025).
</cite> [<a href="https://doi.org/10.3390/s25041266" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11861869/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/40006493/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Alharbey,%20R.%20A.%20&amp;%20Jamil,%20F.%20Federated%20learning%20framework%20for%20real-time%20activity%20and%20context%20monitoring%20using%20edge%20devices.%20Sensors25(4),%201266.%2010.3390/s25041266%20(2025)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR2">
<span class="label">2.</span><cite>Ge, Y. &amp; Ren, Y. Federated transfer fault diagnosis method based on variational auto-encoding with few-shot learning. <em>Mathematics</em><strong>12</strong>(13), 2142. 10.3390/math12132142 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Ge,%20Y.%20&amp;%20Ren,%20Y.%20Federated%20transfer%20fault%20diagnosis%20method%20based%20on%20variational%20auto-encoding%20with%20few-shot%20learning.%20Mathematics12(13),%202142.%2010.3390/math12132142%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR3">
<span class="label">3.</span><cite>Shaik, T. et al. FedStack: Personalized activity monitoring using stacked federated learning. <em>Knowl.-Based Syst.</em><strong>257</strong>, 109929. 10.1016/j.knosys.2022.109929 (2022).</cite> [<a href="https://scholar.google.com/scholar_lookup?Shaik,%20T.%20et%20al.%20FedStack:%20Personalized%20activity%20monitoring%20using%20stacked%20federated%20learning.%20Knowl.-Based%20Syst.257,%20109929.%2010.1016/j.knosys.2022.109929%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR4">
<span class="label">4.</span><cite>Ukoba, K., Olatunji, K. O., Adeoye, E., Jen, T.-C. &amp; Madyira, D. M. Optimizing renewable energy systems through artificial intelligence: Review and future prospects. <em>Energy Environ.</em><strong>35</strong>(7), 3833–3879. 10.1177/0958305x241256293 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Ukoba,%20K.,%20Olatunji,%20K.%20O.,%20Adeoye,%20E.,%20Jen,%20T.-C.%20&amp;%20Madyira,%20D.%20M.%20Optimizing%20renewable%20energy%20systems%20through%20artificial%20intelligence:%20Review%20and%20future%20prospects.%20Energy%20Environ.35(7),%203833%E2%80%933879.%2010.1177/0958305x241256293%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR5">
<span class="label">5.</span><cite>Chan, J. C. K., Mahjoubfar, A., Chen, C. L. &amp; Jalali, B. Context-aware image compression. <em>PLOS ONE</em><strong>11</strong>(7), e0158201. 10.1371/journal.pone.0158201 (2016).
</cite> [<a href="https://doi.org/10.1371/journal.pone.0158201" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4930214/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27367904/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Chan,%20J.%20C.%20K.,%20Mahjoubfar,%20A.,%20Chen,%20C.%20L.%20&amp;%20Jalali,%20B.%20Context-aware%20image%20compression.%20PLOS%20ONE11(7),%20e0158201.%2010.1371/journal.pone.0158201%20(2016)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR6">
<span class="label">6.</span><cite>Jamshidi, M., Kalhor, A. &amp; Vahabie, A.-H. Efficient compression of encoder-decoder models for semantic segmentation using the separation index. <em>Sci. Rep.</em><strong>15</strong>(1), 10348. 10.1038/s41598-025-10348-9 (2025).
</cite> [<a href="https://doi.org/10.1038/s41598-025-10348-9" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC12241452/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/40634505/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Jamshidi,%20M.,%20Kalhor,%20A.%20&amp;%20Vahabie,%20A.-H.%20Efficient%20compression%20of%20encoder-decoder%20models%20for%20semantic%20segmentation%20using%20the%20separation%20index.%20Sci.%20Rep.15(1),%2010348.%2010.1038/s41598-025-10348-9%20(2025)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR7">
<span class="label">7.</span><cite>Zhou, Y., Zhang, Y., Zhang, F., Zhang, Y. &amp; Wang, X. Trajectory compression with spatio-temporal semantic constraints. <em>ISPRS Int. J. Geo Inf.</em><strong>13</strong>(6), 212. 10.3390/ijgi13060212 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Zhou,%20Y.,%20Zhang,%20Y.,%20Zhang,%20F.,%20Zhang,%20Y.%20&amp;%20Wang,%20X.%20Trajectory%20compression%20with%20spatio-temporal%20semantic%20constraints.%20ISPRS%20Int.%20J.%20Geo%20Inf.13(6),%20212.%2010.3390/ijgi13060212%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR8">
<span class="label">8.</span><cite>Montavon, G., Binder, A., Lapuschkin, S., Samek, W., &amp; Müller, K.-R. (2019). Layer-Wise Relevance Propagation: An Overview. In Lecture Notes in Computer Science (pp. 193–209). Springer International Publishing. 10.1007/978-3-030-28954-6_10</cite>
</li>
<li id="CR9">
<span class="label">9.</span><cite>Brauwers, G. &amp; Frasincar, F. A general survey on attention mechanisms in deep learning. <em>IEEE Trans. Knowl. Data Eng.</em><strong>35</strong>(4), 3279–3298. 10.1109/tkde.2021.3126456 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Brauwers,%20G.%20&amp;%20Frasincar,%20F.%20A%20general%20survey%20on%20attention%20mechanisms%20in%20deep%20learning.%20IEEE%20Trans.%20Knowl.%20Data%20Eng.35(4),%203279%E2%80%933298.%2010.1109/tkde.2021.3126456%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR10">
<span class="label">10.</span><cite>Ye, J., Yeo, H., Park, J., &amp; Han, D. (2023). AccelIR: Task-aware Image Compression for Accelerating Neural Restoration. In 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (pp. 18216–18226). 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). IEEE. 10.1109/cvpr52729.2023.01747</cite>
</li>
<li id="CR11">
<span class="label">11.</span><cite>Weingarten, N. Z., Yakhini, Z., Butman, M. &amp; Bustin, R. The Supervised Information Bottleneck. <em>Entropy</em><strong>27</strong>(5), 452. 10.3390/e27050452 (2025).
</cite> [<a href="https://doi.org/10.3390/e27050452" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC12110060/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/40422407/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Weingarten,%20N.%20Z.,%20Yakhini,%20Z.,%20Butman,%20M.%20&amp;%20Bustin,%20R.%20The%20Supervised%20Information%20Bottleneck.%20Entropy27(5),%20452.%2010.3390/e27050452%20(2025)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR12">
<span class="label">12.</span><cite>Kera, H. &amp; Hasegawa, Y. Gradient boosts the approximate vanishing ideal. <em>Proc. AAAI Conf. AI.</em><strong>34</strong>(04), 4428–4435. 10.1609/aaai.v34i04.5869 (2020).</cite> [<a href="https://scholar.google.com/scholar_lookup?Kera,%20H.%20&amp;%20Hasegawa,%20Y.%20Gradient%20boosts%20the%20approximate%20vanishing%20ideal.%20Proc.%20AAAI%20Conf.%20AI.34(04),%204428%E2%80%934435.%2010.1609/aaai.v34i04.5869%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR13">
<span class="label">13.</span><cite>Dai, C. et al. Masked feature compression for object detection. <em>Mathematics</em><strong>12</strong>(12), 1848. 10.3390/math12121848 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Dai,%20C.%20et%20al.%20Masked%20feature%20compression%20for%20object%20detection.%20Mathematics12(12),%201848.%2010.3390/math12121848%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR14">
<span class="label">14.</span><cite>Zhang, S., &amp; Duan, P. (2023). Attention-Guided Motion Estimation for Video Compression. In Lecture Notes in Computer Science (pp. 142–154). Springer Nature Switzerland. 10.1007/978-3-031-46305-1_12</cite>
</li>
<li id="CR15">
<span class="label">15.</span><cite>Huang, Z. et al. Attention guided tongue segmentation with geometric knowledge in complex environments. <em>Biomed. Signal Process. Control</em><strong>104</strong>, 107426. 10.1016/j.bspc.2024.107426 (2025).</cite> [<a href="https://scholar.google.com/scholar_lookup?Huang,%20Z.%20et%20al.%20Attention%20guided%20tongue%20segmentation%20with%20geometric%20knowledge%20in%20complex%20environments.%20Biomed.%20Signal%20Process.%20Control104,%20107426.%2010.1016/j.bspc.2024.107426%20(2025)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR16">
<span class="label">16.</span><cite>Rodríguez Gálvez, B., Thobaben, R. &amp; Skoglund, M. The convex information bottleneck lagrangian. <em>Entropy</em><strong>22</strong>(1), 98. 10.3390/e22010098 (2020).
</cite> [<a href="https://doi.org/10.3390/e22010098" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7516537/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33285873/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Rodr%C3%ADguez%20G%C3%A1lvez,%20B.,%20Thobaben,%20R.%20&amp;%20Skoglund,%20M.%20The%20convex%20information%20bottleneck%20lagrangian.%20Entropy22(1),%2098.%2010.3390/e22010098%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR17">
<span class="label">17.</span><cite>Solera-Rico, A. et al. β-Variational autoencoders and transformers for reduced-order modelling of fluid flows. <em>Nature Commun.</em><strong>15</strong>(1), 45578. 10.1038/s41467-024-45578-4 (2024).</cite> [<a href="https://doi.org/10.1038/s41467-024-45578-4" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10866995/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38355720/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Solera-Rico,%20A.%20et%20al.%20%CE%B2-Variational%20autoencoders%20and%20transformers%20for%20reduced-order%20modelling%20of%20fluid%20flows.%20Nature%20Commun.15(1),%2045578.%2010.1038/s41467-024-45578-4%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR18">
<span class="label">18.</span><cite>Pan, W., Long, F. &amp; Pan, J. ScInfoVAE: Interpretable dimensional reduction of single cell transcription data with variational autoencoders and extended mutual information regularization. <em>BioData Mining</em><strong>16</strong>(1), 333. 10.1186/s13040-023-00333-1 (2023).</cite> [<a href="https://doi.org/10.1186/s13040-023-00333-1" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10257850/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37301826/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Pan,%20W.,%20Long,%20F.%20&amp;%20Pan,%20J.%20ScInfoVAE:%20Interpretable%20dimensional%20reduction%20of%20single%20cell%20transcription%20data%20with%20variational%20autoencoders%20and%20extended%20mutual%20information%20regularization.%20BioData%20Mining16(1),%20333.%2010.1186/s13040-023-00333-1%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR19">
<span class="label">19.</span><cite>Choi, Y., El-Khamy, M., &amp; Lee, J. (2019). Variable Rate Deep Image Compression With a Conditional Autoencoder. In 2019 IEEE/CVF International Conference on Computer Vision (ICCV) (pp. 3146–3154). 2019 IEEE/CVF International Conference on Computer Vision (ICCV). IEEE. 10.1109/iccv.2019.00324</cite>
</li>
<li id="CR20">
<span class="label">20.</span><cite>JimÉnez-Navarro, M. J., MartÍnez-Ballesteros, M., Brito, I. S., MartÍnez-Álvarez, F. &amp; Asencio-CortÉs, G. Embedded feature selection for neural networks via learnable drop layer. <em>Logic J. IGPL</em>10.1093/jigpal/jzae062 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Jim%C3%89nez-Navarro,%20M.%20J.,%20Mart%C3%8Dnez-Ballesteros,%20M.,%20Brito,%20I.%20S.,%20Mart%C3%8Dnez-%C3%81lvarez,%20F.%20&amp;%20Asencio-Cort%C3%89s,%20G.%20Embedded%20feature%20selection%20for%20neural%20networks%20via%20learnable%20drop%20layer.%20Logic%20J.%20IGPL10.1093/jigpal/jzae062%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR21">
<span class="label">21.</span><cite>Cui, J., Bai, L., Zhang, X., Lin, Z. &amp; Liu, Q. The attention-based autoencoder for network traffic classification with interpretable feature representation. <em>Symmetry</em><strong>16</strong>(5), 589. 10.3390/sym16050589 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Cui,%20J.,%20Bai,%20L.,%20Zhang,%20X.,%20Lin,%20Z.%20&amp;%20Liu,%20Q.%20The%20attention-based%20autoencoder%20for%20network%20traffic%20classification%20with%20interpretable%20feature%20representation.%20Symmetry16(5),%20589.%2010.3390/sym16050589%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR22">
<span class="label">22.</span><cite>Lin, W., Zhao, X., Wang, Y., Xu, T., &amp; Wu, X. (2022). AdaFS: Adaptive Feature Selection in Deep Recommender System. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (pp. 3309–3317). KDD ’22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. ACM. 10.1145/3534678.3539204</cite>
</li>
<li id="CR23">
<span class="label">23.</span><cite>Wild, R., Wodaczek, F., Del Tatto, V., Cheng, B. &amp; Laio, A. Automatic feature selection and weighting in molecular systems using differentiable information imbalance. <em>Nature Commun.</em><strong>16</strong>(1), 55449. 10.1038/s41467-024-55449-7 (2025).</cite> [<a href="https://doi.org/10.1038/s41467-024-55449-7" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11696465/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39747013/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Wild,%20R.,%20Wodaczek,%20F.,%20Del%20Tatto,%20V.,%20Cheng,%20B.%20&amp;%20Laio,%20A.%20Automatic%20feature%20selection%20and%20weighting%20in%20molecular%20systems%20using%20differentiable%20information%20imbalance.%20Nature%20Commun.16(1),%2055449.%2010.1038/s41467-024-55449-7%20(2025)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR24">
<span class="label">24.</span><cite>Bartolucci, F., Pandolfi, S. &amp; Pennoni, F. Discrete latent variable models. <em>Ann. Rev. Stat. Appl.</em><strong>9</strong>(1), 425–452. 10.1146/annurev-statistics-040220-091910 (2022).</cite> [<a href="https://scholar.google.com/scholar_lookup?Bartolucci,%20F.,%20Pandolfi,%20S.%20&amp;%20Pennoni,%20F.%20Discrete%20latent%20variable%20models.%20Ann.%20Rev.%20Stat.%20Appl.9(1),%20425%E2%80%93452.%2010.1146/annurev-statistics-040220-091910%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR25">
<span class="label">25.</span><cite>Chen, M., Shlezinger, N., Poor, H. V., Eldar, Y. C. &amp; Cui, S. Communication-efficient federated learning. <em>Proc. Natl. Acad. Sci.</em><strong>118</strong>(17), 89118. 10.1073/pnas.2024789118 (2021).</cite> [<a href="https://doi.org/10.1073/pnas.2024789118" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8092601/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33888586/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Chen,%20M.,%20Shlezinger,%20N.,%20Poor,%20H.%20V.,%20Eldar,%20Y.%20C.%20&amp;%20Cui,%20S.%20Communication-efficient%20federated%20learning.%20Proc.%20Natl.%20Acad.%20Sci.118(17),%2089118.%2010.1073/pnas.2024789118%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR26">
<span class="label">26.</span><cite>Li, J., Zhang, Y., Li, Y., Gong, X. &amp; Wang, W. FedSparse: A communication-efficient federated learning framework based on sparse updates. <em>Electronics</em><strong>13</strong>(24), 5042. 10.3390/electronics13245042 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Li,%20J.,%20Zhang,%20Y.,%20Li,%20Y.,%20Gong,%20X.%20&amp;%20Wang,%20W.%20FedSparse:%20A%20communication-efficient%20federated%20learning%20framework%20based%20on%20sparse%20updates.%20Electronics13(24),%205042.%2010.3390/electronics13245042%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR27">
<span class="label">27.</span><cite>Zhang, L., &amp; Lu, H. (2020). A Feature-Importance-Aware and Robust Aggregator for GCN. In Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management (pp. 1813–1822). CIKM ’20: The 29th ACM International Conference on Information and Knowledge Management. ACM. 10.1145/3340531.3411983</cite>
</li>
<li id="CR28">
<span class="label">28.</span><cite>Qian, D., Cui, Y., Fu, Y., Liu, F. &amp; Wei, T. FedEntropy: Information-entropy-aided training optimization of semi-supervised federated learning. <em>J. Syst. Architect.</em><strong>137</strong>, 102851. 10.1016/j.sysarc.2023.102851 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Qian,%20D.,%20Cui,%20Y.,%20Fu,%20Y.,%20Liu,%20F.%20&amp;%20Wei,%20T.%20FedEntropy:%20Information-entropy-aided%20training%20optimization%20of%20semi-supervised%20federated%20learning.%20J.%20Syst.%20Architect.137,%20102851.%2010.1016/j.sysarc.2023.102851%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR29">
<span class="label">29.</span><cite>Aamer, B., Chergui, H., Benjillali, M. &amp; Verikoukis, C. Entropy-driven stochastic federated learning in non-IID 6G Edge-RAN. <em>Front. Commun. Netw.</em><strong>2</strong>, 739414. 10.3389/frcmn.2021.739414 (2021).</cite> [<a href="https://scholar.google.com/scholar_lookup?Aamer,%20B.,%20Chergui,%20H.,%20Benjillali,%20M.%20&amp;%20Verikoukis,%20C.%20Entropy-driven%20stochastic%20federated%20learning%20in%20non-IID%206G%20Edge-RAN.%20Front.%20Commun.%20Netw.2,%20739414.%2010.3389/frcmn.2021.739414%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR30">
<span class="label">30.</span><cite>Khan, K. Sign-entropy regularization for personalized federated learning. <em>Entropy</em><strong>27</strong>(6), 601. 10.3390/e27060601 (2025).
</cite> [<a href="https://doi.org/10.3390/e27060601" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC12191723/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/40566188/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Khan,%20K.%20Sign-entropy%20regularization%20for%20personalized%20federated%20learning.%20Entropy27(6),%20601.%2010.3390/e27060601%20(2025)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR31">
<span class="label">31.</span><cite>Somasundaram, K. &amp; Kanna, P. R. Scalable hierarchical balanced clustering-based routing with multipath authentication for secured data transmission in large-scale multicast group communications. <em>Expert Syst. Appl.</em><strong>286</strong>, 128149. 10.1016/j.eswa.2025.128149 (2025).</cite> [<a href="https://scholar.google.com/scholar_lookup?Somasundaram,%20K.%20&amp;%20Kanna,%20P.%20R.%20Scalable%20hierarchical%20balanced%20clustering-based%20routing%20with%20multipath%20authentication%20for%20secured%20data%20transmission%20in%20large-scale%20multicast%20group%20communications.%20Expert%20Syst.%20Appl.286,%20128149.%2010.1016/j.eswa.2025.128149%20(2025)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR32">
<span class="label">32.</span><cite>Sathish Kumar, G. et al. Differential privacy scheme using Laplace mechanism and statistical method computation in deep neural network for privacy preservation. <em>Eng. Appl. Artif. Intell.</em><strong>128</strong>, 107399. 10.1016/j.engappai.2023.107399 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Sathish%20Kumar,%20G.%20et%20al.%20Differential%20privacy%20scheme%20using%20Laplace%20mechanism%20and%20statistical%20method%20computation%20in%20deep%20neural%20network%20for%20privacy%20preservation.%20Eng.%20Appl.%20Artif.%20Intell.128,%20107399.%2010.1016/j.engappai.2023.107399%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR33">
<span class="label">33.</span><cite>Rajesh Kanna, P. &amp; Santhi, P. Exploring the landscape of network security: a comparative analysis of attack detection strategies. <em>J. Ambient. Intell. Humaniz. Comput.</em><strong>15</strong>(8), 3211–3228. 10.1007/s12652-024-04794-y (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Rajesh%20Kanna,%20P.%20&amp;%20Santhi,%20P.%20Exploring%20the%20landscape%20of%20network%20security:%20a%20comparative%20analysis%20of%20attack%20detection%20strategies.%20J.%20Ambient.%20Intell.%20Humaniz.%20Comput.15(8),%203211%E2%80%933228.%2010.1007/s12652-024-04794-y%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR34">
<span class="label">34.</span><cite>Dhivya, P., Rajesh Kanna, P., Deepa, K. &amp; Santhiya, S. Square static—deep hyper optimization and genetic meta-learning approach for disease classification. <em>IETE J. Res.</em><strong>70</strong>(4), 3835–3844. 10.1080/03772063.2023.2206367 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Dhivya,%20P.,%20Rajesh%20Kanna,%20P.,%20Deepa,%20K.%20&amp;%20Santhiya,%20S.%20Square%20static%E2%80%94deep%20hyper%20optimization%20and%20genetic%20meta-learning%20approach%20for%20disease%20classification.%20IETE%20J.%20Res.70(4),%203835%E2%80%933844.%2010.1080/03772063.2023.2206367%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR35">
<span class="label">35.</span><cite>Sathish Kumar, G., Premalatha, K., Uma Maheshwari, G. &amp; Rajesh Kanna, P. No more privacy Concern: A privacy-chain based homomorphic encryption scheme and statistical method for privacy preservation of user’s private and sensitive data. <em>Expert Syst. Appl.</em><strong>234</strong>, 121071. 10.1016/j.eswa.2023.121071 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Sathish%20Kumar,%20G.,%20Premalatha,%20K.,%20Uma%20Maheshwari,%20G.%20&amp;%20Rajesh%20Kanna,%20P.%20No%20more%20privacy%20Concern:%20A%20privacy-chain%20based%20homomorphic%20encryption%20scheme%20and%20statistical%20method%20for%20privacy%20preservation%20of%20user%E2%80%99s%20private%20and%20sensitive%20data.%20Expert%20Syst.%20Appl.234,%20121071.%2010.1016/j.eswa.2023.121071%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR36">
<span class="label">36.</span><cite>Kanna, P. R. &amp; Santhi, P. An enhanced hybrid intrusion detection using mapreduce-optimized black widow convolutional LSTM neural networks. <em>Wireless Pers. Commun.</em><strong>138</strong>(4), 2407–2445. 10.1007/s11277-024-11607-0 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Kanna,%20P.%20R.%20&amp;%20Santhi,%20P.%20An%20enhanced%20hybrid%20intrusion%20detection%20using%20mapreduce-optimized%20black%20widow%20convolutional%20LSTM%20neural%20networks.%20Wireless%20Pers.%20Commun.138(4),%202407%E2%80%932445.%2010.1007/s11277-024-11607-0%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR37">
<span class="label">37.</span><cite>Kanna, P. R., Vanithamani, S., Karunakaran, P., Pandiaraja, P., Tamilarasi, N., &amp; Nithin, P. (2024). An Enhanced Traffic Incident Detection using Factor Analysis and Weighted Random Forest Algorithm. In 2024 International Conference on IoT Based Control Networks and Intelligent Systems (ICICNIS) (pp. 1355–1361). 2024 International Conference on IoT Based Control Networks and Intelligent Systems (ICICNIS). IEEE. 10.1109/icicnis64247.2024.10823129</cite>
</li>
<li id="CR38">
<span class="label">38.</span><cite>Kanna, P. R. &amp; Santhi, P. Hybrid intrusion detection using mapreduce based black widow optimized convolutional long short-term memory neural networks. <em>Expert Syst. Appl.</em><strong>194</strong>, 116545. 10.1016/j.eswa.2022.116545 (2022).</cite> [<a href="https://scholar.google.com/scholar_lookup?Kanna,%20P.%20R.%20&amp;%20Santhi,%20P.%20Hybrid%20intrusion%20detection%20using%20mapreduce%20based%20black%20widow%20optimized%20convolutional%20long%20short-term%20memory%20neural%20networks.%20Expert%20Syst.%20Appl.194,%20116545.%2010.1016/j.eswa.2022.116545%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR39">
<span class="label">39.</span><cite>Rajesh Kanna, P. &amp; Santhi, P. Unified deep learning approach for efficient intrusion detection system using integrated spatial-temporal features. <em>Knowl.-Based Syst.</em><strong>226</strong>, 107132. 10.1016/j.knosys.2021.107132 (2021).</cite> [<a href="https://scholar.google.com/scholar_lookup?Rajesh%20Kanna,%20P.%20&amp;%20Santhi,%20P.%20Unified%20deep%20learning%20approach%20for%20efficient%20intrusion%20detection%20system%20using%20integrated%20spatial-temporal%20features.%20Knowl.-Based%20Syst.226,%20107132.%2010.1016/j.knosys.2021.107132%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR40">
<span class="label">40.</span><cite>P, P., K, K., P, R. K., C.Ushapriya, Mahesh, P. C. S., &amp; K, M. (2024). Assessing Secure Cloud Information Sharing Through Authentication and Encoded Indexing. In 2024 8th International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC) (pp. 1030–1037). 2024 8th International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC). IEEE. 10.1109/i-smac61858.2024.10714840</cite>
</li>
<li id="CR41">
<span class="label">41.</span><cite>Kanna, P. R., Sindhanaiselvan, K. &amp; Vijaymeena, M. K. A defensive mechanism based on PCA to defend denial-of-service attack. <em>Int. J. Sec. Appl.</em><strong>11</strong>(1), 71–82. 10.14257/ijsia.2017.11.1.07 (2017).</cite> [<a href="https://scholar.google.com/scholar_lookup?Kanna,%20P.%20R.,%20Sindhanaiselvan,%20K.%20&amp;%20Vijaymeena,%20M.%20K.%20A%20defensive%20mechanism%20based%20on%20PCA%20to%20defend%20denial-of-service%20attack.%20Int.%20J.%20Sec.%20Appl.11(1),%2071%E2%80%9382.%2010.14257/ijsia.2017.11.1.07%20(2017)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR42">
<span class="label">42.</span><cite>Kandasamy, K., Natarajan, Y., Sri Preethaa, K. R. &amp; Ali, A. A. Y. A robust TrafficSignNet algorithm for enhanced traffic sign recognition in autonomous vehicles under varying light conditions. <em>Neural Process. Lett.</em><strong>56</strong>(5), 11693. 10.1007/s11063-024-11693-y (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Kandasamy,%20K.,%20Natarajan,%20Y.,%20Sri%20Preethaa,%20K.%20R.%20&amp;%20Ali,%20A.%20A.%20Y.%20A%20robust%20TrafficSignNet%20algorithm%20for%20enhanced%20traffic%20sign%20recognition%20in%20autonomous%20vehicles%20under%20varying%20light%20conditions.%20Neural%20Process.%20Lett.56(5),%2011693.%2010.1007/s11063-024-11693-y%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR43">
<span class="label">43.</span><cite>Kim, B., Sri Preethaa, K. R., Natarajan, Y., An, J. &amp; Lee, D.-E. Real-time assessment of rebar intervals using a computer vision-based DVNet model for improved structural integrity. <em>Case Stud. Const. Mater.</em><strong>21</strong>, e03707. 10.1016/j.cscm.2024.e03707 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Kim,%20B.,%20Sri%20Preethaa,%20K.%20R.,%20Natarajan,%20Y.,%20An,%20J.%20&amp;%20Lee,%20D.-E.%20Real-time%20assessment%20of%20rebar%20intervals%20using%20a%20computer%20vision-based%20DVNet%20model%20for%20improved%20structural%20integrity.%20Case%20Stud.%20Const.%20Mater.21,%20e03707.%2010.1016/j.cscm.2024.e03707%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR44">
<span class="label">44.</span><cite>Sundaram, K., Subramanian, S., Natarajan, Y. &amp; Thirumalaisamy, S. Improving Performance of Intrusion Detection Using ALO Selected Features and GRU Network. <em>SN Comput. Sci.</em><strong>4</strong>(6), 23110. 10.1007/s42979-023-02311-0 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Sundaram,%20K.,%20Subramanian,%20S.,%20Natarajan,%20Y.%20&amp;%20Thirumalaisamy,%20S.%20Improving%20Performance%20of%20Intrusion%20Detection%20Using%20ALO%20Selected%20Features%20and%20GRU%20Network.%20SN%20Comput.%20Sci.4(6),%2023110.%2010.1007/s42979-023-02311-0%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR45">
<span class="label">45.</span><cite>Sundaram, K., Natarajan, Y., Perumalsamy, A. &amp; Yusuf Ali, A. A. A novel hybrid feature selection with cascaded LSTM: Enhancing security in IoT networks. <em>Wirel. Commun. Mob. Comput.</em><strong>2024</strong>, 1–15. 10.1155/2024/5522431 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Sundaram,%20K.,%20Natarajan,%20Y.,%20Perumalsamy,%20A.%20&amp;%20Yusuf%20Ali,%20A.%20A.%20A%20novel%20hybrid%20feature%20selection%20with%20cascaded%20LSTM:%20Enhancing%20security%20in%20IoT%20networks.%20Wirel.%20Commun.%20Mob.%20Comput.2024,%201%E2%80%9315.%2010.1155/2024/5522431%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR46">
<span class="label">46.</span><cite>Natarajan, Y. et al. Enhancing building energy efficiency with IoT-driven hybrid deep learning models for accurate energy consumption prediction. <em>Sustainability</em><strong>16</strong>(5), 1925. 10.3390/su16051925 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Natarajan,%20Y.%20et%20al.%20Enhancing%20building%20energy%20efficiency%20with%20IoT-driven%20hybrid%20deep%20learning%20models%20for%20accurate%20energy%20consumption%20prediction.%20Sustainability16(5),%201925.%2010.3390/su16051925%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR47">
<span class="label">47.</span><cite>Sundaram, K., Sri Preethaa, K. R., Natarajan, Y., Muthuramalingam, A. &amp; Ali, A. A. Y. Advancing building energy efficiency: A deep learning approach to early-stage prediction of residential electric consumption. <em>Energy Rep.</em><strong>12</strong>, 1281–1292. 10.1016/j.egyr.2024.07.034 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Sundaram,%20K.,%20Sri%20Preethaa,%20K.%20R.,%20Natarajan,%20Y.,%20Muthuramalingam,%20A.%20&amp;%20Ali,%20A.%20A.%20Y.%20Advancing%20building%20energy%20efficiency:%20A%20deep%20learning%20approach%20to%20early-stage%20prediction%20of%20residential%20electric%20consumption.%20Energy%20Rep.12,%201281%E2%80%931292.%2010.1016/j.egyr.2024.07.034%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR48">
<span class="label">48.</span><cite>Janani, M., &amp; Yuvaraj, N. (2018). Social interaction and stress-based recommendations for elderly healthcare support system—a survey. In advances in intelligent systems and computing (pp. 291–303). Springer Singapore. 10.1007/978-981-13-1882-5_26</cite>
</li>
<li id="CR49">
<span class="label">49.</span><cite>Natarajan, Y., Wadhwa, G., Ranganathan, P. A., &amp; Natarajan, K. (2023). Earthquake Damage Prediction and Rapid Assessment of Building Damage Using Deep Learning. In 2023 International Conference on Advances in Electronics, Communication, Computing and Intelligent Information Systems (ICAECIS) (pp. 540–547). 2023 International Conference on Advances in Electronics, Communication, Computing and Intelligent Information Systems (ICAECIS). IEEE. 10.1109/icaecis58353.2023.10169947</cite>
</li>
<li id="CR50">
<span class="label">50.</span><cite>Beck, A. &amp; Teboulle, M. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. <em>SIAM J. Imag. Sci.</em><strong>2</strong>(1), 183–202. 10.1137/080716542 (2009).</cite> [<a href="https://scholar.google.com/scholar_lookup?Beck,%20A.%20&amp;%20Teboulle,%20M.%20A%20fast%20iterative%20shrinkage-thresholding%20algorithm%20for%20linear%20inverse%20problems.%20SIAM%20J.%20Imag.%20Sci.2(1),%20183%E2%80%93202.%2010.1137/080716542%20(2009)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adda93_" lang="en" class="data-availability-statement"><h3 class="pmc_sec_title">Data Availability Statement</h3>
<p>The datasets used in this study are publicly available and subject to their respective licensing terms. The UCI HAR dataset is available at: <a href="https://www.kaggle.com/c/uci-har" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/c/uci-har</a> and is distributed under the Creative Commons Attribution 4.0 International (CC BY 4.0) license, permitting sharing and adaptation with proper citation. The PAMAP2 Physical Activity Monitoring dataset is accessible at: <a href="https://www.kaggle.com/code/avrahamcalev/time-series-models-pamap2-dataset" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.kaggle.com/code/avrahamcalev/time-series-models-pamap2-dataset</a>, also under the CC BY 4.0 license, requiring attribution for any use. No additional data were generated during the current study.</p></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from Scientific Reports are provided here courtesy of <strong>Nature Publishing Group</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1038/s41598-025-16604-2"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/41598_2025_Article_16604.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (6.0 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12374004/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12374004/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12374004%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12374004/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12374004/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12374004/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40847043/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12374004/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40847043/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12374004/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12374004/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="I1mecCPGkwxKx9w2hTwtngBKFoQWRkudW5Dp8plg5lfoJ5NbdNqXlfnsJRwhowLG">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
    

    </body>
</html>
