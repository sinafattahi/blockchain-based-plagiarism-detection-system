
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            AbVLM-Q: intelligent quality assessment for abdominal ultrasound standard planes via vision-language modeling - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="AE5312FD8AEF2EE30512FD00346F9C78.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="bmcmi">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12374393/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="BMC Medical Imaging">
<meta name="citation_title" content="AbVLM-Q: intelligent quality assessment for abdominal ultrasound standard planes via vision-language modeling">
<meta name="citation_author" content="Baohua Wang">
<meta name="citation_author_institution" content="Department of Ultrasound Medicine, The First Affiliated Hospital, Zhejiang University School of Medicine, Hangzhou, Zhejiang Province China">
<meta name="citation_author" content="Yaqian Wang">
<meta name="citation_author_institution" content="Yizhun Medical AI Co., Ltd, Beijing, China">
<meta name="citation_author" content="Yanhua Chu">
<meta name="citation_author_institution" content="Department of Ultrasound Medicine, The First Affiliated Hospital, Zhejiang University School of Medicine, Hangzhou, Zhejiang Province China">
<meta name="citation_author" content="Ke Zhang">
<meta name="citation_author_institution" content="Department of Ultrasound Medicine, The First Affiliated Hospital, Zhejiang University School of Medicine, Hangzhou, Zhejiang Province China">
<meta name="citation_author" content="Lei Liu">
<meta name="citation_author_institution" content="Nanchang People’s Hospital, Nanchang, Jiangxi Province China">
<meta name="citation_author" content="Kexin Zhang">
<meta name="citation_author_institution" content="Yizhun Medical AI Co., Ltd, Beijing, China">
<meta name="citation_author" content="Bowen Zhu">
<meta name="citation_author_institution" content="Yizhun Medical AI Co., Ltd, Beijing, China">
<meta name="citation_author" content="Dong Wang">
<meta name="citation_author_institution" content="Yizhun Medical AI Co., Ltd, Beijing, China">
<meta name="citation_author" content="Tianan Jiang">
<meta name="citation_author_institution" content="Department of Ultrasound Medicine, The First Affiliated Hospital, Zhejiang University School of Medicine, Hangzhou, Zhejiang Province China">
<meta name="citation_publication_date" content="2025 Aug 23">
<meta name="citation_volume" content="25">
<meta name="citation_firstpage" content="344">
<meta name="citation_doi" content="10.1186/s12880-025-01885-w">
<meta name="citation_pmid" content="40849615">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12374393/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12374393/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12374393/pdf/12880_2025_Article_1885.pdf">
<meta name="description" content="Abdominal ultrasound is non-invasive and efficient, yet acquiring standard planes remains challenging due to operator dependency and procedural complexity. We propose AbVLM-Q, a vision-language framework for automated quality assessment of abdominal ...">
<meta name="og:title" content="AbVLM-Q: intelligent quality assessment for abdominal ultrasound standard planes via vision-language modeling">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="Abdominal ultrasound is non-invasive and efficient, yet acquiring standard planes remains challenging due to operator dependency and procedural complexity. We propose AbVLM-Q, a vision-language framework for automated quality assessment of abdominal ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12374393/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12374393">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1186/s12880-025-01885-w"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/12880_2025_Article_1885.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12374393%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12374393/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12374393/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12374393/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-bmcmi.png" alt="BMC Medical Imaging logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to BMC Medical Imaging" title="Link to BMC Medical Imaging" shape="default" href="https://bmcmedimaging.biomedcentral.com/" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">BMC Med Imaging</button></div>. 2025 Aug 23;25:344. doi: <a href="https://doi.org/10.1186/s12880-025-01885-w" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1186/s12880-025-01885-w</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22BMC%20Med%20Imaging%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22BMC%20Med%20Imaging%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22BMC%20Med%20Imaging%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22BMC%20Med%20Imaging%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>AbVLM-Q: intelligent quality assessment for abdominal ultrasound standard planes via vision-language modeling</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Wang%20B%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Baohua Wang</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Baohua Wang</span></h3>
<div class="p">
<sup>1</sup>Department of Ultrasound Medicine, The First Affiliated Hospital, Zhejiang University School of Medicine, Hangzhou, Zhejiang Province China </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Wang%20B%22%5BAuthor%5D" class="usa-link"><span class="name western">Baohua Wang</span></a>
</div>
</div>
<sup>1,</sup><sup>#</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Wang%20Y%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Yaqian Wang</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">Yaqian Wang</span></h3>
<div class="p">
<sup>2</sup>Yizhun Medical AI Co., Ltd, Beijing, China </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Wang%20Y%22%5BAuthor%5D" class="usa-link"><span class="name western">Yaqian Wang</span></a>
</div>
</div>
<sup>2,</sup><sup>#</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Chu%20Y%22%5BAuthor%5D" class="usa-link" aria-describedby="id3"><span class="name western">Yanhua Chu</span></a><div hidden="hidden" id="id3">
<h3><span class="name western">Yanhua Chu</span></h3>
<div class="p">
<sup>1</sup>Department of Ultrasound Medicine, The First Affiliated Hospital, Zhejiang University School of Medicine, Hangzhou, Zhejiang Province China </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Chu%20Y%22%5BAuthor%5D" class="usa-link"><span class="name western">Yanhua Chu</span></a>
</div>
</div>
<sup>1</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Zhang%20K%22%5BAuthor%5D" class="usa-link" aria-describedby="id4"><span class="name western">Ke Zhang</span></a><div hidden="hidden" id="id4">
<h3><span class="name western">Ke Zhang</span></h3>
<div class="p">
<sup>1</sup>Department of Ultrasound Medicine, The First Affiliated Hospital, Zhejiang University School of Medicine, Hangzhou, Zhejiang Province China </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Zhang%20K%22%5BAuthor%5D" class="usa-link"><span class="name western">Ke Zhang</span></a>
</div>
</div>
<sup>1</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Liu%20L%22%5BAuthor%5D" class="usa-link" aria-describedby="id5"><span class="name western">Lei Liu</span></a><div hidden="hidden" id="id5">
<h3><span class="name western">Lei Liu</span></h3>
<div class="p">
<sup>3</sup>Nanchang People’s Hospital, Nanchang, Jiangxi Province China </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Liu%20L%22%5BAuthor%5D" class="usa-link"><span class="name western">Lei Liu</span></a>
</div>
</div>
<sup>3</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Zhang%20K%22%5BAuthor%5D" class="usa-link" aria-describedby="id6"><span class="name western">Kexin Zhang</span></a><div hidden="hidden" id="id6">
<h3><span class="name western">Kexin Zhang</span></h3>
<div class="p">
<sup>2</sup>Yizhun Medical AI Co., Ltd, Beijing, China </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Zhang%20K%22%5BAuthor%5D" class="usa-link"><span class="name western">Kexin Zhang</span></a>
</div>
</div>
<sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Zhu%20B%22%5BAuthor%5D" class="usa-link" aria-describedby="id7"><span class="name western">Bowen Zhu</span></a><div hidden="hidden" id="id7">
<h3><span class="name western">Bowen Zhu</span></h3>
<div class="p">
<sup>2</sup>Yizhun Medical AI Co., Ltd, Beijing, China </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Zhu%20B%22%5BAuthor%5D" class="usa-link"><span class="name western">Bowen Zhu</span></a>
</div>
</div>
<sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Wang%20D%22%5BAuthor%5D" class="usa-link" aria-describedby="id8"><span class="name western">Dong Wang</span></a><div hidden="hidden" id="id8">
<h3><span class="name western">Dong Wang</span></h3>
<div class="p">
<sup>2</sup>Yizhun Medical AI Co., Ltd, Beijing, China </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Wang%20D%22%5BAuthor%5D" class="usa-link"><span class="name western">Dong Wang</span></a>
</div>
</div>
<sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Jiang%20T%22%5BAuthor%5D" class="usa-link" aria-describedby="id9"><span class="name western">Tianan Jiang</span></a><div hidden="hidden" id="id9">
<h3><span class="name western">Tianan Jiang</span></h3>
<div class="p">
<sup>1</sup>Department of Ultrasound Medicine, The First Affiliated Hospital, Zhejiang University School of Medicine, Hangzhou, Zhejiang Province China </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Jiang%20T%22%5BAuthor%5D" class="usa-link"><span class="name western">Tianan Jiang</span></a>
</div>
</div>
<sup>1,</sup><sup>✉</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="Aff1">
<sup>1</sup>Department of Ultrasound Medicine, The First Affiliated Hospital, Zhejiang University School of Medicine, Hangzhou, Zhejiang Province China </div>
<div id="Aff2">
<sup>2</sup>Yizhun Medical AI Co., Ltd, Beijing, China </div>
<div id="Aff3">
<sup>3</sup>Nanchang People’s Hospital, Nanchang, Jiangxi Province China </div>
<div class="author-notes p">
<div class="fn" id="_fncrsp93pmc__">
<sup>✉</sup><p class="display-inline">Corresponding author.</p>
</div>
<div class="fn" id="_eqcntrb93pmc__">
<sup>#</sup><p class="display-inline">Contributed equally.</p>
</div>
</div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2025 Jul 3; Accepted 2025 Aug 14; Collection date 2025.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© The Author(s) 2025</div>
<p><strong>Open Access</strong> This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://creativecommons.org/licenses/by-nc-nd/4.0/</a>.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12374393  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40849615/" class="usa-link">40849615</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="Abs1"><h2>Abstract</h2>
<section id="sec1"><h3 class="pmc_sec_title">Background</h3>
<p id="Par1">Abdominal ultrasound is non-invasive and efficient, yet acquiring standard planes remains challenging due to operator dependency and procedural complexity. We propose AbVLM-Q, a vision-language framework for automated quality assessment of abdominal ultrasound standard planes.</p></section><section id="sec2"><h3 class="pmc_sec_title">Methods</h3>
<p id="Par2">In this study, we assembled a multi-center dataset comprising 7,766 abdominal ultrasound scans, which were randomly divided into training (70%), validation (15%), and testing (15%) subsets. The proposed method, AbVLM-Q, was developed using a three-step approach: (1) hierarchical prompting that incorporates spatially aware querying and sequential reasoning; (2) a quantifiable scoring mechanism based on multi-level clinical penalty criteria; and (3) LoRA (Low-Rank Adaptation)-based fine-tuning of a pretrained vision-language model. Performance was evaluated using mean recall, precision, label accuracy, subset accuracy, and confusion matrix analysis.</p></section><section id="sec3"><h3 class="pmc_sec_title">Results</h3>
<p id="Par3">The system achieved key structure detection with 88.90% mean recall and 98.10% precision, showing higher precision and comparable recall to Faster R-CNN (89.77% recall, 88.64% precision at a 0.5 confidence threshold). Plane classification yielded 98.96% label accuracy and 96.28% subset accuracy, surpassing the best CNN (97.84%, 94.29%; <em>P</em> &lt; 0.05). Image scoring accuracy for the clinically critical “Excellent” grade (scores 8–10) reached 85.11% with the best-performing backbone. Confusion matrix analysis confirmed consistent performance across different backbones, with discrepancies primarily observed at grade boundaries.</p></section><section id="sec4"><h3 class="pmc_sec_title">Conclusions</h3>
<p id="Par4">AbVLM-Q provides a novel method for automated ultrasound quality assessment, functioning as both an evaluation tool and a training platform for standardized scanning. It bridges AI-driven imaging analysis with clinical workflows, enhancing quality control in ultrasound diagnostics.</p></section><section id="sec5"><h3 class="pmc_sec_title">Supplementary Information</h3>
<p>The online version contains supplementary material available at 10.1186/s12880-025-01885-w.</p></section><section id="kwd-group1" lang="en" class="kwd-group"><p><strong>Keywords:</strong> Vision-language models, Quality assessment, Hierarchical prompting, Abdominal ultrasound, Standard plane</p></section></section><section id="Sec1"><h2 class="pmc_sec_title">Introduction</h2>
<p id="Par5">Abdominal ultrasound, a non-invasive and radiation-free modality, is widely utilized for assessing abdominal organs in clinical diagnosis, disease monitoring, and preventive care. Its efficiency establishes it as the preferred imaging choice in emergency medicine and hepatobiliary screening [<a href="#CR1" class="usa-link" aria-describedby="CR1">1</a>, <a href="#CR2" class="usa-link" aria-describedby="CR2">2</a>]. Standard planes, defined by anatomical landmarks, enable systematic evaluation of organ structure and function [<a href="#CR3" class="usa-link" aria-describedby="CR3">3</a>]. However, their clinical utility is limited by inconsistent image quality caused by inter-operator variability (particularly among residents), patient variability, equipment heterogeneity [<a href="#CR4" class="usa-link" aria-describedby="CR4">4</a>], and the anatomical characteristics of specific organs. For instance, in imaging assessments of anatomical structures such as the left branch of the portal vein and the section where hepatic veins drain into the inferior vena cava, inexperienced residents may struggle to accurately identify key anatomical landmarks. This can result in section deviation or omission of critical structures during imaging acquisition. In obese patients, acoustic shadowing caused by adipose tissue, along with challenges in coordinating respiratory movements in elderly patients or those with pain or impaired consciousness, can lead to failure in obtaining standardized anatomical planes. These issues underscore the need for automated quality assessment systems to standardize image interpretation.</p>
<p id="Par6">Recent advances in deep learning have expanded the methodological repertoire for abdominal ultrasound image analysis. CNN-based transfer learning (e.g., VGGNet, ResNet) has demonstrated efficacy in organ classification and discriminative feature extraction [<a href="#CR5" class="usa-link" aria-describedby="CR5">5</a>–<a href="#CR7" class="usa-link" aria-describedby="CR7">7</a>]. Building on these foundations, multi-task architectures combining view classification with landmark detection improve diagnostic speed and accuracy [<a href="#CR8" class="usa-link" aria-describedby="CR8">8</a>]. Hybrid frameworks combining deep learning with interpretable classifiers (e.g., KNN) advance diagnostic automation pipelines [<a href="#CR9" class="usa-link" aria-describedby="CR9">9</a>]. These studies emphasize two key success factors: (1) effective use of pre-trained models through transfer learning, and (2) architectural innovations that balance model complexity with clinical interpretability [<a href="#CR10" class="usa-link" aria-describedby="CR10">10</a>, <a href="#CR11" class="usa-link" aria-describedby="CR11">11</a>]. Despite improvements in CNN-based standard plane analysis, challenges in cross-institutional adaptability and clinical integration remain.</p>
<p id="Par7">Multimodal integration represents the next frontier, with vision-language models (VLMs) demonstrating particular promise [<a href="#CR12" class="usa-link" aria-describedby="CR12">12</a>–<a href="#CR14" class="usa-link" aria-describedby="CR14">14</a>]. Unlike conventional CNN-based methods, which rely exclusively on visual feature extraction and manual encoding of clinical heuristics, vision–language models (VLMs) support multimodal inference through the joint processing of image data and textual clinical knowledge. This dual-modality design enables the parsing and operationalization of standardized protocols expressed in natural language, thereby enhancing interpretability and clinician trust. Moreover, by incorporating clinical guidelines directly into prompt inputs, VLMs reduce implementation complexity and offer greater flexibility in adapting to diverse clinical requirements. The open-source availability of certain models has further accelerated the development of large language models and general artificial intelligence. Recent studies indicate that vision-language models can enhance diagnostic accuracy by processing both imaging features and clinical context [<a href="#CR15" class="usa-link" aria-describedby="CR15">15</a>, <a href="#CR16" class="usa-link" aria-describedby="CR16">16</a>]. However, the absence of a targeted alignment mechanism between ultrasound image features and clinical quality assessment limits their direct applicability to standard plane analysis in abdominal ultrasound.</p>
<p id="Par8">This study investigates the feasibility of applying Vision-Language Models to analyze abdominal ultrasound standard plane images. We propose AbVLM-Q (Abdominal Vision-Language Model for Quality Assessment), an end-to-end framework for automated quality assessment. The development of the AbVLM-Q system incorporates three key elements: (1) hierarchical prompting and structured image-text dialogues to align ultrasound features with clinical context, enabling efficient structure detection and plane classification; (2) a 10-point scoring system based on established expert guidelines for interpretable quality assessment; (3) a multi-center dataset of 11 standard planes, with supervised fine-tuning to improve model adaptability. AbVLM-Q facilitates the quantitative evaluation of ultrasound image quality, enhancing diagnostic consistency in clinical practice and demonstrating its potential for standard plane analysis.</p></section><section id="Sec2"><h2 class="pmc_sec_title">Materials and methods</h2>
<p id="Par9">This multicenter retrospective study was conducted across two large tertiary hospitals in China. Institutional review board approval was obtained from both centers, and the requirement for informed consent was waived due to the retrospective study design. All procedures adhered to ethical guidelines.</p>
<section id="Sec3"><h3 class="pmc_sec_title">Data collection and splitting</h3>
<p id="Par10">This study included images from abdominal ultrasound examinations conducted at two independent ultrasound medicine centers between August 2023 and March 2024, using mainstream ultrasound devices (e.g., GE, Philips, Siemens, CHISON, Mindray) to enhance model generalizability. A total of 7,766 images were initially collected. The inclusion criteria were: (1) acquisition in predefined abdominal standard plane positions; and (2) complete ultrasound scans without visible artifacts or noise. Exclusion criteria were: (1) images with anatomical abnormalities or quality issues that compromised interpretation; (2) absence of key anatomical structures essential for plane classification or presence of irrelevant anatomical structures; and (3) non-abdominal ultrasound images. After applying these criteria, 3,766 standard plane images and 4,000 non-standard plane images (i.e., non-abdominal ultrasound images or ultrasound scans that did not meet the standard plane definition) were collated as comparison data to enhance the robustness of the model in a real clinical setting.</p>
<p id="Par11">The final dataset was randomly partitioned by a ratio of 70%:15%:15% into training, validation, and test sets. Supplementary Table <a href="#MOESM1" class="usa-link">A1</a> summarizes plane types and abbreviations, while Supplementary Figure <a href="#MOESM1" class="usa-link">A1</a> provides schematic illustrations. The distribution of each plane type is detailed in Supplementary Table <a href="#MOESM1" class="usa-link">A2</a>. Score distribution across intervals (0–4, 4–6, 6–8, and 8–10) is shown in Supplementary Figure <a href="#MOESM1" class="usa-link">A2</a>. The workflow for the dataset construction process is illustrated in Fig. <a href="#Fig1" class="usa-link">1</a>.</p>
<figure class="fig xbox font-sm" id="Fig1"><h4 class="obj_head">Fig. 1.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12374393_12880_2025_1885_Fig1_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/398d/12374393/2ec08e128d97/12880_2025_1885_Fig1_HTML.jpg" loading="lazy" id="d33e309" height="795" width="708" alt="Fig. 1"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Flowchart of dataset construction for abdominal ultrasound image analysis</p></figcaption></figure></section><section id="Sec4"><h3 class="pmc_sec_title">Data annotation and preprocessing</h3>
<p id="Par13">During the data annotation phase, two ultrasound specialists annotated the images, and their work was reviewed by an expert to ensure accuracy. The annotation process consisted of several steps. First, each image was evaluated to confirm it represented a valid abdominal ultrasound scan; images deemed invalid were excluded from the dataset. Next, the appropriate plane type for each image was identified. For plane types sharing common abdominal structures, images were labeled with two corresponding sets of tags to reflect overlapping anatomical features. Key structures were then marked with rectangular bounding boxes. Finally, quality scores were assigned based on predefined deduction criteria. All annotations, conducted using custom annotation software, included category labels, structural labels, and quality scores for each image.</p>
<p id="Par14">In the data preprocessing phase, an internally trained region recognition model was applied to extract key regions from the images. The images were then cropped to remove irrelevant content, such as background, patient privacy information, and non-ultrasound elements, retaining only the central ultrasound scan area to focus on clinically relevant regions. Since the Vision-Language Model (VLM) used in this study supports arbitrary input resolutions, resizing was not necessary, thus preventing any potential distortion or deformation.</p></section><section id="Sec5"><h3 class="pmc_sec_title">Task definition</h3>
<p id="Par15">In clinical practice, the assessment of abdominal ultrasound images requires a structured approach to address their complexity. To mirror this process, we designed the task flow in three sequential steps. First, key anatomical structures are detected, as accurate identification of critical structures is essential for confirming the standard plane. Next, standard plane classification assigns the image to its corresponding plane type based on the detected structures.</p>
<p id="Par16">Finally, image quality is scored using predefined clinical criteria, providing an interpretable quality analysis. This hierarchical approach enables the model to capture key steps in clinical decision-making, translating abstract tasks into concrete actions for image quality analysis.</p></section><section id="Sec6"><h3 class="pmc_sec_title">Model construction</h3>
<p id="Par17">Our quality assessment system is based on a Vision-Language Model backbone, specifically tailored for the analysis of abdominal ultrasound standard planes. This section provides an overview of the key components of our approach, including model architecture, hierarchical prompting, the clinical scoring mechanism, and fine-tuning strategies—all of which contribute to an end-to-end framework for the comprehensive evaluation of abdominal ultrasound standard planes.</p>
<section id="Sec7"><h4 class="pmc_sec_title">Model architecture</h4>
<p id="Par18">As illustrated in Fig. <a href="#Fig2" class="usa-link">2</a>, the model architecture consists of four key components: a vision encoder, a text encoder, a multimodal fusion module, and a large language model (LLM). The vision encoder processes abdominal ultrasound images, extracting key visual features that capture both local and global anatomical information. Meanwhile, the text encoder processes hierarchical prompts, generating contextualized embeddings that align with clinical standards. To bridge the disparity between visual and textual features, an input projector transforms the outputs of the vision and text encoders into a shared latent space, ensuring coherent cross-modal feature alignment. This fusion enables the LLM to integrate visual and textual information, supporting advanced semantic understanding, reasoning, and decision-making.</p>
<figure class="fig xbox font-sm" id="Fig2"><h5 class="obj_head">Fig. 2.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12374393_12880_2025_1885_Fig2_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/398d/12374393/38a4980a00a6/12880_2025_1885_Fig2_HTML.jpg" loading="lazy" id="d33e342" height="577" width="669" alt="Fig. 2"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Model architecture and workflow for automated quality assessment of abdominal ultrasound standard planes</p></figcaption></figure><p id="Par20">By combining extracted visual features with text-based information, the model facilitates image-text interactions, supporting three core tasks: key structure detection, where the vision encoder identifies critical structures and the LLM outputs their coordinates; standard plane classification, where the model determines the appropriate standard plane type based on the detected structures and hierarchical cues; and image scoring, where the model assesses image quality by evaluating anatomical structure integrity and ultrasound image clarity, generating an interpretable score aligned with clinical guidelines.</p></section><section id="Sec8"><h4 class="pmc_sec_title">Clinical scoring mechanism</h4>
<p id="Par21">To ensure comprehensive and accurate image quality assignment, we referenced clinical guidelines and translated the judgment rules for 11 standard planes into detailed deduction strategies. Figure <a href="#Fig3" class="usa-link">3</a> illustrates the development process of this clinical scoring mechanism. For instance, the guideline for the gallbladder longitudinal view specifies that “the gallbladder neck, body, and bottom must be fully displayed.” We converted this into: “if any structure is not displayed, deduct 3 points; if incomplete, deduct 2 points.” The specific deduction values are determined through discussion and consensus among clinical experts in the field. This precise deduction strategy ensures that different quality issues are quantified, making the image quality assessment standardized and actionable. Additionally, we introduced global deduction labels to address common image quality issues across all standard planes. For example, “acoustic attenuation” is penalized based on its area ratio within the scanning range: 2 points for mild, 4 points for moderate, and 6 points for severe attenuation.</p>
<figure class="fig xbox font-sm" id="Fig3"><h5 class="obj_head">Fig. 3.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12374393_12880_2025_1885_Fig3_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/398d/12374393/2b32df34267e/12880_2025_1885_Fig3_HTML.jpg" loading="lazy" id="d33e361" height="626" width="708" alt="Fig. 3"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Development of a scoring mechanism for abdominal ultrasound standard planes based on clinical guidelines</p></figcaption></figure></section><section id="Sec9"><h4 class="pmc_sec_title">Hierarchical prompting framework</h4>
<p id="Par23">To enhance the clinical reasoning capabilities of our model, we developed a three-layer hierarchical prompting framework, as illustrated in Fig. <a href="#Fig4" class="usa-link">4</a>. This integrated framework combines task specification, structured querying, and scoring reasoning into a unified workflow, reflecting the sequential progression of clinical logic.</p>
<figure class="fig xbox font-sm" id="Fig4"><h5 class="obj_head">Fig. 4.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12374393_12880_2025_1885_Fig4_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/398d/12374393/b45299bc2d8d/12880_2025_1885_Fig4_HTML.jpg" loading="lazy" id="d33e378" height="430" width="669" alt="Fig. 4"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>A comprehensive hierarchical prompting framework for quality assessment of abdominal ultrasound standard planes</p></figcaption></figure><ul class="list" style="list-style-type:disc">
<li><p id="Par26">Task Specification Layer: We define the model’s role in quality control analysis of abdominal ultrasound images, establishing the context and directing its focus on assessing standard plane image quality. This layer incorporates clinical directives based on established standards, providing broad guidance for the model’s operation.</p></li>
<li><p id="Par27">Structured Query Layer: We integrate spatial awareness queries and bounding box annotations to describe the positions and spatial relationships of anatomical structures within the image. Special tokens, such as (&lt;|object ref start|&gt;, &lt;|object ref end|&gt;) and (&lt;|box start|&gt;, &lt;|box end|&gt;), enable the LLM to interpret the vision encoder’s coordinate outputs, facilitating precise localization of anatomical features.</p></li>
<li><p id="Par28">Scoring Reasoning Layer: We implement a Chain-of-Thought (CoT) approach to break down the scoring process into clinically interpretable steps. The model applies structured reasoning, generating detailed justifications for each deduction by linking them to specific image regions via bounding box annotations. This ensures transparency, traceability, and reliability, allowing the LLM to articulate its decisions in clinical terms based on guideline knowledge.</p></li>
</ul></section><section id="Sec10"><h4 class="pmc_sec_title">Task-specific fine-tuning</h4>
<p id="Par29">For this task we selected Qwen2-vl-2B [<a href="#CR17" class="usa-link" aria-describedby="CR17">17</a>] as the backbone and benchmarked its performance against other open-source vision-language models. Direct application of pretrained models proved infeasible because of domain-specific challenges, such as variability in imaging conditions and anatomical diversity across abdominal ultrasound standard planes; therefore, domain adaptation was required for reliable quality assessment. We employed the SWIFT framework [<a href="#CR18" class="usa-link" aria-describedby="CR18">18</a>] for supervised fine-tuning and applied LoRA [<a href="#CR19" class="usa-link" aria-describedby="CR19">19</a>] to adapt a subset of model parameters. The LoRA configuration used a rank of 16, an alpha of 32, a dropout rate of 0.05, a non-trainable bias setting, and bfloat16 (bf16) precision. Adaptation was performed on key linear projection layers within both the attention mechanisms and the feed-forward networks of the Transformer architecture, and the same LoRA configuration was applied across all experiments reported in this work. This strategy enabled efficient task-specific adaptation while reducing computational cost and mitigating overfitting to pretraining patterns.</p>
<p id="Par30">Fine-tuning was performed on a dual-machine setup equipped with sixteen NVIDIA GeForce RTX 3090 GPUs using a learning rate of 4e − 5. We did not freeze the Vision Transformer (ViT) backbone parameters, allowing continued refinement of visual representations for abdominal ultrasound images. Fine-tuning the model of approximately 2 billion parameters with a batch size of 2 for 20,460 steps required approximately 7.3 h. Fine-tuning the model of approximately 7 billion parameters was constrained to a batch size of 1 due to GPU memory limitations; this run required 40,920 steps and took approximately 15.2 h on the same hardware.</p>
<p id="Par31">The model demonstrated stable convergence during fine-tuning (see Supplementary Figure <a href="#MOESM1" class="usa-link">A3</a>). The fine-tuning loss decreased rapidly in the early iterations and continued to decline, while token-level accuracy reached 96.65% at approximately 4,000 iterations (corresponding fine-tuning loss = 0.036) and thereafter remained at approximately 96.6%. The fine-tuning loss attained a minimum of 3.2e − 6 at step 20,180 and had effectively leveled off by approximately 20,000 iterations. Because token-level accuracy correlates more directly with our phrase- and sentence-level evaluation metrics than next-token validation loss, the combination of a leveled loss and a high, stable token-level accuracy supports our assessment that the model had converged for the downstream tasks.</p></section></section></section><section id="Sec11"><h2 class="pmc_sec_title">Results</h2>
<p id="Par32">The independent test set consists of 1,155 abdominal ultrasound scans. The distribution of each plane type within the dataset is presented in Supplementary Table <a href="#MOESM1" class="usa-link">A2</a>. To address class imbalance, we employed random sampling for each plane type, partitioning the dataset into training, validation, and test sets with a 70%:15%:15% split. This strategy ensures a consistent distribution of plane types across all three sets.</p>
<section id="Sec12"><h3 class="pmc_sec_title">Key structure detection</h3>
<p id="Par33">In this section, we evaluate key structure detection, a critical step for accurately localizing anatomical landmarks in abdominal ultrasound standard planes. For this task, we employed VLMs to generate bounding box predictions, with performance assessed using standard metrics: precision, recall, false positive count (FP), and mean intersection over union (Mean-IoU).</p>
<p id="Par34">Precision measures the model’s ability to generate correct positive predictions. It is defined as the ratio of true positives (TP) to the sum of true positives and false positives (FP)</p>
<table class="disp-formula p" id="Equ1"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/398d/12374393/2de918832b2b/d33e426.gif" loading="lazy" id="d33e426" alt="graphic file with name d33e426.gif"></td>
<td class="label">1</td>
</tr></table>
<p id="Par35">Recall, also known as sensitivity or the true positive rate, quantifies the proportion of actual positives that are correctly identified. It is computed as the ratio of true positives (TP) to the sum of true positives and false negatives (FN):</p>
<table class="disp-formula p" id="Equ2"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/398d/12374393/4819d1994a04/d33e434.gif" loading="lazy" id="d33e434" alt="graphic file with name d33e434.gif"></td>
<td class="label">2</td>
</tr></table>
<p id="Par36">Mean Intersection over Union (Mean-IoU) assesses spatial localization accuracy by quantifying the geometric overlap between predicted and ground truth bounding boxes. For a given true positive detection, the Intersection over Union (IoU) is calculated as:</p>
<table class="disp-formula p" id="Equ3"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/398d/12374393/3180984da444/d33e442.gif" loading="lazy" id="d33e442" alt="graphic file with name d33e442.gif"></td>
<td class="label">3</td>
</tr></table>
<p id="Par37">where A and B denote the areas of the predicted and ground truth bounding boxes, respectively. The Mean-IoU is obtained by averaging the IoU values over all true positive detections:</p>
<table class="disp-formula p" id="Equ4"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/398d/12374393/c15b0164ef21/d33e450.gif" loading="lazy" id="d33e450" alt="graphic file with name d33e450.gif"></td>
<td class="label">4</td>
</tr></table>
<p id="Par38">where <em>N</em> is the total number of true positive detections in the test dataset.</p>
<p id="Par39">False Positive Count (Num of FP) indicates the number of erroneous detections, providing insight into potential diagnostic distractions.</p>
<p id="Par40">We evaluated key structure detection in abdominal ultrasound standard planes, presenting performance metrics in two tables. Table <a href="#Tab1" class="usa-link">1</a> compares AbVLM-Q’s performance across different backbones. AbVLM-Q with Qwen2-vl-2B achieves high precision (98.10%) and Mean-IoU (0.786) with 25 false positives (FP), while Qwen2-vl-7B shows a slight recall increase (88.90% vs. 88.30%) but a minor precision drop (97.90%) and reduced Mean-IoU (0.770) with 28 FP, potentially due to increased model complexity. In contrast, models such as InternVL2, Deepseek-VL, and Minicpm-V2.6 perform worse, with precision below 89% and FP exceeding 140, likely due to the limited relevance of their pre-training datasets to medical imaging.</p>
<section class="tw xbox font-sm" id="Tab1"><h4 class="obj_head">Table 1.</h4>
<div class="caption p"><p>Key structure detection performance of AbVLM-Q with different backbones in abdominal ultrasound standard planes (IoU &gt; 0.5)</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Model</th>
<th align="left" colspan="1" rowspan="1">Backbone</th>
<th align="left" colspan="1" rowspan="1">Size</th>
<th align="left" colspan="1" rowspan="1">Recall (%) ↑</th>
<th align="left" colspan="1" rowspan="1">Precision (%) ↑</th>
<th align="left" colspan="1" rowspan="1">Num of FP↓</th>
<th align="left" colspan="1" rowspan="1">Mean-IOU↑</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="5" colspan="1">
<strong>AbVLM-Q</strong>
</td>
<td align="left" colspan="1" rowspan="1">Qwen2-vl [<a href="#CR17" class="usa-link" aria-describedby="CR17">17</a>]</td>
<td align="left" colspan="1" rowspan="1">2B</td>
<td align="center" colspan="1" rowspan="1">88.30</td>
<td align="center" colspan="1" rowspan="1">98.10</td>
<td align="center" colspan="1" rowspan="1">25</td>
<td align="center" colspan="1" rowspan="1">0.786</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Qwen2-vl [<a href="#CR17" class="usa-link" aria-describedby="CR17">17</a>]</td>
<td align="left" colspan="1" rowspan="1">7B</td>
<td align="center" colspan="1" rowspan="1">88.90</td>
<td align="center" colspan="1" rowspan="1">97.90</td>
<td align="center" colspan="1" rowspan="1">28</td>
<td align="center" colspan="1" rowspan="1">0.770</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">InternVL2 [<a href="#CR21" class="usa-link" aria-describedby="CR21">21</a>]</td>
<td align="left" colspan="1" rowspan="1">2B</td>
<td align="center" colspan="1" rowspan="1">75.40</td>
<td align="center" colspan="1" rowspan="1">88.60</td>
<td align="center" colspan="1" rowspan="1">141</td>
<td align="center" colspan="1" rowspan="1">0.640</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Deepseek-VL [<a href="#CR22" class="usa-link" aria-describedby="CR22">22</a>]</td>
<td align="left" colspan="1" rowspan="1">1.3B</td>
<td align="center" colspan="1" rowspan="1">73.20</td>
<td align="center" colspan="1" rowspan="1">87.00</td>
<td align="center" colspan="1" rowspan="1">159</td>
<td align="center" colspan="1" rowspan="1">0.589</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Minicpm-V2.6 [<a href="#CR23" class="usa-link" aria-describedby="CR23">23</a>]</td>
<td align="left" colspan="1" rowspan="1">8B</td>
<td align="center" colspan="1" rowspan="1">70.60</td>
<td align="center" colspan="1" rowspan="1">86.10</td>
<td align="center" colspan="1" rowspan="1">166</td>
<td align="center" colspan="1" rowspan="1">0.583</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p id="Par42">Table <a href="#Tab2" class="usa-link">2</a> evaluates the Faster R-CNN [<a href="#CR20" class="usa-link" aria-describedby="CR20">20</a>] baseline across varying confidence thresholds, revealing its sensitivity to threshold adjustments. At low thresholds (0.00–0.20), we observed high recall (97.95–96.12%) but low precision (54.54–75.46%) and a high number of FP (1157–443), with Mean-IoU ranging from 0.519 to 0.536. At a threshold of 0.99, precision improved to 98.85% and FP dropped to 6, with Mean-IoU reaching 0.626; however, recall decreased to 36.56%. This trade-off demonstrates challenges in Faster R-CNN’s robustness to the anatomical variability in abdominal ultrasound imaging.</p>
<section class="tw xbox font-sm" id="Tab2"><h4 class="obj_head">Table 2.</h4>
<div class="caption p"><p>Sensitivity of faster R-CNN to confidence thresholds in key structure detection for abdominal ultrasound standard planes (IoU &gt; 0.5)</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead>
<tr>
<th align="left" rowspan="2" colspan="1">Model</th>
<th align="left" rowspan="2" colspan="1">Metric</th>
<th align="left" colspan="8" rowspan="1">Confidence threshold</th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1">0.00</th>
<th align="left" colspan="1" rowspan="1">0.10</th>
<th align="left" colspan="1" rowspan="1">0.20</th>
<th align="left" colspan="1" rowspan="1">0.50</th>
<th align="left" colspan="1" rowspan="1">0.70</th>
<th align="left" colspan="1" rowspan="1">0.90</th>
<th align="left" colspan="1" rowspan="1">0.95</th>
<th align="left" colspan="1" rowspan="1">0.99</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="2" colspan="1">Faster RCNN [<a href="#CR24" class="usa-link" aria-describedby="CR24">24</a>]</td>
<td align="left" colspan="1" rowspan="1">
<p>Recall (%) ↑</p>
<p>Precision (%) ↑</p>
<p>Num of FP ↓</p>
</td>
<td align="left" colspan="1" rowspan="1">
<p>97.95</p>
<p>54.54</p>
<p>1157</p>
</td>
<td align="left" colspan="1" rowspan="1">
<p>97.25</p>
<p>65.15</p>
<p>737</p>
</td>
<td align="left" colspan="1" rowspan="1">
<p>96.12</p>
<p>75.46</p>
<p>443</p>
</td>
<td align="left" colspan="1" rowspan="1">
<p>89.77</p>
<p>88.64</p>
<p>163</p>
</td>
<td align="left" colspan="1" rowspan="1">
<p>72.90</p>
<p>93.65</p>
<p>70</p>
</td>
<td align="left" colspan="1" rowspan="1">
<p>61.26</p>
<p>96.88</p>
<p>28</p>
</td>
<td align="left" colspan="1" rowspan="1">
<p>54.48</p>
<p>97.60</p>
<p>19</p>
</td>
<td align="left" colspan="1" rowspan="1">
<p>36.56</p>
<p>98.85</p>
<p>6</p>
</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Mean-IoU ↑</td>
<td align="left" colspan="1" rowspan="1">0.519</td>
<td align="left" colspan="1" rowspan="1">0.528</td>
<td align="left" colspan="1" rowspan="1">0.536</td>
<td align="left" colspan="1" rowspan="1">0.553</td>
<td align="left" colspan="1" rowspan="1">0.562</td>
<td align="left" colspan="1" rowspan="1">0.568</td>
<td align="left" colspan="1" rowspan="1">0.585</td>
<td align="left" colspan="1" rowspan="1">0.626</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="Sec13"><h3 class="pmc_sec_title">Standard plane image classification</h3>
<p id="Par44">We evaluated the classification performance of models using three key metrics: Subset Accuracy (Subset ACC), Label Accuracy (Label ACC), and the macro-averaged F1-score. Subset ACC is a stringent metric that considers a prediction correct only if the entire predicted label set matches the ground truth, making it particularly relevant for multi-label classification. Label ACC measures accuracy on a per-label basis, while the macro-averaged F1-score provides a balanced evaluation by treating all labels equally, ensuring its suitability for multi-label scenarios. The formal definitions of these metrics are as follows:</p>
<table class="disp-formula p" id="Equ5"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/398d/12374393/fb0f02f5ab22/d33e713.gif" loading="lazy" id="d33e713" alt="graphic file with name d33e713.gif"></td>
<td class="label">5</td>
</tr></table>
<p id="Par45">where <em>N</em> is the total number of samples, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq1"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/398d/12374393/74314b25acfb/d33e724.gif" loading="lazy" id="d33e724" alt="Inline graphic"></span> is the true label set of the <em>i</em>-th sample, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq2"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/398d/12374393/d98f95c1a04c/d33e733.gif" loading="lazy" id="d33e733" alt="Inline graphic"></span> is the predicted label set, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq3"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/398d/12374393/de4a3992f85d/d33e739.gif" loading="lazy" id="d33e739" alt="Inline graphic"></span> (·) is the indicator function.</p>
<table class="disp-formula p" id="Equ6"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/398d/12374393/4b35b1b5520e/d33e746.gif" loading="lazy" id="d33e746" alt="graphic file with name d33e746.gif"></td>
<td class="label">6</td>
</tr></table>
<p id="Par46">where <em>L</em> is the number of labels per sample, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq4"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/398d/12374393/24f0ff30e063/d33e757.gif" loading="lazy" id="d33e757" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq5"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/398d/12374393/5f3027aea1d7/d33e763.gif" loading="lazy" id="d33e763" alt="Inline graphic"></span> denote the <em>l</em>-th true and predicted labels of the <em>i</em>-th sample, respectively.</p>
<table class="disp-formula p" id="Equ7"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/398d/12374393/82d75298c707/d33e776.gif" loading="lazy" id="d33e776" alt="graphic file with name d33e776.gif"></td>
<td class="label">7</td>
</tr></table>
<p id="Par47">Table <a href="#Tab3" class="usa-link">3</a> compares the performance of AbVLM-Q with CNN- and transformer-based models in standard plane classification. AbVLM-Q outperforms all models across key metrics. Qwen-VL-2B achieves a Label ACC of 98.96%, surpassing ConvNeXt-T (97.84%) by 1.12% points, while the difference with Qwen-VL-7B (98.87%) is not statistically significant due to overlapping CIs. In multi-view diagnostic scenarios, Qwen-VL-7B achieves a Subset ACC of 96.28%, exceeding ViT-B/32 (93.68%) and ConvNeXt-T (94.29%). For F1-score, Qwen-VL-7B attains 94.61%, outperforming ConvNeXt-T (93.71%) and ViT-B/32 (89.86%), with Qwen-VL-2B scoring 94.18%. These results highlight the framework’s robustness in standard plane identification, which is essential for ultrasound diagnosis.</p>
<section class="tw xbox font-sm" id="Tab3"><h4 class="obj_head">Table 3.</h4>
<div class="caption p"><p>Performance comparison of models for abdominal ultrasound standard plane classification, reported with 95% confidence intervals (CIs)</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Architecture</th>
<th align="left" colspan="1" rowspan="1">Backbone</th>
<th align="left" colspan="1" rowspan="1">Label ACC (%) ↑</th>
<th align="left" colspan="1" rowspan="1">Subset ACC (%) ↑</th>
<th align="left" colspan="1" rowspan="1">Macro F1-score (%) ↑</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="5" colspan="1">CNN-Based</td>
<td align="left" colspan="1" rowspan="1">ConvNeXt-Tiny [<a href="#CR25" class="usa-link" aria-describedby="CR25">25</a>]</td>
<td align="center" colspan="1" rowspan="1">97.84 (97.04, 98.64)</td>
<td align="center" colspan="1" rowspan="1">94.29 (92.95, 95.63)</td>
<td align="center" colspan="1" rowspan="1">93.71 (92.37, 95.05)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">InceptionV3 [<a href="#CR26" class="usa-link" aria-describedby="CR26">26</a>]</td>
<td align="center" colspan="1" rowspan="1">95.58 (94.44, 96.72)</td>
<td align="center" colspan="1" rowspan="1">92.29 (90.75, 93.83)</td>
<td align="center" colspan="1" rowspan="1">81.83 (79.70, 83.96)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">ResNet-50 [<a href="#CR27" class="usa-link" aria-describedby="CR27">27</a>]</td>
<td align="center" colspan="1" rowspan="1">95.32 (94.15, 96.49)</td>
<td align="center" colspan="1" rowspan="1">90.04 (88.31, 91.77)</td>
<td align="center" colspan="1" rowspan="1">84.44 (82.44, 86.44)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">DenseNet-121 [<a href="#CR28" class="usa-link" aria-describedby="CR28">28</a>]</td>
<td align="center" colspan="1" rowspan="1">94.03 (92.72, 95.34)</td>
<td align="center" colspan="1" rowspan="1">90.30 (88.59, 92.01)</td>
<td align="center" colspan="1" rowspan="1">75.36 (72.98, 77.74)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">MobileNetV2 [<a href="#CR29" class="usa-link" aria-describedby="CR29">29</a>]</td>
<td align="center" colspan="1" rowspan="1">92.93 (91.51, 94.35)</td>
<td align="center" colspan="1" rowspan="1">79.05 (76.70, 81.40)</td>
<td align="center" colspan="1" rowspan="1">65.29 (62.66, 67.92)</td>
</tr>
<tr>
<td align="left" rowspan="2" colspan="1">Transformer-Based</td>
<td align="left" colspan="1" rowspan="1">Swin-Tiny [<a href="#CR30" class="usa-link" aria-describedby="CR30">30</a>]</td>
<td align="center" colspan="1" rowspan="1">97.40 (96.52, 98.28)</td>
<td align="center" colspan="1" rowspan="1">92.73 (91.23, 94.23)</td>
<td align="center" colspan="1" rowspan="1">89.75 (88.07, 91.43)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">ViT-B/32 [<a href="#CR31" class="usa-link" aria-describedby="CR31">31</a>]</td>
<td align="center" colspan="1" rowspan="1">96.97 (96.02, 97.92)</td>
<td align="center" colspan="1" rowspan="1">93.68 (92.28, 95.08)</td>
<td align="center" colspan="1" rowspan="1">89.86 (88.19, 91.53)</td>
</tr>
<tr>
<td align="left" rowspan="5" colspan="1">AbVLM-Q (Ours)</td>
<td align="left" colspan="1" rowspan="1">Qwen-VL-2B [<a href="#CR17" class="usa-link" aria-describedby="CR17">17</a>]</td>
<td align="center" colspan="1" rowspan="1">98.96 (98.40, 99.52)</td>
<td align="center" colspan="1" rowspan="1">96.02 (94.89, 97.15)</td>
<td align="center" colspan="1" rowspan="1">94.18 (92.89, 95.47)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Qwen-VL-7B [<a href="#CR17" class="usa-link" aria-describedby="CR17">17</a>]</td>
<td align="center" colspan="1" rowspan="1">98.87 (98.29, 99.45)</td>
<td align="center" colspan="1" rowspan="1">96.28 (95.19, 97.37)</td>
<td align="center" colspan="1" rowspan="1">94.61 (93.36, 95.86)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">InternVL2-2B [<a href="#CR21" class="usa-link" aria-describedby="CR21">21</a>]</td>
<td align="center" colspan="1" rowspan="1">98.27 (97.55, 98.99)</td>
<td align="center" colspan="1" rowspan="1">95.15 (93.91, 96.39)</td>
<td align="center" colspan="1" rowspan="1">92.80 (91.37, 94.23)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">DeepSeek-VL-1.3B [<a href="#CR22" class="usa-link" aria-describedby="CR22">22</a>]</td>
<td align="center" colspan="1" rowspan="1">97.14 (96.22, 98.06)</td>
<td align="center" colspan="1" rowspan="1">94.20 (92.85, 95.55)</td>
<td align="center" colspan="1" rowspan="1">89.21 (87.49, 90.93)</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">MiniCPM-V2.6 [<a href="#CR23" class="usa-link" aria-describedby="CR23">23</a>]</td>
<td align="center" colspan="1" rowspan="1">95.06 (93.86, 96.26)</td>
<td align="center" colspan="1" rowspan="1">91.43 (89.82, 93.04)</td>
<td align="center" colspan="1" rowspan="1">83.89 (81.86, 85.92)</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p id="Par49">To assess the potential impact of imaging equipment characteristics on classification performance, subgroup analyses were conducted stratifying cases by ultrasound vendor/model and probe type. Categories with limited sample sizes or incomplete metadata were combined into an “Others/Unknown” group to ensure adequate statistical power. Performance metrics, including Label Accuracy and Subset Accuracy with corresponding 95% confidence intervals, are detailed in Supplementary Tables <a href="#MOESM1" class="usa-link">A3</a> and <a href="#MOESM1" class="usa-link">A4</a>. The point estimates and confidence intervals for the majority of subgroups were consistent with those of the overall dataset, and substantial overlap of confidence intervals was observed. These findings indicate no clear evidence of systematic performance variation attributable to specific vendors or probe types within the constraints of the available data.</p></section><section id="Sec14"><h3 class="pmc_sec_title">Image scoring</h3>
<p id="Par50">To evaluate AbVLM-Q’s scoring performance on abdominal ultrasound standard planes, we tested five VLM backbones. Scores were assigned on a 0–10 scale and categorized as Poor (0–4), Moderate (4–6), Good (6–8), and Excellent (8–10). As shown in Fig. <a href="#Fig5" class="usa-link">5</a>, all models exhibited a strong diagonal trend, indicating good agreement with the ground truth. Qwen2-vl-2B achieved the highest accuracy in the Excellent category (263/309, 85.11%), while Qwen2-vl-7B performed best in the Good category. InternVL2-2B showed similar performance but tended to overestimate quality, often misclassifying Good images as Excellent. DeepSeek-VL-1.3B and MiniCPM-V2.6 exhibited more off-diagonal misclassifications, particularly between Moderate and Good, reflecting greater uncertainty in borderline cases.</p>
<figure class="fig xbox font-sm" id="Fig5"><h4 class="obj_head">Fig. 5.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12374393_12880_2025_1885_Fig5_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/398d/12374393/473e9e0f1326/12880_2025_1885_Fig5_HTML.jpg" loading="lazy" id="d33e1000" height="132" width="669" alt="Fig. 5"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig5/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Confusion matrix showing the score distribution for abdominal ultrasound standard plane images across all five backbones of the AbVLM-Q system (Poor (0–4), Moderate (4–6), Good (6–8), and Excellent (8–10))</p></figcaption></figure><p id="Par52">Discrete boundaries in deduction criteria contribute significantly to misclassification between the Poor and Moderate categories. For example, the grading of acoustic attenuation affecting the scan sector is divided by thresholds at one-quarter and one-half of the sector area. When the affected region was close to the one-quarter boundary, small variations in the estimated proportion could lead to a two-point difference in the sub-score, shifting the total score from 6 to 4 (Fig. <a href="#Fig6" class="usa-link">6</a>, a<a href="#Fig1" class="usa-link">1</a>–a<a href="#Fig2" class="usa-link">2</a>). Additionally, the AI occasionally failed to identify subtle anatomical discontinuities that experienced sonographers could detect, such as incomplete anterior or posterior gallbladder walls (indicated by red and green lines in Fig. <a href="#Fig6" class="usa-link">6</a>, b<a href="#Fig2" class="usa-link">2</a>), resulting in under-penalization. However, more prominent features, such as the gallbladder neck, were generally recognized and penalized correctly. Moreover, some discrepancies appear to stem from poor image quality, where the AI conflated multiple penalty items into a single category. For instance, in Fig. <a href="#Fig6" class="usa-link">6</a>, c<a href="#Fig2" class="usa-link">2</a> (Right Subcostal Right Lobe of the Liver and Right Kidney Longitudinal View), the model omitted the ground-truth penalty for incomplete visualization of the right kidney lower pole, possibly because this region overlapped with an area affected by acoustic attenuation.</p>
<figure class="fig xbox font-sm" id="Fig6"><h4 class="obj_head">Fig. 6.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12374393_12880_2025_1885_Fig6_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/398d/12374393/6d3d9fdc7a60/12880_2025_1885_Fig6_HTML.jpg" loading="lazy" id="d33e1034" height="585" width="669" alt="Fig. 6"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig6/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Representative misclassified cases between Moderate and Poor grades. The three columns show (1) the original ultrasound image, (2) abnormalities with penalty annotations, and (3) comparison between gold-standard and AI-derived penalties</p></figcaption></figure></section><section id="Sec15"><h3 class="pmc_sec_title">Inference performance</h3>
<p id="Par54">Inference benchmarking was conducted on a single NVIDIA GeForce RTX 3090 GPU under conditions consistent with those described in Sect. 2.4.4 (Task-Specific Fine-Tuning). The model achieved a mean latency of 1.2 s per image in single-image mode and 0.4 s per image with optimized batch processing, with throughput varying modestly depending on the length of the generated textual output. These results indicate that AbVLM-Q is suitable for retrospective, centralized quality-control workflows and large-scale processing of archived examinations.</p></section></section><section id="Sec16"><h2 class="pmc_sec_title">Discussion and conclusions</h2>
<p id="Par55">Due to the growing demand for high-quality standard plane images in abdominal ultrasound, AI-driven automated analysis has become increasingly important. In this study, we developed AbVLM-Q—an automated quality assessment system that integrates a vision-language model with efficient fine-tuning and hierarchical prompting. AbVLM-Q decomposes the quality assessment task into three interrelated subtasks: key structure detection, standard plane classification, and image scoring, thereby closely mimicking clinical decision-making. Experimental results indicate that AbVLM-Q outperforms conventional models across all three tasks. Importantly, this end-to-end, integrated multi-task system reduces reliance on operator expertise while enhancing the consistency of quality evaluations, underscoring its potential for broad clinical application.</p>
<p id="Par56">Accurate detection of key anatomical structures is essential for reliable landmark localization in abdominal ultrasound. Leveraging the Qwen2-vl-2B backbone, AbVLM-Q achieved a precision of 98.10% and a recall of 88.30%, reflecting a balanced and robust performance. In contrast, traditional models—such as Faster R-CNN—suffer from high false-positive rates and significant drops in recall at higher thresholds. Moreover, while Faster R-CNN attained a maximum mean IoU of 0.626 at a confidence score of 0.99, AbVLM-Q reached 0.786, indicating superior capability in capturing fine details and accurately predicting anatomical boundaries. This robust performance without manual threshold adjustments underscores the practical applicability of AbVLM-Q in complex clinical settings.</p>
<p id="Par57">Classifying abdominal ultrasound standard planes remains challenging—particularly when similar plane types share overlapping anatomical features. In our experiments, AbVLM-Q improved Label Accuracy by 1.12% and Subset Accuracy by 1.99% over conventional models, a notable achievement given the stringent requirement to distinguish among 12 distinct planes simultaneously. Furthermore, in resource-constrained configurations (e.g., using MobileNetV2), traditional models recorded a Subset Accuracy as low as 79.05%, whereas even the lightweight DeepSeek-VL-1.3B backbone enabled AbVLM-Q to achieve a Label Accuracy of 91.43%. These findings indicate that AbVLM-Q is robust to domain shifts and can be effectively deployed on embedded devices without significantly compromising diagnostic accuracy.</p>
<p id="Par58">Previous studies on abdominal ultrasound standard plane classification have reported varying accuracies. For example, Cheng et al. achieved 77.9% accuracy using transfer learning—surpassing radiologists’ 71.7% accuracy [<a href="#CR5" class="usa-link" aria-describedby="CR5">5</a>]—while Lawley et al. reported 83.9% accuracy with InceptionV3 [<a href="#CR7" class="usa-link" aria-describedby="CR7">7</a>], and Wu et al. reached 92.31% accuracy in liver ultrasound plane classification [<a href="#CR6" class="usa-link" aria-describedby="CR6">6</a>]. However, these studies often relied on proprietary datasets and private test sets, which were constrained by patient privacy and ethical considerations, making direct comparisons challenging. In contrast, our study achieves 98.96% label accuracy and 96.28% subset accuracy, thereby providing strong evidence of the high performance and robustness of AbVLM-Q relative to existing approaches.</p>
<p id="Par59">To facilitate clinical integration, we developed a scoring mechanism grounded in established clinical guidelines for abdominal ultrasound. This mechanism aligns the model’s scoring with quality control standards, reduces subjectivity, and enhances clinician acceptance. By capturing subtle image quality details and supporting flexible scoring strategies, the system can adapt to various clinical tasks and remain applicable over the long term. Confusion matrix analysis further demonstrates that AbVLM-Q maintains consistent scoring patterns across different backbones. Notably, for quality classifications (poor, moderate, good, and excellent), all backbones perform best on excellent images—a finding that corresponds with real-world observations where most scans are rated as good or excellent (see Supplementary Figure <a href="#MOESM1" class="usa-link">A2</a>). However, distinguishing between poor and moderate quality images remains challenging due to the inherent ambiguity of image-based scoring.</p>
<p id="Par60">In Sect. “<a href="#Sec14" class="usa-link">Image scoring</a>”, analysis of misclassified cases showed that indistinct deduction point boundaries, limited sensitivity to subtle anatomical details, and image quality variations contributed to confusion between Poor and Moderate grades. These findings underscore the need to improve the imaging encoder’s fine-grained feature extraction and subtle discontinuity detection. Future work could focus on optimizing encoder design, integrating multi-scale features, and incorporating domain-specific attention or high-resolution inputs. Refining scoring criteria near deduction boundaries may further enhance handling of borderline cases, thereby reducing misclassifications and improving the reliability of AI-assisted ultrasound quality assessment in clinical practice.</p>
<p id="Par61">The measured inference latency demonstrates that AbVLM-Q is well suited for retrospective, centralized quality control of large ultrasound datasets. Real-time deployment on ultrasound consoles presents additional challenges, including limited computational resources of embedded hardware, strict latency requirements, and integration complexities with proprietary software systems. Therefore, near-term clinical implementation is most feasible through centralized server-based processing coupled with low-latency network connectivity. Achieving on-device, point-of-care inference will necessitate further engineering efforts such as model compression, quantization, knowledge distillation, and hardware-aware optimization, alongside comprehensive clinical validation and regulatory approval.</p>
<p id="Par62">Despite these promising results, our study has several limitations. First, the dataset was primarily derived from routine clinical examinations and may not adequately represent rare anatomical variants or pathological conditions. Second, since the ultrasound scan data were collected from video screenshots, comprehensive patient demographic information (e.g., age, gender, medical history) was not fully captured, thereby limiting our ability to analyze correlations between patient characteristics and image quality. Future work should address these issues by incorporating a more diverse dataset and complete patient profiles to further validate the system’s performance.</p>
<p id="Par63">In conclusion, this study is the first to apply vision-language models to standard plane analysis of abdominal ultrasound, filling a critical gap in automated quality assessment. AbVLM-Q demonstrates performance that is comparable to or exceeds that of traditional models, while its cross-modal transfer learning effectively associates imaging biomarkers with clinical decision-making. This integration may enhance diagnostic consistency in primary healthcare settings. Moreover, further investigation into the application of vision-language models for related tasks, such as organ classification and tumor characterization, could contribute to meaningful advancements in radiology AI, ultimately improving diagnostic accuracy, decision-making efficiency, and patient care.</p></section><section id="Sec17"><h2 class="pmc_sec_title">Supplementary Information</h2>
<p>Below is the link to the electronic supplementary material.</p>
<section class="sm xbox font-sm" id="MOESM1"><div class="media p"><div class="caption">
<a href="/articles/instance/12374393/bin/12880_2025_1885_MOESM1_ESM.docx" data-ga-action="click_feat_suppl" class="usa-link">Supplementary Material 1</a><sup> (1.3MB, docx) </sup>
</div></div></section></section><section id="ack1" class="ack"><h2 class="pmc_sec_title">Acknowledgements</h2>
<p>The authors would like to acknowledge the Department of Ultrasound Medicine, The First Affiliated Hospital, Zhejiang University School of Medicine, and Nanchang People’s Hospital for data provision, and gratefully acknowledge the algorithmic support from Yizhun Medical AI Co.</p></section><section id="glossary1" class="glossary"><h2 class="pmc_sec_title">Abbreviations</h2>
<dl class="def-list">
<dt>VLMs</dt>
<dd><p id="Par68">Vision-Language Models</p></dd>
<dt>AbVLM-Q</dt>
<dd><p id="Par69">Abdominal Vision-Language Model for Quality Assessment</p></dd>
<dt>LLM</dt>
<dd><p id="Par70">Language Model</p></dd>
<dt>CoT</dt>
<dd><p id="Par71">Chain-of-Thought</p></dd>
<dt>ViT</dt>
<dd><p id="Par72">Vision Transformer</p></dd>
<dt>FP</dt>
<dd><p id="Par73">False Positive</p></dd>
<dt>IoU</dt>
<dd><p id="Par74">Intersection Over Union</p></dd>
<dt>TP</dt>
<dd><p id="Par75">True Positive</p></dd>
</dl></section><section id="notes1"><h2 class="pmc_sec_title">Author contributions</h2>
<p>Study concept and design: Baohua Wang, Yaqian Wang, and Tianan Jiang; Acquisition of data: Baohua Wang, Yaqian Wang, and Yanhua Chu; Analysis and interpretation of data: Baohua Wang and Yaqian Wang; Drafting of the manuscript: Baohua Wang and Yaqian Wang; Critical revision of the manuscript: Baohua Wang, Yaqian Wang, Yanhua Chu, Ke Zhang, Lei Liu, Kexin Zhang, Bowen Zhu, Dong Wang, and Tianan Jiang; Statistical analysis: Baohua Wang and Yaqian Wang; Study supervision: Tianan Jiang.</p></section><section id="notes2"><h2 class="pmc_sec_title">Funding</h2>
<p>This study has received funding by the Development Project of National Major Scientific Research Instrument (82027803), Key Research and Development Project of Zhejiang Province (2024C03092), National Key R&amp;D Program of China (2022YFC2405505).</p></section><section id="notes3"><h2 class="pmc_sec_title">Data availability</h2>
<p>Due to patient privacy considerations, data related to patients cannot be made publicly accessible. However, interested parties can request access to the data from the corresponding author through a reasonable inquiry process, subject to approval by the Institutional Review Board of all enrolled centers.</p></section><section id="notes4"><h2 class="pmc_sec_title">Declarations</h2>
<section id="FPar1"><h3 class="pmc_sec_title">Ethics approval and consent to participate</h3>
<p id="Par64">The study was approved by the ethics committees of the First Affiliated Hospital, Zhejiang University School of Medicine. The study was conducted in accordance with the Declaration of Helsinki. Due to the nature of retrospective study, written informed consent was waived.</p></section><section id="FPar2"><h3 class="pmc_sec_title">Consent for publication</h3>
<p id="Par65">Written informed consent was obtained from the patient for publication of this manuscript and any accompanying images. A copy of the written consent is available for review by the Editor of this journal.</p></section><section id="FPar4"><h3 class="pmc_sec_title">Guarantor</h3>
<p id="Par66">None.</p></section><section id="FPar3"><h3 class="pmc_sec_title">Competing interests</h3>
<p id="Par67">The authors declare no competing interests.</p></section></section><section id="fn-group1" class="fn-group"><h2 class="pmc_sec_title">Footnotes</h2>
<div class="fn-group p font-secondary-light font-sm">
<div class="fn p" id="fn1">
<p><strong>Publisher’s note</strong></p>
<p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</div>
<div class="fn p" id="fn2"><p>Baohua Wang and Yaqian Wang contributed equally to this article.</p></div>
</div></section><section id="Bib1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="Bib1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="CR1">
<span class="label">1.</span><cite>Moore CL, Copel JA. Point-of-care ultrasonography. N Engl J Med. 2011;364(8):749–57.
</cite> [<a href="https://doi.org/10.1056/NEJMra0909487" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/21345104/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Moore%20CL,%20Copel%20JA.%20Point-of-care%20ultrasonography.%20N%20Engl%20J%20Med.%202011;364(8):749%E2%80%9357." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR2">
<span class="label">2.</span><cite>Kameda T, Taniguchi N. Overview of point-of-care abdominal ultrasound in emergency and critical care. J Intensive Care. 2016;4(1):53.
</cite> [<a href="https://doi.org/10.1186/s40560-016-0175-y" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4983797/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27529029/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Kameda%20T,%20Taniguchi%20N.%20Overview%20of%20point-of-care%20abdominal%20ultrasound%20in%20emergency%20and%20critical%20care.%20J%20Intensive%20Care.%202016;4(1):53." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR3">
<span class="label">3.</span><cite>Kamaya A, Wong-You-Cheong J, Park HS, Lane BF, Wasnik AP. Diagnostic ultrasound: abdomen and pelvis. Diagnostic ultrasound: abdomen and pelvis; 2015.</cite>
</li>
<li id="CR4">
<span class="label">4.</span><cite>Wilson SR, Gupta C, Eliasziw M, Andrew A. Volume imaging in the abdomen with ultrasound: how we do it. Ajr Am J Roentgenol. 2009;193(1):79–85.
</cite> [<a href="https://doi.org/10.2214/AJR.08.2273" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/19542398/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Wilson%20SR,%20Gupta%20C,%20Eliasziw%20M,%20Andrew%20A.%20Volume%20imaging%20in%20the%20abdomen%20with%20ultrasound:%20how%20we%20do%20it.%20Ajr%20Am%20J%20Roentgenol.%202009;193(1):79%E2%80%9385." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR5">
<span class="label">5.</span><cite>Cheng PM, Malhi HS. Transfer learning with convolutional neural networks for classification of abdominal ultrasound images. J Digit Imaging. 2017;30(2):234.
</cite> [<a href="https://doi.org/10.1007/s10278-016-9929-2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC5359213/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27896451/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Cheng%20PM,%20Malhi%20HS.%20Transfer%20learning%20with%20convolutional%20neural%20networks%20for%20classification%20of%20abdominal%20ultrasound%20images.%20J%20Digit%20Imaging.%202017;30(2):234." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR6">
<span class="label">6.</span><cite>Wu J, Zeng P, Liu P, Lv G. Automatic classification method of liver ultrasound standard plane images using pre-trained convolutional neural network. Connection Sci. 2022;34(1):975–89.</cite> [<a href="https://scholar.google.com/scholar_lookup?Wu%20J,%20Zeng%20P,%20Liu%20P,%20Lv%20G.%20Automatic%20classification%20method%20of%20liver%20ultrasound%20standard%20plane%20images%20using%20pre-trained%20convolutional%20neural%20network.%20Connection%20Sci.%202022;34(1):975%E2%80%9389." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR7">
<span class="label">7.</span><cite>Alistair L, Rory H, Kevin WG, Dobie. Analysis of neural networks for routine classification of sixteen ultrasound upper abdominal cross sections. Abdom Radiol. 2024;49(2):651–61.</cite> [<a href="https://doi.org/10.1007/s00261-023-04147-x" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10830611/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38214722/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Alistair%20L,%20Rory%20H,%20Kevin%20WG,%20Dobie.%20Analysis%20of%20neural%20networks%20for%20routine%20classification%20of%20sixteen%20ultrasound%20upper%20abdominal%20cross%20sections.%20Abdom%20Radiol.%202024;49(2):651%E2%80%9361." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR8">
<span class="label">8.</span><cite>Xu Z, Huo Y, Park JH, Landman B, Milkowski A, Grbic S, et al. Less is more: simultaneous view classification and landmark detection for abdominal ultrasound images. Cham: Springer; 2018.</cite> [<a href="https://scholar.google.com/scholar_lookup?Xu%20Z,%20Huo%20Y,%20Park%20JH,%20Landman%20B,%20Milkowski%20A,%20Grbic%20S,%20et%20al.%20Less%20is%20more:%20simultaneous%20view%20classification%20and%20landmark%20detection%20for%20abdominal%20ultrasound%20images.%20Cham:%20Springer;%202018." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR9">
<span class="label">9.</span><cite>Li K, Xu Y, Meng QH. Automatic recognition of abdominal organs in ultrasound images based on deep neural networks and K-nearest-neighbor classification. 2021.</cite>
</li>
<li id="CR10">
<span class="label">10.</span><cite>Jia Y, Shelhamer E, Donahue J, Karayev S, Long J, Girshick R et al. caffe: convolutional architecture for fast feature embedding. ACM 2014.</cite>
</li>
<li id="CR11">
<span class="label">11.</span><cite>Simonyan K, Zisserman A. Very deep convolutional networks for Large-Scale image recognition. Comput Sci 2014.</cite>
</li>
<li id="CR12">
<span class="label">12.</span><cite>Li C, Wong C, Zhang S, Usuyama N, Liu H, Yang J et al. LLaVA-Med: training a large language-and-vision assistant for biomedicine in one day. 2023.</cite>
</li>
<li id="CR13">
<span class="label">13.</span><cite>Van MH, Verma P, Wu X. On Large Visual Language Models for Medical Imaging Analysis: an empirical study.</cite>
</li>
<li id="CR14">
<span class="label">14.</span><cite>Hartsock I, Rasool G. Vision-Language models for medical report generation and visual question answering: a review. Front Artif Intell 2024.</cite> [<a href="https://doi.org/10.3389/frai.2024.1430984" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11611889/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39628839/" class="usa-link">PubMed</a>]</li>
<li id="CR15">
<span class="label">15.</span><cite>Fang X, Lin Y, Zhang D, Cheng KT, Chen H. Aligning medical images with general knowledge from large language models; 2024.</cite>
</li>
<li id="CR16">
<span class="label">16.</span><cite>Zhou J, He X, Sun L, Xu J, Chen X, Chu Y et al. Pre-trained multimodal large language model enhances dermatological diagnosis using SkinGPT-4. Nat Commun 2024; 15(1).</cite> [<a href="https://doi.org/10.1038/s41467-024-50043-3" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11226626/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38969632/" class="usa-link">PubMed</a>]</li>
<li id="CR17">
<span class="label">17.</span><cite>Wang P, Bai S, Tan S, Wang S, Fan Z, Bai J et al. Qwen2-vl: enhancing vision-language model’s perception of the world at any resolution. ArXiv Preprint arXiv:240912191 2024.</cite>
</li>
<li id="CR18">
<span class="label">18.</span><cite>Zhao Y, Huang J, Hu J, Wang X, Mao Y, Zhang D et al. Swift: a scalable lightweight infrastructure for fine-tuning. ArXiv Preprint arXiv:240805517 2024.</cite>
</li>
<li id="CR19">
<span class="label">19.</span><cite>Hu EJ, Shen Y, Wallis P, Allen-Zhu Z, Li Y, Wang S, et al. Lora: w-rank adaptation of large language models. ICLR. 2022;1(2):3.</cite> [<a href="https://scholar.google.com/scholar_lookup?Hu%20EJ,%20Shen%20Y,%20Wallis%20P,%20Allen-Zhu%20Z,%20Li%20Y,%20Wang%20S,%20et%20al.%20Lora:%20w-rank%20adaptation%20of%20large%20language%20models.%20ICLR.%202022;1(2):3." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR20">
<span class="label">20.</span><cite>Ren S, He K, Girshick R, Sun J, Faster R-CNN. Towards real-time object detection with region proposal networks. IEEE Trans Pattern Anal Mach Intell. 2016;39(6):1137–49.
</cite> [<a href="https://doi.org/10.1109/TPAMI.2016.2577031" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27295650/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Ren%20S,%20He%20K,%20Girshick%20R,%20Sun%20J,%20Faster%20R-CNN.%20Towards%20real-time%20object%20detection%20with%20region%20proposal%20networks.%20IEEE%20Trans%20Pattern%20Anal%20Mach%20Intell.%202016;39(6):1137%E2%80%9349." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR21">
<span class="label">21.</span><cite>Chen Z, Wang W, Tian H, Ye S, Gao Z, Cui E, et al. How Far are we to gpt-4v? Closing the gap to commercial multimodal models with open-source suites. Sci China Inform Sci. 2024;67(12):220101.</cite> [<a href="https://scholar.google.com/scholar_lookup?Chen%20Z,%20Wang%20W,%20Tian%20H,%20Ye%20S,%20Gao%20Z,%20Cui%20E,%20et%20al.%20How%20Far%20are%20we%20to%20gpt-4v?%20Closing%20the%20gap%20to%20commercial%20multimodal%20models%20with%20open-source%20suites.%20Sci%20China%20Inform%20Sci.%202024;67(12):220101." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR22">
<span class="label">22.</span><cite>Lu H, Liu W, Zhang B, Wang B, Dong K, Liu B et al. Deepseek-vl: towards real-world vision-language understanding. ArXiv Preprint arXiv:240305525 2024.</cite>
</li>
<li id="CR23">
<span class="label">23.</span><cite>Yao Y, Yu T, Zhang A, Wang C, Cui J, Zhu H et al. Minicpm-v: A gpt-4v level Mllm on your phone. ArXiv Preprint arXiv:240801800 2024.</cite>
</li>
<li id="CR24">
<span class="label">24.</span><cite>Ren S, He K, Girshick R, Sun J. Faster r-cnn: towards real-time object detection with region proposal networks. Adv Neural Inf Process Syst 2015; 28.</cite> [<a href="https://doi.org/10.1109/TPAMI.2016.2577031" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27295650/" class="usa-link">PubMed</a>]</li>
<li id="CR25">
<span class="label">25.</span><cite>Liu Z, Mao H, Wu C-Y, Feichtenhofer C, Darrell T, Xie S. A convnet for the 2020s; 2022. pp. 11976-86.</cite>
</li>
<li id="CR26">
<span class="label">26.</span><cite>Szegedy C, Vanhoucke V, Ioffe S, Shlens J, Wojna Z. Rethinking the inception architecture for computer vision; 2016. pp. 2818-26.</cite>
</li>
<li id="CR27">
<span class="label">27.</span><cite>He K, Zhang X, Ren S, Sun J. Deep residual learning for image recognition; 2016. pp. 770 – 78.</cite>
</li>
<li id="CR28">
<span class="label">28.</span><cite>Huang G, Liu Z, Van Der Maaten L, Weinberger KQ. Densely connected convolutional networks; 2017. pp. 4700–08.</cite>
</li>
<li id="CR29">
<span class="label">29.</span><cite>Sandler M, Howard A, Zhu M, Zhmoginov A, Chen L-C. Mobilenetv2: Inverted residuals and linear bottlenecks; 2018. pp. 4510-20.</cite>
</li>
<li id="CR30">
<span class="label">30.</span><cite>Liu Z, Lin Y, Cao Y, Hu H, Wei Y, Zhang Z et al. Swin transformer: hierarchical vision transformer using shifted windows; 2021. pp. 10012–22.</cite>
</li>
<li id="CR31">
<span class="label">31.</span><cite>Dosovitskiy A, Beyer L, Kolesnikov A, Weissenborn D, Zhai X, Unterthiner T et al. An image is worth 16x16 words: transformers for image recognition at scale. ArXiv Preprint arXiv:201011929 2020.</cite>
</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adsm93_" lang="en" class="supplementary-materials"><h3 class="pmc_sec_title">Supplementary Materials</h3>
<section class="sm xbox font-sm" id="db_ds_supplementary-material1_reqid_"><div class="media p"><div class="caption">
<a href="/articles/instance/12374393/bin/12880_2025_1885_MOESM1_ESM.docx" data-ga-action="click_feat_suppl" class="usa-link">Supplementary Material 1</a><sup> (1.3MB, docx) </sup>
</div></div></section></section><section id="_adda93_" lang="en" class="data-availability-statement"><h3 class="pmc_sec_title">Data Availability Statement</h3>
<p>Due to patient privacy considerations, data related to patients cannot be made publicly accessible. However, interested parties can request access to the data from the corresponding author through a reasonable inquiry process, subject to approval by the Institutional Review Board of all enrolled centers.</p></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from BMC Medical Imaging are provided here courtesy of <strong>BMC</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1186/s12880-025-01885-w"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/12880_2025_Article_1885.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (3.7 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12374393/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12374393/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12374393%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12374393/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12374393/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12374393/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40849615/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12374393/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40849615/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12374393/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12374393/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="Fpf6JxMVJIYctdoMqdlHWrhGlKKuTSlt9rIs0y1sbk49tiDBWiD1B9UMetNTQ4Qo">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
    

    </body>
</html>
