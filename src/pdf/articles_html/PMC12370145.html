
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            EchoMamba: A new Mamba model for fast and efficient hyperspectral image classification - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="D2E4A4338AF21F7305A43300412AE0E4.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="plosone">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370145/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="PLOS One">
<meta name="citation_title" content="EchoMamba: A new Mamba model for fast and efficient hyperspectral image classification">
<meta name="citation_author" content="Yancong Zhang">
<meta name="citation_author_institution" content="College of Information and Artificial Intelligence, Anhui Agricultural University, Anhui, China">
<meta name="citation_author_institution" content="Key Laboratory of Agricultural Sensors, Ministry of Agriculture and Rural Affairs, Anhui Agriculture University, Anhui, China">
<meta name="citation_author" content="Xiu Jin">
<meta name="citation_author_institution" content="College of Information and Artificial Intelligence, Anhui Agricultural University, Anhui, China">
<meta name="citation_author_institution" content="Key Laboratory of Agricultural Sensors, Ministry of Agriculture and Rural Affairs, Anhui Agriculture University, Anhui, China">
<meta name="citation_author" content="Xiaodan Zhang">
<meta name="citation_author_institution" content="College of Information and Artificial Intelligence, Anhui Agricultural University, Anhui, China">
<meta name="citation_author_institution" content="Key Laboratory of Agricultural Sensors, Ministry of Agriculture and Rural Affairs, Anhui Agriculture University, Anhui, China">
<meta name="citation_author" content="Yuting Wu">
<meta name="citation_author_institution" content="College of Information and Artificial Intelligence, Anhui Agricultural University, Anhui, China">
<meta name="citation_author_institution" content="Key Laboratory of Agricultural Sensors, Ministry of Agriculture and Rural Affairs, Anhui Agriculture University, Anhui, China">
<meta name="citation_author" content="Lijing Tu">
<meta name="citation_author_institution" content="College of Information and Artificial Intelligence, Anhui Agricultural University, Anhui, China">
<meta name="citation_author_institution" content="Key Laboratory of Agricultural Sensors, Ministry of Agriculture and Rural Affairs, Anhui Agriculture University, Anhui, China">
<meta name="citation_publication_date" content="2025 Aug 21">
<meta name="citation_volume" content="20">
<meta name="citation_issue" content="8">
<meta name="citation_firstpage" content="e0330678">
<meta name="citation_doi" content="10.1371/journal.pone.0330678">
<meta name="citation_pmid" content="40839574">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370145/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370145/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370145/pdf/pone.0330678.pdf">
<meta name="description" content="The classification of hyperspectral images (HSI) is an important foundation in the field of remote sensing. Mamba architectures based on state space model (SSM) have shown great potential in the field of HSI processing due to their powerful ...">
<meta name="og:title" content="EchoMamba: A new Mamba model for fast and efficient hyperspectral image classification">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="The classification of hyperspectral images (HSI) is an important foundation in the field of remote sensing. Mamba architectures based on state space model (SSM) have shown great potential in the field of HSI processing due to their powerful ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370145/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12370145">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1371/journal.pone.0330678"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/pone.0330678.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12370145%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12370145/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12370145/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370145/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-plosone.png" alt="PLOS One logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to PLOS One" title="Link to PLOS One" shape="default" href="https://doi.org/10.1371/journal.pone.0330678" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">PLoS One</button></div>. 2025 Aug 21;20(8):e0330678. doi: <a href="https://doi.org/10.1371/journal.pone.0330678" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1371/journal.pone.0330678</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22PLoS%20One%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22PLoS%20One%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22PLoS%20One%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22PLoS%20One%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>EchoMamba: A new Mamba model for fast and efficient hyperspectral image classification</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Zhang%20Y%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Yancong Zhang</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Yancong Zhang</span></h3>
<div class="p">
<sup>1</sup>College of Information and Artificial Intelligence, Anhui Agricultural University, Anhui, China</div>
<div class="p">
<sup>2</sup>Key Laboratory of Agricultural Sensors, Ministry of Agriculture and Rural Affairs, Anhui Agriculture University, Anhui, China</div>
<div>Data curation, Investigation, Validation, Writing – original draft</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Zhang%20Y%22%5BAuthor%5D" class="usa-link"><span class="name western">Yancong Zhang</span></a>
</div>
</div>
<sup>1,</sup><sup>2,</sup><sup>¤</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Jin%20X%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Xiu Jin</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">Xiu Jin</span></h3>
<div class="p">
<sup>1</sup>College of Information and Artificial Intelligence, Anhui Agricultural University, Anhui, China</div>
<div class="p">
<sup>2</sup>Key Laboratory of Agricultural Sensors, Ministry of Agriculture and Rural Affairs, Anhui Agriculture University, Anhui, China</div>
<div>Data curation</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Jin%20X%22%5BAuthor%5D" class="usa-link"><span class="name western">Xiu Jin</span></a>
</div>
</div>
<sup>1,</sup><sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Zhang%20X%22%5BAuthor%5D" class="usa-link" aria-describedby="id3"><span class="name western">Xiaodan Zhang</span></a><div hidden="hidden" id="id3">
<h3><span class="name western">Xiaodan Zhang</span></h3>
<div class="p">
<sup>1</sup>College of Information and Artificial Intelligence, Anhui Agricultural University, Anhui, China</div>
<div class="p">
<sup>2</sup>Key Laboratory of Agricultural Sensors, Ministry of Agriculture and Rural Affairs, Anhui Agriculture University, Anhui, China</div>
<div>Formal analysis</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Zhang%20X%22%5BAuthor%5D" class="usa-link"><span class="name western">Xiaodan Zhang</span></a>
</div>
</div>
<sup>1,</sup><sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Wu%20Y%22%5BAuthor%5D" class="usa-link" aria-describedby="id4"><span class="name western">Yuting Wu</span></a><div hidden="hidden" id="id4">
<h3><span class="name western">Yuting Wu</span></h3>
<div class="p">
<sup>1</sup>College of Information and Artificial Intelligence, Anhui Agricultural University, Anhui, China</div>
<div class="p">
<sup>2</sup>Key Laboratory of Agricultural Sensors, Ministry of Agriculture and Rural Affairs, Anhui Agriculture University, Anhui, China</div>
<div>Methodology</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Wu%20Y%22%5BAuthor%5D" class="usa-link"><span class="name western">Yuting Wu</span></a>
</div>
</div>
<sup>1,</sup><sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Tu%20L%22%5BAuthor%5D" class="usa-link" aria-describedby="id5"><span class="name western">Lijing Tu</span></a><div hidden="hidden" id="id5">
<h3><span class="name western">Lijing Tu</span></h3>
<div class="p">
<sup>1</sup>College of Information and Artificial Intelligence, Anhui Agricultural University, Anhui, China</div>
<div class="p">
<sup>2</sup>Key Laboratory of Agricultural Sensors, Ministry of Agriculture and Rural Affairs, Anhui Agriculture University, Anhui, China</div>
<div>Validation</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Tu%20L%22%5BAuthor%5D" class="usa-link"><span class="name western">Lijing Tu</span></a>
</div>
</div>
<sup>1,</sup><sup>2,</sup><sup>*</sup>
</div>
<div class="cg p">Editor: <span class="name western">Sandipan Mondal</span><sup>3</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="aff001">
<sup>1</sup>College of Information and Artificial Intelligence, Anhui Agricultural University, Anhui, China</div>
<div id="aff002">
<sup>2</sup>Key Laboratory of Agricultural Sensors, Ministry of Agriculture and Rural Affairs, Anhui Agriculture University, Anhui, China</div>
<div id="edit1">
<sup>3</sup>National Taiwan Ocean University, TAIWAN</div>
<div class="author-notes p">
<div class="fn" id="cor001">
<sup>✉</sup><p class="display-inline">* E-mail: <span>tlj@ahau.edu.cn</span></p>
</div>
<div class="fn" id="coi001"><p><strong>Competing Interests: </strong>The authors have declared that no competing interests exist.</p></div>
<div class="fn" id="currentaff001">
<sup>¤</sup><p class="display-inline">Current Address: College of Computer Science and Engineering, Northeastern University, Shenyang, China</p>
</div>
</div>
<h4 class="font-secondary">Roles</h4>
<div class="p">
<strong class="contrib"><span class="name western">Yancong Zhang</span></strong>: <span class="role">Data curation, Investigation, Validation, Writing – original draft</span>
</div>
<div>
<strong class="contrib"><span class="name western">Xiu Jin</span></strong>: <span class="role">Data curation</span>
</div>
<div>
<strong class="contrib"><span class="name western">Xiaodan Zhang</span></strong>: <span class="role">Formal analysis</span>
</div>
<div>
<strong class="contrib"><span class="name western">Yuting Wu</span></strong>: <span class="role">Methodology</span>
</div>
<div>
<strong class="contrib"><span class="name western">Lijing Tu</span></strong>: <span class="role">Validation</span>
</div>
<div class="p">
<strong class="contrib"><span class="name western">Sandipan Mondal</span></strong>: <span class="role">Editor</span>
</div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2025 Jun 5; Accepted 2025 Aug 3; Collection date 2025.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© 2025 Zhang et al</div>
<p>This is an open access article distributed under the terms of the <a href="https://creativecommons.org/licenses/by/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Creative Commons Attribution License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12370145  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40839574/" class="usa-link">40839574</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="abstract1"><h2>Abstract</h2>
<p>The classification of hyperspectral images (HSI) is an important foundation in the field of remote sensing. Mamba architectures based on state space model (SSM) have shown great potential in the field of HSI processing due to their powerful long-range sequence modeling capabilities and the efficiency advantages of linear computing. Based on this theoretical basis, We propose a novel deep learning framework: long-sequence Mamba (EchoMamba), which combines the powerful long sequence processing capabilities of Long Short-Term Memory(LSTM) and Mamba to further explore the spectral dimension of HSI, and carry out more in-depth mining and learning of the spectral dimension of HSI. Compared with the previous HSI classification model, the experimental results show that EchoMamba can significantly reduce the training time cost of HSI and effectively improve the performance of the classification task.This study not only advances the current state of HSI classification but also provides a robust foundation for future research in spectral-spatial feature extraction and large-scale remote sensing applications.</p></section><section id="sec001"><h2 class="pmc_sec_title">Introduction</h2>
<p>HSI is a kind of image data containing rich spectral information, which can effectively detect the spectral information of ground objects from visible band to thermal infrared band through hundreds of spectral channels. With the nanoscale spectral resolution, the hyperspectral sensor can continuously perform spectral scanning and record the spectral reflectivity of each band, thus forming a continuous spectral curve, which reflects the spectral characteristics of the ground objects, which are closely related to the composition, structure, state and other factors of ground objects [<a href="#pone.0330678.ref001" class="usa-link" aria-describedby="pone.0330678.ref001">1</a>].Through in-depth analysis of these spectral curves, hyperspectral sensors can identify and distinguish different ground objects, so as to achieve accurate classification and feature extraction of land cover.</p>
<p>With its superior spectral resolution, HSI plays an important role in several fields. In the field of agriculture, by analyzing the spectral characteristics of crops at different growth stages, HSI can realize effective monitoring of crop growth, diseases, pests and nutritional status [<a href="#pone.0330678.ref002" class="usa-link" aria-describedby="pone.0330678.ref002">2</a>]. In terms of environmental monitoring, it can monitor water pollution, atmospheric composition, soil characteristics and other key environmental factors [<a href="#pone.0330678.ref003" class="usa-link" aria-describedby="pone.0330678.ref003">3</a>]. In geological exploration, HSI helps to identify mineral composition and provide support for the exploration of geological structures and mineral deposits [<a href="#pone.0330678.ref004" class="usa-link" aria-describedby="pone.0330678.ref004">4</a>]. In urban planning, it can be used for land cover classification and urban heat island effect analysis to support smart city development [<a href="#pone.0330678.ref005" class="usa-link" aria-describedby="pone.0330678.ref005">5</a>]. In addition, in the field of military reconnaissance, it also plays an important role, such as performing tasks such as target identification and camouflage detection [<a href="#pone.0330678.ref006" class="usa-link" aria-describedby="pone.0330678.ref006">6</a>].</p>
<p>Today, deep learning technology has made remarkable progress in dealing with HSI [<a href="#pone.0330678.ref007" class="usa-link" aria-describedby="pone.0330678.ref007">7</a>]. The success of deep learning in this domain can be attributed to its ability to automatically extract hierarchical and discriminative features from high-dimensional and complex data. Unlike traditional methods that often rely on handcrafted features and prior knowledge, Models such as convolutional neural networks (CNN) can learn spatial-spectral features directly from raw HSI data, capturing intricate patterns and relationships that are difficult to model manually. This is especially beneficial for HSI, where the data contains rich spectral information across hundreds of narrow bands, enabling the identification of subtle material differences and fine-grained classification. Additionally, Some deep learning models such as recurrent neural networks (RNN), Transformers, could further enhanced the capability to model sequential dependencies and spatial relationships in HSI data. The scalability and adaptability of deep learning models also make them suitable for various HSI applications [<a href="#pone.0330678.ref008" class="usa-link" aria-describedby="pone.0330678.ref008">8</a>].</p>
<p>CNN can effectively extract the spatial features of images through convolutional layer [<a href="#pone.0330678.ref009" class="usa-link" aria-describedby="pone.0330678.ref009">9</a>], which is very effective for HSI classification and target detection tasks. In addition, the multi-layer structure of CNN allows the model to learn hierarchically from low-level features to high-level features, which can better learn the rich spatial features of HSI in the training stage of the model [<a href="#pone.0330678.ref010" class="usa-link" aria-describedby="pone.0330678.ref010">10</a>]. However, traditional CNN models tend to pay too much attention to the spatial features and ignore the effective use of spectral information when processing HSI, thus limiting the model’s processing performance of HSI. In addition, due to the huge amount of HSI, it is also a great challenge to use CNN to train HSI.</p>
<p>Through its unique parameter-sharing mechanism, RNN can effectively reduce the number of parameters in the model [<a href="#pone.0330678.ref011" class="usa-link" aria-describedby="pone.0330678.ref011">11</a>], which can significantly reduce the time cost compared with CNN when processing HSI, thus effectively improving the operational efficiency of the model [<a href="#pone.0330678.ref012" class="usa-link" aria-describedby="pone.0330678.ref012">12</a>]. However, in terms of processing performance, the sequence data processing characteristics of RNN expose certain limitations in the face of complex data with the characteristics of high-dimensional such as HSI. Since RNN needs to process each element of the sequence in turn when processing data, it has serious shortcomings in spatial feature extraction. Given the rich spatial complexity in HSI, RNN struggle to capture some long-distance dependencies and local features in the image, which leads to certain limitations in its performance in HSI classification tasks.</p>
<p>As a relatively new large model, Transformer has shown excellent performance in the field of HSI processing in recent years. Through its self-attention mechanism, Transformer can effectively capture long-distance dependencies in images, thus realizing accurate understanding of the global context in HSI [<a href="#pone.0330678.ref013" class="usa-link" aria-describedby="pone.0330678.ref013">13</a>]. Different from RNN, Transformer can process all elements in the sequence in parallel, which further improves the speed of model training and reasoning on HSI. By incorporating positional encoding, Transformers preserve the position information of pixels in the image, which is very important for the spatial position analysis of HSI [<a href="#pone.0330678.ref014" class="usa-link" aria-describedby="pone.0330678.ref014">14</a>]. However, although the self-attention mechanism is very effective in HSI processing, the quadratic computational complexity of self-attention mechanisms necessitates a large amount of computing resources and memory when processing HSI with complex dimensions, which is even higher than that of CNN. In addition, due to the complexity of the internal mechanism of Transformer, its decision-making process often lacks transparency, which makes it extremely challenging in terms of model interpretation.</p>
<p>Mamba is a new deep learning framework inspired by the Structured State Space Model (SSM) [<a href="#pone.0330678.ref015" class="usa-link" aria-describedby="pone.0330678.ref015">15</a>], which is a model used to deal with long sequence efficiency problems, but such models have great limitations in terms of application scenarios, and their performance is poor when dealing with modes such as languages. Mamba improves on this by making the parameters of the SSM a function of the input, which allows the improved model to selectively propagate information along the sequence length dimension based on the tokens currently being processed. Although the improved SSM cannot use convolution to speed up data processing, Mamba has designed a hardware-friendly parallel algorithm that enables efficient processing of data in circular mode; In addition, because Mamba presents linear scaling O(n) with sequence length, it is able to efficiently process large data volumes. Benchmark experiments demonstrate that when performing the same task, compared with Transformer, Mamba can achieve a nearly 5 × speedup in inference speed while ensuring output quality.</p>
<p>Based on its strong adaptability to long sequence data [<a href="#pone.0330678.ref016" class="usa-link" aria-describedby="pone.0330678.ref016">16</a>], Mamba is able to effectively process HSI. The content-based reasoning ability of allows it to selectively perform propagation-or-forget operations based on the information in each band in the HSI, thus capturing spectral features more efficiently. In addition, Mamba’s advanced performance on multiple modes and good generalization ability enable it to effectively adapt to data types with complex dimensions such as HSI. In view of the huge amount of data in HSI, Mamba’s hardware-optimization parallel algorithm also enables it to effectively utilize computing resources and realize efficient processing of HSI [<a href="#pone.0330678.ref017" class="usa-link" aria-describedby="pone.0330678.ref017">17</a>]. However, Mamba’s ability to process data depends to a certain extent on the quality of the data itself. In the case of poor HSI data quality, the performance of the model may suffer and thus reduce the ability to process HSI. Therefore, before using Mamba to process HSI, HSI preprocessing becomes a significant challenge.</p>
<p>In order to further explore the potential of Mamba in HSI processing, a novel Long-sequence Mamba(EchoMamba) framework is proposed in this paper. On the basis of full reference and fusion of existing technologies, the framework adopts a series of efficient data preprocessing strategies, including feature selection and oversampling, to ensure the quality and reliability of HSI data. On this basis, EchoMamba cleverly combines short-term memory network (LSTM) with original Mamba to form a highly innovative deep learning model. This new framework not only inherits Mamba’s unique advantages in processing HSI, but also enhances the model’s processing capability of HSI spectral dimensions through LSTM, providing more powerful technical support for HSI classification, recognition and analysis.</p></section><section id="sec002"><h2 class="pmc_sec_title">Materials &amp; methods</h2>
<section id="sec003"><h3 class="pmc_sec_title">Hyperspectral images: basic research</h3>
<p>As an advanced remote sensing image, HSI plays an important role in many fields because of its unique data characteristics and wide application prospects. The image reveals the rich spectral features of ground objects through capturing the reflection or emission information of objects in different spectral bands. The HSI is presented as a three-dimensional data cube in terms of character [<a href="#pone.0330678.ref018" class="usa-link" aria-describedby="pone.0330678.ref018">18</a>], where each pixel contains not only a single characteristic value, but a complete spectral curve. Such a data structure gives Although it means that HSI can provide detailed spectral information about ground objects, which greatly promotes the analysis and classification of material composition, its huge amount of data is difficult to deal with, which is an unavoidable problem.</p>
<p>In the field of deep learning, in order to effectively process and analyze HSI, researchers have used CNN, RNN, Transformer and other technologies to make many attempts. Hsi-CNN is a convolutional neural network framework used to improve the classification performance of HSI [<a href="#pone.0330678.ref019" class="usa-link" aria-describedby="pone.0330678.ref019">19</a>]. According to the characteristics of HSI data, the framework is designed to extract the spectrum-space features of target pixels and their neighborhoods, convert these features into one-dimensional feature maps through convolution operations, and stack them into two-dimensional matrices, which are finally input into the standard convolutional neural network as images for classification. Instead of using convolution to process HSI, Zhang et al proposed a local spatial sequence method, LSS [<a href="#pone.0330678.ref020" class="usa-link" aria-describedby="pone.0330678.ref020">20</a>], which they embedded into RNN to extract local and semantic information of HSI, thus achieving classification of HSI. Specifically, they extracted and fused low-level features, including texture and differential morphological contours, through the analysis of HSI to construct LSS features. Then they used these features as inputs, an RNN model was trained to optimize the system parameters of the network. At the end of the network, the high-level semantic features generated by the RNN are fed into the Softmax layer for final classification decisions.ConGCN is an HSI classification model based on graph convolution network and contrastive learning [<a href="#pone.0330678.ref021" class="usa-link" aria-describedby="pone.0330678.ref021">21</a>]. To solve the problem of insufficient supervision caused by the scarcity of HSI labeled samples, CONGCN integrates spectrum-space contrast supervision and adaptive graph structure optimization to improve the classification performance. In this model, a semi-supervised contrast learning mechanism is designed to implement feature consistency constraints on the nodes of the same object category or the enhanced view of the same node, and the implicit spectral discrimination information is mined from the limited markers. Secondly, the potential spatial relationships between pixels are captured by the graph-generation loss guidance model, and the topological relationships of adjacent similar nodes are converted into auxiliary supervisory signals. At the same time, combined with spectral similarity and spatial distance, the node connection weights of the graph are dynamically adjusted, and the adaptive enhanced graph structure is constructed to enhance the rationality of feature comparison. Finally, the combined multi-source supervised graph convolutional network can effectively learn discriminative features under the condition of a few labels, and achieve classification accuracy beyond the traditional GCN and comparison model on six typical data sets.</p>
<p>According to the theoretical results of the researchers, we can conclude that CNN and RNN have their own advantages in the field of HSI. With its excellent ability of convolutional feature extraction, CNN are powerful in dealing with the spatial dimension of HSI, and can carry out feature learning efficiently. However, when faced with the spectral dimension with long sequence features, the processing ability of CNN is slightly insufficient. On the contrary, relying on its unique cyclic characteristics, RNN have significant advantages in deep mining the spectral dimension of HSI, but their performance is relatively limited when dealing with more complex spatial information containing two dimensions.</p>
<p>Considering that it is difficult to fully excavate the multi-dimensional deep information when using CNN, GCN or RNN alone to process HSI, He et al proposed an innovative Space-Spectral Transformer (SST) classification framework based on the theory of Transformer’s HSI processing. This framework cleverly combines CNN to extract spatial features of images, and captures long-distance spectral sequence relationships through an improved Transformer structure. Based on this, multi-layer perceptrons are utilized for the classification task. Compared with the previous methods, the SST framework can handle HSI more comprehensively, and demonstrates significant improvements. However, due to the complexity of its model structure, SST has a O(n<sup>2</sup>) computational complexity for the HSI training phase, which indicates that there are still some challenges and limitations when using Transformer for HSI processing.</p>
<p>To sum up, existing approaches to HSI classification, including CNN, RNN and GCN-based methods, continue to face performance limitations. Although Transformer models show promising results in this domain, their application is constrained by substantial computational requirements.</p></section><section id="sec004"><h3 class="pmc_sec_title">Mamba: reference model</h3>
<p>Mamba has shown excellent applicability in HSI training, mainly due to its strong feature extraction and timing modeling capabilities [<a href="#pone.0330678.ref022" class="usa-link" aria-describedby="pone.0330678.ref022">22</a>]. HSI has high dimensionality, high correlation and rich spectral information, which makes traditional models often face problems such as high computational complexity and difficulty in feature extraction when processing such data. Mamba, through its core component SSM, is able to effectively capture continuous spectral information in HSI, thus achieving excellent performance in tasks such as classification, identification and anomaly detection.</p>
<p><a href="#pone.0330678.g001" class="usa-link">Fig 1</a> shows the basic framework of SSM. SSM is constructed from a continuous-time system [<a href="#pone.0330678.ref023" class="usa-link" aria-describedby="pone.0330678.ref023">23</a>], which maps the input sequence x(t) to the corresponding output signal y(t) through an potential state h(t).</p>
<figure class="fig xbox font-sm" id="pone.0330678.g001"><h4 class="obj_head">Fig 1. State Space Model(SSM) framework.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370145_pone.0330678.g001.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b8dc/12370145/38b8de3fbe94/pone.0330678.g001.jpg" loading="lazy" height="306" width="756" alt="Fig 1"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330678.g001/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><table class="disp-formula p" id="pone.0330678.e001"><tr>
<td class="formula"><math id="M1" display="block" overflow="linebreak"><mrow><mtable columnspacing="2pt" displaystyle="true" rowspacing="3pt"><mtr><mtd columnalign="right"><msup><mtext>h</mtext><mrow><mi>′</mi></mrow></msup><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>=</mo><mtext>Ah</mtext><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>+</mo><mtext>Bx</mtext><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mtd></mtr></mtable></mrow></math></td>
<td class="label">(1)</td>
</tr></table>
<table class="disp-formula p" id="pone.0330678.e002"><tr>
<td class="formula"><math id="M2" display="block" overflow="linebreak"><mrow><mtext>y</mtext><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>=</mo><mtext>Ch</mtext><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>+</mo><mtext>Dx</mtext><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></td>
<td class="label">(2)</td>
</tr></table>
<p>Formula (1) describes the dynamic evolution process of h(t) with time t. Where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e003"><math id="M3" display="inline" overflow="linebreak"><mrow><mtable columnspacing="2pt" displaystyle="true" rowspacing="3pt"><mtr><mtd columnalign="right"><msup><mtext>h</mtext><mrow><mi>′</mi></mrow></msup><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mtd></mtr></mtable></mrow></math></span> represents a hidden intermediate state in the model from <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e004"><math id="M4" display="inline" overflow="linebreak"><mrow><mtext>x</mtext><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></span> to <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e005"><math id="M5" display="inline" overflow="linebreak"><mrow><mtext>y</mtext><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></span>. In this model, the state transition matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e006"><math id="M6" display="inline" overflow="linebreak"><mrow><mtext>A</mtext><mo>∈</mo><msup><mrow><mtext>R</mtext></mrow><mrow><mtext>N</mtext><mo>*</mo><mtext>N</mtext></mrow></msup></mrow></math></span>, which precisely characterizes the state transition mechanism of h(t) from one moment to the next on the timeline. In other words, A determines how state h(t) transitions between different points in time, which allows the model to predict where the state will go in the future. B <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e007"><math id="M7" display="inline" overflow="linebreak"><mrow><mo>∈</mo><msup><mrow><mtext>R</mtext></mrow><mrow><mtext>N</mtext><mo>*</mo><mtext>M</mtext></mrow></msup></mrow></math></span>,which is a control matrix that reveals the extent to which x(t) contributes to changes in the h(t). Specifically, the B describes how the x(t) can influence the dynamics of h(t) through a complex series of interactions. This formula shows that the change in h(t) is a result of the interaction between the h(t) and the x(t). This interaction is not only continuous in time, but also shows the response ability of the system to the external stimulus.</p>
<p>Formula (2) illustrates the process by which h(t) and x(t) generate y(t). As the observation matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e008"><math id="M8" display="inline" overflow="linebreak"><mrow><mtext>C</mtext><mo>∈</mo><msup><mrow><mtext>R</mtext></mrow><mrow><mtext>O</mtext><mo>*</mo><mtext>N</mtext></mrow></msup></mrow></math></span>, it extracts the information related to the output in h(t), transforming it into a part of y(t). D<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e009"><math id="M9" display="inline" overflow="linebreak"><mrow><mo>∈</mo><msup><mrow><mtext>R</mtext></mrow><mrow><mtext>O</mtext><mo>*</mo><mtext>M</mtext></mrow></msup></mrow></math></span>, which is a direct transfer matrix that describes the process by which x(t) is passed directly to y(t) without going through h(t), which can be seen as a residual connection that allows the input signal to have a direct effect on the output. By combining the linear transformation of C to h(t) with the direct transfer of D to x(t), Formula (2) obtained the final output y(t).</p>
<p>However, SSM faces a significant efficiency bottleneck when dealing with long sequences and large volumes of data. This is because the memory and computation time required by the SSM model show a linear increase trend as the length of the sequence increases. This characteristic limits the performance of SSM when dealing with some discrete signal processing tasks. In practical applications, this bottleneck may lead to slow processing speed, excessive resource consumption, and even the inability to process ultra-long sequences or large-scale data sets, thus affecting the applicable scope and popularization value of the model</p>
<p>To solve this problem, the researchers use zero-order preservation technique to discretize the system parameters in SSM. Zero-order hold technique is a discretization method commonly used in digital signal processing. Based on this technique, the re-parameterization process of system matrix and time scale parameters is as follows:</p>
<table class="disp-formula p" id="pone.0330678.e010"><tr>
<td class="formula"><math id="M10" display="block" overflow="linebreak"><mrow><mover><mrow><mtext>A</mtext></mrow><mo accent="true">―</mo></mover><mo>=</mo><mtext>exp</mtext><mo stretchy="false">(</mo><mrow><mi>Δ</mi></mrow><mtext>A</mtext><mo stretchy="false">)</mo></mrow></math></td>
<td class="label">(3)</td>
</tr></table>
<table class="disp-formula p" id="pone.0330678.e011"><tr>
<td class="formula"><math id="M11" display="block" overflow="linebreak"><mrow><mover><mrow><mtext>B</mtext></mrow><mo accent="true">―</mo></mover><mo>=</mo><msup><mrow><mo stretchy="false">(</mo><mrow><mi>Δ</mi></mrow><mtext>A</mtext><mo stretchy="false">)</mo></mrow><mrow><mo>−</mo><mtext>1</mtext></mrow></msup><mo stretchy="false">(</mo><mover><mrow><mtext>A</mtext></mrow><mo accent="true">―</mo></mover><mo>−</mo><mtext>I</mtext><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mrow><mi>Δ</mi></mrow><mtext>B</mtext><mo stretchy="false">)</mo></mrow></math></td>
<td class="label">(4)</td>
</tr></table>
<table class="disp-formula p" id="pone.0330678.e012"><tr><td class="formula"><math id="M12" display="block" overflow="linebreak"><mrow><mo>≈</mo><msup><mrow><mo stretchy="false">(</mo><mrow><mi>Δ</mi></mrow><mtext>A</mtext><mo stretchy="false">)</mo></mrow><mrow><mo>−</mo><mtext>1</mtext></mrow></msup><mo stretchy="false">(</mo><mrow><mi>Δ</mi></mrow><mtext>A</mtext><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mrow><mi>Δ</mi></mrow><mtext>B</mtext><mo stretchy="false">)</mo></mrow></math></td></tr></table>
<table class="disp-formula p" id="pone.0330678.e013"><tr><td class="formula"><math id="M13" display="block" overflow="linebreak"><mrow><mo>=</mo><mrow><mi>Δ</mi></mrow><mtext>B</mtext></mrow></math></td></tr></table>
<p>Formula 3 achieves discretization of the A, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e014"><math id="M14" display="inline" overflow="linebreak"><mrow><mrow><mi>Δ</mi></mrow><mtext>A</mtext></mrow></math></span> is the product of A and the sampling time interval <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e015"><math id="M15" display="inline" overflow="linebreak"><mrow><mrow><mi>Δ</mi></mrow></mrow></math></span>. In discrete-time system, the state transition matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e016"><math id="M16" display="inline" overflow="linebreak"><mrow><mover><mrow><mtext>A</mtext></mrow><mo accent="true">―</mo></mover></mrow></math></span> is obtained by performing an exponential operation on A, where the exponential operation of A can be computed by summing the Taylor series expansions of the <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e017"><math id="M17" display="inline" overflow="linebreak"><mrow><mrow><mi>Δ</mi></mrow><mtext>A</mtext></mrow></math></span>, As shown in Formula 5.</p>
<table class="disp-formula p" id="pone.0330678.e018"><tr>
<td class="formula"><math id="M18" display="block" overflow="linebreak"><mrow><mtext>exp</mtext><mo stretchy="false">(</mo><mrow><mi>Δ</mi></mrow><mtext>A</mtext><mo stretchy="false">)</mo><mo>=</mo><mtext>I</mtext><mo>+</mo><mrow><mi>Δ</mi></mrow><mtext>A</mtext><mo>+</mo><mfrac><mrow><msup><mrow><mo stretchy="false">(</mo><mrow><mi>Δ</mi></mrow><mtext>A</mtext><mo stretchy="false">)</mo></mrow><mrow><mtext>2</mtext></mrow></msup></mrow><mrow><mtext>2</mtext><mo>!</mo></mrow></mfrac><mo>+</mo><mfrac><mrow><msup><mrow><mo stretchy="false">(</mo><mrow><mi>Δ</mi></mrow><mtext>A</mtext><mo stretchy="false">)</mo></mrow><mrow><mtext>3</mtext></mrow></msup></mrow><mrow><mtext>3</mtext><mo>!</mo></mrow></mfrac><mo>+</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>+</mo><mfrac><mrow><msup><mrow><mo stretchy="false">(</mo><mrow><mi>Δ</mi></mrow><mtext>A</mtext><mo stretchy="false">)</mo></mrow><mrow><mtext>n</mtext></mrow></msup></mrow><mrow><mtext>n</mtext><mo>!</mo></mrow></mfrac></mrow></math></td>
<td class="label">(5)</td>
</tr></table>
<p>In Formula 4, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e019"><math id="M19" display="inline" overflow="linebreak"><mrow><mrow><mi>Δ</mi></mrow><mtext>B</mtext></mrow></math></span> is the product of B and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e020"><math id="M20" display="inline" overflow="linebreak"><mrow><mrow><mi>Δ</mi></mrow></mrow></math></span>, this formula is actually an approximation calculation that uses a first-order Taylor series to approximate the expansion <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e021"><math id="M21" display="inline" overflow="linebreak"><mrow><mover><mrow><mtext>B</mtext></mrow><mo accent="true">―</mo></mover></mrow></math></span>, which is finally obtained<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e022"><math id="M22" display="inline" overflow="linebreak"><mrow><mo> </mo><mtext>result</mtext><mo> </mo><mover><mrow><mtext>B</mtext></mrow><mo accent="true">―</mo></mover><mo>=</mo><mrow><mi>Δ</mi></mrow><mtext>B</mtext></mrow></math></span>.</p>
<p>After discretizing the parametric matrix, the discrete SSM can be formulated as the following cyclic representation:</p>
<table class="disp-formula p" id="pone.0330678.e023"><tr>
<td class="formula"><math id="M23" display="block" overflow="linebreak"><mrow><msub><mrow><mtext>h</mtext></mrow><mrow><mtext>k</mtext></mrow></msub><mo>=</mo><mover><mrow><mtext>A</mtext></mrow><mo accent="true">―</mo></mover><msub><mrow><mtext>h</mtext></mrow><mrow><mtext>k</mtext><mo>−</mo><mtext>1</mtext></mrow></msub><mo>+</mo><mover><mrow><mtext>B</mtext></mrow><mo accent="true">―</mo></mover><msub><mrow><mtext>x</mtext></mrow><mrow><mtext>k</mtext></mrow></msub></mrow></math></td>
<td class="label">(6)</td>
</tr></table>
<table class="disp-formula p" id="pone.0330678.e024"><tr>
<td class="formula"><math id="M24" display="block" overflow="linebreak"><mrow><msub><mrow><mtext>y</mtext></mrow><mrow><mtext>k</mtext></mrow></msub><mo>=</mo><mtext>C</mtext><msub><mrow><mtext>h</mtext></mrow><mrow><mtext>k</mtext></mrow></msub></mrow></math></td>
<td class="label">(7)</td>
</tr></table>
<p>Formulas 6 and 7 together define the discretized SSM, which can be used for dynamic systems in simulation and control theory, as well as for processing sequence data such as language, audio, and images. By expanding the state-space model into a recursive relationship, it can be processed in a computational framework similar to RNN, and training efficiency can be improved by GPU acceleration.</p>
<table class="disp-formula p" id="pone.0330678.e025"><tr>
<td class="formula"><math id="M25" display="block" overflow="linebreak"><mrow><mtext>y</mtext><mo>=</mo><mtext>x</mtext><mo>*</mo><mover><mrow><mtext>k</mtext></mrow><mo accent="true">―</mo></mover></mrow></math></td>
<td class="label">(8)</td>
</tr></table>
<p>In order to better adapt to the efficient parallel computing characteristics of GPU, Formula 8 further optimizes this recurrence relationship. The original recurrence relationship is expanded and transformed into the form of global convolution, where is the convolution kernel <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e026"><math id="M26" display="inline" overflow="linebreak"><mrow><mover><mrow><mtext>k</mtext></mrow><mo accent="true">―</mo></mover></mrow></math></span>, which is composed of a series of matrix products of discretized SSM, the specific form is as Formula 9:</p>
<table class="disp-formula p" id="pone.0330678.e027"><tr>
<td class="formula"><math id="M27" display="block" overflow="linebreak"><mrow><mover><mrow><mtext>k</mtext></mrow><mo accent="true">―</mo></mover><mo>=</mo><mo stretchy="false">(</mo><mtext>C</mtext><mover><mrow><mtext>B</mtext></mrow><mo accent="true">―</mo></mover><mo>,</mo><mtext>C</mtext><mover><mrow><mtext>A</mtext></mrow><mo accent="true">―</mo></mover><mover><mrow><mtext>B</mtext></mrow><mo accent="true">―</mo></mover><mtext>,</mtext><mo>.</mo><mo>.</mo><mo>.</mo><mtext>M</mtext><mo>,</mo><mtext>C</mtext><msup><mrow><mover><mrow><mtext>A</mtext></mrow><mo accent="true">―</mo></mover></mrow><mrow><mtext>L</mtext><mo>−</mo><mtext>1</mtext></mrow></msup><mover><mrow><mtext>B</mtext></mrow><mo accent="true">―</mo></mover><mo stretchy="false">)</mo></mrow></math></td>
<td class="label">(9)</td>
</tr></table>
<p>The conversion of Formula 9 not only improves the parallelism of the computation, but also enables the GPU to make more efficient use of its powerful computing resources when processing large-scale data. In this way, discretizing SSM significantly improves the algorithm’s speed, providing a solid foundation for processing certain tasks of discretizing signal data.</p>
<p>In addition to the limitation of linear problems, SSM also has the assumption of linear time invariance (LTI). This means that the model parameters remain constant over each time step and do not have the property of changing over time. This assumption makes it impossible for SSM to update parameters in time when processing data with time-varying dynamic behavior, thus limiting the expressiveness of the model.</p>
<p>Selective SSM (S6) is a new type of system state model, which breaks the constraints of LTI by parameterizing parameter <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e028"><math id="M28" display="inline" overflow="linebreak"><mrow><mo stretchy="false">(</mo><mrow><mi>Δ</mi></mrow><mo>,</mo><mtext>B</mtext><mo>,</mo><mtext>C</mtext><mo stretchy="false">)</mo></mrow></math></span> as a function of input x, so that SSM can obtain more powerful selection ability and can focus on important content while ignoring unimportant information. Based on the core structure of S6, the researchers propose the Mamba framework, which is a simplified neural network architecture that includes linear layers, convolutional layers, residual connections, nonlinear transformations and, most importantly, the S6 kernel. In order to ensure the efficient implementation of Mamba, the researchers also propose an optimization strategy for the hardware, so that Mamba can dynamically adjust parameters according to different inputs, and better process information.</p>
<p>In the process of in-depth study on the HSI processing field combined with Mamba theory, researchers have carried out a variety of improvements and optimization measures to the Mamba framework. Based on the theoretical basis of Mamba, He et al. proposed a 3D-Spectral-Spatial Mamba (3DSS-Mamba) framework [<a href="#pone.0330678.ref024" class="usa-link" aria-describedby="pone.0330678.ref024">24</a>]. 3DSS-Mamba focuses on the extraction of spectrum-spatial information in three-dimensional space. The framework transforms the HSI cube into a set of 3D Spectral-Spatial Selective Scanning (3DSS) by designing a spectral-spatial label generation (SSTG) module, and introduces a 3D-spectral Spatial Selective Scanning (3DSS) mechanism. This mechanism enables pixel-wise selective scanning of 3D hyperspectral markers in spectral and spatial dimensions to overcome the limitations of traditional Mamba in dealing with high-dimensional scenes. In addition, He et al. constructed 5 scanning paths to study the influence of dimensional priority, and combined the 3DSS scanning mechanism with traditional mapping operations to form a 3D spectrum-space Mamba block (3DMB), thus realizing the extraction of global spectrum-space semantic representation and improving computational efficiency.</p>
<p><a href="#pone.0330678.g002" class="usa-link">Fig 2</a> shows the basic process framework of 3DSS-Mamba. 3DSS-Mamba firstly reduces the dimensionality of the input HSI data through principal component analysis (PCA) to extract the key spectral information, and then converts the processed data into a set of 3D spectral spatial labels through the Spectral-Spatial Token Generation (SSTG) module. These tags are then input into 3D-Spectral Spatial Mamba blocks (3DMB). Within each 3DMB block, specific pooling and classification operations are performed for further feature extraction and classification prediction of the tags. Finally, the output of all 3DMB blocks is summarized. The final HSI classification result is obtained through the pooling layer and classifier, and the whole process effectively combines spectral and spatial information to achieve efficient HSI classification. As an advanced HSI classifier, 3DSS-Mamba reflects the trend of sequential processing in HSI classification. Researchers usually treat the spectral dimension as a potential continuous sequence for processing. This trend demonstrates that the spectral bands of HSI have long sequence characteristics similar to time series.</p>
<figure class="fig xbox font-sm" id="pone.0330678.g002"><h4 class="obj_head">Fig 2. Architecture of 3DSS-Mamba framework.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370145_pone.0330678.g002.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b8dc/12370145/70bbfbcb1fd8/pone.0330678.g002.jpg" loading="lazy" height="633" width="716" alt="Fig 2"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330678.g002/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p>According to this improved method, it can be seen that the trend and direction of the improvement of Mamba by researchers mainly focus on the deep fusion of spatial and spectral information to improve the accuracy of HSI classification, and pay attention to the improvement of the computational efficiency of variant models to ensure that the performance is enhanced without sacrificing the computing speed [<a href="#pone.0330678.ref025" class="usa-link" aria-describedby="pone.0330678.ref025">25</a>]. These improvements also include the innovation of the model structure to better capture the local and global features of the image, enhance the robustness of the model, and enable it to adapt to different data variations [<a href="#pone.0330678.ref026" class="usa-link" aria-describedby="pone.0330678.ref026">26</a>]. In addition, researchers tend to optimize the process of feature extraction and representation learning through more efficient feature coding to enhance model interpretability [<a href="#pone.0330678.ref027" class="usa-link" aria-describedby="pone.0330678.ref027">27</a>]. These improved strategies further promote the performance of the model in practical application, bring a new research perspective and methodology to the HSI processing field, and also provide a wealth of inspiration and reference for the subsequent research work of this paper. Based on the theoretical foundation of Mamba model in HSI field, we construct a new variant model EchoMamba. In the following sections, we will introduce this model in detail.</p></section><section id="sec005"><h3 class="pmc_sec_title">EchoMamba: preliminaries</h3>
<p>In order to further improve Mamba’s performance in processing HSI data, we deeply optimize and innovate its processing techniques in spatial dimension and spectral dimension on the basis of inheriting the traditional Mamba theory. This improvement aims to comprehensively improve the application effect of Mamba in the field of HSI analysis.</p>
<p>For the spatial dimension of HSI data, Since Mamba itself is more suitable for processing continuous data types, if only a single Mamba is used to process the spatial dimensions of HSI, it is necessary to first mark the positions of each data in the spatial dimensions of HSI, and then flatten the overall three-dimensional dimension to treat it as data of a continuous dimension. Each position (x, y) that was previously marked is processed in turn by Mamba.</p>
<table class="disp-formula p" id="pone.0330678.e029"><tr>
<td class="formula"><math id="M29" display="block" overflow="linebreak"><mrow><msub><mrow><mtext>h</mtext></mrow><mrow><mtext>x</mtext><mo>,</mo><mtext>y</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>=</mo><mtext>A</mtext><msub><mrow><mtext>h</mtext></mrow><mrow><mtext>x</mtext><mo>,</mo><mtext>y</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>+</mo><mtext>Bu</mtext><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>+</mo><mi>ω</mi><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></td>
<td class="label">(10)</td>
</tr></table>
<table class="disp-formula p" id="pone.0330678.e030"><tr>
<td class="formula"><math id="M30" display="block" overflow="linebreak"><mrow><msub><mrow><mtext>y</mtext></mrow><mrow><mtext>x</mtext><mo>,</mo><mtext>y</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>=</mo><mtext>C</mtext><msub><mrow><mtext>h</mtext></mrow><mrow><mtext>x</mtext><mo>,</mo><mtext>y</mtext></mrow></msub><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>+</mo><mi>D</mi><mi>u</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mi>ω</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></math></td>
<td class="label">(11)</td>
</tr></table>
<p>Formula 10,11 is Mamba’s improved process for HSI spatial dimensions. In the state-space model, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e031"><math id="M31" display="inline" overflow="linebreak"><mrow><msub><mrow><mtext>h</mtext></mrow><mrow><mtext>x</mtext><mo>,</mo><mtext>y</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></span> represents the hidden state at the spatial position (x,y) at the time step t. The state is updated by combining the state transition matrix A with the state at the previous moment and the control input matrix B with the external input <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e032"><math id="M32" display="inline" overflow="linebreak"><mrow><mtext>u</mtext><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></span>, and adding process noise <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e033"><math id="M33" display="inline" overflow="linebreak"><mrow><mi>ω</mi></mrow></math></span>(t). <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e034"><math id="M34" display="inline" overflow="linebreak"><mrow><msub><mrow><mtext>y</mtext></mrow><mrow><mtext>x</mtext><mo>,</mo><mtext>y</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></span> represents the observed data position (x,y) at the time step <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e035"><math id="M35" display="inline" overflow="linebreak"><mrow><mtext>t</mtext></mrow></math></span>, which is associated with the hidden state and external input through the observation matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e036"><math id="M36" display="inline" overflow="linebreak"><mrow><mtext>C</mtext></mrow></math></span> and the direct transfer matrix <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e037"><math id="M37" display="inline" overflow="linebreak"><mrow><mtext>D</mtext></mrow></math></span>, and is affected by the observation noise <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e038"><math id="M38" display="inline" overflow="linebreak"><mrow><mi>ω</mi></mrow></math></span>(t). For the spatial features of the global image, Mamba’s processing process is shown in Formula 12,13.</p>
<table class="disp-formula p" id="pone.0330678.e039"><tr>
<td class="formula"><math id="M39" display="block" overflow="linebreak"><mrow><msub><mrow><mtext>H</mtext></mrow><mrow><mtext>x</mtext><mo>,</mo><mtext>y</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>=</mo><mtext>A</mtext><msub><mrow><mtext>H</mtext></mrow><mrow><mtext>x</mtext><mo>,</mo><mtext>y</mtext></mrow></msub><mo stretchy="false">(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mo>+</mo><mi>B</mi><mi>U</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>+</mo><mi>ω</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></math></td>
<td class="label">(12)</td>
</tr></table>
<table class="disp-formula p" id="pone.0330678.e040"><tr>
<td class="formula"><math id="M40" display="block" overflow="linebreak"><mrow><msub><mrow><mtext>Y</mtext></mrow><mrow><mtext>x</mtext><mo>,</mo><mtext>y</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>=</mo><mtext>C</mtext><msub><mrow><mtext>H</mtext></mrow><mrow><mtext>x</mtext><mo>,</mo><mtext>y</mtext></mrow></msub><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>+</mo><mi>D</mi><mi>U</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>+</mo><mi>ω</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow></math></td>
<td class="label">(13)</td>
</tr></table>
<p>Where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e041"><math id="M41" display="inline" overflow="linebreak"><mrow><msub><mrow><mtext>H</mtext></mrow><mrow><mtext>x</mtext><mo>,</mo><mtext>y</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e042"><math id="M42" display="inline" overflow="linebreak"><mrow><msub><mrow><mtext>Y</mtext></mrow><mrow><mtext>x</mtext><mo>,</mo><mtext>y</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></span> are respectively the potential states and outputs of all pixel spatial features in the time step t.</p>
<p>For the spectral dimension, we treat the multiple bands of HSI pixels as a continuous time series. Based on the previous theoretical basis, we improve it and construct a formula to capture the long-term dependence on the spectral dimension.</p>
<table class="disp-formula p" id="pone.0330678.e043"><tr>
<td class="formula"><math id="M43" display="block" overflow="linebreak"><mrow><msub><mrow><mtext>h</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>=</mo><mtext>A</mtext><msub><mrow><mtext>h</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo>−</mo><mtext>1</mtext><mo stretchy="false">)</mo><mo>+</mo><mtext>B</mtext><msub><mrow><mtext>x</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></td>
<td class="label">(14)</td>
</tr></table>
<table class="disp-formula p" id="pone.0330678.e044"><tr>
<td class="formula"><math id="M44" display="block" overflow="linebreak"><mrow><msub><mrow><mtext>y</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>=</mo><mtext>C</mtext><msub><mrow><mtext>h</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>+</mo><mtext>D</mtext><msub><mrow><mtext>x</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></td>
<td class="label">(15)</td>
</tr></table>
<p>Formula 14 describes the recurrence process of the potential state of the spectrum. At time step t, the potential state <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e045"><math id="M45" display="inline" overflow="linebreak"><mrow><msub><mrow><mtext>h</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></span> of spectral band b is calculated from the potential state of the previous time step through the A and combined with the input data <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e046"><math id="M46" display="inline" overflow="linebreak"><mrow><msub><mrow><mtext>x</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></span> transformed by the B.In Formula 15, we transform the potential state through C, and introduce D to directly influence the output observation of spectral band b under time step t. Finally, the two results are added together to get the final output prediction value <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e047"><math id="M47" display="inline" overflow="linebreak"><mrow><msub><mrow><mtext>y</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></span>.</p>
<p>In order to apply the Mamba layer to all spectral dimensions of HSI, we apply the above recurrence relationship to each pixel of the image (i,j) on the spectral band.</p>
<table class="disp-formula p" id="pone.0330678.e048"><tr>
<td class="formula"><math id="M48" display="block" overflow="linebreak"><mrow><msub><mrow><mtext>h</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>i</mtext><mo>,</mo><mtext>j</mtext><mo>,</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>=</mo><mtext>A</mtext><msub><mrow><mtext>h</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>i</mtext><mo>,</mo><mtext>j</mtext><mo>,</mo><mtext>t</mtext><mo>−</mo><mtext>1</mtext><mo stretchy="false">)</mo><mo>+</mo><mtext>B</mtext><msub><mrow><mtext>x</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>i</mtext><mo>,</mo><mtext>j</mtext><mo>,</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></td>
<td class="label">(16)</td>
</tr></table>
<table class="disp-formula p" id="pone.0330678.e049"><tr>
<td class="formula"><math id="M49" display="block" overflow="linebreak"><mrow><msub><mrow><mtext>y</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>i</mtext><mo>,</mo><mtext>j</mtext><mo>,</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>=</mo><mtext>C</mtext><msub><mrow><mtext>h</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>i</mtext><mo>,</mo><mtext>j</mtext><mo>,</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>+</mo><mtext>D</mtext><msub><mrow><mtext>x</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>i</mtext><mo>,</mo><mtext>j</mtext><mo>,</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></td>
<td class="label">(17)</td>
</tr></table>
<p>For the entire image, this process can then be expressed as:</p>
<table class="disp-formula p" id="pone.0330678.e050"><tr>
<td class="formula"><math id="M50" display="block" overflow="linebreak"><mrow><msub><mrow><mtext>H</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>=</mo><mtext>A</mtext><msub><mrow><mtext>H</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo>−</mo><mtext>1</mtext><mo stretchy="false">)</mo><mo>+</mo><mtext>B</mtext><msub><mrow><mtext>X</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></td>
<td class="label">(18)</td>
</tr></table>
<table class="disp-formula p" id="pone.0330678.e051"><tr>
<td class="formula"><math id="M51" display="block" overflow="linebreak"><mrow><msub><mrow><mtext>Y</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>=</mo><mtext>C</mtext><msub><mrow><mtext>H</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>+</mo><mtext>D</mtext><msub><mrow><mtext>X</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></td>
<td class="label">(19)</td>
</tr></table>
<p>Where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e052"><math id="M52" display="inline" overflow="linebreak"><mrow><msub><mrow><mtext>H</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e053"><math id="M53" display="inline" overflow="linebreak"><mrow><msub><mrow><mtext>Y</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo></mrow></math></span> are respectively the potential states and outputs of spectral features of all pixels in the time step <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330678.e054"><math id="M54" display="inline" overflow="linebreak"><mrow><mtext>t</mtext></mrow></math></span>.</p>
<table class="disp-formula p" id="pone.0330678.e055"><tr>
<td class="formula"><math id="M55" display="block" overflow="linebreak"><mrow><mtext>F</mtext><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>=</mo><mtext>concrete</mtext><mo stretchy="false">(</mo><msub><mrow><mtext>Y</mtext></mrow><mrow><mtext>x</mtext><mo>,</mo><mtext>y</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo>,</mo><msub><mrow><mtext>Y</mtext></mrow><mrow><mtext>b</mtext></mrow></msub><mo stretchy="false">(</mo><mtext>t</mtext><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></math></td>
<td class="label">(20)</td>
</tr></table>
<p>After using Mamba to process the spatial and spectral dimensions of HSI respectively, as shown in Formula 20, the features of these two dimensions are integrated and analyzed, and finally the complete processing process of HSI data is realized by Mamba.</p>
<p>In view of some limitations of Mamba model in processing HSI, especially in the face of poor data quality, its performance may be affected. We decided to optimize the model and improve its performance by combining other advanced deep learning neural network layers with the Mamba model. The core idea of this strategy is to combine the strengths of different network layers to form complementary advantages, so as to enhance the processing ability of the model for HSI data.</p>
<p>In the process of this exploration, Our goal is to further expand the application range of Mamba model in the HSI processing field and improve its performance in practical applications through this innovative fusion strategy on the basis of retaining the original advantages of Mamba model.</p>
<p>RNN is a deep learning model designed specifically for processing sequence data, and its core advantage is its ability to capture time series features in the data [<a href="#pone.0330678.ref028" class="usa-link" aria-describedby="pone.0330678.ref028">28</a>]. By introducing a cyclic structure, this network forms a unique “memory” mechanism, which enables the network to not only consider the current input information when processing sequence data, but also remember the previous information. This property gives RNNS a significant advantage when dealing with scenarios such as text, speech, time series data, etc.</p>
<p>Although RNN provide a powerful framework for processing sequence data, this architecture has encountered many limitations in some practical applications. For example, in the process of processing long sequence data, it is difficult for RNN to learn the long distance dependency during training, because in the process of back propagation, the gradient tends to decrease exponentially with the increase of time step, resulting in the network failing to capture the information at a long distance in the sequence and eventually causing the problem of gradient disappearance [<a href="#pone.0330678.ref029" class="usa-link" aria-describedby="pone.0330678.ref029">29</a>]. In addition, in contrast to the disappearance of gradient, the gradient of RNN will become very large when the model learning rate is set too high, the network depth is too deep and so on, which makes the network weight need to be updated on a large scale, and finally leads to the entire learning process of the model is extremely unstable.</p>
<p>A Long Short-Term Memory (LSTM) is a variant of an RNN in deep learning that is designed to solve the problems of gradient disappearance and gradient explosion that standard RNNS encounter when processing long sequence data [<a href="#pone.0330678.ref030" class="usa-link" aria-describedby="pone.0330678.ref030">30</a>]. At the heart of LSTM is its unique memory unit, which is capable of transmitting state information over a long period of time in the network, a property that is carefully regulated through three gate structures: forget gates, input gates, and output gates.the forget gate determines what information should be discarded from the memory unit, a process that prevents the accumulation of irrelevant information; The input gate is responsible for updating the state of the memory unit, by combining the old state and the new input information to decide what data needs to be stored; Finally, the output gate controls how the contents of the memory unit affect the next hidden state and output, ensuring that relevant information is passed on to the next layer of the network in a timely manner. This structure makes LSTM excellent when dealing with sequence data with long distance dependencies, such as time series analysis, language models, speech recognition and other fields.</p>
<p>LSTM excels at mining deep dependencies in time series data with its superior ability. Although this may seem to have no direct relation to the processing of hyperspectral image data, previous studies have shown that the spectral sequence of hyperspectral image data contains rich and complex internal connections, which makes hyperspectral image data, to some extent, exhibit a high similarity to time series data. In summary, we try to combine LSTM and Mamba model on the basis of a series of data preprocessing strategies, and construct a new variant model EchoMamba.</p>
<p>The core feature of HSI data lies in the rich spectral dimension information contained in each pixel. Although there are spatial correlations among HSI pixels, and this spatial information is equally important for tasks such as scene understanding, image segmentation and object detection, this characteristic is not the most distinctive advantage of HSI. Therefore, in the process of using EchoMamba to process HSI data, we intentionally downplay the model’s dependence on the spatial dimension of the image, and instead give full play to the advantages of LSTM and Mamba, regard the spectral sequence as a special time series, and deeply explore the rich information of the spectral dimension. To enable more accurate interpretation and analysis of HSI data by the model. In next section, we will take a more detailed and in-depth look at the architecture of EchoMamba.</p></section><section id="sec006"><h3 class="pmc_sec_title">EchoMamba: strategy and structure</h3>
<p>EchoMamba is an innovative variant that improves on the traditional Mamba model, building an entirely new model framework. As shown in <a href="#pone.0330678.g003" class="usa-link">Fig 3</a>, we was structurally designed to improve the performance and efficiency of the model. The framework mainly includes two parts: the data preprocessing strategy Random Forest Smote(RFMS) and the variant model Long Short-Term Memory Mamba S6(LSTMS6).</p>
<figure class="fig xbox font-sm" id="pone.0330678.g003"><h4 class="obj_head">Fig 3. Architecture of the EchoMamba framework.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370145_pone.0330678.g003.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b8dc/12370145/df45a52cab4b/pone.0330678.g003.jpg" loading="lazy" height="417" width="750" alt="Fig 3"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330678.g003/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p>Next, this article will delve deeper into these two core components of EchoMamba. We will elaborate on their functions, features, and performance in practical applications one by one, enabling comprehensive understanding of component functionalities and their important role in the overall architecture.</p></section><section id="sec007"><h3 class="pmc_sec_title">EchoMamba strategy of data preprocessing</h3>
<p>In spatial dimension, each pixel in the HSI represents a smaller area of the actual ground, which allows researchers to observe more detailed surface features in the image; In the spectral dimension, HSI usually contains tens to hundreds of continuous bands, the band width is usually between a few nanometers to tens of nanometers, covering the spectral range from visible light to near-infrared and even short-wave infrared, so that HSI can capture the subtle differences between ground objects in the spectral dimension. To sum up, HSI has extremely high resolution in both spatial dimension and spectral dimension.</p>
<p>However, although the unique data characteristics of HSI provide researchers with rich information, the complex dimension and huge amount of data also make its structure extremely complex. Therefore, RFMS adopts the techniques of feature selection and oversampling to process the different data features of HSI respectively.</p>
<p>While maintaining the spatial dimension of the original HSI data, we use random forest (RF) as our main method of feature extraction to extract the spectral dimension of the data. RF is an ensemble tree-based machine learning algorithm, which is often used for classification and regression tasks [<a href="#pone.0330678.ref031" class="usa-link" aria-describedby="pone.0330678.ref031">31</a>]. RF shows excellent performance in processing spectral dimension feature extraction of HSI.</p>
<p>The uneven distribution of samples is a common and challenging problem in HSI data analysis. There may be significant differences in the number of samples of different types of ground objects, and such unbalanced data distribution will adversely affect the training and performance of the model [<a href="#pone.0330678.ref032" class="usa-link" aria-describedby="pone.0330678.ref032">32</a>]. The evaluation index of the model may be too optimistic due to the domination of the majority class, and can not truly reflect its performance on the minority class, resulting in distortion of accuracy. In addition, the model relies too much on the characteristics of the majority class, which may lead to the lack of generalization ability in the face of minority class samples.</p>
<p>Synthetic Minority Oversampling Technique(SMOTE) has been applied to solve the problem of uneven sample distribution in HSI data effectively. The core idea of this algorithm is to create a batch of new synthetic samples with high authenticity by accurate interpolation between a few class samples of HSI data [<a href="#pone.0330678.ref033" class="usa-link" aria-describedby="pone.0330678.ref033">33</a>]. The aim is to significantly increase the number of samples in a few classes to balance the distribution of samples between the various classes and to avoid bias of the model against some classes during training.</p>
<p>Through the comprehensive application of a series of traditional methods, RFMS significantly improves the generalization ability of the model in HSI, further improves the accuracy of the prediction, and provides strong support for the effective analysis and application of HSI.</p></section><section id="sec008"><h3 class="pmc_sec_title">EchoMamba structure of LSTM and Mamba</h3>
<p>LSTMS6 is the core architecture of the EchoMamba system, and its design is inspired by the theoretical foundation discussed earlier. On the basis of fully retaining the original structural advantages of the LSTM neural network layer and the S6 model, We cleverly spliced the two modules together, specifically, LSTM as a model block directly spliced with the S6 model. The S6 module, as the global context encoder of the spectral sequence, can extract the key spectral features and suppress the noise in the whole band range through its selective state space dynamic optimization mechanism. On this basis, LSTM layer, as a local temporal decoder, conducts a secondary modeling of the hidden state of S6 output through the coordination of the gate control unit: The forgetting gate dynamically adjusts the memory intensity of global features according to the current context, effectively eliminating the residual influence of environmental noise such as atmospheric interference; The input gate enhances the local temporal pattern with class discrimination through nonlinear transformation, thus forming a “global-local” two-granularity feature representation system. This cascading structure not only inherits the linear computational complexity advantage of S6 model for long sequence modeling, but also solves the limitation of traditional state space model in local nonlinear dynamic modeling through the temporal memory characteristic of LSTM. LSTMS6 specifically consists of three main components: the LSTM layer, the linear transformation layer, and the Mamba layer. The specific parameters and connection methods of each layer are shown in <a href="#pone.0330678.g004" class="usa-link">Fig 4</a>. Algorithm 1 illustrates the specific implementation process of LSTMS6.</p>
<figure class="fig xbox font-sm" id="pone.0330678.g004"><h4 class="obj_head">Fig 4. Details of the connection of the LSTM component.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370145_pone.0330678.g004.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b8dc/12370145/0a24c646f2db/pone.0330678.g004.jpg" loading="lazy" height="466" width="789" alt="Fig 4"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330678.g004/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p>Algorithm 1: LSTMS6</p>
<p>1. <strong>Input</strong>: The number of samples in a batch: <strong>batch_size</strong>, The time step length of the input sequence: <strong>seq_length</strong>, Dimension of input features: <strong>feature_dim</strong>.</p>
<p>2. <strong>Output</strong>: <strong>batch_size</strong>, Dimension of output features: <strong>output_dim</strong>.</p>
<p>3. <strong>For</strong> each epoch ∈(1, 200), <strong>do</strong></p>
<p>4. <strong>inputs</strong>(batch_size, feature_dim), <strong>labels</strong>(batch_size)←<strong>train_loader</strong></p>
<p>5. <strong>inputs</strong>(batch_size, 1, feature_dim)←<strong>inputs</strong>.unsqueeze(1)</p>
<p>6. # Forward Propagation of LSTM Layer</p>
<p>7. <strong>outputs_lstm</strong>, (hn, cn) ← <strong>LSTM</strong>(inputs, (h0, c0))</p>
<p>8. # Linear Transformation for Dimension Adjustment</p>
<p>9. <strong>outputs_linear</strong> ← <strong>Linear</strong>(outputs_lstm)</p>
<p>10. # Mamba Layer Forward Propagation</p>
<p>11. <strong>outputs_mamba</strong> ← <strong>Mamba</strong>(outputs_linear)</p>
<p>12. <strong>outputs</strong> ← <strong>outputs_mamba.squeeze</strong>(1)</p>
<p>13. # Calculate Loss</p>
<p>14. <strong>loss</strong> ← <strong>CrossEntropyLoss</strong>(outputs, labels)</p>
<p>15. # Backpropagation (Gradient Calculation)</p>
<p>16. <strong>d_loss</strong> ← <strong>loss</strong>.backward()</p>
<p>17. # Mamba Layer Backpropagation</p>
<p><strong>18.</strong> ∇<strong>outputs_mamba</strong> ← <strong>gradients_from_loss</strong></p>
<p>19. # Linear Layer Backpropagation</p>
<p>20. ∇<strong>outputs_linear</strong> ← <strong>Mamba</strong>.backward(∇<strong>outputs_mamba</strong>)</p>
<p>21. # Backpropagation in LSTM Layer</p>
<p>22. ∇<strong>outputs_lstm</strong> ← <strong>Linear</strong>.backward(∇<strong>outputs_linear</strong>)</p>
<p>23. ∇<strong>inputs</strong>, (∇hn, ∇cn) ← <strong>LSTM</strong>.backward(∇<strong>outputs_lstm</strong>, (hn, cn))</p>
<p>24. # Parameter Update</p>
<p>25. <strong>optimizer</strong>.step()</p>
<p> - <strong>LSTM weights</strong> (W_ii, W_if, W_ig, W_io)</p>
<p> - <strong>LSTM bias</strong> (b_i, b_f, b_g, b_o)</p>
<p> - <strong>Linear layer weights</strong> (W_linear)</p>
<p> - <strong>Linear layer bias</strong> (b_linear)</p>
<p> - <strong>Mamba internal parameters</strong></p>
<p>However, in this fusion process, how to establish the hierarchical relationship between LSTM and Mamba has become a big challenge for us.</p>
<p>In order to solve this problem, we have carried out in-depth research and exploration. Through observation, we find that placing LSTM in front of S6 model can take advantage of LSTM’s advantages in processing abstract features, so that it can learn on higher-level features extracted and transformed by S6, which not only improves the level of time series understanding, but also optimizes the information flow, thus reducing the number of parameters in LSTM layer and improving the computational efficiency. At the same time, this structure helps to reduce the gradient disappearance problem, and enables LSTM to more directly propagate the prediction error to the S6 layer, which helps the S6 layer to better adjust the feature extraction strategy. In addition, for the domain-specific adaptability of HSI, LSTM can perform time series analysis more efficiently before S6, while the modular design also makes the model more flexible and easy to adjust according to different data sets and task requirements. As a result, the LSTM could theoretically achieve better results in front of the S6 layer. On the premise of ensuring the full play of the two characteristics, we designed a new structural layout, so that LSTM and S6 can coordinate and complement each other.</p>
<p>LSTMS6 significantly improves the performance of processing HSI time series relationship, feature extraction, computational efficiency and generalization ability through its innovative integration of structures. <a href="#pone.0330678.t001" class="usa-link">Table 1</a> illustrates the theoretical differences between EchoMamba and the various Mamba variants mentioned earlier in terms of architecture and functionality. The model utilizes the unique gating mechanism of the LSTM layer to effectively capture the long-term dependency relationship in image data and deeply understand the timing features. At the same time, combined with Mamba model’s expertise in feature extraction and transformation, it provides high-quality learning materials for the LSTM layer. So that the model can more effectively extract key features and perform efficient data transformation when dealing with complex HSI. In addition, by optimizing the hierarchical relationship, the LSTMS6 model effectively alleviates the problem of gradient disappearance, improves training efficiency and model performance, and thus shows higher accuracy in identifying and classifying HSI. The structural innovation also enables more efficient use of computing resources, reduced training time, and demonstrated advantages during deployment and application. At the same time, the model shows stronger generalization ability when facing HSI with different scenarios and conditions, achieving end-to-end learning from raw data to final prediction, simplifying the data processing process and improving the overall learning efficiency.</p>
<section class="tw xbox font-sm" id="pone.0330678.t001"><h4 class="obj_head">Table 1. Theoretical comparison of the Mamba variant model.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">Framework</th>
<th align="left" rowspan="1" colspan="1">Function</th>
<th align="left" rowspan="1" colspan="1">Advantage</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">CNN+Mamba</td>
<td align="left" rowspan="1" colspan="1">Spatial-spectral separation modeling</td>
<td align="left" rowspan="1" colspan="1">Strong ability to capture spatial features</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">GCN+Mamba</td>
<td align="left" rowspan="1" colspan="1">Non-Euclidean relationship modeling</td>
<td align="left" rowspan="1" colspan="1">Skilled in long-distance spatial dependency and non-local feature interaction</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Transformer+Mamba</td>
<td align="left" rowspan="1" colspan="1">Attention-enhanced sequence modeling</td>
<td align="left" rowspan="1" colspan="1">Stronger theoretical modeling ability</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">3DSS-Mamba</td>
<td align="left" rowspan="1" colspan="1">Empty spectrum combined three-dimensional modeling</td>
<td align="left" rowspan="1" colspan="1">Reasonable utilization of spatial and spectral information</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">EchoMamba</td>
<td align="left" rowspan="1" colspan="1">Dual exploration of spectral dimension depth</td>
<td align="left" rowspan="1" colspan="1">Comprehensive and detailed extraction of spectral characteristics</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0330678.t001/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="t001fn001"><p>EchoMamba not only innovates in data processing and model structure design, but also provides a new way of thinking for HSI analysis and processing. In the next section, we will use the core component of EchoMamba, namely LSTMS6, to compare the performance of several other combined models, so as to prove the feasibility of this model.</p></div></div></section></section></section><section id="sec009"><h2 class="pmc_sec_title">Results</h2>
<section id="sec010"><h3 class="pmc_sec_title">Dataset</h3>
<p>Six internationally recognized HSI datasets were selected for model performance evaluation: Augsburg, Salinas, Pavia Centre scene, Pavia University, Indian Pines, Houston 2013. The following are detailed descriptions of each dataset:</p>
<p>Augsburg Dataset: This dataset covers part of the city of Augsburg, Germany, and was collected using a hyperspectral imaging spectrometer. It consists of 180 wavebands with image sizes of 332 * 485 pixels, divided into seven feature categories. The spatial resolution is 1 meter, which allows the features to be displayed in fine detail. In the entire data set, there are 161020 pixels, of which 78294 are ground objects and the rest are background pixels.</p>
<p>Salinas Dataset: This dataset originated in the Salinas Valley, California, USA, and was captured by the AVIRIS sensor. The dataset contains 224 bands with image sizes of 512 * 217 pixels divided into 16 feature categories. The spatial resolution is 3.7 meters, which ensures the identification and classification of the features. Of the 111104 pixels, 54129 are ground objects and the rest are background pixels.</p>
<p>Pavia Centre scene dataset: This dataset was taken over the city of Pavia, Italy, also by the AVIRIS sensor. The dataset consists of 102 wavebands with images of 1096 * 715 pixels grouped into nine feature categories. The spatial resolution is 1.3 meters, which provides high accuracy for the recognition of ground objects. There are 783640 pixels in the data set, of which 7456 are ground objects and the rest are background pixels.</p>
<p>Pavia University dataset: This dataset is part of the HSI acquired by the AVIRIS sensor in Pavia, Italy. It contains 103 spectral bands with an image size of 610 * 340 divided into nine different feature categories. The dataset has a spatial resolution of about 1.3 meters and a total of 207400 pixels, of which 42776 pixels are labeled as ground objects and the rest are background pixels.</p>
<p>Indian Pines Dataset: This dataset was acquired by an AVIRIS sensor in Indiana, USA, over the Indian Pines region. It contains 220 spectral bands with image sizes of 145 * 145 and covers 16 different feature categories. The spatial resolution is about 20 meters, and the entire dataset has a total of 21025 pixels, of which only 10249 pixels are in the feature category, and the rest are background pixels.</p>
<p>Houston 2013 dataset: It was acquired by ITRES CASI-1500 in and around the University of Houston campus. It contains 144 spectral bands, with an image size of 349 * 1905, grouped into 15 different feature categories. The data set has a spatial resolution of about 2.5 meters and a total of 664845 pixels, of which only 15029 pixels are labeled as ground objects and the rest are background pixels.</p>
<p><a href="#pone.0330678.t002" class="usa-link">Table 2</a> shows the category distribution and quantity of each data set.</p>
<section class="tw xbox font-sm" id="pone.0330678.t002"><h4 class="obj_head">Table 2. Specific data sets and categories.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">Class</th>
<th align="left" rowspan="1" colspan="1">Ausburg</th>
<th align="left" rowspan="1" colspan="1">Salinas</th>
<th align="left" rowspan="1" colspan="1">Pavia Centre scene</th>
<th align="left" rowspan="1" colspan="1">Pavia University</th>
<th align="left" rowspan="1" colspan="1">Indian Pines</th>
<th align="left" rowspan="1" colspan="1">Houston 2013</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">13507</td>
<td align="left" rowspan="1" colspan="1">2009</td>
<td align="left" rowspan="1" colspan="1">824</td>
<td align="left" rowspan="1" colspan="1">6631</td>
<td align="left" rowspan="1" colspan="1">46</td>
<td align="left" rowspan="1" colspan="1">1251</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">30329</td>
<td align="left" rowspan="1" colspan="1">3726</td>
<td align="left" rowspan="1" colspan="1">820</td>
<td align="left" rowspan="1" colspan="1">18649</td>
<td align="left" rowspan="1" colspan="1">1428</td>
<td align="left" rowspan="1" colspan="1">1254</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">3851</td>
<td align="left" rowspan="1" colspan="1">1976</td>
<td align="left" rowspan="1" colspan="1">816</td>
<td align="left" rowspan="1" colspan="1">2099</td>
<td align="left" rowspan="1" colspan="1">830</td>
<td align="left" rowspan="1" colspan="1">697</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4</td>
<td align="left" rowspan="1" colspan="1">26857</td>
<td align="left" rowspan="1" colspan="1">1394</td>
<td align="left" rowspan="1" colspan="1">808</td>
<td align="left" rowspan="1" colspan="1">3064</td>
<td align="left" rowspan="1" colspan="1">237</td>
<td align="left" rowspan="1" colspan="1">1244</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">575</td>
<td align="left" rowspan="1" colspan="1">2678</td>
<td align="left" rowspan="1" colspan="1">808</td>
<td align="left" rowspan="1" colspan="1">1345</td>
<td align="left" rowspan="1" colspan="1">483</td>
<td align="left" rowspan="1" colspan="1">1242</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">6</td>
<td align="left" rowspan="1" colspan="1">1645</td>
<td align="left" rowspan="1" colspan="1">3959</td>
<td align="left" rowspan="1" colspan="1">1260</td>
<td align="left" rowspan="1" colspan="1">5029</td>
<td align="left" rowspan="1" colspan="1">730</td>
<td align="left" rowspan="1" colspan="1">325</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">7</td>
<td align="left" rowspan="1" colspan="1">1530</td>
<td align="left" rowspan="1" colspan="1">3579</td>
<td align="left" rowspan="1" colspan="1">476</td>
<td align="left" rowspan="1" colspan="1">1330</td>
<td align="left" rowspan="1" colspan="1">28</td>
<td align="left" rowspan="1" colspan="1">1268</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">8</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">11271</td>
<td align="left" rowspan="1" colspan="1">824</td>
<td align="left" rowspan="1" colspan="1">3682</td>
<td align="left" rowspan="1" colspan="1">478</td>
<td align="left" rowspan="1" colspan="1">1244</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">9</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">6203</td>
<td align="left" rowspan="1" colspan="1">820</td>
<td align="left" rowspan="1" colspan="1">947</td>
<td align="left" rowspan="1" colspan="1">20</td>
<td align="left" rowspan="1" colspan="1">1252</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">10</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">3278</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">972</td>
<td align="left" rowspan="1" colspan="1">1227</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">11</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">1068</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">2455</td>
<td align="left" rowspan="1" colspan="1">1235</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">12</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">1927</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">593</td>
<td align="left" rowspan="1" colspan="1">1233</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">13</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">916</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">205</td>
<td align="left" rowspan="1" colspan="1">469</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">14</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">1070</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">1265</td>
<td align="left" rowspan="1" colspan="1">428</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">15</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">7268</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">386</td>
<td align="left" rowspan="1" colspan="1">660</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">16</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">1807</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">93</td>
<td align="left" rowspan="1" colspan="1"></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Total</td>
<td align="left" rowspan="1" colspan="1">78294</td>
<td align="left" rowspan="1" colspan="1">54129</td>
<td align="left" rowspan="1" colspan="1">7456</td>
<td align="left" rowspan="1" colspan="1">42776</td>
<td align="left" rowspan="1" colspan="1">10249</td>
<td align="left" rowspan="1" colspan="1">15029</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0330678.t002/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="sec011"><h3 class="pmc_sec_title">Basic experiment</h3>
<section id="sec012"><h4 class="pmc_sec_title">Implementation details.</h4>
<p>To facilitate reproducibility and fair comparison, all experiments were conducted using identical hardware and training configurations. The specific as detailed below:</p>
<ul class="list" style="list-style-type:none">
<li><p>Hardware Specifications</p></li>
<li><p>CPU: 11th Gen Intel® Core™ i7-11800H (8 cores, 16 threads @ 2.30 GHz)</p></li>
<li><p>GPU: NVIDIA GeForce RTX 3060 Laptop GPU (6GB GDDR6 VRAM)</p></li>
<li><p>RAM: 16GB DDR4 (2 × 8GB @ 3200MHz)</p></li>
<li><p>Storage: NVMe SSD (*employed to minimize I/O bottlenecks during data loading*)</p></li>
<li><p>Training Configuration</p></li>
<li><p>Batch size: 64</p></li>
<li><p>Epochs: 200</p></li>
<li><p>Optimizer: AdamW (learning rate = 0.001, weight decay = 1 × 10⁻⁴)</p></li>
<li><p>Details of EchoMamba’s model parameters</p></li>
<li><p>EchoMamba (LSTM+Mamba) Parameters: 201,561 (approximately 0.20 million)</p></li>
<li><p>EchoMamba Model File Size: 0.77 MB (FP32 precision)</p></li>
</ul>
<p>This standardized setup ensures that performance differences observed between the core EchoMamba model and the benchmark models (Mamba, CNN+Mamba, GCN+Mamba, Transformer, CNN+Transformer, GCN+Transformer, LSTM+Transformer) are attributable to their architectural differences rather than variations in training conditions or hardware utilization.</p></section></section><section id="sec013"><h3 class="pmc_sec_title">Validation set performance comparison</h3>
<p>Based on Mamba and Transformer infrastructures, we build two sets of models by integrating CNN、GCN and LSTM layers respectively. Including eight models: Mamba, CNN+Mamba, GCN+Mamba, LSTM+Mamba, Transformer, CNN+Transformer, GCN+Transformer, LSTM+Transformer. LSTM+Mamba is the core component LSTMS6 of the EchoMamba framework proposed by us. In order to ensure the consistency and reliability when applied to different models, the data sets are preprocessed by RSFM strategy before the model is used to process the data sets.</p>
<p>By combining CNN, GCN, and LSTM with Mamba and Transformer, respectively, the experimental design aims to systematically verify how different feature extraction paradigms such as local perception, graph structure modeling, and temporal memory complement or compete with the two types of core architectures (SSM and Attention).</p>
<p><a href="#pone.0330678.t003" class="usa-link">Table 3</a> provides a detailed comparison of the average performance of these two benchmark models across ten independent repeated experiments on the validation sets of six different hyperspectral image datasets. In order to analyze the performance of the model from as comprehensive a perspective as possible, while retaining the traditional performance indicators such as overall accuracy (OA), and Kappa coefficient (κ), we also introduced the key performance indicator of model training time, which is measured in min. Which defined as the time it took to train the model over 200 cycles. Through this comprehensive evaluation method, this paper aims to deeply analyze how the model can effectively reduce the training time while maintaining high classification performance when processing HSI data.</p>
<section class="tw xbox font-sm" id="pone.0330678.t003"><h4 class="obj_head">Table 3. Performance comparison of validationsets.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead>
<tr>
<th align="left" colspan="2" rowspan="3">DataSet</th>
<th align="left" colspan="8" rowspan="1">Model</th>
</tr>
<tr>
<th align="left" colspan="4" rowspan="1">Mamba benchmark model</th>
<th align="left" colspan="4" rowspan="1">Transformer benchmark model</th>
</tr>
<tr>
<th align="left" rowspan="1" colspan="1">Null</th>
<th align="left" rowspan="1" colspan="1">CNN</th>
<th align="left" rowspan="1" colspan="1">GCN</th>
<th align="left" rowspan="1" colspan="1">LSTM<br>(EchoMamba)</th>
<th align="left" rowspan="1" colspan="1">Null</th>
<th align="left" rowspan="1" colspan="1">CNN</th>
<th align="left" rowspan="1" colspan="1">GCN</th>
<th align="left" rowspan="1" colspan="1">LSTM</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="3" colspan="1">Ausburg</td>
<td align="left" rowspan="1" colspan="1">Train time(min)</td>
<td align="left" rowspan="1" colspan="1">0.6477</td>
<td align="left" rowspan="1" colspan="1">0.7276</td>
<td align="left" rowspan="1" colspan="1">0.9365</td>
<td align="left" rowspan="1" colspan="1">0.7768</td>
<td align="left" rowspan="1" colspan="1">10</td>
<td align="left" rowspan="1" colspan="1">11</td>
<td align="left" rowspan="1" colspan="1">9</td>
<td align="left" rowspan="1" colspan="1">12</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">OA</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.9945</td>
<td align="left" rowspan="1" colspan="1">0.9862</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.9823</td>
<td align="left" rowspan="1" colspan="1">0.9943</td>
<td align="left" rowspan="1" colspan="1">0.9341</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">κ</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.9911</td>
<td align="left" rowspan="1" colspan="1">0.9886</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.9744</td>
<td align="left" rowspan="1" colspan="1">0.9917</td>
<td align="left" rowspan="1" colspan="1">0.9134</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">Salinas</td>
<td align="left" rowspan="1" colspan="1">Train time(min)</td>
<td align="left" rowspan="1" colspan="1">88</td>
<td align="left" rowspan="1" colspan="1">96</td>
<td align="left" rowspan="1" colspan="1">77</td>
<td align="left" rowspan="1" colspan="1">99</td>
<td align="left" rowspan="1" colspan="1">1045</td>
<td align="left" rowspan="1" colspan="1">1112</td>
<td align="left" rowspan="1" colspan="1">803</td>
<td align="left" rowspan="1" colspan="1">1147</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">OA</td>
<td align="left" rowspan="1" colspan="1">0.9667</td>
<td align="left" rowspan="1" colspan="1">0.9432</td>
<td align="left" rowspan="1" colspan="1">0.9636</td>
<td align="left" rowspan="1" colspan="1">0.9799</td>
<td align="left" rowspan="1" colspan="1">0.9811</td>
<td align="left" rowspan="1" colspan="1">0.9803</td>
<td align="left" rowspan="1" colspan="1">0.9782</td>
<td align="left" rowspan="1" colspan="1">0.9795</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">κ</td>
<td align="left" rowspan="1" colspan="1">0.9676</td>
<td align="left" rowspan="1" colspan="1">0.9621</td>
<td align="left" rowspan="1" colspan="1">0.9601</td>
<td align="left" rowspan="1" colspan="1">0.9813</td>
<td align="left" rowspan="1" colspan="1">0.9823</td>
<td align="left" rowspan="1" colspan="1">0.9754</td>
<td align="left" rowspan="1" colspan="1">0.9732</td>
<td align="left" rowspan="1" colspan="1">0.9788</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">Pavia Centre scene</td>
<td align="left" rowspan="1" colspan="1">Train time(min)</td>
<td align="left" rowspan="1" colspan="1">195</td>
<td align="left" rowspan="1" colspan="1">220</td>
<td align="left" rowspan="1" colspan="1">224</td>
<td align="left" rowspan="1" colspan="1">226</td>
<td align="left" rowspan="1" colspan="1">3548</td>
<td align="left" rowspan="1" colspan="1">3741</td>
<td align="left" rowspan="1" colspan="1">3529</td>
<td align="left" rowspan="1" colspan="1">3892</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">OA</td>
<td align="left" rowspan="1" colspan="1">0.9244</td>
<td align="left" rowspan="1" colspan="1">0.9321</td>
<td align="left" rowspan="1" colspan="1">0.9280</td>
<td align="left" rowspan="1" colspan="1">0.9567</td>
<td align="left" rowspan="1" colspan="1">0.9423</td>
<td align="left" rowspan="1" colspan="1">0.9688</td>
<td align="left" rowspan="1" colspan="1">0.9732</td>
<td align="left" rowspan="1" colspan="1">0.9522</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">κ</td>
<td align="left" rowspan="1" colspan="1">0.8899</td>
<td align="left" rowspan="1" colspan="1">0.9071</td>
<td align="left" rowspan="1" colspan="1">0.8992</td>
<td align="left" rowspan="1" colspan="1">0.9367</td>
<td align="left" rowspan="1" colspan="1">0.9266</td>
<td align="left" rowspan="1" colspan="1">0.9602</td>
<td align="left" rowspan="1" colspan="1">0.9588</td>
<td align="left" rowspan="1" colspan="1">0.9332</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">Pavia University</td>
<td align="left" rowspan="1" colspan="1">Train time(min)</td>
<td align="left" rowspan="1" colspan="1">52</td>
<td align="left" rowspan="1" colspan="1">56</td>
<td align="left" rowspan="1" colspan="1">69</td>
<td align="left" rowspan="1" colspan="1">61</td>
<td align="left" rowspan="1" colspan="1">969</td>
<td align="left" rowspan="1" colspan="1">1041</td>
<td align="left" rowspan="1" colspan="1">777</td>
<td align="left" rowspan="1" colspan="1">1059</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">OA</td>
<td align="left" rowspan="1" colspan="1">0.9571</td>
<td align="left" rowspan="1" colspan="1">0.9622</td>
<td align="left" rowspan="1" colspan="1">0.9777</td>
<td align="left" rowspan="1" colspan="1">0.9978</td>
<td align="left" rowspan="1" colspan="1">0.9821</td>
<td align="left" rowspan="1" colspan="1">0.9911</td>
<td align="left" rowspan="1" colspan="1">0.9903</td>
<td align="left" rowspan="1" colspan="1">0.9869</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">κ</td>
<td align="left" rowspan="1" colspan="1">0.9431</td>
<td align="left" rowspan="1" colspan="1">0.9478</td>
<td align="left" rowspan="1" colspan="1">0.9732</td>
<td align="left" rowspan="1" colspan="1">0.9930</td>
<td align="left" rowspan="1" colspan="1">0.9822</td>
<td align="left" rowspan="1" colspan="1">0.9923</td>
<td align="left" rowspan="1" colspan="1">0.9929</td>
<td align="left" rowspan="1" colspan="1">0.9828</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">Indian pines</td>
<td align="left" rowspan="1" colspan="1">Train time(min)</td>
<td align="left" rowspan="1" colspan="1">12</td>
<td align="left" rowspan="1" colspan="1">15</td>
<td align="left" rowspan="1" colspan="1">16</td>
<td align="left" rowspan="1" colspan="1">15</td>
<td align="left" rowspan="1" colspan="1">218</td>
<td align="left" rowspan="1" colspan="1">227</td>
<td align="left" rowspan="1" colspan="1">245</td>
<td align="left" rowspan="1" colspan="1">231</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">OA</td>
<td align="left" rowspan="1" colspan="1">0.9786</td>
<td align="left" rowspan="1" colspan="1">0.9634</td>
<td align="left" rowspan="1" colspan="1">0.9870</td>
<td align="left" rowspan="1" colspan="1">0.9951</td>
<td align="left" rowspan="1" colspan="1">0.9973</td>
<td align="left" rowspan="1" colspan="1">0.9967</td>
<td align="left" rowspan="1" colspan="1">0.9922</td>
<td align="left" rowspan="1" colspan="1">0.9926</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">κ</td>
<td align="left" rowspan="1" colspan="1">0.9777</td>
<td align="left" rowspan="1" colspan="1">0.9621</td>
<td align="left" rowspan="1" colspan="1">0.9844</td>
<td align="left" rowspan="1" colspan="1">0.9931</td>
<td align="left" rowspan="1" colspan="1">0.9965</td>
<td align="left" rowspan="1" colspan="1">0.9943</td>
<td align="left" rowspan="1" colspan="1">0.9956</td>
<td align="left" rowspan="1" colspan="1">0.9942</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">Houston<br>2013</td>
<td align="left" rowspan="1" colspan="1">Train time(min)</td>
<td align="left" rowspan="1" colspan="1">6</td>
<td align="left" rowspan="1" colspan="1">6</td>
<td align="left" rowspan="1" colspan="1">10</td>
<td align="left" rowspan="1" colspan="1">7</td>
<td align="left" rowspan="1" colspan="1">56</td>
<td align="left" rowspan="1" colspan="1">105</td>
<td align="left" rowspan="1" colspan="1">98</td>
<td align="left" rowspan="1" colspan="1">106</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">OA</td>
<td align="left" rowspan="1" colspan="1">0.9822</td>
<td align="left" rowspan="1" colspan="1">0.9534</td>
<td align="left" rowspan="1" colspan="1">0.9889</td>
<td align="left" rowspan="1" colspan="1">0.9895</td>
<td align="left" rowspan="1" colspan="1">0.9913</td>
<td align="left" rowspan="1" colspan="1">0.9909</td>
<td align="left" rowspan="1" colspan="1">0.9959</td>
<td align="left" rowspan="1" colspan="1">0.9907</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">κ</td>
<td align="left" rowspan="1" colspan="1">0.9796</td>
<td align="left" rowspan="1" colspan="1">0.9488</td>
<td align="left" rowspan="1" colspan="1">0.9832</td>
<td align="left" rowspan="1" colspan="1">0.9877</td>
<td align="left" rowspan="1" colspan="1">0.9904</td>
<td align="left" rowspan="1" colspan="1">0.9889</td>
<td align="left" rowspan="1" colspan="1">0.9957</td>
<td align="left" rowspan="1" colspan="1">0.9901</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0330678.t003/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p>The Transformer benchmark model has shown extremely excellent performance on the three HSI data sets, and the OA is maintained at a high level. However, in terms of training time, the Transformer benchmark model generally takes a long time for data training, which requires a high time cost.</p>
<p>The Mamba benchmark model demonstrated excellent performance on six separate HSI datasets. In particular, on the Salinas dataset, all four Mamba benchmark models achieved an overall accuracy of at or near 100% on the validation set with very short training times. Compared with Mamba, CNN+Mamba achieved certain performance improvement in the processing of two datasets, Pavia Centre scene and Pavia University, but did not show obvious advantages in the other four datasets. GCN+Mamba has demonstrated superior performance compared to CNN+Mamba on datasets such as Pavia University, Indian Pines, Houston, etc. In some aspects, this model even surpasses the performance of EchoMamba. Although the six datasets used have some differences in data characteristics, from the performance analysis, compared with the other three Mamba benchmark models, the EchoMamba model has achieved improvements ranging from 0.01% to 4.99% in each performance metric with only slightly increased training time.</p>
<p>As can be seen from the Train time, with the same training period set, the time cost required by the Mamba benchmark model to train the data set is much smaller than that of the Transformer benchmark model. In addition, in the two indexes of OA and κ, Mamba benchmark model and Transformer benchmark model showed very similar performance on data set processing, and even showed better performance than Transformer benchmark model on some data sets. This result shows that compared with the Transformer benchmark model, the Mamba benchmark model can achieve very close performance while greatly improving the training efficiency.</p>
<p>Due to the comprehensive advantages of the Mamba benchmark model compared to the Transformer benchmark model, we will not consider using the Transformer benchmark model during the in-depth comparison of the model’s experimental performance on the test set of the dataset in the following section. Instead, we will focus on a more comprehensive and in-depth performance comparison of the Mamba benchmark model. Through this comparison, it is expected to provide a more solid and reliable experimental basis for model selection and optimization.</p></section><section id="sec014"><h3 class="pmc_sec_title">Test set performance comparison</h3>
<p>In order to comprehensively evaluate the performance of Mamba variant models, we introduce a more comprehensive set of evaluation indicators in the processing of test set. In addition to using the population Accuracy (OA) as the core performance indicator, we also calculated the average accuracy (AA) to ensure careful consideration of the recognition accuracy of each class of samples in the HSI. In addition, to provide an in-depth analysis of the model’s performance, we introduced the F1 score, which balances accuracy and recall to give a more complete picture of the model’s classification. We recorded the performance of each framework in ten independent repeated experiments on different datasets in the form of standard deviation. Additionally, we added confidence intervals to the OA index to measure the differences in performance stability among different models. <a href="#pone.0330678.t004" class="usa-link">Table 4</a> shows the performance of the Mamba benchmark model in predicting the test set of six HSI datasets.</p>
<section class="tw xbox font-sm" id="pone.0330678.t004"><h4 class="obj_head">Table 4. Performance comparison of test set.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead>
<tr>
<th align="left" colspan="2" rowspan="2">DataSet</th>
<th align="left" colspan="5" rowspan="1">Index</th>
</tr>
<tr>
<th align="left" rowspan="1" colspan="1">OA</th>
<th align="left" rowspan="1" colspan="1">OA confidence interval</th>
<th align="left" rowspan="1" colspan="1">AA</th>
<th align="left" rowspan="1" colspan="1">κ</th>
<th align="left" rowspan="1" colspan="1">F1</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="4" colspan="1">Ausburg</td>
<td align="left" rowspan="1" colspan="1">Mamba</td>
<td align="left" rowspan="1" colspan="1">0.9940 ± 0.0058</td>
<td align="left" rowspan="1" colspan="1">[0.9882, 1.0000]</td>
<td align="left" rowspan="1" colspan="1">0.9932 ± 0.0063</td>
<td align="left" rowspan="1" colspan="1">0.9928 ± 0.0053</td>
<td align="left" rowspan="1" colspan="1">0.9223 ± 0.0055</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">CNN+Mamba</td>
<td align="left" rowspan="1" colspan="1">0.9481 ± 0.0052</td>
<td align="left" rowspan="1" colspan="1">[0.9383, 0.9579]</td>
<td align="left" rowspan="1" colspan="1">0.9402 ± 0.0053</td>
<td align="left" rowspan="1" colspan="1">0.9300 ± 0.0049</td>
<td align="left" rowspan="1" colspan="1">0.9523 ± 0.0059</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">GCN+Mamba</td>
<td align="left" rowspan="1" colspan="1">0.9932 ± 0.0053</td>
<td align="left" rowspan="1" colspan="1">[0.9892, 1.0000]</td>
<td align="left" rowspan="1" colspan="1">0.9939 ± 0.0054</td>
<td align="left" rowspan="1" colspan="1">0.9942 ± 0.0047</td>
<td align="left" rowspan="1" colspan="1">0.9933 ± 0.0052</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">EchoMamba<br>(LSTM+Mamba)</td>
<td align="left" rowspan="1" colspan="1">0.9970 ± 0.0030</td>
<td align="left" rowspan="1" colspan="1">[0.9941, 1.0000]</td>
<td align="left" rowspan="1" colspan="1">0.9965 ± 0.0033</td>
<td align="left" rowspan="1" colspan="1">0.9970 ± 0.0023</td>
<td align="left" rowspan="1" colspan="1">0.9966 ± 0.0034</td>
</tr>
<tr>
<td align="left" rowspan="4" colspan="1">Salinas</td>
<td align="left" rowspan="1" colspan="1">Mamba</td>
<td align="left" rowspan="1" colspan="1">0.9655 ± 0.0033</td>
<td align="left" rowspan="1" colspan="1">[0.9586, 0.9724]</td>
<td align="left" rowspan="1" colspan="1">0.9842 ± 0.0036</td>
<td align="left" rowspan="1" colspan="1">0.9617 ± 0.0038</td>
<td align="left" rowspan="1" colspan="1">0.9848 ± 0.0041</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">CNN+Mamba</td>
<td align="left" rowspan="1" colspan="1">0.9472 ± 0.0038</td>
<td align="left" rowspan="1" colspan="1">[0.9394, 0.9550]</td>
<td align="left" rowspan="1" colspan="1">0.9766 ± 0.0042</td>
<td align="left" rowspan="1" colspan="1">0.9413 ± 0.0046</td>
<td align="left" rowspan="1" colspan="1">0.9770 ± 0.0044</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">GCN+Mamba</td>
<td align="left" rowspan="1" colspan="1">0.9601 ± 0.0032</td>
<td align="left" rowspan="1" colspan="1">[0.9542, 0.9660]</td>
<td align="left" rowspan="1" colspan="1">0.9828 ± 0.0036</td>
<td align="left" rowspan="1" colspan="1">0.9555 ± 0.0031</td>
<td align="left" rowspan="1" colspan="1">0.9830 ± 0.0037</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">EchoMamba<br>(LSTM+Mamba)</td>
<td align="left" rowspan="1" colspan="1">0.9865 ± 0.0021</td>
<td align="left" rowspan="1" colspan="1">[0.9826, 0.9904]</td>
<td align="left" rowspan="1" colspan="1">0.9941 ± 0.0025</td>
<td align="left" rowspan="1" colspan="1">0.9850 ± 0.0022</td>
<td align="left" rowspan="1" colspan="1">0.9941 ± 0.0029</td>
</tr>
<tr>
<td align="left" rowspan="4" colspan="1">Pavia Centre scene</td>
<td align="left" rowspan="1" colspan="1">Mamba</td>
<td align="left" rowspan="1" colspan="1">0.9242 ± 0.0022</td>
<td align="left" rowspan="1" colspan="1">[0.9203, 0.9281]</td>
<td align="left" rowspan="1" colspan="1">0.8250 ± 0.0023</td>
<td align="left" rowspan="1" colspan="1">0.8943 ± 0.0027</td>
<td align="left" rowspan="1" colspan="1">0.8546 ± 0.0026</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">CNN+Mamba</td>
<td align="left" rowspan="1" colspan="1">0.9343 ± 0.0022</td>
<td align="left" rowspan="1" colspan="1">[0.9299, 0.9387]</td>
<td align="left" rowspan="1" colspan="1">0.8401 ± 0.0027</td>
<td align="left" rowspan="1" colspan="1">0.9080 ± 0.0022</td>
<td align="left" rowspan="1" colspan="1">0.8690 ± 0.0022</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">GCN+Mamba</td>
<td align="left" rowspan="1" colspan="1">0.9316 ± 0.0018</td>
<td align="left" rowspan="1" colspan="1">[0.9281, 0.9351]</td>
<td align="left" rowspan="1" colspan="1">0.9136 ± 0.0023</td>
<td align="left" rowspan="1" colspan="1">0.9039 ± 0.0013</td>
<td align="left" rowspan="1" colspan="1">0.8606 ± 0.0017</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">EchoMamba<br>(LSTM+Mamba)</td>
<td align="left" rowspan="1" colspan="1">0.9544 ± 0.0010</td>
<td align="left" rowspan="1" colspan="1">[0.9525, 0.9563]</td>
<td align="left" rowspan="1" colspan="1">0.8750 ± 0.0015</td>
<td align="left" rowspan="1" colspan="1">0.9363 ± 0.0009</td>
<td align="left" rowspan="1" colspan="1">0.9100 ± 0.0008</td>
</tr>
<tr>
<td align="left" rowspan="4" colspan="1">Pavia University</td>
<td align="left" rowspan="1" colspan="1">Mamba</td>
<td align="left" rowspan="1" colspan="1">0.9600 ± 0.0040</td>
<td align="left" rowspan="1" colspan="1">[0.9522, 0.9678]</td>
<td align="left" rowspan="1" colspan="1">0.9381 ± 0.0045</td>
<td align="left" rowspan="1" colspan="1">0.9490 ± 0.0043</td>
<td align="left" rowspan="1" colspan="1">0.9473 ± 0.0041</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">CNN+Mamba</td>
<td align="left" rowspan="1" colspan="1">0.9537 ± 0.0045</td>
<td align="left" rowspan="1" colspan="1">[0.9449, 0.9625]</td>
<td align="left" rowspan="1" colspan="1">0.9322 ± 0.0051</td>
<td align="left" rowspan="1" colspan="1">0.9405 ± 0.0047</td>
<td align="left" rowspan="1" colspan="1">0.9393 ± 0.0046</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">GCN+Mamba</td>
<td align="left" rowspan="1" colspan="1">0.9776 ± 0.0037</td>
<td align="left" rowspan="1" colspan="1">[0.9707, 0.9845]</td>
<td align="left" rowspan="1" colspan="1">0.9788 ± 0.0042</td>
<td align="left" rowspan="1" colspan="1">0.9705 ± 0.0036</td>
<td align="left" rowspan="1" colspan="1">0.9725 ± 0.0037</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">EchoMamba<br>(LSTM+Mamba)</td>
<td align="left" rowspan="1" colspan="1">0.9972 ± 0.0027</td>
<td align="left" rowspan="1" colspan="1">[0.9923, 1.0000]</td>
<td align="left" rowspan="1" colspan="1">0.9960 ± 0.0032</td>
<td align="left" rowspan="1" colspan="1">0.9962 ± 0.0027</td>
<td align="left" rowspan="1" colspan="1">0.9965 ± 0.0023</td>
</tr>
<tr>
<td align="left" rowspan="4" colspan="1">Indian Pines</td>
<td align="left" rowspan="1" colspan="1">Mamba</td>
<td align="left" rowspan="1" colspan="1">0.9814 ± 0.0031</td>
<td align="left" rowspan="1" colspan="1">[0.9755, 0.9873]</td>
<td align="left" rowspan="1" colspan="1">0.9852 ± 0.0036</td>
<td align="left" rowspan="1" colspan="1">0.9867 ± 0.0031</td>
<td align="left" rowspan="1" colspan="1">0.9787 ± 0.0034</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">CNN+Mamba</td>
<td align="left" rowspan="1" colspan="1">0.9561 ± 0.0037</td>
<td align="left" rowspan="1" colspan="1">[0.9492, 0.9630]</td>
<td align="left" rowspan="1" colspan="1">0.9692 ± 0.0040</td>
<td align="left" rowspan="1" colspan="1">0.9712 ± 0.0034</td>
<td align="left" rowspan="1" colspan="1">0.9496 ± 0.0034</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">GCN+Mamba</td>
<td align="left" rowspan="1" colspan="1">0.9873 ± 0.0021</td>
<td align="left" rowspan="1" colspan="1">[0.9824, 0.9922]</td>
<td align="left" rowspan="1" colspan="1">0.9918 ± 0.0031</td>
<td align="left" rowspan="1" colspan="1">0.9856 ± 0.0023</td>
<td align="left" rowspan="1" colspan="1">0.9908 ± 0.0026</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">EchoMamba<br>(LSTM+Mamba)</td>
<td align="left" rowspan="1" colspan="1">0.9903 ± 0.0015</td>
<td align="left" rowspan="1" colspan="1">[0.9874, 0.9932]</td>
<td align="left" rowspan="1" colspan="1">0.9916 ± 0.0021</td>
<td align="left" rowspan="1" colspan="1">0.9888 ± 0.0013</td>
<td align="left" rowspan="1" colspan="1">0.9924 ± 0.0017</td>
</tr>
<tr>
<td align="left" rowspan="4" colspan="1">Houston<br>2013</td>
<td align="left" rowspan="1" colspan="1">Mamba</td>
<td align="left" rowspan="1" colspan="1">0.9781 ± 0.0022</td>
<td align="left" rowspan="1" colspan="1">[0.9732, 0.9830]</td>
<td align="left" rowspan="1" colspan="1">0.9793 ± 0.0032</td>
<td align="left" rowspan="1" colspan="1">0.9787 ± 0.0025</td>
<td align="left" rowspan="1" colspan="1">0.9762 ± 0.0022</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">CNN+Mamba</td>
<td align="left" rowspan="1" colspan="1">0.9668 ± 0.0031</td>
<td align="left" rowspan="1" colspan="1">[0.9609, 0.9727]</td>
<td align="left" rowspan="1" colspan="1">0.9707 ± 0.0039</td>
<td align="left" rowspan="1" colspan="1">0.9702 ± 0.0036</td>
<td align="left" rowspan="1" colspan="1">0.9641 ± 0.0031</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">GCN+Mamba</td>
<td align="left" rowspan="1" colspan="1">0.9934 ± 0.0023</td>
<td align="left" rowspan="1" colspan="1">[0.9895, 0.9973]</td>
<td align="left" rowspan="1" colspan="1">0.9948 ± 0.0027</td>
<td align="left" rowspan="1" colspan="1">0.9928 ± 0.0021</td>
<td align="left" rowspan="1" colspan="1">0.9936 ± 0.0023</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">EchoMamba<br>(LSTM+Mamba)</td>
<td align="left" rowspan="1" colspan="1">0.9840 ± 0.0012</td>
<td align="left" rowspan="1" colspan="1">[0.9816, 0.9864]</td>
<td align="left" rowspan="1" colspan="1">0.9840 ± 0.0016</td>
<td align="left" rowspan="1" colspan="1">0.9847 ± 0.0012</td>
<td align="left" rowspan="1" colspan="1">0.9827 ± 0.0014</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0330678.t004/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p>Based on the results of the standard deviation and the confidence interval of OA, it can be seen that the performance of each group of models is within a relatively stable range. In theory, CNN+Mamba, as a variant of Mamba, should demonstrate performance beyond the original Mamba model. However, in practical tests, for the five datasets of Augsburg, Pavia Centre scene, Pavia University, Indian Pines and Houston 2013, the predictive performance of CNN+Mamba model is slightly lower than that of the original Mamba model. In the performance comparison of the verification set, GCN+Mamba and CNN+Mamba have their own advantages and disadvantages in the processing performance of the six data sets, and do not show obvious advantages. However, in the performance comparison of the test set, compared with the performance of CNN+Mamba, GCN+Mamba has achieved all-round breakthroughs. It even shows better performance than EchoMamba in the processing of the Houston 2013 dataset. But overall, the EchoMamba model is significantly better than the other three models in the prediction performance indexes for all the test set of data used, showing excellent performance. The results show that CNN+Mamba does not achieve a comprehensive improvement in performance compared with Mamba. GCN+Mamba outperformed CNN+Mamba in results, but the overall performance was still not comparable to EchoMamba. However, EchoMamba model shows better prediction ability than GCN+Mamba, CNN+Mamba and Mamba.</p>
<p>To further confirm the superiority of EchoMamba model, <a href="#pone.0330678.g005" class="usa-link">Fig 5</a> shows the prediction confusion matrix of EchoMamba model on the test set of six data sets(Let’s take one of the ten independent repeated experiments as an example). These confusion matrices clearly show the classification accuracy of the model across different categories, thus further validating the superiority of the EchoMamba model in the HSI classification task.</p>
<figure class="fig xbox font-sm" id="pone.0330678.g005"><h4 class="obj_head">Fig 5. Test set confusion matrix with EchoMamba.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370145_pone.0330678.g005.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b8dc/12370145/addac0064b21/pone.0330678.g005.jpg" loading="lazy" height="1043" width="773" alt="Fig 5"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330678.g005/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p>The analysis of the confusion matrix revealed some challenges that EchoMamba still faced in its classification performance on the evaluated datasets. On the Ausburg dataset, there were obvious misclassification phenomena between the category 3 and category 5, as well as between the category 6 and category 7. Similarly, on the Salinas dataset, the misclassification rate between the category 8 and category 10 was relatively high. On the Pavia University dataset, the performance was good, and no intermittent high misclassification rates for specific categories were observed; it is notable that EchoMamba achieved a perfect 100% accuracy rate for the category 7. On the Houston 2013 dataset, the classification accuracy for the category 9 was extremely high (98.4%), but its main misclassification was caused by confusion with the category 7.</p>
<p>To specifically evaluate the robustness of EchoMamba in the presence of imbalanced sample distribution, we focused on the Indian Pines dataset and the Pavia Centre scene dataset, both of which have significant class imbalance issues. For the Indian Pines dataset, its sample distribution was extremely unbalanced, and EchoMamba made many errors when classifying the categories with very few samples (specifically categories 1 and 16). The results on the Pavia Centre scene dataset further highlighted the influence of sample quantity: for the categories with a larger number of samples, the classification accuracy reached 99.2%, but for the categories with a smaller number of samples, the accuracy dropped significantly to 89.7%. This phenomenon indicates that when dealing with datasets with uneven sample distribution, there is still much room for improvement in EchoMamba’s generalization ability.</p>
<p>To sum up, EchoMamba is compared with several advanced models in terms of overall performance. These models include Mamba, CNN+Mamba, GCN+Mamba, Transformer, CNN+Transformer, GCN+Transformer, LSTM+Transformer. Through rigorous experimental testing and evaluation, we draw the following conclusions: in the process of processing HSI data sets, EchoMamba has shown more powerful model performance than other benchmark models in terms of feature extraction, classification accuracy, and model generalization ability.</p>
<p>In the second stage of the experiment, we will continue to explore the EchoMamba model and make a detailed performance comparison between the EchoMamba model and the improved Mamba model proposed by other researchers mentioned earlier in the field of hyperspectral image processing. Through this series of comparisons, we hope to further verify the superiority of EchoMamba model and contribute new insights to the development of HSI processing technology.</p></section><section id="sec015"><h3 class="pmc_sec_title">Advanced experiment</h3>
<p>In this stage of the experiment, we compare the performance of EchoMamba with the more advanced variant model 3DSS-Mamba mentioned earlier to explore the advantages and disadvantages of both. We selected three datasets, Pavia University, Indian Pine and Houston 2013, which completely coincided with the research of He et al [<a href="#pone.0330678.ref024" class="usa-link" aria-describedby="pone.0330678.ref024">24</a>]. to conduct a detailed test on the performance of 3DSS-Mamba. In order to ensure the consistency of experimental conditions, we strictly followed the partitioning method of data sets proposed by He et al.: For the Pavia University dataset, we adopted the partitioning ratio of 5% training set and 95% test set; And for Indian Pines and Houston 2013 data sets, 10% training set and 90% test set were divided.</p>
<p>We used the complete EchoMamba framework, which includes RFMS data preprocessing strategies and LSTMS6 model components, to sequentially train and predict three reclassified data sets, and compared the performance of 3DSS-Mamba.</p>
<p>In order to further verify the performance of EchoMamba, we replicated another advanced framework – the 3D-CNN HSI classification framework [<a href="#pone.0330678.ref034" class="usa-link" aria-describedby="pone.0330678.ref034">34</a>]. We compared its performance with that of EchoMamba by placing it alongside 3DSS-Mamba as a competing model. In <a href="#pone.0330678.t005" class="usa-link">Table 5</a>, we provide a detailed comparative analysis of the classification prediction performance of EchoMamba, 3DSS-Mamba and 3D-CNN on three datasets covering accuracy, overall accuracy (OA), average accuracy (AA), and Kappa coefficient (κ) for each category of features.</p>
<section class="tw xbox font-sm" id="pone.0330678.t005"><h4 class="obj_head">Table 5. Performance comparison between 3DSS-Mamba and EchoMamba.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead>
<tr>
<th align="left" rowspan="2" colspan="1">Class</th>
<th align="left" colspan="3" rowspan="1">Pavia University</th>
<th align="left" colspan="3" rowspan="1">Indian Pines</th>
<th align="left" colspan="3" rowspan="1">Houston 2013</th>
</tr>
<tr>
<th align="left" rowspan="1" colspan="1">EchoMamba</th>
<th align="left" rowspan="1" colspan="1">3DSS-Mamba</th>
<th align="left" rowspan="1" colspan="1">3D-CNN</th>
<th align="left" rowspan="1" colspan="1">EchoMamba</th>
<th align="left" rowspan="1" colspan="1">3DSS-Mamba</th>
<th align="left" rowspan="1" colspan="1">3D-CNN</th>
<th align="left" rowspan="1" colspan="1">EchoMamba</th>
<th align="left" rowspan="1" colspan="1">3DSS-Mamba</th>
<th align="left" rowspan="1" colspan="1">3D-CNN</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">0.9811</td>
<td align="left" rowspan="1" colspan="1">0.9933</td>
<td align="left" rowspan="1" colspan="1">0.9922</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.7805</td>
<td align="left" rowspan="1" colspan="1">0.9202</td>
<td align="left" rowspan="1" colspan="1">0.9992</td>
<td align="left" rowspan="1" colspan="1">0.9902</td>
<td align="left" rowspan="1" colspan="1">0.9887</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">0.9955</td>
<td align="left" rowspan="1" colspan="1">0.9934</td>
<td align="left" rowspan="1" colspan="1">0.9821</td>
<td align="left" rowspan="1" colspan="1">0.9951</td>
<td align="left" rowspan="1" colspan="1">0.9027</td>
<td align="left" rowspan="1" colspan="1">0.9129</td>
<td align="left" rowspan="1" colspan="1">0.9960</td>
<td align="left" rowspan="1" colspan="1">0.9956</td>
<td align="left" rowspan="1" colspan="1">0.9647</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">0.9938</td>
<td align="left" rowspan="1" colspan="1">0.9509</td>
<td align="left" rowspan="1" colspan="1">0.9611</td>
<td align="left" rowspan="1" colspan="1">0.9916</td>
<td align="left" rowspan="1" colspan="1">0.9304</td>
<td align="left" rowspan="1" colspan="1">0.9455</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.9276</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4</td>
<td align="left" rowspan="1" colspan="1">0.9967</td>
<td align="left" rowspan="1" colspan="1">0.9591</td>
<td align="left" rowspan="1" colspan="1">0.9550</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.9343</td>
<td align="left" rowspan="1" colspan="1">0.9445</td>
<td align="left" rowspan="1" colspan="1">0.9976</td>
<td align="left" rowspan="1" colspan="1">0.9768</td>
<td align="left" rowspan="1" colspan="1">0.9821</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">0.9993</td>
<td align="left" rowspan="1" colspan="1">0.9969</td>
<td align="left" rowspan="1" colspan="1">0.9928</td>
<td align="left" rowspan="1" colspan="1">0.9876</td>
<td align="left" rowspan="1" colspan="1">0.9770</td>
<td align="left" rowspan="1" colspan="1">0.9236</td>
<td align="left" rowspan="1" colspan="1">0.9992</td>
<td align="left" rowspan="1" colspan="1">0.9991</td>
<td align="left" rowspan="1" colspan="1">0.9964</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">6</td>
<td align="left" rowspan="1" colspan="1">0.9980</td>
<td align="left" rowspan="1" colspan="1">0.9943</td>
<td align="left" rowspan="1" colspan="1">0.9933</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.9726</td>
<td align="left" rowspan="1" colspan="1">0.9828</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.9829</td>
<td align="left" rowspan="1" colspan="1">0.9987</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">7</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.9588</td>
<td align="left" rowspan="1" colspan="1">0.9721</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.9600</td>
<td align="left" rowspan="1" colspan="1">0.9543</td>
<td align="left" rowspan="1" colspan="1">0.9976</td>
<td align="left" rowspan="1" colspan="1">0.9755</td>
<td align="left" rowspan="1" colspan="1">0.9653</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">8</td>
<td align="left" rowspan="1" colspan="1">0.9902</td>
<td align="left" rowspan="1" colspan="1">0.9620</td>
<td align="left" rowspan="1" colspan="1">0.9533</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.9930</td>
<td align="left" rowspan="1" colspan="1">0.9882</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.9616</td>
<td align="left" rowspan="1" colspan="1">0.9789</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">9</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.9722</td>
<td align="left" rowspan="1" colspan="1">0.9678</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.3889</td>
<td align="left" rowspan="1" colspan="1">0.6709</td>
<td align="left" rowspan="1" colspan="1">0.9840</td>
<td align="left" rowspan="1" colspan="1">0.9627</td>
<td align="left" rowspan="1" colspan="1">0.9553</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">10</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">0.9990</td>
<td align="left" rowspan="1" colspan="1">0.9680</td>
<td align="left" rowspan="1" colspan="1">0.9338</td>
<td align="left" rowspan="1" colspan="1">0.9976</td>
<td align="left" rowspan="1" colspan="1">0.9955</td>
<td align="left" rowspan="1" colspan="1">0.9931</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">11</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">0.9939</td>
<td align="left" rowspan="1" colspan="1">0.9891</td>
<td align="left" rowspan="1" colspan="1">0.9762</td>
<td align="left" rowspan="1" colspan="1">0.9984</td>
<td align="left" rowspan="1" colspan="1">0.9820</td>
<td align="left" rowspan="1" colspan="1">0.9632</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">12</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.9139</td>
<td align="left" rowspan="1" colspan="1">0.8991</td>
<td align="left" rowspan="1" colspan="1">0.9984</td>
<td align="left" rowspan="1" colspan="1">0.9838</td>
<td align="left" rowspan="1" colspan="1">0.9281</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">13</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.9568</td>
<td align="left" rowspan="1" colspan="1">0.9567</td>
<td align="left" rowspan="1" colspan="1">0.9893</td>
<td align="left" rowspan="1" colspan="1">0.9668</td>
<td align="left" rowspan="1" colspan="1">0.9765</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">14</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">0.9573</td>
<td align="left" rowspan="1" colspan="1">0.9965</td>
<td align="left" rowspan="1" colspan="1">0.9768</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.9948</td>
<td align="left" rowspan="1" colspan="1">0.9932</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">15</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">0.9845</td>
<td align="left" rowspan="1" colspan="1">0.9452</td>
<td align="left" rowspan="1" colspan="1">0.9543</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.9765</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">16</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1">1.0000</td>
<td align="left" rowspan="1" colspan="1">0.8452</td>
<td align="left" rowspan="1" colspan="1">0.8932</td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
<td align="left" rowspan="1" colspan="1"></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">OA</td>
<td align="left" rowspan="1" colspan="1">0.9935</td>
<td align="left" rowspan="1" colspan="1">0.9848</td>
<td align="left" rowspan="1" colspan="1">0.9801</td>
<td align="left" rowspan="1" colspan="1">0.9906</td>
<td align="left" rowspan="1" colspan="1">0.9582</td>
<td align="left" rowspan="1" colspan="1">0.9568</td>
<td align="left" rowspan="1" colspan="1">0.9970</td>
<td align="left" rowspan="1" colspan="1">0.9837</td>
<td align="left" rowspan="1" colspan="1">0.9725</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">AA</td>
<td align="left" rowspan="1" colspan="1">0.9865</td>
<td align="left" rowspan="1" colspan="1">0.9756</td>
<td align="left" rowspan="1" colspan="1">0.9712</td>
<td align="left" rowspan="1" colspan="1">0.9896</td>
<td align="left" rowspan="1" colspan="1">0.9083</td>
<td align="left" rowspan="1" colspan="1">0.9271</td>
<td align="left" rowspan="1" colspan="1">0.9971</td>
<td align="left" rowspan="1" colspan="1">0.9844</td>
<td align="left" rowspan="1" colspan="1">0.9726</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">κ</td>
<td align="left" rowspan="1" colspan="1">0.9914</td>
<td align="left" rowspan="1" colspan="1">0.9798</td>
<td align="left" rowspan="1" colspan="1">0.9754</td>
<td align="left" rowspan="1" colspan="1">0.9893</td>
<td align="left" rowspan="1" colspan="1">0.9523</td>
<td align="left" rowspan="1" colspan="1">0.9501</td>
<td align="left" rowspan="1" colspan="1">0.9968</td>
<td align="left" rowspan="1" colspan="1">0.9824</td>
<td align="left" rowspan="1" colspan="1">0.9727</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0330678.t005/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p>The results show that EchoMamba outperforms 3DSS-Mamba and 3D-CNN on all test datasets. In particular, on some categories, 3DSS-Mamba and 3D-CNN failed to achieve 90% accuracy, while EchoMamba was able to achieve almost 100% prediction accuracy. This significant difference fully reflects the advanced nature and practical value of EchoMamba in the field of HSI processing. In addition, visually demonstrate EchoMamba’s predictive effect on these three data sets, further confirming its superior performance.</p>
<figure class="fig xbox font-sm" id="pone.0330678.g006"><h4 class="obj_head">Fig 6. The predictive effect of EchoMamba on Pavia University.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370145_pone.0330678.g006.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b8dc/12370145/663fa8ac3067/pone.0330678.g006.jpg" loading="lazy" height="627" width="746" alt="Fig 6"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330678.g006/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><figure class="fig xbox font-sm" id="pone.0330678.g007"><h4 class="obj_head">Fig 7. The predictive effect of EchoMamba on Indian Pines.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370145_pone.0330678.g007.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b8dc/12370145/509bf59dfc28/pone.0330678.g007.jpg" loading="lazy" height="335" width="670" alt="Fig 7"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330678.g007/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><figure class="fig xbox font-sm" id="pone.0330678.g008"><h4 class="obj_head">Fig 8. The predictive effect of EchoMamba on Houston 2013.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370145_pone.0330678.g008.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b8dc/12370145/ee0e632be501/pone.0330678.g008.jpg" loading="lazy" height="376" width="670" alt="Fig 8"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330678.g008/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure></section><section id="sec016"><h3 class="pmc_sec_title">Parameter adjustment</h3>
<p>On the basis of following the data set partitioning principle in advanced experiment, we dig deeply into the performance of EchoMamba model. In order to maximize the performance of the model, we carried out fine parameter adjustment and optimization.</p>
<p>First of all, in the core component of EchoMamba, LSTMS6, we use the unidirectional LSTM module by default, although the combination of unidirectional LSTM and Mamba can achieve better performance than the combination of CNN, GCN and Mamba. However, to ensure maximum use of LSTM in EchoMamba, we took a closer look at the original LSTM module and compared the performance of unidirectional LSTM, bidirectional LSTM and GRU in combination with Mamba, respectively as shown in <a href="#pone.0330678.t006" class="usa-link">Table 6</a>.</p>
<section class="tw xbox font-sm" id="pone.0330678.t006"><h4 class="obj_head">Table 6. Further performance comparison of LSTM modules.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">DataSet</th>
<th align="left" rowspan="1" colspan="1">Model(+Mamba)</th>
<th align="left" rowspan="1" colspan="1">OA</th>
<th align="left" rowspan="1" colspan="1">AA</th>
<th align="left" rowspan="1" colspan="1">κ</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="3" colspan="1">Pavia University</td>
<td align="left" rowspan="1" colspan="1">Unidirectional LSTM</td>
<td align="left" rowspan="1" colspan="1">0.9979</td>
<td align="left" rowspan="1" colspan="1">0.9974</td>
<td align="left" rowspan="1" colspan="1">0.9972</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Bidirectional LSTM</td>
<td align="left" rowspan="1" colspan="1">0.9979</td>
<td align="left" rowspan="1" colspan="1">0.9970</td>
<td align="left" rowspan="1" colspan="1">0.9971</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">GRU</td>
<td align="left" rowspan="1" colspan="1">0.9955</td>
<td align="left" rowspan="1" colspan="1">0.9936</td>
<td align="left" rowspan="1" colspan="1">0.9941</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">Indian Pines</td>
<td align="left" rowspan="1" colspan="1">Unidirectional LSTM</td>
<td align="left" rowspan="1" colspan="1">0.9951</td>
<td align="left" rowspan="1" colspan="1">0.9919</td>
<td align="left" rowspan="1" colspan="1">0.9944</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Bidirectional LSTM</td>
<td align="left" rowspan="1" colspan="1">0.9844</td>
<td align="left" rowspan="1" colspan="1">0.9851</td>
<td align="left" rowspan="1" colspan="1">0.9822</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">GRU</td>
<td align="left" rowspan="1" colspan="1">0.9951</td>
<td align="left" rowspan="1" colspan="1">0.9874</td>
<td align="left" rowspan="1" colspan="1">0.9944</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">Houston 2013</td>
<td align="left" rowspan="1" colspan="1">Unidirectional LSTM</td>
<td align="left" rowspan="1" colspan="1">0.9840</td>
<td align="left" rowspan="1" colspan="1">0.9835</td>
<td align="left" rowspan="1" colspan="1">0.9829</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Bidirectional LSTM</td>
<td align="left" rowspan="1" colspan="1">0.9840</td>
<td align="left" rowspan="1" colspan="1">0.9839</td>
<td align="left" rowspan="1" colspan="1">0.9827</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">GRU</td>
<td align="left" rowspan="1" colspan="1">0.9842</td>
<td align="left" rowspan="1" colspan="1">0.9851</td>
<td align="left" rowspan="1" colspan="1">0.9835</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0330678.t006/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p>In the processing of the three data sets, Unidirectional LSTM as a module is concatenated on the Mamba model to achieve the most powerful performance, although Bidirectional LSTM+Mamba can theoretically better learn HSI data correlation. However, the performance of Unidirectional LSTM+Mamba is not exceeded. Therefore, according to <a href="#pone.0330678.t006" class="usa-link">Table 6</a>, the combination of Unidirectional LSTM and Mamba can better realize the role of LSTM layer in EchoMamba framework.</p>
<p>In LSTMS6, the core component of the EchoMamba model, the location of the LSTM layer and its dimensional scale are two key factors. In the experiments in Chapter 2, we placed the LSTM layer above the S6 layer by default. In order to investigate the effect of the LSTM layer position on the performance of the EchoMamba model in depth, the following attempts were made: The LSTM layer was placed in the first layer of LSTMS6 (i.e., the layer above the S6 model) and the last layer (i.e., the layer below the S6 model). We trained these two models on three datasets: Pavia University, Indian Pines, and Houston 2013. After testing, the performance of the two models on the test set is shown in <a href="#pone.0330678.t007" class="usa-link">Table 7</a>.</p>
<section class="tw xbox font-sm" id="pone.0330678.t007"><h4 class="obj_head">Table 7. Performance comparison of LSTM layers at different locations in LSTMS6.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">DataSet</th>
<th align="left" rowspan="1" colspan="1">Model</th>
<th align="left" rowspan="1" colspan="1">OA</th>
<th align="left" rowspan="1" colspan="1">AA</th>
<th align="left" rowspan="1" colspan="1">κ</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="2" colspan="1">Pavia University</td>
<td align="left" rowspan="1" colspan="1">EchoMamba1<br>(Upper LSTM)</td>
<td align="left" rowspan="1" colspan="1">0.9978</td>
<td align="left" rowspan="1" colspan="1">0.9961</td>
<td align="left" rowspan="1" colspan="1">0.9970</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">EchoMamba2<br>(Lower LSTM)</td>
<td align="left" rowspan="1" colspan="1">0.7848</td>
<td align="left" rowspan="1" colspan="1">0.6580</td>
<td align="left" rowspan="1" colspan="1">0.7229</td>
</tr>
<tr>
<td align="left" rowspan="2" colspan="1">Indian Pines</td>
<td align="left" rowspan="1" colspan="1">EchoMamba1<br>(Upper LSTM)</td>
<td align="left" rowspan="1" colspan="1">0.9922</td>
<td align="left" rowspan="1" colspan="1">0.9927</td>
<td align="left" rowspan="1" colspan="1">0.9911</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">EchoMamba2<br>(Lower LSTM)</td>
<td align="left" rowspan="1" colspan="1">0.4488</td>
<td align="left" rowspan="1" colspan="1">0.5978</td>
<td align="left" rowspan="1" colspan="1">0.3964</td>
</tr>
<tr>
<td align="left" rowspan="2" colspan="1">Houston 2013</td>
<td align="left" rowspan="1" colspan="1">EchoMamba1<br>(Upper LSTM)</td>
<td align="left" rowspan="1" colspan="1">0.9971</td>
<td align="left" rowspan="1" colspan="1">0.9969</td>
<td align="left" rowspan="1" colspan="1">0.9968</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">EchoMamba2<br>(Lower LSTM)</td>
<td align="left" rowspan="1" colspan="1">0.7117</td>
<td align="left" rowspan="1" colspan="1">0.7102</td>
<td align="left" rowspan="1" colspan="1">0.6885</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0330678.t007/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p>As shown in <a href="#pone.0330678.t007" class="usa-link">Table 7</a>, EchoMamba1 has significantly better performance than EchoMamba2 in various verification indicators. This finding indicates that placing the LSTM layer in the first layer of LSTMS6, in other words, placing the LSTM layer on top of the S6 layer, can significantly improve the performance of the EchoMamba model and achieve optimal performance.</p>
<p>In order to solve the problem of dimension scale of LSTM layer, we set the dimension of LSTM to 90 in Chapter 2, and the data set is processed to achieve a better result. In order to further explore whether EchoMamba can achieve better performance in HSI data processing, we modified the dimension of LSTM layer, and tried it successively from 80 to 100 around the original set of 90. The changing trend of model performance is shown in <a href="#pone.0330678.g009" class="usa-link">Fig 9</a>.</p>
<figure class="fig xbox font-sm" id="pone.0330678.g009"><h4 class="obj_head">Fig 9. Adjustments for LSTM hidden layer dimensions.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370145_pone.0330678.g009.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b8dc/12370145/fc4917c9b2a3/pone.0330678.g009.jpg" loading="lazy" height="372" width="694" alt="Fig 9"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330678.g009/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p>As shown in <a href="#pone.0330678.g009" class="usa-link">Fig 9</a>, for OA, AA, κ and other indicators of the three datasets, when LSTM’s hidden layer dimension is 92, EchoMamba’s OA, AA, and κ at Pavia University are 0.9969, 0.9947, and 0.9959. On Indian Pines, OA was 0.9945, AA was 0.9936, κ was 0.9936; Houston 2013 has OA of 0.9964, AA of 0.9968, κ of 0.9961, which can achieve the best model performance across the three datasets.</p>
<p>In adjusting the learning rate of the model, we conducted a careful experimental comparison, testing four different learning rate Settings of 0.1, 0.01, 0.001 and 0.0001 respectively. After observation and analysis of a series of training cycles, we found that when the learning rate was set to 0.1 and 0.01, the model showed a certain volatility in the training process. Specifically, in the early training period, the performance index of the model gradually increased, showing a good learning effect. However, in the middle and late training period. However, the performance of the model under the learning rate setting suddenly and rapidly decreased, and the phenomenon of gradient explosion appeared; When the learning rate is set to 0.0001 and 0.00001, the performance of the model is gradually improved in the training stage, but the performance on the test is far worse than the performance on the training, which may be due to the overfitting of the model. Different from the first two cases, when the learning rate is set to 0.001, the model shows a more robust learning process. With the increase of training cycle, the performance index of the model continues to rise, and finally stabilizes at a higher level, and also shows excellent performance on the test set. By comparing the experimental results, we come to the conclusion that 0.001 is the most suitable learning rate for EchoMamba among the tested learning rates, which enables the model to achieve the best performance in the training process, so as to learn the training set features of HSI data more thoroughly and apply them to the test set.</p>
<p>To sum up, we achieve the optimal performance of EchoMamba through parameter adjustment. When the LSTM layer is placed in the first layer of LSTMS6 and the dimension is set to 92, the learning rate of the model is set to 0.01, which can play the best prediction and classification ability of EchoMamba on HSI.</p></section></section><section id="sec017"><h2 class="pmc_sec_title">Discussion</h2>
<p>In basic experiment, we have observed a significant phenomenon: although the Mamba benchmark model has a significant reduction in training time compared with the Transformer benchmark model, its predictive performance is very similar to that of the Transformer benchmark model or even better in some data sets. HSI datasets have a large amount of data and complex dimensions. Each pixel contains numerous spectral bands, each band corresponds to a time step, resulting in extremely large data series length. Therefore, in the training process of HSI, training time cost has become an important index to measure model performance. The Mamba benchmark model, with its linear time complexity, shows a significant training speed advantage when processing such long sequences of HSI data. In addition, the built-in selectivity mechanism of the Mamba model allows the model to selectively focus on or ignore certain information according to the characteristics of the input data, which not only effectively compresses the state space, but also greatly improves the processing efficiency of the model. Redundant information and noise are common problems in HSI data. Mamba’s own selectivity mechanism can effectively screen out useful information and filter out interference factors, thus further improving its performance. In contrast, the Transformer benchmark model has a unique self-attention mechanism to capture complex relationships in the data, but this also means a lot of matrix multiplication and nonlinear calculation in the process, which is not only computationally heavy, but also the memory consumption of the device is extremely challenging. Therefore, compared with Mamba benchmark model, Transformer benchmark model has obvious shortcomings in terms of processing speed.</p>
<p>In the internal comparison of the Mamba benchmark model, it can be observed that compared with the original Mamba model, the performance of CNN+Mamba integrated into the CNN layer has not been significantly improved. On the contrary, the performance of CNN+Mamba is even worse than that of Mamba in some datasets. This phenomenon likely stems from the combination of CNN and Mamba increases the complexity of the model, resulting in some overfitting problems in the model, which makes it difficult for CNN+Mamba to generalize the learning of the training set to the test set and even the whole data set. Due to the dimensional complexity of HSI, the spectral information may be sufficient for the task of image prediction and classification. The additional spatial information learned by combining CNN may not bring further performance improvement of the model, and even increase the noise of the model. With its selective mechanism, Mamba pays more attention to the spectral dimension information of HSI data, while CNN pays more attention to the learning of spatial dimension information. In addition, in the CNN+Mamba model, information fusion is also a major problem, and improper fusion strategies may also lead to data loss and confusion, thus reducing the performance of the model.</p>
<p>When processing HSI, GCN+Mamba shows better performance than CNN+Mamba, which may be mainly due to their complementary adaptation to HSI data characteristics. HSI data has the characteristics of high-dimensional continuous spectral features coupled with local spatial structure, and its pixels form a long sequence correlation of non-Euclidean manifolds in spectral dimension, while there are local similarities in spatial dimension. GCN models the global relationship between pixels or regions through the graph structure, regards each pixel as a graph node, uses spectral similarity or spatial adjacency to build edge weights, and can explicitly capture long-distance dependence and non-local feature interaction in high-dimensional space. This capability is especially suitable for the continuity and redundancy characteristics of HSI spectral dimensions. However, the convolution kernel of traditional CNN is limited by the assumption of local sensitivity field and invariance of displacement, so it is difficult to model the global nonlinear relationship in spectral dimension, and the low spatial resolution of HSI may introduce noise in the extraction of spatial features. As a state-space model, Mamba can model long sequences efficiently through a selective state mechanism. When the graph structure features extracted by GCN are input, the implied state can further optimize the spectrum-space joint representation, dynamically screen important band information along the sequence dimension and suppress redundancy. However, if the front-end uses CNN, the regular grid features of its output may have lost part of the global spectral association information, which makes it difficult for Mamba to fully exploit the complex cross-band dependence. In addition, the graph convolution operation of GCN realizes frequency domain filtering through Laplacian matrix, which is physically consistent with the spectral signal processing requirements of HSI data in essence, while the spatial convolution operation of CNN is more inclined to spatial texture extraction. The difference of inductive bias between the two in HSI tasks may eventually lead to the combination of GCN+Mamba being more effective in collaborative modeling of the deep semantic information of spectral-spatial dual modes.</p>
<p>EchoMamba stands out in the performance of four Mamba benchmark models. This may be due to the multi-scale dynamic modeling of spectrum-space complex dependence through the deep collaboration mechanism between LSTM and Mamba. The spectral sequence of HSI data not only contains long distance global associations, but also local timing patterns and dynamic context sensitivity. LSTM can explicitly capture the local timing dependence and short-term memory of spectral dimensions with its gated loop structure, and filter noise and redundancy adaptively through gradient-controlled information flow, while preserving the context coherence of key spectral features. Mamba, on the other hand, uses a selective state space model for efficient global modeling of long sequences, and its dynamic update mechanism of hidden states can focus on cross-band strongly correlated features and suppress irrelevant interference. The combination of the two forms a double enhancement of “local segmentation - global abstraction” during feature transfer: LSTM first extracts local temporal features and compacts memory of the original spectral sequence to alleviate the information overload problem that may be caused by the direct input of long sequences into Mamba, and at the same time retains the local spectral response mode sensitive to classification through the gating mechanism. Mamba then further explores the global nonlinear relationship in spectral dimension and the implicit cross-band interaction based on the higher-order temporal characterization of LSTM output, and its selectivity mechanism can dynamically adjust the weight of attention to the features of different time steps in LSTM memory units, thus achieving a more detailed hierarchical representation at the spectrum-space joint embedding level. In addition, the cyclic iterative characteristics of LSTM are complementary to the parallel long series processing capability of Mamba. The former enhances the sensitivity of the model to subtle spectral differences through gradual iteration, while the latter enhances the generalization ability of the overall distribution law through efficient global modeling. This structural design may be more suitable for the classification requirements driven by local spectral features and global distribution patterns in HSI data.</p>
<p>The improvement idea of 3DSS-Mamba represents the mainstream way of Mamba in the field of HSI data processing, that is, HSI is regarded as a 3D data cube, and spectral spatial features are extracted by convolutional operation, and feature selection and information propagation are carried out by Mamba model to realize the fusion of spectral and spatial information. This method effectively realizes the combination of spatial dimension and spectral dimension. However, like the CNN+Mamba benchmark model we used, 3DSS-Mamba has a relatively complex design of model structure in order to comprehensively learn multidimensional data features, while EchoMamba regards HSI bands as time series and uses LSTM to capture long-term dependence between bands. And combined with the feature extraction capability of Mamba model to realize the effective utilization of spectral features. This approach appropriately reduces the model’s attention to the HSI spatial dimension, on the contrary, it focuses on the in-depth mining of the spectral dimension, and the model structure is relatively simple. Compared with 3DSS-Mamba in advanced experiment performance comparison, EchoMamba shows a comprehensive advantage, which proves the practicability and advanced nature of this framework.</p>
<p>In the study of EchoMamba’s LSTM module, we tried to replace it with bidirectional LSTM, GRU. However, the results show that the processing performance of unidirectional LSTM combined with Mamba on three common data sets is stronger than that of bidirectional LSTM and GRU as module concatenation.Hyperspectral data has significant local spatial-spectral correlation, and its classification task is highly dependent on local context information of pixel neighborhood or band, and unidirectional LSTM one-way information flow exactly conforms to this local causality -- through the dynamic regulation of forgetting gate and input gate, It accurately captures key features of the preceding band or adjacent pixels while avoiding interference from non-causal noise. Although bidirectional LSTM can theoretically merge the global context, in HSI scenarios, the “future information” introduced by the reverse sequence may destroy the physical coherence of local features, causing the model to confuse the core discriminant features. Especially when the data size is limited, the complex parameter number of bidirectional structure is more likely to cause overfitting, further weakening performance. Although the GRU reduces the computation cost by simplifying the gating mechanism, its coarse-grained control of information flow is inadequate in processing HSI high-dimensional nonlinear spectral features, and it is difficult to accurately screen and transmit multi-level features through independent gating like LSTM.</p>
<p>During the adjustment of EchoMamba, we observed that the position of LSTM in LSTMS6 plays an important role in the performance of the model. When LSTM is placed in the first layer of the model, that is, the upper layer of S6, the performance of EchoMamba can be achieved far better than that of LSTM placed in the last layer. This may be because LSTM can directly learn the local features and timing information of the image at the input layer, and use it as the input of S6, so as to help S6 better capture the context information and long-distance dependence relationship of the image, realize the close combination of feature extraction and timing modeling, and improve the richness of feature representation. In addition, LSTM can directly integrate the learned time sequence information into the feature extraction process of S6 at the input layer to achieve efficient fusion of information transfer and avoid additional integration and modeling at the output layer, thus simplifying the model structure, reducing the computational complexity, and improving the reasoning speed and output quality of the model.</p>
<p>While EchoMamba has demonstrated significant advantages in HSI classification tasks, it still faces limitations and challenges that require further exploration and improvement. EchoMamba primarily focuses on spectral feature extraction, with limited exploitation of spatial information. When EchoMamba flattens the spatial data of HSI, the change of dimension may destroy the spatial feature relationship of the original HSI. This may lead to performance degradation when dealing with tasks sensitive to spatial information, such as high-resolution HSI image classification or object detection. To further enhance the performance and applicability of EchoMamba, future research directions can be concentrated on integrating spatial feature extraction into the model.</p></section><section id="sec018"><h2 class="pmc_sec_title">Conclusions</h2>
<p>This paper proposes an HSI data processing model based on Mamba, EchoMamba, which combines a series of data preprocessing strategies with LSTM and Mamba model, and utilizes LSTM ability to capture the relationship between bands and Mamba’s powerful feature extraction ability. By sacrificing some spatial relationship learning capability, we can conduct more in-depth exploration of the deep spectral relationships within HSI data. A large number of experiments have proved that the EchoMamba proposed in this paper and the HSI classification model based on Transformer, as well as some traditional Mamba improved models that integrate spatial features with spectral features, have more powerful classification and prediction ability. This study provides a new feasible solution for the HSI classification task. In the future, the focus of the research will be on exploring the scalability of the Mamba model in a wider range of hyperspectral scenarios.</p></section><section id="ack1" class="ack"><h2 class="pmc_sec_title">Acknowledgments</h2>
<p>The authors thank the Key Laboratory of Agricultural Sensors, Ministry of Agriculture and Rural Affairs at Anhui Agriculture University. All authors have reviewed and approved the final manuscript. We also extend our gratitude to the providers of the publicly available datasets used in this study. Indian Pines, Salinas, Pavia University and Pavia Centre are available by visiting the following links: <a href="http://www.ehu.eus/ccwintco/index.php?title=Hyperspectral_Remote_Sensing_Scenes" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://www.ehu.eus/ccwintco/index.php?title=Hyperspectral_Remote_Sensing_Scenes</a>. Houston 2013 set of data can be accessed through the following link to obtain: <a href="https://github.com/songyz2019/fetch_houston2013" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/songyz2019/fetch_houston2013</a>. Augsburg data set can be accessed through the following links for: <a href="https://github.com/danfenghong/ISPRS_S2FL" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/danfenghong/ISPRS_S2FL</a>. These datasets were instrumental in supporting the experimental validation and analysis presented in this work.The implementation code is publicly available at: <a href="https://github.com/ZYC-121/EchoMamba-HSI.git" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/ZYC-121/EchoMamba-HSI.git</a>.</p></section><section id="notes1"><h2 class="pmc_sec_title">Data Availability</h2>
<p>All relevant data are in the manuscript and its supporting information files. Indian Pines, Salinas, Pavia University and Pavia Centre are available by visiting the following links: <a href="http://www.ehu.eus/ccwintco/index.php?title=Hyperspectral_Remote_Sensing_ScenesHouston2013" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://www.ehu.eus/ccwintco/index.php?title=Hyperspectral_Remote_Sensing_ScenesHouston2013</a> set of data can be accessed through the following link to obtain: <a href="https://github.com/songyz2019/fetch_houston2013" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/songyz2019/fetch_houston2013</a> Augsburg data set can be accessed through the following links for: <a href="https://github.com/danfenghong/ISPRS_S2FL" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/danfenghong/ISPRS_S2FL</a> These datasets were instrumental in supporting the experimental validation and analysis presented in this work.</p></section><section id="funding-statement1" lang="en"><h2 class="pmc_sec_title">Funding Statement</h2>
<p>The author(s) received no specific funding for this work.</p></section><section id="ref-list1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="ref-list1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="pone.0330678.ref001">
<span class="label">1.</span><cite>Landgrebe D. Hyperspectral image data analysis. IEEE Signal Process Mag. 2002;19(1):17–28. doi: 10.1109/79.974718</cite> [<a href="https://doi.org/10.1109/79.974718" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Signal%20Process%20Mag&amp;title=Hyperspectral%20image%20data%20analysis&amp;author=D%20Landgrebe&amp;volume=19&amp;issue=1&amp;publication_year=2002&amp;pages=17-28&amp;doi=10.1109/79.974718&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref002">
<span class="label">2.</span><cite>Lu B, Dao P, Liu J, He Y, Shang J. Recent Advances of Hyperspectral Imaging Technology and Applications in Agriculture. Remote Sensing. 2020;12(16):2659. doi: 10.3390/rs12162659</cite> [<a href="https://doi.org/10.3390/rs12162659" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Remote%20Sensing&amp;title=Recent%20Advances%20of%20Hyperspectral%20Imaging%20Technology%20and%20Applications%20in%20Agriculture&amp;author=B%20Lu&amp;author=P%20Dao&amp;author=J%20Liu&amp;author=Y%20He&amp;author=J%20Shang&amp;volume=12&amp;issue=16&amp;publication_year=2020&amp;pages=2659&amp;doi=10.3390/rs12162659&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref003">
<span class="label">3.</span><cite>Stuart MB, McGonigle AJS, Willmott JR. Hyperspectral Imaging in Environmental Monitoring: A Review of Recent Developments and Technological Advances in Compact Field Deployable Systems. Sensors (Basel). 2019;19(14):3071. doi: 10.3390/s19143071

</cite> [<a href="https://doi.org/10.3390/s19143071" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6678368/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31336796/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Sensors%20(Basel)&amp;title=Hyperspectral%20Imaging%20in%20Environmental%20Monitoring:%20A%20Review%20of%20Recent%20Developments%20and%20Technological%20Advances%20in%20Compact%20Field%20Deployable%20Systems&amp;author=MB%20Stuart&amp;author=AJS%20McGonigle&amp;author=JR%20Willmott&amp;volume=19&amp;issue=14&amp;publication_year=2019&amp;pages=3071&amp;pmid=31336796&amp;doi=10.3390/s19143071&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref004">
<span class="label">4.</span><cite>Peyghambari S, Zhang Y. Hyperspectral remote sensing in lithological mapping, mineral exploration, and environmental geology: an updated review. J Appl Rem Sens. 2021;15(03). doi: 10.1117/1.jrs.15.031501</cite> [<a href="https://doi.org/10.1117/1.jrs.15.031501" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Appl%20Rem%20Sens&amp;title=Hyperspectral%20remote%20sensing%20in%20lithological%20mapping,%20mineral%20exploration,%20and%20environmental%20geology:%20an%20updated%20review&amp;author=S%20Peyghambari&amp;author=Y%20Zhang&amp;volume=15&amp;issue=03&amp;publication_year=2021&amp;doi=10.1117/1.jrs.15.031501&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref005">
<span class="label">5.</span><cite>Nisha A, Anitha A. Current advances in hyperspectral remote sensing in urban planning. In: 2022 Third International Conference on intelligent computing instrumentation and control technologies (ICICICT), 2022. 94–8.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=Current%20advances%20in%20hyperspectral%20remote%20sensing%20in%20urban%20planning&amp;author=A%20Nisha&amp;author=A%20Anitha&amp;publication_year=2022&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref006">
<span class="label">6.</span><cite>Shimoni M, Haelterman R, Perneel C. Hyperspectral Imaging for Military and Security Applications: Combining Myriad Processing and Sensing Techniques. IEEE Geosci Remote Sens Mag. 2019;7(2):101–17. doi: 10.1109/mgrs.2019.2902525</cite> [<a href="https://doi.org/10.1109/mgrs.2019.2902525" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Geosci%20Remote%20Sens%20Mag&amp;title=Hyperspectral%20Imaging%20for%20Military%20and%20Security%20Applications:%20Combining%20Myriad%20Processing%20and%20Sensing%20Techniques&amp;author=M%20Shimoni&amp;author=R%20Haelterman&amp;author=C%20Perneel&amp;volume=7&amp;issue=2&amp;publication_year=2019&amp;pages=101-17&amp;doi=10.1109/mgrs.2019.2902525&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref007">
<span class="label">7.</span><cite>Li S, Song W, Fang L, Chen Y, Ghamisi P, Benediktsson JA. Deep Learning for Hyperspectral Image Classification: An Overview. IEEE Trans Geosci Remote Sensing. 2019;57(9):6690–709. doi: 10.1109/tgrs.2019.2907932</cite> [<a href="https://doi.org/10.1109/tgrs.2019.2907932" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans%20Geosci%20Remote%20Sensing&amp;title=Deep%20Learning%20for%20Hyperspectral%20Image%20Classification:%20An%20Overview&amp;author=S%20Li&amp;author=W%20Song&amp;author=L%20Fang&amp;author=Y%20Chen&amp;author=P%20Ghamisi&amp;volume=57&amp;issue=9&amp;publication_year=2019&amp;pages=6690-709&amp;doi=10.1109/tgrs.2019.2907932&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref008">
<span class="label">8.</span><cite>Petersson H, Gustafsson D, Bergstrom D. Hyperspectral image analysis using deep learning—A review. In: 2016 sixth international conference on image processing theory, tools and applications (IPTA). 2016. 1–6.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=Hyperspectral%20image%20analysis%20using%20deep%20learning%E2%80%94A%20review&amp;author=H%20Petersson&amp;author=D%20Gustafsson&amp;author=D%20Bergstrom&amp;publication_year=2016&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref009">
<span class="label">9.</span><cite>Srivastava V, Biswas B. CNN-based salient features in HSI image semantic target prediction. Connection Science. 2019;32(2):113–31. doi: 10.1080/09540091.2019.1650330</cite> [<a href="https://doi.org/10.1080/09540091.2019.1650330" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Connection%20Science&amp;title=CNN-based%20salient%20features%20in%20HSI%20image%20semantic%20target%20prediction&amp;author=V%20Srivastava&amp;author=B%20Biswas&amp;volume=32&amp;issue=2&amp;publication_year=2019&amp;pages=113-31&amp;doi=10.1080/09540091.2019.1650330&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref010">
<span class="label">10.</span><cite>Zhang M, Li W, Du Q. Diverse Region-Based CNN for Hyperspectral Image Classification. IEEE Trans Image Process. 2018;27(6):2623–34. doi: 10.1109/TIP.2018.2809606

</cite> [<a href="https://doi.org/10.1109/TIP.2018.2809606" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/29533899/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans%20Image%20Process&amp;title=Diverse%20Region-Based%20CNN%20for%20Hyperspectral%20Image%20Classification&amp;author=M%20Zhang&amp;author=W%20Li&amp;author=Q%20Du&amp;volume=27&amp;issue=6&amp;publication_year=2018&amp;pages=2623-34&amp;pmid=29533899&amp;doi=10.1109/TIP.2018.2809606&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref011">
<span class="label">11.</span><cite>Luo H. Shorten spatial-spectral RNN with parallel-GRU for hyperspectral image classification. 2018. doi: arxiv:1810.12563</cite> [<a href="https://scholar.google.com/scholar_lookup?Luo%20H.%20Shorten%20spatial-spectral%20RNN%20with%20parallel-GRU%20for%20hyperspectral%20image%20classification.%202018.%20doi:%20arxiv:1810.12563" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref012">
<span class="label">12.</span><cite>Mou L, Ghamisi P, Zhu XX. Deep Recurrent Neural Networks for Hyperspectral Image Classification. IEEE Trans Geosci Remote Sensing. 2017;55(7):3639–55. doi: 10.1109/tgrs.2016.2636241</cite> [<a href="https://doi.org/10.1109/tgrs.2016.2636241" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans%20Geosci%20Remote%20Sensing&amp;title=Deep%20Recurrent%20Neural%20Networks%20for%20Hyperspectral%20Image%20Classification&amp;author=L%20Mou&amp;author=P%20Ghamisi&amp;author=XX%20Zhu&amp;volume=55&amp;issue=7&amp;publication_year=2017&amp;pages=3639-55&amp;doi=10.1109/tgrs.2016.2636241&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref013">
<span class="label">13.</span><cite>Sun L, Zhao G, Zheng Y, Wu Z. Spectral–Spatial Feature Tokenization Transformer for Hyperspectral Image Classification. IEEE Trans Geosci Remote Sensing. 2022;60:1–14. doi: 10.1109/tgrs.2022.3144158</cite> [<a href="https://doi.org/10.1109/tgrs.2022.3144158" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans%20Geosci%20Remote%20Sensing&amp;title=Spectral%E2%80%93Spatial%20Feature%20Tokenization%20Transformer%20for%20Hyperspectral%20Image%20Classification&amp;author=L%20Sun&amp;author=G%20Zhao&amp;author=Y%20Zheng&amp;author=Z%20Wu&amp;volume=60&amp;publication_year=2022&amp;pages=1-14&amp;doi=10.1109/tgrs.2022.3144158&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref014">
<span class="label">14.</span><cite>He X, Chen Y, Lin Z. Spatial-Spectral Transformer for Hyperspectral Image Classification. Remote Sensing. 2021;13(3):498. doi: 10.3390/rs13030498</cite> [<a href="https://doi.org/10.3390/rs13030498" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Remote%20Sensing&amp;title=Spatial-Spectral%20Transformer%20for%20Hyperspectral%20Image%20Classification&amp;author=X%20He&amp;author=Y%20Chen&amp;author=Z%20Lin&amp;volume=13&amp;issue=3&amp;publication_year=2021&amp;pages=498&amp;doi=10.3390/rs13030498&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref015">
<span class="label">15.</span><cite>Zhang H, Zhu Y, Wang D, Zhang L, Chen T, Wang Z, et al. A Survey on Visual Mamba. Applied Sci. 2024;14(13):5683. doi: 10.3390/app14135683</cite> [<a href="https://doi.org/10.3390/app14135683" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Applied%20Sci&amp;title=A%20Survey%20on%20Visual%20Mamba&amp;author=H%20Zhang&amp;author=Y%20Zhu&amp;author=D%20Wang&amp;author=L%20Zhang&amp;author=T%20Chen&amp;volume=14&amp;issue=13&amp;publication_year=2024&amp;pages=5683&amp;doi=10.3390/app14135683&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref016">
<span class="label">16.</span><cite>Li Y, Luo Y, Zhang L, Wang Z, Du B. MambaHSI: Spatial–Spectral Mamba for Hyperspectral Image Classification. IEEE Trans Geosci Remote Sensing. 2024;62:1–16. doi: 10.1109/tgrs.2024.3430985</cite> [<a href="https://doi.org/10.1109/tgrs.2024.3430985" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans%20Geosci%20Remote%20Sensing&amp;title=MambaHSI:%20Spatial%E2%80%93Spectral%20Mamba%20for%20Hyperspectral%20Image%20Classification&amp;author=Y%20Li&amp;author=Y%20Luo&amp;author=L%20Zhang&amp;author=Z%20Wang&amp;author=B%20Du&amp;volume=62&amp;publication_year=2024&amp;pages=1-16&amp;doi=10.1109/tgrs.2024.3430985&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref017">
<span class="label">17.</span><cite>Wang C, Huang J, Lv M, Du H, Wu Y, Qin R. A local enhanced mamba network for hyperspectral image classification. International Journal of Applied Earth Observation and Geoinformation. 2024;133:104092. doi: 10.1016/j.jag.2024.104092</cite> [<a href="https://doi.org/10.1016/j.jag.2024.104092" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=International%20Journal%20of%20Applied%20Earth%20Observation%20and%20Geoinformation&amp;title=A%20local%20enhanced%20mamba%20network%20for%20hyperspectral%20image%20classification&amp;author=C%20Wang&amp;author=J%20Huang&amp;author=M%20Lv&amp;author=H%20Du&amp;author=Y%20Wu&amp;volume=133&amp;publication_year=2024&amp;pages=104092&amp;doi=10.1016/j.jag.2024.104092&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref018">
<span class="label">18.</span><cite>Amigo JM, Babamoradi H, Elcoroaristizabal S. Hyperspectral image analysis. A tutorial. Anal Chim Acta. 2015;896:34–51. doi: 10.1016/j.aca.2015.09.030

</cite> [<a href="https://doi.org/10.1016/j.aca.2015.09.030" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/26481986/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Anal%20Chim%20Acta&amp;title=Hyperspectral%20image%20analysis.%20A%20tutorial&amp;author=JM%20Amigo&amp;author=H%20Babamoradi&amp;author=S%20Elcoroaristizabal&amp;volume=896&amp;publication_year=2015&amp;pages=34-51&amp;pmid=26481986&amp;doi=10.1016/j.aca.2015.09.030&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref019">
<span class="label">19.</span><cite>Luo Y, Zou J, Yao C, Zhao A o s o n g, Li T, Bai G. HSI-CNN: A novel convolution neural network for hyperspectral image. In: 2018 International Conference on Audio, Language and Image Processing (ICALIP). 2018. 464–9.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=HSI-CNN:%20A%20novel%20convolution%20neural%20network%20for%20hyperspectral%20image&amp;author=Y%20Luo&amp;author=J%20Zou&amp;author=C%20Yao&amp;author=g%20Zhao%20A%20o%20s%20o%20n&amp;author=T%20Li&amp;publication_year=2018&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref020">
<span class="label">20.</span><cite>Zhang X, Sun Y, Jiang K, Li C, Jiao L, Zhou H. Spatial Sequential Recurrent Neural Network for Hyperspectral Image Classification. IEEE J Sel Top Appl Earth Observations Remote Sensing. 2018;11(11):4141–55. doi: 10.1109/jstars.2018.2844873</cite> [<a href="https://doi.org/10.1109/jstars.2018.2844873" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20J%20Sel%20Top%20Appl%20Earth%20Observations%20Remote%20Sensing&amp;title=Spatial%20Sequential%20Recurrent%20Neural%20Network%20for%20Hyperspectral%20Image%20Classification&amp;author=X%20Zhang&amp;author=Y%20Sun&amp;author=K%20Jiang&amp;author=C%20Li&amp;author=L%20Jiao&amp;volume=11&amp;issue=11&amp;publication_year=2018&amp;pages=4141-55&amp;doi=10.1109/jstars.2018.2844873&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref021">
<span class="label">21.</span><cite>Yu W, Wan S, Li G, Yang J, Gong C. Hyperspectral Image Classification With Contrastive Graph Convolutional Network. IEEE Trans Geosci Remote Sensing. 2023;61:1–15. doi: 10.1109/tgrs.2023.3240721</cite> [<a href="https://doi.org/10.1109/tgrs.2023.3240721" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans%20Geosci%20Remote%20Sensing&amp;title=Hyperspectral%20Image%20Classification%20With%20Contrastive%20Graph%20Convolutional%20Network&amp;author=W%20Yu&amp;author=S%20Wan&amp;author=G%20Li&amp;author=J%20Yang&amp;author=C%20Gong&amp;volume=61&amp;publication_year=2023&amp;pages=1-15&amp;doi=10.1109/tgrs.2023.3240721&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref022">
<span class="label">22.</span><cite>Jin C, Teng X, Chu M, Hao Y, Qin S, Li X, et al. LDBMamba: Language-guided Dual-Branch Mamba for hyperspectral image domain generalization. Expert Systems with Applications. 2025;280:127620. doi: 10.1016/j.eswa.2025.127620</cite> [<a href="https://doi.org/10.1016/j.eswa.2025.127620" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Expert%20Systems%20with%20Applications&amp;title=LDBMamba:%20Language-guided%20Dual-Branch%20Mamba%20for%20hyperspectral%20image%20domain%20generalization&amp;author=C%20Jin&amp;author=X%20Teng&amp;author=M%20Chu&amp;author=Y%20Hao&amp;author=S%20Qin&amp;volume=280&amp;publication_year=2025&amp;pages=127620&amp;doi=10.1016/j.eswa.2025.127620&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref023">
<span class="label">23.</span><cite>Gu A, Dao T. “Mamba: Linear-time sequence modeling with selective state spaces.” 2023; arxiv preprint arxiv:2312.00752.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=arxiv%20preprint%20arxiv&amp;author=A%20Gu&amp;author=T%20Dao&amp;publication_year=2023&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref024">
<span class="label">24.</span><cite>He Y, Tu B, Liu B, Li J, Plaza A. 3DSS-Mamba: 3D-Spectral-Spatial Mamba for Hyperspectral Image Classification. IEEE Trans Geosci Remote Sensing. 2024;62:1–16. doi: 10.1109/tgrs.2024.3472091</cite> [<a href="https://doi.org/10.1109/tgrs.2024.3472091" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans%20Geosci%20Remote%20Sensing&amp;title=3DSS-Mamba:%203D-Spectral-Spatial%20Mamba%20for%20Hyperspectral%20Image%20Classification&amp;author=Y%20He&amp;author=B%20Tu&amp;author=B%20Liu&amp;author=J%20Li&amp;author=A%20Plaza&amp;volume=62&amp;publication_year=2024&amp;pages=1-16&amp;doi=10.1109/tgrs.2024.3472091&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref025">
<span class="label">25.</span><cite>Dong J, Yin H, Li H, Li W, Zhang Y, Khan S, et al. Dual hyperspectral mamba for efficient spectral compressive imaging. arxiv preprint. 2024. doi: arxiv:2406.00449</cite> [<a href="https://scholar.google.com/scholar_lookup?Dong%20J,%20Yin%20H,%20Li%20H,%20Li%20W,%20Zhang%20Y,%20Khan%20S,%20et%20al.%20Dual%20hyperspectral%20mamba%20for%20efficient%20spectral%20compressive%20imaging.%20arxiv%20preprint.%202024.%20doi:%20arxiv:2406.00449" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref026">
<span class="label">26.</span><cite>Liu Q, Yue J, Fang Y, Xia S, Fang L. HyperMamba: A Spectral-Spatial Adaptive Mamba for Hyperspectral Image Classification. IEEE Trans Geosci Remote Sensing. 2024;62:1–14. doi: 10.1109/tgrs.2024.3482473</cite> [<a href="https://doi.org/10.1109/tgrs.2024.3482473" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans%20Geosci%20Remote%20Sensing&amp;title=HyperMamba:%20A%20Spectral-Spatial%20Adaptive%20Mamba%20for%20Hyperspectral%20Image%20Classification&amp;author=Q%20Liu&amp;author=J%20Yue&amp;author=Y%20Fang&amp;author=S%20Xia&amp;author=L%20Fang&amp;volume=62&amp;publication_year=2024&amp;pages=1-14&amp;doi=10.1109/tgrs.2024.3482473&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref027">
<span class="label">27.</span><cite>Sheng J, Zhou J, Wang J, Ye P, Fan J. Dualmamba: A lightweight spectral-spatial mamba-convolution network for hyperspectral image classification. IEEE Transactions on Geoscience and Remote Sensing. 2024.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Transactions%20on%20Geoscience%20and%20Remote%20Sensing&amp;title=Dualmamba:%20A%20lightweight%20spectral-spatial%20mamba-convolution%20network%20for%20hyperspectral%20image%20classification&amp;author=J%20Sheng&amp;author=J%20Zhou&amp;author=J%20Wang&amp;author=P%20Ye&amp;author=J%20Fan&amp;publication_year=2024&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref028">
<span class="label">28.</span><cite>Sherstinsky A. Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) network. Physica D: Nonlinear Phenomena. 2020;404:132306. doi: 10.1016/j.physd.2019.132306</cite> [<a href="https://doi.org/10.1016/j.physd.2019.132306" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Physica%20D:%20Nonlinear%20Phenomena&amp;title=Fundamentals%20of%20Recurrent%20Neural%20Network%20(RNN)%20and%20Long%20Short-Term%20Memory%20(LSTM)%20network&amp;author=A%20Sherstinsky&amp;volume=404&amp;publication_year=2020&amp;pages=132306&amp;doi=10.1016/j.physd.2019.132306&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref029">
<span class="label">29.</span><cite>Greff K, Srivastava RK, Koutnik J, Steunebrink BR, Schmidhuber J. LSTM: A Search Space Odyssey. IEEE Trans Neural Netw Learn Syst. 2017;28(10):2222–32. doi: 10.1109/TNNLS.2016.2582924

</cite> [<a href="https://doi.org/10.1109/TNNLS.2016.2582924" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27411231/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans%20Neural%20Netw%20Learn%20Syst&amp;title=LSTM:%20A%20Search%20Space%20Odyssey&amp;author=K%20Greff&amp;author=RK%20Srivastava&amp;author=J%20Koutnik&amp;author=BR%20Steunebrink&amp;author=J%20Schmidhuber&amp;volume=28&amp;issue=10&amp;publication_year=2017&amp;pages=2222-32&amp;pmid=27411231&amp;doi=10.1109/TNNLS.2016.2582924&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref030">
<span class="label">30.</span><cite>Yu Y, Si X, Hu C, Zhang J. A Review of Recurrent Neural Networks: LSTM Cells and Network Architectures. Neural Comput. 2019;31(7):1235–70. doi: 10.1162/neco_a_01199

</cite> [<a href="https://doi.org/10.1162/neco_a_01199" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31113301/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Neural%20Comput&amp;title=A%20Review%20of%20Recurrent%20Neural%20Networks:%20LSTM%20Cells%20and%20Network%20Architectures&amp;author=Y%20Yu&amp;author=X%20Si&amp;author=C%20Hu&amp;author=J%20Zhang&amp;volume=31&amp;issue=7&amp;publication_year=2019&amp;pages=1235-70&amp;pmid=31113301&amp;doi=10.1162/neco_a_01199&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref031">
<span class="label">31.</span><cite>Rigatti SJ. Random forest. Journal of Insurance Medicine. 2017;47(1):31–9.
</cite> [<a href="https://doi.org/10.17849/insm-47-01-31-39.1" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/28836909/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Journal%20of%20Insurance%20Medicine&amp;title=Random%20forest&amp;author=SJ%20Rigatti&amp;volume=47&amp;issue=1&amp;publication_year=2017&amp;pages=31-9&amp;pmid=28836909&amp;doi=10.17849/insm-47-01-31-39.1&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref032">
<span class="label">32.</span><cite>Xu Y, Hu X, Gong J, Huang X, Li J. Deep Learning Training with Unbalance Sample Distribution for Remote Sensing Image Segmentation. The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences. 2022;43(2022):223–8.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=The%20International%20Archives%20of%20the%20Photogrammetry,%20Remote%20Sensing%20and%20Spatial%20Information%20Sciences&amp;title=Deep%20Learning%20Training%20with%20Unbalance%20Sample%20Distribution%20for%20Remote%20Sensing%20Image%20Segmentation&amp;author=Y%20Xu&amp;author=X%20Hu&amp;author=J%20Gong&amp;author=X%20Huang&amp;author=J%20Li&amp;volume=43&amp;issue=2022&amp;publication_year=2022&amp;pages=223-8&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref033">
<span class="label">33.</span><cite>Fernandez A, Garcia S, Herrera F, Chawla NV. SMOTE for Learning from Imbalanced Data: Progress and Challenges, Marking the 15-year Anniversary. jair. 2018;61:863–905. doi: 10.1613/jair.1.11192</cite> [<a href="https://doi.org/10.1613/jair.1.11192" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=jair&amp;title=SMOTE%20for%20Learning%20from%20Imbalanced%20Data:%20Progress%20and%20Challenges,%20Marking%20the%2015-year%20Anniversary&amp;author=A%20Fernandez&amp;author=S%20Garcia&amp;author=F%20Herrera&amp;author=NV%20Chawla&amp;volume=61&amp;publication_year=2018&amp;pages=863-905&amp;doi=10.1613/jair.1.11192&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330678.ref034">
<span class="label">34.</span><cite>Li Y, Zhang H, Shen Q. Spectral–Spatial Classification of Hyperspectral Imagery with 3D Convolutional Neural Network. Remote Sensing. 2017;9(1):67. doi: 10.3390/rs9010067</cite> [<a href="https://doi.org/10.3390/rs9010067" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Remote%20Sensing&amp;title=Spectral%E2%80%93Spatial%20Classification%20of%20Hyperspectral%20Imagery%20with%203D%20Convolutional%20Neural%20Network&amp;author=Y%20Li&amp;author=H%20Zhang&amp;author=Q%20Shen&amp;volume=9&amp;issue=1&amp;publication_year=2017&amp;pages=67&amp;doi=10.3390/rs9010067&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adda93_" lang="en" class="data-availability-statement"><h3 class="pmc_sec_title">Data Availability Statement</h3>
<p>All relevant data are in the manuscript and its supporting information files. Indian Pines, Salinas, Pavia University and Pavia Centre are available by visiting the following links: <a href="http://www.ehu.eus/ccwintco/index.php?title=Hyperspectral_Remote_Sensing_ScenesHouston2013" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://www.ehu.eus/ccwintco/index.php?title=Hyperspectral_Remote_Sensing_ScenesHouston2013</a> set of data can be accessed through the following link to obtain: <a href="https://github.com/songyz2019/fetch_houston2013" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/songyz2019/fetch_houston2013</a> Augsburg data set can be accessed through the following links for: <a href="https://github.com/danfenghong/ISPRS_S2FL" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/danfenghong/ISPRS_S2FL</a> These datasets were instrumental in supporting the experimental validation and analysis presented in this work.</p></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from PLOS One are provided here courtesy of <strong>PLOS</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1371/journal.pone.0330678"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/pone.0330678.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (2.5 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12370145/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12370145/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12370145%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370145/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12370145/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12370145/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40839574/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12370145/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40839574/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12370145/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12370145/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="j4GLxQNjq0UFHUPxYBw8w84svn4IAagO00wB9nSTbFe518XldMyx4lrZJK4UpSSq">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
        <script type="module" crossorigin="" src="/static/assets/math-574fdcc6.js"></script>
    
    

    </body>
</html>
