
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            Spacetop: A multimodal fMRI dataset unifying naturalistic processes with a rich array of experimental tasks - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="AE532D3A8AF202F3052D3A0022490D46.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="sdata">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373947/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="Scientific Data">
<meta name="citation_title" content="Spacetop: A multimodal fMRI dataset unifying naturalistic processes with a rich array of experimental tasks">
<meta name="citation_author" content="Heejung Jung">
<meta name="citation_author_institution" content="Dartmouth College, Hanover, NH USA">
<meta name="citation_author" content="Maryam Amini">
<meta name="citation_author_institution" content="Dartmouth College, Hanover, NH USA">
<meta name="citation_author" content="Bethany J Hunt">
<meta name="citation_author_institution" content="Dartmouth College, Hanover, NH USA">
<meta name="citation_author" content="Eilis I Murphy">
<meta name="citation_author_institution" content="Dartmouth College, Hanover, NH USA">
<meta name="citation_author" content="Patrick Sadil">
<meta name="citation_author_institution" content="Johns Hopkins University, Baltimore, MD USA">
<meta name="citation_author" content="Yaroslav O Halchenko">
<meta name="citation_author_institution" content="Dartmouth College, Hanover, NH USA">
<meta name="citation_author" content="Bogdan Petre">
<meta name="citation_author_institution" content="Dartmouth College, Hanover, NH USA">
<meta name="citation_author" content="Zizhuang Miao">
<meta name="citation_author_institution" content="Dartmouth College, Hanover, NH USA">
<meta name="citation_author" content="Philip A Kragel">
<meta name="citation_author_institution" content="Emory University, Atlanta, GA USA">
<meta name="citation_author" content="Xiaochun Han">
<meta name="citation_author_institution" content="Beijing Normal University, Beijing, China">
<meta name="citation_author" content="Mickela O Heilicher">
<meta name="citation_author_institution" content="University of Wisconsin-Madison, Madison, WI USA">
<meta name="citation_author" content="Michael Sun">
<meta name="citation_author_institution" content="Dartmouth College, Hanover, NH USA">
<meta name="citation_author" content="Owen G Collins">
<meta name="citation_author_institution" content="University of California, Irvine, CA USA">
<meta name="citation_author" content="Martin A Lindquist">
<meta name="citation_author_institution" content="Johns Hopkins University, Baltimore, MD USA">
<meta name="citation_author" content="Tor D Wager">
<meta name="citation_author_institution" content="Dartmouth College, Hanover, NH USA">
<meta name="citation_publication_date" content="2025 Aug 22">
<meta name="citation_volume" content="12">
<meta name="citation_firstpage" content="1465">
<meta name="citation_doi" content="10.1038/s41597-025-05154-x">
<meta name="citation_pmid" content="40846708">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373947/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373947/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373947/pdf/41597_2025_Article_5154.pdf">
<meta name="description" content="Cognitive neuroscience has advanced significantly due to the availability of openly shared datasets. Large sample sizes, large amounts of data per person, and diversity in tasks and data types are all desirable, but are difficult to achieve in a ...">
<meta name="og:title" content="Spacetop: A multimodal fMRI dataset unifying naturalistic processes with a rich array of experimental tasks">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="Cognitive neuroscience has advanced significantly due to the availability of openly shared datasets. Large sample sizes, large amounts of data per person, and diversity in tasks and data types are all desirable, but are difficult to achieve in a ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373947/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12373947">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1038/s41597-025-05154-x"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/41597_2025_Article_5154.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12373947%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12373947/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12373947/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373947/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-sdata.jpg" alt="Scientific Data logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to Scientific Data" title="Link to Scientific Data" shape="default" href="http://www.nature.com/sdata/" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">Sci Data</button></div>. 2025 Aug 22;12:1465. doi: <a href="https://doi.org/10.1038/s41597-025-05154-x" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1038/s41597-025-05154-x</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22Sci%20Data%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sci%20Data%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22Sci%20Data%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22Sci%20Data%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Spacetop: A multimodal fMRI dataset unifying naturalistic processes with a rich array of experimental tasks</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Jung%20H%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Heejung Jung</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Heejung Jung</span></h3>
<div class="p">
<sup>1</sup>Dartmouth College, Hanover, NH USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Jung%20H%22%5BAuthor%5D" class="usa-link"><span class="name western">Heejung Jung</span></a>
</div>
</div>
<sup>1,</sup><sup>✉</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Amini%20M%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Maryam Amini</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">Maryam Amini</span></h3>
<div class="p">
<sup>1</sup>Dartmouth College, Hanover, NH USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Amini%20M%22%5BAuthor%5D" class="usa-link"><span class="name western">Maryam Amini</span></a>
</div>
</div>
<sup>1,</sup><sup>#</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Hunt%20BJ%22%5BAuthor%5D" class="usa-link" aria-describedby="id3"><span class="name western">Bethany J Hunt</span></a><div hidden="hidden" id="id3">
<h3><span class="name western">Bethany J Hunt</span></h3>
<div class="p">
<sup>1</sup>Dartmouth College, Hanover, NH USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Hunt%20BJ%22%5BAuthor%5D" class="usa-link"><span class="name western">Bethany J Hunt</span></a>
</div>
</div>
<sup>1,</sup><sup>#</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Murphy%20EI%22%5BAuthor%5D" class="usa-link" aria-describedby="id4"><span class="name western">Eilis I Murphy</span></a><div hidden="hidden" id="id4">
<h3><span class="name western">Eilis I Murphy</span></h3>
<div class="p">
<sup>1</sup>Dartmouth College, Hanover, NH USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Murphy%20EI%22%5BAuthor%5D" class="usa-link"><span class="name western">Eilis I Murphy</span></a>
</div>
</div>
<sup>1,</sup><sup>#</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sadil%20P%22%5BAuthor%5D" class="usa-link" aria-describedby="id5"><span class="name western">Patrick Sadil</span></a><div hidden="hidden" id="id5">
<h3><span class="name western">Patrick Sadil</span></h3>
<div class="p">
<sup>2</sup>Johns Hopkins University, Baltimore, MD USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sadil%20P%22%5BAuthor%5D" class="usa-link"><span class="name western">Patrick Sadil</span></a>
</div>
</div>
<sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Halchenko%20YO%22%5BAuthor%5D" class="usa-link" aria-describedby="id6"><span class="name western">Yaroslav O Halchenko</span></a><div hidden="hidden" id="id6">
<h3><span class="name western">Yaroslav O Halchenko</span></h3>
<div class="p">
<sup>1</sup>Dartmouth College, Hanover, NH USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Halchenko%20YO%22%5BAuthor%5D" class="usa-link"><span class="name western">Yaroslav O Halchenko</span></a>
</div>
</div>
<sup>1</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Petre%20B%22%5BAuthor%5D" class="usa-link" aria-describedby="id7"><span class="name western">Bogdan Petre</span></a><div hidden="hidden" id="id7">
<h3><span class="name western">Bogdan Petre</span></h3>
<div class="p">
<sup>1</sup>Dartmouth College, Hanover, NH USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Petre%20B%22%5BAuthor%5D" class="usa-link"><span class="name western">Bogdan Petre</span></a>
</div>
</div>
<sup>1</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Miao%20Z%22%5BAuthor%5D" class="usa-link" aria-describedby="id8"><span class="name western">Zizhuang Miao</span></a><div hidden="hidden" id="id8">
<h3><span class="name western">Zizhuang Miao</span></h3>
<div class="p">
<sup>1</sup>Dartmouth College, Hanover, NH USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Miao%20Z%22%5BAuthor%5D" class="usa-link"><span class="name western">Zizhuang Miao</span></a>
</div>
</div>
<sup>1</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kragel%20PA%22%5BAuthor%5D" class="usa-link" aria-describedby="id9"><span class="name western">Philip A Kragel</span></a><div hidden="hidden" id="id9">
<h3><span class="name western">Philip A Kragel</span></h3>
<div class="p">
<sup>3</sup>Emory University, Atlanta, GA USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kragel%20PA%22%5BAuthor%5D" class="usa-link"><span class="name western">Philip A Kragel</span></a>
</div>
</div>
<sup>3</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Han%20X%22%5BAuthor%5D" class="usa-link" aria-describedby="id10"><span class="name western">Xiaochun Han</span></a><div hidden="hidden" id="id10">
<h3><span class="name western">Xiaochun Han</span></h3>
<div class="p">
<sup>4</sup>Beijing Normal University, Beijing, China </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Han%20X%22%5BAuthor%5D" class="usa-link"><span class="name western">Xiaochun Han</span></a>
</div>
</div>
<sup>4</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Heilicher%20MO%22%5BAuthor%5D" class="usa-link" aria-describedby="id11"><span class="name western">Mickela O Heilicher</span></a><div hidden="hidden" id="id11">
<h3><span class="name western">Mickela O Heilicher</span></h3>
<div class="p">
<sup>5</sup>University of Wisconsin-Madison, Madison, WI USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Heilicher%20MO%22%5BAuthor%5D" class="usa-link"><span class="name western">Mickela O Heilicher</span></a>
</div>
</div>
<sup>5</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sun%20M%22%5BAuthor%5D" class="usa-link" aria-describedby="id12"><span class="name western">Michael Sun</span></a><div hidden="hidden" id="id12">
<h3><span class="name western">Michael Sun</span></h3>
<div class="p">
<sup>1</sup>Dartmouth College, Hanover, NH USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sun%20M%22%5BAuthor%5D" class="usa-link"><span class="name western">Michael Sun</span></a>
</div>
</div>
<sup>1</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Collins%20OG%22%5BAuthor%5D" class="usa-link" aria-describedby="id13"><span class="name western">Owen G Collins</span></a><div hidden="hidden" id="id13">
<h3><span class="name western">Owen G Collins</span></h3>
<div class="p">
<sup>6</sup>University of California, Irvine, CA USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Collins%20OG%22%5BAuthor%5D" class="usa-link"><span class="name western">Owen G Collins</span></a>
</div>
</div>
<sup>6</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Lindquist%20MA%22%5BAuthor%5D" class="usa-link" aria-describedby="id14"><span class="name western">Martin A Lindquist</span></a><div hidden="hidden" id="id14">
<h3><span class="name western">Martin A Lindquist</span></h3>
<div class="p">
<sup>2</sup>Johns Hopkins University, Baltimore, MD USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Lindquist%20MA%22%5BAuthor%5D" class="usa-link"><span class="name western">Martin A Lindquist</span></a>
</div>
</div>
<sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Wager%20TD%22%5BAuthor%5D" class="usa-link" aria-describedby="id15"><span class="name western">Tor D Wager</span></a><div hidden="hidden" id="id15">
<h3><span class="name western">Tor D Wager</span></h3>
<div class="p">
<sup>1</sup>Dartmouth College, Hanover, NH USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Wager%20TD%22%5BAuthor%5D" class="usa-link"><span class="name western">Tor D Wager</span></a>
</div>
</div>
<sup>1,</sup><sup>✉</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="Aff1">
<sup>1</sup>Dartmouth College, Hanover, NH USA </div>
<div id="Aff2">
<sup>2</sup>Johns Hopkins University, Baltimore, MD USA </div>
<div id="Aff3">
<sup>3</sup>Emory University, Atlanta, GA USA </div>
<div id="Aff4">
<sup>4</sup>Beijing Normal University, Beijing, China </div>
<div id="Aff5">
<sup>5</sup>University of Wisconsin-Madison, Madison, WI USA </div>
<div id="Aff6">
<sup>6</sup>University of California, Irvine, CA USA </div>
<div class="author-notes p">
<div class="fn" id="_fncrsp93pmc__">
<sup>✉</sup><p class="display-inline">Corresponding author.</p>
</div>
<div class="fn" id="_eqcntrb93pmc__">
<sup>#</sup><p class="display-inline">Contributed equally.</p>
</div>
</div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2024 Dec 2; Accepted 2025 May 8; Collection date 2025.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© The Author(s) 2025</div>
<p><strong>Open Access</strong> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="https://creativecommons.org/licenses/by/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://creativecommons.org/licenses/by/4.0/</a>.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12373947  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40846708/" class="usa-link">40846708</a>
</div>
<div class="ra xbox p" role="complementary" aria-label="Related or updated information about this article"><div>
<strong>Previous version available:</strong> This article is based on a previously available preprint posted on bioRxiv on June 26, 2024: "<a href="/articles/PMC11230225/" class="usa-link">
A multimodal fMRI dataset unifying naturalistic processes with a rich array of experimental tasks
</a>".</div></div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="Abs1"><h2>Abstract</h2>
<p id="Par1">Cognitive neuroscience has advanced significantly due to the availability of openly shared datasets. Large sample sizes, large amounts of data per person, and diversity in tasks and data types are all desirable, but are difficult to achieve in a single dataset. Here, we present an open dataset with N = 101 participants and 6 hours of scanning per participant, including 6 multifaceted functional tasks, 2 hours of naturalistic movie viewing, structural T1 images and multi-shell diffusion imaging as well as autonomic physiological data. This dataset’s combination of sample size, extensive data per participant (&gt;600 iso-hours of data), and a wide range of experimental conditions — including cognitive, affective, social, and somatic/interoceptive tasks — positions it uniquely for probing important questions in cognitive neuroscience.</p>
<section id="kwd-group1" class="kwd-group"><p><strong>Subject terms:</strong> Perception, Language, Decision</p></section></section><section id="Sec1"><h2 class="pmc_sec_title">Background &amp; Summary</h2>
<p id="Par2">Neuroimaging has significantly advanced our understanding of the dynamics of the human mind, specifically at the macroscale level. This progress – which nicely complements human behavioral studies and animal models of micro-meso scale neuroscience – is driven by developments in analytic methods, the high quality of imaging data, the increase in practices of sharing open datasets, and extensive data collection efforts. In large scale studies, two primary approaches are employed: either sampling a large number of participants to enhance statistical power for group average analyses (increasing between-subject sampling) or collecting extended hours within participants to better detect specific processes (increasing within-subject sampling)<sup><a href="#CR1" class="usa-link" aria-describedby="CR1">1</a></sup>. Here, leveraging both between-subject and within-subject sampling, we introduce “Spacetop” – a dataset that adeptly balances a large sample size of 101 participants with 6 hours worth of neuroimaging data per participant. Originally developed for functional alignment of individuals via naturalistic movie data and modeling of topological brain spaces across diverse cognitive tasks, this dataset is positioned to deepen our understanding of individual brain function, and also highlight individual differences in cognitive processes, given the statistical power that this dataset offers.</p>
<p id="Par3">Another line of consideration in data collection has been the choice between naturalistic and experimental paradigms. Recently, naturalistic stimuli have proven invaluable for scientific advances in the neuroimaging community<sup><a href="#CR2" class="usa-link" aria-describedby="CR2">2</a>–<a href="#CR4" class="usa-link" aria-describedby="CR4">4</a></sup>, providing rich contexts for exploring a wide range of features from perceptional, situational, to abstract conceptual levels. They offer ecological validity, enabling deeper insights into sensory perception or abstract processing, as the meaning of a stimulus unfolds in a dynamic context in the real world. For example, research in behavioral neuroscience reveals that even robust findings in the primary visual cortex (V1) demonstrate different tuning profiles towards naturalistic movie stimuli and non-naturalistic Gabor filters<sup><a href="#CR5" class="usa-link" aria-describedby="CR5">5</a></sup>. This suggests that the neural mechanisms of natural vision may differ from our scientific understanding of vision, due to the large dependence on highly controlled experiments. To further illustrate this notion, studies using naturalistic speech narratives uncover distributed representations of semantic knowledge, contrary to past findings of lateralization in semantic knowledge<sup><a href="#CR6" class="usa-link" aria-describedby="CR6">6</a></sup>. However, it is important to note the inherent challenges of these naturalistic approaches, as they often yield noisier parameters and require complex modeling approaches compared to traditional experimental designs.</p>
<p id="Par4">For these reasons, experimental designs are indeed crucial to understanding human brain function. In fact, causal relationships of treatment effects are only guaranteed through manipulation and randomization of variables<sup><a href="#CR7" class="usa-link" aria-describedby="CR7">7</a>–<a href="#CR10" class="usa-link" aria-describedby="CR10">10</a></sup>. A well-defined parameter space in experiments allows for testing specific hypotheses, developing precise models, and increasing efficiency and statistical power. The rigor and precision of experimental designs are precisely why they are considered the gold standard in biomedical science and why regulatory agencies require randomized controlled trials for drug approvals. These designs effectively isolate the variables of interest and minimize the influence of confound variables. As is well known, fMRI data, specifically the Blood Oxygen Level-Dependent (BOLD) response, is delayed and cumulative in nature compared to neural activity, thereby complicating signal attribution to a variable of interest. However, extensive research on the signal profile in tandem with optimized experimental designs<sup><a href="#CR11" class="usa-link" aria-describedby="CR11">11</a>–<a href="#CR13" class="usa-link" aria-describedby="CR13">13</a></sup> have mitigated these limitations, enhancing the accuracy of interpretations of the defined parameter space, driving advancements in human neuroimaging for decades.</p>
<p id="Par5">By integrating both naturalistic and experimental stimuli, we are able to uncover common neural properties that bridge the gap between ecologically valid contexts and experimentally controlled conditions. This integrated approach in past studies has led to significant insights. For example, in an fMRI study on action perception, researchers find several visual processing regions that are consistently activated for both static and dynamic conditions, indicating invariance to form or presentation modality<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a></sup>. Similarly, a study on numerical processing using electrocorticography<sup><a href="#CR15" class="usa-link" aria-describedby="CR15">15</a></sup> revealed that the intraparietal sulcus, active in numeracy tasks in experimental settings, are also active during social conversations in naturalistic settings involving numerical concepts. This combined approach not only identifies the homology between the two different settings, but also highlights the subtle distinctions inherent in each process, offering a more holistic understanding of human brain functions.</p>
<p id="Par6">Harnessing the power of both approaches, our dataset includes 120 minutes of naturalistic movie data and audio narratives, complemented by subjective ratings from participants, and a range of experimental tasks, including somatic, social, cognitive, and affective experimental conditions. Such an approach leverages both ecological validity and statistical power. We envision this dual approach to serve as a versatile tool for probing brain function (For a comparative overview of this dataset in relation to other large scale datasets, see Table <a href="#Tab1" class="usa-link">1</a>).</p>
<section class="tw xbox font-sm" id="Tab1"><h3 class="obj_head">Table 1.</h3>
<div class="caption p"><p>Comparison of major open fMRI datasets.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead>
<tr>
<th align="left" rowspan="2" colspan="1">Dataset</th>
<th align="left" colspan="3" rowspan="1">Between-/Within-Subjects</th>
<th align="left" colspan="2" rowspan="1">Task Type</th>
<th align="left" colspan="2" rowspan="1">Data Type</th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1">Functional Isohours</th>
<th align="left" colspan="1" rowspan="1"># of Subjects</th>
<th align="left" colspan="1" rowspan="1">Hours per Subject</th>
<th align="left" colspan="1" rowspan="1"># of fMRI Tasks</th>
<th align="left" colspan="1" rowspan="1">Naturalistic or Experimental</th>
<th align="left" colspan="1" rowspan="1">Somatic Pain</th>
<th align="left" colspan="1" rowspan="1">Physiological Data</th>
</tr>
<tr>
<th colspan="1" rowspan="1">Spacetop</th>
<th colspan="1" rowspan="1">606</th>
<th colspan="1" rowspan="1">101</th>
<th colspan="1" rowspan="1">6</th>
<th colspan="1" rowspan="1">9</th>
<th colspan="1" rowspan="1">Both</th>
<th colspan="1" rowspan="1">Yes</th>
<th colspan="1" rowspan="1">Yes</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="1" rowspan="1">BioBank</td>
<td colspan="1" rowspan="1">0.1</td>
<td colspan="1" rowspan="1">500,000</td>
<td colspan="1" rowspan="1">0.1</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">Resting-state/Experimental</td>
<td colspan="1" rowspan="1">No</td>
<td colspan="1" rowspan="1">No</td>
</tr>
<tr>
<td colspan="1" rowspan="1">ABCD</td>
<td colspan="1" rowspan="1">2,000</td>
<td colspan="1" rowspan="1">10,000</td>
<td colspan="1" rowspan="1">0.5</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">Experimental</td>
<td colspan="1" rowspan="1">No</td>
<td colspan="1" rowspan="1">No</td>
</tr>
<tr>
<td colspan="1" rowspan="1">HCP</td>
<td colspan="1" rowspan="1">3,300</td>
<td colspan="1" rowspan="1">1,200</td>
<td colspan="1" rowspan="1">2.75</td>
<td colspan="1" rowspan="1">7</td>
<td colspan="1" rowspan="1">Experimental</td>
<td colspan="1" rowspan="1">No</td>
<td colspan="1" rowspan="1">No</td>
</tr>
<tr>
<td colspan="1" rowspan="1">SuperStruct</td>
<td colspan="1" rowspan="1">314</td>
<td colspan="1" rowspan="1">1,570</td>
<td colspan="1" rowspan="1">0.2</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">Resting-state</td>
<td colspan="1" rowspan="1">No</td>
<td colspan="1" rowspan="1">No</td>
</tr>
<tr>
<td colspan="1" rowspan="1">NSD</td>
<td colspan="1" rowspan="1">320</td>
<td colspan="1" rowspan="1">8</td>
<td colspan="1" rowspan="1">40</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">Experimental</td>
<td colspan="1" rowspan="1">No</td>
<td colspan="1" rowspan="1">No</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Narratives</td>
<td colspan="1" rowspan="1">345</td>
<td colspan="1" rowspan="1">345</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">Naturalistic</td>
<td colspan="1" rowspan="1">No</td>
<td colspan="1" rowspan="1">No</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Midnight Scan Club</td>
<td colspan="1" rowspan="1">110</td>
<td colspan="1" rowspan="1">10</td>
<td colspan="1" rowspan="1">11</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">Experimental</td>
<td colspan="1" rowspan="1">No</td>
<td colspan="1" rowspan="1">No</td>
</tr>
<tr>
<td colspan="1" rowspan="1">BOLD5000</td>
<td colspan="1" rowspan="1">96</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">24</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">Experimental</td>
<td colspan="1" rowspan="1">No</td>
<td colspan="1" rowspan="1">No</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="_fn_p8"><p>This dataset uniquely positions itself amongst a selection of notable publicly available neuroimaging datasets. There are many great open datasets, majority shared on OpenNeuro, amounting to 1,300 public datasets. A subset of the datasets are summarized here for comparison, based on key examples referenced in Naselaris and colleagues<sup><a href="#CR1" class="usa-link" aria-describedby="CR1">1</a></sup>, who summarized datasets based on the distribution of within/between-subjects of each dataset. Summary of nine publicly available neuroimaging datasets, comparing scale, experimental design, and inclusion of pain- or physiology-related data is listed in the table. <strong>Functional isohours</strong> refers to the approximate total number of functional scanning hours across subjects, i.e. multiplication of <strong>of Subjects</strong> and Hours per subject. <strong>Hours per subject</strong> indicates the average duration of fMRI data collected per participant. For further details on openly shared datasets, please see Botvinik-Nezer and Wager (2024).</p></div></div></section><p id="Par7">One primary use case of this dataset, Spacetop, would be to develop functional alignment techniques to address the challenges of individual differences in neuroimaging. Alignment methods<sup><a href="#CR16" class="usa-link" aria-describedby="CR16">16</a></sup>, such as hyperalignment, connectivity alignment, and shared response models, provide solutions to narrow the gap across individuals and help uncover group-level neural processes. Since using functional training data from the same individuals is essential for implementing these techniques effectively, the 90 minutes of movie data provides an ideal test environment. Additionally, the inclusion of experimental tasks allows for rigorous test comparisons between different functional alignment methods, while allowing for an opportunity to establish convergent construct validity between experimental and naturalistic tasks.</p></section><section id="Sec2"><h2 class="pmc_sec_title">Methods</h2>
<section id="Sec3"><h3 class="pmc_sec_title">Participants</h3>
<p id="Par8">This dataset includes 101 adult participants (mean ± s.d. age: 24.7 ± 5.5 years; 69 males, 45 females, 2 others). Data were collected from December 2020 to July 2022 at the Dartmouth Brain Imaging Center. Participants were healthy individuals, with normal or corrected-to-normal vision and hearing, no recent psychiatric or neurological diagnoses within the past six months, no MRI contraindications, and no chronic pain. We determined eligibility via a general health questionnaire, a pain safety screening form, and an MRI safety screening form. Additionally, individuals with self-reported chronic pain who anticipated discomfort while lying in an MRI scanner were not enrolled. All participants were right handed. Participants were recruited from the area of New Hampshire and Vermont as well as the Dartmouth college student body. The institutional review board (IRB) of Dartmouth College approved to conduct the study and share the data (CPHS STUDY00031937), and all participants provided written consent. The consent form included a section on data sharing, which explicitly states that deidentified data may be shared via a publicly available data archive. In addition, participants were informed that, for all potentially shared data, every reasonable effort would be made to remove identifiers from the data that would indicate any connection to the participant. Participants reconsented for each visit. A consort diagram is included to illustrate the enrollment and study attrition rate across four sessions (Fig. <a href="#Fig1" class="usa-link">1</a>).</p>
<figure class="fig xbox font-sm" id="Fig1"><h4 class="obj_head">Fig. 1.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2fa4/12373947/691d21e86190/41597_2025_5154_Fig1_HTML.jpg" loading="lazy" id="d33e587" height="462" width="633" alt="Fig. 1"></p>
<div class="p text-right font-secondary"><a href="figure/Fig1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Consort diagram. A total of 185 participants enrolled in the study. Of these, 116 participants completed session 1, 106 completed session 2, and 102 completed session 3. A total of 101 participants completed all four sessions.</p></figcaption></figure></section><section id="Sec4"><h3 class="pmc_sec_title">Overview of experimental procedures</h3>
<p id="Par9">This dataset includes multimodal data from four in-person neuroimaging sessions and an at-home questionnaire survey session. Upon arrival for each in-person neuroimaging session, participants were invited to a separate behavioral testing facility to complete a behavioral informational session, where they signed consent forms and then had scripted task instructions read to them, accompanied by visual aids of upcoming tasks. Participants then completed a behavioral practice task on a computer to reinforce their understanding of the task. After the behavioral information session, participants were invited to the MRI scanning facility, in which they completed experimental tasks with concurrent fMRI and physiological recordings of skin conductance and photoplethysmography (Fig. <a href="#Fig2" class="usa-link">2</a>; see Table <a href="#Tab2" class="usa-link">2</a> for imaging acquisition parameters). Participants completed at-home surveys prior to the first incoming scan session. These surveys primarily assessed general psychosocial tendencies, with the aim to link them with behavioral, physiological, and neural responses observed during the neuroimaging experiments (Table <a href="#Tab3" class="usa-link">3</a>).</p>
<figure class="fig xbox font-sm" id="Fig2"><h4 class="obj_head">Fig. 2.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373947_41597_2025_5154_Fig2_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2fa4/12373947/01f8e9d7fe34/41597_2025_5154_Fig2_HTML.jpg" loading="lazy" id="d33e611" height="265" width="698" alt="Fig. 2"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Overview of acquired data. Dataset includes N = 101 participants worth of data, including (<em>clockwise</em>): 1) functional BOLD echo-planar imaging with cognitive tasks (TR = 460 msec, MB = 8), 2) a T1-weighted anatomical scan, 3) a multi-shell diffusion weighted MRI (dMRI) scan, 4) a battery of questionnaires prior to scanning, 5) physiological data collected during scanning, and 4) behavioral data collected during scanning.</p></figcaption></figure><section class="tw xbox font-sm" id="Tab2"><h4 class="obj_head">Table 2.</h4>
<div class="caption p"><p>Description of imaging acquisition parameters.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Features</th>
<th align="left" colspan="1" rowspan="1">Main Task</th>
<th align="left" colspan="1" rowspan="1">T1w</th>
<th align="left" colspan="1" rowspan="1">DWI</th>
<th align="left" colspan="1" rowspan="1">Distortion Correction</th>
</tr></thead>
<tbody>
<tr>
<td colspan="1" rowspan="1">Resolution [mm]</td>
<td colspan="1" rowspan="1">2.7 (iso)</td>
<td colspan="1" rowspan="1">0.8 (iso)</td>
<td colspan="1" rowspan="1">1.7 (iso)</td>
<td colspan="1" rowspan="1">2.7 (iso)</td>
</tr>
<tr>
<td colspan="1" rowspan="1"># Volumes</td>
<td colspan="1" rowspan="1">Varies per task</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">2</td>
</tr>
<tr>
<td colspan="1" rowspan="1">FOV [mm]</td>
<td colspan="1" rowspan="1">220</td>
<td colspan="1" rowspan="1">256</td>
<td colspan="1" rowspan="1">240</td>
<td colspan="1" rowspan="1">220</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Matrix Size</td>
<td colspan="1" rowspan="1">82 × 82</td>
<td colspan="1" rowspan="1">320 × 320</td>
<td colspan="1" rowspan="1">130 × 130</td>
<td colspan="1" rowspan="1">82 × 82</td>
</tr>
<tr>
<td colspan="1" rowspan="1">TR [s]</td>
<td colspan="1" rowspan="1">0.46</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">4.11</td>
<td colspan="1" rowspan="1">7.22</td>
</tr>
<tr>
<td colspan="1" rowspan="1">TE [ms]</td>
<td colspan="1" rowspan="1">27.20</td>
<td colspan="1" rowspan="1">2.11</td>
<td colspan="1" rowspan="1">88.40</td>
<td colspan="1" rowspan="1">73.00</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Flip Angle [degree]</td>
<td colspan="1" rowspan="1">44<sup>°</sup>
</td>
<td colspan="1" rowspan="1">8<sup>°</sup>
</td>
<td colspan="1" rowspan="1">90<sup>°</sup>
</td>
<td colspan="1" rowspan="1">90<sup>°</sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Slice Orientation</td>
<td colspan="1" rowspan="1">Transversal</td>
<td colspan="1" rowspan="1">Sagittal</td>
<td colspan="1" rowspan="1">Transversal</td>
<td colspan="1" rowspan="1">Transversal</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Phase Encoding Direction</td>
<td colspan="1" rowspan="1">A &gt;&gt; P</td>
<td colspan="1" rowspan="1">A &gt;&gt; P</td>
<td colspan="1" rowspan="1">A &gt;&gt; P</td>
<td colspan="1" rowspan="1">A &gt;&gt; P</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Number of Slices</td>
<td colspan="1" rowspan="1">56</td>
<td colspan="1" rowspan="1">224</td>
<td colspan="1" rowspan="1">81</td>
<td colspan="1" rowspan="1">56</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Slice Thickness [mm]</td>
<td colspan="1" rowspan="1">2.7</td>
<td colspan="1" rowspan="1">0.8</td>
<td colspan="1" rowspan="1">1.7</td>
<td colspan="1" rowspan="1">2.7</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Distance Factor [%]</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">50</td>
<td colspan="1" rowspan="1">0</td>
<td colspan="1" rowspan="1">0</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Order of Slice Acquisition</td>
<td colspan="1" rowspan="1">Interleaved</td>
<td colspan="1" rowspan="1">Interleaved</td>
<td colspan="1" rowspan="1">Interleaved</td>
<td colspan="1" rowspan="1">Interleaved</td>
</tr>
<tr>
<td colspan="1" rowspan="1">iPAT mode</td>
<td colspan="1" rowspan="1">none</td>
<td colspan="1" rowspan="1">GRAPPA</td>
<td colspan="1" rowspan="1">none</td>
<td colspan="1" rowspan="1">none</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Multiband Acceleration Factor</td>
<td colspan="1" rowspan="1">8</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">1</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Bandwidth [Hz/px]</td>
<td colspan="1" rowspan="1">3048</td>
<td colspan="1" rowspan="1">240</td>
<td colspan="1" rowspan="1">1700</td>
<td colspan="1" rowspan="1">3048</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><section class="tw xbox font-sm" id="Tab3"><h4 class="obj_head">Table 3.</h4>
<div class="caption p"><p>Description of questionnaires.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Name of instrument</th>
<th align="left" colspan="1" rowspan="1">Description</th>
<th align="left" colspan="1" rowspan="1">Primary source</th>
</tr></thead>
<tbody>
<tr><td align="left" colspan="3" rowspan="1"><strong>Online Behavioral Surveys</strong></td></tr>
<tr>
<td colspan="1" rowspan="1">a) Demographics survey</td>
<td colspan="1" rowspan="1">Demographics</td>
<td colspan="1" rowspan="1">Internal Survey</td>
</tr>
<tr>
<td colspan="1" rowspan="1">b) Jessor Demographics</td>
<td colspan="1" rowspan="1">Demographics</td>
<td colspan="1" rowspan="1">Internal Survey</td>
</tr>
<tr>
<td colspan="1" rowspan="1">c) Multidimensional Assessment of Interoceptive Awareness (MAIA-32)</td>
<td colspan="1" rowspan="1">Interoception</td>
<td colspan="1" rowspan="1">Mehling <em>et al</em>.<sup><a href="#CR57" class="usa-link" aria-describedby="CR57">57</a></sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">d) PROMIS-57 Profile v2.1</td>
<td colspan="1" rowspan="1">Physical function, anxiety, depression, and pain</td>
<td colspan="1" rowspan="1">Cella <em>et al</em>.<sup><a href="#CR58" class="usa-link" aria-describedby="CR58">58</a></sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">e) Canlab Pain Survey (Pain Symptoms)</td>
<td colspan="1" rowspan="1">Pain disorders or sensitivities</td>
<td colspan="1" rowspan="1">Internal Survey</td>
</tr>
<tr>
<td colspan="1" rowspan="1">f) Life Orientation Test Revised (LOT-R)</td>
<td colspan="1" rowspan="1">Trait levels of optimism and pessimism</td>
<td colspan="1" rowspan="1">Scheier <em>et al</em>.<sup><a href="#CR59" class="usa-link" aria-describedby="CR59">59</a></sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">g) Positive and Negative Affect Scale</td>
<td colspan="1" rowspan="1">Trait levels of positive and negative affect</td>
<td colspan="1" rowspan="1">Watson <em>et al</em>.<sup><a href="#CR60" class="usa-link" aria-describedby="CR60">60</a></sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">h) Fear of Pain (FOP)</td>
<td colspan="1" rowspan="1">Fear and anxiety associated with pain</td>
<td colspan="1" rowspan="1">McNeil &amp; Rainwater<sup><a href="#CR61" class="usa-link" aria-describedby="CR61">61</a></sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">i) Behavioral Inhibition/Behavioral Activation (BIS/BAS)</td>
<td colspan="1" rowspan="1">Trait levels of approach and avoidance behavior</td>
<td colspan="1" rowspan="1">Carver &amp; White<sup><a href="#CR62" class="usa-link" aria-describedby="CR62">62</a></sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">j) The “Big 5” Brief Inventory Brief Version</td>
<td colspan="1" rowspan="1">Various personality traits</td>
<td colspan="1" rowspan="1">Rammstedt &amp; John<sup><a href="#CR63" class="usa-link" aria-describedby="CR63">63</a></sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">k) Ego-Resiliency Scale (ER89)</td>
<td colspan="1" rowspan="1">Ability to respond adaptively and resourcefully to new situations</td>
<td colspan="1" rowspan="1">Block &amp; Kremen<sup><a href="#CR64" class="usa-link" aria-describedby="CR64">64</a></sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">l) Adverse Childhood Experience (ACE) Questionnaire</td>
<td colspan="1" rowspan="1">Childhood trauma (if any)</td>
<td colspan="1" rowspan="1">Felitti <em>et al</em>.<sup><a href="#CR65" class="usa-link" aria-describedby="CR65">65</a></sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">m) Marlow-Crowne Social Desirability Scale 13-Item Short Form</td>
<td colspan="1" rowspan="1">Social desirability</td>
<td colspan="1" rowspan="1">Crowne &amp; Marlowe<sup><a href="#CR66" class="usa-link" aria-describedby="CR66">66</a></sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">n) Interpersonal Reactivity Index (IRI)</td>
<td colspan="1" rowspan="1">Thoughts and feelings in a variety of situations</td>
<td colspan="1" rowspan="1">Davis<sup><a href="#CR67" class="usa-link" aria-describedby="CR67">67</a></sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">o) PhenX Alcohol Lifetime Use</td>
<td colspan="1" rowspan="1">Degree of lifetime alcohol use</td>
<td colspan="1" rowspan="1">PhenX Toolkit<sup><a href="#CR68" class="usa-link" aria-describedby="CR68">68</a></sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">p) PhenX Alcohol Age of First Use</td>
<td colspan="1" rowspan="1">Age of first alcohol use</td>
<td colspan="1" rowspan="1">”</td>
</tr>
<tr>
<td colspan="1" rowspan="1">q) PhenX Alcohol 30Day Quantity and Frequency</td>
<td colspan="1" rowspan="1">Quantity and frequency of alcohol use</td>
<td colspan="1" rowspan="1">”</td>
</tr>
<tr>
<td colspan="1" rowspan="1">r) PhenX Substances Lifetime Use</td>
<td colspan="1" rowspan="1">Degree of lifetime substance use</td>
<td colspan="1" rowspan="1">”</td>
</tr>
<tr>
<td colspan="1" rowspan="1">s) PhenX Substances Age of First Use</td>
<td colspan="1" rowspan="1">Age of first substance use</td>
<td colspan="1" rowspan="1">”</td>
</tr>
<tr>
<td colspan="1" rowspan="1">t) PhenX Substance 30 Day Frequency</td>
<td colspan="1" rowspan="1">Frequency of substance use</td>
<td colspan="1" rowspan="1">”</td>
</tr>
<tr>
<td colspan="1" rowspan="1">u) PhenX Cigarette Smoking Status Adult</td>
<td colspan="1" rowspan="1">Status of cigarette smoking</td>
<td colspan="1" rowspan="1">”</td>
</tr>
<tr>
<td colspan="1" rowspan="1">v) PhenX Tobacco Age of Initiation of Use Adolescent</td>
<td colspan="1" rowspan="1">Age of tobacco initiation</td>
<td colspan="1" rowspan="1">”</td>
</tr>
<tr>
<td colspan="1" rowspan="1">w) PhenX Tobacco 30 Day Frequency</td>
<td colspan="1" rowspan="1">Frequency of tobacco use</td>
<td colspan="1" rowspan="1">”</td>
</tr>
<tr>
<td colspan="1" rowspan="1">x) Self-Report Psychopathy Scale</td>
<td colspan="1" rowspan="1">Identification of psychopathic behaviors</td>
<td colspan="1" rowspan="1">Williams <em>et al</em>.<sup><a href="#CR69" class="usa-link" aria-describedby="CR69">69</a></sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">y) Balanced Inventory of Desirable Responding Short-Form (BIDR)</td>
<td colspan="1" rowspan="1">Tendency to self report with positive bias and impression management</td>
<td colspan="1" rowspan="1">Hart <em>et al</em>.<sup><a href="#CR70" class="usa-link" aria-describedby="CR70">70</a></sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">z) 20-Item Prosopagnosia Index</td>
<td colspan="1" rowspan="1">Face recognition ability</td>
<td colspan="1" rowspan="1">Shah <em>et al</em>.<sup><a href="#CR71" class="usa-link" aria-describedby="CR71">71</a></sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">aa) Tendency to Conform</td>
<td colspan="1" rowspan="1">Social conformity</td>
<td colspan="1" rowspan="1">Goldsmith <em>et al</em>.<sup><a href="#CR72" class="usa-link" aria-describedby="CR72">72</a></sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">bb) Therapeutic Reactance</td>
<td colspan="1" rowspan="1">Psychological reactance</td>
<td colspan="1" rowspan="1">Dowd <em>et al</em>.<sup><a href="#CR73" class="usa-link" aria-describedby="CR73">73</a></sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">cc) Revised Self-Monitoring</td>
<td colspan="1" rowspan="1">Sensitivity to expressive behavior and ability to monitor self-representation</td>
<td colspan="1" rowspan="1">Lennox &amp; Wolfe<sup><a href="#CR74" class="usa-link" aria-describedby="CR74">74</a></sup>
</td>
</tr>
<tr>
<td colspan="1" rowspan="1">dd) Concern for Appropriateness</td>
<td colspan="1" rowspan="1">Tendency to conform</td>
<td colspan="1" rowspan="1">Lennox &amp; Wolfe<sup><a href="#CR74" class="usa-link" aria-describedby="CR74">74</a></sup>
</td>
</tr>
<tr><td align="left" colspan="3" rowspan="1"><strong>In-person Surveys (prior to fMRI scan)</strong></td></tr>
<tr>
<td colspan="1" rowspan="1">Pain Medication Questionnaire</td>
<td colspan="1" rowspan="1">Pain medication administration within the last 12 hrs prior to participation</td>
<td colspan="1" rowspan="1">Internal Survey</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Menstruation Questionnaire</td>
<td colspan="1" rowspan="1">Menstrual cycle phase at the time of the participation and details about participants cycle</td>
<td colspan="1" rowspan="1">Internal Survey</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="_fn_p16"><p>Participants completed at-home surveys prior to initial neuroimaging sessions. <strong>Name of instrument</strong> column indicates the short hand title of each questionnaire. <strong>Description</strong> indicates a short summary of the aim of each questionnaire and <strong>Primary source</strong> indicates the reference for each questionnaire.</p></div></div></section></section><section id="Sec5"><h3 class="pmc_sec_title">Overview of neuroimaging modalities and tasks</h3>
<p id="Par10">The dataset includes three modalities of neuroimaging data: Anatomical T1-weighted image, diffusion weighted image, and functional echo-planar images (EPI) for experimental/naturalistic tasks. Each neuroimaging session encompassed a variety of tasks, each designed to probe different cognitive domains (illustrated in Fig. <a href="#Fig3" class="usa-link">3</a>: “task description”). For example, in task-alignvideo, participants watch naturalistic videos and rate their emotional responses. Therefore, this task includes multimodal stimuli, incorporating both visual and auditory elements, and incorporates affective and social domains. Conversely, task-faces specifically focuses on face processing, involving visual recognition and interpretation of affective facial expressions. Detailed descriptions of each task are provided in subsequent subsections, denoted as “task-”. Visual representations of individual trials within each task are depicted in Fig. <a href="#Fig4" class="usa-link">4</a>. While analysis of interest may vary across researchers, we provide a detailed overview of the key contrasts inherent to each task (Table <a href="#Tab4" class="usa-link">4</a>). This includes a description of the primary cognitive processes, or “canonical” contrasts, which serve for understanding the core aspects of each tasks’ design and its analytical focus.</p>
<figure class="fig xbox font-sm" id="Fig3"><h4 class="obj_head">Fig. 3.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373947_41597_2025_5154_Fig3_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2fa4/12373947/791d70dd0c11/41597_2025_5154_Fig3_HTML.jpg" loading="lazy" id="d33e1258" height="799" width="669" alt="Fig. 3"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Data acquisition layout. Each neuroimaging session included task data from multiple cognitive domains. The upper panel illustrates all of the tasks included in this dataset with 1) the name of each task, 2) its corresponding Brain Imaging Data Structure (BIDS) task name, and 3) a short task description. The lower panel illustrates the task composition across four sessions. Session 1 consisted of one anatomical T1-weighted scan, multi-shell diffusion weighted image, phase-encoding polarity (PEpolar) image for distortion correction, followed by six EPI runs of the multimodal negative affect task (“task-social”), another PEpolar image for distortion correction, followed by four EPI runs of the naturalistic video viewing task (“task-alignvideo”). Session 2 started with a PEpolar image, followed by four runs of naturalistic narrative task (“task-narratives”), three EPI runs of the dynamic faces task (“task-faces”), followed by PEpolar run, and four EPI runs of the naturalistic video viewing task (“task-alignvideo”). Session 3 consisted of an PEpolar run, followed by six EPI runs of the multimodal negative affect task (“task-social”), one EPI run of the video-based multiattribute social judgment task (“task-shortvideo”), PEpolar run, and ended with three EPI runs of the naturalistic video viewing task (“task-alignvideo”). Session 4 started with an PEpolar run, followed by two EPI runs of the cognitive/theory of mind task (“task-fractional”), six EPI runs of the multimodal negative affect task (“task-social”), another PEpolar run, followed by two EPI runs of the naturalistic video viewing task (“task-alignvideo”).</p></figcaption></figure><figure class="fig xbox font-sm" id="Fig4"><h4 class="obj_head">Fig. 4.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373947_41597_2025_5154_Fig4_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2fa4/12373947/553dd9ed0dcb/41597_2025_5154_Fig4_HTML.jpg" loading="lazy" id="d33e1278" height="928" width="760" alt="Fig. 4"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Depiction of task structure and its variations across runs. Each of the six panels refers to a task. Within each panel, “trials” are described, which are fundamental units of a run, designed to capture a specific cognitive process. Trials are repeated within runs. The number of these repetitions, which may vary across tasks, is indicated on the right side of the panel. For tasks employing a factorial design, — specifically, task-faces, task-shortvideo, task-social, task-tomsaxe, task-posner, task-tomspunt, task-memory — the experimental factors are also listed on the right. On the left side of each panel, we note any changes in rating or stimulus modality across runs. For example, task-narratives encompassed two distinct stimulus modalities: audio and text narratives, delivered in separate runs. In a similar vein, the task-social consisted of several distinct runs, each dedicated to a different domain: somatic pain, vicarious pain, and cognitive effort. Stimuli corresponding to each domain were presented exclusively within their respective runs. Lastly, task-faces included three runs, each requiring participants to judge faces based on different dimensions, such as sex and age respectively. These variations in modality and rating type across runs are indicated in bubbles on the left side of each panel.</p></figcaption></figure><section class="tw xbox font-sm" id="Tab4"><h4 class="obj_head">Table 4.</h4>
<div class="caption p"><p>Description of canonical neuroimaging contrasts per task.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Task</th>
<th align="left" colspan="1" rowspan="1">Contrasts</th>
<th align="left" colspan="1" rowspan="1">Covariates</th>
</tr></thead>
<tbody>
<tr>
<td rowspan="2" colspan="1">
<p>Naturalistic video viewing task</p>
<p>task-alignvideo</p>
</td>
<td colspan="1" rowspan="1">Video  &gt; baseline rating</td>
<td colspan="1" rowspan="1">Emotion ratings</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Encoding models of video attributes</td>
<td colspan="1" rowspan="1">—</td>
</tr>
<tr>
<td rowspan="2" colspan="1">
<p>Naturalistic narratives task</p>
<p>task-narratives</p>
</td>
<td colspan="1" rowspan="1">Audio  &gt; Text narrative</td>
<td colspan="1" rowspan="1">—</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Narrative (Audio and Text)  &gt; baseline</td>
<td colspan="1" rowspan="1">Expectation &amp; Feeling rating</td>
</tr>
<tr>
<td rowspan="3" colspan="1">
<p>Multimodal affective task</p>
<p>task-social</p>
</td>
<td colspan="1" rowspan="1">Somatic pain  &gt; baseline</td>
<td colspan="1" rowspan="1">Expectation &amp; Outcome rating</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Vicarious pain  &gt; baseline</td>
<td colspan="1" rowspan="1">Expectation &amp; Outcome rating</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Cognitive discomfort  &gt; baseline</td>
<td colspan="1" rowspan="1">Expectation &amp; Outcome rating</td>
</tr>
<tr>
<td rowspan="3" colspan="1">
<p>Dynamic Faces task</p>
<p>task-faces</p>
</td>
<td colspan="1" rowspan="1">Age  &gt; baseline</td>
<td colspan="1" rowspan="1">Age rating</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Gender  &gt; baseline</td>
<td colspan="1" rowspan="1">Sex rating</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Facial expression  &gt; baseline</td>
<td colspan="1" rowspan="1">Intensity rating</td>
</tr>
<tr>
<td rowspan="3" colspan="1">
<p>Video-based multiattribute</p>
<p>social judgement task</p>
<p>task-shortvideo</p>
</td>
<td colspan="1" rowspan="1">Likeability  &gt; baseline</td>
<td colspan="1" rowspan="1">Likeability rating</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Similarity  &gt; baseline</td>
<td colspan="1" rowspan="1">Similarity rating</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Mental state attribution  &gt; baseline</td>
<td colspan="1" rowspan="1">Mental state attribution rating</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Fractionated “Why/how” task</td>
<td colspan="1" rowspan="1">Why  &gt; How</td>
<td colspan="1" rowspan="1">Accuracy (image detection)</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Fractionated “False-belief” task</td>
<td colspan="1" rowspan="1">False belief  &gt; False photograph</td>
<td colspan="1" rowspan="1">Accuracy (true/false judgment)</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Fractionated “Posner” task</td>
<td colspan="1" rowspan="1">Invalid cue  &gt; Valid cue</td>
<td colspan="1" rowspan="1">Accuracy (target detection)</td>
</tr>
<tr>
<td rowspan="2" colspan="1">Fractionated “Memory” task</td>
<td colspan="1" rowspan="1">Encoding  &gt; baseline</td>
<td colspan="1" rowspan="1">Accuracy (old/new identification)</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Retrieval  &gt; baseline</td>
<td colspan="1" rowspan="1">Accuracy (old/new identification)</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="_fn_p32"><p>To facilitate exploration of the dataset, we highlight the primary processes associated with each task by outlining the canonical contrasts each task (listed in <strong>Task</strong> and <strong>Contrasts</strong> column). Additionally, <strong>Covariates</strong> indicate the participant ratings collected during each trial. These covariates could be integrated into within-subject models or included as between-subject individual difference measures after further computation. For example, the Narratives task includes contrasts such as 1) audio vs. text modality comparison, 2) narrative vs. baseline comparison, and 3) the incorporation of behavioral ratings as covariates.</p></div></div></section></section><section id="Sec6"><h3 class="pmc_sec_title">Specific tasks, stimuli and rating description</h3>
<section id="Sec7"><h4 class="pmc_sec_title">Generalized Labeled Magnitude Scale (gLMS)</h4>
<p id="Par11">A challenge in scientific studies of human behavior is the subjectivity of outcome measures, making ratings often non-comparable across studies. For this dataset, we used a modified semi-circular-shaped generalized labeled magnitude scale (gLMS<sup><a href="#CR17" class="usa-link" aria-describedby="CR17">17</a></sup>), which allows for magnitude matching across participants, originating from gustatory research and psychophysics. Two tasks – Multimodal negative affect task (“task-social”) and Video-based multiattribute social judgement task (“task-shortvideo”) – use elements of the gLMS. The scale is intended to measure subjective sensory experiences quantifiably and comparably across different sensory/cognitive domains, allowing for comparisons both between and within participants. Labels on the scale range from “No sensation” (0<sup>∘</sup>), “Barely detectable” (3<sup>∘</sup>), “Weak” (10<sup>∘</sup>), “Moderate” (29<sup>∘</sup>), “Strong” (64<sup>∘</sup>), “Very Strong” (98<sup>∘</sup>) to “Strongest sensation of any kind” (180<sup>∘</sup>). To mitigate scale usage bias, the scale was adapted from a vertical linear scale to a semicircular presentation, in which reported ratings are designed to be equidistant from the cursor starting point. The scale and associated tasks were presented on a desktop computer during the pre-scan behavioral instruction sessions and in-scanner fMRI tasks. The scale was adapted to each task by modifying the label of the maximum magnitude marker within the context of the task’s measures.</p></section><section id="Sec8"><h4 class="pmc_sec_title">Naturalistic video viewing task 'task-alignvideo'</h4>
<section id="FPar1"><h5 class="pmc_sec_title">Task procedures</h5>
<p id="Par12">A naturalistic video-viewing task was administered across all four sessions. Each session consisted of multiple runs (see Fig. <a href="#Fig3" class="usa-link">3</a> for run composition per session); each run consisted of multiple video trials. Each trial consisted of two epochs of watching a video and rating seven emotion categories. First, participants watched a series of emotionally salient videos (“video”) and next, were intermittently prompted to provide ratings (“rating”) about how the video made them feel in relation to seven affective domains: 1) personal relevance, 2) happy, 3) sad, 4) afraid, 5) disgusted, 6) warm and tender, and 7) engaged. Participants were given 5 seconds to make each of the seven ratings; the sequence of these ratings were kept constant. A variety of 49 unique videos were presented to participants, ranging from 20 seconds to 5 min 39 seconds in duration, amounting to 86 minutes and 9 seconds across 4 sessions (See Table <a href="#Tab5" class="usa-link">5</a> for detailed breakdown of video duration, order and, number of TRs). Each video was played once, with no repetitions. The sequence of the videos were identical across participants, purposefully designed for functional alignment purposes.</p>
<section class="tw xbox font-sm" id="Tab5"><h6 class="obj_head">Table 5.</h6>
<div class="caption p"><p>Overview of the naturalistic videos used in task-alignvideo.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Video name</th>
<th align="left" colspan="1" rowspan="1">Session</th>
<th align="left" colspan="1" rowspan="1">Run</th>
<th align="left" colspan="1" rowspan="1">Order</th>
<th align="left" colspan="1" rowspan="1">Duration (mm:ss)</th>
<th align="left" colspan="1" rowspan="1">TRs</th>
</tr></thead>
<tbody>
<tr>
<td colspan="1" rowspan="1">idiots</td>
<td colspan="1" rowspan="1">ses-01</td>
<td colspan="1" rowspan="1">run-01</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">00:53</td>
<td colspan="1" rowspan="1">115</td>
</tr>
<tr>
<td colspan="1" rowspan="1">wanderers</td>
<td colspan="1" rowspan="1">ses-01</td>
<td colspan="1" rowspan="1">run-01</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">03:18</td>
<td colspan="1" rowspan="1">430</td>
</tr>
<tr>
<td colspan="1" rowspan="1">lioncubs</td>
<td colspan="1" rowspan="1">ses-01</td>
<td colspan="1" rowspan="1">run-01</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">01:00</td>
<td colspan="1" rowspan="1">130</td>
</tr>
<tr>
<td colspan="1" rowspan="1">parkour</td>
<td colspan="1" rowspan="1">ses-01</td>
<td colspan="1" rowspan="1">run-01</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">00:38</td>
<td colspan="1" rowspan="1">82</td>
</tr>
<tr>
<td colspan="1" rowspan="1">harrymetsally</td>
<td colspan="1" rowspan="1">ses-01</td>
<td colspan="1" rowspan="1">run-02</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">02:35</td>
<td colspan="1" rowspan="1">336</td>
</tr>
<tr>
<td colspan="1" rowspan="1">HB</td>
<td colspan="1" rowspan="1">ses-01</td>
<td colspan="1" rowspan="1">run-02</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">00:57</td>
<td colspan="1" rowspan="1">123</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Islamophobia</td>
<td colspan="1" rowspan="1">ses-01</td>
<td colspan="1" rowspan="1">run-02</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">04:03</td>
<td colspan="1" rowspan="1">528</td>
</tr>
<tr>
<td colspan="1" rowspan="1">beach sunset</td>
<td colspan="1" rowspan="1">ses-01</td>
<td colspan="1" rowspan="1">run-02</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">00:30</td>
<td colspan="1" rowspan="1">65</td>
</tr>
<tr>
<td colspan="1" rowspan="1">Hugging pets</td>
<td colspan="1" rowspan="1">ses-01</td>
<td colspan="1" rowspan="1">run-03</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">01:46</td>
<td colspan="1" rowspan="1">230</td>
</tr>
<tr>
<td colspan="1" rowspan="1">bestfriendsweating</td>
<td colspan="1" rowspan="1">ses-01</td>
<td colspan="1" rowspan="1">run-03</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">00:59</td>
<td colspan="1" rowspan="1">128</td>
</tr>
<tr>
<td colspan="1" rowspan="1">cupstacking</td>
<td colspan="1" rowspan="1">ses-01</td>
<td colspan="1" rowspan="1">run-03</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">00:20</td>
<td colspan="1" rowspan="1">43</td>
</tr>
<tr>
<td colspan="1" rowspan="1">dancewithdeath</td>
<td colspan="1" rowspan="1">ses-01</td>
<td colspan="1" rowspan="1">run-03</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">02:16</td>
<td colspan="1" rowspan="1">295</td>
</tr>
<tr>
<td colspan="1" rowspan="1">beatbox</td>
<td colspan="1" rowspan="1">ses-01</td>
<td colspan="1" rowspan="1">run-04</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">02:22</td>
<td colspan="1" rowspan="1">308</td>
</tr>
<tr>
<td colspan="1" rowspan="1">angrygrandpa</td>
<td colspan="1" rowspan="1">ses-01</td>
<td colspan="1" rowspan="1">run-04</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">05:39</td>
<td colspan="1" rowspan="1">736</td>
</tr>
<tr>
<td colspan="1" rowspan="1">knifegame</td>
<td colspan="1" rowspan="1">ses-02</td>
<td colspan="1" rowspan="1">run-01</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">00:26</td>
<td colspan="1" rowspan="1">56</td>
</tr>
<tr>
<td colspan="1" rowspan="1">freesolo</td>
<td colspan="1" rowspan="1">ses-02</td>
<td colspan="1" rowspan="1">run-01</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">01:11</td>
<td colspan="1" rowspan="1">154</td>
</tr>
<tr>
<td colspan="1" rowspan="1">youth</td>
<td colspan="1" rowspan="1">ses-02</td>
<td colspan="1" rowspan="1">run-01</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">01:51</td>
<td colspan="1" rowspan="1">241</td>
</tr>
<tr>
<td colspan="1" rowspan="1">deer</td>
<td colspan="1" rowspan="1">ses-02</td>
<td colspan="1" rowspan="1">run-01</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">00:30</td>
<td colspan="1" rowspan="1">65</td>
</tr>
<tr>
<td colspan="1" rowspan="1">mediabias</td>
<td colspan="1" rowspan="1">ses-02</td>
<td colspan="1" rowspan="1">run-02</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">01:59</td>
<td colspan="1" rowspan="1">258</td>
</tr>
<tr>
<td colspan="1" rowspan="1">photography</td>
<td colspan="1" rowspan="1">ses-02</td>
<td colspan="1" rowspan="1">run-02</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">03:27</td>
<td colspan="1" rowspan="1">450</td>
</tr>
<tr>
<td colspan="1" rowspan="1">menrunning</td>
<td colspan="1" rowspan="1">ses-02</td>
<td colspan="1" rowspan="1">run-02</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">03:23</td>
<td colspan="1" rowspan="1">441</td>
</tr>
<tr>
<td colspan="1" rowspan="1">giving</td>
<td colspan="1" rowspan="1">ses-02</td>
<td colspan="1" rowspan="1">run-02</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">02:57</td>
<td colspan="1" rowspan="1">384</td>
</tr>
<tr>
<td colspan="1" rowspan="1">unefille</td>
<td colspan="1" rowspan="1">ses-02</td>
<td colspan="1" rowspan="1">run-03</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">01:56</td>
<td colspan="1" rowspan="1">252</td>
</tr>
<tr>
<td colspan="1" rowspan="1">captureflag</td>
<td colspan="1" rowspan="1">ses-02</td>
<td colspan="1" rowspan="1">run-03</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">02:59</td>
<td colspan="1" rowspan="1">389</td>
</tr>
<tr>
<td colspan="1" rowspan="1">tornado</td>
<td colspan="1" rowspan="1">ses-02</td>
<td colspan="1" rowspan="1">run-03</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">00:26</td>
<td colspan="1" rowspan="1">56</td>
</tr>
<tr>
<td colspan="1" rowspan="1">war</td>
<td colspan="1" rowspan="1">ses-02</td>
<td colspan="1" rowspan="1">run-03</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">01:02</td>
<td colspan="1" rowspan="1">134</td>
</tr>
<tr>
<td colspan="1" rowspan="1">forestfire</td>
<td colspan="1" rowspan="1">ses-02</td>
<td colspan="1" rowspan="1">run-04</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">00:47</td>
<td colspan="1" rowspan="1">102</td>
</tr>
<tr>
<td colspan="1" rowspan="1">iceblock</td>
<td colspan="1" rowspan="1">ses-02</td>
<td colspan="1" rowspan="1">run-04</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">00:47</td>
<td colspan="1" rowspan="1">102</td>
</tr>
<tr>
<td colspan="1" rowspan="1">alwaysafamily</td>
<td colspan="1" rowspan="1">ses-02</td>
<td colspan="1" rowspan="1">run-04</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">02:26</td>
<td colspan="1" rowspan="1">317</td>
</tr>
<tr>
<td colspan="1" rowspan="1">visswar</td>
<td colspan="1" rowspan="1">ses-02</td>
<td colspan="1" rowspan="1">run-04</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">00:33</td>
<td colspan="1" rowspan="1">71</td>
</tr>
<tr>
<td colspan="1" rowspan="1">mountainbike</td>
<td colspan="1" rowspan="1">ses-03</td>
<td colspan="1" rowspan="1">run-01</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">03:31</td>
<td colspan="1" rowspan="1">458</td>
</tr>
<tr>
<td colspan="1" rowspan="1">carflood</td>
<td colspan="1" rowspan="1">ses-03</td>
<td colspan="1" rowspan="1">run-01</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">00:20</td>
<td colspan="1" rowspan="1">43</td>
</tr>
<tr>
<td colspan="1" rowspan="1">fireplace</td>
<td colspan="1" rowspan="1">ses-03</td>
<td colspan="1" rowspan="1">run-01</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">00:30</td>
<td colspan="1" rowspan="1">65</td>
</tr>
<tr>
<td colspan="1" rowspan="1">snakes</td>
<td colspan="1" rowspan="1">ses-03</td>
<td colspan="1" rowspan="1">run-01</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">02:03</td>
<td colspan="1" rowspan="1">267</td>
</tr>
<tr>
<td colspan="1" rowspan="1">planetearth</td>
<td colspan="1" rowspan="1">ses-03</td>
<td colspan="1" rowspan="1">run-02</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">02:28</td>
<td colspan="1" rowspan="1">321</td>
</tr>
<tr>
<td colspan="1" rowspan="1">normativeprosocial3</td>
<td colspan="1" rowspan="1">ses-03</td>
<td colspan="1" rowspan="1">run-02</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">01:26</td>
<td colspan="1" rowspan="1">186</td>
</tr>
<tr>
<td colspan="1" rowspan="1">heartstop</td>
<td colspan="1" rowspan="1">ses-03</td>
<td colspan="1" rowspan="1">run-02</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">03:16</td>
<td colspan="1" rowspan="1">426</td>
</tr>
<tr>
<td colspan="1" rowspan="1">beachsunrise</td>
<td colspan="1" rowspan="1">ses-03</td>
<td colspan="1" rowspan="1">run-02</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">00:35</td>
<td colspan="1" rowspan="1">76</td>
</tr>
<tr>
<td colspan="1" rowspan="1">normativeprosocial2</td>
<td colspan="1" rowspan="1">ses-03</td>
<td colspan="1" rowspan="1">run-03</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">01:45</td>
<td colspan="1" rowspan="1">228</td>
</tr>
<tr>
<td colspan="1" rowspan="1">normativeprosocial1</td>
<td colspan="1" rowspan="1">ses-03</td>
<td colspan="1" rowspan="1">run-03</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">01:14</td>
<td colspan="1" rowspan="1">160</td>
</tr>
<tr>
<td colspan="1" rowspan="1">stardust</td>
<td colspan="1" rowspan="1">ses-03</td>
<td colspan="1" rowspan="1">run-03</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">03:16</td>
<td colspan="1" rowspan="1">426</td>
</tr>
<tr>
<td colspan="1" rowspan="1">universe</td>
<td colspan="1" rowspan="1">ses-04</td>
<td colspan="1" rowspan="1">run-01</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">00:50</td>
<td colspan="1" rowspan="1">108</td>
</tr>
<tr>
<td colspan="1" rowspan="1">gockskumara</td>
<td colspan="1" rowspan="1">ses-04</td>
<td colspan="1" rowspan="1">run-01</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">02:59</td>
<td colspan="1" rowspan="1">389</td>
</tr>
<tr>
<td colspan="1" rowspan="1">skiing</td>
<td colspan="1" rowspan="1">ses-04</td>
<td colspan="1" rowspan="1">run-01</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">00:56</td>
<td colspan="1" rowspan="1">121</td>
</tr>
<tr>
<td colspan="1" rowspan="1">cyclegraphics</td>
<td colspan="1" rowspan="1">ses-04</td>
<td colspan="1" rowspan="1">run-01</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">02:27</td>
<td colspan="1" rowspan="1">319</td>
</tr>
<tr>
<td colspan="1" rowspan="1">dogdance</td>
<td colspan="1" rowspan="1">ses-04</td>
<td colspan="1" rowspan="1">run-02</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">00:38</td>
<td colspan="1" rowspan="1">82</td>
</tr>
<tr>
<td colspan="1" rowspan="1">littleboat</td>
<td colspan="1" rowspan="1">ses-04</td>
<td colspan="1" rowspan="1">run-02</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">01:14</td>
<td colspan="1" rowspan="1">160</td>
</tr>
<tr>
<td colspan="1" rowspan="1">gangan</td>
<td colspan="1" rowspan="1">ses-04</td>
<td colspan="1" rowspan="1">run-02</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">02:18</td>
<td colspan="1" rowspan="1">300</td>
</tr>
<tr>
<td colspan="1" rowspan="1">tornado</td>
<td colspan="1" rowspan="1">ses-04</td>
<td colspan="1" rowspan="1">run-02</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">00:27</td>
<td colspan="1" rowspan="1">58</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab5/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="_fn_p36"><p>Each row represents a video that was presented during one trial. The column <strong>Video</strong> indicates the video filename. <strong>Session</strong> and <strong>Run</strong> indicates the session and run in which the videos were presented. <strong>Order</strong> indicates the order of the video played in each run. <strong>Duration (mm:ss)</strong> indicates the length of the video. <strong>TRs</strong> indicates the number of TRs, i.e. 0.46 seconds, that the video spans. Each video file follows the naming convention: {Session}_{Run}_order-{Order}_content-{Videonames}.mp4, shared in the stimuli/task-alignvideo folder.</p></div></div></section></section><section id="FPar2"><h5 class="pmc_sec_title">Stimuli and scales</h5>
<p id="Par13">To submit affective ratings of videos, the participants were presented with a continuous, linear scale ranging from “Barely at all” to “Strongest imaginable”. Practice ratings were provided using a computer mouse, and experimental ratings were provided using an MR-compatible trackball.</p></section></section><section id="Sec9"><h4 class="pmc_sec_title">Multimodal negative affect task 'task-social.'</h4>
<section id="FPar3"><h5 class="pmc_sec_title">Task procedures</h5>
<p id="Par14">Participants performed three different task domains: somatic pain (“pain”), vicarious pain (“vicarious”), and mental rotation (“cognitive”). Each task was designed as a 2 cue (high/low) x 3 stimulus intensity (high/med/low) factorial design. The three tasks were conducted repeatedly on average, one week apart across three sessions (ses-01, ses-03, ses-04). Each trial consisted of four events: first, participants passively viewed a presentation of a high or low social cue, consisting of data points that participants believed indicated other people’s ratings for the upcoming stimulus. Cues were presented for 1 second on screen (“cue”); second, participants provided ratings of their expectations on the upcoming stimulus intensity on a gLMS scale for a total duration of 4 seconds overlaid with the cue image (“expectancy rating”); third, participants passively received/viewed experimentally delivered stimuli for each of the mental rotation, vicarious pain, and somatic pain tasks for 5 seconds each (“stimulus”); lastly, participants provided ratings on their subjective experience of cognitive effort, vicarious pain, or somatic pain for 4 seconds (“outcome rating”). In total, each run was designed to last 6 minutes and 41 seconds, i.e., 872 TRs. The task was administered in ses-01, ses-03, and ses-04.</p></section><section id="FPar4"><h5 class="pmc_sec_title">Stimuli and scales</h5>
<p id="Par15">Stimuli for the somatic pain task were thermal heat stimuli, administered using a TSA2 system (Medoc) with a 16-mm Peltier contact thermode, delivered to the glaborous skin of the ventral surface of the left forearm. Stimuli at three stimulus intensity levels were delivered (low: 48<sup>°</sup>C; medium: 49<sup>°</sup>C; high: 50<sup>°</sup>C), for a total duration of 9 seconds with a 5 second plateau. Baseline temperature was 32<sup>°</sup>C. To account for the delay in reaching the intended temperature, an additional two seconds were padded to both the ramp-up and ramp-down phases. As a result, the pain stimulus was 9 seconds long, with 5 seconds of peak intended temperature. To maintain consistency across conditions, the vicarious and cognitive stimuli were also padded with fixation crosses to match the stimulus duration across conditions. Stimuli for the vicarious task were videos of patients in pain, selected from the UNBC-McMaster shoulder pain expression archive database 10.1109/FG.2011.5771462<sup><a href="#CR18" class="usa-link" aria-describedby="CR18">18</a></sup> and categorized into three stimulus intensity levels using the pre-normed ratings (self-reported pain rating and observer estimated-pain rating) provided from the dataset. Stimuli for the mental rotation task were images from the Ganis &amp; Kievet 10.5334/jopd.ai; <a href="https://figshare.com/articles/dataset/A_new_set_of_three_dimensional_stimuli_for_investigating_mental_rotation_processes/1045385" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://figshare.com/articles/dataset/A_new_set_of_three_dimensional_stimuli_for_investigating_mental_rotation_processes/1045385</a><sup><a href="#CR19" class="usa-link" aria-describedby="CR19">19</a></sup> dataset, selecting images that were rotated 50, 100, 150 <sup>∘</sup> to account for three intensity levels.</p></section></section><section id="Sec10"><h4 class="pmc_sec_title">Naturalistic narratives task 'task-narratives'</h4>
<section id="FPar5"><h5 class="pmc_sec_title">Task procedures</h5>
<p id="Par16">Participants were instructed to read or listen to 8 different narratives while in the scanner, with each narrative chunked into 9 clips. Each trial started with a fixation period with jittered durations between 2 and 8 seconds (“fixation”). During the narrative epoch, audio or text clips were presented (“audio” or “text”). Participants were then prompted to rate how they felt about the narrative (“feeling”) and what their expectations were for the upcoming narrative on how good or bad the future storyline would be (“expectation”). The entire task consisted of four runs, with two narratives, i.e. 18 narrative clips in each run. In total, each run was designed to last 7 minutes 24 seconds to 9 minutes 57 seconds, i.e., 967, 1098, 1298, 1156 TRs per run. The task was administered in ses-02.</p></section><section id="FPar6"><h5 class="pmc_sec_title">Stimuli and scales</h5>
<p id="Par17">The narrative contents were manipulated across three distinct timescales: individual situations, the context of those situations, and the overarching full narrative. Each narrative includes a single main character who moves between three different contexts and, in each context, encounters three different situations (characterized by interpersonal relationships and actions). We use Polti’s 36 situations to construct these different situations<sup><a href="#CR20" class="usa-link" aria-describedby="CR20">20</a></sup>. The duration of the eight narratives range from 1 minute 36 seconds to 3 minutes 29 seconds (Table <a href="#Tab6" class="usa-link">6</a>). The rating scale had two poles on the scale, each labeled “good” and “bad”, presented at the two upper corners of the screen. The center of the poles represent higher intensity; participants would report how intensely good or bad they felt about the current narrative and expected what the next narrative would be like. The scale allows for encoding two dimensions of a participants subjective experience – intensity and valence – in comparison to a linear scale.</p>
<section class="tw xbox font-sm" id="Tab6"><h6 class="obj_head">Table 6.</h6>
<div class="caption p"><p>Overview of the naturalistic narratives used in the Narratives task.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Run #</th>
<th align="left" colspan="1" rowspan="1">Story #</th>
<th align="left" colspan="1" rowspan="1">Modality</th>
<th align="left" colspan="1" rowspan="1">Duration (mm:ss)</th>
<th align="left" colspan="1" rowspan="1">TRs</th>
<th align="left" colspan="1" rowspan="1">Words</th>
</tr></thead>
<tbody>
<tr>
<td colspan="1" rowspan="1">run-01</td>
<td colspan="1" rowspan="1">7</td>
<td colspan="1" rowspan="1">audio</td>
<td colspan="1" rowspan="1">02:01</td>
<td colspan="1" rowspan="1">263</td>
<td colspan="1" rowspan="1">429</td>
</tr>
<tr>
<td colspan="1" rowspan="1">run-01</td>
<td colspan="1" rowspan="1">8</td>
<td colspan="1" rowspan="1">audio</td>
<td colspan="1" rowspan="1">01:36</td>
<td colspan="1" rowspan="1">209</td>
<td colspan="1" rowspan="1">314</td>
</tr>
<tr>
<td colspan="1" rowspan="1">run-02</td>
<td colspan="1" rowspan="1">5</td>
<td colspan="1" rowspan="1">audio</td>
<td colspan="1" rowspan="1">02:30</td>
<td colspan="1" rowspan="1">326</td>
<td colspan="1" rowspan="1">511</td>
</tr>
<tr>
<td colspan="1" rowspan="1">run-02</td>
<td colspan="1" rowspan="1">6</td>
<td colspan="1" rowspan="1">audio</td>
<td colspan="1" rowspan="1">02:04</td>
<td colspan="1" rowspan="1">269</td>
<td colspan="1" rowspan="1">447</td>
</tr>
<tr>
<td colspan="1" rowspan="1">run-03</td>
<td colspan="1" rowspan="1">3</td>
<td colspan="1" rowspan="1">text</td>
<td colspan="1" rowspan="1">03:11</td>
<td colspan="1" rowspan="1">415</td>
<td colspan="1" rowspan="1">573</td>
</tr>
<tr>
<td colspan="1" rowspan="1">run-03</td>
<td colspan="1" rowspan="1">4</td>
<td colspan="1" rowspan="1">text</td>
<td colspan="1" rowspan="1">03:29</td>
<td colspan="1" rowspan="1">454</td>
<td colspan="1" rowspan="1">626</td>
</tr>
<tr>
<td colspan="1" rowspan="1">run-04</td>
<td colspan="1" rowspan="1">1</td>
<td colspan="1" rowspan="1">text</td>
<td colspan="1" rowspan="1">02:43</td>
<td colspan="1" rowspan="1">355</td>
<td colspan="1" rowspan="1">490</td>
</tr>
<tr>
<td colspan="1" rowspan="1">run-04</td>
<td colspan="1" rowspan="1">2</td>
<td colspan="1" rowspan="1">text</td>
<td colspan="1" rowspan="1">02:40</td>
<td colspan="1" rowspan="1">348</td>
<td colspan="1" rowspan="1">480</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab6/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="_fn_p43"><p>The narrative task was operated within a single session, ses-02. There were four runs in total, with eight different narratives. Each row represents a narrative, presented within each run. The <strong>Run</strong> column indicates the run order in which the narrative was presented. Story represents the narrative index. <strong>Modality</strong> indicates the form in which each narrative was presented. <strong>Duration (mm:ss)</strong> indicates the length of the narrative. <strong>TRs</strong> indicates the number of TRs, i.e. 0.46 seconds, that the audio or text-based narrative spans. Each narrative was further divided into nine chunks labeled by situations; each chunk was presented per trial.</p></div></div></section></section></section><section id="Sec11"><h4 class="pmc_sec_title">Dynamic faces task 'task-faces'</h4>
<section id="FPar7"><h5 class="pmc_sec_title">Task procedures</h5>
<p id="Par18">Participants were presented with 288 dynamic faces of varying race, age, sex, and facial expressions. The faces task consisted of three runs; in each run, participants were prompted to rate specific dimensions of the face: age, sex, or intensity of the facial expression. The order of the runs were pseudo-randomized based on odd and even numbered participant IDs. Participants were made aware of the rating dimension before the start of each run. In each trial, a brief video featuring a single face, displaying an expression, was played (“faces”), and participants were given 1.875 seconds to rate the face on the corresponding rating: the intensity of the facial expressions, the sex of the face, or the age of the face (“rating”). Participants indicated their responses by either clicking the mouse to lock in their rating or by allowing the cursor position at the end of the response period to serve as their recorded rating. After each rating, a fixation cross was displayed with a jittered duration of 0-4 seconds. Each of the three runs lasted 7 minutes and 7 seconds, (i.e., 914 TRs) and featured 96 facial stimuli. The task was administered within a single session, during ses-02.</p></section><section id="FPar8"><h5 class="pmc_sec_title">Stimuli and scales</h5>
<p id="Par19">The stimuli were animated clips of human faces, ranging from 1.3 to 2.1 seconds, varying across four underlying factors: age, sex, race, and facial expression. The faces were either young or old (“age”), male or female (“sex”), Eastern Asian, Western Caucasian, or African (“race”) and exhibited one of eight emotions: happiness, surprise, fear, disgust, anger, sadness, pain, and pleasure (“expression”). The faces were crossed with the four factors. The rating scale was a linear scale with keywords at each end, serving as axes for the rating scale (i.e. young-old, male-female, neutral-strongest imaginable for each age, sex, expression block of trials).</p></section></section><section id="Sec12"><h4 class="pmc_sec_title">Video-based multiattribute social judgement task "task-shortvideo."</h4>
<section id="FPar9"><h5 class="pmc_sec_title">Task procedures</h5>
<p id="Par20">The video-based multiattribute social judgement task is a theory of mind task in which participants are prompted to make three different types of assessments about a featured character from a video clip: 1) similarity, 2) likeability, 3) mental state attribution. Participants were familiar with the featured character because the short video clips were pulled from full-length videos that participants had watched in previous sessions, specifically during task-alignvideo. Participants rated three types of ratings per video: 1) perceived similarity towards the character (“similarity”), worded as “How similar are you to this character?”; 2) likeability towards the character (“likeability”) worded as “How much do you like this character?”; and 3) inferring what the character is thinking based on a question prompt, such as “Did the character feel in danger?” or “Was the character remembering something?” (“mental state attribution”). At the beginning of each block, participants were visually presented with one of these three questions prior to watching a set of three character-videos. Subsequently, participants were given a rating cue (e.g. “how similar?”) and were shown a five-second video clip of the character. Once the clip ended, participants had five-seconds to respond to the question using a modified version of the semi-circular gLMS rating scale. To ensure participants were clear about which character the experiment referred to, several measures were implemented: 1) The characters were introduced in videos during earlier sessions, 2) participants rewatched these videos during a pre-scan instructional session, and 3) a slideshow was used to highlight the face of the character being discussed, after participants completed rewatching the videos. We asked participants recognition of the characters; videos were replayed if the participants were not able to recognize the said character. Repeating video stimuli to support video recognition during subsequent character judgment provides an additional avenue: memory-related processes, specifically linking videos across previous sessions of the Naturalistic video viewing task “task-alignvideo”. In total, each run was designed to last 12 minutes and 23 seconds, i.e., 1616 TRs. The task was administered within a single session, during ses-03.</p></section><section id="FPar10"><h5 class="pmc_sec_title">Stimuli and scales</h5>
<p id="Par21">Participants were presented with a series of short video clips, ranging from 4.1 to 6.9 seconds (“video”). As mentioned, these video clips were pulled from previous sessions, and edited to single out a character of interest. Immediately following each video clip, participants were prompted to provide character assessments using a modified version of the gLMS (“rating”). The modified gLMS rating scale included the following anchors: Not at all, barely detectable, weak, moderate, high, very high, strongest possible similarity/likability. For mental ease on rating self-referential thoughts on the videos, we cued participants with the type of rating – likeability, similarity, mental state attribution – at the beginning of a video. Afterwards, three trials consecutively asked the same questions. In other words, a rating question was first presented, followed by one video, then followed by a shorter question cue, and this was iteratively done for three consecutive trials.</p></section></section><section id="Sec13"><h4 class="pmc_sec_title">Cognitive and Theory of mind task set "task-fractional"</h4>
<p id="Par22">The Cognitive and Theory of mind (ToM) task set consisted of four subtasks: attention reorienting<sup><a href="#CR21" class="usa-link" aria-describedby="CR21">21</a></sup> (N = 48), memory encoding/retrieval (N = 52), text-based theory of mind<sup><a href="#CR22" class="usa-link" aria-describedby="CR22">22</a></sup> (N = 51), and image-based theory of mind<sup><a href="#CR23" class="usa-link" aria-describedby="CR23">23</a></sup> (N = 47). The purpose of this task was to select and compare across subtasks that are known to engage the angular gyrus. Each participant was pseudo-randomly assigned to undergo two subtasks, which were counterbalanced across participants. In other words, one set of participants completed the attention reorienting task and image-based theory of mind task, while a different participant completed a text-based theory of mind task and memory/encoding task. This task was completed within one session, during ses-04.</p>
<p id="Par23"><strong>Cognitive/ToM task A: Attention reorienting task</strong> 'runtype-posner'</p>
<section id="FPar11"><h5 class="pmc_sec_title">Task procedures</h5>
<p id="Par24">This subtask was a canonical spatial cueing paradigm<sup><a href="#CR21" class="usa-link" aria-describedby="CR21">21</a></sup>, which consists of three phases: fixation phase, cue phase, and target search phase. The goal is to identify and indicate the location of the <em>target</em> as quickly as possible. A cue precedes the target, designed to highlight the location of the upcoming target. A valid cue correctly precedes the location of the target, facilitating the detection of a target; conversely, an invalid cue incorrectly signals the location of the target. To elaborate on each phase of a given trial, during the fixation phase, participants were presented with a fixation cross and two white-outlined empty square boxes, positioned in the visual fields on the left and right. This was displayed for a jittered duration, averaging around 2.5 seconds (“fixation”). During the cue phase, one of the boxes was highlighted with a green color for 0.2 seconds (“cue”). During the target search phase, a green circle, the target, appeared in the center of the square box on the left or right for 2 seconds (“target”). If the participant responded within this 2-second window, a feedback screen highlighted the box they selected for 0.5 seconds. Afterwards, the next trial begins, with the presentation of the fixation cross and empty white boxes on the screen. A total of 120 trials were performed on this task. On average, the proportion of valid to invalid cues was equal, with a 50/50 distribution across participants (M = 50.82, SD = 5.55). The sequence of valid and invalid cues was generated using a random walk procedure, ensuring variation across participants. This approach was chosen to align with the structure of the task-social paradigm, where high and low cues also occur with equal probability. This design deviates from the original Posner-cueing paradigm, which typically includes 80% valid cues<sup><a href="#CR21" class="usa-link" aria-describedby="CR21">21</a></sup>. This approach was chosen to align with the structure of the task-social paradigm, where high and low cues also occur with equal probability. This aligns with the overarching aim of the task: to examine how participants dynamically adjust their attention based on changing cue informativeness, rather than relying on consistent probabilistic structure. In total, each run was designed to last 10 minutes and 8 seconds, i.e., 1322 TRs.</p></section><section id="FPar12"><h5 class="pmc_sec_title">Stimuli and scales</h5>
<p id="Par25">Stimuli were simple geometric shapes, i.e. boxes and circles. In this subtask, no rating scale was used. Participants responded to the target using the two buttons of an MR-compatible trackball. Code was custom-developed for this task.</p>
<p id="Par26"><strong>Cognitive/ToM task B: Memory encoding-retrieval task</strong> 'runtype-memory'</p></section><section id="FPar13"><h5 class="pmc_sec_title">Task procedures</h5>
<p id="Par27">This subtask was designed to be identical to encoding retrieval tasks, which consist of three phases, repeated twice: a memory encoding phase, a memory distraction phase, and a memory recall phase. The memory encoding phase entailed the presentation of a small illustration clip-art presented for 1 second each (“encoding”), with a total of 26 × 2, i.e., 52 images. The memory distraction phase, intended to prohibit active memory maintenance, included a math calculation task with two math problems × 2 (“distraction”), each displayed for 25 seconds followed by a 5 second response epoch. During the memory recall phase, participants were presented with clip-arts one by one, with a total of 40 × 2 images, and were asked whether they had seen each clip-art before or not. Participants then responded “old” or “new” by pressing the appropriate button under each clip-art. Each response phase lasted 2 seconds (“retrieval”). In total, each run was designed to last 10 minutes and 8 seconds, i.e., 1322 TRs. Due to the recency and primary memory effects, the first and last three images in the encoding test are labeled as null trials.</p></section><section id="FPar14"><h5 class="pmc_sec_title">Stimuli and scales</h5>
<p id="Par28">Stimuli were image-based drawings of everyday objects or animate beings. No rating scale was used. Participants responded to the target using the two buttons of an MR-compatible trackball, indicating “old” or “new” to the image presented on screen. Code was custom-developed for this task.</p>
<p id="Par29"><strong>Cognitive/ToM task C: Image-based theory of mind task</strong> 'runtype-tomspunt'</p></section><section id="FPar15"><h5 class="pmc_sec_title">Task procedures</h5>
<p id="Par30">This subtask was derived from Spunt &amp; Adolphs’ theory of mind why/how localizer<sup><a href="#CR23" class="usa-link" aria-describedby="CR23">23</a></sup> to investigate mental state attribution. The experiment focuses on two cognitive aspects of observable actions: mentalizing the implicit mental states driving the actions (“why”) and describing the explicit physical attributes of these actions (“how”). In each trial, participants first saw a prompt (“question”) for 2.1 seconds, followed by a photo (“photo”) with a duration of 1.75 seconds, and then answered yes/no to the prompted question. In total, each run was designed to have 256 images, with 64 images crossed with 2 questions (why/how) and 2 mediums (face/hand), and lasted 10 minutes and 8 seconds, i.e., 1322 TRs.</p></section><section id="FPar16"><h5 class="pmc_sec_title">Stimuli and scales</h5>
<p id="Par31">An example of a stimulus includes a photo that depicts an individual looking sideways. One question would ask “Is this person looking away? (how)” and another would ask “Is this person expressing doubt? (why)” The same image was yoked with the 2 (why/how) × 2 (face/hand) combination of questions, which engaged different processes related to physical vs. mental state attribution. Stimuli, scales, and code are available via 10.5281/zenodo.50244.</p>
<p id="Par32"><strong>Cognitive/ToM task D: Text-based theory of mind task</strong> 'runtype-tomsaxe'</p></section><section id="FPar17"><h5 class="pmc_sec_title">Task procedures</h5>
<p id="Par33">This subtask was derived from Dodell-Feder, Dufour, and Saxe’s theory of mind false belief localizer task<sup><a href="#CR22" class="usa-link" aria-describedby="CR22">22</a></sup> to investigate theory of mind processes, i.e., the process of representing and attributing mental states of another agent. Participants read anecdotes of false beliefs and false photographs and answered a true/false questions regarding the stories. In each trial, a fixation cross was presented for 12 seconds (“fixation”), after which participants read an anecdote for 14 seconds (“story”) and responded to a question regarding the anecdote, presented on screen for 10 seconds (“question”). In total, each run was designed to last 10 minutes and 8 seconds, i.e., 1322 TRs.</p></section><section id="FPar18"><h5 class="pmc_sec_title">Stimuli and scales</h5>
<p id="Par34">“False belief” stories were narratives where the reader had to represent outdated beliefs of an agent’s latent thought to achieve a correct understanding. For example, “Tom usually takes a left turn on the main road to get to work. Little did Tom know that, this morning, the left section of the main road was under construction.” “False photo” stories involved interpreting false or outdated content in a photograph. For example, an old photograph depicts the photo of an island, but no longer accurately describes the current state due to a volcanic erruption. “Questions” were structured as true/false statements; “true/false” keywords were displayed on-screen. For a statement like “Tom makes a right turn on the main road to avoid the construction”, or ”The island still exists in its beautiful form” participants responded by pressing a button to indicate their answer, either true or false. Stimuli, scales, and code are available via <a href="https://saxelab.mit.edu/use-our-efficient-false-belief-localizer/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://saxelab.mit.edu/use-our-efficient-false-belief-localizer/</a>.</p></section></section></section><section id="Sec14"><h3 class="pmc_sec_title">MRI data acquisition</h3>
<p id="Par35">All fMRI data were acquired on a 3T Siemens MAGNETOM Prisma MRI scanner with 32-channel parallel imaging at the Dartmouth Brain Imaging Center at Dartmouth College. Structural images were acquired using high-resolution T1 spoiled gradient recall images and were used for anatomical localization and warping to the standard Montreal Neurological Institute (MNI) space only. Functional images were acquired with a multiband EPI sequence (repetition time = 460 ms, echo time = 27.2 ms, field of view = 220 mm, multiband acceleration factor = 8, flip angle = 44<sup>°</sup>, 64 × 64 matrix, 2.7 × 2.7 × 2.7 mm voxels, 56 interleaved ascending slices, phase encoding posterior  &gt;&gt; anterior). Stimulus presentation and behavioral data acquisition were controlled using Psychtoolbox (MATLAB, MathWorks). Magnetic resonance imaging acquisition parameters are listed in Table <a href="#Tab2" class="usa-link">2</a>.</p></section><section id="Sec15"><h3 class="pmc_sec_title">MRI data curation</h3>
<p id="Par36">MRI protocols in the scanner were renamed to follow the ReproIn naming convention, ensuring robust and automated conversion into BIDS format using HeuDiConv v.0.9.0<sup><a href="#CR24" class="usa-link" aria-describedby="CR24">24</a></sup>. For initial sequences not named according to ReproIn, we provided a remapping to facilitate conversion. All participant IDs were anonymized to follow within study sequential order from 1 to 133, left padded with 0 to the length of four digits, e.g. sub-0123. Data was converted to BIDS DataLad dataset using HeuDiConv with dcm2niix v.1.0.20201102<sup><a href="#CR25" class="usa-link" aria-describedby="CR25">25</a></sup>, shipped within Singularity container of the ReproNim/containers DataLad dataset<sup><a href="#CR26" class="usa-link" aria-describedby="CR26">26</a></sup> repronim-reproin–0.9.0.sing.</p></section><section id="Sec16"><h3 class="pmc_sec_title">MRI preprocessing</h3>
<p id="Par37">Preprocessing was performed using fMRIPrep 21.0.2<sup><a href="#CR27" class="usa-link" aria-describedby="CR27">27</a></sup> which is based on Nipype 1.6.1<sup><a href="#CR28" class="usa-link" aria-describedby="CR28">28</a></sup>,<sup><a href="#CR29" class="usa-link" aria-describedby="CR29">29</a></sup>. The following description in this section is generated from the standard fMRIPrep preprocessing boilerplate text to ensure a consistent description across different processing pipelines.</p>
<section id="Sec17"><h4 class="pmc_sec_title">Preprocessing of B0 inhomogeneity mappings</h4>
<p id="Par38">A <em>B0</em>-nonuniformity map (or <em>fieldmap</em>) was estimated based on two (or more) echo-planar imaging (EPI) references with topup [FSL 6.0.5.1: 57b01774]<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup>.</p></section><section id="Sec18"><h4 class="pmc_sec_title">Anatomical data preprocessing</h4>
<p id="Par39">A total of 1 T1-weighted (T1w) images were found within the input BIDS dataset.The T1-weighted (T1w) image was corrected for intensity non-uniformity (INU) with N4BiasFieldCorrection<sup><a href="#CR31" class="usa-link" aria-describedby="CR31">31</a></sup>, distributed with ANTs 2.3.3 [RRID: SCR_004757]<sup><a href="#CR32" class="usa-link" aria-describedby="CR32">32</a></sup>, and used as T1w-reference throughout the workflow. The T1w-reference was then skull-stripped with a <em>Nipype</em> implementation of the antsBrainExtraction.sh workflow (from ANTs), using OASIS30ANTs as target template. Brain tissue segmentation of cerebrospinal fluid (CSF), white-matter (WM) and gray-matter (GM) was performed on the brain-extracted T1w using fast [FSL 6.0.5.1: 57b01774, RRID: SCR_002823]<sup><a href="#CR33" class="usa-link" aria-describedby="CR33">33</a></sup>. Brain surfaces were reconstructed using recon-all [FreeSurfer 6.0.1,RRID: SCR_001847]<sup><a href="#CR34" class="usa-link" aria-describedby="CR34">34</a></sup>, and the brain mask estimated previously was refined with a custom variation of the method to reconcile ANTs-derived and FreeSurfer-derived segmentations of the cortical gray-matter of Mindboggle [RRID: SCR_002438]<sup><a href="#CR35" class="usa-link" aria-describedby="CR35">35</a></sup>. Volume-based spatial normalization to two standard spaces (MNI152NLin2009cAsym, MNI152NLin2009cAsym) was performed through nonlinear registration with antsRegistration (ANTs 2.3.3), using brain-extracted versions of both T1w reference and the T1w template. The following templates were selected for spatial normalization: <em>ICBM 152 Nonlinear Asymmetrical template version 2009c</em> [<sup><a href="#CR36" class="usa-link" aria-describedby="CR36">36</a></sup>, RRID: SCR_008796; TemplateFlow ID: MNI152NLin2009cAsym], <em>FSL’s MNI ICBM 152 non-linear 6th Generation Asymmetric Average Brain Stereotaxic Registration Model</em><sup><a href="#CR37" class="usa-link" aria-describedby="CR37">37</a></sup> mni152nlin6asym, RRID: SCR_002823; TemplateFlow ID: MNI152NLin6Asym].</p></section><section id="Sec19"><h4 class="pmc_sec_title">Functional data preprocessing</h4>
<p id="Par40">For each of the 41 BOLD runs found per participant (across all tasks and sessions), the following preprocessing was performed. First, a reference volume and its skull-stripped version were generated by aligning and averaging 1 single-band references (SBRefs). Head-motion parameters with respect to the BOLD reference (transformation matrices, and six corresponding rotation and translation parameters) are estimated before any spatiotemporal filtering using mcflirt [FSL 6.0.5.1: 57b01774]<sup><a href="#CR38" class="usa-link" aria-describedby="CR38">38</a></sup>. The estimated <em>fieldmap</em> was then aligned with rigid-registration to the target EPI (echo-planar imaging) reference run. The field coefficients were mapped on to the reference EPI using the transform. The BOLD reference was then co-registered to the T1w reference using bbregister (FreeSurfer) which implements boundary-based registration<sup><a href="#CR39" class="usa-link" aria-describedby="CR39">39</a></sup>. Co-registration was configured with nine degrees of freedom to account for distortions remaining in the BOLD reference. First, a reference volume and its skull-stripped version were generated using a custom methodology of <em>fMRIPrep</em>. Several confounding time-series were calculated based on the <em>preprocessed BOLD</em>: framewise displacement (FD), DVARS and three region-wise global signals. FD was computed using two formulations following Power (absolute sum of relative motions<sup><a href="#CR40" class="usa-link" aria-describedby="CR40">40</a></sup>) and Jenkinson (relative root mean square displacement between affines<sup><a href="#CR38" class="usa-link" aria-describedby="CR38">38</a></sup>). FD and DVARS are calculated for each functional run, both using their implementations in <em>Nipype</em> following the definitions by Powers and colleagues<sup><a href="#CR40" class="usa-link" aria-describedby="CR40">40</a></sup>. The three global signals are extracted within the CSF, the WM, and the whole-brain masks. Additionally, a set of physiological regressors were extracted to allow for component-based noise correction <em>CompCor</em><sup><a href="#CR41" class="usa-link" aria-describedby="CR41">41</a></sup>. Principal components are estimated after high-pass filtering the <em>preprocessed BOLD</em> time-series (using a discrete cosine filter with 128s cut-off) for the two <em>CompCor</em> variants: temporal (tCompCor) and anatomical (aCompCor). tCompCor components are then calculated from the top 2% variable voxels within the brain mask. For aCompCor, three probabilistic masks (CSF, WM and combined CSF+WM) are generated in anatomical space. The implementation differs from that of Behzadi <em>et al</em>. in that instead of eroding the masks by 2 pixels on BOLD space, the aCompCor masks are subtracted a mask of pixels that likely contain a volume fraction of GM. This mask is obtained by dilating a GM mask extracted from the FreeSurfer’s <em>aseg</em> segmentation, and it ensures components are not extracted from voxels containing a minimal fraction of GM. Finally, these masks are resampled into BOLD space and binarized by thresholding at 0.99 (as in the original implementation). Components are also calculated separately within the WM and CSF masks. For each CompCor decomposition, the <em>k</em> components with the largest singular values are retained, such that the retained components” time series are sufficient to explain 50 percent of variance across the nuisance mask (CSF, WM, combined, or temporal). The remaining components are dropped from consideration. The head-motion estimates calculated in the correction step were also placed within the corresponding confounds file. The confound time series derived from head motion estimates and global signals were expanded with the inclusion of temporal derivatives and quadratic terms for each<sup><a href="#CR42" class="usa-link" aria-describedby="CR42">42</a></sup>. Frames that exceeded a threshold of 0.9 mm FD or 1.5 standardised DVARS were annotated as motion outliers. The BOLD time-series were resampled into standard space, generating a <em>preprocessed BOLD run in MNI152NLin2009cAsym space</em>. First, a reference volume and its skull-stripped version were generated using a custom methodology of <em>fMRIPrep</em>. The BOLD time-series were resampled onto the following surfaces (FreeSurfer reconstruction nomenclature): <em>fsaverage</em>. <em>Grayordinates</em> files<sup><a href="#CR43" class="usa-link" aria-describedby="CR43">43</a></sup> containing 91k samples were also generated using the highest-resolution fsaverage as intermediate standardized surface space. All resamplings can be performed with <em>a single interpolation step</em> by composing all the pertinent transformations (i.e. head-motion transform matrices, susceptibility distortion correction when available, and co-registrations to anatomical and output spaces). Gridded (volumetric) resamplings were performed using antsApplyTransforms (ANTs), configured with Lanczos interpolation to minimize the smoothing effects of other kernels<sup><a href="#CR44" class="usa-link" aria-describedby="CR44">44</a></sup>. Non-gridded (surface) resamplings were performed using mri_vol2surf (FreeSurfer).</p></section></section><section id="Sec20"><h3 class="pmc_sec_title">Pre-session questionnaires</h3>
<p id="Par41">To connect neuroimaging and behavioral parameters to general psychosocial characteristics, we administered a battery of questionnaires prior to participants’ first visit (Table <a href="#Tab3" class="usa-link">3</a>).</p></section><section id="Sec21"><h3 class="pmc_sec_title">Task instructions</h3>
<p id="Par42">During the behavioral instruction phase, we ensured that participant were informed of the same instructions, despite being introduced to different individuals. Therefore, scripted dialogues were provided to experimenters to be verbally read aloud (hosted on: <a href="https://github.com/spatialtopology/calibrate/tree/main/dialogue" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/calibrate/tree/main/dialogue</a>). This was accompanied by visual aids presented on a monitor in front of participants. Afterwards, participants would complete practice tasks, which are located in github repositories (<a href="https://github.com/spatialtopology/task-alignvideo/blob/main/scripts/RUN_alignvideos.m" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/task-alignvideo/blob/main/scripts/RUN_alignvideos.m</a>; <a href="https://github.com/spatialtopology/fractional_factorials/blob/master/RUN_practice.m" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/fractional_factorials/blob/master/RUN_practice.m</a>).</p>
<section id="Sec22"><h4 class="pmc_sec_title">Scan setup</h4>
<section id="FPar19"><h5 class="pmc_sec_title">Audio Calibration</h5>
<p id="Par43">To ensure that auditory stimuli delivered during the experimental tasks would be presented at a volume that was perceptible to the participant, prior to each scan session, participants completed a brief audio calibration task. During initial structural scans (i.e., scout, PEpolar scans), a video clip was played and the participant provided a rating to indicate whether the volume was set to a satisfactory level (<a href="https://github.com/spatialtopology/calibrate/blob/main/scripts/RUN_audio_calibrate.m" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/calibrate/blob/main/scripts/RUN_audio_calibrate.m</a>). After the audio calibration task was complete, the experimenters verbally confirmed with the participant that the final volume level was adequate.</p></section><section id="FPar20"><h5 class="pmc_sec_title">Arm Measurement Procedures for Application of Thermal Device</h5>
<p id="Par44">Two arm sites were identified for the administration of thermal stimuli during the multimodal negative affect task-social task. To ensure the same sites were used reliably across sessions, we developed an arm measurement protocol. First, the experimenter took an initial measurement along the midline of the participants left arm: from the crease of the elbow to the crease of the wrist. Using this baseline measurement, the experimenter marked two primary sites, located 1/3 and 2/3 of the distance from the elbow to the wrist. The thermode was applied to these sites and the participant completed a pain screening procedure to verify that they could tolerate the noxious stimuli used during the study. If participants reported hypersensitivity or hyposensitivity on either of the primary arm sites, a secondary site was used, 3 cm below the primary site locations. If hypersensitivity or hyposensitivity was also reported at the secondary arm sites, then the participant was removed from the experiment.</p></section></section></section><section id="Sec23"><h3 class="pmc_sec_title">Preprocessing computing environment</h3>
<p id="Par45">The BIDS-formatted data was analyzed at the Johns Hopkins University Joint High Performance Computing Exchange, a high-performance cluster running CentOS Linux 7.9 and the Sun Grid Engine scheduler. On the Exchange, software packages are made accessible via lmod<sup><a href="#CR45" class="usa-link" aria-describedby="CR45">45</a></sup>. For this dataset, job submissions were managed with targets<sup><a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup>, which interfaces with the scheduler via batchtools<sup><a href="#CR47" class="usa-link" aria-describedby="CR47">47</a></sup>. These packages were tracked via renv<sup><a href="#CR48" class="usa-link" aria-describedby="CR48">48</a></sup>. Each job consisted of a call to a Singularity image<sup><a href="#CR49" class="usa-link" aria-describedby="CR49">49</a>,<a href="#CR50" class="usa-link" aria-describedby="CR50">50</a></sup> which implemented one of the analyses described above (e.g., fMRIPrep, MRIQC). The derivatives of these apps were tracked by git-annex and DataLad<sup><a href="#CR51" class="usa-link" aria-describedby="CR51">51</a></sup>.</p></section></section><section id="Sec24"><h2 class="pmc_sec_title">Data Records</h2>
<p id="Par46">The unprocessed source data — with corresponding metadata, events files, and stimuli — are publicly available on OpenNeuro (<a href="https://openneuro.org/datasets/ds005256/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://openneuro.org/datasets/ds005256/</a>)<sup><a href="#CR52" class="usa-link" aria-describedby="CR52">52</a></sup>. The dataset is organized abiding the Brain Imaging Data Structure (BIDS)<sup><a href="#CR53" class="usa-link" aria-describedby="CR53">53</a></sup> version 1.9.0, which allows for standardized file naming convention and storage structure for accessibility and reproducibility across neuroimaging datasets. Further details on the BIDS format can be found at <a href="https://bids-specification.readthedocs.io/en/v1.9.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://bids-specification.readthedocs.io/en/v1.9.0/</a>. Participants are indexed with numerical identifiers (e.g. sub-0001) and scanned across multiple sessions (ses-01, ses-02, etc). Within each session, different tasks were performed (task-alignvideos, task-narratives, task-faces, etc.), with multiple runs for each task (run-01, run-02 etc.). Each run may vary in task instructions or counterbalancing schemes depending on the task- type (see subsection “Specific Tasks” for further details).</p>
<p id="Par47">At the participant level, session-specific subdirectories (ses-01 to ses-04) contain folders for anatomical (anat), (func), and (fmap) data. T1-weighted images and diffusion weighted images are stored under anat/ (collected only during ses-01), functional EPI images are under func/ (available for all sessions), and corresponding B0 maps are hosted under fmap/, which can be utilized for further distortion correction. Sidecar JSON files accompanying these images provide metadata on MRI acquisition parameters. For each functional data, _events.tsv files document timestamps and metadata for trial event during functional tasks. Each session directory also includes a _scans.tsv file and corresponding JSON file, which documents filename and task conditions that were operated on a run- level. (For example, the column task-social_runtype within _scans.tsv specifics the subtask out of three subtasks performed within task-social). The top-level directory includes a data_description.json file with metadata on licensing, acknowledgements, and funding. A code/ directory contains scripts used for dataset duration, (available on github at <a href="http://github.com/spatialtopology/spacetop-prep" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">github.com/spatialtopology/spacetop-prep</a>), and a stimuli/ directory hosts all the stimuli presented in the functional tasks, organized by task type. A README and CHANGE file provide additional dataset documentation.</p>
<p id="Par48">This dataset was curated using DataLad (<a href="https://www.datalad.org/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.datalad.org/</a>), whih integrates git and git-annex on large scale datasets. DataLad allows users to keep track of any changes made to the source data files and its derivatives while enabling subdatasets and its independent download, manipulation or purging of subdatasets, such as code/ and stimuli/.</p></section><section id="Sec25"><h2 class="pmc_sec_title">Technical Validation</h2>
<section id="Sec26"><h3 class="pmc_sec_title">Preprocessing metrics</h3>
<p id="Par49">For quality control, we used MRIQC BIDS-App<sup><a href="#CR54" class="usa-link" aria-describedby="CR54">54</a></sup> and extracted image quality metrics (IQMs). To demonstrate quality of the data, we focus on temporal signal to noise ratio (tSNR) and framewise displacement (FD). For the tSNR, per run, we calculate the mean image and temporal standard deviation image and divide the two. The mean image was generated from fMRIPrep, the standard deviation map was generated using fslmaths. These tSNR maps are aggregated to the participant level (Fig. <a href="#Fig5" class="usa-link">5a)</a>. The tSNR maps are fairly homogenous across tasks, so we have plotted the median tSNR map from the task-alignvideo as a reference (Fig. <a href="#Fig5" class="usa-link">5b)</a>. In addition, we extract the framewise displacement values per run, average within-participant, and aggregate it to the group level (Fig. <a href="#Fig5" class="usa-link">5c)</a>. Each task’s median FD value is smaller than 0.2 mm, and comparable or smaller than that when compared to the FD values of a large scale dataset, UKbiobank<sup><a href="#CR55" class="usa-link" aria-describedby="CR55">55</a></sup>.</p>
<figure class="fig xbox font-sm" id="Fig5"><h4 class="obj_head">Fig. 5.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373947_41597_2025_5154_Fig5_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2fa4/12373947/ac37e88ce3ec/41597_2025_5154_Fig5_HTML.jpg" loading="lazy" id="d33e3044" height="763" width="659" alt="Fig. 5"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig5/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Image quality metrics. <strong>(a)</strong> Temporal signal to noise ratio (tSNR) was calculated within-subject runs and aggregated across participants. Each density plot represents the distribution of tSNR median values across participants, also reflected in the task-corresponding color markers. The black color markers indicate the group average median tSNR value, calculated across within-mask voxels. The black error bars represent the within-subjects confidence interval for the median tSNR value; Given that task-shortvideo has one run in the experiment, the error bar reflects the between-subject confidence interval. As indicated in the plot, median tSNR confidence intervals shrink as a function of repeated runs (alignvideos 13 runs; faces 3 runs; fractional 2 runs; narratives 4 runs; shortvideo 1 run; social 18 runs; all tasks 41 runs). <strong>(b)</strong> tSNR of align video task across the cortical surface. Colors indicate median tSNR per voxel. tSNR maps were computed using the preprocessed MNI runwise maps. Groupwise median tSNR maps were converted to fsaverage6 space, using neuromaps, for visualization. <strong>(c)</strong> Head movement is kept to a minimum, reflected in framewise-displacement (FD) values. Each density plot represents the distribution of FD values across participants, also reflected in the task-corresponding color markers. The box plot represents the median value and interquartile range of the group level FD distribution. UKbiobank (UKB) FD values are displayed here for comparison; Across all tasks, the current dataset FD values are lower and less variable compared to that of the “UKB faces” task. “UKB rest” condition has a slightly lower median as it serves as a no task condition compared to the tasks in our current dataset. Overall, head movement was kept to a minimum, as demonstrated by framewise displacement lower than that of the UK biobank, in spite of the longer scan protocol.</p></figcaption></figure></section><section id="Sec27"><h3 class="pmc_sec_title">Statistical maps</h3>
<p id="Par50">For data quality validation, we analyzed general linear model (GLM) contrast maps from four different tasks (Fig. <a href="#Fig6" class="usa-link">6</a>). We primarily aimed to evaluate that the statistical maps showed robust effects consistent with prior research. Each statistical map is a group-level average of specific contrasts, in which the condition of interest was modeled as a boxcar function, contrasted against an implicit baseline of fixation epochs, and group-averaged across subjects, later thresholded (FDR <em>q</em> &lt; 0.001 for task-social, task-narratives, and task-faces as the sample size includes the entire dataset; FDR <em>q</em> &lt; 0.05 for task-fractional as the sample size includes a subset of the dataset) For task-social, we present conditions of somatic pain, vicarious pain, and cognitive effort during stimulus presentation, contrasted against an implicit baseline. The motor response is when the trackball button was pressed. In the narratives task, we estimated the neural correlates of reading and listening to the narratives, resulting in robust activation in the temporal cortices. The task-faces statistical map recruits greater activation in the fusiform cortices when participants view faces compared to an implicit baseline; lastly, robust activation in the temporal parietal junction and prefrontal cortices are notable during task-fraction for both image-based and text-based theory of mind tasks.</p>
<figure class="fig xbox font-sm" id="Fig6"><h4 class="obj_head">Fig. 6.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373947_41597_2025_5154_Fig6_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/2fa4/12373947/0f0c085152b0/41597_2025_5154_Fig6_HTML.jpg" loading="lazy" id="d33e3099" height="410" width="660" alt="Fig. 6"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig6/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Statistical maps of canonical contrasts across four tasks. Group-average statistical maps from each task suggests robust activation that aligns with past literature/activation patterns. Each map is constructed by modeling conditions of interest as a box car function (e.g. somatic pain, vicarious pain, faces), group-averaged across participants, and thresholded at FDR q &lt; 0.001 or q &lt; 0.05. Within task-social, we see canonical activation in the somatosensory and dorsal posterior insula for somatic pain conditions. Within Task-fractional, the temporal cortex displays robust activation. task-social statistical maps involve activation in the temporal parietal junction across text- and image-based theory of mind tasks. Task-faces recruits the fusiform face cortex.</p></figcaption></figure></section></section><section id="Sec28"><h2 class="pmc_sec_title">Usage Notes</h2>
<p id="Par51">This dataset is accessible on OpenNeuro using the following link: <a href="https://openneuro.org/datasets/ds005256/versions/1.1.0" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://openneuro.org/datasets/ds005256/versions/1.1.0</a><sup><a href="#CR52" class="usa-link" aria-describedby="CR52">52</a></sup>. Users can download the dataset using the web browser or via command line tools. Using openneuro-cli: openneuro download –snapshot 1.0.0 ds005256 ds005256-download/. Further usage details on OpenNeuro datasets can be found at <a href="https://docs.openneuro.org/user_guide.html#viewing-and-downloading-a-dataset" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://docs.openneuro.org/user_guide.html#viewing-and-downloading-a-dataset</a>. Users can also download the dataset via DataLad: datalad install<a href="https://github.com/OpenNeuroDatasets/ds005256.git" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/OpenNeuroDatasets/ds005256.git</a>.</p></section><section id="ack1" class="ack"><h2 class="pmc_sec_title">Acknowledgements</h2>
<p>We would like to express our gratitude to the following individuals and institutions for their invaluable contributions to this study: Elizabeth C. Tremmel for the insightful comments, Terry J. Sackett and Courtney Rogers for the technical support in data collection; Chandana Kodiweera for the valuable input on MR quality control; Ma Feilong for technical support on the dynamic faces analysis. This data collection was funded by NIBIB:R01EB026549-03.</p></section><section id="notes1"><h2 class="pmc_sec_title">Author contributions</h2>
<p>T.W., H.J., P.A.K., X.H. M.L. conceived the experiment(s). H.J., P.A.K., X.H., M.S., M.O.H. experimental setup H.J., M.A., B.J.H., E.I.M. B.P. conducted the experiment H.J., Y.O.H., Z.M. data organization P.S., H.J., Y.O.H., B.P. data preprocessing H.J., Z.M., O.G.C. data quality control and QC analysis All authors reviewed the manuscript.</p></section><section id="notes2"><h2 class="pmc_sec_title">Code availability</h2>
<p>Code for stimulus presentation and data acquisition is published in a GitHub repository (<a href="https://github.com/spatialtopology" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology</a>). To ensure reproducibility of the experimental procedures, we released the code as version 1, prior to data collection (“task-alignvideo”: <a href="https://github.com/spatialtopology/alignvideos/releases/tag/v1.0.0-stable" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/alignvideos/releases/tag/v1.0.0-stable</a>, “task-social”: <a href="https://github.com/spatialtopology/social_influence/releases/tag/v1.0.0-stable" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/social_influence/releases/tag/v1.0.0-stable</a>, “task-faces”: <a href="https://github.com/spatialtopology/task-faces/releases/tag/1.0.0" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/task-faces/releases/tag/1.0.0</a>, “task-narratives”: <a href="https://github.com/spatialtopology/narratives/releases/tag/v.1.0.0" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/narratives/releases/tag/v.1.0.0</a>, “task-shortvideo”: <a href="https://github.com/spatialtopology/shortvideos/releases/tag/v1.0.0-stable" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/shortvideos/releases/tag/v1.0.0-stable</a>, “task-fractional”: <a href="https://github.com/spatialtopology/fractional_factorials/releases/tag/v.1.0.0" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/fractional_factorials/releases/tag/v.1.0.0</a>). Code for data wrangling, preprocessing, and analyzing the data is in the GitHub repository (<a href="https://github.com/spatialtopology/spacetop-prep" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/spacetop-prep</a>). Neuroimaging data and behavioral data are BIDS-formatted in DataLad<sup><a href="#CR56" class="usa-link" aria-describedby="CR56">56</a></sup>. Code for data wrangling and analyzing the data is in the github repository (<a href="https://github.com/spatialtopology/spacetop-prep" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/spacetop-prep</a>). Neuroimaging data and behavioral data are BIDS-formatted in DataLad (<a href="https://openneuro.org/datasets/ds005256" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://openneuro.org/datasets/ds005256</a>).</p></section><section id="FPar21"><h2 class="pmc_sec_title">Competing interests</h2>
<p id="Par52">The authors declare no competing interests.</p></section><section id="fn-group1" class="fn-group"><h2 class="pmc_sec_title">Footnotes</h2>
<div class="fn-group p font-secondary-light font-sm">
<div class="fn p" id="fn1"><p><strong>Publisher’s note</strong> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div>
<div class="fn p" id="fn2"><p>These authors contributed equally: Maryam Amini, Bethany J. Hunt, Eilis I. Murphy.</p></div>
</div></section><section id="_ci93_" lang="en" class="contrib-info"><h2 class="pmc_sec_title">Contributor Information</h2>
<p>Heejung Jung, Email: Heejung.jung@dartmouth.edu.</p>
<p>Tor D. Wager, Email: Tor.D.Wager@dartmouth.edu</p></section><section id="Bib1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="Bib1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="CR1">
<span class="label">1.</span><cite>Naselaris, T., Allen, E. &amp; Kay, K. Extensive sampling for complete models of individual brains. <em>Current Opinion in Behavioral Sciences</em><strong>40</strong>, 45–51, 10.1016/j.cobeha.2020.12.008 (2021).</cite> [<a href="https://scholar.google.com/scholar_lookup?Naselaris,%20T.,%20Allen,%20E.%20&amp;%20Kay,%20K.%20Extensive%20sampling%20for%20complete%20models%20of%20individual%20brains.%20Current%20Opinion%20in%20Behavioral%20Sciences40,%2045%E2%80%9351,%2010.1016/j.cobeha.2020.12.008%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR2">
<span class="label">2.</span><cite>Nastase, S. A., Goldstein, A. &amp; Hasson, U. Keep it real: rethinking the primacy of experimental control in cognitive neuroscience. <em>Neuroimage</em><strong>222</strong>, 117254, 10.31234/osf.io/whn6d (2020).
</cite> [<a href="https://doi.org/10.1016/j.neuroimage.2020.117254" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7789034/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32800992/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Nastase,%20S.%20A.,%20Goldstein,%20A.%20&amp;%20Hasson,%20U.%20Keep%20it%20real:%20rethinking%20the%20primacy%20of%20experimental%20control%20in%20cognitive%20neuroscience.%20Neuroimage222,%20117254,%2010.31234/osf.io/whn6d%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR3">
<span class="label">3.</span><cite>Sonkusare, S., Breakspear, M. &amp; Guo, C. Naturalistic stimuli in neuroscience: critically acclaimed. <em>Trends in Cognitive Sciences</em><strong>23</strong>, 699–714, 10.1016/j.tics.2019.05.004 (2019).
</cite> [<a href="https://doi.org/10.1016/j.tics.2019.05.004" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31257145/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Sonkusare,%20S.,%20Breakspear,%20M.%20&amp;%20Guo,%20C.%20Naturalistic%20stimuli%20in%20neuroscience:%20critically%20acclaimed.%20Trends%20in%20Cognitive%20Sciences23,%20699%E2%80%93714,%2010.1016/j.tics.2019.05.004%20(2019)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR4">
<span class="label">4.</span><cite>Jääskeläinen, I. P., Sams, M., Glerean, E. &amp; Ahveninen, J. Movies and narratives as naturalistic stimuli in neuroimaging. <em>Neuroimage</em><strong>224</strong>, 117445, 10.1016/j.neuroimage.2020.117445 (2021).
</cite> [<a href="https://doi.org/10.1016/j.neuroimage.2020.117445" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7805386/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33059053/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?J%C3%A4%C3%A4skel%C3%A4inen,%20I.%20P.,%20Sams,%20M.,%20Glerean,%20E.%20&amp;%20Ahveninen,%20J.%20Movies%20and%20narratives%20as%20naturalistic%20stimuli%20in%20neuroimaging.%20Neuroimage224,%20117445,%2010.1016/j.neuroimage.2020.117445%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR5">
<span class="label">5.</span><cite>David, S. V., Vinje, W. E. &amp; Gallant, J. L. Natural stimulus statistics alter the receptive field structure of v1 neurons. <em>Journal of Neuroscience</em><strong>24</strong>, 6991–7006, 10.1523/jneurosci.1422-04.2004 (2004).
</cite> [<a href="https://doi.org/10.1523/JNEUROSCI.1422-04.2004" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6729594/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/15295035/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?David,%20S.%20V.,%20Vinje,%20W.%20E.%20&amp;%20Gallant,%20J.%20L.%20Natural%20stimulus%20statistics%20alter%20the%20receptive%20field%20structure%20of%20v1%20neurons.%20Journal%20of%20Neuroscience24,%206991%E2%80%937006,%2010.1523/jneurosci.1422-04.2004%20(2004)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR6">
<span class="label">6.</span><cite>Huth, A. G., De Heer, W. A., Griffiths, T. L., Theunissen, F. E. &amp; Gallant, J. L. Natural speech reveals the semantic maps that tile human cerebral cortex. <em>Nature</em><strong>532</strong>, 453–458, 10.1038/nature17637 (2016).
</cite> [<a href="https://doi.org/10.1038/nature17637" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4852309/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27121839/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Huth,%20A.%20G.,%20De%20Heer,%20W.%20A.,%20Griffiths,%20T.%20L.,%20Theunissen,%20F.%20E.%20&amp;%20Gallant,%20J.%20L.%20Natural%20speech%20reveals%20the%20semantic%20maps%20that%20tile%20human%20cerebral%20cortex.%20Nature532,%20453%E2%80%93458,%2010.1038/nature17637%20(2016)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR7">
<span class="label">7.</span><cite>Fisher, R. A.<em>Statistical Methods for Research Workers</em>, vol. 20 (Oliver and Boyd, 1928).</cite>
</li>
<li id="CR8">
<span class="label">8.</span><cite>Rubin, D. B. Causal inference using potential outcomes: Design, modeling, decisions. <em>Journal of the American Statistical Association</em><strong>100</strong>, 322–331, 10.1198/016214504000001880 (2005).</cite> [<a href="https://scholar.google.com/scholar_lookup?Rubin,%20D.%20B.%20Causal%20inference%20using%20potential%20outcomes:%20Design,%20modeling,%20decisions.%20Journal%20of%20the%20American%20Statistical%20Association100,%20322%E2%80%93331,%2010.1198/016214504000001880%20(2005)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR9">
<span class="label">9.</span><cite>Little, R. J. &amp; Rubin, D. B. Causal effects in clinical and epidemiological studies via potential outcomes: concepts and analytical approaches. <em>Annual Review of Public Health</em><strong>21</strong>, 121–145, 10.1146/annurev.publhealth.21.1.121 (2000).
</cite> [<a href="https://doi.org/10.1146/annurev.publhealth.21.1.121" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/10884949/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Little,%20R.%20J.%20&amp;%20Rubin,%20D.%20B.%20Causal%20effects%20in%20clinical%20and%20epidemiological%20studies%20via%20potential%20outcomes:%20concepts%20and%20analytical%20approaches.%20Annual%20Review%20of%20Public%20Health21,%20121%E2%80%93145,%2010.1146/annurev.publhealth.21.1.121%20(2000)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR10">
<span class="label">10.</span><cite>Neyman, J. On the two different aspects of the representative method: The method of stratified sampling and the method of purposive selection. <em>Journal of the Royal Statistical Society</em><strong>97</strong>, 558–625, 10.2307/2342192 (1934).</cite> [<a href="https://scholar.google.com/scholar_lookup?Neyman,%20J.%20On%20the%20two%20different%20aspects%20of%20the%20representative%20method:%20The%20method%20of%20stratified%20sampling%20and%20the%20method%20of%20purposive%20selection.%20Journal%20of%20the%20Royal%20Statistical%20Society97,%20558%E2%80%93625,%2010.2307/2342192%20(1934)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR11">
<span class="label">11.</span><cite>Wager, T. D. &amp; Nichols, T. E. Optimization of experimental design in fmri: a general framework using a genetic algorithm. <em>Neuroimage</em><strong>18</strong>, 293–309, 10.1016/s1053-8119(02)00046-0 (2003).
</cite> [<a href="https://doi.org/10.1016/s1053-8119(02)00046-0" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/12595184/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Wager,%20T.%20D.%20&amp;%20Nichols,%20T.%20E.%20Optimization%20of%20experimental%20design%20in%20fmri:%20a%20general%20framework%20using%20a%20genetic%20algorithm.%20Neuroimage18,%20293%E2%80%93309,%2010.1016/s1053-8119(02)00046-0%20(2003)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR12">
<span class="label">12.</span><cite>Wager, T. D., Vazquez, A., Hernandez, L. &amp; Noll, D. C. Accounting for nonlinear bold effects in fmri: parameter estimates and a model for prediction in rapid event-related studies. <em>Neuroimage</em><strong>25</strong>, 206–218, 10.1016/j.neuroimage.2004.11.008 (2005).
</cite> [<a href="https://doi.org/10.1016/j.neuroimage.2004.11.008" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/15734356/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Wager,%20T.%20D.,%20Vazquez,%20A.,%20Hernandez,%20L.%20&amp;%20Noll,%20D.%20C.%20Accounting%20for%20nonlinear%20bold%20effects%20in%20fmri:%20parameter%20estimates%20and%20a%20model%20for%20prediction%20in%20rapid%20event-related%20studies.%20Neuroimage25,%20206%E2%80%93218,%2010.1016/j.neuroimage.2004.11.008%20(2005)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR13">
<span class="label">13.</span><cite>Burock, M. A., Buckner, R. L., Woldorff, M. G., Rosen, B. R. &amp; Dale, A. M. Randomized event-related experimental designs allow for extremely rapid presentation rates using functional mri. <em>Neuroreport</em><strong>9</strong>, 3735–3739, 10.1097/00001756-199811160-00030 (1998).
</cite> [<a href="https://doi.org/10.1097/00001756-199811160-00030" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/9858388/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Burock,%20M.%20A.,%20Buckner,%20R.%20L.,%20Woldorff,%20M.%20G.,%20Rosen,%20B.%20R.%20&amp;%20Dale,%20A.%20M.%20Randomized%20event-related%20experimental%20designs%20allow%20for%20extremely%20rapid%20presentation%20rates%20using%20functional%20mri.%20Neuroreport9,%203735%E2%80%933739,%2010.1097/00001756-199811160-00030%20(1998)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR14">
<span class="label">14.</span><cite>Hafri, A., Trueswell, J. C. &amp; Epstein, R. A. Neural representations of observed actions generalize across static and dynamic visual input. <em>Journal of Neuroscience</em><strong>37</strong>, 3056–3071, 10.1523/JNEUROSCI.2496-16.2017 (2017).
</cite> [<a href="https://doi.org/10.1523/JNEUROSCI.2496-16.2017" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6596723/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/28209734/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Hafri,%20A.,%20Trueswell,%20J.%20C.%20&amp;%20Epstein,%20R.%20A.%20Neural%20representations%20of%20observed%20actions%20generalize%20across%20static%20and%20dynamic%20visual%20input.%20Journal%20of%20Neuroscience37,%203056%E2%80%933071,%2010.1523/JNEUROSCI.2496-16.2017%20(2017)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR15">
<span class="label">15.</span><cite>Dastjerdi, M., Ozker, M., Foster, B. L., Rangarajan, V. &amp; Parvizi, J. Numerical processing in the human parietal cortex during experimental and natural conditions. <em>Nature Communications</em><strong>4</strong>, 2528, 10.1038/ncomms3528 (2013).
</cite> [<a href="https://doi.org/10.1038/ncomms3528" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3826627/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/24129341/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Dastjerdi,%20M.,%20Ozker,%20M.,%20Foster,%20B.%20L.,%20Rangarajan,%20V.%20&amp;%20Parvizi,%20J.%20Numerical%20processing%20in%20the%20human%20parietal%20cortex%20during%20experimental%20and%20natural%20conditions.%20Nature%20Communications4,%202528,%2010.1038/ncomms3528%20(2013)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR16">
<span class="label">16.</span><cite>Haxby, J. V., Guntupalli, J. S., Nastase, S. A. &amp; Feilong, M. Hyperalignment: Modeling shared information encoded in idiosyncratic cortical topographies. <em>eLife</em><strong>9</strong>, 10.7554/elife.56601 (2020).</cite> [<a href="https://doi.org/10.7554/eLife.56601" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7266639/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32484439/" class="usa-link">PubMed</a>]</li>
<li id="CR17">
<span class="label">17.</span><cite>Bartoshuk, L. M. <em>et al</em>. Valid across-group comparisons with labeled scales: the glms versus magnitude matching. <em>Physiology &amp; Behavior</em><strong>82</strong>, 109–114, 10.1016/j.physbeh.2004.02.033 (2004).
</cite> [<a href="https://doi.org/10.1016/j.physbeh.2004.02.033" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/15234598/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Bartoshuk,%20L.%20M.%20et%20al.%20Valid%20across-group%20comparisons%20with%20labeled%20scales:%20the%20glms%20versus%20magnitude%20matching.%20Physiology%20&amp;%20Behavior82,%20109%E2%80%93114,%2010.1016/j.physbeh.2004.02.033%20(2004)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR18">
<span class="label">18.</span><cite>Lucey, P., Cohn, J. F., Prkachin, K. M., Solomon, P. E. &amp; Matthews, I. Painful data: The unbc-mcmaster shoulder pain expression archive database. In <em>Automatic Face &amp; Gesture Recognition (FG)</em>, 10.1109/fg.2011.5771462 (IEEE, 2011).</cite>
</li>
<li id="CR19">
<span class="label">19.</span><cite>Ganis, G. &amp; Kievit, R. A new set of three-dimensional shapes for investigating mental rotation processes: validation data and stimulus set. <em>Journal of Open Psychology Data</em>10.5334/jopd.ai (2015).</cite>
</li>
<li id="CR20">
<span class="label">20.</span><cite>Polti, G.<em>The thirty-six dramatic situations</em> (Editor Company, 1917).</cite>
</li>
<li id="CR21">
<span class="label">21.</span><cite>Posner, M. I. Orienting of attention. <em>Quarterly journal of experimental psychology</em><strong>32</strong>, 3–25, 10.1080/00335558008248231 (1980).
</cite> [<a href="https://doi.org/10.1080/00335558008248231" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/7367577/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Posner,%20M.%20I.%20Orienting%20of%20attention.%20Quarterly%20journal%20of%20experimental%20psychology32,%203%E2%80%9325,%2010.1080/00335558008248231%20(1980)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR22">
<span class="label">22.</span><cite>Dodell-Feder, D., Koster-Hale, J., Bedny, M. &amp; Saxe, R. fmri item analysis in a theory of mind task. <em>Neuroimage</em><strong>55</strong>, 705–712, 10.1016/j.neuroimage.2010.12.040 (2011).
</cite> [<a href="https://doi.org/10.1016/j.neuroimage.2010.12.040" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/21182967/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Dodell-Feder,%20D.,%20Koster-Hale,%20J.,%20Bedny,%20M.%20&amp;%20Saxe,%20R.%20fmri%20item%20analysis%20in%20a%20theory%20of%20mind%20task.%20Neuroimage55,%20705%E2%80%93712,%2010.1016/j.neuroimage.2010.12.040%20(2011)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR23">
<span class="label">23.</span><cite>Spunt, R. P. &amp; Adolphs, R. Validating the why/how contrast for functional mri studies of theory of mind. <em>Neuroimage</em><strong>99</strong>, 301–311, 10.1016/j.neuroimage.2014.05.023 (2014).
</cite> [<a href="https://doi.org/10.1016/j.neuroimage.2014.05.023" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4111963/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/24844746/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Spunt,%20R.%20P.%20&amp;%20Adolphs,%20R.%20Validating%20the%20why/how%20contrast%20for%20functional%20mri%20studies%20of%20theory%20of%20mind.%20Neuroimage99,%20301%E2%80%93311,%2010.1016/j.neuroimage.2014.05.023%20(2014)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR24">
<span class="label">24.</span><cite>Halchenko, Y. <em>et al</em>. nipy/heudiconv v0.9.0, 10.5281/zenodo.4390433 (2020).</cite>
</li>
<li id="CR25">
<span class="label">25.</span><cite>Li, X., Morgan, P. S., Ashburner, J., Smith, J. &amp; Rorden, C. The first step for neuroimaging data analysis: Dicom to nifti conversion. <em>Journal of Neuroscience Methods</em><strong>264</strong>, 47–56, 10.1016/j.jneumeth.2016.03.001 (2016).
</cite> [<a href="https://doi.org/10.1016/j.jneumeth.2016.03.001" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/26945974/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Li,%20X.,%20Morgan,%20P.%20S.,%20Ashburner,%20J.,%20Smith,%20J.%20&amp;%20Rorden,%20C.%20The%20first%20step%20for%20neuroimaging%20data%20analysis:%20Dicom%20to%20nifti%20conversion.%20Journal%20of%20Neuroscience%20Methods264,%2047%E2%80%9356,%2010.1016/j.jneumeth.2016.03.001%20(2016)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR26">
<span class="label">26.</span><cite>Halchenko, Y., Haselgrove, C., Travers, M., Wodder, J. &amp; Macdonald, A. Repronim/containers - containerized environments for reproducible neuroimaging, 10.5281/ZENODO.10607992 (2024).</cite>
</li>
<li id="CR27">
<span class="label">27.</span><cite>Esteban, O. <em>et al</em>. fmriprep: a robust preprocessing pipeline for functional mri. <em>Nature Methods</em><strong>16</strong>, 111–116, 10.1038/s41592-018-0235-4 (2018).
</cite> [<a href="https://doi.org/10.1038/s41592-018-0235-4" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6319393/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/30532080/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Esteban,%20O.%20et%20al.%20fmriprep:%20a%20robust%20preprocessing%20pipeline%20for%20functional%20mri.%20Nature%20Methods16,%20111%E2%80%93116,%2010.1038/s41592-018-0235-4%20(2018)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR28">
<span class="label">28.</span><cite>Gorgolewski, K. <em>et al</em>. Nipype: A flexible, lightweight and extensible neuroimaging data processing framework in python. <em>Frontiers in Neuroinformatics</em><strong>5</strong>, 10.3389/fninf.2011.00013 (2011).</cite> [<a href="https://doi.org/10.3389/fninf.2011.00013" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3159964/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/21897815/" class="usa-link">PubMed</a>]</li>
<li id="CR29">
<span class="label">29.</span><cite>Gorgolewski, K. J., Nichols, T., Kennedy, D. N., Poline, J.-B. &amp; Poldrack, R. A. Making replication prestigious. <em>Behavioral and Brain Sciences</em><strong>41</strong>, 10.1017/s0140525x18000663 (2018).</cite> [<a href="https://doi.org/10.1017/S0140525X18000663" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31064546/" class="usa-link">PubMed</a>]</li>
<li id="CR30">
<span class="label">30.</span><cite>Andersson, J. L., Skare, S. &amp; Ashburner, J. How to correct susceptibility distortions in spin-echo echo-planar images: application to diffusion tensor imaging. <em>NeuroImage</em><strong>20</strong>, 870–888, 10.1016/S1053-8119(03)00336-7 (2003).
</cite> [<a href="https://doi.org/10.1016/S1053-8119(03)00336-7" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/14568458/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Andersson,%20J.%20L.,%20Skare,%20S.%20&amp;%20Ashburner,%20J.%20How%20to%20correct%20susceptibility%20distortions%20in%20spin-echo%20echo-planar%20images:%20application%20to%20diffusion%20tensor%20imaging.%20NeuroImage20,%20870%E2%80%93888,%2010.1016/S1053-8119(03)00336-7%20(2003)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR31">
<span class="label">31.</span><cite>Tustison, N. J. <em>et al</em>. N4itk: Improved n3 bias correction. <em>IEEE Transactions on Medical Imaging</em><strong>29</strong>, 1310–1320, 10.1109/TMI.2010.2046908 (2010).
</cite> [<a href="https://doi.org/10.1109/TMI.2010.2046908" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3071855/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/20378467/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Tustison,%20N.%20J.%20et%20al.%20N4itk:%20Improved%20n3%20bias%20correction.%20IEEE%20Transactions%20on%20Medical%20Imaging29,%201310%E2%80%931320,%2010.1109/TMI.2010.2046908%20(2010)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR32">
<span class="label">32.</span><cite>Avants, B., Epstein, C., Grossman, M. &amp; Gee, J. Symmetric diffeomorphic image registration with cross-correlation: Evaluating automated labeling of elderly and neurodegenerative brain. <em>Medical Image Analysis</em><strong>12</strong>, 26–41, 10.1016/j.media.2007.06.004 (2008).
</cite> [<a href="https://doi.org/10.1016/j.media.2007.06.004" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC2276735/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/17659998/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Avants,%20B.,%20Epstein,%20C.,%20Grossman,%20M.%20&amp;%20Gee,%20J.%20Symmetric%20diffeomorphic%20image%20registration%20with%20cross-correlation:%20Evaluating%20automated%20labeling%20of%20elderly%20and%20neurodegenerative%20brain.%20Medical%20Image%20Analysis12,%2026%E2%80%9341,%2010.1016/j.media.2007.06.004%20(2008)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR33">
<span class="label">33.</span><cite>Zhang, Y., Brady, M. &amp; Smith, S. Segmentation of brain MR images through a hidden markov random field model and the expectation-maximization algorithm. <em>IEEE Transactions on Medical Imaging</em><strong>20</strong>, 45–57, 10.1109/42.906424 (2001).
</cite> [<a href="https://doi.org/10.1109/42.906424" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/11293691/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Zhang,%20Y.,%20Brady,%20M.%20&amp;%20Smith,%20S.%20Segmentation%20of%20brain%20MR%20images%20through%20a%20hidden%20markov%20random%20field%20model%20and%20the%20expectation-maximization%20algorithm.%20IEEE%20Transactions%20on%20Medical%20Imaging20,%2045%E2%80%9357,%2010.1109/42.906424%20(2001)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR34">
<span class="label">34.</span><cite>Dale, A. M., Fischl, B. &amp; Sereno, M. I. Cortical surface-based analysis: I. segmentation and surface reconstruction. <em>NeuroImage</em><strong>9</strong>, 179–194, 10.1006/nimg.1998.0395 (1999).
</cite> [<a href="https://doi.org/10.1006/nimg.1998.0395" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/9931268/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Dale,%20A.%20M.,%20Fischl,%20B.%20&amp;%20Sereno,%20M.%20I.%20Cortical%20surface-based%20analysis:%20I.%20segmentation%20and%20surface%20reconstruction.%20NeuroImage9,%20179%E2%80%93194,%2010.1006/nimg.1998.0395%20(1999)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR35">
<span class="label">35.</span><cite>Klein, A. <em>et al</em>. Mindboggling morphometry of human brains. <em>PLOS Computational Biology</em><strong>13</strong>, e1005350, 10.1371/journal.pcbi.1005350 (2017).
</cite> [<a href="https://doi.org/10.1371/journal.pcbi.1005350" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC5322885/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/28231282/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Klein,%20A.%20et%20al.%20Mindboggling%20morphometry%20of%20human%20brains.%20PLOS%20Computational%20Biology13,%20e1005350,%2010.1371/journal.pcbi.1005350%20(2017)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR36">
<span class="label">36.</span><cite>Fonov, V.S., Evans, A.C., McKinstry, R.C., Almli, C.R., &amp; Collins, D.L. Unbiased nonlinear average age-appropriate brain templates from birth to adulthood. <em>NeuroImage</em>, <strong>47</strong>, S102. 10.1016/S1053-8119(09)70884-5 (2009).</cite>
</li>
<li id="CR37">
<span class="label">37.</span><cite>Evans, A., Janke, A., Collins, D. &amp; Baillet, S. Brain templates and atlases. <em>NeuroImage</em><strong>62</strong>, 911–922, 10.1016/j.neuroimage.2012.01.024 (2012).
</cite> [<a href="https://doi.org/10.1016/j.neuroimage.2012.01.024" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/22248580/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Evans,%20A.,%20Janke,%20A.,%20Collins,%20D.%20&amp;%20Baillet,%20S.%20Brain%20templates%20and%20atlases.%20NeuroImage62,%20911%E2%80%93922,%2010.1016/j.neuroimage.2012.01.024%20(2012)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR38">
<span class="label">38.</span><cite>Jenkinson, M., Bannister, P., Brady, M. &amp; Smith, S. Improved optimization for the robust and accurate linear registration and motion correction of brain images. <em>NeuroImage</em><strong>17</strong>, 825–841, 10.1006/nimg.2002.1132 (2002).
</cite> [<a href="https://doi.org/10.1016/s1053-8119(02)91132-8" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/12377157/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Jenkinson,%20M.,%20Bannister,%20P.,%20Brady,%20M.%20&amp;%20Smith,%20S.%20Improved%20optimization%20for%20the%20robust%20and%20accurate%20linear%20registration%20and%20motion%20correction%20of%20brain%20images.%20NeuroImage17,%20825%E2%80%93841,%2010.1006/nimg.2002.1132%20(2002)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR39">
<span class="label">39.</span><cite>Greve, D. N. &amp; Fischl, B. Accurate and robust brain image alignment using boundary-based registration. <em>NeuroImage</em><strong>48</strong>, 63–72, 10.1016/j.neuroimage.2009.06.060 (2009).
</cite> [<a href="https://doi.org/10.1016/j.neuroimage.2009.06.060" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC2733527/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/19573611/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Greve,%20D.%20N.%20&amp;%20Fischl,%20B.%20Accurate%20and%20robust%20brain%20image%20alignment%20using%20boundary-based%20registration.%20NeuroImage48,%2063%E2%80%9372,%2010.1016/j.neuroimage.2009.06.060%20(2009)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR40">
<span class="label">40.</span><cite>Power, J. D. <em>et al</em>. Methods to detect, characterize, and remove motion artifact in resting state fmri. <em>NeuroImage</em><strong>84</strong>, 320–341, 10.1016/j.neuroimage.2013.08.048 (2014).
</cite> [<a href="https://doi.org/10.1016/j.neuroimage.2013.08.048" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3849338/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/23994314/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Power,%20J.%20D.%20et%20al.%20Methods%20to%20detect,%20characterize,%20and%20remove%20motion%20artifact%20in%20resting%20state%20fmri.%20NeuroImage84,%20320%E2%80%93341,%2010.1016/j.neuroimage.2013.08.048%20(2014)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR41">
<span class="label">41.</span><cite>Behzadi, Y., Restom, K., Liau, J. &amp; Liu, T. T. A component based noise correction method (CompCor) for BOLD and perfusion based fmri. <em>NeuroImage</em><strong>37</strong>, 90–101, 10.1016/j.neuroimage.2007.04.042 (2007).
</cite> [<a href="https://doi.org/10.1016/j.neuroimage.2007.04.042" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC2214855/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/17560126/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Behzadi,%20Y.,%20Restom,%20K.,%20Liau,%20J.%20&amp;%20Liu,%20T.%20T.%20A%20component%20based%20noise%20correction%20method%20(CompCor)%20for%20BOLD%20and%20perfusion%20based%20fmri.%20NeuroImage37,%2090%E2%80%93101,%2010.1016/j.neuroimage.2007.04.042%20(2007)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR42">
<span class="label">42.</span><cite>Satterthwaite, T. D. <em>et al</em>. An improved framework for confound regression and filtering for control of motion artifact in the preprocessing of resting-state functional connectivity data. <em>NeuroImage</em><strong>64</strong>, 240–256, 10.1016/j.neuroimage.2012.08.052 (2013).
</cite> [<a href="https://doi.org/10.1016/j.neuroimage.2012.08.052" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3811142/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/22926292/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Satterthwaite,%20T.%20D.%20et%20al.%20An%20improved%20framework%20for%20confound%20regression%20and%20filtering%20for%20control%20of%20motion%20artifact%20in%20the%20preprocessing%20of%20resting-state%20functional%20connectivity%20data.%20NeuroImage64,%20240%E2%80%93256,%2010.1016/j.neuroimage.2012.08.052%20(2013)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR43">
<span class="label">43.</span><cite>Glasser, M. F. <em>et al</em>. The minimal preprocessing pipelines for the human connectome project. <em>NeuroImage</em><strong>80</strong>, 105–124, 10.1016/j.neuroimage.2013.04.127 (2013).
</cite> [<a href="https://doi.org/10.1016/j.neuroimage.2013.04.127" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3720813/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/23668970/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Glasser,%20M.%20F.%20et%20al.%20The%20minimal%20preprocessing%20pipelines%20for%20the%20human%20connectome%20project.%20NeuroImage80,%20105%E2%80%93124,%2010.1016/j.neuroimage.2013.04.127%20(2013)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR44">
<span class="label">44.</span><cite>Lanczos, C. Evaluation of noisy data. <em>Journal of the Society for Industrial and Applied Mathematics Series B Numerical Analysis</em><strong>1</strong>, 76–85, 10.1137/0701007 (1964).</cite> [<a href="https://scholar.google.com/scholar_lookup?Lanczos,%20C.%20Evaluation%20of%20noisy%20data.%20Journal%20of%20the%20Society%20for%20Industrial%20and%20Applied%20Mathematics%20Series%20B%20Numerical%20Analysis1,%2076%E2%80%9385,%2010.1137/0701007%20(1964)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR45">
<span class="label">45.</span><cite>McLay, R., Schulz, K. W., Barth, W. L. &amp; Minyard, T. Best practices for the deployment and management of production hpc clusters. In <em>State of the Practice Reports</em>, SC ”11, 10.1145/2063348.2063360 (ACM, 2011).</cite>
</li>
<li id="CR46">
<span class="label">46.</span><cite>Landau, W. M. The targets r package: a dynamic make-like function-oriented pipeline toolkit for reproducibility and high-performance computing. <em>Journal of Open Source Software</em><strong>6</strong>, 2959, 10.21105/joss.02959 (2021).</cite> [<a href="https://scholar.google.com/scholar_lookup?Landau,%20W.%20M.%20The%20targets%20r%20package:%20a%20dynamic%20make-like%20function-oriented%20pipeline%20toolkit%20for%20reproducibility%20and%20high-performance%20computing.%20Journal%20of%20Open%20Source%20Software6,%202959,%2010.21105/joss.02959%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR47">
<span class="label">47.</span><cite>Lang, M., Bischl, B. &amp; Surmann, D. batchtools: Tools for r to work on batch systems. <em>Journal of Open Source Software</em><strong>2</strong>, 135, 10.21105/joss.00135 (2017).</cite> [<a href="https://scholar.google.com/scholar_lookup?Lang,%20M.,%20Bischl,%20B.%20&amp;%20Surmann,%20D.%20batchtools:%20Tools%20for%20r%20to%20work%20on%20batch%20systems.%20Journal%20of%20Open%20Source%20Software2,%20135,%2010.21105/joss.00135%20(2017)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR48">
<span class="label">48.</span><cite>Ushey, K. &amp; Wickham, H. <em>renv: Project Environments</em><a href="https://rstudio.github.io/renv/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://rstudio.github.io/renv/</a> (2023).</cite>
</li>
<li id="CR49">
<span class="label">49.</span><cite>Kurtzer, G. M., Sochat, V. &amp; Bauer, M. W. Singularity: scientific containers for mobility of compute. <em>PLOS ONE</em><strong>12</strong>, e0177459, 10.1371/journal.pone.0177459 (2017).
</cite> [<a href="https://doi.org/10.1371/journal.pone.0177459" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC5426675/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/28494014/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Kurtzer,%20G.%20M.,%20Sochat,%20V.%20&amp;%20Bauer,%20M.%20W.%20Singularity:%20scientific%20containers%20for%20mobility%20of%20compute.%20PLOS%20ONE12,%20e0177459,%2010.1371/journal.pone.0177459%20(2017)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR50">
<span class="label">50.</span><cite>Kurtzer, G. M. <em>et al</em>. Hpcng/singularity: Singularity 3.7.3. <em>Zenodo</em>, 10.5281/zenodo.1310023 (2021).</cite>
</li>
<li id="CR51">
<span class="label">51.</span><cite>Halchenko, Y. <em>et al</em>. Datalad: distributed system for joint management of code, data, and their relationship. <em>Journal of Open Source Software</em><strong>6</strong>, 10.21105/joss.03262 (2021).</cite> [<a href="https://doi.org/10.21105/joss.03262" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11514317/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39469147/" class="usa-link">PubMed</a>]</li>
<li id="CR52">
<span class="label">52.</span><cite>Jung, H. <em>et al</em>. A multimodal fMRI dataset unifying naturalistic processes with a rich array of experimental tasks. OpenNeuro. 10.18112/openneuro.ds005256.v1.1.0 (2025)</cite> [<a href="https://doi.org/10.1038/s41597-025-05154-x" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC12373947/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/40846708/" class="usa-link">PubMed</a>]</li>
<li id="CR53">
<span class="label">53.</span><cite>Gorgolewski, K. J. <em>et al</em>. The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments. <em>Scientific Data</em><strong>3</strong>, 1–9, 10.1038/sdata.2016.44 (2016).</cite> [<a href="https://doi.org/10.1038/sdata.2016.44" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4978148/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27326542/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Gorgolewski,%20K.%20J.%20et%20al.%20The%20brain%20imaging%20data%20structure,%20a%20format%20for%20organizing%20and%20describing%20outputs%20of%20neuroimaging%20experiments.%20Scientific%20Data3,%201%E2%80%939,%2010.1038/sdata.2016.44%20(2016)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR54">
<span class="label">54.</span><cite>Gorgolewski, K. J. <em>et al</em>. Bids apps: Improving ease of use, accessibility, and reproducibility of neuroimaging data analysis methods. <em>PLOS Computational Biology</em><strong>13</strong>, e1005209, 10.1371/journal.pcbi.1005209 (2017).
</cite> [<a href="https://doi.org/10.1371/journal.pcbi.1005209" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC5363996/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/28278228/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Gorgolewski,%20K.%20J.%20et%20al.%20Bids%20apps:%20Improving%20ease%20of%20use,%20accessibility,%20and%20reproducibility%20of%20neuroimaging%20data%20analysis%20methods.%20PLOS%20Computational%20Biology13,%20e1005209,%2010.1371/journal.pcbi.1005209%20(2017)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR55">
<span class="label">55.</span><cite>Sudlow, C. <em>et al</em>. Uk biobank: An open access resource for identifying the causes of a wide range of complex diseases of middle and old age. <em>PLOS Medicine</em><strong>12</strong>, e1001779, 10.1371/journal.pmed.1001779 (2015).
</cite> [<a href="https://doi.org/10.1371/journal.pmed.1001779" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4380465/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/25826379/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Sudlow,%20C.%20et%20al.%20Uk%20biobank:%20An%20open%20access%20resource%20for%20identifying%20the%20causes%20of%20a%20wide%20range%20of%20complex%20diseases%20of%20middle%20and%20old%20age.%20PLOS%20Medicine12,%20e1001779,%2010.1371/journal.pmed.1001779%20(2015)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR56">
<span class="label">56.</span><cite>Halchenko, Y. <em>et al</em>. Datalad: distributed system for joint management of code, data, and their relationship. <em>Journal of Open Source Software</em><strong>6</strong>, 3262, 10.21105/joss.03262 (2021).
</cite> [<a href="https://doi.org/10.21105/joss.03262" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11514317/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39469147/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Halchenko,%20Y.%20et%20al.%20Datalad:%20distributed%20system%20for%20joint%20management%20of%20code,%20data,%20and%20their%20relationship.%20Journal%20of%20Open%20Source%20Software6,%203262,%2010.21105/joss.03262%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR57">
<span class="label">57.</span><cite>Mehling, W. E. <em>et al</em>. The multidimensional assessment of interoceptive awareness (MAIA). <em>PLoS One</em><strong>7</strong>, e48230, 10.1371/journal.pone.0048230 (2012).
</cite> [<a href="https://doi.org/10.1371/journal.pone.0048230" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3486814/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/23133619/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Mehling,%20W.%20E.%20et%20al.%20The%20multidimensional%20assessment%20of%20interoceptive%20awareness%20(MAIA).%20PLoS%20One7,%20e48230,%2010.1371/journal.pone.0048230%20(2012)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR58">
<span class="label">58.</span><cite>Cella, D. <em>et al</em>. The Patient-Reported outcomes measurement information system (PROMIS) developed and tested its first wave of adult self-reported health outcome item banks: 2005-2008. <em>J. Clin. Epidemiol.</em><strong>63</strong>, 1179–1194, 10.1016/j.jclinepi.2010.04.011 (2010).
</cite> [<a href="https://doi.org/10.1016/j.jclinepi.2010.04.011" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC2965562/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/20685078/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Cella,%20D.%20et%20al.%20The%20Patient-Reported%20outcomes%20measurement%20information%20system%20(PROMIS)%20developed%20and%20tested%20its%20first%20wave%20of%20adult%20self-reported%20health%20outcome%20item%20banks:%202005-2008.%20J.%20Clin.%20Epidemiol.63,%201179%E2%80%931194,%2010.1016/j.jclinepi.2010.04.011%20(2010)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR59">
<span class="label">59.</span><cite>Scheier, M. F., Carver, C. S. &amp; Bridges, M. W. Distinguishing optimism from neuroticism (and trait anxiety, self-mastery, and self-esteem): a reevaluation of the life orientation test. <em>J. Pers. Soc. Psychol.</em><strong>67</strong>, 1063–1078, 10.1037/0022-3514.67.6.1063 (1994).
</cite> [<a href="https://doi.org/10.1037//0022-3514.67.6.1063" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/7815302/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Scheier,%20M.%20F.,%20Carver,%20C.%20S.%20&amp;%20Bridges,%20M.%20W.%20Distinguishing%20optimism%20from%20neuroticism%20(and%20trait%20anxiety,%20self-mastery,%20and%20self-esteem):%20a%20reevaluation%20of%20the%20life%20orientation%20test.%20J.%20Pers.%20Soc.%20Psychol.67,%201063%E2%80%931078,%2010.1037/0022-3514.67.6.1063%20(1994)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR60">
<span class="label">60.</span><cite>Watson, D., Clark, L. A. &amp; Tellegen, A. Development and validation of brief measures of positive and negative affect: The panas scales. <em>Journal of Personality and Social Psychology</em><strong>54</strong>, 1063–1070, 10.1037/0022-3514.54.6.1063 (1988).
</cite> [<a href="https://doi.org/10.1037//0022-3514.54.6.1063" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/3397865/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Watson,%20D.,%20Clark,%20L.%20A.%20&amp;%20Tellegen,%20A.%20Development%20and%20validation%20of%20brief%20measures%20of%20positive%20and%20negative%20affect:%20The%20panas%20scales.%20Journal%20of%20Personality%20and%20Social%20Psychology54,%201063%E2%80%931070,%2010.1037/0022-3514.54.6.1063%20(1988)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR61">
<span class="label">61.</span><cite>McNeil, D. W. &amp; Rainwater, A. J. 3rd. Development of the fear of pain Questionnaire–III. <em>J. Behav. Med.</em><strong>21</strong>, 389–410, 10.1023/A:1018782831217 (1998).
</cite> [<a href="https://doi.org/10.1023/a:1018782831217" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/9789168/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?McNeil,%20D.%20W.%20&amp;%20Rainwater,%20A.%20J.%203rd.%20Development%20of%20the%20fear%20of%20pain%20Questionnaire%E2%80%93III.%20J.%20Behav.%20Med.21,%20389%E2%80%93410,%2010.1023/A:1018782831217%20(1998)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR62">
<span class="label">62.</span><cite>Carver, C. S. &amp; White, T. L. Behavioral inhibition, behavioral activation, and affective responses to impending reward and punishment: The bis/bas scales. <em>Journal of Personality and Social Psychology</em><strong>67</strong>, 319–333, 10.1037/0022-3514.67.2.319 (1994).</cite> [<a href="https://scholar.google.com/scholar_lookup?Carver,%20C.%20S.%20&amp;%20White,%20T.%20L.%20Behavioral%20inhibition,%20behavioral%20activation,%20and%20affective%20responses%20to%20impending%20reward%20and%20punishment:%20The%20bis/bas%20scales.%20Journal%20of%20Personality%20and%20Social%20Psychology67,%20319%E2%80%93333,%2010.1037/0022-3514.67.2.319%20(1994)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR63">
<span class="label">63.</span><cite>Rammstedt, B. &amp; John, O. P. Measuring personality in one minute or less: A 10-item short version of the big five inventory in english and german. <em>J. Res. Pers.</em><strong>41</strong>, 203–212, 10.1016/j.jrp.2006.02.001 (2007).</cite> [<a href="https://scholar.google.com/scholar_lookup?Rammstedt,%20B.%20&amp;%20John,%20O.%20P.%20Measuring%20personality%20in%20one%20minute%20or%20less:%20A%2010-item%20short%20version%20of%20the%20big%20five%20inventory%20in%20english%20and%20german.%20J.%20Res.%20Pers.41,%20203%E2%80%93212,%2010.1016/j.jrp.2006.02.001%20(2007)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR64">
<span class="label">64.</span><cite>Block, J. &amp; Kremen, A. M. IQ and ego-resiliency: conceptual and empirical connections and separateness. <em>Journal of personality and social psychology</em><strong>70</strong>, 349, 10.1037/0022-3514.70.2.349 (1996).
</cite> [<a href="https://doi.org/10.1037//0022-3514.70.2.349" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/8636887/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Block,%20J.%20&amp;%20Kremen,%20A.%20M.%20IQ%20and%20ego-resiliency:%20conceptual%20and%20empirical%20connections%20and%20separateness.%20Journal%20of%20personality%20and%20social%20psychology70,%20349,%2010.1037/0022-3514.70.2.349%20(1996)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR65">
<span class="label">65.</span><cite>Felitti, V. J. <em>et al</em>. Relationship of childhood abuse and household dysfunction to many of the leading causes of death in adults. the adverse childhood experiences (ACE) study. <em>Am. J. Prev. Med.</em><strong>14</strong>, 245–258, 10.1016/S0749-3797(98)00017-8 (1998).
</cite> [<a href="https://doi.org/10.1016/s0749-3797(98)00017-8" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/9635069/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Felitti,%20V.%20J.%20et%20al.%20Relationship%20of%20childhood%20abuse%20and%20household%20dysfunction%20to%20many%20of%20the%20leading%20causes%20of%20death%20in%20adults.%20the%20adverse%20childhood%20experiences%20(ACE)%20study.%20Am.%20J.%20Prev.%20Med.14,%20245%E2%80%93258,%2010.1016/S0749-3797(98)00017-8%20(1998)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR66">
<span class="label">66.</span><cite>Crowne, D. P. &amp; Marlowe, D. A new scale of social desirability independent of psychopathology. <em>Journal of Consulting Psychology</em><strong>24</strong>, 349–354, 10.1037/h0047358 (1960).
</cite> [<a href="https://doi.org/10.1037/h0047358" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/13813058/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Crowne,%20D.%20P.%20&amp;%20Marlowe,%20D.%20A%20new%20scale%20of%20social%20desirability%20independent%20of%20psychopathology.%20Journal%20of%20Consulting%20Psychology24,%20349%E2%80%93354,%2010.1037/h0047358%20(1960)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR67">
<span class="label">67.</span><cite>Davis, M. H. Measuring individual differences in empathy: Evidence for a multidimensional approach. <em>Journal of Personality and Social Psychology</em><strong>44</strong>, 113–126, 10.1037/0022-3514.44.1.113 (1983).</cite> [<a href="https://scholar.google.com/scholar_lookup?Davis,%20M.%20H.%20Measuring%20individual%20differences%20in%20empathy:%20Evidence%20for%20a%20multidimensional%20approach.%20Journal%20of%20Personality%20and%20Social%20Psychology44,%20113%E2%80%93126,%2010.1037/0022-3514.44.1.113%20(1983)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR68">
<span class="label">68.</span><cite>Hamilton, C. M. <em>et al</em>. The PhenX toolkit: get the most from your measures. <em>Am. J. Epidemiol.</em><strong>174</strong>, 253–260, 10.1093/aje/kwr193 (2011).
</cite> [<a href="https://doi.org/10.1093/aje/kwr193" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3141081/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/21749974/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Hamilton,%20C.%20M.%20et%20al.%20The%20PhenX%20toolkit:%20get%20the%20most%20from%20your%20measures.%20Am.%20J.%20Epidemiol.174,%20253%E2%80%93260,%2010.1093/aje/kwr193%20(2011)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR69">
<span class="label">69.</span><cite>Williams, K. M., Paulhus, D. L. &amp; Hare, R. D. Capturing the four-factor structure of psychopathy in college students via self-report. <em>J. Pers. Assess.</em><strong>88</strong>, 205–219, 10.1080/00223890701268074 (2007).
</cite> [<a href="https://doi.org/10.1080/00223890701268074" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/17437385/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Williams,%20K.%20M.,%20Paulhus,%20D.%20L.%20&amp;%20Hare,%20R.%20D.%20Capturing%20the%20four-factor%20structure%20of%20psychopathy%20in%20college%20students%20via%20self-report.%20J.%20Pers.%20Assess.88,%20205%E2%80%93219,%2010.1080/00223890701268074%20(2007)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR70">
<span class="label">70.</span><cite>Hart, C. M., Ritchie, T. D., Hepper, E. G. &amp; Gebauer, J. E. The balanced inventory of desirable responding short form (bidr-16). <em>SAGE Open</em><strong>5</strong>, 215824401562111, 10.1177/2158244015621113 (2015).</cite> [<a href="https://scholar.google.com/scholar_lookup?Hart,%20C.%20M.,%20Ritchie,%20T.%20D.,%20Hepper,%20E.%20G.%20&amp;%20Gebauer,%20J.%20E.%20The%20balanced%20inventory%20of%20desirable%20responding%20short%20form%20(bidr-16).%20SAGE%20Open5,%20215824401562111,%2010.1177/2158244015621113%20(2015)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR71">
<span class="label">71.</span><cite>Shah, P., Gaule, A., Sowden, S., Bird, G. &amp; Cook, R. The 20-item prosopagnosia index (PI20): a self-report instrument for identifying developmental prosopagnosia. <em>R Soc Open Sci</em><strong>2</strong>, 140343, 10.1098/rsos.140343 (2015).
</cite> [<a href="https://doi.org/10.1098/rsos.140343" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4632531/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/26543567/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Shah,%20P.,%20Gaule,%20A.,%20Sowden,%20S.,%20Bird,%20G.%20&amp;%20Cook,%20R.%20The%2020-item%20prosopagnosia%20index%20(PI20):%20a%20self-report%20instrument%20for%20identifying%20developmental%20prosopagnosia.%20R%20Soc%20Open%20Sci2,%20140343,%2010.1098/rsos.140343%20(2015)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR72">
<span class="label">72.</span><cite>Goldsmith, R. E., Clark, R. A. &amp; Lafferty, B. A. Tendency to conform: A new measure and its relationship to psychological reactance. <em>Psychological Reports</em><strong>96</strong>, 591–594, 10.2466/pr0.96.3.591-594 (2005).
</cite> [<a href="https://doi.org/10.2466/pr0.96.3.591-594" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/16050608/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Goldsmith,%20R.%20E.,%20Clark,%20R.%20A.%20&amp;%20Lafferty,%20B.%20A.%20Tendency%20to%20conform:%20A%20new%20measure%20and%20its%20relationship%20to%20psychological%20reactance.%20Psychological%20Reports96,%20591%E2%80%93594,%2010.2466/pr0.96.3.591-594%20(2005)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR73">
<span class="label">73.</span><cite>Dowd, E. T., Milne, C. R. &amp; Wise, S. L. The therapeutic reactance scale: A measure of psychological reactance. <em>Journal of Counseling &amp; Development</em><strong>69</strong>, 541–545, 10.1002/j.1556-6676.1991.tb02638.x (1991).</cite> [<a href="https://scholar.google.com/scholar_lookup?Dowd,%20E.%20T.,%20Milne,%20C.%20R.%20&amp;%20Wise,%20S.%20L.%20The%20therapeutic%20reactance%20scale:%20A%20measure%20of%20psychological%20reactance.%20Journal%20of%20Counseling%20&amp;%20Development69,%20541%E2%80%93545,%2010.1002/j.1556-6676.1991.tb02638.x%20(1991)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR74">
<span class="label">74.</span><cite>Lennox, R. D. &amp; Wolfe, R. N. Revision of the Self-Monitoring scale. <em>J. Pers. Soc. Psychol.</em><strong>46</strong>, 1349–1364, 10.1037/0022-3514.46.6.1349 (1984).
</cite> [<a href="https://doi.org/10.1037//0022-3514.46.6.1349" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/6737217/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Lennox,%20R.%20D.%20&amp;%20Wolfe,%20R.%20N.%20Revision%20of%20the%20Self-Monitoring%20scale.%20J.%20Pers.%20Soc.%20Psychol.46,%201349%E2%80%931364,%2010.1037/0022-3514.46.6.1349%20(1984)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adda93_" lang="en" class="data-availability-statement"><h3 class="pmc_sec_title">Data Availability Statement</h3>
<p>Code for stimulus presentation and data acquisition is published in a GitHub repository (<a href="https://github.com/spatialtopology" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology</a>). To ensure reproducibility of the experimental procedures, we released the code as version 1, prior to data collection (“task-alignvideo”: <a href="https://github.com/spatialtopology/alignvideos/releases/tag/v1.0.0-stable" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/alignvideos/releases/tag/v1.0.0-stable</a>, “task-social”: <a href="https://github.com/spatialtopology/social_influence/releases/tag/v1.0.0-stable" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/social_influence/releases/tag/v1.0.0-stable</a>, “task-faces”: <a href="https://github.com/spatialtopology/task-faces/releases/tag/1.0.0" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/task-faces/releases/tag/1.0.0</a>, “task-narratives”: <a href="https://github.com/spatialtopology/narratives/releases/tag/v.1.0.0" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/narratives/releases/tag/v.1.0.0</a>, “task-shortvideo”: <a href="https://github.com/spatialtopology/shortvideos/releases/tag/v1.0.0-stable" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/shortvideos/releases/tag/v1.0.0-stable</a>, “task-fractional”: <a href="https://github.com/spatialtopology/fractional_factorials/releases/tag/v.1.0.0" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/fractional_factorials/releases/tag/v.1.0.0</a>). Code for data wrangling, preprocessing, and analyzing the data is in the GitHub repository (<a href="https://github.com/spatialtopology/spacetop-prep" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/spacetop-prep</a>). Neuroimaging data and behavioral data are BIDS-formatted in DataLad<sup><a href="#CR56" class="usa-link" aria-describedby="CR56">56</a></sup>. Code for data wrangling and analyzing the data is in the github repository (<a href="https://github.com/spatialtopology/spacetop-prep" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://github.com/spatialtopology/spacetop-prep</a>). Neuroimaging data and behavioral data are BIDS-formatted in DataLad (<a href="https://openneuro.org/datasets/ds005256" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://openneuro.org/datasets/ds005256</a>).</p></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from Scientific Data are provided here courtesy of <strong>Nature Publishing Group</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1038/s41597-025-05154-x"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/41597_2025_Article_5154.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (5.4 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12373947/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12373947/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12373947%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373947/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12373947/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12373947/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40846708/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12373947/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40846708/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12373947/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12373947/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="sHjUE4TCxBBtVrOM19Ge5xbpPFS1p03pQ5QinPSZVA6cliJoKso9cxoGD8EUjOXX">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
    

    </body>
</html>
