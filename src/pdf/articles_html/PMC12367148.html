
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            Qualities of music-evoked autobiographical memories are associated with auditory features of the memory-evoking music - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="D2E4AF818AF31EA305AF8100170D5952.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="plosone">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12367148/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="PLOS One">
<meta name="citation_title" content="Qualities of music-evoked autobiographical memories are associated with auditory features of the memory-evoking music">
<meta name="citation_author" content="Safiyyah Nawaz">
<meta name="citation_author_institution" content="Department of Psychology, Goldsmiths University of London, London, United Kingdom">
<meta name="citation_author" content="Diana Omigie">
<meta name="citation_author_institution" content="Department of Psychology, Goldsmiths University of London, London, United Kingdom">
<meta name="citation_publication_date" content="2025 Aug 20">
<meta name="citation_volume" content="20">
<meta name="citation_issue" content="8">
<meta name="citation_firstpage" content="e0329072">
<meta name="citation_doi" content="10.1371/journal.pone.0329072">
<meta name="citation_pmid" content="40833929">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12367148/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12367148/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12367148/pdf/pone.0329072.pdf">
<meta name="description" content="Studies of music-evoked autobiographical memories (MEAMs) show that music is a potent cue for retrieving vivid and self-relevant memories. However, whether and how musical features are able to predict the qualities of MEAMs – including their ...">
<meta name="og:title" content="Qualities of music-evoked autobiographical memories are associated with auditory features of the memory-evoking music">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="Studies of music-evoked autobiographical memories (MEAMs) show that music is a potent cue for retrieving vivid and self-relevant memories. However, whether and how musical features are able to predict the qualities of MEAMs – including their ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12367148/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12367148">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1371/journal.pone.0329072"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/pone.0329072.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12367148%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12367148/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12367148/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12367148/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-plosone.png" alt="PLOS One logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to PLOS One" title="Link to PLOS One" shape="default" href="https://doi.org/10.1371/journal.pone.0329072" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">PLoS One</button></div>. 2025 Aug 20;20(8):e0329072. doi: <a href="https://doi.org/10.1371/journal.pone.0329072" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1371/journal.pone.0329072</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22PLoS%20One%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22PLoS%20One%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22PLoS%20One%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22PLoS%20One%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Qualities of music-evoked autobiographical memories are associated with auditory features of the memory-evoking music</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Nawaz%20S%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Safiyyah Nawaz</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Safiyyah Nawaz</span></h3>
<div class="p">
<sup>1</sup>Department of Psychology, Goldsmiths University of London, London, United Kingdom</div>
<div>Conceptualization, Formal analysis, Investigation, Methodology, Project administration, Visualization, Writing – original draft, Writing – review &amp; editing</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Nawaz%20S%22%5BAuthor%5D" class="usa-link"><span class="name western">Safiyyah Nawaz</span></a>
</div>
</div>
<sup>1,</sup><sup>*</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Omigie%20D%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Diana Omigie</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">Diana Omigie</span></h3>
<div class="p">
<sup>1</sup>Department of Psychology, Goldsmiths University of London, London, United Kingdom</div>
<div>Conceptualization, Methodology, Supervision, Writing – review &amp; editing</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Omigie%20D%22%5BAuthor%5D" class="usa-link"><span class="name western">Diana Omigie</span></a>
</div>
</div>
<sup>1</sup>
</div>
<div class="cg p">Editor: <span class="name western">Igor Sotgiu</span><sup>2</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="aff001">
<sup>1</sup>Department of Psychology, Goldsmiths University of London, London, United Kingdom</div>
<div id="edit1">
<sup>2</sup>University of Bergamo, ITALY</div>
<div class="author-notes p">
<div class="fn" id="coi001"><p><strong>Competing Interests: </strong>The authors have declared that no competing interests exist.</p></div>
<div class="fn" id="cor001">
<sup>✉</sup><p class="display-inline">* E-mail: <span>snawa003@gold.ac.uk</span></p>
</div>
</div>
<h4 class="font-secondary">Roles</h4>
<div class="p">
<strong class="contrib"><span class="name western">Safiyyah Nawaz</span></strong>: <span class="role">Conceptualization, Formal analysis, Investigation, Methodology, Project administration, Visualization, Writing – original draft, Writing – review &amp; editing</span>
</div>
<div>
<strong class="contrib"><span class="name western">Diana Omigie</span></strong>: <span class="role">Conceptualization, Methodology, Supervision, Writing – review &amp; editing</span>
</div>
<div class="p">
<strong class="contrib"><span class="name western">Igor Sotgiu</span></strong>: <span class="role">Editor</span>
</div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2024 Sep 25; Accepted 2025 Jul 10; Collection date 2025.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© 2025 Nawaz, Omigie</div>
<p>This is an open access article distributed under the terms of the <a href="https://creativecommons.org/licenses/by/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Creative Commons Attribution License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12367148  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40833929/" class="usa-link">40833929</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="abstract1"><h2>Abstract</h2>
<p>Studies of music-evoked autobiographical memories (MEAMs) show that music is a potent cue for retrieving vivid and self-relevant memories. However, whether and how musical features are able to predict the qualities of MEAMs – including their emotional qualities, phenomenological characteristics and retrieval efficiency – remains unclear. In our study, a sample of 233 adult participants identified a piece of music that evoked an autobiographical memory (AM) before providing a written description of the memory, and then evaluating its emotional and phenomenological content. Participants were then presented with excerpts of ten songs that were popular during their childhood and early adulthood and reported the same details for any AMs evoked. Features of all songs were extracted using the Spotify Web API and subjected to principal components analysis for dimension reduction. This revealed a primary auditory feature component – characterised by low energeticness and high acousticness – that was found to predict several qualities of the memory. Specifically, results showed that low energetic – high acoustic songs were associated with AMs characterised emotionally by aesthetic appreciation, adoration, calmness, romance and sadness, while high energetic – low acoustic songs were associated with AMs high in memory energeticness, amusement and excitement. Phenomenologically, AMs associated with low energetic – high acoustic songs were described as less social, and more vivid, unique and important, and, in terms of retrieval efficacy, tended to be retrieved more slowly. Our findings show for the first time the extent to which the qualities of MEAMs can be predicted by music’s stimulus features. Further, by taking into account how the AMs were evoked, and subjective factors related to the memory-evoking music such as liking and familiarity, our study provides insights into possible mechanisms underlying music-assisted memory encoding and retrieval. We discuss the implications of our findings for understanding the links between perception, emotion and memory processes, and make suggestions for future work that can advance this research area.</p></section><section id="sec001"><h2 class="pmc_sec_title">Introduction</h2>
<p>Decades of research have confirmed most people’s intuition of a compelling connection between music and autobiographical memory. Hearing a song and recalling a memory – complete with the sensations, feelings or thoughts that were experienced at the time – has been estimated to happen as often as daily [<a href="#pone.0329072.ref001" class="usa-link" aria-describedby="pone.0329072.ref001">1</a>] and as such studying music-evoked autobiographical memories presents a valuable opportunity to better understand complex memory retrieval processes.</p>
<p>Autobiographical memories (AMs) are complex recollections of episodes from individuals’ personal histories that include the representations of thoughts and emotions corresponding to those episodes. Interestingly, in addition to their high incidence, AMs show a large amount of variety. Amongst other distinctions, AMs can range from recollections of personally-significant periods of time to specific moments or events [<a href="#pone.0329072.ref002" class="usa-link" aria-describedby="pone.0329072.ref002">2</a>]; they can be activated voluntarily or involuntarily; and they can be cued by sensory stimuli or effortfully retrieved by direct search. Autobiographical reminiscence is held to serve a range of socio-cognitive functions that contribute to identity and self-development [<a href="#pone.0329072.ref003" class="usa-link" aria-describedby="pone.0329072.ref003">3</a>,<a href="#pone.0329072.ref004" class="usa-link" aria-describedby="pone.0329072.ref004">4</a>], and it is thus relevant for psychologists to seek a better understanding of AM retrieval and elaboration. Here we use music, a powerful cue for triggering vivid AMs [<a href="#pone.0329072.ref005" class="usa-link" aria-describedby="pone.0329072.ref005">5</a>] to explore a question of broad relevance; namely, the extent to which features of a memory cue can predict the qualities of retrieved AMs.</p>
<section id="sec002"><h3 class="pmc_sec_title">Music as a retrieval cue for rich autobiographical memories</h3>
<p>Music has long been shown to be important in shaping listeners’ identities and sense of self [<a href="#pone.0329072.ref006" class="usa-link" aria-describedby="pone.0329072.ref006">6</a>,<a href="#pone.0329072.ref007" class="usa-link" aria-describedby="pone.0329072.ref007">7</a>], motivating researchers to investigate how – and the extent to which – music may be uniquely able to evoke significant memories. To this end, studies of music-evoked autobiographical memories (MEAMs) have tended to compare AMs evoked by music to AMs evoked by other sensory-perceptual cues (such as images of famous faces, words, and food). Main conclusions from this research have been that music is a salient cue for retrieving vivid memories [<a href="#pone.0329072.ref005" class="usa-link" aria-describedby="pone.0329072.ref005">5</a>], and that MEAMs tend to be experienced as disproportionately positive (whereby even the memories cued by negative music are reported as more positive than those cued by other negative stimuli [<a href="#pone.0329072.ref008" class="usa-link" aria-describedby="pone.0329072.ref008">8</a>]).</p>
<p>Yet other research has examined whether differences between music cues, especially the emotions the music expresses, may be seen reflected in the nature of the AMs evoked by said music. This line of research, which has mostly used unfamiliar instrumental music as cues, has shown that the emotionality – specifically arousal and valence – of unfamiliar emotional music cues influences the nature of retrieved AMs. Specifically, AMs cued by positive music have been shown to be retrieved more quickly [<a href="#pone.0329072.ref009" class="usa-link" aria-describedby="pone.0329072.ref009">9</a>,<a href="#pone.0329072.ref010" class="usa-link" aria-describedby="pone.0329072.ref010">10</a>], more often [<a href="#pone.0329072.ref011" class="usa-link" aria-describedby="pone.0329072.ref011">11</a>], and to be reported as more positive [<a href="#pone.0329072.ref008" class="usa-link" aria-describedby="pone.0329072.ref008">8</a>] than those cued by negative music. Furthermore, memories cued by high arousing music have been reported as more positive and episodic, and as containing specific and contextual information about the memory [<a href="#pone.0329072.ref009" class="usa-link" aria-describedby="pone.0329072.ref009">9</a>].</p>
<p>Interestingly, while there is some evidence of an emotion-congruence effect, whereby the emotions reported as part of a memory tend to match the emotions expressed by the music cue [<a href="#pone.0329072.ref009" class="usa-link" aria-describedby="pone.0329072.ref009">9</a>], studies which have used arousal and valence to characterise the music and memories in question have often found interactions that are suggestive of a more complex relationship between music and memory emotionality (for instance, low valence/low arousal music cues being shown to lead to less positive memories than low valence/high arousal music [<a href="#pone.0329072.ref011" class="usa-link" aria-describedby="pone.0329072.ref011">11</a>,<a href="#pone.0329072.ref012" class="usa-link" aria-describedby="pone.0329072.ref012">12</a>]). Such findings raise the possibility that the emotionality of a memory may be influenced by features of the memory-evoking music stimuli other than its position in the 2-dimensional circumplex emotion model. Here, we suggest that in addition to factors such as music liking and familiarity, which have already been shown to predict aspects of MEAM retrieval and emotionality [<a href="#pone.0329072.ref012" class="usa-link" aria-describedby="pone.0329072.ref012">12</a>,<a href="#pone.0329072.ref013" class="usa-link" aria-describedby="pone.0329072.ref013">13</a>], other factors like the auditory features of the memory-evoking music are worthy of systematic exploration, with regard to the role that they may play in determining the qualities of memories that music induces.</p></section><section id="sec003"><h3 class="pmc_sec_title">A data-driven musical-feature approach to MEAMs</h3>
<p>Taken together, and especially given views that emotional experience may be more precisely represented by distinct emotion categories than by valence and arousal dimensions [<a href="#pone.0329072.ref014" class="usa-link" aria-describedby="pone.0329072.ref014">14</a>], previous studies that have characterised both music stimulus features and AM emotionality solely with regard to arousal and valence may be considered limited in fully exploring MEAM retrieval mechanisms. Put another way, as previous research has not included the breadth of distinct emotional experiences that can be reported or observed as a part of memories (e.g., romance or amusement), it remains unclear whether memories related to such states can be reliably triggered by manipulating the qualities of presented music.</p>
<p>Features of music like melody, harmony, rhythm, dynamics and timbre are known to influence music-induced and perceived emotions [<a href="#pone.0329072.ref015" class="usa-link" aria-describedby="pone.0329072.ref015">15</a>] but at present, the extent to which such musical features may also predict the nature of music-evoked memories remains unclear. While musico-acoustic features of music have been and can be explored in a range of different ways (often to explore how features of music predict key emotional responses to music), recent studies have leveraged Spotify’s Web API for its versatility and convenience. In one recent study, de Fleurian &amp; Pearce used this tool to show that chills-evoking songs are less loud and energetic (relating to dynamic range, timbre, onset range and general entropy), have lower tempos, and are more acoustic and instrumental than matched non-chills songs [<a href="#pone.0329072.ref016" class="usa-link" aria-describedby="pone.0329072.ref016">16</a>]. Similarly, Baltazar &amp; Västfjäll used the tool to demonstrate that, in addition to loudness and energy, features such as acousticness and instrumentalness may distinguish relaxing from non-relaxing pieces. [<a href="#pone.0329072.ref017" class="usa-link" aria-describedby="pone.0329072.ref017">17</a>].</p>
<p>To date, only one study has examined the relationship between musical features and autobiographical memories. In that study, Salakka and colleagues examined the acoustic profiles of familiar music that participants had rated for emotionality and autobiographical salience, and were able to identify timbral, tonal, and temporal features that predicted emotionality, familiarity and autobiographical salience of the memories [<a href="#pone.0329072.ref018" class="usa-link" aria-describedby="pone.0329072.ref018">18</a>]. Specifically, their results showed that songs with a weaker pulse, fewer higher-mid frequencies and less harmonics and high notes were associated with higher autobiographical salience. Interestingly, statistical analysis showed that the music’s emotional intensity mediated these effects, demonstrating that the experience of strong emotions may be the strongest predictor of autobiographical salience. Here, it is important to note that autobiographical memory in that study was explored with a sole focus on general autobiographical salience; that is by asking <em>‘how much personal memories did the song evoke?</em>’. Thus, with no further evaluations of AMs being made by participants, it remains unclear how features of music may influence the many other ways in which MEAMs are known to vary, from their level of vividness, uniqueness, and self-importance, to their associated emotions and the speed with which they are retrieved.</p></section><section id="sec004"><h3 class="pmc_sec_title">The current study</h3>
<p>From the studies discussed above, a picture emerges of music-evoked autobiographical memory as a complex phenomenon that can offer insight into several aspects of AM processes. The literature points towards music being a strong sensory cue that evokes memories through emotion-related processes, and which auditory features are likely to contribute to. While several studies have examined how arousal and valence, as well as music liking and familiarity, relate to characteristics of AM [<a href="#pone.0329072.ref009" class="usa-link" aria-describedby="pone.0329072.ref009">9</a>,<a href="#pone.0329072.ref010" class="usa-link" aria-describedby="pone.0329072.ref010">10</a>,<a href="#pone.0329072.ref012" class="usa-link" aria-describedby="pone.0329072.ref012">12</a>,<a href="#pone.0329072.ref013" class="usa-link" aria-describedby="pone.0329072.ref013">13</a>], and while one study has shown musical features to relate to autobiographical salience [<a href="#pone.0329072.ref018" class="usa-link" aria-describedby="pone.0329072.ref018">18</a>], it nevertheless remains to be systematically investigated how well auditory features of memory-evoking music can predict the nature of the memories they evoke.</p>
<p>In light of the gap in the literature, and in line with the approach taken by Jakubowski and Eerola [<a href="#pone.0329072.ref008" class="usa-link" aria-describedby="pone.0329072.ref008">8</a>], who examined effects on MEAMs of music and non-musical memory cues varying in arousal and valence, the current study therefore asked: 1) how music’s auditory features influence emotional qualities of recalled memories, 2) how music’s auditory features relate to the phenomenological characteristics of memories (that is, characteristics related to the content of the memory and its persistence in long-term AM), and finally, 3) how music’s auditory features influence the efficiency with which memories are retrieved.</p>
<p>To this end, features of memory-evoking songs were extracted using the Spotify API, and we asked how those features related to emotional qualities, phenomenological content of, and efficiency of retrieving AMs. Critically, we extended beyond dimensional (arousal-valence) approaches to characterising emotional qualities i) by asking participants to identify categorical emotions related to their memories, and ii) by analysing memory descriptions for inclusion of emotional and perceptual words. These analyses allowed us to investigate which categories of emotions are present in memories that music tends to evoke, and also allowed us to examine whether musical features have predictive power in which memories are evoked.</p>
<p>We conducted a principal components analysis (PCA), which we predicted would reveal two components of musical features more or less related to arousal and valence. In turn we anticipated that, in line with other work, arousal-related features might contribute to arousal, valence, vividness, uniqueness, and retrieval efficiency of AMs, while musical valence-related features would influence AMs’ valence, social content, importance, vividness, and retrieval efficiency. To pre-empt our results section, PCA revealed only one main component characterised by <em>both</em> arousal and valence-related music features and as such our evaluation of results is only broadly discussed in reference to our initial pre-registered predictions.</p></section></section><section id="sec005"><h2 class="pmc_sec_title">Materials and methods</h2>
<section id="sec006"><h3 class="pmc_sec_title">Participants</h3>
<p>In total, 233 adult participants completed the study, including 154 women, 69 men, 6 nonbinary individuals, and 4 preferring not to say with ages ranging from 18 to 76 years old (M = 37.65, SD = 16.15). The recruitment aim was 200 participants, as this exceeded sample sizes across six comparable studies (42–114 participants) that showed effects of music on AMs similar to those examined here [<a href="#pone.0329072.ref008" class="usa-link" aria-describedby="pone.0329072.ref008">8</a>–<a href="#pone.0329072.ref010" class="usa-link" aria-describedby="pone.0329072.ref010">10</a>]. Participants were recruited through online subject-recruiting platform Prolific [<a href="#pone.0329072.ref019" class="usa-link" aria-describedby="pone.0329072.ref019">19</a>], Goldsmiths University undergraduate participation scheme, word of mouth, and were also incentivized by the chance to win one of three £20 cash vouchers.</p></section><section id="sec007"><h3 class="pmc_sec_title">Materials</h3>
<section id="sec008"><h4 class="pmc_sec_title">Music stimuli.</h4>
<p>In line with MEAM studies utilising a similar procedure [<a href="#pone.0329072.ref005" class="usa-link" aria-describedby="pone.0329072.ref005">5</a>,<a href="#pone.0329072.ref020" class="usa-link" aria-describedby="pone.0329072.ref020">20</a>–<a href="#pone.0329072.ref022" class="usa-link" aria-describedby="pone.0329072.ref022">22</a>], we used songs from the Billboard Hot 100 year-end charts between the years 1941 and 2022 to cue MEAMs. All musical stimuli were 15-second excerpts containing highly recognizable parts of the song, as shared and described by Belfi et al. [<a href="#pone.0329072.ref005" class="usa-link" aria-describedby="pone.0329072.ref005">5</a>].</p>
<p>Each participant was presented with 10 clips of songs that were on the Billboard Hot 100 charts during the years in which they were between the ages of 9 and 19, with one song selected for each year. We defined the ‘reminiscence bump’ as this age range (i.e., between ages 9 and 19 where 14 is the midpoint), as 14 has previously been identified as the peak age for music-related memories [<a href="#pone.0329072.ref023" class="usa-link" aria-describedby="pone.0329072.ref023">23</a>].</p></section></section><section id="sec009"><h3 class="pmc_sec_title">Procedure</h3>
<p>Participants completed the study using the online survey platform Qualtrics [<a href="#pone.0329072.ref024" class="usa-link" aria-describedby="pone.0329072.ref024">24</a>]. Participants first reported on one MEAM related to a self-selected song in the first part of the survey, then reported on experimenter selected music-cued MEAMs (as cued by songs from Billboard Hot 100) in the second part of the survey.</p>
<p>For self-selected AMs, participants were instructed to identify the title and artist of a song related to an AM as such:</p>
<blockquote class="text-italic"><p>
<em>Think of a song that reliably evokes an autobiographical memory of yours. That is, when you think about or hear this song, you are taken back in time to a specific memory in which you can visualise where you are and what you’re doing from your own perspective.</em>
</p></blockquote>
<p>An autobiographical memory was defined as follows (as from [<a href="#pone.0329072.ref025" class="usa-link" aria-describedby="pone.0329072.ref025">25</a>])</p>
<blockquote class="text-italic"><p><em>An</em>
<strong><em>autobiographical memory</em></strong>
<em>occurs when you remember personal experiences from your past. These memories may contain details about events, people, places, and time periods from your life. Such a memory could be of a unique event, such as a memory of your 10th birthday party, or a recurring event, such as a memory of walking your dog.’</em></p></blockquote>
<p>For the self-selected MEAM, participants were allowed to report any song of any genre or musical style as preferred. Participants were then prompted to write a description of the corresponding memory and provide responses to Likert questions related to emotionality (such as memory valence and arousal), phenomenological characteristics (such as vividness and uniqueness), and memory retrieval such as degree of spontaneity retrieving the memory (see <a href="#pone.0329072.t001" class="usa-link">Table 1</a> for full list of dependent variables). All Likert variables were intended to be reported on a 5-point scale for consistency; however, vividness was inadvertently rated on a 7-point scale. This discrepancy was identified after data collection had commenced, and as such, we retained the 7-point scale data for vividness in our analysis.</p>
<section class="tw xbox font-sm" id="pone.0329072.t001"><h4 class="obj_head">Table 1. Outcome variables list and measurement.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">Variable</th>
<th align="left" rowspan="1" colspan="1">Outcome category</th>
<th align="left" rowspan="1" colspan="1">Measurement</th>
<th align="left" rowspan="1" colspan="1">Measured for self-selected or cued MEAMs</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">AM arousal</td>
<td align="left" rowspan="1" colspan="1">Emotionality</td>
<td align="left" rowspan="1" colspan="1">Likert rating: “How energizing did the experience reported in your memory feel at the time?”</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">AM valence</td>
<td align="left" rowspan="1" colspan="1">Emotionality</td>
<td align="left" rowspan="1" colspan="1">Likert rating: “How negative or positive did the experience reported in your memory feel at the time?”</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Categorical Emotions</td>
<td align="left" rowspan="1" colspan="1">Emotionality</td>
<td align="left" rowspan="1" colspan="1">List of 34 emotions (as few or many able to be selected): admiration, adoration, aesthetic appreciation, amusement, anger, anxiety, awe, awkwardness, boredom, calmness, confusion, contempt, craving, disappointment, disgust, empathic pain, entrancement, envy, excitement, fear, guilt, horror, interest, joy, nostalgia, pride, relief, romance, sadness, satisfaction, sexual desire, surprise, sympathy, triumph</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Positive emotion words</td>
<td align="left" rowspan="1" colspan="1">Emotionality</td>
<td align="left" rowspan="1" colspan="1">LIWC analysis</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Negative emotion words</td>
<td align="left" rowspan="1" colspan="1">Emotionality</td>
<td align="left" rowspan="1" colspan="1">LIWC analysis</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">AM vividness</td>
<td align="left" rowspan="1" colspan="1">Phenomenological characteristics</td>
<td align="left" rowspan="1" colspan="1">Likert rating: “How vivid is this memory in your mind?”</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">AM uniqueness</td>
<td align="left" rowspan="1" colspan="1">Phenomenological characteristics</td>
<td align="left" rowspan="1" colspan="1">Likert rating: “How unique is the experience reported in your memory?”</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">AM importance</td>
<td align="left" rowspan="1" colspan="1">Phenomenological characteristics</td>
<td align="left" rowspan="1" colspan="1">Likert rating: “How important is this memory to your life story?”</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">AM social content</td>
<td align="left" rowspan="1" colspan="1">Phenomenological characteristics</td>
<td align="left" rowspan="1" colspan="1">Likert rating: “How social was the experience reported in your memory?”</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Age at time of memory</td>
<td align="left" rowspan="1" colspan="1">Phenomenological characteristics</td>
<td align="left" rowspan="1" colspan="1">Numerical</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Specificity of AM</td>
<td align="left" rowspan="1" colspan="1">Phenomenological characteristics</td>
<td align="left" rowspan="1" colspan="1">Forced-choice:<br>1. Memory for a specific event<br>2. Memory for a time period or time of your life<br>3. General memories (for example, memory of a person or a place)</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Music presence</td>
<td align="left" rowspan="1" colspan="1">Phenomenological characteristics</td>
<td align="left" rowspan="1" colspan="1">Yes/No/Not sure to the below question:<br><em>Was the piece of music that you just heard present during the experience reported in your memory? That is, did the memory involve a previous incident of listening to this same music?</em>
</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">‘Motion’ words</td>
<td align="left" rowspan="1" colspan="1">Phenomenological characteristics</td>
<td align="left" rowspan="1" colspan="1">LIWC Analysis</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">‘Space’ words</td>
<td align="left" rowspan="1" colspan="1">Phenomenological characteristics</td>
<td align="left" rowspan="1" colspan="1">LIWC Analysis</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">‘See’ words</td>
<td align="left" rowspan="1" colspan="1">Phenomenological characteristics</td>
<td align="left" rowspan="1" colspan="1">LIWC Analysis</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">‘Hear’ words</td>
<td align="left" rowspan="1" colspan="1">Phenomenological characteristics</td>
<td align="left" rowspan="1" colspan="1">LIWC Analysis</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">‘Feel’ words</td>
<td align="left" rowspan="1" colspan="1">Phenomenological characteristics</td>
<td align="left" rowspan="1" colspan="1">LIWC Analysis</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">‘Social’ words</td>
<td align="left" rowspan="1" colspan="1">Phenomenological characteristics</td>
<td align="left" rowspan="1" colspan="1">LIWC Analysis</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Word count</td>
<td align="left" rowspan="1" colspan="1">Phenomenological characteristics</td>
<td align="left" rowspan="1" colspan="1">LIWC Analysis</td>
<td align="left" rowspan="1" colspan="1">Both</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Retrieval speed</td>
<td align="left" rowspan="1" colspan="1">Retrieval efficiency</td>
<td align="left" rowspan="1" colspan="1">Calculated in time elapsed between onset of stimulus and participant indication of memory</td>
<td align="left" rowspan="1" colspan="1">Experimenter-cued</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Spontaneity of AM</td>
<td align="left" rowspan="1" colspan="1">Retrieval efficiency</td>
<td align="left" rowspan="1" colspan="1">Likert rating</td>
<td align="left" rowspan="1" colspan="1">Experimenter-cued</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0329072.t001/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p>Participants then selected all the categorical emotions they would use to describe the experience reported in the memory from a list of 34 emotions that were previously compiled by Cowen &amp; Keltner, who in previous work derived the list from several emotion taxonomies to incorporate nuances of states varying in positive, negative and everyday emotions [<a href="#pone.0329072.ref014" class="usa-link" aria-describedby="pone.0329072.ref014">14</a>]. Finally, participants identified whether the piece of music was present during the recalled memory, a type of situation which we refer to as <em>music presence</em>. Questions about the memory were phrased to prompt participants to report regarding how the experience felt <em>at the time of it occurring</em>, rather than how they were feeling in the moment of recalling the memory. For instance, “How negative or positive did the experience reported in your memory feel at the time?” was asked rather than “how negative or positive was the memory?”, since the latter could erroneously prompt participants to evaluate the valence of the memory in the moment of recall.</p>
<p>For experimenter-cued MEAMs (after reporting their own AM as described above), participants were presented with ten songs from the Billboard Hot 100 charts randomly selected from their reminiscence bump years as described in Materials. In each trial, a song started playing automatically and participants were asked to indicate when they had recalled a memory by clicking a button on screen, but to refrain from clicking the button if no memory came to mind. If they indicated that they recalled a memory, participants were then asked to provide a description of the memory and to rate the same items as described for the self-selected AM; afterwards, they would be prompted to also rate their liking and the familiarity of the song. Retrieval speed was calculated as the duration of time between the start of the page and song presentation and when the participant indicated a memory. If no memory was recalled, they would not be shown the memory questions and would only be asked to rate their liking and familiarity of the song before moving to the next trial.</p>
<p>Before moving on to questionnaires, participants were given the opportunity, where they didn’t have the chance to report it in the original trial, to report on up to two memories that came to mind after the excerpt ended. In these cases, participants were asked to indicate the title and artist of the song, and provide the memory and ratings as described above. Nine participants provided an additional AM through this opportunity.</p>
<p>At the end, participants completed STOMP (Short Test of Musical Preferences; [<a href="#pone.0329072.ref026" class="usa-link" aria-describedby="pone.0329072.ref026">26</a>]), and VVIQ (Vividness of Visual Imagery Questionnaire; [<a href="#pone.0329072.ref027" class="usa-link" aria-describedby="pone.0329072.ref027">27</a>]) questionnaires and two questions assessing musicality. These data were the focus of other studies and so will not be included in the present study’s analysis.</p></section><section id="sec011"><h3 class="pmc_sec_title">Ethics</h3>
<p>The protocol of the current study received approval from the Goldsmiths Psychology Department Ethics Committee at Goldsmiths, University of London (approval number: PS130623SNS). Recruitment took place between July 8, 2023 and February 25, 2024, and written informed consent was obtained for all participants included in the study and documented via responses in the Qualtrics survey. Only participants over 18 years of age were permitted to participate.</p></section><section id="sec012"><h3 class="pmc_sec_title">Analyses</h3>
<section id="sec013"><h4 class="pmc_sec_title">Data Cleaning and Processing.</h4>
<p>All statistical analyses were performed with R version 4.2.3. Prior to analysis, data were inspected to identify missing values, outliers, and to confirm that data met necessary assumptions for statistical models. Full documentation of the data cleaning process is included in Supplementary Information: <a href="#pone.0329072.s001" class="usa-link">S1 Appendix</a> Data Cleaning and Assumptions.</p></section><section id="sec014"><h4 class="pmc_sec_title">Music features.</h4>
<p>Auditory features of both experimenter-selected and self-selected songs were obtained using the R package <em>spotifyr</em>, which pulls track information from the Spotify Web API [<a href="#pone.0329072.ref028" class="usa-link" aria-describedby="pone.0329072.ref028">28</a>]. We identified nine auditory features of interest to include in our principal component analyses: acousticness, danceability, energy, instrumentalness, liveness, loudness, speechiness, tempo and valence [<a href="#pone.0329072.ref029" class="usa-link" aria-describedby="pone.0329072.ref029">29</a>]. Descriptions of the features can be seen in Spotify’s developer documentation and provided in <a href="#pone.0329072.t002" class="usa-link">Table 2</a>.</p>
<section class="tw xbox font-sm" id="pone.0329072.t002"><h5 class="obj_head">Table 2. Spotify auditory features definitions.</h5>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">Variable</th>
<th align="left" rowspan="1" colspan="1">Description</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">
<strong>acousticness</strong>
</td>
<td align="left" rowspan="1" colspan="1">A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">
<strong>danceability</strong>
</td>
<td align="left" rowspan="1" colspan="1">Danceability describes how suitable a track is for dancing based on a combination of musical elements including <strong><em>tempo, rhythm stability, beat strength, and overall regularity</em></strong>. A value of 0.0 is least danceable and 1.0 is most danceable.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">
<strong>energy</strong>
</td>
<td align="left" rowspan="1" colspan="1">Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include <strong><em>dynamic range, perceived loudness, timbre, onset rate, and general entropy</em></strong>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">
<strong>instrumentalness</strong>
</td>
<td align="left" rowspan="1" colspan="1">Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">
<strong>liveness</strong>
</td>
<td align="left" rowspan="1" colspan="1">Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">
<strong>loudness</strong>
</td>
<td align="left" rowspan="1" colspan="1">The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is <strong>the primary psychological correlate of physical strength (amplitude)</strong>. Values typically range between −60 and 0 db.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">
<strong>speechiness</strong>
</td>
<td align="left" rowspan="1" colspan="1">Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g., talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">
<strong>tempo</strong>
</td>
<td align="left" rowspan="1" colspan="1">The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the <strong>average beat duration</strong>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">
<strong>valence</strong>
</td>
<td align="left" rowspan="1" colspan="1">A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g., happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g., sad, depressed, angry).</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0329072.t002/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="sec015"><h4 class="pmc_sec_title">Linguistic inquiry and word count (LIWC).</h4>
<p>Descriptions of reported autobiographical memories were analysed using the Linguistic Inquiry and Word Count (LIWC) software, which processes excerpts of text and returns summary variables reflecting a composite usage of words belonging to specific categories (i.e., parts of speech, emotion content, perceptual words) [<a href="#pone.0329072.ref030" class="usa-link" aria-describedby="pone.0329072.ref030">30</a>]. We identified 8 categories to include in analyses: positive emotion and negative emotion (as measures of emotionality), and motion, space, see, hear, feel, and social (as measures of phenomenological characteristics, i.e., subjective qualities referring to the individual’s experience of the memory). Our selection was informed by previous work that has found MEAM descriptions (compared to descriptions of AMs cued by other stimuli) to be characterised by differences in these categories [<a href="#pone.0329072.ref021" class="usa-link" aria-describedby="pone.0329072.ref021">21</a>,<a href="#pone.0329072.ref022" class="usa-link" aria-describedby="pone.0329072.ref022">22</a>,<a href="#pone.0329072.ref025" class="usa-link" aria-describedby="pone.0329072.ref025">25</a>,<a href="#pone.0329072.ref031" class="usa-link" aria-describedby="pone.0329072.ref031">31</a>].</p>
<p>LIWC variables tend to be non-normally distributed with a high proportion of MEAMs having 0 values in LIWC categories. A new boolean dummy variable was therefore created for each of the eight above categories, with values coded either 0 or for 1, with scores of 0 remaining as 0, and above 0 being coded as a 1. For the LIWC word count variable, which did not have a high prevalence of 0 value entries but was still non-normally distributed, a median split was used to obtain 0 (low word count) and 1 (high word count) codes. Subsequently, logistic regression analyses were conducted to determine which music features increased likelihood of greater-than-zero/ higher scores in each of the LIWC categories.</p></section><section id="sec016"><h4 class="pmc_sec_title">Predicting characteristics of AMs.</h4>
<p>In the interest of simplicity and parsimony, we favoured an analytic strategy that included only as many music feature dimensions as necessary to provide meaningful interpretation. Accordingly, a principal components analysis for reducing dimensionality was conducted on the nine auditory features obtained from the Spotify API (see <a href="#pone.0329072.t002" class="usa-link">Table 2</a>). As this resulted in one component that described the majority of explained variance, our primary analyses examining emotionality, phenomenological characteristics, and retrieval efficiency (linear mixed effects models or mixed-effects logistic regressions models as appropriate, with individual participant and stimulus as random effects) therefore included this principal component as the sole music feature predictor (see <a href="#pone.0329072.t001" class="usa-link">Table 1</a>). However, in the interest of comprehensiveness, we also provide an analogous secondary set of analyses where the nine auditory features, as well as two non-continuous variables of key and mode, are included as individual predictors.</p>
<p>For both types of models (using one main principle component feature or individual features as predictors), emotionality outcome variables comprised Likert ratings of valence and arousal of AM, occurrence of the most commonly reported categorical emotions and LIWC scores for positive and negative emotion words. Phenomenological characteristic outcome variables comprised Likert ratings of vividness, uniqueness, importance and social content, memory specificity, description word count, music presence (whether the song that evoked the memory was also present in the reported memory), age at time of memory and LIWC scores for perceptual and social word categories. Retrieval efficiency outcome variables comprised retrieval time and reported spontaneity of recall, and for experimenter-cued memories only, a logistic regression analysis was conducted to examine whether music features could predict the likelihood of the track evoking a memory.</p></section><section id="sec017"><h4 class="pmc_sec_title">Comparing memories in response to participant-selected and experimenter-selected stimuli.</h4>
<p>Given the intrinsic differences between how they are cued, we sought to examine differences between the musical features of, as well as the memories evoked by, experimenter-cued versus participant-selected songs. To this end, we conducted two exploratory cluster analyses, one including measures of memory content (both emotional and phenomenological), and one including auditory features from Spotify in an attempt to see whether clusters relating to type of MEAM (self-selected or experimenter-cued) would form. However, no clusters were identified, so subsequent linear mixed models including memory type (experimenter vs self-selected) as a fixed effect were conducted for each of the measures originally included in cluster analyses. For all analyses, the level of significance was α = 0.05, except where noted as Bonferroni-corrected for multiple comparisons.</p></section><section id="sec018"><h4 class="pmc_sec_title">Exploratory analyses.</h4>
<p>Finally, two further sets of exploratory analyses were conducted: one set to examine the predictive power of music features when music is not heard during retrieval (i.e., self-selected MEAMs), and one set to examine the predictive power of music features when other personal subjective information (e.g., music liking and familiarity) is available. In the former, mixed effects models as described in ‘Predicting characteristics of AMs’ section were carried out but only on self-selected MEAMs. In the latter, mixed effects models as described in ‘Predicting characteristics of AMs’ section were carried out but i) including music liking and familiarity in addition to the principal component retained from the PCA as predictors of memory outcomes and also ii) including only experimenter-cued MEAMs (as liking and familiarity data were not available for self-selected).</p></section></section></section><section id="sec019"><h2 class="pmc_sec_title">Results</h2>
<section id="sec020"><h3 class="pmc_sec_title">Descriptive statistics</h3>
<p>In total, 214 AMs were self-selected, and 1224 AMs were evoked from experimenter-selected tracks, for a total of 1438 MEAMs. On average, participants recalled 5.34 memories (SD = 2.71, range = 0–10) from 10 cued songs, meaning 53% of cues presented to participants successfully evoked memories. Descriptive statistics for Likert ratings of AM details are provided in <a href="#pone.0329072.t003" class="usa-link">Table 3</a>.</p>
<section class="tw xbox font-sm" id="pone.0329072.t003"><h4 class="obj_head">Table 3. Descriptive statistics for AM Likert ratings.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">Variable</th>
<th align="left" rowspan="1" colspan="1">Range</th>
<th align="left" rowspan="1" colspan="1">Mean rating</th>
<th align="left" rowspan="1" colspan="1">SD</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Vividness</td>
<td align="left" rowspan="1" colspan="1">1 (not at all vivid) – 7 (extremely vivid)</td>
<td align="left" rowspan="1" colspan="1">4.74</td>
<td align="left" rowspan="1" colspan="1">1.71</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Valence</td>
<td align="left" rowspan="1" colspan="1">1 (very negative) – 5 (very positive)</td>
<td align="left" rowspan="1" colspan="1">3.85</td>
<td align="left" rowspan="1" colspan="1">1.04</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Arousal</td>
<td align="left" rowspan="1" colspan="1">1 (extremely calm) – 5 (extremely energising)</td>
<td align="left" rowspan="1" colspan="1">3.56</td>
<td align="left" rowspan="1" colspan="1">1.11</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Uniqueness</td>
<td align="left" rowspan="1" colspan="1">1 (this kind of experience happens all the time) – 5 (this is a once in a lifetime experience)</td>
<td align="left" rowspan="1" colspan="1">2.75</td>
<td align="left" rowspan="1" colspan="1">1.26</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Importance</td>
<td align="left" rowspan="1" colspan="1">1 (not at all important) – 5 (extremely important)</td>
<td align="left" rowspan="1" colspan="1">2.66</td>
<td align="left" rowspan="1" colspan="1">1.30</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Social content</td>
<td align="left" rowspan="1" colspan="1">1 (not at all social) – 5 (extremely social)</td>
<td align="left" rowspan="1" colspan="1">3.15</td>
<td align="left" rowspan="1" colspan="1">1.41</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0329072.t003/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="sec021"><h3 class="pmc_sec_title">Principal components analysis of auditory features</h3>
<p>Our principal components analysis (PCA) of the auditory feature values (see <a href="#pone.0329072.t001" class="usa-link">Table 1</a>) resulted in four components with an eigenvalue above 1. However, after inspection of the scree plot (see <a href="#pone.0329072.g001" class="usa-link">Fig 1</a>), we retained one component that captured the majority of variance in the data and used this as a predictor in subsequent mixed effects models.</p>
<figure class="fig xbox font-sm" id="pone.0329072.g001"><h4 class="obj_head">Fig 1. Scree plot of PCA components.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12367148_pone.0329072.g001.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/0aa7/12367148/d0e57b89c02a/pone.0329072.g001.jpg" loading="lazy" height="517" width="700" alt="Fig 1"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329072.g001/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Predictor variables included in PCA include nine auditory features: acousticness, danceability, energy, instrumentalness, liveness, loudness, speechiness, tempo and valence.</p></figcaption></figure><p>The one retained component had the highest positive loading from acousticness, and the highest negative loadings from energy and loudness, as well as moderate negative loadings from danceability and valence variables, (see <a href="#pone.0329072.g002" class="usa-link">Fig 2</a> for scatterplots and correlations between E-A and all included auditory features). We named this component energeticness-acousticness or E-A, based on the highest positive loading variable (acousticness) and highest negative loading variable (energy) to represent the auditory properties of individual songs as they range from high energy and low acoustic to low energy and high acoustic. Put simply, songs with high values in E-A are quieter, more acoustic, and have lower-energy perceptual features (ex: <em>re: stacks</em> – Bon Iver, <em>Clair de Lune</em> – Debussy) while songs with low values in E-A are louder, feel more energetic and are less acoustic (ex: <em>Trap Queen</em> – Fetty Wap, <em>When Doves Cry</em> – Prince). Linear mixed effects models to explore any relation E-A might have to liking and familiarity of songs showed it was neither related to liking (Estimate = −0.01, SE = 0.04, t(300.59) = −0.29, p = 0.77), nor familiarity (Estimate = −0.05, SE = 0.03, t(254.08) = −1.55, p = 0.12).</p>
<figure class="fig xbox font-sm" id="pone.0329072.g002"><h4 class="obj_head">Fig 2. Scatterplots of E-A and each auditory feature.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12367148_pone.0329072.g002.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/0aa7/12367148/d37b0c397f00/pone.0329072.g002.jpg" loading="lazy" height="736" width="741" alt="Fig 2"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329072.g002/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Correlation values are indicated in the top left corner of each scatterplot.</p></figcaption></figure></section><section id="sec022"><h3 class="pmc_sec_title">Effect of E-A on emotional content of autobiographical memories</h3>
<p>With regard to valence and arousal, E-A had no effect on AM valence or positive emotion words. However, it had a negative effect on AM arousal rating, (Estimate = −0.11, SE = 0.02, t(420.03) = −5.60, p &lt; 0.001), and was associated with an increased likelihood of reporting LIWC negative emotion words (Estimate = 0.16, SE = 0.05, z = 3.32, p = 0.001). (see <a href="#pone.0329072.g003" class="usa-link">Fig 3</a> for plots, <a href="#pone.0329072.t004" class="usa-link">Table 4</a> for statistical reporting of all linear mixed effects models, <a href="#pone.0329072.t005" class="usa-link">Table 5</a> for statistical reporting of logistic mixed effects models).</p>
<figure class="fig xbox font-sm" id="pone.0329072.g003"><h4 class="obj_head">Fig 3. Plots showing E-A and outcome variables.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12367148_pone.0329072.g003.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/0aa7/12367148/4679e7aa42bd/pone.0329072.g003.jpg" loading="lazy" height="540" width="723" alt="Fig 3"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329072.g003/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>A. Scatterplots and sigmoid function plots of E-A and MEAM emotional content outcomes B. Scatterplots of E-A and non-LIWC phenomenological characteristics. C. Scatterplots and sigmoid function plot of E-A and cue efficiency outcomes. D. Sigmoid function plots of E-A and LIWC phenomenological characteristic outcomes. Significance indicated as follows: *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05.</p></figcaption></figure><section class="tw xbox font-sm" id="pone.0329072.t004"><h4 class="obj_head">Table 4. Estimate, standard error, t-value and p-values of linear mixed effects models of E-A for each outcome variable.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">Dependent measure</th>
<th align="left" rowspan="1" colspan="1">
<em>B</em>
</th>
<th align="left" rowspan="1" colspan="1">SE</th>
<th align="left" rowspan="1" colspan="1">t</th>
<th align="left" rowspan="1" colspan="1">p</th>
</tr></thead>
<tbody>
<tr><td align="left" colspan="5" rowspan="1">Emotionality</td></tr>
<tr>
<td align="left" rowspan="1" colspan="1">1.<strong>Arousal***</strong>
</td>
<td align="left" rowspan="1" colspan="1">−0.11</td>
<td align="left" rowspan="1" colspan="1">0.02</td>
<td align="left" rowspan="1" colspan="1">−5.60</td>
<td align="left" rowspan="1" colspan="1">&lt; 0.001</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2.Valence</td>
<td align="left" rowspan="1" colspan="1">−0.02</td>
<td align="left" rowspan="1" colspan="1">0.02</td>
<td align="left" rowspan="1" colspan="1">−1.01</td>
<td align="left" rowspan="1" colspan="1">0.31</td>
</tr>
<tr><td align="left" colspan="5" rowspan="1">Phenomenological characteristics</td></tr>
<tr>
<td align="left" rowspan="1" colspan="1">1. <strong>Vividness***</strong>
</td>
<td align="left" rowspan="1" colspan="1">0.10</td>
<td align="left" rowspan="1" colspan="1">0.03</td>
<td align="left" rowspan="1" colspan="1">3.45</td>
<td align="left" rowspan="1" colspan="1">0.001</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2. <strong>Uniqueness**</strong>
</td>
<td align="left" rowspan="1" colspan="1">0.06</td>
<td align="left" rowspan="1" colspan="1">0.02</td>
<td align="left" rowspan="1" colspan="1">2.75</td>
<td align="left" rowspan="1" colspan="1">0.006</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">3. <strong>Importance***</strong>
</td>
<td align="left" rowspan="1" colspan="1">0.12</td>
<td align="left" rowspan="1" colspan="1">0.02</td>
<td align="left" rowspan="1" colspan="1">5.77</td>
<td align="left" rowspan="1" colspan="1">&lt; 0.001</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4. <strong>Social content***</strong>
</td>
<td align="left" rowspan="1" colspan="1">−0.10</td>
<td align="left" rowspan="1" colspan="1">0.02</td>
<td align="left" rowspan="1" colspan="1">−4.02</td>
<td align="left" rowspan="1" colspan="1">&lt; 0.001</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">5. Age at time of memory</td>
<td align="left" rowspan="1" colspan="1">0.09</td>
<td align="left" rowspan="1" colspan="1">0.10</td>
<td align="left" rowspan="1" colspan="1">0.89</td>
<td align="left" rowspan="1" colspan="1">0.38</td>
</tr>
<tr><td align="left" colspan="5" rowspan="1">Retrieval efficiency</td></tr>
<tr>
<td align="left" rowspan="1" colspan="1">6. <strong>Retrieval time*</strong>
</td>
<td align="left" rowspan="1" colspan="1">0.25</td>
<td align="left" rowspan="1" colspan="1">0.11</td>
<td align="left" rowspan="1" colspan="1">2.36</td>
<td align="left" rowspan="1" colspan="1">0.02</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">7. Spontaneity- deliberateness</td>
<td align="left" rowspan="1" colspan="1">−0.01</td>
<td align="left" rowspan="1" colspan="1">0.02</td>
<td align="left" rowspan="1" colspan="1">−0.34</td>
<td align="left" rowspan="1" colspan="1">0.73</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0329072.t004/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="t004fn001"><p>Participant and song are included as random effects for each model.</p></div></div></section><section class="tw xbox font-sm" id="pone.0329072.t005"><h4 class="obj_head">Table 5. Estimate, standard error, z-value and p-values of mixed effects logistic regressions of E-A on reporting each outcome variable.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">Dependent measure</th>
<th align="left" rowspan="1" colspan="1">
<em>B</em>
</th>
<th align="left" rowspan="1" colspan="1">SE</th>
<th align="left" rowspan="1" colspan="1">z</th>
<th align="left" rowspan="1" colspan="1">p</th>
</tr></thead>
<tbody>
<tr><td align="left" colspan="5" rowspan="1">Emotionality reported<br>For categorical emotions:<br>* = significant at α = 0.0035 (0.05/14)<br>** = significant at α = 0.0007 (.01/14)<br>*** = significant at α = 0.00007 (.001/14)</td></tr>
<tr>
<td align="left" rowspan="1" colspan="1">1. LIWC – positive emotion</td>
<td align="left" rowspan="1" colspan="1">0.03</td>
<td align="left" rowspan="1" colspan="1">0.04</td>
<td align="left" rowspan="1" colspan="1">0.75</td>
<td align="left" rowspan="1" colspan="1">0.46</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2. <strong>LIWC – negative emotion **</strong>
</td>
<td align="left" rowspan="1" colspan="1">0.16</td>
<td align="left" rowspan="1" colspan="1">0.05</td>
<td align="left" rowspan="1" colspan="1">3.32</td>
<td align="left" rowspan="1" colspan="1">0.001</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">3. Admiration</td>
<td align="left" rowspan="1" colspan="1">0.08</td>
<td align="left" rowspan="1" colspan="1">0.06</td>
<td align="left" rowspan="1" colspan="1">1.36</td>
<td align="left" rowspan="1" colspan="1">0.18</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4. <strong>Adoration***</strong>
</td>
<td align="left" rowspan="1" colspan="1">0.24</td>
<td align="left" rowspan="1" colspan="1">0.06</td>
<td align="left" rowspan="1" colspan="1">3.98</td>
<td align="left" rowspan="1" colspan="1">&lt; 0.001</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">5. <strong>Aesthetic appreciation*</strong>
</td>
<td align="left" rowspan="1" colspan="1">0.21</td>
<td align="left" rowspan="1" colspan="1">0.07</td>
<td align="left" rowspan="1" colspan="1">2.94</td>
<td align="left" rowspan="1" colspan="1">0.003</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">6. <strong>Amusement***</strong>
</td>
<td align="left" rowspan="1" colspan="1">−0.32</td>
<td align="left" rowspan="1" colspan="1">0.05</td>
<td align="left" rowspan="1" colspan="1">−6.46</td>
<td align="left" rowspan="1" colspan="1">&lt; 0.001</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">7. <strong>Calmness***</strong>
</td>
<td align="left" rowspan="1" colspan="1">0.45</td>
<td align="left" rowspan="1" colspan="1">0.06</td>
<td align="left" rowspan="1" colspan="1">7.20</td>
<td align="left" rowspan="1" colspan="1">&lt; 0.001</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">8. <strong>Excitement***</strong>
</td>
<td align="left" rowspan="1" colspan="1">−0.21</td>
<td align="left" rowspan="1" colspan="1">0.04</td>
<td align="left" rowspan="1" colspan="1">−4.96</td>
<td align="left" rowspan="1" colspan="1">&lt; 0.001</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">9. Interest</td>
<td align="left" rowspan="1" colspan="1">−0.14</td>
<td align="left" rowspan="1" colspan="1">0.05</td>
<td align="left" rowspan="1" colspan="1">−2.84</td>
<td align="left" rowspan="1" colspan="1">0.005</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">10. Joy</td>
<td align="left" rowspan="1" colspan="1">−0.10</td>
<td align="left" rowspan="1" colspan="1">0.04</td>
<td align="left" rowspan="1" colspan="1">−2.54</td>
<td align="left" rowspan="1" colspan="1">0.011</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">11. Nostalgia</td>
<td align="left" rowspan="1" colspan="1">0.11</td>
<td align="left" rowspan="1" colspan="1">0.04</td>
<td align="left" rowspan="1" colspan="1">2.60</td>
<td align="left" rowspan="1" colspan="1">0.009</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">12. Satisfaction</td>
<td align="left" rowspan="1" colspan="1">−0.07</td>
<td align="left" rowspan="1" colspan="1">0.06</td>
<td align="left" rowspan="1" colspan="1">−1.18</td>
<td align="left" rowspan="1" colspan="1">0.24</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">13. <strong>Romance**</strong>
</td>
<td align="left" rowspan="1" colspan="1">0.24</td>
<td align="left" rowspan="1" colspan="1">0.06</td>
<td align="left" rowspan="1" colspan="1">3.74</td>
<td align="left" rowspan="1" colspan="1">&lt; 0.001</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">14. Awe</td>
<td align="left" rowspan="1" colspan="1">0.08</td>
<td align="left" rowspan="1" colspan="1">0.07</td>
<td align="left" rowspan="1" colspan="1">1.21</td>
<td align="left" rowspan="1" colspan="1">0.23</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">15. <strong>Sadness***</strong>
</td>
<td align="left" rowspan="1" colspan="1">0.36</td>
<td align="left" rowspan="1" colspan="1">0.07</td>
<td align="left" rowspan="1" colspan="1">4.89</td>
<td align="left" rowspan="1" colspan="1">&lt; 0.001</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">16. Awkwardness</td>
<td align="left" rowspan="1" colspan="1">−0.13</td>
<td align="left" rowspan="1" colspan="1">0.09</td>
<td align="left" rowspan="1" colspan="1">−1.51</td>
<td align="left" rowspan="1" colspan="1">0.13</td>
</tr>
<tr><td align="left" colspan="5" rowspan="1">Phenomenological characteristics</td></tr>
<tr>
<td align="left" rowspan="1" colspan="1">1. Specificity</td>
<td align="left" rowspan="1" colspan="1">−0.02</td>
<td align="left" rowspan="1" colspan="1">0.04</td>
<td align="left" rowspan="1" colspan="1">−0.40</td>
<td align="left" rowspan="1" colspan="1">0.69</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2. Music presence</td>
<td align="left" rowspan="1" colspan="1">0.00</td>
<td align="left" rowspan="1" colspan="1">0.04</td>
<td align="left" rowspan="1" colspan="1">0.06</td>
<td align="left" rowspan="1" colspan="1">0.95</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">3. <strong>Word count***</strong>
</td>
<td align="left" rowspan="1" colspan="1">0.25</td>
<td align="left" rowspan="1" colspan="1">0.06</td>
<td align="left" rowspan="1" colspan="1">4.31</td>
<td align="left" rowspan="1" colspan="1">&lt; 0.001</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">4. LIWC – seeing</td>
<td align="left" rowspan="1" colspan="1">0.08</td>
<td align="left" rowspan="1" colspan="1">0.04</td>
<td align="left" rowspan="1" colspan="1">1.96</td>
<td align="left" rowspan="1" colspan="1">0.05</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">5. <strong>LIWC – hearing**</strong>
</td>
<td align="left" rowspan="1" colspan="1">0.14</td>
<td align="left" rowspan="1" colspan="1">0.04</td>
<td align="left" rowspan="1" colspan="1">3.20</td>
<td align="left" rowspan="1" colspan="1">0.001</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">6. LIWC – feeling</td>
<td align="left" rowspan="1" colspan="1">0.12</td>
<td align="left" rowspan="1" colspan="1">0.07</td>
<td align="left" rowspan="1" colspan="1">1.55</td>
<td align="left" rowspan="1" colspan="1">0.12</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">7. LIWC – motion</td>
<td align="left" rowspan="1" colspan="1">0.00</td>
<td align="left" rowspan="1" colspan="1">0.04</td>
<td align="left" rowspan="1" colspan="1">0.10</td>
<td align="left" rowspan="1" colspan="1">0.92</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">8. LIWC – space</td>
<td align="left" rowspan="1" colspan="1">0.03</td>
<td align="left" rowspan="1" colspan="1">0.05</td>
<td align="left" rowspan="1" colspan="1">0.64</td>
<td align="left" rowspan="1" colspan="1">0.52</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">9. LIWC – social</td>
<td align="left" rowspan="1" colspan="1">0.07</td>
<td align="left" rowspan="1" colspan="1">0.05</td>
<td align="left" rowspan="1" colspan="1">1.43</td>
<td align="left" rowspan="1" colspan="1">0.15</td>
</tr>
<tr><td align="left" colspan="5" rowspan="1">Retrieval efficiency</td></tr>
<tr>
<td align="left" rowspan="1" colspan="1">10. <strong>Likelihood of evoking an AM**</strong>
</td>
<td align="left" rowspan="1" colspan="1">−0.16</td>
<td align="left" rowspan="1" colspan="1">0.05</td>
<td align="left" rowspan="1" colspan="1">−2.97</td>
<td align="left" rowspan="1" colspan="1">0.003</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0329072.t005/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<div class="tw-foot p"><div class="fn" id="t005fn001"><p>Participant and song are included as random effects for each model.</p></div></div></section><p>To examine the predictive power of E-A with respect to AM-related categorical emotions, we first identified the most commonly reported emotion categories (by visual inspection of a bar plot of the number of times each emotion was reported, and including emotions associated with at least 100 individual AMs) and used logistic regression analysis to try to predict their occurrence with E-A. For these analyses, Bonferroni-corrections, with the corrected alpha level set at α = 0.05/ 14 = 0.0036, was applied due to multiple comparisons.</p>
<p>Of the fourteen emotions included in analyses (see <a href="#pone.0329072.g004" class="usa-link">Fig 4</a> for occurrence of all emotion categories), E-A was not predictive of the occurrence of admiration, awe, awkwardness, interest, joy, nostalgia, or satisfaction. However, aesthetic appreciation (Estimate = 0.21, SE = 0.07, z = 2.94, p = 0.003), adoration (Estimate = 0.24, SE = 0.06, z = 3.98, p &lt; 0.001), calmness (Estimate = 0.45, SE = 0.06, z = 7.20, p &lt; 0.001), romance (Estimate = 0.24, SE = 0.06, z = 3.74, p &lt; 0.001) and sadness (Estimate = 0.36, SE = 0.07, z = 4.89, p &lt; 0.001) were predicted by increasing E-A while amusement (Estimate = −0.32, SE = 0.05, z = −6.46, p &lt; 0.001) and excitement (Estimate = −0.21, SE = 0.04, z = −4.96, p &lt; 0.001) were predicted by decreasing E-A (see <a href="#pone.0329072.g005" class="usa-link">Fig 5</a> for sigmoid function plots of most commonly reported emotions, <a href="#pone.0329072.t005" class="usa-link">Table 5</a> for statistical reporting of mixed effects logistic regressions).</p>
<figure class="fig xbox font-sm" id="pone.0329072.g004"><h4 class="obj_head">Fig 4. Occurrence of reported AM-associated categorical emotions.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12367148_pone.0329072.g004.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/0aa7/12367148/8cc438e7ac1f/pone.0329072.g004.jpg" loading="lazy" height="404" width="660" alt="Fig 4"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329072.g004/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Values reflect sum of times each emotion was reported as associated with an AM. The top fourteen most commonly reported emotions used in analyses are indicated in dark blue.</p></figcaption></figure><figure class="fig xbox font-sm" id="pone.0329072.g005"><h4 class="obj_head">Fig 5. Sigmoid function plots of top emotion categories.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12367148_pone.0329072.g005.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/0aa7/12367148/6d74dc7477e2/pone.0329072.g005.jpg" loading="lazy" height="739" width="741" alt="Fig 5"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329072.g005/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Significant models are indicated with asterisks as follows: * = significant at α = 0.0035 (0.05/14); ** = significant at α = 0.0007 (.01/14); *** = significant at α = 0.00007 (.001/14).</p></figcaption></figure></section><section id="sec023"><h3 class="pmc_sec_title">Effect of E-A on phenomenological content of autobiographical memories</h3>
<p>Analysis examining the phenomenological properties of AMs showed a positive effect of E-A on memory vividness (Estimate = 0.10, SE = 0.03, t(504.98) = 3.45, p = 0.001), importance (Estimate = 0.12, SE = 0.02, t(337.10) = 5.77, p &lt; 0.001) and uniqueness (Estimate = 0.06, SE = 0.02, t(401.48) = 2.75, p = 0.006), as well as a higher likelihood of high word count (Estimate = 0.21, SE = 0.05, z = 4.43, p &lt; 0.001) and of reporting LIWC ‘hear’ words (Estimate = 0.14, SE = 0.04, z = 3.20, p = 0.001). Analyses also revealed a negative effect of E-A on social content (Estimate = −0.10, SE = 0.02, t(522.38) = −4.02, p &lt; 0.001) (see <a href="#pone.0329072.g003" class="usa-link">Fig 3</a> for scatterplots, <a href="#pone.0329072.t004" class="usa-link">Tables 4</a> and <a href="#pone.0329072.t005" class="usa-link">5</a> for statistical reporting). E-A had no relationship with memory specificity, age at the time of the memory reported, or music presence (whether the song that evoked the memory was present in the reported memory itself), nor with LIWC motion, space, visual, feeling or social words.</p></section><section id="sec024"><h3 class="pmc_sec_title">Effect of E-A on retrieval efficiency of autobiographical memories</h3>
<p>Examination of E-A’s effect on memory retrieval showed high E-A songs to be associated with longer memory retrieval time (Estimate = 0.25, SE = 0.11, t(332.30) = 2.36, p = 0.02), while logistic regression analysis showed that high E-A (experimenter-cued) songs were less likely to induce memories (Estimate = −0.16, SE = 0.05, z = −2.97, p = 0.003). No effect of E-A on spontaneity of memory was found. (See <a href="#pone.0329072.g003" class="usa-link">Fig 3</a> for plots, <a href="#pone.0329072.t004" class="usa-link">Tables 4</a> and <a href="#pone.0329072.t005" class="usa-link">5</a> for statistical reporting).</p></section><section id="sec025"><h3 class="pmc_sec_title">The effect of individual auditory features</h3>
<p>To complement our primary analyses, and further assess the strength of individual auditory features as predictors of memory qualities, we replicated the above analyses with mixed-effects models that included the nine continuous auditory features used in the PCA and described in <a href="#pone.0329072.t001" class="usa-link">Table 1</a>, as well as key (a categorical variable wherein integers map to pitch classes) and mode (a boolean variable representing major key as 1 and minor key as 0) as predictors.</p>
<p>These analyses resulted in similar outcomes to models that used E-A as the single predictor: individual features predicted almost all of the same outcome variables as E-A for non-LIWC variables (as summarised in <a href="#pone.0329072.t004" class="usa-link">Tables 4</a> and <a href="#pone.0329072.t005" class="usa-link">5</a>), and the majority of independent features that significantly predicted outcomes loaded strongly onto E-A. For LIWC variables, some relationships were observed whereby individual features predicted the presence of certain LIWC categories that E-A did not predict (with energy predicting see, feel and motion words; acousticness predicting space words; loudness predicting see words; danceability predicting positive emotion words; tempo predicting feel words; and instrumentalness predicting positive emotion and motion words). We further point out that unlike in the E-A models, these sets of analyses showed i) higher instrumentalness, which did not strongly load onto E-A, to predict increased likelihood of MEAMs having high LIWC word count and including negative emotion, positive emotion and motion words, ii) lower tempo, which also did not load onto E-A, to predict high memory age, uniqueness, importance and presence of LIWC feel and negative emotion words, and finally iii) energy, loudness and valence to all independently predict memory valence (despite E-A not being able to predict memory valence). Results of these analyses are displayed in <a href="#pone.0329072.g006" class="usa-link">Fig 6</a> which shows p-values of mixed-effects models. All statistical output for these models is also reported in OSF at this link: <a href="https://osf.io/jke9w/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://osf.io/jke9w/</a></p>
<figure class="fig xbox font-sm" id="pone.0329072.g006"><h4 class="obj_head">Fig 6. P-value heatmaps of mixed-effects models including individual auditory features as independent predictors of MEAM outcome variables.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12367148_pone.0329072.g006.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/0aa7/12367148/67b0cb122fe0/pone.0329072.g006.jpg" loading="lazy" height="220" width="723" alt="Fig 6"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329072.g006/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Note that E-A was not included as a predictor in these models but is added to these plots to allow the reader to compare the two analysis approaches. <strong>A.</strong> P-value heatmap for outcome variables excluding LIWC and categorical emotions. <strong>B.</strong> P-value heatmap for categorical emotions. <strong>C.</strong> P-value heatmap for LIWC categories. For plots A and C, * = significant at α = 0.05, ** = significant at α = 0.01, ** = significant at α = 0.001. For plot B, * = significant at α = 0.0035, ** = significant at α = 0.0007, ** = significant at α = 0.00007 reflecting Bonferroni corrections.</p></figcaption></figure></section><section id="sec026"><h3 class="pmc_sec_title">Exploratory analyses</h3>
<section id="sec027"><h4 class="pmc_sec_title">Comparing self-selected and experimenter-cued MEAMs.</h4>
<p>Exploratory cluster analyses (as described in our pre-registration report) were conducted to explore patterns of reported autobiographical memories among participants in the study, and specifically to see whether any salient differences between self-selected and experimenter-cued MEAMs might be seen reflected in meaningful clusters. Hierarchical clustering with complete linkage and Euclidean distance as the similarity measure, however, failed to show distinct clusters.</p>
<p>Therefore mixed effects models were conducted for each variable that had been included in the cluster analysis, where MEAMs only corresponding to reminiscence bump age (between 9 and 19) were included to constitute a comparable sample. This was done as a majority of experimenter-cued MEAMs would have been from this time frame, and we aimed to identify differences on account of whether MEAMs were self-selected or cued, not on the basis of age of memory. To control for the increased risk of Type I errors due to multiple comparisons (n = 17), we applied Bonferroni corrections, with the corrected alpha level set at α = 0.05/ 17 = 0.0029.</p>
<p>Analyses revealed that self-selected memories were more specific (Estimate = 0.84, SE = 0.24, z = 3.53, p &lt; 0.001), vivid (Estimate = 1.19, SE = 0.15, t(910.07) = 7.86, p &lt; 0.001), positive (Estimate = 0.50, SE = 0.10, t(944.77) = 5.25), p &lt; 0.001), arousing (Estimate = 0.43, SE = 0.10, t(851.70) = 4.12, p &lt; 0.001), unique (Estimate = 0.74, SE = 0.10, t(848.98) = 7.20, p &lt; 0.001), important (Estimate = 1.31, SE = 0.11, t(890.74) = 12.48, p &lt; 0.001) and had a higher likelihood of having high word count (Estimate = 4.72, SE = 0.53, z = 8.95, p &lt; 0.001). With regard to LIWC word ratings, self-selected memories also predicted a greater likelihood of positive emotion words (Estimate = 1.37, SE = 0.24, z = 5.71, p &lt; 0.001), negative emotion words (Estimate = 1.12, SE = 0.24, z = 4.60, p &lt; 0.001), motion words (Estimate = 2.11, SE = 0.29, z = 7.31, p &lt; 0.001), space words (Estimate = 2.10, SE = 0.53, z = 3.95, p &lt; 0.001), see words (Estimate = 1.10, SE = 0.24, z = 4.67, p &lt; 0.001), hear words (Estimate = 1.79, SE = 0.00, z = 1614.89, p &lt; 0.001), social words (Estimate = 2.25, SE = 0.53, z = 4.22, p &lt; 0.001) and feeling words (Estimate = 7.28, SE = 0.00, z = 2712.79, p &lt; 0.001). Analysis also revealed self-selected memories to be associated with higher values of E-A (Estimate = 0.37, SE = 0.03, t(768.79) = 13.43, p &lt; 0.001).</p></section><section id="sec028"><h4 class="pmc_sec_title">Effects of E-A on self-selected MEAMs only.</h4>
<p>Models examining the effect of E-A on self-selected MEAMs only were carried out to determine E-A’s predictive power in situations where listeners recount the memory without hearing the music. While this characteristic of the self-selected music cannot be isolated from the fact that self-selected MEAMs music i) is more personally salient (being self-selected) and ii) spans more varied genres and time periods than the experimenter selected billboard music, it is interesting to note what E-A continued to predict or not. Indeed, results showed that E-A continued to predict many aspects of emotionality, namely AM arousal (Estimate = −0.16, SE = 0.04, t(207.31) = −4.48, p &lt; 0.001), likelihood of reporting negative words (Estimate = 0.19, SE = 0.07, z = 2.81, p = 0.005), calmness (Estimate = 0.26, SE = 0.07, z = 3.89, p &lt; 0.001) and excitement (Estimate = −0.23, SE = 0.07, z = −3.15, p = 0.002); as well as the phenomenological quality of social content (Estimate = −0.14, SE = 0.04, t(212) = −3.41, p = 0.001.</p>
<p>Conversely, while we cannot rule out that this was due to the reduced sample size inevitable when looking at self-selected MEAMs only, these analyses showed E-A was not able to predict several categorical emotions (aesthetic appreciation, adoration, amusement, sadness or romance) and a number of key phenomenological variables (vividness, uniqueness, importance, high word count and likelihood of using ‘hear’ words).</p></section><section id="sec029"><h4 class="pmc_sec_title">Effects of E-A in models including music liking and familiarity.</h4>
<p>Our results showed E-A to predict numerous aspects of MEAMs, even in the absence of the music. However, it remained unclear how well it would perform as a predictor of memory qualities when details of personal salience (i.e., liking and familiarity) of the music stimuli are also available. To this end, linear mixed effects models analogous to the above but including music liking and familiarity in addition to E-A, as predictors were run on experimenter-cued AMs. Results from these analyses showed E-A to continue to significantly predict several aspects of emotionality (arousal, reporting of calmness, amusement, excitement, and sadness), phenomenological characteristics (social content), and retrieval efficiency (likelihood of evoking memory and retrieval speed). However, we found that E-A no longer significantly predicted some aspects of emotionality: negative emotion words, likelihood of reporting certain emotions (aesthetic appreciation, adoration, and romance) and phenomenological characteristics: vividness, importance, uniqueness, likelihood of high word count and hearing words, and age at time of memory, with liking and/or familiarity shown to predict these outcome variables more strongly. In brief, these results showed that liking and familiarity, when available and included, may be more able to account for some effects initially attributed solely to E-A. Full results for these models are available in OSF: <a href="https://osf.io/jke9w/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://osf.io/jke9w/</a></p></section></section></section><section id="sec030"><h2 class="pmc_sec_title">Discussion</h2>
<p>This study aimed to examine how characteristics of music-evoked autobiographical memories may be influenced by auditory features of the same memory-evoking music in MEAMs that were either volunteered by participants or cued by experimenter-selected popular music. Analyses revealed a single musical feature component we named energeticness-acousticness or E-A. This component was shown to predict qualities related to the emotionality, phenomenological characteristics and retrieval efficiency of MEAMs, albeit only to a lesser extent in the presence of information about how much the music was familiar to or liked by the listener.</p>
<section id="sec031"><h3 class="pmc_sec_title">Music features can predict categorical emotions associated with AMs</h3>
<p>A large bulk of the research regarding MEAMs has characterised the emotionality of music and the AMs that it triggers using the circumplex model of emotion [<a href="#pone.0329072.ref032" class="usa-link" aria-describedby="pone.0329072.ref032">32</a>]; where the emotional content of both music and memories is operationalised primarily by arousal and valence. [<a href="#pone.0329072.ref008" class="usa-link" aria-describedby="pone.0329072.ref008">8</a>–<a href="#pone.0329072.ref012" class="usa-link" aria-describedby="pone.0329072.ref012">12</a>,<a href="#pone.0329072.ref018" class="usa-link" aria-describedby="pone.0329072.ref018">18</a>,<a href="#pone.0329072.ref033" class="usa-link" aria-describedby="pone.0329072.ref033">33</a>–<a href="#pone.0329072.ref035" class="usa-link" aria-describedby="pone.0329072.ref035">35</a>]. Some studies have assessed more complex emotional responses related to remembering MEAMs [<a href="#pone.0329072.ref001" class="usa-link" aria-describedby="pone.0329072.ref001">1</a>], or to hearing memory-evoking songs [<a href="#pone.0329072.ref036" class="usa-link" aria-describedby="pone.0329072.ref036">36</a>]. However, the current study was the first to characterise emotional experiences reported in memories as rich categorical emotion states, and to examine how those emotional experiences in these MEAMs may be influenced by features of the music in question. With suggestions that there exist between 20 and 30 distinct emotional states [<a href="#pone.0329072.ref037" class="usa-link" aria-describedby="pone.0329072.ref037">37</a>], and that emotion categories drive reports of emotional experience more than dimensions of arousal and valence [<a href="#pone.0329072.ref014" class="usa-link" aria-describedby="pone.0329072.ref014">14</a>], the extent to which such memory types can be predicted by musical stimuli constituted an important outstanding question.</p>
<p>Our results, which showed auditory profiles of memory-evoking music to be predictive of several complex categorical emotions – aesthetic appreciation, calmness, adoration, amusement, excitement, sadness and romance – demonstrate the relevance of this approach. We were able to show the distinct kinds of positive emotional experiences that music tends to be associated with, expanding on the established evidence that MEAMs are regarded as positive [<a href="#pone.0329072.ref038" class="usa-link" aria-describedby="pone.0329072.ref038">38</a>]. That joy, adoration, admiration, aesthetic experience and excitement were among the top most commonly reported emotions associated with AMs highlights that MEAMs may overlap with what is referred to in music psychology as strong experiences with music (SEM), understood as instances of music-listening involving high absorption, emotional intensity and ‘peak experience’ [<a href="#pone.0329072.ref039" class="usa-link" aria-describedby="pone.0329072.ref039">39</a>]. Most importantly, however, by demonstrating that musical features can predict the incidence of AMs with rich and mixed emotional qualities (as well as the phenomenological characteristics of these AMs), we show the potential for successfully evoking memories of specific kinds, for example in the context of reminiscence therapies for populations with memory impairments.</p>
<p>In any case, we show how the nuance of the emotionality of MEAMs may be lost upon reducing emotion into two dimensions of arousal and valence. Our findings show that while MEAMs are indeed generally positive, (as we found MEAMs to be described as positive on average (M = 3.86 out of 5), the nature of positive emotions associated with the MEAM may differ qualitatively with respect to the musical profile of the memory-evoking song. If not for the inclusion of complex categorical emotions, such distinctions would have been harder to detect. While some categorical emotions can be mapped to arousal and valence in predictable ways (i.e., excitement as high arousal-high valence and calmness as low arousal-high valence), others such as romance are less obvious. It follows that work concerning music-evoked autobiographical memory benefits from exploring the kinds of specific emotion states that are prevalent in AMs and the features of music that are able to cue such memories.</p></section><section id="sec032"><h3 class="pmc_sec_title">Music features can predict phenomenological characteristics of AMs</h3>
<p>Our study asked whether phenomenological characteristics of AMs such as vividness of remembering, importance to the individual, degree of social content of the memory, and uniqueness can be predicted by the musical cue, and we showed this to be case.</p>
<p>We demonstrated that memories of experiences that are highly social tended to be associated with less acoustic and more energetic, danceable (low E-A) songs, whereas memories of vivid, unique and self-important experiences were associated with more acoustic, contemplative (high E-A) songs. These results are in line with previous studies which have reported that positive music stimuli (danceable being a common characteristic) cue more social and energising memories compared to more negative (less upbeat) music, and that less arousing music elicits more vivid and unique memories than high arousing music [<a href="#pone.0329072.ref010" class="usa-link" aria-describedby="pone.0329072.ref010">10</a>].</p>
<p>Interestingly, a closer look at the phenomenological characteristics of MEAMs corroborate assumptions about the types of events or experiences at which certain types of music might be present and which may thus contribute to autobiographical encoding. In other words, our study shows that the nature of the match between music and AMs is consistent with social and cultural expectations. Parties, social events and nightclubs are likely to have energetic music playing, as well as dancing and socialisation. More melancholic, slow songs are unlikely to be present at these kinds of events, and consequently more likely to be associated with instances of independent or small group listening. Here, our finding that low energetic-high acoustic music was associated with occurrence of words relating to hearing are in line with this interpretation, as it indicates that more acoustic and sadder songs are associated with AMs characterised by attentive music-listening.</p>
<p>Our results additionally highlight that participants may evaluate MEAMs as positive even when they describe the initial event itself as being negative. We found that while low energetic-high acoustic songs were more likely to be associated with memories that had more negative words in their descriptions, this did not equate to a more negative AM valence rating. In other words, while AMs evoked by acoustic songs may be around sadder events, even these MEAMs overall are still considered by participants to be positive. This seemingly conflicting finding of ours is interesting as it speaks to the power of music to help listeners cope with negative events and appraise them in a more positive light. It is also consistent with a large body of work that emphasises MEAMS as being generally positive [<a href="#pone.0329072.ref008" class="usa-link" aria-describedby="pone.0329072.ref008">8</a>,<a href="#pone.0329072.ref025" class="usa-link" aria-describedby="pone.0329072.ref025">25</a>,<a href="#pone.0329072.ref033" class="usa-link" aria-describedby="pone.0329072.ref033">33</a>]. Once again, it seems important to note that this finding would not have been possible had we not accessed both their description of the event around the memory (allowing us to extract actual memory valence using LIWC) and their subjective evaluation of how the memory felt at the time (necessarily influenced by appraisal processes).</p></section><section id="sec033"><h3 class="pmc_sec_title">The limits of music features’ predictive power</h3>
<p>Our main analyses examining how features predicted qualities of memory mostly collapsed across self-selected and experimenter-cued memories. However these are objectively different types of memories due to several defining differences. In the former case, there is greater diversity in terms of genres, time periods and musical styles of the memory-evoking music, as well as an expectation that either those memories or songs reported might be more familiar or rehearsed compared to experimenter-cued MEAMs. Additionally, in self-selected MEAMs, musical stimuli are not acoustically present while for experimenter-cued MEAMs, they are.</p>
<p>Because of these differences, and even though the presence of music may not necessarily lead to more emotional recollections compared to other memory-evoking cues [<a href="#pone.0329072.ref040" class="usa-link" aria-describedby="pone.0329072.ref040">40</a>], a conservative approach to looking at how well music features of songs predict qualities of memories was taken whereby we only examined those memories where music was not heard during retrieval. Carrying out these analyses confirmed that some emotional qualities (arousal, calmness, excitement, negative words) and the phenomenological quality of social content continued to be predictable even with the substantially smaller sample of self-selected (N = 214) (compared with the combined sample (N = 1438) of MEAMs initially used), suggesting that our conclusions on the combined sample are largely supported. However, smaller sample size notwithstanding, it is relevant to consider which effects failed to be maintained when only looking at self-selected MEAMs: these less reliable effects were categorical emotions of aesthetic appreciation, adoration, amusement, sadness and romance; phenomenological characteristics like vividness, importance and uniqueness, high word count, age at time of memory, and finally, likelihood of using ‘hear’-related words in descriptions.</p>
<p>We suggest that these observed differences in E-A’s predictive ability of certain memory qualities may at least in part be due to characteristics unique to self-selected MEAMs. Self-selected MEAMs on the whole were associated with higher ratings for emotional and phenomenological variables, were likelier to be recollections of specific events compared to experimenter-cued MEAMs, and were also characterised by higher E-A values, (i.e., more acoustic and less energetic songs compared to experimenter-cued MEAMs). Indeed, all of these might have reduced the capacity for E-A to predict memory characteristics due to reduced variance and ceiling effects in both the predictor (E-A) and the variables (emotionality and phenomenological variables) we were examining.</p>
<p>Another possible explanation of the observed differences in E-A’s predictive ability is that the predictive capacity of auditory features holds only when music is acoustically present. That is, hearing the music influences responding, and in the case of high E-A songs, evokes more complex emotions (e.g., aesthetic appreciation, adoration) that in turn prime memories of a similar nature. Here it is important to note that, if that is the case, one proposed implication of the current work, (namely being able to predict memories evoked based on music features alone) may be more limited in scope than thought. Further studies will be needed to examine this more carefully.</p>
<p>In any case, at this point of considering different possible retrieval mechanisms in MEAMs, it is interesting to note that the degree of personal relevance music has for a listener (liking and familiarity) seems to be more powerful than acoustic features in predicting memories’ vividness, importance and uniqueness as well as some more complex emotions of aesthetic appreciation, adoration and romance. This finding corroborates previous findings showing a strong influence of liking and familiarity on memory qualities and also reinforces the idea that, when available, such information (about preferred or personally salient music) is especially useful in ensuring that vivid and important memories are elicited [<a href="#pone.0329072.ref041" class="usa-link" aria-describedby="pone.0329072.ref041">41</a>].</p></section><section id="sec034"><h3 class="pmc_sec_title">Implications, further directions and limitations</h3>
<section id="sec035"><h4 class="pmc_sec_title">Implications.</h4>
<p>A compelling finding from the current research is that the tendency of certain music to be present in certain contexts may lead to it being a good trigger of particular types of memories. In other words, we show that music with certain features may be better able to conjure up specific moments in our past. At the same time, our results hint that more qualities of personally significant MEAMs (here self-selected MEAMs) may be less strongly predicted by the music’s acoustic-musical profile. Our study’s findings speak to the relevance of trying to bridge the divide between studying the role of music at encoding and studying the role of music at retrieval since neither the former nor latter alone can fully explain the mechanisms underlying music-related autobiographical memories.</p>
<p>Our study also speaks to the importance of broadening the way in which music and memories are characterised away from the 2-dimensional circumplex model. We found that in the context of familiar self-selected and Billboard songs, musical characteristics may be distilled into one main component to describe the music that is listened to in the (Western) population. In a study by de Fleurian &amp; Pearce using Spotify auditory features to explore musical profiles of chill-evoking songs, a principal components analysis revealed a component similar to our E-A, characterised by high negative loadings for acousticness and instrumentalness, and high positive loadings for arousal, valence, loudness, danceability and tempo [<a href="#pone.0329072.ref016" class="usa-link" aria-describedby="pone.0329072.ref016">16</a>]. This outcome demonstrates how ecological validity of studies may be lost by forcing musical stimuli into one of four arousal-valence quadrants. Taken together, ours and De Fleurian &amp; Pearce’s musical feature analysis appear to be picking up on this collapsed dimension which demonstrates that, particularly in music that participants identify as listening to out of choice, arousal and valence tend to be correlated.</p>
<p>Further, our results add nuance to the existing body of work as they show that a particular set of low- and high-level auditory features tend to group together and consequently relate to characteristics of MEAMs in reliable ways. We also show that some individual features are especially predictive of certain MEAM characteristics (tempo predicting uniqueness and importance, for instance), while others seem to relate minimally with MEAMs (speechiness, instrumentalness, liveness, key and mode). These findings are an interesting first step in looking at low- and high-level stimulus properties of memory-evoking music, and can help in shaping hypotheses for future research.</p>
<p>Finally, our findings that self-selected MEAMs differed in many ways from experimenter cued (were more specific, vivid, positive, arousing, unique and important than experimenter-cued MEAMs) demonstrate the importance of careful consideration of methodology and music stimuli used in evoking AMs. It seems clear that self-selected music is associated with more meaningful and especially episodic AMs, as has also previously been shown in populations with Alzheimer’s Disease when comparing self-selected to researcher-selected music and silence [<a href="#pone.0329072.ref041" class="usa-link" aria-describedby="pone.0329072.ref041">41</a>]. In any case, these findings highlight the role of music’s personal significance in MEAMs, and accordingly in the building of an identity and sense of self.</p></section><section id="sec036"><h4 class="pmc_sec_title">Further directions.</h4>
<p>The present work provides new insights into potential mechanisms behind music-evoked reminiscence and how perceptual experience may drive memory of certain details and not others. However, understanding the factors that influence the degree of accuracy of MEAMs could be considered to lie at the frontier of MEAM research and has many interesting implications. The current body of work shows MEAMs to be experienced as vivid; however, with the majority of methods relying on self-report of events that occurred up to decades earlier, there is a strong need to improve our understanding of whether music contributes to actual accuracy of memories recalled or alternatively simply enhances feelings of vividness that are independent of coherence with the initial experience of the event.</p>
<p>On this topic, recent work by Jakubowski and colleagues has begun to demonstrate that music, compared to non-musical sounds, may lead to similarly vivid but less accurately recalled episodic memories. It will be interesting to examine the extent to which this observation holds in the case of long-term autobiographical memories [<a href="#pone.0329072.ref042" class="usa-link" aria-describedby="pone.0329072.ref042">42</a>]. In any case, future studies would benefit from carefully considering conditions of MEAM encoding and retrieval, with or without acoustically presented music, and how those factors may be influencing results.</p></section><section id="sec037"><h4 class="pmc_sec_title">Limitations.</h4>
<p>It is worth noting that our study, as is the case with many studies of MEAMs relying on Billboard music to cue memories, is limited by the nature of the music cues. That is, the conclusions drawn from this work rely on a set of music stimuli that (with the exception of self-selected MEAMs) are all Western, contemporary, and chart-topping songs. Whether or not the same grouping of auditory features would continue to predict the same emotional and phenomenological characteristics of MEAMs as found here (had the music stimuli represented non-Western musical cultures) will need to be investigated. It is well-evidenced that culture influences several processes that relate to autobiographical memory such as emotion knowledge, self-goals and perceptual style [<a href="#pone.0329072.ref043" class="usa-link" aria-describedby="pone.0329072.ref043">43</a>]. Thus, it follows that a lack of both non-Western stimuli and participants limits a comprehensive and fully generalisable understanding of music-related AM processes and that future work will benefit from specific attention to MEAMs cued by a variety of genres and musical traditions.</p></section></section></section><section id="sec038"><h2 class="pmc_sec_title">Conclusions</h2>
<p>Our study showed that music features of memory-evoking music predict several characteristics of AMs. As such it extends established findings that expressed emotionality of music influences the kinds of MEAMs that are retrieved and the efficiency of their retrieval. It also extends findings that auditory features of memory-evoking music may impact AM through said emotionality. Our study adds nuance to existing research in key ways. Not only does it elaborate on a wider range of possible effects that objective stimulus features of music cues can have on evoked memories, but it also highlights some of the distinct kinds of emotional AMs that music may be able to evoke. Finally, it highlights the importance of introducing novel methods to study MEAMs: ones that reflect naturalistic experiences of MEAMs and ones that can begin to tease apart how different retrieval conditions may influence the nature of memories recalled.</p></section><section id="sec039"><h2 class="pmc_sec_title">Supporting information</h2>
<section class="sm xbox font-sm" id="pone.0329072.s001"><div class="caption p">
<span>S1 Appendix. Data Cleaning and Assumptions.</span><p>In this supplementary appendix we report our complete data cleaning procedures and assumption testing for statistical models.</p>
<p>(DOCX)</p>
</div>
<div class="media p"><div class="caption">
<a href="/articles/instance/12367148/bin/pone.0329072.s001.docx" data-ga-action="click_feat_suppl" class="usa-link">pone.0329072.s001.docx</a><sup> (7MB, docx) </sup>
</div></div></section></section><section id="ack1" class="ack"><h2 class="pmc_sec_title">Acknowledgments</h2>
<p>We would like to thank Amy Belfi for providing music stimuli that were used in our experiment. Data have been made available in the following OSF link: <a href="https://osf.io/jke9w/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://osf.io/jke9w/</a> Written memory descriptions have been removed from the publicly available data to maintain anonymity of participants; however, these can be shared with researchers upon request.</p></section><section id="notes1"><h2 class="pmc_sec_title">Data Availability</h2>
<p>All data used for the purposes of this study are available from the following OSF link: <a href="https://osf.io/jke9w/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://osf.io/jke9w/</a>
</p></section><section id="funding-statement1" lang="en"><h2 class="pmc_sec_title">Funding Statement</h2>
<p>The author(s) received no specific funding for this work.</p></section><section id="ref-list1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="ref-list1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="pone.0329072.ref001">
<span class="label">1.</span><cite>Jakubowski K, Ghosh A. Music-evoked autobiographical memories in everyday life. Psychol Music. 2019;49(3):649–66. doi: 10.1177/0305735619888803</cite> [<a href="https://doi.org/10.1177/0305735619888803" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Psychol%20Music&amp;title=Music-evoked%20autobiographical%20memories%20in%20everyday%20life&amp;author=K%20Jakubowski&amp;author=A%20Ghosh&amp;volume=49&amp;issue=3&amp;publication_year=2019&amp;pages=649-66&amp;doi=10.1177/0305735619888803&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref002">
<span class="label">2.</span><cite>Fivush R. The Development of Autobiographical Memory. Annu Rev Psychol. 2011;62(1):559–82. doi: 10.1146/annurev.psych.121208.131702
</cite> [<a href="https://doi.org/10.1146/annurev.psych.121208.131702" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/20636128/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Annu%20Rev%20Psychol&amp;title=The%20Development%20of%20Autobiographical%20Memory&amp;author=R%20Fivush&amp;volume=62&amp;issue=1&amp;publication_year=2011&amp;pages=559-82&amp;pmid=20636128&amp;doi=10.1146/annurev.psych.121208.131702&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref003">
<span class="label">3.</span><cite>Moulin CJA, Carreras F, Barzykowski K. The phenomenology of autobiographical retrieval. WIRES Cognitive Sci. 2022;14(3). doi: 10.1002/wcs.1638</cite> [<a href="https://doi.org/10.1002/wcs.1638" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36458642/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=WIRES%20Cognitive%20Sci&amp;title=The%20phenomenology%20of%20autobiographical%20retrieval&amp;author=CJA%20Moulin&amp;author=F%20Carreras&amp;author=K%20Barzykowski&amp;volume=14&amp;issue=3&amp;publication_year=2022&amp;pmid=36458642&amp;doi=10.1002/wcs.1638&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref004">
<span class="label">4.</span><cite>Sow F, Dijkstra K, Janssen SMJ. Developments in the functions of autobiographical memory: An advanced review. WIRES Cognitive Sci. 2022;14(3). doi: 10.1002/wcs.1625</cite> [<a href="https://doi.org/10.1002/wcs.1625" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36165349/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=WIRES%20Cognitive%20Sci&amp;title=Developments%20in%20the%20functions%20of%20autobiographical%20memory:%20An%20advanced%20review&amp;author=F%20Sow&amp;author=K%20Dijkstra&amp;author=SMJ%20Janssen&amp;volume=14&amp;issue=3&amp;publication_year=2022&amp;pmid=36165349&amp;doi=10.1002/wcs.1625&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref005">
<span class="label">5.</span><cite>Belfi AM, Karlan B, Tranel D. Music evokes vivid autobiographical memories. Memory. 2015;24(7):979–89. doi: 10.1080/09658211.2015.1061012
</cite> [<a href="https://doi.org/10.1080/09658211.2015.1061012" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/26259098/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Memory&amp;title=Music%20evokes%20vivid%20autobiographical%20memories&amp;author=AM%20Belfi&amp;author=B%20Karlan&amp;author=D%20Tranel&amp;volume=24&amp;issue=7&amp;publication_year=2015&amp;pages=979-89&amp;pmid=26259098&amp;doi=10.1080/09658211.2015.1061012&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref006">
<span class="label">6.</span><cite>Lamont A, Loveday C. A New Framework for Understanding Memories and Preference for Music. Music Sci. 2020;3. doi: 10.1177/2059204320948315</cite> [<a href="https://doi.org/10.1177/2059204320948315" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Music%20Sci&amp;title=A%20New%20Framework%20for%20Understanding%20Memories%20and%20Preference%20for%20Music&amp;author=A%20Lamont&amp;author=C%20Loveday&amp;volume=3&amp;publication_year=2020&amp;doi=10.1177/2059204320948315&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref007">
<span class="label">7.</span><cite>Loveday C, Woy A, Conway MA. The self-defining period in autobiographical memory: Evidence from a long-running radio show. Quarterly J Experimen Psychol. 2020;73(11):1969–76. doi: 10.1177/1747021820940300</cite> [<a href="https://doi.org/10.1177/1747021820940300" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7583440/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32564690/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Quarterly%20J%20Experimen%20Psychol&amp;title=The%20self-defining%20period%20in%20autobiographical%20memory:%20Evidence%20from%20a%20long-running%20radio%20show&amp;author=C%20Loveday&amp;author=A%20Woy&amp;author=MA%20Conway&amp;volume=73&amp;issue=11&amp;publication_year=2020&amp;pages=1969-76&amp;pmid=32564690&amp;doi=10.1177/1747021820940300&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref008">
<span class="label">8.</span><cite>Jakubowski K, Eerola T. Music evokes fewer but more positive autobiographical memories than emotionally matched sound and word cues.
J Applied Res Memory Cognition. 2022;11(2):272–88. doi: 10.1016/j.jarmac.2021.09.002</cite> [<a href="https://doi.org/10.1016/j.jarmac.2021.09.002" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Applied%20Res%20Memory%20Cognition&amp;title=Music%20evokes%20fewer%20but%20more%20positive%20autobiographical%20memories%20than%20emotionally%20matched%20sound%20and%20word%20cues.&amp;author=K%20Jakubowski&amp;author=T%20Eerola&amp;volume=11&amp;issue=2&amp;publication_year=2022&amp;pages=272-88&amp;doi=10.1016/j.jarmac.2021.09.002&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref009">
<span class="label">9.</span><cite>Sheldon S, Williams K, Harrington S, Otto AR. Emotional cue effects on accessing and elaborating upon autobiographical memories. Cognition. 2020;198:104217. doi: 10.1016/j.cognition.2020.104217

</cite> [<a href="https://doi.org/10.1016/j.cognition.2020.104217" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32044616/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Cognition&amp;title=Emotional%20cue%20effects%20on%20accessing%20and%20elaborating%20upon%20autobiographical%20memories&amp;author=S%20Sheldon&amp;author=K%20Williams&amp;author=S%20Harrington&amp;author=AR%20Otto&amp;volume=198&amp;publication_year=2020&amp;pages=104217&amp;pmid=32044616&amp;doi=10.1016/j.cognition.2020.104217&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref010">
<span class="label">10.</span><cite>Sheldon S, Donahue J. More than a feeling: Emotional cues impact the access and experience of autobiographical memories. Mem Cogn. 2017;45(5):731–44. doi: 10.3758/s13421-017-0691-6</cite> [<a href="https://doi.org/10.3758/s13421-017-0691-6" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/28244010/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Mem%20Cogn&amp;title=More%20than%20a%20feeling:%20Emotional%20cues%20impact%20the%20access%20and%20experience%20of%20autobiographical%20memories&amp;author=S%20Sheldon&amp;author=J%20Donahue&amp;volume=45&amp;issue=5&amp;publication_year=2017&amp;pages=731-44&amp;pmid=28244010&amp;doi=10.3758/s13421-017-0691-6&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref011">
<span class="label">11.</span><cite>Schulkind MD, Woldorf GM. Emotional organization of autobiographical memory. Memory Cognition. 2005;33(6):1025–35. doi: 10.3758/bf03193210
</cite> [<a href="https://doi.org/10.3758/bf03193210" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/16496723/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Memory%20Cognition&amp;title=Emotional%20organization%20of%20autobiographical%20memory&amp;author=MD%20Schulkind&amp;author=GM%20Woldorf&amp;volume=33&amp;issue=6&amp;publication_year=2005&amp;pages=1025-35&amp;pmid=16496723&amp;doi=10.3758/bf03193210&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref012">
<span class="label">12.</span><cite>Jakubowski K, Francini E. Differential effects of familiarity and emotional expression of musical cues on autobiographical memory properties. Q J Experimental Psychol. 2022;76(9):2001–16. doi: 10.1177/17470218221129793

</cite> [<a href="https://doi.org/10.1177/17470218221129793" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10466948/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36121341/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Q%20J%20Experimental%20Psychol&amp;title=Differential%20effects%20of%20familiarity%20and%20emotional%20expression%20of%20musical%20cues%20on%20autobiographical%20memory%20properties&amp;author=K%20Jakubowski&amp;author=E%20Francini&amp;volume=76&amp;issue=9&amp;publication_year=2022&amp;pages=2001-16&amp;pmid=36121341&amp;doi=10.1177/17470218221129793&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref013">
<span class="label">13.</span><cite>Jakubowski K, Lee E, Bai E, Belfi AM. Individual differences in music-evoked autobiographical memories. Musicae Scientiae. 2024;29(2):195–216. doi: 10.1177/10298649241288173</cite> [<a href="https://doi.org/10.1177/10298649241288173" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Musicae%20Scientiae&amp;title=Individual%20differences%20in%20music-evoked%20autobiographical%20memories&amp;author=K%20Jakubowski&amp;author=E%20Lee&amp;author=E%20Bai&amp;author=AM%20Belfi&amp;volume=29&amp;issue=2&amp;publication_year=2024&amp;pages=195-216&amp;doi=10.1177/10298649241288173&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref014">
<span class="label">14.</span><cite>Cowen AS, Keltner D. Self-report captures 27 distinct categories of emotion bridged by continuous gradients. Proc Natl Acad Sci USA. 2017;114(38). doi: 10.1073/pnas.1702247114</cite> [<a href="https://doi.org/10.1073/pnas.1702247114" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC5617253/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/28874542/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Proc%20Natl%20Acad%20Sci%20USA&amp;title=Self-report%20captures%2027%20distinct%20categories%20of%20emotion%20bridged%20by%20continuous%20gradients&amp;author=AS%20Cowen&amp;author=D%20Keltner&amp;volume=114&amp;issue=38&amp;publication_year=2017&amp;pmid=28874542&amp;doi=10.1073/pnas.1702247114&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref015">
<span class="label">15.</span><cite>Panda R, Malheiro R, Paiva RP. Audio Features for Music Emotion Recognition: A Survey. IEEE Trans Affective Comput. 2023;14(1):68–88. doi: 10.1109/taffc.2020.3032373</cite> [<a href="https://doi.org/10.1109/taffc.2020.3032373" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans%20Affective%20Comput&amp;title=Audio%20Features%20for%20Music%20Emotion%20Recognition:%20A%20Survey&amp;author=R%20Panda&amp;author=R%20Malheiro&amp;author=RP%20Paiva&amp;volume=14&amp;issue=1&amp;publication_year=2023&amp;pages=68-88&amp;doi=10.1109/taffc.2020.3032373&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref016">
<span class="label">16.</span><cite>de Fleurian R, Pearce MT. The Relationship Between Valence and Chills in Music: A Corpus Analysis. i-Perception. 2021;12(4). doi: 10.1177/20416695211024680</cite> [<a href="https://doi.org/10.1177/20416695211024680" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8323431/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34377428/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=i-Perception&amp;title=The%20Relationship%20Between%20Valence%20and%20Chills%20in%20Music:%20A%20Corpus%20Analysis&amp;author=R%20de%20Fleurian&amp;author=MT%20Pearce&amp;volume=12&amp;issue=4&amp;publication_year=2021&amp;pmid=34377428&amp;doi=10.1177/20416695211024680&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref017">
<span class="label">17.</span><cite>Baltazar M, Västfjäll D. Songs perceived as relaxing: musical features, lyrics, and contributing mechanisms. In: Conf Proc, 2019.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Conf%20Proc&amp;title=Songs%20perceived%20as%20relaxing:%20musical%20features,%20lyrics,%20and%20contributing%20mechanisms&amp;author=M%20Baltazar&amp;author=D%20V%C3%A4stfj%C3%A4ll&amp;publication_year=2019&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref018">
<span class="label">18.</span><cite>Salakka I, Pitkäniemi A, Pentikäinen E, Mikkonen K, Saari P, Toiviainen P, et al. What makes music memorable? Relationships between acoustic musical features and music-evoked emotions and memories in older adults. PLoS ONE. 2021;16(5):e0251692. doi: 10.1371/journal.pone.0251692</cite> [<a href="https://doi.org/10.1371/journal.pone.0251692" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8121320/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33989366/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=PLoS%20ONE&amp;title=What%20makes%20music%20memorable?%20Relationships%20between%20acoustic%20musical%20features%20and%20music-evoked%20emotions%20and%20memories%20in%20older%20adults&amp;author=I%20Salakka&amp;author=A%20Pitk%C3%A4niemi&amp;author=E%20Pentik%C3%A4inen&amp;author=K%20Mikkonen&amp;author=P%20Saari&amp;volume=16&amp;issue=5&amp;publication_year=2021&amp;pmid=33989366&amp;doi=10.1371/journal.pone.0251692&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref019">
<span class="label">19.</span><cite>Prolific. London, UK; <a href="https://www.prolific.com" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.prolific.com</a>.</cite> [<a href="https://scholar.google.com/scholar_lookup?Prolific.%20London,%20UK;%20https://www.prolific.com." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref020">
<span class="label">20.</span><cite>Belfi AM, Karlan B, Tranel D. Damage to the medial prefrontal cortex impairs music-evoked autobiographical memories.
Psychomusicology: Music, Mind, and Brain. 2018;28(4):201–8. doi: 10.1037/pmu0000222</cite> [<a href="https://doi.org/10.1037/pmu0000222" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Psychomusicology:%20Music,%20Mind,%20and%20Brain&amp;title=Damage%20to%20the%20medial%20prefrontal%20cortex%20impairs%20music-evoked%20autobiographical%20memories.&amp;author=AM%20Belfi&amp;author=B%20Karlan&amp;author=D%20Tranel&amp;volume=28&amp;issue=4&amp;publication_year=2018&amp;pages=201-8&amp;doi=10.1037/pmu0000222&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref021">
<span class="label">21.</span><cite>Belfi AM, Bai E, Stroud A. Comparing Methods for Analyzing Music-Evoked Autobiographical Memories. Music Percept. 2020;37: 392–402. doi: 10.1525/mp.2020.37.5.392</cite> [<a href="https://doi.org/10.1525/mp.2020.37.5.392" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Music%20Percept&amp;title=Comparing%20Methods%20for%20Analyzing%20Music-Evoked%20Autobiographical%20Memories&amp;author=AM%20Belfi&amp;author=E%20Bai&amp;author=A%20Stroud&amp;volume=37&amp;publication_year=2020&amp;pages=392-402&amp;doi=10.1525/mp.2020.37.5.392&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref022">
<span class="label">22.</span><cite>Belfi AM, Bai E, Stroud A, Twohy R, Beadle JN. Investigating the role of involuntary retrieval in music-evoked autobiographical memories. Consciousness and Cognition. 2022;100:103305. doi: 10.1016/j.concog.2022.103305
</cite> [<a href="https://doi.org/10.1016/j.concog.2022.103305" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9059816/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35278896/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Consciousness%20and%20Cognition&amp;title=Investigating%20the%20role%20of%20involuntary%20retrieval%20in%20music-evoked%20autobiographical%20memories&amp;author=AM%20Belfi&amp;author=E%20Bai&amp;author=A%20Stroud&amp;author=R%20Twohy&amp;author=JN%20Beadle&amp;volume=100&amp;publication_year=2022&amp;pages=103305&amp;pmid=35278896&amp;doi=10.1016/j.concog.2022.103305&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref023">
<span class="label">23.</span><cite>Jakubowski K, Eerola T, Tillmann B, Perrin F, Heine L. A Cross-Sectional Study of Reminiscence Bumps for Music-Related Memories in Adulthood. Music &amp; Science. 2020;3. doi: 10.1177/2059204320965058</cite> [<a href="https://doi.org/10.1177/2059204320965058" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Music%20&amp;%20Science&amp;title=A%20Cross-Sectional%20Study%20of%20Reminiscence%20Bumps%20for%20Music-Related%20Memories%20in%20Adulthood&amp;author=K%20Jakubowski&amp;author=T%20Eerola&amp;author=B%20Tillmann&amp;author=F%20Perrin&amp;author=L%20Heine&amp;volume=3&amp;publication_year=2020&amp;doi=10.1177/2059204320965058&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref024">
<span class="label">24.</span><cite>Qualtrics. Provo, Utah, USA: Qualtrics; 2020. Available: <a href="https://www.qualtrics.com" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.qualtrics.com</a></cite>
</li>
<li id="pone.0329072.ref025">
<span class="label">25.</span><cite>Jakubowski K, Belfi AM, Eerola T. Phenomenological Differences in Music- and Television-Evoked Autobiographical Memories. Music Percept. 2021;38: 435–55. doi: 10.1525/mp.2021.38.5.435</cite> [<a href="https://doi.org/10.1525/mp.2021.38.5.435" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Music%20Percept&amp;title=Phenomenological%20Differences%20in%20Music-%20and%20Television-Evoked%20Autobiographical%20Memories&amp;author=K%20Jakubowski&amp;author=AM%20Belfi&amp;author=T%20Eerola&amp;volume=38&amp;publication_year=2021&amp;pages=435-55&amp;doi=10.1525/mp.2021.38.5.435&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref026">
<span class="label">26.</span><cite>Rentfrow PJ, Goldberg LR, Levitin DJ. The structure of musical preferences: A five-factor model.
Journal of Personal Social Psychol. 2011;100(6):1139–57. doi: 10.1037/a0022406</cite> [<a href="https://doi.org/10.1037/a0022406" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3138530/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/21299309/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Journal%20of%20Personal%20Social%20Psychol&amp;title=The%20structure%20of%20musical%20preferences:%20A%20five-factor%20model.&amp;author=PJ%20Rentfrow&amp;author=LR%20Goldberg&amp;author=DJ%20Levitin&amp;volume=100&amp;issue=6&amp;publication_year=2011&amp;pages=1139-57&amp;pmid=21299309&amp;doi=10.1037/a0022406&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref027">
<span class="label">27.</span><cite>Marks DF. Visual imagery differences in the recall of pictures. British J of Psychology. 1973;64(1):17–24. doi: 10.1111/j.2044-8295.1973.tb01322.x</cite> [<a href="https://doi.org/10.1111/j.2044-8295.1973.tb01322.x" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/4742442/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=British%20J%20of%20Psychology&amp;title=Visual%20imagery%20differences%20in%20the%20recall%20of%20pictures&amp;author=DF%20Marks&amp;volume=64&amp;issue=1&amp;publication_year=1973&amp;pages=17-24&amp;pmid=4742442&amp;doi=10.1111/j.2044-8295.1973.tb01322.x&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref028">
<span class="label">28.</span><cite>Thompson C, Parry J, Phipps D, Wolff T. R wrapper for the “Spotify” web API. <a href="https://www.rcharlie.com/spotifyr/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.rcharlie.com/spotifyr/</a>. 2022. Accessed 2024 May 17.</cite>
</li>
<li id="pone.0329072.ref029">
<span class="label">29.</span><cite>Web API Reference | Spotify for Developers. <a href="https://developer.spotify.com/documentation/web-api/reference/get-audio-features" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://developer.spotify.com/documentation/web-api/reference/get-audio-features</a>. Accessed 2024 May 17.</cite>
</li>
<li id="pone.0329072.ref030">
<span class="label">30.</span><cite>Pennebaker JW, Boyd RL, Jordan K, Blackburn K. The development and psychometric properties of LIWC2015. Austin, TX: University of Texas at Austin. 2015.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=The%20development%20and%20psychometric%20properties%20of%20LIWC2015&amp;author=JW%20Pennebaker&amp;author=RL%20Boyd&amp;author=K%20Jordan&amp;author=K%20Blackburn&amp;publication_year=2015&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref031">
<span class="label">31.</span><cite>Zator K, Katz AN. The language used in describing autobiographical memories prompted by life period visually presented verbal cues, event-specific visually presented verbal cues and short musical clips of popular music. Memory. 2016;25(6):831–44. doi: 10.1080/09658211.2016.1224353

</cite> [<a href="https://doi.org/10.1080/09658211.2016.1224353" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27580165/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Memory&amp;title=The%20language%20used%20in%20describing%20autobiographical%20memories%20prompted%20by%20life%20period%20visually%20presented%20verbal%20cues,%20event-specific%20visually%20presented%20verbal%20cues%20and%20short%20musical%20clips%20of%20popular%20music&amp;author=K%20Zator&amp;author=AN%20Katz&amp;volume=25&amp;issue=6&amp;publication_year=2016&amp;pages=831-44&amp;pmid=27580165&amp;doi=10.1080/09658211.2016.1224353&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref032">
<span class="label">32.</span><cite>Russell JA. A circumplex model of affect. J Pers Soc Psychol. 1980;39:1161.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Pers%20Soc%20Psychol&amp;title=A%20circumplex%20model%20of%20affect&amp;author=JA%20Russell&amp;volume=39&amp;publication_year=1980&amp;pages=1161&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref033">
<span class="label">33.</span><cite>Cuddy LL, Sikka R, Silveira K, Bai S, Vanstone A. Music-evoked autobiographical memories (MEAMs) in Alzheimer disease: Evidence for a positivity effect. Cogent Psychology. 2017;4(1):1277578. doi: 10.1080/23311908.2016.1277578</cite> [<a href="https://doi.org/10.1080/23311908.2016.1277578" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Cogent%20Psychology&amp;title=Music-evoked%20autobiographical%20memories%20(MEAMs)%20in%20Alzheimer%20disease:%20Evidence%20for%20a%20positivity%20effect&amp;author=LL%20Cuddy&amp;author=R%20Sikka&amp;author=K%20Silveira&amp;author=S%20Bai&amp;author=A%20Vanstone&amp;volume=4&amp;issue=1&amp;publication_year=2017&amp;pages=1277578&amp;doi=10.1080/23311908.2016.1277578&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref034">
<span class="label">34.</span><cite>Jakubowski K, Belfi AM, Kvavilashvili L, Ely A, Gill M, Herbert G. Comparing music‐ and food‐evoked autobiographical memories in young and older adults: A diary study. Br J Psychol. 2023;114(3):580–604. doi: 10.1111/bjop.12639

</cite> [<a href="https://doi.org/10.1111/bjop.12639" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10363233/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36779290/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Br%20J%20Psychol&amp;title=Comparing%20music%E2%80%90%20and%20food%E2%80%90evoked%20autobiographical%20memories%20in%20young%20and%20older%20adults:%20A%20diary%20study&amp;author=K%20Jakubowski&amp;author=AM%20Belfi&amp;author=L%20Kvavilashvili&amp;author=A%20Ely&amp;author=M%20Gill&amp;volume=114&amp;issue=3&amp;publication_year=2023&amp;pages=580-604&amp;pmid=36779290&amp;doi=10.1111/bjop.12639&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref035">
<span class="label">35.</span><cite>Janata P. The Neural Architecture of Music-Evoked Autobiographical Memories. Cerebral Cortex. 2009;19(11):2579–94. doi: 10.1093/cercor/bhp008
</cite> [<a href="https://doi.org/10.1093/cercor/bhp008" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC2758676/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/19240137/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Cerebral%20Cortex&amp;title=The%20Neural%20Architecture%20of%20Music-Evoked%20Autobiographical%20Memories&amp;author=P%20Janata&amp;volume=19&amp;issue=11&amp;publication_year=2009&amp;pages=2579-94&amp;pmid=19240137&amp;doi=10.1093/cercor/bhp008&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref036">
<span class="label">36.</span><cite>Janata P, Tomic ST, Rakowski SK. Characterisation of music-evoked autobiographical memories. Memory. 2007;15(8):845–60. doi: 10.1080/09658210701734593
</cite> [<a href="https://doi.org/10.1080/09658210701734593" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/17965981/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Memory&amp;title=Characterisation%20of%20music-evoked%20autobiographical%20memories&amp;author=P%20Janata&amp;author=ST%20Tomic&amp;author=SK%20Rakowski&amp;volume=15&amp;issue=8&amp;publication_year=2007&amp;pages=845-60&amp;pmid=17965981&amp;doi=10.1080/09658210701734593&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref037">
<span class="label">37.</span><cite>Keltner D. Toward a consensual taxonomy of emotions. Cognition and Emotion. 2019;33(1):14–9. doi: 10.1080/02699931.2019.1574397
</cite> [<a href="https://doi.org/10.1080/02699931.2019.1574397" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/30795713/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Cognition%20and%20Emotion&amp;title=Toward%20a%20consensual%20taxonomy%20of%20emotions&amp;author=D%20Keltner&amp;volume=33&amp;issue=1&amp;publication_year=2019&amp;pages=14-9&amp;pmid=30795713&amp;doi=10.1080/02699931.2019.1574397&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref038">
<span class="label">38.</span><cite>Kaiser AP, Berntsen D. The cognitive characteristics of music‐evoked autobiographical memories: Evidence from a systematic review of clinical investigations. WIRES Cognitive Science. 2022;14(3). doi: 10.1002/wcs.1627

</cite> [<a href="https://doi.org/10.1002/wcs.1627" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36223919/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=WIRES%20Cognitive%20Science&amp;title=The%20cognitive%20characteristics%20of%20music%E2%80%90evoked%20autobiographical%20memories:%20Evidence%20from%20a%20systematic%20review%20of%20clinical%20investigations&amp;author=AP%20Kaiser&amp;author=D%20Berntsen&amp;volume=14&amp;issue=3&amp;publication_year=2022&amp;pmid=36223919&amp;doi=10.1002/wcs.1627&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref039">
<span class="label">39.</span><cite>Gabrielsson A. Strong experiences with music: Music is much more than just music. OUP Oxford. 2011.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=Strong%20experiences%20with%20music:%20Music%20is%20much%20more%20than%20just%20music&amp;author=A%20Gabrielsson&amp;publication_year=2011&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref040">
<span class="label">40.</span><cite>Cady ET, Harris RJ, Knappenberger JB. Using music to cue autobiographical memories of different lifetime periods. Psychology of Music. 2007;36(2):157–77. doi: 10.1177/0305735607085010</cite> [<a href="https://doi.org/10.1177/0305735607085010" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Psychology%20of%20Music&amp;title=Using%20music%20to%20cue%20autobiographical%20memories%20of%20different%20lifetime%20periods&amp;author=ET%20Cady&amp;author=RJ%20Harris&amp;author=JB%20Knappenberger&amp;volume=36&amp;issue=2&amp;publication_year=2007&amp;pages=157-77&amp;doi=10.1177/0305735607085010&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref041">
<span class="label">41.</span><cite>El Haj M, Postal V, Allain P. Music Enhances Autobiographical Memory in Mild Alzheimer’s Disease. Educat Gerontol. 2011;38(1):30–41. doi: 10.1080/03601277.2010.515897</cite> [<a href="https://doi.org/10.1080/03601277.2010.515897" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Educat%20Gerontol&amp;title=Music%20Enhances%20Autobiographical%20Memory%20in%20Mild%20Alzheimer%E2%80%99s%20Disease&amp;author=M%20El%20Haj&amp;author=V%20Postal&amp;author=P%20Allain&amp;volume=38&amp;issue=1&amp;publication_year=2011&amp;pages=30-41&amp;doi=10.1080/03601277.2010.515897&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref042">
<span class="label">42.</span><cite>Jakubowski K, Walker D, Wang H. Music cues impact the emotionality but not richness of episodic memory retrieval. Memory. 2023;31(10):1259–68. doi: 10.1080/09658211.2023.2256055
</cite> [<a href="https://doi.org/10.1080/09658211.2023.2256055" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37679863/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Memory&amp;title=Music%20cues%20impact%20the%20emotionality%20but%20not%20richness%20of%20episodic%20memory%20retrieval&amp;author=K%20Jakubowski&amp;author=D%20Walker&amp;author=H%20Wang&amp;volume=31&amp;issue=10&amp;publication_year=2023&amp;pages=1259-68&amp;pmid=37679863&amp;doi=10.1080/09658211.2023.2256055&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329072.ref043">
<span class="label">43.</span><cite>Wang Q. Cultural Pathways and Outcomes of Autobiographical Memory Development. Child Dev Perspectives. 2021;15(3):196–202. doi: 10.1111/cdep.12423</cite> [<a href="https://doi.org/10.1111/cdep.12423" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Child%20Dev%20Perspectives&amp;title=Cultural%20Pathways%20and%20Outcomes%20of%20Autobiographical%20Memory%20Development&amp;author=Q%20Wang&amp;volume=15&amp;issue=3&amp;publication_year=2021&amp;pages=196-202&amp;doi=10.1111/cdep.12423&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adsm93_" lang="en" class="supplementary-materials"><h3 class="pmc_sec_title">Supplementary Materials</h3>
<section class="sm xbox font-sm" id="db_ds_supplementary-material1_reqid_"><div class="caption p">
<span>S1 Appendix. Data Cleaning and Assumptions.</span><p>In this supplementary appendix we report our complete data cleaning procedures and assumption testing for statistical models.</p>
<p>(DOCX)</p>
</div>
<div class="media p"><div class="caption">
<a href="/articles/instance/12367148/bin/pone.0329072.s001.docx" data-ga-action="click_feat_suppl" class="usa-link">pone.0329072.s001.docx</a><sup> (7MB, docx) </sup>
</div></div></section></section><section id="_adda93_" lang="en" class="data-availability-statement"><h3 class="pmc_sec_title">Data Availability Statement</h3>
<p>All data used for the purposes of this study are available from the following OSF link: <a href="https://osf.io/jke9w/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://osf.io/jke9w/</a>
</p></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from PLOS One are provided here courtesy of <strong>PLOS</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1371/journal.pone.0329072"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/pone.0329072.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (1.5 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12367148/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12367148/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12367148%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12367148/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12367148/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12367148/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40833929/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12367148/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40833929/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12367148/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12367148/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="tX0xad4TM1IETpcJycwmqPPAzQePoGmpWqbqjwklgksUw7P6ombglMNBoyiOncsd">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
    

    </body>
</html>
