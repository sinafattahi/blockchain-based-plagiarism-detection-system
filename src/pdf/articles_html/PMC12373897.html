
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            Micro-variations in timing and loudness affect music-evoked mental imagery - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="AE532DAA8AF209D3052DAA000562E0E8.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="scirep">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373897/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="Scientific Reports">
<meta name="citation_title" content="Micro-variations in timing and loudness affect music-evoked mental imagery">
<meta name="citation_author" content="Ceren Ayyildiz">
<meta name="citation_author_institution" content="Sydney Conservatorium of Music, The University of Sydney, Sydney, NSW Australia">
<meta name="citation_author_institution" content="The MARCS Institute for Brain, Behaviour and Development, Western Sydney University, Sydney, NSW Australia">
<meta name="citation_author" content="Andrew J Milne">
<meta name="citation_author_institution" content="The MARCS Institute for Brain, Behaviour and Development, Western Sydney University, Sydney, NSW Australia">
<meta name="citation_author" content="Muireann Irish">
<meta name="citation_author_institution" content="Brain and Mind Centre, The University of Sydney, Sydney, NSW Australia">
<meta name="citation_author_institution" content="School of Psychology, The University of Sydney, Sydney, NSW Australia">
<meta name="citation_author" content="Steffen A Herff">
<meta name="citation_author_institution" content="Sydney Conservatorium of Music, The University of Sydney, Sydney, NSW Australia">
<meta name="citation_author_institution" content="The MARCS Institute for Brain, Behaviour and Development, Western Sydney University, Sydney, NSW Australia">
<meta name="citation_publication_date" content="2025 Aug 22">
<meta name="citation_volume" content="15">
<meta name="citation_firstpage" content="30967">
<meta name="citation_doi" content="10.1038/s41598-025-12604-4">
<meta name="citation_pmid" content="40846722">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373897/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373897/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373897/pdf/41598_2025_Article_12604.pdf">
<meta name="description" content="Music can shape the vividness, sentiment, and content of directed mental imagery. Yet, the role of specific musical features in these effects remains elusive. One important aspect of human musical performances is the presence of ...">
<meta name="og:title" content="Micro-variations in timing and loudness affect music-evoked mental imagery">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="Music can shape the vividness, sentiment, and content of directed mental imagery. Yet, the role of specific musical features in these effects remains elusive. One important aspect of human musical performances is the presence of ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373897/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12373897">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1038/s41598-025-12604-4"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/41598_2025_Article_12604.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12373897%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12373897/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12373897/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373897/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-scirep.jpg" alt="Scientific Reports logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to Scientific Reports" title="Link to Scientific Reports" shape="default" href="http://www.nature.com/srep" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">Sci Rep</button></div>. 2025 Aug 22;15:30967. doi: <a href="https://doi.org/10.1038/s41598-025-12604-4" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1038/s41598-025-12604-4</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22Sci%20Rep%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sci%20Rep%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22Sci%20Rep%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22Sci%20Rep%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Micro-variations in timing and loudness affect music-evoked mental imagery</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Ayyildiz%20C%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Ceren Ayyildiz</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Ceren Ayyildiz</span></h3>
<div class="p">
<sup>1</sup>Sydney Conservatorium of Music, The University of Sydney, Sydney, NSW Australia </div>
<div class="p">
<sup>2</sup>The MARCS Institute for Brain, Behaviour and Development, Western Sydney University, Sydney, NSW Australia </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Ayyildiz%20C%22%5BAuthor%5D" class="usa-link"><span class="name western">Ceren Ayyildiz</span></a>
</div>
</div>
<sup>1,</sup><sup>2,</sup><sup>✉</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Milne%20AJ%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Andrew J Milne</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">Andrew J Milne</span></h3>
<div class="p">
<sup>2</sup>The MARCS Institute for Brain, Behaviour and Development, Western Sydney University, Sydney, NSW Australia </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Milne%20AJ%22%5BAuthor%5D" class="usa-link"><span class="name western">Andrew J Milne</span></a>
</div>
</div>
<sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Irish%20M%22%5BAuthor%5D" class="usa-link" aria-describedby="id3"><span class="name western">Muireann Irish</span></a><div hidden="hidden" id="id3">
<h3><span class="name western">Muireann Irish</span></h3>
<div class="p">
<sup>3</sup>Brain and Mind Centre, The University of Sydney, Sydney, NSW Australia </div>
<div class="p">
<sup>4</sup>School of Psychology, The University of Sydney, Sydney, NSW Australia </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Irish%20M%22%5BAuthor%5D" class="usa-link"><span class="name western">Muireann Irish</span></a>
</div>
</div>
<sup>3,</sup><sup>4</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Herff%20SA%22%5BAuthor%5D" class="usa-link" aria-describedby="id4"><span class="name western">Steffen A Herff</span></a><div hidden="hidden" id="id4">
<h3><span class="name western">Steffen A Herff</span></h3>
<div class="p">
<sup>1</sup>Sydney Conservatorium of Music, The University of Sydney, Sydney, NSW Australia </div>
<div class="p">
<sup>2</sup>The MARCS Institute for Brain, Behaviour and Development, Western Sydney University, Sydney, NSW Australia </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Herff%20SA%22%5BAuthor%5D" class="usa-link"><span class="name western">Steffen A Herff</span></a>
</div>
</div>
<sup>1,</sup><sup>2</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="Aff1">
<sup>1</sup>Sydney Conservatorium of Music, The University of Sydney, Sydney, NSW Australia </div>
<div id="Aff2">
<sup>2</sup>The MARCS Institute for Brain, Behaviour and Development, Western Sydney University, Sydney, NSW Australia </div>
<div id="Aff3">
<sup>3</sup>Brain and Mind Centre, The University of Sydney, Sydney, NSW Australia </div>
<div id="Aff4">
<sup>4</sup>School of Psychology, The University of Sydney, Sydney, NSW Australia </div>
<div class="author-notes p"><div class="fn" id="_fncrsp93pmc__">
<sup>✉</sup><p class="display-inline">Corresponding author.</p>
</div></div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2025 Feb 25; Accepted 2025 Jul 18; Collection date 2025.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© The Author(s) 2025</div>
<p><strong>Open Access</strong> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="https://creativecommons.org/licenses/by/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://creativecommons.org/licenses/by/4.0/</a>.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12373897  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40846722/" class="usa-link">40846722</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="Abs1"><h2>Abstract</h2>
<p id="Par1">Music can shape the vividness, sentiment, and content of directed mental imagery. Yet, the role of specific musical features in these effects remains elusive. One important aspect of human musical performances is the presence of micro-variations—small deviations in timbre, pitch, and timing, driven by motor and attentional processes. These variations enhance perceived “naturalness” compared to mechanical playing without such variations. Here, we investigated whether random micro-variation, as opposed to mechanical playing, affects mental imagery characteristics. One hundred participants performed a directed mental imagery task where they imagined a journey, accompanied either by drumming with micro-variation, drumming without micro-variation, or silence. Participants rated the vividness, distance and time travelled of their imagined content, alongside free-format content responses. Bayesian multilevel regression model showed that repetitive quasi-isochronous drumming enhanced mental imagery vividness, with a stronger effect observed when the drumming contained random micro-variation. Drumming with random micro-variation also increased imagined distance and time travelled compared with silence. Furthermore, individual traits in absorption, ability to imagine vividly, and level of musical training interacted with auditory conditions to further shape mental imagery characteristics. The findings have implications for the use of music to support imagery in creative, recreational, and therapeutic settings.</p>
<section id="kwd-group1" lang="en" class="kwd-group"><p><strong>Keywords:</strong> Mental imagery, Music cognition, Individual differences, Micro-timing, Musical expression, Music-evoked mental imagery</p></section><section id="kwd-group2" class="kwd-group"><p><strong>Subject terms:</strong> Psychology, Human behaviour</p></section></section><section id="Sec1"><h2 class="pmc_sec_title">Introduction</h2>
<p id="Par2">Music is an important component of human culture<sup><a href="#CR1" class="usa-link" aria-describedby="CR1">1</a>–<a href="#CR4" class="usa-link" aria-describedby="CR4">4</a></sup>. It considerably influences our mental and emotional states<sup><a href="#CR5" class="usa-link" aria-describedby="CR5">5</a></sup> and can impact dimensions such as motivation<sup><a href="#CR6" class="usa-link" aria-describedby="CR6">6</a></sup>, decisions<sup><a href="#CR7" class="usa-link" aria-describedby="CR7">7</a></sup>, and general thoughts<sup><a href="#CR8" class="usa-link" aria-describedby="CR8">8</a>,<a href="#CR9" class="usa-link" aria-describedby="CR9">9</a></sup>. These thoughts can, for example, manifest as associations<sup><a href="#CR10" class="usa-link" aria-describedby="CR10">10</a></sup>, autobiographical memories<sup><a href="#CR11" class="usa-link" aria-describedby="CR11">11</a></sup>, daydreams<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup>, and mind-wandering<sup><a href="#CR13" class="usa-link" aria-describedby="CR13">13</a></sup>. In many cases, music has the capacity to evoke mental imagery, where these thoughts are vividly imagined (i.e., perceived with clarity, detail, and intensity)<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a>–<a href="#CR16" class="usa-link" aria-describedby="CR16">16</a></sup>. Mental imagery allows individuals to simulate past and future scenarios<sup><a href="#CR17" class="usa-link" aria-describedby="CR17">17</a>,<a href="#CR18" class="usa-link" aria-describedby="CR18">18</a></sup>, adaptively interpret experiences<sup><a href="#CR19" class="usa-link" aria-describedby="CR19">19</a>,<a href="#CR20" class="usa-link" aria-describedby="CR20">20</a></sup>, and engage in effective planning<sup><a href="#CR21" class="usa-link" aria-describedby="CR21">21</a></sup> and decision-making<sup><a href="#CR20" class="usa-link" aria-describedby="CR20">20</a></sup>. Despite mental imagery’s important part in human cognition, the mechanisms by which music influences it – particularly through musical features like timing and loudness – remain largely unknown<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a>,<a href="#CR22" class="usa-link" aria-describedby="CR22">22</a></sup>. Inspired by ethnomusicological accounts, we draw on the musical features involved in rituals traditionally designed to facilitate mental imagery<sup><a href="#CR23" class="usa-link" aria-describedby="CR23">23</a>–<a href="#CR25" class="usa-link" aria-describedby="CR25">25</a></sup>. Building on prior work into the role of micro-variation in music perception<sup><a href="#CR26" class="usa-link" aria-describedby="CR26">26</a>–<a href="#CR28" class="usa-link" aria-describedby="CR28">28</a></sup>, we explore the role of small, random variations in the musical signal on vividness, emotional sentiment, and spatiotemporal aspects of music-evoked mental imagery.</p>
<p id="Par3">Mental imagery is defined as a mental simulation of a mono- or multi-modal experience in the absence of the corresponding physical stimulus, whilst being aware of the counterfactual nature of the experience<sup><a href="#CR29" class="usa-link" aria-describedby="CR29">29</a>–<a href="#CR31" class="usa-link" aria-describedby="CR31">31</a></sup>. In addition to its everyday role in cognition such as simulating future scenarios<sup><a href="#CR32" class="usa-link" aria-describedby="CR32">32</a></sup>, it is often used in recreational<sup><a href="#CR33" class="usa-link" aria-describedby="CR33">33</a></sup> and clinical applications, such as role play<sup><a href="#CR34" class="usa-link" aria-describedby="CR34">34</a></sup>, imagery exposure<sup><a href="#CR35" class="usa-link" aria-describedby="CR35">35</a></sup> and rescripting therapy<sup><a href="#CR36" class="usa-link" aria-describedby="CR36">36</a></sup>. In these contexts, mental imagery is commonly deployed in an intentional, goal-directed way, in which individual attempts to imagine specific content, guided by their own intentions or with the assistance of an external guide (e.g., a game master, officiant, or therapist)<sup><a href="#CR23" class="usa-link" aria-describedby="CR23">23</a>,<a href="#CR37" class="usa-link" aria-describedby="CR37">37</a>–<a href="#CR40" class="usa-link" aria-describedby="CR40">40</a></sup>. However, the effectiveness of mental imagery in such settings may depend on an individual’s ability to alter the vividness and emotional sentiment of the imagined content<sup><a href="#CR35" class="usa-link" aria-describedby="CR35">35</a>,<a href="#CR40" class="usa-link" aria-describedby="CR40">40</a></sup>. External stimuli capable of influencing mental imagery, such as music, are therefore of great interest in such contexts.</p>
<p id="Par4">More than 70% of participants report commonly experiencing mental imagery whilst listening to music<sup><a href="#CR41" class="usa-link" aria-describedby="CR41">41</a>–<a href="#CR43" class="usa-link" aria-describedby="CR43">43</a></sup>. Such imagery contains both realistic (e.g., images from past events and landscapes) as well as abstract (e.g., colours and shapes) imagined content<sup><a href="#CR41" class="usa-link" aria-describedby="CR41">41</a></sup>. Moreover, music influences vividness, spatial–temporal, and emotional sentiment, specifically in deliberate, goal-directed mental imagery<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a></sup>, with eye closure intensifying these effects<sup><a href="#CR44" class="usa-link" aria-describedby="CR44">44</a>,<a href="#CR45" class="usa-link" aria-describedby="CR45">45</a></sup>. Findings further suggest that music, compared to silence, evokes more extended narratives, and predicts imagery with greater affect, confidence, and social dynamics<sup><a href="#CR46" class="usa-link" aria-describedby="CR46">46</a>–<a href="#CR48" class="usa-link" aria-describedby="CR48">48</a></sup>. Yet, a deep understanding of the effects of specific musical features on mental imagery<sup><a href="#CR9" class="usa-link" aria-describedby="CR9">9</a>,<a href="#CR14" class="usa-link" aria-describedby="CR14">14</a>,<a href="#CR22" class="usa-link" aria-describedby="CR22">22</a></sup> remains unclear.</p>
<p id="Par5">Some previous studies observed that tempo can act as a mediator, where faster tempo in a directed mental imagery paradigm predicted less imagined distance travelled and time passed, as well as greater positive sentiment<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a></sup>. Similarly, decreased mind-wandering and increased meta-awareness were associated with faster tempo in an unintentional mind-wandering task<sup><a href="#CR13" class="usa-link" aria-describedby="CR13">13</a></sup>. Musical structure manipulations and thematic entrances can also manipulate the subjective experience of imagined episodes, often eliciting positive emotions and relaxation, particularly during states of absorption<sup><a href="#CR8" class="usa-link" aria-describedby="CR8">8</a>,<a href="#CR10" class="usa-link" aria-describedby="CR10">10</a>,<a href="#CR49" class="usa-link" aria-describedby="CR49">49</a></sup>. Recently, Jakubowski et al.<sup><a href="#CR9" class="usa-link" aria-describedby="CR9">9</a></sup> scrutinised how music-evoked thoughts—ranging from sensory experiences (e.g., olfactory, gustatory) to autobiographical memories and fictional stories—are influenced by musical genre, emotional expression, familiarity and liking. They found that classical and electronic music elicited more thoughts than pop or rock music, with genre, valence, and familiarity shaping the occurrence, type, and novelty of these thoughts. It has also been demonstrated that systematic changes in musical parameters, such as pitch contour, dynamics, and tonal stability, can elicit distinct spatial and motion-related imagery, showing the potential role of cross-modal correspondences<sup><a href="#CR50" class="usa-link" aria-describedby="CR50">50</a>–<a href="#CR53" class="usa-link" aria-describedby="CR53">53</a></sup>. These findings illustrate the potential of specific musical features to affect mental imagery. Crucially, however, much of the existing research has focused on fully orchestrated Western musical stimuli (e.g<sup><a href="#CR13" class="usa-link" aria-describedby="CR13">13</a>,<a href="#CR14" class="usa-link" aria-describedby="CR14">14</a>,<a href="#CR54" class="usa-link" aria-describedby="CR54">54</a></sup>.,). This is important to consider, as music-evoked mental imagery may vary between individuals depending on cultural background<sup><a href="#CR3" class="usa-link" aria-describedby="CR3">3</a></sup>, musical listening habits<sup><a href="#CR55" class="usa-link" aria-describedby="CR55">55</a></sup>, or musical expertise<sup><a href="#CR56" class="usa-link" aria-describedby="CR56">56</a></sup>. For example, imagined content is more similar within cultures than between<sup><a href="#CR3" class="usa-link" aria-describedby="CR3">3</a></sup>, and prevalence of music-evoked mental imagery rises during absorbed music listening<sup><a href="#CR57" class="usa-link" aria-describedby="CR57">57</a></sup>. In addition, fully orchestrated music renders isolating the effects of individual features difficult, highlighting the need for studies to systematically explore and vary specific musical features to better understand their effects on mental imagery.</p>
<p id="Par6">A bottom-up exploration of features implicated in music-evoked mental imagery should consider existing music that has already been used to support processes akin to mental imagery. For example, multiple cultures or traditions, such as Mandé culture of West Africa, deploy ritual repetitive drumming to support catharsis (e.g., ritual participants releasing negative emotions)<sup><a href="#CR23" class="usa-link" aria-describedby="CR23">23</a>,<a href="#CR58" class="usa-link" aria-describedby="CR58">58</a></sup>. The ‘healer’ in these rituals guides participants to evoke various forms of mental images, such as memories and scenarios, which may in turn influence their emotional states, while listening to or participating in musical activity<sup><a href="#CR25" class="usa-link" aria-describedby="CR25">25</a></sup>. This approach is somewhat similar to modern imagery-based therapies<sup><a href="#CR23" class="usa-link" aria-describedby="CR23">23</a></sup>, such as Imagery Rescripting and Imaginal Exposure<sup><a href="#CR35" class="usa-link" aria-describedby="CR35">35</a>,<a href="#CR39" class="usa-link" aria-describedby="CR39">39</a>,<a href="#CR59" class="usa-link" aria-describedby="CR59">59</a></sup>. Ethnomusicologists studying these types of traditional ritual music emphasise that they often focus on repetitive quasi-isochronous patterns—beats with nearly equal, but not perfectly uniform, intervals between sound onsets<sup><a href="#CR1" class="usa-link" aria-describedby="CR1">1</a>,<a href="#CR58" class="usa-link" aria-describedby="CR58">58</a></sup>—played with expressive micro-variations rather than mechanically identical rhythms<sup><a href="#CR28" class="usa-link" aria-describedby="CR28">28</a>,<a href="#CR58" class="usa-link" aria-describedby="CR58">58</a>,<a href="#CR60" class="usa-link" aria-describedby="CR60">60</a>,<a href="#CR61" class="usa-link" aria-describedby="CR61">61</a></sup>. Mechanical here refers to a theoretical performance style whereby each drum strike is perfectly identical to the previous one in terms of timing, velocity, and strike location, without any small intentional or unintentional variations between strikes and timbre<sup><a href="#CR26" class="usa-link" aria-describedby="CR26">26</a>,<a href="#CR62" class="usa-link" aria-describedby="CR62">62</a>,<a href="#CR63" class="usa-link" aria-describedby="CR63">63</a></sup>. In contrast, expressive, deliberate micro-variations in timing (typically less than 50 ms)<sup><a href="#CR60" class="usa-link" aria-describedby="CR60">60</a></sup>, dynamics, and articulation in performance can convey emotion, expression, and interpretation<sup><a href="#CR64" class="usa-link" aria-describedby="CR64">64</a></sup>, and have been shown to support synchronisation of sensory and motor activities with rhythmic cues<sup><a href="#CR65" class="usa-link" aria-describedby="CR65">65</a></sup>. This provides a foundation for further exploration of whether and how micro-variations can influence higher-order processes like mental imagery likely due to their emotionally evocative nature, consistent with findings that emotion and visual imagery are closely related<sup><a href="#CR22" class="usa-link" aria-describedby="CR22">22</a></sup>.</p>
<p id="Par7">Regarding micro-variations in timing and loudness, timing variations as small as 15 ms, can affect listeners’ aesthetic preferences (e.g., liking<sup><a href="#CR66" class="usa-link" aria-describedby="CR66">66</a></sup>) and musical traditions of expressive micro-variations can communicate group cohesion and cultural origin through them<sup><a href="#CR1" class="usa-link" aria-describedby="CR1">1</a>,<a href="#CR27" class="usa-link" aria-describedby="CR27">27</a>,<a href="#CR28" class="usa-link" aria-describedby="CR28">28</a>,<a href="#CR67" class="usa-link" aria-describedby="CR67">67</a></sup>. Similarly, studies have shown that small-scale variability in drum strike velocity, such as variations influenced by strike force and starting height, can enhance expressive depth and variability in drumming<sup><a href="#CR68" class="usa-link" aria-describedby="CR68">68</a></sup>, with expert drummers routinely demonstrating superior precision and control in their strike velocity variability compared to amateurs<sup><a href="#CR69" class="usa-link" aria-describedby="CR69">69</a>,<a href="#CR70" class="usa-link" aria-describedby="CR70">70</a></sup><em>.</em> Besides intentional, expressive micro-variations, musical performances by humans also contain random micro-variations, which arise from the intrinsic randomness involved in movement generation and attention<sup><a href="#CR71" class="usa-link" aria-describedby="CR71">71</a>,<a href="#CR72" class="usa-link" aria-describedby="CR72">72</a></sup>. These variations are not deliberately controlled by the performer, nor are they entirely accidental; instead, they emerge naturally and are coupled with physiological constraints such as muscle fatigue or refractory periods<sup><a href="#CR73" class="usa-link" aria-describedby="CR73">73</a></sup>, and external noise sources<sup><a href="#CR74" class="usa-link" aria-describedby="CR74">74</a></sup>. Whilst it is easy to dismiss unintentional random micro-variation as an undesired source of error in performance, these human random micro-variations between strikes and timbre play an important role in contributing to naturalness (i.e., lifelike, organic, and authentic, rather than mechanical) and human-sounding performances. Indeed, a study demonstrated that listeners robustly prefer these musical rhythms with human-like long-range correlated fluctuations over perfectly timed beats<sup><a href="#CR75" class="usa-link" aria-describedby="CR75">75</a></sup>.</p>
<p id="Par8">The evidence to date suggests that random micro-variations significantly influence cognitive and perceptual processes<sup><a href="#CR60" class="usa-link" aria-describedby="CR60">60</a>,<a href="#CR67" class="usa-link" aria-describedby="CR67">67</a>,<a href="#CR76" class="usa-link" aria-describedby="CR76">76</a>,<a href="#CR77" class="usa-link" aria-describedby="CR77">77</a></sup>; however, their effect on mental imagery is unknown. The objective of this study was to understand how random micro-variation, as opposed to mechanical playing, affects mental imagery characteristics in a directed mental imagery paradigm<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a></sup>. Participants performed a mental imagery task with their eyes closed in which they were instructed to imagine a continuation of a journey prompted by a visual inducer. After each trial, participants completed questions regarding vividness, distance travelled and time passed of the imagined content, and provided an open-text response describing their experience. We additionally collected data on individuals’ proneness to imaginative and altered states (absorption), their ability to imagine vividly, and level of musical training, in order to control for these factors when analysing the results. Whilst performing the task, participants either listened to silence, mechanical drum patterns, or drum patterns containing small random micro-variations. We used quasi-isochronous drum patterns played at 240 beats per minute (BPM), which is similar to the shamanic ritual repetitive drumming observed by several interdisciplinary researchers<sup><a href="#CR78" class="usa-link" aria-describedby="CR78">78</a>–<a href="#CR83" class="usa-link" aria-describedby="CR83">83</a></sup>. Each of our 100 participants listened to 7 stimuli in a fully random order: the quasi-isochronous drum pattern in the three timbres (i.e., instruments), each once mechanical and once with micro-variations. To avoid simply replicating music production effects such as the ‘machine gun’ effect<sup><a href="#CR84" class="usa-link" aria-describedby="CR84">84</a></sup>, the auditory stimuli were generated using physical models of drums<sup><a href="#CR85" class="usa-link" aria-describedby="CR85">85</a></sup> that are struck with simulated strikes. This approach inherently introduces a small amount of randomisation to the timbre, even in the mechanical condition, preventing the repetitive and unnatural sound typical of the machine-gun effect. A physical drum model, rather than a sample-based sequencer, has the advantage that, when modelling mechanically identical strikes, the resulting sounds differ slightly with each strike due to the ongoing and complex vibrations of the drum from previous strikes. In the micro-variation condition, additional minor random variations in terms of timing, strike velocity, and drum-hit location were applied to the strikes, resulting in a more “human-like” performance.</p>
<p id="Par9">To summarise, we investigate the influence of micro-variations on directed mental imagery. Based on previous research and theoretical frameworks, we test the following hypotheses:</p>
<ol class="list" style="list-style-type:decimal">
<li><p id="Par10">Random micro-variations induce more imagined vividness than mechanical playing and silence (supported)</p></li>
<li><p id="Par11">Random micro-variations induce more imagined positive emotional sentiment than mechanical playing and silence (not supported)</p></li>
<li><p id="Par12">Auditory conditions induce greater imagined travelled distance and time than silence (supported for imagined distance, partially supported for imagined time)</p></li>
<li><p id="Par13">Interactions between conditions and individual differences in imagery characteristics were investigated in an exploratory fashion.</p></li>
</ol></section><section id="Sec2"><h2 class="pmc_sec_title">Results</h2>
<section id="Sec3"><h3 class="pmc_sec_title">Random micro-variations induce more vivid imagery than silence and mechanical playing</h3>
<p id="Par14">Participants used the entire range of the 100-point vividness scale, with responses spanning from 0 to 100 (<em>M</em> = 51.42, <em>SD</em> = 27.65). Bayesian multilevel regression model predicted standardised vividness based on auditory condition (factor with three levels: Silence, Mechanical, and Random Micro-Variation) as a predictor, whilst controlling for participant and trial number (more details of the model in the Method section). As shown in Fig. <a href="#Fig1" class="usa-link">1</a>a,b, we observed strong evidence (<em>Odds</em> ≥ 19 for one-sided hypothesis tests<sup><a href="#CR86" class="usa-link" aria-describedby="CR86">86</a></sup>) that playing drum patterns with random micro-variation increased vividness of mental imagery compared to silence (<em>β</em> = 0.15, <em>EEβ</em> = 0.07, <em>Odds</em> (<em>β</em> &gt; 0) = 63.86*, <em>Post.Prob</em> = 0.98) as well as mechanical playing (<em>β</em> = 0.11, <em>EEβ</em> = 0.05, <em>Odds</em> (<em>β</em> &gt; 0) = 100.69*, <em>Post.Prob</em> = 0.99). There was no compelling difference in vividness between silence and mechanical playing (<em>Odds</em> = 2.36, <em>Post.Prob</em> = 0.70).</p>
<figure class="fig xbox font-sm" id="Fig1"><h4 class="obj_head">Fig. 1.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373897_41598_2025_12604_Fig1_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/6f3f/12373897/90cabc51ead5/41598_2025_12604_Fig1_HTML.jpg" loading="lazy" id="d33e747" height="492" width="669" alt="Fig. 1"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Posterior predictions of standardised Vividness and Sentiment in the Silence, Mechanical, and Micro-Variation (MV) conditions. The left column (<strong>a, c</strong>) shows the model’s posterior predictions of (<strong>a</strong>) vividness and (<strong>c</strong>) sentiment for the conditions, and the right column (<strong>b, d</strong>) shows predicted differences of (<strong>b</strong>) vividness and (<strong>d</strong>) sentiment between the conditions. For predicted differences, dark purple indicates strong evidence, whereas light purple indicates no strong evidence. “n.e.” corresponds to “no strong evidence”. Error bars show 95% CI. <em>Odds</em> ≥ 19 are strong evidence for one-sided hypothesis tests, indicated above the parentheses with an evidence ratio and marked with an asterisk (*).</p></figcaption></figure></section><section id="Sec4"><h3 class="pmc_sec_title">Random micro-variations show no strong evidence on imagined emotional sentiment compared to silence, but weak to moderate evidence compared to mechanical playing</h3>
<p id="Par15">Imagined sentiment, referring to the emotional tone attributed to participants’ mental imagery episodes, was obtained from the open-text responses describing their imagery. NTLK<sup><a href="#CR87" class="usa-link" aria-describedby="CR87">87</a></sup> and VADER<sup><a href="#CR88" class="usa-link" aria-describedby="CR88">88</a></sup> were used to analyse sentiment by giving numerical scores from negative to positive for each description. They estimate emotional valence and intensity on a continuous scale, with higher values reflecting more positive sentiment. We observed no evidence that patterns with random micro-variation increased sentiment compared to the silence control (<em>Odds</em> = 3.31, <em>Post.Prob</em> = 0.77) and weak to moderate of an increase compared to the mechanical style (<em>β</em> = 0.11, <em>EEβ</em> = 0.08, <em>Odds</em> (<em>β</em> &gt; 0) = 11.49, <em>Post.Prob</em> = 0.92). Additionally, we observed no strong evidence for a predictive relationship between silence and mechanical conditions (<em>Odds</em> = 0.03, <em>Post.Prob</em> = 0.40; Fig. <a href="#Fig1" class="usa-link">1</a>c,d).</p></section><section id="Sec5"><h3 class="pmc_sec_title">Random micro-variations show very strong evidence on imagined distance travelled compared to silence, and weak to moderate evidence compared to mechanical playing</h3>
<p id="Par16">We observed very strong evidence that in both drumming conditions, participants imagined greater distances travelled compared to the silence condition (random micro-variations vs silence: <em>β</em> = 0.37, <em>EEβ</em> = 0.09, <em>Odds</em> (<em>β</em> &gt; 0) &gt; 9999*, <em>Post.Prob</em> = 1.00, mechanical vs silence: <em>β</em> = 0.26, <em>EEβ</em> = 0.09, <em>Odds</em> (<em>β</em> &gt; 0) = 557.14*, <em>Post.Prob</em> = 1.00). There was only weak to moderate evidence for a difference between random micro-variation and mechanical condition (<em>Odds</em> = 16.43, <em>Post.Prob</em> = 0.94). See Fig. <a href="#Fig2" class="usa-link">2</a>b for an illustration of posterior predictions of these findings.</p>
<figure class="fig xbox font-sm" id="Fig2"><h4 class="obj_head">Fig. 2.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373897_41598_2025_12604_Fig2_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/6f3f/12373897/f8114f638f54/41598_2025_12604_Fig2_HTML.jpg" loading="lazy" id="d33e853" height="277" width="669" alt="Fig. 2"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Posterior predictions of the standardised and log-transformed Imagined Time and Distance in Silence, Mechanical, Micro-Variation (MV). The left column (<strong>a</strong>) shows the model’s posterior predictions of imagined distance, and the right column (<strong>b</strong>) column shows the model’s posterior predictions of imagined time for the conditions. Error bars show 95% CI. “n.e.” corresponds to “no strong evidence”. <em>Odds</em> ≥ 19 are deemed strong evidence for one-sided hypothesis tests, indicated above the parentheses with an evidence ratio and marked with an asterisk (*).</p></figcaption></figure></section><section id="Sec6"><h3 class="pmc_sec_title">Random micro-variations predict longer imagined time travelled than silence, but show no strong evidence compared to mechanical playing</h3>
<p id="Par17">Compared to the silence condition, we observed strong evidence that the imagined time travelled was greater in the random micro-variation condition (<em>β</em> = 0.15, <em>EEβ</em> = 0.08, <em>Odds</em> (<em>β</em> &gt; 0) = 34.98*, <em>Post.Prob</em> = 0.97). However, there were no compelling differences between mechanical and silence (<em>Odds</em> = 4.69, <em>Post.Prob</em> = 0.82) as well as micro-variation and mechanical conditions (<em>Odds</em> = 11.42, <em>Post.Prob</em> = 0.92). See Fig. <a href="#Fig2" class="usa-link">2</a>a for an illustration of posterior predictions of these findings.</p></section><section id="Sec7"><h3 class="pmc_sec_title">Exploring individual differences in mental imagery across conditions</h3>
<p id="Par18">We also analysed the effects of absorption tendencies (measured by the “prone to imaginative and altered states” subscale of Tellegen Absorption Scale (TAS)<sup><a href="#CR89" class="usa-link" aria-describedby="CR89">89</a></sup>), vividness of visual imagery tendencies (measured by Vividness of Visual Imagery Questionnaire (VVIQ)<sup><a href="#CR90" class="usa-link" aria-describedby="CR90">90</a></sup>), and Musical Training (measured by the “musical training” (MT) subscale of Goldsmiths Musical Sophistication Index (GMSI)<sup><a href="#CR91" class="usa-link" aria-describedby="CR91">91</a></sup>) with each condition, using one-sided hypothesis tests (<em>Odds</em> ≥ 19 for strong evidence)<sup><a href="#CR86" class="usa-link" aria-describedby="CR86">86</a></sup>. High (<em>Mean</em> + 1<em>SD</em>) and low (<em>Mean </em>- 1<em>SD</em>) scores were defined as one standard deviation above or below the mean. Additionally, we examined their interactions with the silence, mechanical and random micro-variation conditions, on vividness, sentiment (VADER), imagined distance, and imagined time, applying two-sided hypothesis tests (<em>Odds</em> ≥ 39 for strong evidence)<sup><a href="#CR92" class="usa-link" aria-describedby="CR92">92</a></sup>.</p>
<section id="Sec8"><h4 class="pmc_sec_title">Vividness</h4>
<p id="Par19"><strong>TAS </strong>There was strong evidence that higher trait level absorption scores on the TAS in general are associated with increased vividness of the imagined content (<em>β</em> = 0.43, <em>EEβ</em> = 0.20, <em>Odds</em> (<em>β</em> &gt; 0) = 63.00*, <em>Post.Prob</em> = 0.98). However, when broken down by condition, this effect was only observed in the random micro-variation (<em>β</em> = 0.49, <em>SE</em> = 0.21, <em>Odds</em> (<em>β</em> &gt; 0) = 95.00*, <em>Post.Prob</em> = 0.99) and mechanical conditions (<em>β</em> = 0.42, <em>SE</em> = 0.21, <em>Odds</em> (β &gt; 0) = 44.11*, <em>Post.Prob</em> = 0.98), but not in the silence condition (<em>Odds</em> = 7.43, <em>Post.Prob</em> = 0.88). When compared directly with the silence condition, only the random micro-variation (<em>β</em> = 0.25, <em>SE</em> = 0.11, Odds (<em>β</em> &gt; 0) = 89.91*, <em>Post.Prob</em> = 0.99), but not the mechanical condition (Odds = 4.85, <em>Post.Prob</em> = 0.83), yielded compelling evidence for a greater effect of individuals with higher absorption tendencies on vividness. There was no strong difference between the random micro-variation and mechanical conditions (Odds = 36.27, <em>Post.Prob</em> = 0.97) in individuals with higher absorption tendencies on vividness. For individuals with lower absorption tendencies, vividness scores were consistently and comparably low across all conditions, with no evidence of a strong difference between any specific condition (all <em>Odds</em> ≤ 5.52, all <em>Post.Prob</em> ≤ 0.85, see Fig. <a href="#Fig3" class="usa-link">3</a>a).</p>
<figure class="fig xbox font-sm" id="Fig3"><h5 class="obj_head">Fig. 3.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373897_41598_2025_12604_Fig3_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/6f3f/12373897/d469712b8893/41598_2025_12604_Fig3_HTML.jpg" loading="lazy" id="d33e1068" height="426" width="669" alt="Fig. 3"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Posterior predictions of the Standardised Vividness in Silence, Mechanical, Micro-Variation (MV), and whether the predictions differ based on Tellegen Absorption Scale (TAS, in <em>SD</em>), and Vividness of Visual Imagery Questionnaire (VVIQ, in <em>SD</em>) in two levels [high (TAS = <em>Mean</em> + 1<em>SD</em>; VVIQ = <em>Mean</em> + 1<em>SD</em>) and low (TAS = <em>Mean </em>- 1<em>SD</em>; VVIQ = <em>Mean </em>- 1<em>SD</em>)]. The left column shows the model’s posterior predictions of Vividness by (<strong>a</strong>) TAS level, and the right column shows the model’s posterior predictions of Vividness by (<strong>b</strong>) VVIQ level. Darker grey indicates high scale level, and lighter grey indicates low scale level. Error bars show 95% CI. “n.e.” corresponds to “no strong evidence”. <em>Odds</em> ≥ 19 are deemed strong evidence for one-sided hypothesis tests and <em>Odds</em> ≥ 39 are deemed strong evidence for two-sided hypothesis tests, indicated above the parentheses with an evidence ratio and marked with an asterisk (*).</p></figcaption></figure></section><section id="Sec9"><h4 class="pmc_sec_title">VVIQ</h4>
<p id="Par20">There was also strong evidence that higher vivid imagery tendencies on VVIQ are associated with increased vividness of the imagined content (<em>β</em> = 0.34, <em>EEβ</em> = 0.19, <em>Odds</em> (<em>β</em> &gt; 0) = 22.98*, <em>Post.Prob</em> = 0.96). Those with only lower vivid imagery tendencies showed a stronger effect on vividness in the random micro-variation compared to the silence condition (<em>β</em> = 0.22, <em>EEβ</em> = 0.11, <em>Odds</em> (<em>β</em> &gt; 0) = 55.21*, <em>Post.Prob</em> = 0.98, see Fig. <a href="#Fig3" class="usa-link">3</a>b).</p></section><section id="Sec10"><h4 class="pmc_sec_title">MT</h4>
<p id="Par21">We observed no strong evidence that musical training scores influenced vividness across conditions (all <em>Odds</em> ≤ 23.17, all <em>Post.Prob</em> ≤ 0.96).</p></section><section id="Sec11"><h4 class="pmc_sec_title">Emotional sentiment</h4>
<p id="Par22"><strong><em>TAS. VVIQ. MT.</em></strong> We observed no strong evidence that absorption tendencies (all <em>Odds</em> ≤ 7.04, all <em>Post.Prob</em> ≤ 0.88), vividness of visual imagery tendencies (all <em>Odds</em> ≤ 6.62, all <em>Post.Prob</em> ≤ 0.87), and musical training scores (all <em>Odds</em> ≤ 6.72, all <em>Post.Prob</em> ≤ 0.87) influenced sentiment across conditions.</p></section><section id="Sec12"><h4 class="pmc_sec_title">Imagined distance</h4>
<section id="Sec13"><h5 class="pmc_sec_title">TAS</h5>
<p id="Par23">There was no strong evidence that higher absorption scores on the TAS were associated with heightened imagined distance on the experimental task (<em>Odds</em> = 0.47, <em>Post.Prob</em> = 0.32). Although higher absorption individuals demonstrated no strong evidence across conditions (<em>Odds</em> = 26.49, <em>Post.Prob</em> = 0.96), individuals with lower absorption tendencies were associated with stronger effects on imagined distance in the random micro-variation (<em>β</em> = 0.47, <em>SE</em> = 0.14, <em>Odds</em> (<em>β</em> &gt; 0) = 1499.00*, <em>Post.Prob</em> = 1.00) and mechanical style (<em>β</em> = 0.36, <em>SE</em> = 0.14, <em>Odds</em> (<em>β</em> &gt; 0) = 153.84*, <em>Post.Prob</em> = 0.99), both relative to silence (Fig. <a href="#Fig4" class="usa-link">4</a>a).</p>
<figure class="fig xbox font-sm" id="Fig4"><h6 class="obj_head">Fig. 4.</h6>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373897_41598_2025_12604_Fig4_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/6f3f/12373897/745f5072e941/41598_2025_12604_Fig4_HTML.jpg" loading="lazy" id="d33e1246" height="426" width="669" alt="Fig. 4"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Posterior predictions of the standardised and log-transformed Imagined Distance in Silence, Mechanical, Micro-Variation (MV), and whether the predictions differ based on Tellegen Absorption Scale (TAS, in <em>SD</em>), and Vividness of Visual Imagery Questionnaire (VVIQ, in <em>SD</em>) in two levels [high (TAS = <em>Mean</em> + 1<em>SD</em>; VVIQ = <em>Mean</em> + 1<em>SD</em>) and low (TAS = <em>Mean </em>- 1<em>SD</em>; VVIQ = <em>Mean </em>- 1<em>SD</em>)]. The left column shows the model’s posterior predictions of Imagined Distance by (<strong>a</strong>) TAS level, and the right column shows the model’s posterior predictions of Imagined Distance by (<strong>b</strong>) VVIQ level. Darker grey indicates high scale level, and lighter grey indicates low scale level. Error bars show 95% CI. “n.e.” corresponds to “no strong evidence”. <em>Odds</em> ≥ 19 are deemed strong evidence for one-sided hypothesis tests and <em>Odds</em> ≥ 39 are deemed strong evidence for two-sided hypothesis tests, indicated above the parentheses with an evidence ratio and marked with an asterisk (*).</p></figcaption></figure></section><section id="Sec14"><h5 class="pmc_sec_title">VVIQ</h5>
<p id="Par24">Overall, individuals with more vivid visual imagery scores on the VVIQ did not provide strong evidence for greater levels of imagined distance on the experimental task (<em>β</em> = 0.29, <em>SE</em> = 0.17, <em>Odds</em> (<em>β</em> &gt; 0) = 23.49, <em>Post.Prob</em> = 0.96). Yet, when split by condition, a relationship was observed only in the random micro-variation (<em>β</em> = 0.48, <em>SE</em> = 0.19, <em>Odds</em> (<em>β</em> &gt; 0) = 149.94*, <em>Post.Prob</em> = 0.99), but not in the mechanical (<em>Odds</em> = 5.02, <em>Post.Prob</em> = 0.83) nor silence (<em>Odds</em> (<em>β</em> &gt; 0) = 1.68, <em>Post.Prob</em> = 0.63) conditions. When micro-variation condition was directly compared with the mechanical condition, higher vivid imagery tendencies were associated with greater imagined distance travelled (<em>β</em> = 0.25, <em>SE</em> = 0.10, <em>Odds</em> (<em>β</em> &gt; 0) = 133.08*, <em>Post.Prob</em> = 0.99). A stronger effect was observed for individuals with higher vivid imagery tendencies on imagined distance in both random micro-variation (<em>β</em> = 0.57, <em>SE</em> = 0.14, <em>Odds</em> (<em>β</em> &gt; 0) &gt; 9999*, <em>Post.Prob</em> = 1.00) and mechanical style (<em>β</em> = 0.32, <em>SE</em> = 0.14, <em>Odds</em> (<em>β</em> &gt; 0) = 74.47*, <em>Post.Prob</em> = 0.99) conditions compared to the silence condition. There was no strong evidence for lower vivid imagery tendencies across conditions (all <em>Odds</em> ≤ 12.99, all <em>Post.Prob</em> ≤ 0.93; Fig. <a href="#Fig4" class="usa-link">4</a>b).</p></section><section id="Sec15"><h5 class="pmc_sec_title">MT</h5>
<p id="Par25">There was no strong evidence that higher musical training scores were associated with greater imagined distance on the task (<em>Odds</em> = 1.36, <em>Post.Prob</em> = 0.58). Higher levels of musical training were associated with stronger effects on imagined distance in the random micro-variation (<em>β</em> = 0.52, <em>SE</em> = 0.13, <em>Odds</em> (<em>β</em> &gt; 0) &gt; 9999*, <em>Post.Prob</em> = 1.00) and mechanical style (<em>β</em> = 0.38, <em>SE</em> = 0.13, <em>Odds</em> (<em>β</em> &gt; 0) = 599.00*, <em>Post.Prob</em> = 1.00) compared to silence. However, there were no compelling differences between random micro-variation and mechanical conditions (<em>Odds</em> = 12.61, <em>Post.Prob</em> = 0.93) on imagined distance. There was also no strong evidence for lower musical training scores across conditions (<em>Odds</em> = 18.59, <em>Post.Prob</em> = 0.93; Fig. <a href="#Fig5" class="usa-link">5</a>a).</p>
<figure class="fig xbox font-sm" id="Fig5"><h6 class="obj_head">Fig. 5.</h6>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373897_41598_2025_12604_Fig5_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/6f3f/12373897/c7c52187f1bf/41598_2025_12604_Fig5_HTML.jpg" loading="lazy" id="d33e1448" height="435" width="669" alt="Fig. 5"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig5/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Posterior predictions of the standardised and log-transformed Imagined Distance and Time in Silence, Mechanical, Micro-Variation (MV), and whether the predictions differ based on Musical Training (MT in GMSI, in <em>SD</em>) scores in two levels [high (GMSI = <em>Mean</em> + 1<em>SD</em>) and low (MT = <em>Mean </em>- 1<em>SD</em>)]. The left column shows the model’s posterior predictions of (<strong>a</strong>) Imagined Distance by MT level, and the right column shows the model’s posterior predictions of (<strong>b</strong>) Imagined Time by MT level. Darker grey indicates high scale level, and lighter grey indicates low scale level. Error bars show 95% CI. “n.e.” corresponds to “no strong evidence”. <em>Odds</em> ≥ 19 are deemed strong evidence for one-sided hypothesis tests and <em>Odds</em> ≥ 39 are deemed strong evidence for two-sided hypothesis tests, indicated above the parentheses with an evidence ratio and marked with an asterisk (*).</p></figcaption></figure></section></section><section id="Sec16"><h4 class="pmc_sec_title">Imagined time</h4>
<section id="Sec17"><h5 class="pmc_sec_title">TAS. VVIQ</h5>
<p id="Par26">We found no strong evidence that absorption tendencies (all <em>Odds</em> ≤ 26.30, all <em>Post.Prob</em> ≤ 0.96) and vividness of visual imagery tendencies (all <em>Odds</em> ≤ 15.42, all <em>Post.Prob</em> ≤ 0.94) influenced imagined time across conditions.</p></section><section id="Sec18"><h5 class="pmc_sec_title">MT</h5>
<p id="Par27">There was no compelling evidence to suggest that overall higher musical training scores are generally associated with increased imagined time (<em>Odds</em> = 1.74, <em>Post.Prob</em> = 0.64). However, when split by conditions, individuals with higher musical training in the random micro-variation (<em>β</em> = 0.29, <em>SE</em> = 0.11, <em>Odds</em> (<em>β</em> &gt; 0) = 175.47*, <em>Post.Prob</em> = 0.99) and mechanical (<em>β</em> = 0.24, <em>SE</em> = 0.11, <em>Odds</em> (<em>β</em> &gt; 0) = 55.60*, <em>Post.Prob</em> = 0.98) conditions showed a longer imagined time travelled compared to silence. Meanwhile, there was no compelling difference between random micro-variation and mechanical style (<em>Odds</em> = 2.69, <em>Post.Prob</em> = 0.73). There was also no strong effect for individuals with lower musical training on imagined time across all conditions (all <em>Odds</em> ≤ 10.19, all <em>Post.Prob</em> ≤ 0.91; Fig. <a href="#Fig5" class="usa-link">5</a>b). Furthermore, the difference in imagined time between the silence and mechanical conditions increased with increasing musical training (<em>β</em> = 0.33, <em>SE</em> = 0.16, <em>Odds</em> (<em>β</em> &lt; 0) = 44.11*, <em>Post.Prob</em> = 0.98).</p></section></section></section></section><section id="Sec19"><h2 class="pmc_sec_title">Discussion</h2>
<p id="Par28">This study investigated how random micro-variations, a core component of human music performance, in quasi-isochronous repetitive drumming patterns affect the vividness, emotional sentiment, as well as imagined distance and time travelled of the imagined content in concurrent directed mental imagery. Our findings reveal that quasi-isochronous drumming with random micro-variation increases vividness of imagined content compared to silence. There is compelling evidence that drumming with micro-variation enhances vividness of imagined content more than purely mechanical drumming. Furthermore, random micro-variations – but not mechanical performances – also induce longer imagined time of travel than silence, and both random micro-variation and mechanical conditions lead to greater imagined distance travelled than silence. We also found that individual differences, such as tendencies toward absorption and imagining vividly, and musical training, interact with drumming to shape mental imagery. The pattern of results, as well as their potential recreational, aesthetic, and clinical implications and future directions are discussed in the following.</p>
<p id="Par29">Our research demonstrates that auditory stimulation can influence the vividness of mental imagery compared to silence, aligning with previous reports<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a>,<a href="#CR44" class="usa-link" aria-describedby="CR44">44</a>,<a href="#CR46" class="usa-link" aria-describedby="CR46">46</a>,<a href="#CR48" class="usa-link" aria-describedby="CR48">48</a></sup>. Our most striking finding is that random micro-variation enhanced the vividness of imagined content more than mechanical drumming. We speculate that one possible explanation for this finding is that listeners may perceive drumming with micro-variation as more natural and organic by listeners, potentially aligning with a general preference for such rhythms in mental imagery. While the role of this preference in mental imagery remains uncertain, prior work suggests that the inherently human quality of these variations evokes a sense of authenticity and pleasantness absent from mechanical performances<sup><a href="#CR75" class="usa-link" aria-describedby="CR75">75</a></sup>. Moreover, vividness of imagined content seems to be associated with the aesthetic appeal of music, although this appeal varies from individual to individual<sup><a href="#CR15" class="usa-link" aria-describedby="CR15">15</a></sup>. In addition to aesthetic and perceptual speculation, alternative explanations could come from embodied cognition frameworks, where listeners internally simulate action-related qualities of the sounds, that may enrich the vividness of mental imagery. Findings that human-performed music enhances sensorimotor and synesthetic responses more than a “deadpan” (without expression) performance<sup><a href="#CR93" class="usa-link" aria-describedby="CR93">93</a></sup> support this position. Accordingly, such embodiment engagement may contribute to richer internal representations potentially explaining why micro-variation enhances vividness of imagined content more than mechanical condition. This is also especially relevant in the context of drumming, where it is the highly physical form of music-making where sound is directly shaped by movement, and thus the expressivity<sup><a href="#CR94" class="usa-link" aria-describedby="CR94">94</a></sup>. Taken together, the current paper’s finding highlights random micro-variation as a distinct musical feature capable of enhancing the vividness of mental imagery.</p>
<p id="Par30">The results showed no strong evidence for emotional sentiment being affected by random micro-variations and mechanical playing, compared to silence. This is an important observation as it supports prior findings that the effect of music on vividness and sentiment of imagined content can be distinct<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a></sup>. Furthermore, the finding suggests that random micro-variation, as a specific musical feature, have a targeted effect, influencing vividness of imagined content while having minimal to no impact on emotional sentiment. This distinction allows for a degree of dissociation between these processes, providing valuable insights into how specific musical features uniquely contribute to different aspects of mental imagery. One potential explanation for the lack of strong emotional effects is the repetitive rhythmic nature of our stimuli and the use of micro-timing variations with a standard deviation as small as 4 ms. These patterns, while ideal for isolating micro-variation effects, may not engage emotional processing as effectively as musical stimuli with richer rhythmic, melodic, and harmonic content. Previous studies have shown that structural features such as harmony and rhythm evoke strong neural engagement in emotion-related areas of the brain (e.g., limbic system)<sup><a href="#CR95" class="usa-link" aria-describedby="CR95">95</a>,<a href="#CR96" class="usa-link" aria-describedby="CR96">96</a></sup>. Alternatively, or in addition, the effect of random micro-variation should be understood as enhancing existing effects of the musical stimuli. Since quasi-isochronous drum patterns do not evoke strong emotions to begin with, random micro-variations may have little sentiment to affect.</p>
<p id="Par31">Both random micro-variation and mechanical drumming elicited greater imagined distance compared to silence. This is consistent with prior studies also observing greater imagined distance travelled during music listening<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a>,<a href="#CR44" class="usa-link" aria-describedby="CR44">44</a></sup>. While individuals typically maintain awareness of their physical surroundings and the present moment<sup><a href="#CR97" class="usa-link" aria-describedby="CR97">97</a></sup>, spatial navigation enables the formation of mental representations linking different points and allows behavioural flexibility for goal-directed planning<sup><a href="#CR98" class="usa-link" aria-describedby="CR98">98</a></sup>. Drumming likely served as an attentional anchor<sup><a href="#CR99" class="usa-link" aria-describedby="CR99">99</a></sup>, shaping mental representations and navigational cues. The repetitive patterns of drumming may have enhanced continuity in imagined distance. As the hierarchical structure of the musical stimuli used here are not rich, the attention may have shifted to micro-variations, such as micro-timing (as hypothesised by Margulis<sup><a href="#CR100" class="usa-link" aria-describedby="CR100">100</a></sup>). Micro-timing changes, which have been associated with increased mental effort (as indicated by pupillometry)<sup><a href="#CR76" class="usa-link" aria-describedby="CR76">76</a></sup>, might have anchored attention, thereby contributing to the perception of greater imagined distance.</p>
<p id="Par32">Interestingly, for imagined time, only random micro-variation showed stronger evidence for longer imagined time passed compared to silence, whereas the mechanical condition did not show strong evidence for a difference. This is somewhat unexpected, particularly given previous findings that even repetitive, mechanical sounds can influence perceived time through entrainment (i.e., the synchronisation of cognitive rhythmic processes with external rhythmic stimuli)<sup><a href="#CR77" class="usa-link" aria-describedby="CR77">77</a>,<a href="#CR101" class="usa-link" aria-describedby="CR101">101</a>,<a href="#CR102" class="usa-link" aria-describedby="CR102">102</a></sup>. In our model, the posterior probability of a positive effect of the mechanical condition on imagined time (relative to silence) was 0.82, which is not sufficient to draw firm conclusions. If there is indeed no or only a small effect of mechanical rhythms on imagined time, one possible explanation could be that participants habituated to their high predictable pattern<sup><a href="#CR103" class="usa-link" aria-describedby="CR103">103</a></sup>, and that individuals may not require as much cognitive effort or flexibility to monitor time. In turn, this could result in a perception of time that feels static or unchanging, similar to the experience during silence. Specifically, repeated stimuli are perceived to last for shorter durations in contrast to novel stimuli, potentially because neural responses diminish with repeated exposure<sup><a href="#CR104" class="usa-link" aria-describedby="CR104">104</a></sup>. Another possibility is that the visual imagery task, which is based on imagining physical distance, may have dominated participants’ temporal judgments, thereby attenuating subtle entrainment effects associated with the mechanical condition. Perhaps future research could better disentangle this effect by using alternative control conditions, such as static visuals, to isolate modality-specific contributions. In contrast, engaging activities with variability and complexity often make time seem to pass more quickly, a phenomenon commonly referred to as “time flies when you’re having fun”<sup><a href="#CR105" class="usa-link" aria-describedby="CR105">105</a></sup>. The randomness of micro-variations, such as in time and loudness, might create more moments of novelty, increasing the level of engagement<sup><a href="#CR106" class="usa-link" aria-describedby="CR106">106</a></sup>.</p>
<section id="Sec20"><h3 class="pmc_sec_title">Individual differences</h3>
<p id="Par33">There is significant variation among individuals in their capacity to form mental images<sup><a href="#CR107" class="usa-link" aria-describedby="CR107">107</a></sup>. First considering the absorption level on the TAS, our findings showed that individuals with higher absorption tend to experience more vivid mental imagery in both random micro-variation and mechanical conditions, but not in the silence condition. This effect was particularly pronounced in the random micro-variation condition. Interestingly, however, level of absorption was not found to exert the same effect for emotional sentiment. These findings suggest that while individuals higher in absorption are more likely to deeply engage with auditory stimuli, especially random micro-variations, and vividly imagine in response to them, this heightened absorption does not necessarily translate to stronger imagined emotional content. Initially, it might be puzzling why in terms of vividness, absorption shows such a clear effect in both music conditions, but not the silence condition. It might be that individuals with higher propensity for absorption benefit from the additional mental imagery support that music—remarkably random micro-variations—provides, as evidenced by their increased vividness scores in music conditions compared to silence. This suggests that absorption tendency may predict an individual’s capacity to engage with music to enhance mental imagery.</p>
<p id="Par34">Our findings also revealed that individuals with lower absorption tendencies experienced greater imagined distance in both random micro-variation and mechanical conditions compared to silence. Conversely, no strong association emerged for individuals with higher absorption on imagined distance. This suggests that subtle variations within quasi-isochronous patterns may provide external auditory cues that facilitate spatial exploration for individuals with lower absorption tendencies, who may otherwise rely less on internal mental imagery. Integrating these findings with vivid visual imagery tendencies, as measured by the VVIQ, revealed complementary insights. Individuals with higher vivid imagery tendencies imagined greater distances on the task, most pronounced in the micro-variation condition. For individuals with lower absorption tendencies, quasi-isochronous rhythms with micro-variation and mechanical style were associated with increased imagined distance. Meanwhile, higher vivid imagery tendencies seem to align more directly with the ability to engage in spatial exploration (e.g., to reach a goal, i.e., the landmark in the visual stimuli<sup><a href="#CR98" class="usa-link" aria-describedby="CR98">98</a></sup>). Taken together, these results indicate that individual differences in absorption and imagery vividness shape how simplistic auditory structure supports imagined movement either by compensating for weaker internal imagery in low absorbers and/or by enhancing already vivid mental representations in high visualisers.</p>
<p id="Par35">Relating to musical training as an interacting effect for mental imagery in this study, it is also worth noting that as musical expertise increased, participants imagined greater distances travelled and longer times spent in micro-variation and mechanical conditions than in the silence condition. Furthermore, and again, micro-variation had a more pronounced effect than mechanical style. The observed effect on imagined time in both the micro-variation and mechanical conditions suggests that their shared rhythmic predictability engages the temporal imagery of highly trained listeners in similar ways, resulting in no strong difference between the two conditions. A similar pattern was observed for imagined distance, suggesting that as musical expertise increases, rhythmic auditory input may serve as a stronger cue for constructing spatiotemporal imagery, while silence may result in a lower baseline. Considering that micro-variations had a larger overall effect on this variable, this study is the first, among those employing this mental imagery paradigm<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a>,<a href="#CR44" class="usa-link" aria-describedby="CR44">44</a>,<a href="#CR46" class="usa-link" aria-describedby="CR46">46</a>,<a href="#CR48" class="usa-link" aria-describedby="CR48">48</a>,<a href="#CR108" class="usa-link" aria-describedby="CR108">108</a></sup>, to understand how specific musical mechanisms – namely, micro-variations – interact with musical training to influence imagined distance and time.</p></section><section id="Sec21"><h3 class="pmc_sec_title">Implications and future directions</h3>
<p id="Par36">The present findings support music’s potential to play a beneficial role in evidence-based therapies<sup><a href="#CR109" class="usa-link" aria-describedby="CR109">109</a></sup>, creative practices<sup><a href="#CR110" class="usa-link" aria-describedby="CR110">110</a></sup>, as well as recreational settings that utilise mental imagery<sup><a href="#CR39" class="usa-link" aria-describedby="CR39">39</a></sup>. Quasi-isochronous patterns with random micro-variations could be applied in such settings to enhance the vividness of individuals’ imagined scenarios as well as spatiotemporal properties, both independent of the emotional sentiment of imagined content. For example, individuals suffering from Generalised Anxiety Disorder (GAD) often struggle with planning and decision-making<sup><a href="#CR97" class="usa-link" aria-describedby="CR97">97</a>,</sup> and music containing micro-variations, may aid in stepwise planning by facilitating the mental simulation of future events<sup><a href="#CR111" class="usa-link" aria-describedby="CR111">111</a></sup>. Furthermore, in some cognitive behavioural therapies such as imagery exposure therapy<sup><a href="#CR35" class="usa-link" aria-describedby="CR35">35</a></sup>, the therapist relies on carefully calibrating the vividness of imagined content, and adding or removing micro-variations to accompanying music could help in such scenarios. Outside the clinical domain, professional and recreational activities commonly rely on spatial imagery, such as strategy-based games (e.g., chess<sup><a href="#CR112" class="usa-link" aria-describedby="CR112">112</a></sup>) or high-performance sports (e.g., figure skating<sup><a href="#CR113" class="usa-link" aria-describedby="CR113">113</a></sup>). Precisely aligning players’ desired levels of mental imagery characteristics through manipulations of background music (e.g., micro-variations) and considering individual traits (e.g., absorption) could further optimise the efficacy of mental imagery techniques and deepen engagement in activities like role-playing<sup><a href="#CR114" class="usa-link" aria-describedby="CR114">114</a></sup>. Nonetheless, these applications remain speculative and should be tested through future research, including dual-task paradigms that use more structured and goal-oriented imagery tasks such as role-playing.</p>
<p id="Par37">Mental imagery also plays a critical role in the aesthetic implications and cognitive processing of music. For composers and producers aiming to create music that fosters vivid imagery, incorporating micro-variations, such as those enabled by the “humanise” control in digital audio workstations, can be a valuable tool. For instance, in genres where creating imagery simulations and immersion is the key, such as film scoring<sup><a href="#CR115" class="usa-link" aria-describedby="CR115">115</a></sup>, micro-variations could be strategically used to enhance the narrative or atmospheric qualities of a piece. Similarly, sound engineers and mixers could apply these findings to fine-tune the perceptual qualities of recorded performances, enhancing the human-like qualities of electronic or AI-generated music. In this way, music that engages vivid mental imagery could open new creative possibilities for artists, producers, and engineers.</p>
<p id="Par38">The musical stimuli used here were deliberately simplistic to control and isolate the constructs of interests. To explore simpler underlying structures, future studies could model micro-variation parameters (micro-timing, strike velocity, and drum-hit location) as continuous predictors to better understand their individual contributions to mental imagery. Additionally, incorporating white noise and random, irregular drumbeats as control conditions could help isolate the effects of these micro-variations. Indeed, while synthesised stimuli here allowed for precise control over parameters, future studies could incorporate performances by expert drummers to enhance ecological validity more and explore how naturally performed quasi-isochronous rhythms compare to algorithmically controlled ones (e.g<sup><a href="#CR94" class="usa-link" aria-describedby="CR94">94</a></sup>.,). Moreover, both micro-variation and mechanical conditions were based on acoustic drum simulations, potentially resulting in the micro-variation stimuli sounding more natural. Future work could test this further using ecologically valid yet mechanically timed styles such as electronic dance music.</p>
<p id="Par39">To increase the generalisability and applied value of the present findings, future studies could incrementally increase the complexity and sophistication of the stimuli and explore other musical features in a controlled environment. For example, future work could build on the current framework by incorporating layered drum patterns, such as those with overlapping rhythmic textures, polyphonic rhythms—where multiple rhythms interact simultaneously—or manipulated harmonic content, to explore how structural, timbral, and rhythmic complexity shape listeners’ mental imagery.</p>
<p id="Par40">Besides, while the current visual imagery task was intentionally neutral to isolate the effects of micro-variation on imagery, further studies could also explore how emotionally charged tasks (both musically and visually) interact with musical expressivity. Micro-variation potentially could further enhance vividness in emotionally engaging contexts.</p></section></section><section id="Sec22"><h2 class="pmc_sec_title">Conclusions</h2>
<p id="Par41">The present study is among the first to systematically explore the effects of specific musical features, here random micro-variation, on the vividness, sentiment, distance and time travelled of the imagined content in a directed mental imagery task. Our findings underscore the ability of music to influence concurrent directed mental imagery, whilst also revealing how individual differences in tendency for absorption, imagining vividly, and musical training interact with such micro-variations in auditory stimuli to shape directed mental imagery characteristics. In addition, the present results further highlight that random micro-variations can greatly enrich music and its impact on listeners, offering important avenues to pursue in therapeutic, creative, and recreational settings.</p></section><section id="Sec23"><h2 class="pmc_sec_title">Methods</h2>
<section id="Sec24"><h3 class="pmc_sec_title">Participants</h3>
<p id="Par42">One hundred participants (43 females, 55 males, 2 unreported; <em>M</em><sub><em>Age</em></sub> = 30.53, <em>SD</em><sub><em>Age</em></sub> = 9.21, <em>Range</em> = 18 to 65 years) completed the experiment through the online platform Prolific Academic. The sample size was determined based on previous studies employing the same paradigm<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a>,<a href="#CR44" class="usa-link" aria-describedby="CR44">44</a>,<a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup>. The inclusion criteria were that participants needed to be fluent in English and have normal or corrected-to-normal hearing, and that all participants provided informed consent. Participants’ country of residence was geographically diverse and distributed as follows: Americas (45%) [North America (32%), South America (13%)], Europe (29%), Africa (16%), Oceania (8%), and Asia (2%). Musical expertise of the participants was varied with <em>M</em> = 19.1, <em>SD</em> = 9.27, <em>Range</em> = 7 to 43, calculated through 7 items of the Goldsmiths Musical Sophistication Index’s (Gold-MSI) musical training subscale<sup><a href="#CR91" class="usa-link" aria-describedby="CR91">91</a></sup>. Each participant received a reimbursement of 10 GBP. The study adhered to the declaration of Helsinki at all times and received ethics approval from the Western Sydney University Human Research Ethics Committee (<a href="https://www.ncbi.nlm.nih.gov/nuccore/H15657" class="usa-link" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">H15657</a>).</p></section><section id="Sec25"><h3 class="pmc_sec_title">Musical stimuli</h3>
<p id="Par43">We recreated the stimulus for this experiment using a recording that was also used in prior studies<sup><a href="#CR78" class="usa-link" aria-describedby="CR78">78</a>–<a href="#CR82" class="usa-link" aria-describedby="CR82">82</a></sup>. The original stimulus is a soundtrack titled “15-min solo drumming journey with callback” from Michael Harner’s <em>Shamanic Journey: Solo and Double Drumming</em><sup><a href="#CR116" class="usa-link" aria-describedby="CR116">116</a></sup>. It consists of a fast quasi-isochronous naturalistic drumming, with 240 BPM or 4 Hz<sup><a href="#CR78" class="usa-link" aria-describedby="CR78">78</a>,<a href="#CR80" class="usa-link" aria-describedby="CR80">80</a></sup>. The original stimulus, performed by humans, contains subtle micro-variations in timing, drum-strike velocity, and drum-hit location. To replicate these characteristics, we recreated all drumming stimuli using Ableton Live 11 Suite<sup><a href="#CR117" class="usa-link" aria-describedby="CR117">117</a></sup>, and Chromaphone 2—a synthesiser specially built to have distinct timbres—which includes full physical models of the drums and an option to synthesise performances with random micro-variation<sup><a href="#CR85" class="usa-link" aria-describedby="CR85">85</a></sup>.</p>
<p id="Par44">Recreating the stimulus in a Digital-Audio-Work station allowed for the manipulation and control of the instrumentation of the stimulus, whilst avoiding additional variability (e.g., audio processing artifacts and background noise) that natural recordings would entail<sup><a href="#CR118" class="usa-link" aria-describedby="CR118">118</a></sup>. In this way, the internal validity and reliability of our findings would be enhanced while providing a controlled environment to accurately assess the effects of quasi-isochronous rhythms with micro-variation versus mechanical version.</p>
<p id="Par45">Three different drums were used: a round-frame drum, Chromaphone pre-designed “African Drum” (sound designer: Philippe Derogis), and “Snare Natural” (sound designer: Philippe Derogis). The round-frame drum, 16-inch single-headed drum commonly used in practices of Core Shamanism—a modern framework by Michael Harner that emphasises universal shamanic practices like drumming to induce altered states of consciousness and facilitate mental imagery<sup><a href="#CR78" class="usa-link" aria-describedby="CR78">78</a>–<a href="#CR81" class="usa-link" aria-describedby="CR81">81</a>,<a href="#CR119" class="usa-link" aria-describedby="CR119">119</a></sup>—was included for its significance in these practices and its demonstrated effectiveness in this regard. We took a Chromaphone sample instrument, “Arabian Drum” (sound designer: Christian Laffitte), to design the round-frame drum from scratch and emulate the drum sound in the original soundtrack as closely as possible<sup><a href="#CR116" class="usa-link" aria-describedby="CR116">116</a></sup>. The adjustments involved modifying the settings for mallet stiffness, noise density, and resonator properties. Additional resynthesis settings in Ableton included Out Hi 127 [to adjust the high-frequency output level to enhance the clarity and presence of the higher frequencies in the sound], Dynamic Tube (84.1% wet signal, -295% envelope, 47.1 ms attack, 23.0 ms release, 9.05 dB drive, -1.90 output level) for the purpose of adding warmth and slight distortion to the sound, and specific Equalisation (EQ) settings (Frequency 4.26 kHz, 0.61 Q factor) to fine-tune its frequency characteristics. Furthermore, in Ableton and for all drums, Dark Snare Room with chambers and large room settings at 30% dry was applied across both random micro-variation and mechanical conditions, to make the audio sound fuller and richer and give the impression that it was recorded with the natural acoustics of a large room.</p>
<p id="Par46">Each of these drums had both random micro-variation and mechanical versions (see Fig. <a href="#Fig6" class="usa-link">6</a> for example waveforms). Mechanical versions were included to explore the effect of random micro-variations by serving as an unnaturalistic style of the drum patterns and eliminating variation to highlight the specific effects introduced by micro-variation. Additionally, a silence condition as a control was included to distinguish the effects of drum patterns from those specific to the random micro-variation version. The silence version also enabled comparisons with prior studies using the same paradigm but different musical stimuli<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a>,<a href="#CR44" class="usa-link" aria-describedby="CR44">44</a></sup>. Several elements were randomised in the micro-variation drum stimuli, including strike velocity, drum-hit location, and timing, to ensure a more naturalistic, humanised variation in the drumming patterns. Three different versions of random micro-variation stimuli were created, with each participant randomly assigned to hear only one version. These micro-variations were drawn from pre-specified random distributions that were piloted to sound natural. Each participant and instrument combination received a unique random draw from these distributions. The following are the parameters of the main controls (i.e., micro-timing, strike velocity, and drum-hit location) as encoded in Ableton and Chromaphone. These parameters differ systematically between the micro-variation and mechanical conditions and serve as the basis for quantifiable contrasts. We either report the actual distribution or the percentage of variability in it. For timing, we used normal (0, 4 ms). In terms of strike velocity, we used the “Velocity” feature on Ableton to add or subtract a random number between 0 and 26 from the original MIDI velocity of each strike. For drum-hit location, we used the “Hit Position” parameter on Chromaphone to modulate the drum-hit location, carefully tuning the drums by hand and ear. This parameter determines the excitation point on the resonator as a percentage of the object’s size. Minimum values correspond to excitation at the object’s border, while maximum values correspond to excitation at its centre. The specified values (frame drum velocity = 19.90%; “African” drum velocity = -60.00%; and snare drum velocity = 15.00%) control how much the velocity influences the hit position, with higher values creating more variation in excitation points. The “Key” (pitch signal) and “Random Signal” (random modulation) controls were both set to 0.00%. Each drum’s hit position in Chromaphone is modulated by the incoming MIDI note’s velocity, which is randomised by Ableton and influenced by the Velocity sub-parameter of Hit Position setting. We also used Chromaphone’s built-in controls, such as mallet stiffness, to modulate loudness and intensity of the drum sound, ensuring natural-sounding results. These modulations were part of the original presets and were not specifically modified.</p>
<figure class="fig xbox font-sm" id="Fig6"><h4 class="obj_head">Fig. 6.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373897_41598_2025_12604_Fig6_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/6f3f/12373897/74e63a9532be/41598_2025_12604_Fig6_HTML.jpg" loading="lazy" id="d33e1857" height="247" width="669" alt="Fig. 6"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig6/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Waveforms of 1-s Mechanical (on the left column) and Random Micro-Variation (on the right column) of quasi-isochronous rhythmic stimuli (240 BPM) played by the “African” drum. The y-axis shows the amplitude, and the x-axis shows the time in seconds. This figure highlights the differences in timing and amplitude patterns between mechanical and random micro-variation conditions, illustrating the subtle variations introduced by the micro-variation condition compared to the uniformity of the mechanical condition.</p></figcaption></figure><p id="Par47">Regarding the mechanical stimuli, all main randomisation parameters (i.e., strike velocity, drum-hit location, and timing) were set to 0 while keeping other settings the same.</p>
<p id="Par48">Overall stimuli loudness was normalised to the common value of -23 ± 5*10<sup>–7</sup> LUFS, as per EBU R-12881, using pyloudnorm Python library82<sup><a href="#CR120" class="usa-link" aria-describedby="CR120">120</a></sup>. The duration of each stimulus was 90 s without a gong at the end. All musical stimuli and the Ableton project are available on OSF, <a href="https://osf.io/2qr4n/?view_only=5738a93396434f72bd54736bc801dbb2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://osf.io/2qr4n/?view_only=5738a93396434f72bd54736bc801dbb2</a>.</p></section><section id="Sec26"><h3 class="pmc_sec_title">Procedure and task</h3>
<p id="Par49">The experiment employed a directed mental imagery task, which has been used in prior studies<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a>,<a href="#CR44" class="usa-link" aria-describedby="CR44">44</a>,<a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup>. The experiment was created in PsychoPy<sup><a href="#CR121" class="usa-link" aria-describedby="CR121">121</a></sup>, and the experiment was accommodated on the online platform Pavlovia (<a href="http://www.pavlovia.org" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">www.pavlovia.org</a>), which was then linked to Prolific Academic for participant recruitment.</p>
<p id="Par50">Participants were presented with a visual inducer consisting of a figure travelling towards a hardly perceptible small hill, with an unclear landmark appearing from the distance once the figure reaches the top of the hill (Fig. <a href="#Fig7" class="usa-link">7</a>a). This visual inducer was taken from a video game, “Journey” (<a href="https://thatgamecompany.com/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://thatgamecompany.com/</a>), acquired with the permission of <em>ThatGameCompany.</em> After 15 s of watching the video, participants were then presented with a gong sound and instructed to close their eyes to imagine a continuation of the figure’s journey in the direction of the landmark (Fig. <a href="#Fig7" class="usa-link">7</a>b). This session was accompanied by a black screen with white lettering stating, “Please close your eyes”. During each trial, participants listened to one of six stimuli detailed in the Musical Stimuli section or the silence control condition. Each participant completed a total of seven trials, with the order of conditions randomised. The gong was played at the end of each trial after one minute and thirty seconds, which prompted participants to open their eyes and report on their use of mental imagery through several questions concerning the imagined travel (Fig. <a href="#Fig7" class="usa-link">7</a>c):</p>
<ol class="list" style="list-style-type:decimal">
<li><p id="Par51">How much time really passed between the two gong sounds? (minutes, seconds)</p></li>
<li><p id="Par52">How far away do you estimate the mountain to be at the beginning of the journey? (kilometres, meters)</p></li>
<li><p id="Par53">How much time passed in your imagination? (years, months, days, hours, minutes, seconds)</p></li>
<li><p id="Par54">How far did you travel in your imagination? (kilometres, meters)</p></li>
<li><p id="Par55">How vivid (clear) was the imagery you experienced compared to experiences in real life? (Please indicate a number from 0 = not very clear to 100 = very clear)</p></li>
<li><p id="Par56">Please describe your imagination in as much detail as possible. [A free-format text box]</p></li>
</ol>
<figure class="fig xbox font-sm" id="Fig7"><h4 class="obj_head">Fig. 7.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373897_41598_2025_12604_Fig7_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/6f3f/12373897/4b330904f879/41598_2025_12604_Fig7_HTML.jpg" loading="lazy" id="d33e1973" height="448" width="669" alt="Fig. 7"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig7/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Imagination task. Reproduced with permission from Herff et al.<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a></sup> and Taruffi et al.<sup><a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup> Participants were presented with a visual inducer acquired from the video game “Journey” with written permission of Jenova Chen, CEO of ThatGameCompany (<a href="https://thatgamecompany.com" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://thatgamecompany.com</a>). The whole experiment took between 30 and 60 min to complete. (<strong>a</strong>) 15-s video illustrates a figure ascending a small hill. Once the figure reaches the top of the hill, a vague landmark appears in the far distance. (<strong>b</strong>) Participants hear a gong-sound and are instructed to close their eyes and imagine a continuation of the figure’s journey towards the landmark. The imagination task lasts one minute and thirty seconds (excluding the initial visual inducer), and is accompanied by a black screen with white lettering stating, “Please close your eyes”. During each trial, participants either listen to quasi-isochronous repetitive drumming with random-micro variation, quasi-isochronous repetitive drumming with a mechanical version, or a silent control condition. (<strong>c</strong>) At the end of the task, the gong-sound is played again, signalling participants to open their eyes and answer a series of questions on time and distance of imagined travel, vividness, sentiment, and content of thoughts.</p></figcaption></figure><p id="Par57">While participants were asked to freely describe their imagined experience for each trial, the task did not constrain them to any specific imagery modality (e.g., visual, kinaesthetic).</p>
<p id="Par58">At the end of the seven trials, participants were required to complete several self-report questionnaires to assess trait level individual differences in the following order: level of imagery absorption, vividness of visual imagery, and musical training.</p>
<p id="Par59">The Tellegen Absorption Scale (TAS)<sup><a href="#CR89" class="usa-link" aria-describedby="CR89">89</a></sup> was used to assess the trait level absorption of participants, i.e., the inclination to deeply engage in imaginative or sensory experiences<sup><a href="#CR122" class="usa-link" aria-describedby="CR122">122</a></sup>. We focused on the prone to imaginative and altered states subscale due to its strong alignment with our research questions, and its specificity in capturing the dimensions of absorption pertinent to our task. This subscale contains 18 items on a 5-point rating scale, and shows adequate test–retest reliability and internal consistency<sup><a href="#CR123" class="usa-link" aria-describedby="CR123">123</a></sup>.</p>
<p id="Par60">The Vividness of Visual Imagery Questionnaire (VVIQ)<sup><a href="#CR90" class="usa-link" aria-describedby="CR90">90</a></sup> was employed to assess individual variations in the ability to generate and experience vivid visual mental imagery. The questionnaire has 16 items on a 5-point rating scale, assessing the extent to which individuals can mentally visualise and perceive visual images with clarity, detail, and realism<sup><a href="#CR90" class="usa-link" aria-describedby="CR90">90</a></sup>. Many studies have shown that VVIQ has a high reliability and validity (e.g<sup><a href="#CR124" class="usa-link" aria-describedby="CR124">124</a></sup>.,).</p>
<p id="Par61">Level of musical training was established using the Musical Training subscale of the Goldsmiths Musical Sophistication Index (Gold-MSI)<sup><a href="#CR91" class="usa-link" aria-describedby="CR91">91</a></sup>, which contains seven self-report questions on a 7-point rating scale. The scale demonstrates high test–retest reliability and good internal reliability, mostly through English-speaking participants. It also exhibits reliable correlations with various objective listening ability tests (e.g<sup><a href="#CR125" class="usa-link" aria-describedby="CR125">125</a></sup>.,).</p>
<p id="Par62">The short-form of the Depression Anxiety Stress Scale (DASS-21)<sup><a href="#CR126" class="usa-link" aria-describedby="CR126">126</a></sup> was additionally utilised to explore the influence of mood symptoms on mental imagery. The DASS-21 has 21 items, and demonstrates good reliability and validity in non-clinical adult populations<sup><a href="#CR126" class="usa-link" aria-describedby="CR126">126</a></sup>. The DASS results were excluded from the analyses as they belong to a broader study and will be presented in a separate report.</p>
<section id="Sec27"><h4 class="pmc_sec_title">Catch trial</h4>
<p id="Par63">At the end of the experiment, a clock-drawing catch trial was included to assess participants’ attentiveness and detect artificial intelligence or automated tools (e.g. “bots”). In this trial, participants were presented with an instruction: “Please use the white box on the right and your mouse to draw a clock face with numbers and the hands at ten past five.” Responses were evaluated based on accuracy, considering the correct placement of the clock hands and the inclusion of necessary numbers for successful completion. In a few instances, participants reversed the hands, placing the minute hand pointing near the five and the hour hand at the two. After carefully checking their overall responses, we accepted these as valid, recognising them as genuine human errors rather than indicators of inattentiveness or automated output.</p>
<p id="Par64">The whole experiment took around one hour to complete.</p></section></section><section id="Sec28"><h3 class="pmc_sec_title">Statistical approach</h3>
<p id="Par65">Data analysis was carried out using Bayesian multilevel regression model to enable modelling each response for the variables (vividness, sentiment, time and distance travelled) while controlling for crossed random effects, such as trial numbers and participants<sup><a href="#CR127" class="usa-link" aria-describedby="CR127">127</a></sup>. The model included fixed effects for the interaction between (1) music and silence, (2) random micro-variation, mechanical, and silence, and (3) scores for TAS, VVIQ, and GMSI. Importantly, Sets (1) and (2) were not treated independently. Rather, this structure reflects a hierarchical nesting, where the model first distinguishes between music and silence in (1). Then, conditional on the trial being music, it further models differences between random micro-variation and mechanical conditions in (2). The inclusion of “silence” in (2) is a modelling strategy to support faster convergence and does not imply independent treatment. The random effects controlled for trial numbers, participants, and the nested interactions among (1), (2), (3) instruments (including frame, snare, or “African”) or silence, and (4) which micro-variation (1, 2, or 3) was taken into account. While instrument type was not a primary focus of the current study, analyses exploring its role are reported in the supplementary materials (available via OSF, <a href="https://osf.io/2qr4n/?view_only=5738a93396434f72bd54736bc801dbb2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://osf.io/2qr4n/?view_only=5738a93396434f72bd54736bc801dbb2</a>). These analyses follow the statistical approach employed in previous studies using the same paradigm<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a>,<a href="#CR44" class="usa-link" aria-describedby="CR44">44</a>,<a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup>. All analyses were implemented in R<sup><a href="#CR128" class="usa-link" aria-describedby="CR128">128</a></sup>, using the brms package<sup><a href="#CR129" class="usa-link" aria-describedby="CR129">129</a></sup>.</p>
<p id="Par66">Following previous auditory perception work<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a>,<a href="#CR44" class="usa-link" aria-describedby="CR44">44</a></sup>, continuous variables were standardised (<em>M</em> = 0, <em>SD</em> = 1), and the imagined time and distance travelled responses by the participants were natural log-scaled to be standardised. A weakly informative prior (a Student’s t-distribution with a mean of 0, a standard deviation of 1, and 3 degrees of freedom) was set, and the models ran with 4,000 warm-ups, and 10,000 iterations on 4 Markov chains. All R-hats were 1.00, indicating full convergence. Here, hypotheses are reported with the model coefficients (<em>β</em>) related to certain hypotheses, the estimated error for these coefficients (<em>EE</em><sub><em>β</em></sub>), the evidence ratio in favour of that certain hypothesis (<em>Odds</em><sub><em>β</em></sub>), and their Posterior Probability (<em>Post.Prob</em>). Average predictions were generated and evaluated to draw inference<sup><a href="#CR130" class="usa-link" aria-describedby="CR130">130</a></sup>. For convenience, we mark effects deemed strong evidence at a 5% alpha level with * (i.e., evidence ratio ≥ 19 (<em>Post.Prob</em> ≥ 0.95) for one-sided or ≥ 39 (<em>Post.Prob</em> ≥ 0.98) for two-sided tests; see<sup><a href="#CR86" class="usa-link" aria-describedby="CR86">86</a>,<a href="#CR92" class="usa-link" aria-describedby="CR92">92</a></sup>). For hypotheses with a clear directional expectation (e.g., random micro-variation &gt; mechanical &gt; silence or high &gt; low scale test scores, we ran one-sided tests (<em>Odds</em> ≥ 19). For analyses without a clear directional expectation (e.g., interactions between conditions and scales), we applied a more stringent threshold (<em>Odds</em> ≥ 39) for significance and ran two-sided tests.</p>
<p id="Par67">Imagined sentiment from the free-format responses was first extracted by Natural Language Toolkit (NLTK)<sup><a href="#CR87" class="usa-link" aria-describedby="CR87">87</a></sup> and the Valence Aware Dictionary for sEntiment Reasoning (VADER) model<sup><a href="#CR88" class="usa-link" aria-describedby="CR88">88</a></sup> in Python3. The VADER provides an output of emotional valence and intensity in a continuum from negative to positive through mapping lexical features, higher numerical values indicating a more positive sentiment. VADER is trained on a pre-defined lexicon of around 7,500 words and phrases, applying rule-based heuristics for a fast sentiment analysis.</p></section></section><section id="ack1" class="ack"><h2 class="pmc_sec_title">Acknowledgements</h2>
<p>This project was supported by the Australian Government through the Australian Research Council (ARC) under the Discovery Early Career Researcher Award (DECRA, DE2201100961, awarded to SAH), by the Swiss National Science Foundation (SNF) under the SPARK grant scheme (CRSK-1_196567 / 1, awarded to SAH) and by the University of Sydney, through the Sydney Horizon Fellowship (awarded to SAH). MI is supported by a National Health and Medical Research Council of Australia Investigator Grant (GNT2025228). We thank all our participants for their contribution and Jenova Chen for allowing us to use content from the video game “Journey” to function as visual inducers. We thank Marc-Pierre Verge from Applied Acoustic Systems for his input in interpreting Chromaphone 2 functions. We thank all members of the Sydney, Music, Mind, and Body Lab for constructive feedback on an earlier draft of the manuscript. We also thank the editor, Dr. Xiangbin Teng, and the reviewers for their constructive comments.</p></section><section id="notes1"><h2 class="pmc_sec_title">Author contributions</h2>
<p>C.A. contributed to the theoretical and methodological design, produced the auditory stimuli, collected the data, did the statistical analysis, wrote the first draft and revised the later drafts of the manuscript. A.J.M. contributed to the supervision, theoretical and methodological design, statistical analysis, and revised the manuscript. M.I. contributed to the methodological design, supervision, and revised the manuscript. S.A.H. contributed to the supervision, theoretical and methodological design, statistical analysis, edited and revised the manuscript, and acquired funding. All authors reviewed and approved the manuscript.</p></section><section id="notes2"><h2 class="pmc_sec_title">Data availability</h2>
<p>All data, analytical scripts, the Ableton project, and musical stimuli are available on OSF, <a href="https://osf.io/2qr4n/?view_only=5738a93396434f72bd54736bc801dbb2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://osf.io/2qr4n/?view_only=5738a93396434f72bd54736bc801dbb2</a>.</p></section><section id="notes3"><h2 class="pmc_sec_title">Declarations</h2>
<section id="FPar1"><h3 class="pmc_sec_title">Competing interests</h3>
<p id="Par68">The authors declare no competing interests.</p></section></section><section id="fn-group1" class="fn-group"><h2 class="pmc_sec_title">Footnotes</h2>
<div class="fn-group p font-secondary-light font-sm"><div class="fn p" id="fn1">
<p><strong>Publisher’s note</strong></p>
<p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</div></div></section><section id="Bib1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="Bib1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="CR1">
<span class="label">1.</span><cite>Savage, P. E., Brown, S., Sakai, E. &amp; Currie, T. E. Statistical universals reveal the structures and functions of human music. <em>Proc. Natl. Acad. Sci.</em><strong>112</strong>, 8987–8992 (2015). 10.1073/pnas.1414495112
</cite> [<a href="https://doi.org/10.1073/pnas.1414495112" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4517223/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/26124105/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Savage,%20P.%20E.,%20Brown,%20S.,%20Sakai,%20E.%20&amp;%20Currie,%20T.%20E.%20Statistical%20universals%20reveal%20the%20structures%20and%20functions%20of%20human%20music.%20Proc.%20Natl.%20Acad.%20Sci.112,%208987%E2%80%938992%20(2015).%2010.1073/pnas.1414495112" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR2">
<span class="label">2.</span><cite>Jacoby, N. et al. Cross-cultural work in music cognition: Challenges, insights, and recommendations. <em>Music. Percept.</em><strong>37</strong>, 185–195 (2020). 10.1525/mp.2020.37.3.185
</cite> [<a href="https://doi.org/10.1525/mp.2020.37.3.185" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10019032/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36936548/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Jacoby,%20N.%20et%20al.%20Cross-cultural%20work%20in%20music%20cognition:%20Challenges,%20insights,%20and%20recommendations.%20Music.%20Percept.37,%20185%E2%80%93195%20(2020).%C2%A010.1525/mp.2020.37.3.185" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR3">
<span class="label">3.</span><cite>Margulis, E. H., Wong, P. C. M., Turnbull, C., Kubit, B. M. &amp; McAuley, J. D. Narratives imagined in response to instrumental music reveal culture-bounded intersubjectivity. <em>Proc. Natl. Acad. Sci.</em><strong>119</strong>, e2110406119 (2022). 10.1073/pnas.211040611
</cite> [<a href="https://doi.org/10.1073/pnas.2110406119" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8795501/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35064081/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Margulis,%20E.%20H.,%20Wong,%20P.%20C.%20M.,%20Turnbull,%20C.,%20Kubit,%20B.%20M.%20&amp;%20McAuley,%20J.%20D.%20Narratives%20imagined%20in%20response%20to%20instrumental%20music%20reveal%20culture-bounded%20intersubjectivity.%20Proc.%20Natl.%20Acad.%20Sci.119,%20e2110406119%20(2022).%C2%A010.1073/pnas.211040611" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR4">
<span class="label">4.</span><cite>Singh, M. &amp; Mehr, S. A. Universality, domain-specificity and development of psychological responses to music. <em>Nat. Rev. Psychol.</em><strong>2</strong>, 333–346 (2023). 10.1038/s44159-023-00182-z
</cite> [<a href="https://doi.org/10.1038/s44159-023-00182-z" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10745197/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38143935/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Singh,%20M.%20&amp;%20Mehr,%20S.%20A.%20Universality,%20domain-specificity%20and%20development%20of%20psychological%20responses%20to%20music.%20Nat.%20Rev.%20Psychol.2,%20333%E2%80%93346%20(2023).%C2%A010.1038/s44159-023-00182-z" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR5">
<span class="label">5.</span><cite>Eerola, T. &amp; Vuoskoski, J. K. A review of music and emotion studies: Approaches, emotion models, and stimuli. <em>Music. Percept.</em><strong>30</strong>, 307–340 (2013). https://doi.org/10.1525/mp.2012.30.3.307</cite> [<a href="https://scholar.google.com/scholar_lookup?Eerola,%20T.%20&amp;%20Vuoskoski,%20J.%20K.%20A%20review%20of%20music%20and%20emotion%20studies:%20Approaches,%20emotion%20models,%20and%20stimuli.%20Music.%20Percept.30,%20307%E2%80%93340%20(2013).%C2%A0https://doi.org/10.1525/mp.2012.30.3.307" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR6">
<span class="label">6.</span><cite>Dimitriadis, T. et al. Motivation and music interventions in adults: A systematic review. <em>Neuropsychol. Rehabil.</em><strong>34</strong>, 649–678 (2024). 10.1080/09602011.2023.2224033
</cite> [<a href="https://doi.org/10.1080/09602011.2023.2224033" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37340969/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Dimitriadis,%20T.%20et%20al.%20Motivation%20and%20music%20interventions%20in%20adults:%20A%20systematic%20review.%20Neuropsychol.%20Rehabil.34,%20649%E2%80%93678%20(2024).%C2%A010.1080/09602011.2023.2224033" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR7">
<span class="label">7.</span><cite>Palazzi, A., Wagner Fritzen, B. &amp; Gauer, G. Music-induced emotion effects on decision-making. <em>Psychol. Music</em><strong>47</strong>, 621–643 (2019). 10.1177/0305735618779224</cite> [<a href="https://scholar.google.com/scholar_lookup?Palazzi,%20A.,%20Wagner%20Fritzen,%20B.%20&amp;%20Gauer,%20G.%20Music-induced%20emotion%20effects%20on%20decision-making.%20Psychol.%20Music47,%20621%E2%80%93643%20(2019).%C2%A010.1177/0305735618779224" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR8">
<span class="label">8.</span><cite>Koelsch, S., Bashevkin, T., Kristensen, J., Tvedt, J. &amp; Jentschke, S. Heroic music stimulates empowering thoughts during mind-wandering. <em>Sci. Rep.</em><strong>9</strong>, 10317 (2019). 10.1038/s41598-019-46266-w
</cite> [<a href="https://doi.org/10.1038/s41598-019-46266-w" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6635482/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31311967/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Koelsch,%20S.,%20Bashevkin,%20T.,%20Kristensen,%20J.,%20Tvedt,%20J.%20&amp;%20Jentschke,%20S.%20Heroic%20music%20stimulates%20empowering%20thoughts%20during%20mind-wandering.%20Sci.%20Rep.9,%2010317%20(2019).%C2%A010.1038/s41598-019-46266-w" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR9">
<span class="label">9.</span><cite>Jakubowski, K., Margulis, E. H. &amp; Taruffi, L. Music-evoked thoughts: Genre and emotional expression of music impact concurrent imaginings. <em>Music. Percept.</em><strong>42</strong>, 3–18 (2024). 10.1525/mp.2024.42.1.3</cite> [<a href="https://scholar.google.com/scholar_lookup?Jakubowski,%20K.,%20Margulis,%20E.%20H.%20&amp;%20Taruffi,%20L.%20Music-evoked%20thoughts:%20Genre%20and%20emotional%20expression%20of%20music%20impact%20concurrent%20imaginings.%20Music.%20Percept.42,%203%E2%80%9318%20(2024).%C2%A010.1525/mp.2024.42.1.3" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR10">
<span class="label">10.</span><cite>Margulis, E. H., Williams, J., Simchy-Gross, R. &amp; McAuley, J. D. When did that happen? The dynamic unfolding of perceived musical narrative. <em>Cognition</em><strong>226</strong>, 105180 (2022). 10.1016/j.cognition.2022.105180
</cite> [<a href="https://doi.org/10.1016/j.cognition.2022.105180" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35665662/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Margulis,%20E.%20H.,%20Williams,%20J.,%20Simchy-Gross,%20R.%20&amp;%20McAuley,%20J.%20D.%20When%20did%20that%20happen?%20The%20dynamic%20unfolding%20of%20perceived%20musical%20narrative.%20Cognition226,%20105180%20(2022).%C2%A010.1016/j.cognition.2022.105180" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR11">
<span class="label">11.</span><cite>Jakubowski, K. et al. Comparing music- and food-evoked autobiographical memories in young and older adults: A diary study. <em>Br. J. Psychol.</em><strong>114</strong>, 580–604 (2023). 10.1111/bjop.12639
</cite> [<a href="https://doi.org/10.1111/bjop.12639" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10363233/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36779290/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Jakubowski,%20K.%20et%20al.%20Comparing%20music-%20and%20food-evoked%20autobiographical%20memories%20in%20young%20and%20older%20adults:%20A%20diary%20study.%20Br.%20J.%20Psychol.114,%20580%E2%80%93604%20(2023).%C2%A010.1111/bjop.12639" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR12">
<span class="label">12.</span><cite>Herbert, R. Musical daydreaming and kinds of consciousness. In <em>Music and Mental Imagery</em> (eds. Küssner, M. B., Taruffi, L. &amp; Floridou, G. A.) 167–177 (Routledge, 2022).</cite> [<a href="https://scholar.google.com/scholar_lookup?Herbert,%20R.%20Musical%20daydreaming%20and%20kinds%20of%20consciousness.%20In%20Music%20and%20Mental%20Imagery%C2%A0(eds.%20K%C3%BCssner,%20M.%20B.,%20Taruffi,%20L.%20&amp;%20Floridou,%20G.%20A.)%20167%E2%80%93177%20(Routledge,%202022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR13">
<span class="label">13.</span><cite>Taruffi, L., Pehrs, C., Skouras, S. &amp; Koelsch, S. Effects of sad and happy music on mind-wandering and the default mode network. <em>Sci. Rep.</em><strong>1</strong>, 14396 (2017). 10.1038/s41598-017-14849-0</cite> [<a href="https://doi.org/10.1038/s41598-017-14849-0" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC5663956/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/29089542/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Taruffi,%20L.,%20Pehrs,%20C.,%20Skouras,%20S.%20&amp;%20Koelsch,%20S.%20Effects%20of%20sad%20and%20happy%20music%20on%20mind-wandering%20and%20the%20default%20mode%20network.%20Sci.%20Rep.1,%2014396%20(2017).%C2%A010.1038/s41598-017-14849-0" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR14">
<span class="label">14.</span><cite>Herff, S. A., Cecchetti, G., Taruffi, L. &amp; Déguernel, K. Music influences vividness and content of imagined journeys in a directed visual imagery task. <em>Sci. Rep.</em><strong>11</strong>, 15990 (2021). 10.1038/s41598-021-95260-8
</cite> [<a href="https://doi.org/10.1038/s41598-021-95260-8" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8346606/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34362960/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Herff,%20S.%20A.,%20Cecchetti,%20G.,%20Taruffi,%20L.%20&amp;%20D%C3%A9guernel,%20K.%20Music%20influences%20vividness%20and%20content%20of%20imagined%20journeys%20in%20a%20directed%20visual%20imagery%20task.%20Sci.%20Rep.11,%2015990%20(2021).%C2%A010.1038/s41598-021-95260-8" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR15">
<span class="label">15.</span><cite>Belfi, A. Emotional valence and vividness of imagery predict aesthetic appeal in music. <em>Psychomusicol. Music Mind Brain</em><strong>29</strong>, 128–135 (2019). 10.1037/pmu0000232</cite> [<a href="https://scholar.google.com/scholar_lookup?Belfi,%20A.%20Emotional%20valence%20and%20vividness%20of%20imagery%20predict%20aesthetic%20appeal%20in%20music.%20Psychomusicol.%20Music%20Mind%20Brain29,%20128%E2%80%93135%20(2019).%C2%A010.1037/pmu0000232" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR16">
<span class="label">16.</span><cite>Hashim, S., Stewart, L., Küssner, M. B. &amp; Omigie, D. Correction: Music listening evokes story-like visual imagery with both idiosyncratic and shared content. <em>PLoS ONE</em><strong>20</strong>, e0317174 (2025). 10.1371/journal.pone.0317174
</cite> [<a href="https://doi.org/10.1371/journal.pone.0317174" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11698391/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39752350/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Hashim,%20S.,%20Stewart,%20L.,%20K%C3%BCssner,%20M.%20B.%20&amp;%20Omigie,%20D.%20Correction:%20Music%20listening%20evokes%20story-like%20visual%20imagery%20with%20both%20idiosyncratic%20and%20shared%20content.%20PLoS%20ONE20,%20e0317174%20(2025).%C2%A010.1371/journal.pone.0317174" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR17">
<span class="label">17.</span><cite>Blackwell, S. E. Mental imagery: From basic research to clinical practice. <em>J. Psychother. Integr.</em><strong>29</strong>, 235–247 (2019). 10.1037/int0000108</cite> [<a href="https://scholar.google.com/scholar_lookup?Blackwell,%20S.%20E.%20Mental%20imagery:%20From%20basic%20research%20to%20clinical%20practice.%20J.%20Psychother.%20Integr.29,%20235%E2%80%93247%20(2019).%C2%A010.1037/int0000108" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR18">
<span class="label">18.</span><cite>Conti, F. &amp; Irish, M. Harnessing visual imagery and oculomotor behaviour to understand prospection. <em>Trends Cogn. Sci.</em><strong>25</strong>, 272–283 (2021). 10.1016/j.tics.2021.01.009
</cite> [<a href="https://doi.org/10.1016/j.tics.2021.01.009" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33618981/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Conti,%20F.%20&amp;%20Irish,%20M.%20Harnessing%20visual%20imagery%20and%20oculomotor%20behaviour%20to%20understand%20prospection.%20Trends%20Cogn.%20Sci.25,%20272%E2%80%93283%20(2021).%C2%A010.1016/j.tics.2021.01.009" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR19">
<span class="label">19.</span><cite>Holmes, E. A., Mathews, A., Dalgleish, T. &amp; Mackintosh, B. Positive interpretation training: Effects of mental imagery versus verbal training on positive mood. <em>Behav. Ther.</em><strong>37</strong>, 237–247 (2006). 10.1016/j.beth.2006.02.002
</cite> [<a href="https://doi.org/10.1016/j.beth.2006.02.002" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/16942975/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Holmes,%20E.%20A.,%20Mathews,%20A.,%20Dalgleish,%20T.%20&amp;%20Mackintosh,%20B.%20Positive%20interpretation%20training:%20Effects%20of%20mental%20imagery%20versus%20verbal%20training%20on%20positive%20mood.%20Behav.%20Ther.37,%20237%E2%80%93247%20(2006).%C2%A010.1016/j.beth.2006.02.002" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR20">
<span class="label">20.</span><cite>Bulley, A. &amp; Irish, M. The functions of prospection—Variations in health and disease. <em>Front. Psychol.</em><strong>9</strong>, 2328 (2018). 10.3389/fpsyg.2018.02328
</cite> [<a href="https://doi.org/10.3389/fpsyg.2018.02328" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6277467/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/30538655/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Bulley,%20A.%20&amp;%20Irish,%20M.%20The%20functions%20of%20prospection%E2%80%94Variations%20in%20health%20and%20disease.%20Front.%20Psychol.9,%202328%20(2018).%C2%A010.3389/fpsyg.2018.02328" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR21">
<span class="label">21.</span><cite>Knäuper, B. et al. Fruitful plans: Adding targeted mental imagery to implementation intentions increases fruit consumption. <em>Psychol. Health</em><strong>26</strong>, 601–617 (2011). 10.1080/08870441003703218
</cite> [<a href="https://doi.org/10.1080/08870441003703218" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/21337259/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Kn%C3%A4uper,%20B.%20et%20al.%20Fruitful%20plans:%20Adding%20targeted%20mental%20imagery%20to%20implementation%20intentions%20increases%20fruit%20consumption.%20Psychol.%20Health26,%20601%E2%80%93617%20(2011).%C2%A010.1080/08870441003703218" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR22">
<span class="label">22.</span><cite>Taruffi, L. &amp; Küssner, M. B. A review of music-evoked visual mental imagery: Conceptual issues, relation to emotion, and functional outcome. <em>Psychomusicol. Music Mind Brain</em><strong>29</strong>, 62–74 (2019). 10.1037/pmu0000226</cite> [<a href="https://scholar.google.com/scholar_lookup?Taruffi,%20L.%20&amp;%20K%C3%BCssner,%20M.%20B.%20A%20review%20of%20music-evoked%20visual%20mental%20imagery:%20Conceptual%20issues,%20relation%20to%20emotion,%20and%20functional%20outcome.%20Psychomusicol.%20Music%20Mind%20Brain29,%2062%E2%80%9374%20(2019).%C2%A010.1037/pmu0000226" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR23">
<span class="label">23.</span><cite>Hinton, D. E. &amp; Kirmayer, L. H. The flexibility hypothesis of healing. <em>Cult. Med. Psychiatry</em><strong>41</strong>, 3–34 (2017). 10.1007/s11013-016-9493-8
</cite> [<a href="https://doi.org/10.1007/s11013-016-9493-8" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27142641/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Hinton,%20D.%20E.%20&amp;%20Kirmayer,%20L.%20H.%20The%20flexibility%20hypothesis%20of%20healing.%20Cult.%20Med.%20Psychiatry41,%203%E2%80%9334%20(2017).%C2%A010.1007/s11013-016-9493-8" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR24">
<span class="label">24.</span><cite>Agawu, K. <em>The African Imagination in Music</em> (Oxford University Press, 2016). 10.1093/acprof:oso/9780190263201.001.0001.</cite> [<a href="https://scholar.google.com/scholar_lookup?Agawu,%20K.%20The%20African%20Imagination%20in%20Music%20(Oxford%20University%20Press,%202016).%2010.1093/acprof:oso/9780190263201.001.0001." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR25">
<span class="label">25.</span><cite>Friedson, S. M. <em>Dancing Prophets: Musical Experience in Tumbuka Healing</em> (University of Chicago Press, 1996).</cite> [<a href="https://scholar.google.com/scholar_lookup?Friedson,%20S.%20M.%20Dancing%20Prophets:%20Musical%20Experience%20in%20Tumbuka%20Healing%20(University%20of%20Chicago%20Press,%201996)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR26">
<span class="label">26.</span><cite>Kilchenmann, L. &amp; Senn, O. Microtiming in Swing and Funk affects the body movement behavior of music expert listeners. <em>Front. Psychol.</em><strong>6</strong>, 1232 (2015). 10.3389/fpsyg.2015.01232
</cite> [<a href="https://doi.org/10.3389/fpsyg.2015.01232" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4542135/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/26347694/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Kilchenmann,%20L.%20&amp;%20Senn,%20O.%20Microtiming%20in%20Swing%20and%20Funk%20affects%20the%20body%20movement%20behavior%20of%20music%20expert%20listeners.%20Front.%20Psychol.6,%201232%20(2015).%2010.3389/fpsyg.2015.01232" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR27">
<span class="label">27.</span><cite>Cano, E. &amp; Beveridge, S. Microtiming analysis in traditional Shetland fiddle music. In <em>Proceedings of the 20th International Society for Music Information Retrieval Conference (ISMIR 2019), Delft, The Netherlands</em> (2019).</cite>
</li>
<li id="CR28">
<span class="label">28.</span><cite>Iyer, V. Embodied mind, situated cognition, and expressive microtiming in African–American music. <em>Music. Percept.</em><strong>19</strong>, 387–414 (2002). 10.1525/mp.2002.19.3.387</cite> [<a href="https://scholar.google.com/scholar_lookup?Iyer,%20V.%20Embodied%20mind,%20situated%20cognition,%20and%20expressive%20microtiming%20in%20African%E2%80%93American%20music.%20Music.%20Percept.19,%20387%E2%80%93414%20(2002).%C2%A010.1525/mp.2002.19.3.387" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR29">
<span class="label">29.</span><cite>Richardson, A. <em>Mental Imagery</em> (Springer, 1969).</cite> [<a href="https://scholar.google.com/scholar_lookup?Richardson,%20A.%20Mental%20Imagery%20(Springer,%201969)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR30">
<span class="label">30.</span><cite>Kosslyn, S. M. Mental imagery. In <em>Visual Cognition: An Invitation to Cognitive Science, Vol. 2 (2nd edn)</em> (eds. Kosslyn, S. M. &amp; Osherson, D. N.) 267–296 (MIT Press, Cambridge, MA, 1995).</cite>
</li>
<li id="CR31">
<span class="label">31.</span><cite>MacKisack, M. et al. On picturing a candle: The prehistory of imagery science. <em>Front. Psychol.</em><strong>7</strong>, 515 (2016). 10.3389/fpsyg.2016.00515
</cite> [<a href="https://doi.org/10.3389/fpsyg.2016.00515" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4835444/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27148124/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?MacKisack,%20M.%20et%20al.%20On%20picturing%20a%20candle:%20The%20prehistory%20of%20imagery%20science.%20Front.%20Psychol.7,%20515%20(2016).%C2%A010.3389/fpsyg.2016.00515" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR32">
<span class="label">32.</span><cite>Schubert, T., Eloo, R., Scharfen, J. &amp; Morina, N. How imagining personal future scenarios influences affect: Systematic review and meta-analysis. <em>Clin. Psychol. Rev.</em><strong>75</strong>, 101811 (2020). 10.1016/j.cpr.2019.101811
</cite> [<a href="https://doi.org/10.1016/j.cpr.2019.101811" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31884148/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Schubert,%20T.,%20Eloo,%20R.,%20Scharfen,%20J.%20&amp;%20Morina,%20N.%20How%20imagining%20personal%20future%20scenarios%20influences%20affect:%20Systematic%20review%20and%20meta-analysis.%20Clin.%20Psychol.%20Rev.75,%20101811%20(2020).%C2%A010.1016/j.cpr.2019.101811" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR33">
<span class="label">33.</span><cite>Cumming, J. &amp; Hall, C. Deliberate imagery practice: The development of imagery skills in competitive athletes. <em>J. Sports Sci.</em><strong>20</strong>, 137–145 (2002). 10.1080/026404102317200846
</cite> [<a href="https://doi.org/10.1080/026404102317200846" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/11811570/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Cumming,%20J.%20&amp;%20Hall,%20C.%20Deliberate%20imagery%20practice:%20The%20development%20of%20imagery%20skills%20in%20competitive%20athletes.%20J.%20Sports%20Sci.20,%20137%E2%80%93145%20(2002).%C2%A010.1080/026404102317200846" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR34">
<span class="label">34.</span><cite>Honeycutt, J. M., Pecchioni, L., Keaton, S. A. &amp; Pence, M. E. Developmental implications of mental imagery in childhood imaginary companions. <em>Imagin. Cogn. Pers.</em><strong>31</strong>, 79–98 (2011). 10.2190/IC.31.1-2.h</cite> [<a href="https://scholar.google.com/scholar_lookup?Honeycutt,%20J.%20M.,%20Pecchioni,%20L.,%20Keaton,%20S.%20A.%20&amp;%20Pence,%20M.%20E.%20Developmental%20implications%20of%20mental%20imagery%20in%20childhood%20imaginary%20companions.%20Imagin.%20Cogn.%20Pers.31,%2079%E2%80%9398%20(2011).%C2%A010.2190/IC.31.1-2.h" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR35">
<span class="label">35.</span><cite>Mota, N. P. et al. Imagery vividness ratings during exposure treatment for posttraumatic stress disorder as a predictor of treatment outcome. <em>Behav. Res. Ther.</em><strong>69</strong>, 22–28 (2015). 10.1016/j.brat.2015.03.003
</cite> [<a href="https://doi.org/10.1016/j.brat.2015.03.003" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4425990/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/25863254/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Mota,%20N.%20P.%20et%20al.%20Imagery%20vividness%20ratings%20during%20exposure%20treatment%20for%20posttraumatic%20stress%20disorder%20as%20a%20predictor%20of%20treatment%20outcome.%20Behav.%20Res.%20Ther.69,%2022%E2%80%9328%20(2015).%C2%A010.1016/j.brat.2015.03.003" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR36">
<span class="label">36.</span><cite>Moritz, S. et al. We cannot change the past, but we can change its meaning. A randomized controlled trial on the effects of self-help imagery rescripting on depression. <em>Behav. Res. Therapy</em><strong>104</strong>, 74–83 (2018). 10.1016/j.brat.2018.02.007</cite> [<a href="https://doi.org/10.1016/j.brat.2018.02.007" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/29597112/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Moritz,%20S.%20et%20al.%20We%20cannot%20change%20the%20past,%20but%20we%20can%20change%20its%20meaning.%20A%20randomized%20controlled%20trial%20on%20the%20effects%20of%20self-help%20imagery%20rescripting%20on%20depression.%20Behav.%20Res.%20Therapy104,%2074%E2%80%9383%20(2018).%C2%A010.1016/j.brat.2018.02.007" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR37">
<span class="label">37.</span><cite>Rodrigues, J., Marzban, D. &amp; Hewig, J. The influence of mental imagery expertise of pen and paper players versus computer gamers upon performance and electrocortical correlates in a difficult mental rotation task. <em>Symmetry</em><strong>13</strong>, 2337 (2021). 10.3390/sym13122337</cite> [<a href="https://scholar.google.com/scholar_lookup?Rodrigues,%20J.,%20Marzban,%20D.%20&amp;%20Hewig,%20J.%20The%20influence%20of%20mental%20imagery%20expertise%20of%20pen%20and%20paper%20players%20versus%20computer%20gamers%20upon%20performance%20and%20electrocortical%20correlates%20in%20a%20difficult%20mental%20rotation%20task.%20Symmetry13,%202337%20(2021).%C2%A010.3390/sym13122337" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR38">
<span class="label">38.</span><cite>Fischer, R., Callander, R., Reddish, P. &amp; Bulbulia, J. How do rituals affect cooperation?. <em>Hum. Nat.</em><strong>24</strong>, 115–125 (2013). 10.1007/s12110-013-9167-y
</cite> [<a href="https://doi.org/10.1007/s12110-013-9167-y" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/23666518/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Fischer,%20R.,%20Callander,%20R.,%20Reddish,%20P.%20&amp;%20Bulbulia,%20J.%20How%20do%20rituals%20affect%20cooperation?.%20Hum.%20Nat.24,%20115%E2%80%93125%20(2013).%C2%A010.1007/s12110-013-9167-y" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR39">
<span class="label">39.</span><cite>Holmes, E. A., Arntz, A. &amp; Smucker, M. R. Imagery rescripting in cognitive behaviour therapy: Images, treatment techniques and outcomes. <em>J. Behav. Ther. Exp. Psychiatry</em><strong>38</strong>, 297–305 (2007). 10.1016/j.jbtep.2007.10.007
</cite> [<a href="https://doi.org/10.1016/j.jbtep.2007.10.007" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/18035331/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Holmes,%20E.%20A.,%20Arntz,%20A.%20&amp;%20Smucker,%20M.%20R.%20Imagery%20rescripting%20in%20cognitive%20behaviour%20therapy:%20Images,%20treatment%20techniques%20and%20outcomes.%20J.%20Behav.%20Ther.%20Exp.%20Psychiatry38,%20297%E2%80%93305%20(2007).%C2%A010.1016/j.jbtep.2007.10.007" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR40">
<span class="label">40.</span><cite>Brown, G. et al. Imagery re-scripting for PTSD: Session content and its relation to symptom improvement. <em>Behav. Cogn. Psychother.</em><strong>51</strong>, 1–10 (2023). 10.1017/S1352465822000479
</cite> [<a href="https://doi.org/10.1017/S1352465822000479" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36258276/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Brown,%20G.%20et%20al.%20Imagery%20re-scripting%20for%20PTSD:%20Session%20content%20and%20its%20relation%20to%20symptom%20improvement.%20Behav.%20Cogn.%20Psychother.51,%201%E2%80%9310%20(2023).%C2%A010.1017/S1352465822000479" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR41">
<span class="label">41.</span><cite>Küssner, M. B. &amp; Eerola, T. The content and functions of vivid and soothing visual imagery during music listening: Findings from a survey study. <em>Psychomusicol. Music Mind Brain</em><strong>29</strong>, 90–99 (2019). 10.1037/pmu0000238</cite> [<a href="https://scholar.google.com/scholar_lookup?K%C3%BCssner,%20M.%20B.%20&amp;%20Eerola,%20T.%20The%20content%20and%20functions%20of%20vivid%20and%20soothing%20visual%20imagery%20during%20music%20listening:%20Findings%20from%20a%20survey%20study.%20Psychomusicol.%20Music%20Mind%20Brain29,%2090%E2%80%9399%20(2019).%C2%A010.1037/pmu0000238" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR42">
<span class="label">42.</span><cite>Dahl, S., Stella, A. &amp; Bjørner, T. Tell me what you see: An exploratory investigation of visual mental imagery evoked by music. <em>Music. Sci.</em><strong>27</strong>, 717–740 (2022). 10.1177/10298649221124862</cite> [<a href="https://scholar.google.com/scholar_lookup?Dahl,%20S.,%20Stella,%20A.%20&amp;%20Bj%C3%B8rner,%20T.%20Tell%20me%20what%20you%20see:%20An%20exploratory%20investigation%20of%20visual%20mental%20imagery%20evoked%20by%20music.%20Music.%20Sci.27,%20717%E2%80%93740%20(2022).%C2%A010.1177/10298649221124862" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR43">
<span class="label">43.</span><cite>Deil, J. et al. Mind-wandering during contemporary live music: An exploratory study. <em>Music. Sci.</em><strong>0</strong>, 1–21 (2022). 10.1177/10298649221103210</cite> [<a href="https://scholar.google.com/scholar_lookup?Deil,%20J.%20et%20al.%20Mind-wandering%20during%20contemporary%20live%20music:%20An%20exploratory%20study.%20Music.%20Sci.0,%201%E2%80%9321%20(2022).%C2%A010.1177/10298649221103210" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR44">
<span class="label">44.</span><cite>Herff, S. A., McConnell, S., Ji, J. L. &amp; Prince, J. B. Eye closure interacts with music to influence vividness and content of directed imagery. <em>Music Sci.</em><strong>5</strong> (2022). 10.1177/20592043221142711</cite>
</li>
<li id="CR45">
<span class="label">45.</span><cite>Hashim, S., Stewart, L. &amp; Küssner, M. B. Saccadic eye-movements suppress visual mental imagery and partly reduce emotional response during music listening. <em>Music Sci.</em><strong>3</strong>, 2059204320959580 (2020). 10.1177/2059204320959580</cite> [<a href="https://scholar.google.com/scholar_lookup?Hashim,%20S.,%20Stewart,%20L.%20&amp;%20K%C3%BCssner,%20M.%20B.%20Saccadic%20eye-movements%20suppress%20visual%20mental%20imagery%20and%20partly%20reduce%20emotional%20response%20during%20music%20listening.%20Music%20Sci.3,%C2%A02059204320959580%20(2020).%C2%A010.1177/2059204320959580" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR46">
<span class="label">46.</span><cite>Taruffi, L., Ayyildiz, C. &amp; Herff, S. A. Thematic contents of mental imagery are shaped by concurrent task-irrelevant music. <em>Imagin. Cogn. Pers.</em><strong>43</strong>, 169–192 (2023). 10.1177/02762366231193145
</cite> [<a href="https://doi.org/10.1177/02762366231193145" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10620066/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37928803/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Taruffi,%20L.,%20Ayyildiz,%20C.%20&amp;%20Herff,%20S.%20A.%20Thematic%20contents%20of%20mental%20imagery%20are%20shaped%20by%20concurrent%20task-irrelevant%20music.%20Imagin.%20Cogn.%20Pers.43,%20169%E2%80%93192%20(2023).%C2%A010.1177/02762366231193145" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR47">
<span class="label">47.</span><cite>Ayyildiz, C. <em>et al.</em> Music as social surrogate? A qualitative analysis of older adults’ choices of music to alleviate loneliness. <em>Music. Sci. </em>10298649251319403 (2025). 10.1177/10298649251319403</cite>
</li>
<li id="CR48">
<span class="label">48.</span><cite>Herff, S.A., Cecchetti, G., Ericson, P. et al. Solitary silence and social sounds: music can influence mental imagery, inducing thoughts of social interactions. <em>Sci. Rep.</em><strong>15</strong>, 27583 (2025). 10.1038/s41598-025-10309-2</cite> [<a href="https://doi.org/10.1038/s41598-025-10309-2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC12307588/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/40730598/" class="usa-link">PubMed</a>]</li>
<li id="CR49">
<span class="label">49.</span><cite>Eitan, Z. &amp; Granot, R. Y. How music moves: Musical parameters and listeners images of motion. <em>Music. Percept.</em><strong>23</strong>, 221–248 (2006). 10.1525/mp.2006.23.3.221</cite> [<a href="https://scholar.google.com/scholar_lookup?Eitan,%20Z.%20&amp;%20Granot,%20R.%20Y.%20How%20music%20moves:%20Musical%20parameters%20and%20listeners%20images%20of%20motion.%20Music.%20Percept.23,%20221%E2%80%93248%20(2006).%C2%A010.1525/mp.2006.23.3.221" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR50">
<span class="label">50.</span><cite>Eitan, Z. &amp; Tubul, N. Musical parameters and children’s images of motion. <em>Music. Sci.</em><strong>14</strong>, 89–111 (2010). 10.1177/10298649100140S207</cite> [<a href="https://scholar.google.com/scholar_lookup?Eitan,%20Z.%20&amp;%20Tubul,%20N.%20Musical%20parameters%20and%20children%E2%80%99s%20images%20of%20motion.%20Music.%20Sci.14,%2089%E2%80%93111%20(2010).%C2%A010.1177/10298649100140S207" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR51">
<span class="label">51.</span><cite>Eitan, Z., Ornoy, E. &amp; Granot, R. Y. Listening in the dark: Congenital and early blindness and cross-domain mappings in music. <em>Psychomusicol. Music Mind Brain</em><strong>22</strong>, 33–45 (2012). 10.1037/a0028939</cite> [<a href="https://scholar.google.com/scholar_lookup?Eitan,%20Z.,%20Ornoy,%20E.%20&amp;%20Granot,%20R.%20Y.%20Listening%20in%20the%20dark:%20Congenital%20and%20early%20blindness%20and%20cross-domain%20mappings%20in%20music.%20Psychomusicol.%20Music%20Mind%20Brain22,%2033%E2%80%9345%20(2012).%C2%A010.1037/a0028939" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR52">
<span class="label">52.</span><cite>Maimon, N. B., Lamy, D. &amp; Eitan, Z. Space oddity: Musical syntax is mapped onto visual space. <em>Sci. Rep.</em><strong>11</strong>, 22343 (2021). 10.1038/s41598-021-01393-1
</cite> [<a href="https://doi.org/10.1038/s41598-021-01393-1" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8595729/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34785694/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Maimon,%20N.%20B.,%20Lamy,%20D.%20&amp;%20Eitan,%20Z.%20Space%20oddity:%20Musical%20syntax%20is%20mapped%20onto%20visual%20space.%20Sci.%20Rep.11,%2022343%20(2021).%C2%A010.1038/s41598-021-01393-1" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR53">
<span class="label">53.</span><cite>McKinney, C. H. &amp; Honig, T. J. Health outcomes of a series of bonny method of guided imagery and music sessions: A systematic review. <em>J. Music Ther.</em><strong>54</strong>, 1–34 (2016). 10.1093/jmt/thw016</cite> [<a href="https://doi.org/10.1093/jmt/thw016" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27941132/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?McKinney,%20C.%20H.%20&amp;%20Honig,%20T.%20J.%20Health%20outcomes%20of%20a%20series%20of%20bonny%20method%20of%20guided%20imagery%20and%20music%20sessions:%20A%20systematic%20review.%20J.%20Music%20Ther.54,%201%E2%80%9334%20(2016).%C2%A010.1093/jmt/thw016" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR54">
<span class="label">54.</span><cite>Taruffi, L. Mind-wandering during personal music listening in everyday life: music-evoked emotions predict thought valence. <em>Int. J. Environ. Res. Public Health</em><strong>18</strong>, 12321 (2021). 10.3390/ijerph182312321
</cite> [<a href="https://doi.org/10.3390/ijerph182312321" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8656507/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34886046/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Taruffi,%20L.%20Mind-wandering%20during%20personal%20music%20listening%20in%20everyday%20life:%20music-evoked%20emotions%20predict%20thought%20valence.%20Int.%20J.%20Environ.%20Res.%20Public%20Health18,%2012321%20(2021).%C2%A010.3390/ijerph182312321" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR55">
<span class="label">55.</span><cite>Talamini, F., Vigl, J., Doerr, E., Grassi, M. &amp; Carretti, B. Auditory and visual mental imagery in musicians and non-musicians. <em>Music. Sci.</em><strong>27</strong>, 428–441 (2023). 10.1177/10298649211062724</cite> [<a href="https://scholar.google.com/scholar_lookup?Talamini,%20F.,%20Vigl,%20J.,%20Doerr,%20E.,%20Grassi,%20M.%20&amp;%20Carretti,%20B.%20Auditory%20and%20visual%20mental%20imagery%20in%20musicians%20and%20non-musicians.%20Music.%20Sci.27,%20428%E2%80%93441%20(2023).%C2%A010.1177/10298649211062724" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR56">
<span class="label">56.</span><cite>Vroegh, T. Music-evoked imagery in an absorbed state of mind: A Bayesian network approach. In <em>Music and Mental Imagery </em>(eds. Küssner, M. B., Taruffi, L. &amp; Floridou, G. A.) 189–198 (Routledge, 2022).</cite> [<a href="https://scholar.google.com/scholar_lookup?Vroegh,%20T.%20Music-evoked%20imagery%20in%20an%20absorbed%20state%20of%20mind:%20A%20Bayesian%20network%20approach.%20In%20Music%20and%20Mental%20Imagery%20(eds.%20K%C3%BCssner,%20M.%20B.,%20Taruffi,%20L.%20&amp;%20Floridou,%20G.%20A.)%C2%A0189%E2%80%93198%20(Routledge,%202022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR57">
<span class="label">57.</span><cite>Polak, R., London, J. &amp; Jacoby, N. Both isochronous and non-isochronous metrical subdivision afford precise and stable ensemble entrainment: A Corpus study of Malian Jembe drumming. <em>Front. Neurosci.</em><strong>10</strong>, 285 (2016). 10.3389/fnins.2016.00285
</cite> [<a href="https://doi.org/10.3389/fnins.2016.00285" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4923149/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27445659/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Polak,%20R.,%20London,%20J.%20&amp;%20Jacoby,%20N.%20Both%20isochronous%20and%20non-isochronous%20metrical%20subdivision%20afford%20precise%20and%20stable%20ensemble%20entrainment:%20A%20Corpus%20study%20of%20Malian%20Jembe%20drumming.%20Front.%20Neurosci.10,%20285%20(2016).%2010.3389/fnins.2016.00285" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR58">
<span class="label">58.</span><cite>Reiss, N. et al. Effects of cognitive behavioral therapy with relaxation vs. imagery rescripting on test anxiety: A randomized controlled trial. <em>J. Affect. Disord.</em><strong>208</strong>, 483–489 (2017). 10.1016/j.jad.2016.10.039
</cite> [<a href="https://doi.org/10.1016/j.jad.2016.10.039" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27825724/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Reiss,%20N.%20et%20al.%20Effects%20of%20cognitive%20behavioral%20therapy%20with%20relaxation%20vs.%20imagery%20rescripting%20on%20test%20anxiety:%20A%20randomized%20controlled%20trial.%20J.%20Affect.%20Disord.208,%20483%E2%80%93489%20(2017).%C2%A010.1016/j.jad.2016.10.039" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR59">
<span class="label">59.</span><cite>Etani, T. et al. A review of psychological and neuroscientific research on musical groove. <em>Neurosci. Biobehav. Rev.</em><strong>158</strong>, 105522 (2024). 10.1016/j.neubiorev.2023.105522
</cite> [<a href="https://doi.org/10.1016/j.neubiorev.2023.105522" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38141692/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Etani,%20T.%20et%20al.%20A%20review%20of%20psychological%20and%20neuroscientific%20research%20on%20musical%20groove.%20Neurosci.%20Biobehav.%20Rev.158,%20105522%20(2024).%C2%A010.1016/j.neubiorev.2023.105522" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR60">
<span class="label">60.</span><cite>Chernoff, J. M. <em>African Rhythm and African Sensibility: Aesthetics and Social Action in African Musical Idioms</em> (University of Chicago Press, 1979).</cite> [<a href="https://scholar.google.com/scholar_lookup?Chernoff,%20J.%20M.%20African%20Rhythm%20and%20African%20Sensibility:%20Aesthetics%20and%20Social%20Action%20in%20African%20Musical%20Idioms%20(University%20of%20Chicago%20Press,%201979)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR61">
<span class="label">61.</span><cite>Drake, C., Penel, A. &amp; Bigand, E. Tapping in time with mechanically and expressively performed music. <em>Music. Percept.</em><strong>18</strong>, 1–23 (2000). 10.2307/40285899</cite> [<a href="https://scholar.google.com/scholar_lookup?Drake,%20C.,%20Penel,%20A.%20&amp;%20Bigand,%20E.%20Tapping%20in%20time%20with%20mechanically%20and%20expressively%20performed%20music.%20Music.%20Percept.18,%201%E2%80%9323%20(2000).%C2%A010.2307/40285899" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR62">
<span class="label">62.</span><cite>Stamatatos, E. Quantifying the differences between music performers: Score vs. norm. In <em>Proceedings of the International Computer Music Conference (ICMC 2002), Göteborg, Sweden</em>, 376–382 (2002).</cite>
</li>
<li id="CR63">
<span class="label">63.</span><cite>Drake, C., Jones, M. R. &amp; Baruch, C. The development of rhythmic attending in auditory sequences: Attunement, referent period, focal attending. <em>Cognition</em><strong>77</strong>, 251–288 (2000). 10.1016/S0010-0277(00)00106-2
</cite> [<a href="https://doi.org/10.1016/s0010-0277(00)00106-2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/11018511/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Drake,%20C.,%20Jones,%20M.%20R.%20&amp;%20Baruch,%20C.%20The%20development%20of%20rhythmic%20attending%20in%20auditory%20sequences:%20Attunement,%20referent%20period,%20focal%20attending.%20Cognition77,%20251%E2%80%93288%20(2000).%C2%A010.1016/S0010-0277(00)00106-2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR64">
<span class="label">64.</span><cite>Hove, M. J., Keller, P. E. &amp; Krumhansl, C. L. Sensorimotor synchronization with chords containing tone-onset asynchronies. <em>Percept. Psychophys.</em><strong>69</strong>, 699–708 (2007). 10.3758/BF03193772
</cite> [<a href="https://doi.org/10.3758/bf03193772" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/17929693/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Hove,%20M.%20J.,%20Keller,%20P.%20E.%20&amp;%20Krumhansl,%20C.%20L.%20Sensorimotor%20synchronization%20with%20chords%20containing%20tone-onset%20asynchronies.%20Percept.%20Psychophys.69,%20699%E2%80%93708%20(2007).%C2%A010.3758/BF03193772" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR65">
<span class="label">65.</span><cite>Jakubowski, K., Polak, R., Rocamora, M., Jure, L. &amp; Jacoby, N. Aesthetics of musical timing: Culture and expertise affect preferences for isochrony but not synchrony. <em>Cognition</em><strong>227</strong>, 105205 (2022). 10.1016/j.cognition.2022.105205
</cite> [<a href="https://doi.org/10.1016/j.cognition.2022.105205" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35724531/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Jakubowski,%20K.,%20Polak,%20R.,%20Rocamora,%20M.,%20Jure,%20L.%20&amp;%20Jacoby,%20N.%20Aesthetics%20of%20musical%20timing:%20Culture%20and%20expertise%20affect%20preferences%20for%20isochrony%20but%20not%20synchrony.%20Cognition227,%20105205%20(2022).%C2%A010.1016/j.cognition.2022.105205" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR66">
<span class="label">66.</span><cite>Danielsen, A. et al. There’s more to timing than time: Investigating musical microrhythm across disciplines and cultures. <em>Music. Percept.</em><strong>41</strong>, 176–198 (2024). 10.1525/mp.2024.41.3.176</cite> [<a href="https://scholar.google.com/scholar_lookup?Danielsen,%20A.%20et%20al.%20There%E2%80%99s%20more%20to%20timing%20than%20time:%20Investigating%20musical%20microrhythm%20across%20disciplines%20and%20cultures.%20Music.%20Percept.41,%20176%E2%80%93198%20(2024).%C2%A010.1525/mp.2024.41.3.176" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR67">
<span class="label">67.</span><cite>Dahl, S. Movements, Timing, and Precision of Drummers. In <em>Handbook of Human Motion </em>(eds. Müller, B. &amp; Wolf, S.) 1839–1857 (Springer, 2018). 10.1007/978-3-319-14418-4_110</cite>
</li>
<li id="CR68">
<span class="label">68.</span><cite>Buck, B., Beveridge, S., Breaden Madden, G. &amp; Jabusch, H.-C. Expertise- and tempo-related performance differences in unimanual drumming. <em>Mot. Control</em><strong>25</strong>, 644–679. 10.1123/mc.2020-0029 (2021).</cite> [<a href="https://doi.org/10.1123/mc.2020-0029" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34544901/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Buck,%20B.,%20Beveridge,%20S.,%20Breaden%20Madden,%20G.%20&amp;%20Jabusch,%20H.-C.%20Expertise-%20and%20tempo-related%20performance%20differences%20in%20unimanual%20drumming.%20Mot.%20Control25,%20644%E2%80%93679.%2010.1123/mc.2020-0029%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR69">
<span class="label">69.</span><cite>Herff, S. A., Breaden Madden, G., Beveridge, S., Altenmüller, E. &amp; Jabusch, H.-C. Muscle Physiology in Drumming: Characteristic patterns of wrist muscle activation are predicted by drummers’ level of expertise. <em>Preprint</em> at <a href="https://osf.io/mt5za/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://osf.io/mt5za/</a> (2025).</cite>
</li>
<li id="CR70">
<span class="label">70.</span><cite>Duke, R. A., Cash, C. D. &amp; Allen, S. E. Focus of attention affects performance of motor skills in music. <em>J. Res. Music Educ.</em><strong>59</strong>, 44–55 (2011). 10.1177/0022429410396093</cite> [<a href="https://scholar.google.com/scholar_lookup?Duke,%20R.%20A.,%20Cash,%20C.%20D.%20&amp;%20Allen,%20S.%20E.%20Focus%20of%20attention%20affects%20performance%20of%20motor%20skills%20in%20music.%20J.%20Res.%20Music%20Educ.59,%2044%E2%80%9355%20(2011).%C2%A010.1177/0022429410396093" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR71">
<span class="label">71.</span><cite>Goldberg, D. Timing variations in two Balkan percussion performances. <em>EMR</em><strong>10</strong>, 305–328 (2016).10.18061/emr.v10i4.4884</cite> [<a href="https://scholar.google.com/scholar_lookup?Goldberg,%20D.%20Timing%20variations%20in%20two%20Balkan%20percussion%20performances.%20EMR10,%20305%E2%80%93328%20(2016).10.18061/emr.v10i4.4884" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR72">
<span class="label">72.</span><cite>Goubault, E. et al. Exhausting repetitive piano tasks lead to local forearm manifestation of muscle fatigue and negatively affect musical parameters. <em>Sci. Rep.</em><strong>11</strong>, 8117 (2021). 10.1038/s41598-021-87403-8
</cite> [<a href="https://doi.org/10.1038/s41598-021-87403-8" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8047012/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33854088/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Goubault,%20E.%20et%20al.%20Exhausting%20repetitive%20piano%20tasks%20lead%20to%20local%20forearm%20manifestation%20of%20muscle%20fatigue%20and%20negatively%20affect%20musical%20parameters.%20Sci.%20Rep.11,%208117%20(2021).%C2%A010.1038/s41598-021-87403-8" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR73">
<span class="label">73.</span><cite>Hadley, L. V. &amp; Ward, J. A. Synchrony as a measure of conversation difficulty: Movement coherence increases with background noise level and complexity in dyads and triads. <em>PLoS ONE</em><strong>16</strong>, 1–13 (2021). 10.1371/journal.pone.0258247</cite> [<a href="https://doi.org/10.1371/journal.pone.0258247" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8491905/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34610018/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Hadley,%20L.%20V.%20&amp;%20Ward,%20J.%20A.%20Synchrony%20as%20a%20measure%20of%20conversation%20difficulty:%20Movement%20coherence%20increases%20with%20background%20noise%20level%20and%20complexity%20in%20dyads%20and%20triads.%20PLoS%20ONE16,%201%E2%80%9313%20(2021).%C2%A010.1371/journal.pone.0258247" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR74">
<span class="label">74.</span><cite>Hennig, H. et al. The nature and perception of fluctuations in human musical rhythms. <em>PLoS ONE</em><strong>6</strong>, 1–7 (2011). 10.1371/journal.pone.0026457</cite> [<a href="https://doi.org/10.1371/journal.pone.0026457" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3202537/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/22046289/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Hennig,%20H.%20et%20al.%20The%20nature%20and%20perception%20of%20fluctuations%20in%20human%20musical%20rhythms.%20PLoS%20ONE6,%201%E2%80%937%20(2011).%C2%A010.1371/journal.pone.0026457" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR75">
<span class="label">75.</span><cite>Skaansar, J. F., Laeng, B. &amp; Danielsen, A. Microtiming and mental effort: Onset asynchronies in musical rhythm modulate pupil size. <em>Music Percept. Interdiscip. J.</em><strong>37</strong>, 111–133 (2019). 10.1525/mp.2019.37.2.111</cite> [<a href="https://scholar.google.com/scholar_lookup?Skaansar,%20J.%20F.,%20Laeng,%20B.%20&amp;%20Danielsen,%20A.%20Microtiming%20and%20mental%20effort:%20Onset%20asynchronies%20in%20musical%20rhythm%20modulate%20pupil%20size.%20Music%20Percept.%20Interdiscip.%20J.37,%20111%E2%80%93133%20(2019).%C2%A010.1525/mp.2019.37.2.111" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR76">
<span class="label">76.</span><cite>Cameron, D. J. et al. Neural entrainment is associated with subjective groove and complexity for performed but not mechanical musical rhythms. <em>Exp. Brain Res.</em><strong>237</strong>, 1981–1991 (2019). 10.1007/s00221-019-05557-4
</cite> [<a href="https://doi.org/10.1007/s00221-019-05557-4" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6647194/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31152188/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Cameron,%20D.%20J.%20et%20al.%20Neural%20entrainment%20is%20associated%20with%20subjective%20groove%20and%20complexity%20for%20performed%20but%20not%20mechanical%20musical%20rhythms.%20Exp.%20Brain%20Res.237,%201981%E2%80%931991%20(2019).%C2%A010.1007/s00221-019-05557-4" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR77">
<span class="label">77.</span><cite>Harner, M. J. <em>The Way of the Shaman: A Guide to Power and Healing</em> (Harper &amp; Row, 1990).</cite> [<a href="https://scholar.google.com/scholar_lookup?Harner,%20M.%20J.%20The%20Way%20of%20the%20Shaman:%20A%20Guide%20to%20Power%20and%20Healing%20(Harper%20&amp;%20Row,%201990)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR78">
<span class="label">78.</span><cite>Huels, E. R. et al. Neural correlates of the shamanic state of consciousness. <em>Front. Hum. Neurosci.</em><strong>15</strong>, 610466 (2021). 10.3389/fnhum.2021.610466
</cite> [<a href="https://doi.org/10.3389/fnhum.2021.610466" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8012721/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33815077/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Huels,%20E.%20R.%20et%20al.%20Neural%20correlates%20of%20the%20shamanic%20state%20of%20consciousness.%20Front.%20Hum.%20Neurosci.15,%20610466%20(2021).%C2%A010.3389/fnhum.2021.610466" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR79">
<span class="label">79.</span><cite>Hove, M. J. et al. Brain network reconfiguration and perceptual decoupling during an absorptive state of consciousness. <em>Cereb. Cortex</em><strong>26</strong>, 3116–3124 (2015). 10.1093/cercor/bhv137
</cite> [<a href="https://doi.org/10.1093/cercor/bhv137" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4898667/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/26108612/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Hove,%20M.%20J.%20et%20al.%20Brain%20network%20reconfiguration%20and%20perceptual%20decoupling%20during%20an%20absorptive%20state%20of%20consciousness.%20Cereb.%20Cortex26,%203116%E2%80%933124%20(2015).%C2%A010.1093/cercor/bhv137" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR80">
<span class="label">80.</span><cite>Maurer, S. R. L., Kumar, V. K., Woodside, L. &amp; Pekala, R. J. Phenomenological experience in response to monotonous drumming and hypnotizability. <em>Am. J. Clin. Hypn.</em><strong>40</strong>, 130–145 (1997). 10.1080/00029157.1997.10403417
</cite> [<a href="https://doi.org/10.1080/00029157.1997.10403417" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/9385724/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Maurer,%20S.%20R.%20L.,%20Kumar,%20V.%20K.,%20Woodside,%20L.%20&amp;%20Pekala,%20R.%20J.%20Phenomenological%20experience%20in%20response%20to%20monotonous%20drumming%20and%20hypnotizability.%20Am.%20J.%20Clin.%20Hypn.40,%20130%E2%80%93145%20(1997).%C2%A010.1080/00029157.1997.10403417" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR81">
<span class="label">81.</span><cite>Flor-Henry, P., Shapiro, Y. &amp; Sombrun, C. Brain changes during a shamanic trance: Altered modes of consciousness, hemispheric laterality, and systemic psychobiology. <em>Cogent Psychol.</em><strong>4</strong>, 1313522 (2017). 10.1080/23311908.2017.1313522</cite> [<a href="https://scholar.google.com/scholar_lookup?Flor-Henry,%20P.,%20Shapiro,%20Y.%20&amp;%20Sombrun,%20C.%20Brain%20changes%20during%20a%20shamanic%20trance:%20Altered%20modes%20of%20consciousness,%20hemispheric%20laterality,%20and%20systemic%20psychobiology.%20Cogent%20Psychol.4,%201313522%20(2017).%C2%A010.1080/23311908.2017.1313522" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR82">
<span class="label">82.</span><cite>Kjellgren, A. &amp; Eriksson, A. Altered states during shamanic drumming: A phenomenological study. <em>Int. J. Transpers. Stud.</em><strong>29</strong>, 1–10 (2010). 10.24972/ijts.2010.29.2.1</cite> [<a href="https://scholar.google.com/scholar_lookup?Kjellgren,%20A.%20&amp;%20Eriksson,%20A.%20Altered%20states%20during%20shamanic%20drumming:%20A%20phenomenological%20study.%20Int.%20J.%20Transpers.%20Stud.29,%201%E2%80%9310%20(2010).%C2%A010.24972/ijts.2010.29.2.1" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR83">
<span class="label">83.</span><cite>Kirby, T. &amp; Sandler, M. The evolution of drum modes with strike intensity: Analysis and synthesis using the discrete cosine transform. <em>J. Acoust. Soc. Am.</em><strong>150</strong>, 202–214 (2021). 10.1121/10.0005509
</cite> [<a href="https://doi.org/10.1121/10.0005509" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34340487/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Kirby,%20T.%20&amp;%20Sandler,%20M.%20The%20evolution%20of%20drum%20modes%20with%20strike%20intensity:%20Analysis%20and%20synthesis%20using%20the%20discrete%20cosine%20transform.%20J.%20Acoust.%20Soc.%20Am.150,%20202%E2%80%93214%20(2021).%C2%A010.1121/10.0005509" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR84">
<span class="label">84.</span><cite>Russell, J. The ‘acoustic object synthesizer’ is back. So what’s new with this version of AAS’s physical modeling instrument?. <em>Electron. Music.</em><strong>37</strong>, 51–52 (2021).</cite> [<a href="https://scholar.google.com/scholar_lookup?Russell,%20J.%20The%20%E2%80%98acoustic%20object%20synthesizer%E2%80%99%20is%20back.%20So%20what%E2%80%99s%20new%20with%20this%20version%20of%20AAS%E2%80%99s%20physical%20modeling%20instrument?.%20Electron.%20Music.37,%2051%E2%80%9352%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR85">
<span class="label">85.</span><cite>Milne, A. J. &amp; Herff, S. A. The perceptual relevance of balance, evenness, and entropy in musical rhythms. <em>Cognition</em><strong>203</strong>, 104233 (2020). 10.1016/j.cognition.2020.104233
</cite> [<a href="https://doi.org/10.1016/j.cognition.2020.104233" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32629203/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Milne,%20A.%20J.%20&amp;%20Herff,%20S.%20A.%20The%20perceptual%20relevance%20of%20balance,%20evenness,%20and%20entropy%20in%20musical%20rhythms.%20Cognition203,%20104233%20(2020).%C2%A010.1016/j.cognition.2020.104233" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR86">
<span class="label">86.</span><cite>Loper, E. &amp; Bird, S. NLTK: The Natural Language Toolkit. <em>arXiv preprint cs/0205028</em> (2002). 10.48550/ARXIV.CS/0205028</cite>
</li>
<li id="CR87">
<span class="label">87.</span><cite>Hutto, C. &amp; Gilbert, E. VADER: A parsimonious rule-based model for sentiment analysis of social media text. <em>Proc. Int. AAAI Conf. Web Soc. Med.</em><strong>8</strong>, 216–225 (2014). 10.1609/icwsm.v8i1.14550</cite> [<a href="https://scholar.google.com/scholar_lookup?Hutto,%20C.%20&amp;%20Gilbert,%20E.%20VADER:%20A%20parsimonious%20rule-based%20model%20for%20sentiment%20analysis%20of%20social%20media%20text.%20Proc.%20Int.%20AAAI%20Conf.%20Web%20Soc.%20Med.8,%20216%E2%80%93225%20(2014).%C2%A010.1609/icwsm.v8i1.14550" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR88">
<span class="label">88.</span><cite>Tellegen, A. Brief manual for the Multidimensional Personality Questionnaire. (1982).</cite>
</li>
<li id="CR89">
<span class="label">89.</span><cite>Marks, D. F. Vividness of visual imagery questionnaire (VVIQ). <em>APA PsycTests</em> (1973). 10.1037/t05959-000</cite> [<a href="https://scholar.google.com/scholar_lookup?Marks,%20D.%20F.%20Vividness%20of%20visual%20imagery%20questionnaire%20(VVIQ).%20APA%20PsycTests%20(1973).%2010.1037/t05959-000" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR90">
<span class="label">90.</span><cite>Müllensiefen, D., Gingras, B., Musil, J. &amp; Stewart, L. The musicality of non-musicians: An index for assessing musical sophistication in the general population. <em>PLoS ONE</em><strong>9</strong>, e89642 (2014). 10.1371/journal.pone.0101091
</cite> [<a href="https://doi.org/10.1371/journal.pone.0089642" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3935919/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/24586929/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?M%C3%BCllensiefen,%20D.,%20Gingras,%20B.,%20Musil,%20J.%20&amp;%20Stewart,%20L.%20The%20musicality%20of%20non-musicians:%20An%20index%20for%20assessing%20musical%20sophistication%20in%20the%20general%20population.%20PLoS%20ONE9,%20e89642%20(2014).%2010.1371/journal.pone.0101091" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR91">
<span class="label">91.</span><cite>Curwen, C., Timmers, R. &amp; Schiavio, A. Action, emotion, and music-colour synaesthesia: an examination of sensorimotor and emotional responses in synaesthetes and non-synaesthetes. <em>Psychol. Res.</em><strong>88</strong>, 348–362 (2024). 10.1007/s00426-023-01856-2
</cite> [<a href="https://doi.org/10.1007/s00426-023-01856-2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10857979/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37453940/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Curwen,%20C.,%20Timmers,%20R.%20&amp;%20Schiavio,%20A.%20Action,%20emotion,%20and%20music-colour%20synaesthesia:%20an%20examination%20of%20sensorimotor%20and%20emotional%20responses%20in%20synaesthetes%20and%20non-synaesthetes.%20Psychol.%20Res.88,%20348%E2%80%93362%20(2024).%C2%A010.1007/s00426-023-01856-2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR92">
<span class="label">92.</span><cite>Cheng, S., Milne, A. J., Dean, R. T., Hanham, J. &amp; MacRitchie, J. Exploring the comprehensibility of ten different musical notation systems and underlying factors. <em>Music Sci.</em> <strong>7</strong>, 20592043241292952 (2024). 10.1177/2059204324129295</cite> [<a href="https://scholar.google.com/scholar_lookup?Cheng,%20S.,%20Milne,%20A.%20J.,%20Dean,%20R.%20T.,%20Hanham,%20J.%20&amp;%20MacRitchie,%20J.%20Exploring%20the%20comprehensibility%20of%20ten%20different%20musical%20notation%20systems%20and%20underlying%20factors.%20Music%20Sci.%C2%A07,%2020592043241292952%20(2024).%C2%A010.1177/2059204324129295" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR93">
<span class="label">93.</span><cite>Koelsch, S. Brain correlates of music-evoked emotions. <em>Nat. Rev. Neurosci.</em><strong>15</strong>, 170–180 (2014). 10.1038/nrn3666
</cite> [<a href="https://doi.org/10.1038/nrn3666" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/24552785/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Koelsch,%20S.%20Brain%20correlates%20of%20music-evoked%20emotions.%20Nat.%20Rev.%20Neurosci.15,%20170%E2%80%93180%20(2014).%C2%A010.1038/nrn3666" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR94">
<span class="label">94.</span><cite>Menon, V. &amp; Levitin, D. J. The rewards of music listening: Response and physiological connectivity of the mesolimbic system. <em>Neuroimage</em><strong>28</strong>, 175–184 (2005). 10.1016/j.neuroimage.2005.05.053
</cite> [<a href="https://doi.org/10.1016/j.neuroimage.2005.05.053" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/16023376/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Menon,%20V.%20&amp;%20Levitin,%20D.%20J.%20The%20rewards%20of%20music%20listening:%20Response%20and%20physiological%20connectivity%20of%20the%20mesolimbic%20system.%20Neuroimage28,%20175%E2%80%93184%20(2005).%C2%A010.1016/j.neuroimage.2005.05.053" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR95">
<span class="label">95.</span><cite>Tallon, K., Ovanessian, M. M., Koerner, N. &amp; Dugas, M. J. Mental imagery in generalized anxiety disorder: A comparison with healthy control participants. <em>Behav. Res. Ther.</em><strong>127</strong>, 103571 (2020). 10.1016/j.brat.2020.103571
</cite> [<a href="https://doi.org/10.1016/j.brat.2020.103571" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32087392/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Tallon,%20K.,%20Ovanessian,%20M.%20M.,%20Koerner,%20N.%20&amp;%20Dugas,%20M.%20J.%20Mental%20imagery%20in%20generalized%20anxiety%20disorder:%20A%20comparison%20with%20healthy%20control%20participants.%20Behav.%20Res.%20Ther.127,%20103571%20(2020).%2010.1016/j.brat.2020.103571" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR96">
<span class="label">96.</span><cite>Crivelli-Decker, J. et al. Goal-oriented representations in the human hippocampus during planning and navigation. <em>Nat. Commun.</em><strong>14</strong>, 2946 (2023). 10.1038/s41467-023-35967-6
</cite> [<a href="https://doi.org/10.1038/s41467-023-35967-6" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10206082/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37221176/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Crivelli-Decker,%20J.%20et%20al.%20Goal-oriented%20representations%20in%20the%20human%20hippocampus%20during%20planning%20and%20navigation.%20Nat.%20Commun.14,%202946%20(2023).%C2%A010.1038/s41467-023-35967-6" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR97">
<span class="label">97.</span><cite>Slater, J., Ashley, R., Tierney, A. &amp; Kraus, N. Got rhythm? Better inhibitory control is linked with more consistent drumming and enhanced neural tracking of the musical beat in adult percussionists and nonpercussionists. <em>J. Cogn. Neurosci.</em><strong>30</strong>, 14–24 (2018). 10.1162/jocn_a_01189
</cite> [<a href="https://doi.org/10.1162/jocn_a_01189" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/28949825/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Slater,%20J.,%20Ashley,%20R.,%20Tierney,%20A.%20&amp;%20Kraus,%20N.%20Got%20rhythm?%20Better%20inhibitory%20control%20is%20linked%20with%20more%20consistent%20drumming%20and%20enhanced%20neural%20tracking%20of%20the%20musical%20beat%20in%20adult%20percussionists%20and%20nonpercussionists.%20J.%20Cogn.%20Neurosci.30,%2014%E2%80%9324%20(2018).%C2%A010.1162/jocn_a_01189" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR98">
<span class="label">98.</span><cite>Margulis, E. H. Repetition and emotive communication in music versus speech. <em>Front. Psychol.</em><strong>4</strong>, 167 (2013). 10.3389/fpsyg.2013.00167
</cite> [<a href="https://doi.org/10.3389/fpsyg.2013.00167" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3616255/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/23576998/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Margulis,%20E.%20H.%20Repetition%20and%20emotive%20communication%20in%20music%20versus%20speech.%20Front.%20Psychol.4,%20167%20(2013).%C2%A010.3389/fpsyg.2013.00167" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR99">
<span class="label">99.</span><cite>Ross, J. M. &amp; Balasubramaniam, R. Time perception for musical rhythms: Sensorimotor perspectives on entrainment, simulation, and prediction. <em>Front. Integr. Neurosci.</em><strong>16</strong>, 916220 (2022). 10.3389/fnint.2022.916220
</cite> [<a href="https://doi.org/10.3389/fnint.2022.916220" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9294366/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35865808/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Ross,%20J.%20M.%20&amp;%20Balasubramaniam,%20R.%20Time%20perception%20for%20musical%20rhythms:%20Sensorimotor%20perspectives%20on%20entrainment,%20simulation,%20and%20prediction.%20Front.%20Integr.%20Neurosci.16,%20916220%20(2022).%C2%A010.3389/fnint.2022.916220" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR100">
<span class="label">100.</span><cite>Beveridge, S., Cano, E. &amp; Herff, S. A. The effect of low-frequency equalisation on preference and sensorimotor synchronisation in music. <em>Q. J. Exp. Psychol.</em><strong>75</strong>, 475–490 (2022). 10.1177/17470218211037145</cite> [<a href="https://doi.org/10.1177/17470218211037145" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34293989/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Beveridge,%20S.,%20Cano,%20E.%20&amp;%20Herff,%20S.%20A.%20The%20effect%20of%20low-frequency%20equalisation%20on%20preference%20and%20sensorimotor%20synchronisation%20in%20music.%20Q.%20J.%20Exp.%20Psychol.75,%20475%E2%80%93490%20(2022).%C2%A010.1177/17470218211037145" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR101">
<span class="label">101.</span><cite>Gold, B. P., Pearce, M. T., Mas-Herrero, E., Dagher, A. &amp; Zatorre, R. J. Predictability and uncertainty in the pleasure of music: A reward for learning?. <em>J. Neurosci.</em><strong>39</strong>, 9397–9409 (2019). 10.1523/JNEUROSCI.0428-19.2019
</cite> [<a href="https://doi.org/10.1523/JNEUROSCI.0428-19.2019" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6867811/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31636112/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Gold,%20B.%20P.,%20Pearce,%20M.%20T.,%20Mas-Herrero,%20E.,%20Dagher,%20A.%20&amp;%20Zatorre,%20R.%20J.%20Predictability%20and%20uncertainty%20in%20the%20pleasure%20of%20music:%20A%20reward%20for%20learning?.%20J.%20Neurosci.39,%209397%E2%80%939409%20(2019).%C2%A010.1523/JNEUROSCI.0428-19.2019" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR102">
<span class="label">102.</span><cite>Matthews, W. J. Stimulus repetition and the perception of time: The effects of prior exposure on temporal discrimination, judgment, and production. <em>PLoS ONE</em><strong>6</strong>, 1–7 (2011). 10.1371/journal.pone.0019815</cite> [<a href="https://doi.org/10.1371/journal.pone.0019815" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3090413/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/21573020/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Matthews,%20W.%20J.%20Stimulus%20repetition%20and%20the%20perception%20of%20time:%20The%20effects%20of%20prior%20exposure%20on%20temporal%20discrimination,%20judgment,%20and%20production.%20PLoS%20ONE6,%201%E2%80%937%20(2011).%C2%A010.1371/journal.pone.0019815" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR103">
<span class="label">103.</span><cite>Kawabata, M. &amp; Chatzisarantis, N. L. D. Does time fly when you engage more? Effort intensity moderates the relationship between affect and time perception. <em>Curr. Psychol.</em><strong>42</strong>, 20814–20823 (2023). 10.1007/s12144-022-03191-y</cite> [<a href="https://scholar.google.com/scholar_lookup?Kawabata,%20M.%20&amp;%20Chatzisarantis,%20N.%20L.%20D.%20Does%20time%20fly%20when%20you%20engage%20more?%20Effort%20intensity%20moderates%20the%20relationship%20between%20affect%20and%20time%20perception.%20Curr.%20Psychol.42,%2020814%E2%80%9320823%20(2023).%C2%A010.1007/s12144-022-03191-y" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR104">
<span class="label">104.</span><cite>Zioga, I., Harrison, P. M. C., Pearce, M., Bhattacharya, J. &amp; Di Bernardi Luft, C. The association between liking, learning and creativity in music. <em>Sci. Rep.</em><strong>14</strong>, 19048 (2024). 10.1038/s41598-024-70027-z
</cite> [<a href="https://doi.org/10.1038/s41598-024-70027-z" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11329743/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39152203/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Zioga,%20I.,%20Harrison,%20P.%20M.%20C.,%20Pearce,%20M.,%20Bhattacharya,%20J.%20&amp;%20Di%20Bernardi%20Luft,%20C.%20The%20association%20between%20liking,%20learning%20and%20creativity%20in%20music.%20Sci.%20Rep.14,%2019048%20(2024).%C2%A010.1038/s41598-024-70027-z" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR105">
<span class="label">105.</span><cite>Vroegh, T. P. Visual imagery in the listener’s mind: A network analysis of absorbed consciousness. <em>Psychol. Conscious. Theory Res. Pract.</em> (2021). 10.1037/cns0000274</cite> [<a href="https://scholar.google.com/scholar_lookup?Vroegh,%20T.%20P.%20Visual%20imagery%20in%20the%20listener%E2%80%99s%20mind:%20A%20network%20analysis%20of%20absorbed%20consciousness.%20Psychol.%20Conscious.%20Theory%20Res.%20Pract.%20(2021).%2010.1037/cns0000274" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR106">
<span class="label">106.</span><cite>Prince, J. B., Delalande, J., Ayyildiz, C. &amp; Herff, S. A. Traffic jams: Music and traffic noise interact to influence the vividness, sentiment, and spatiotemporal properties of directed mental imagery. <em>Research Square</em> (2024). 10.21203/rs.3.rs-4285253/v1</cite>
</li>
<li id="CR107">
<span class="label">107.</span><cite>D’Argembeau, A. &amp; Van der Linden, M. Individual differences in the phenomenology of mental time travel: The effect of vivid visual imagery and emotion regulation strategies. <em>Conscious. Cog.</em> <strong>15</strong>, 342–350 (2006). 10.1016/j.concog.2005.09.001
</cite> [<a href="https://doi.org/10.1016/j.concog.2005.09.001" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/16230028/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?D%E2%80%99Argembeau,%20A.%20&amp;%20Van%20der%20Linden,%20M.%20Individual%20differences%20in%20the%20phenomenology%20of%20mental%20time%20travel:%20The%20effect%20of%20vivid%20visual%20imagery%20and%20emotion%20regulation%20strategies.%20Conscious.%20Cog.%C2%A015,%20342%E2%80%93350%20(2006).%C2%A010.1016/j.concog.2005.09.001" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR108">
<span class="label">108.</span><cite>Bailes, F. &amp; Bishop, L. Musical imagery in the creative process. In <em>The Act of Musical Composition: Studies in the Creative Process</em> (ed. Collins, D.), 53–77 (Ashgate, United Kingdom, 2012).</cite>
</li>
<li id="CR109">
<span class="label">109.</span><cite>Irish, M. Semantic memory as the essential scaffold for future-oriented mental time travel. In <em>Seeing the Future: Theoretical Perspectives on Future-Oriented Mental Time Travel</em> (eds. Michaelian, K., Klein, S. B. &amp; Szpunar, K. K.) 389–408 (Oxford University Press, 2016). 10.1093/acprof:oso/9780190241537.003.0019</cite>
</li>
<li id="CR110">
<span class="label">110.</span><cite>Waters, A. J. &amp; Gobet, F. Mental imagery and chunks: Empirical and computational findings. <em>Mem. Cognit.</em><strong>36</strong>, 505–517 (2008). 10.3758/MC.36.3.505
</cite> [<a href="https://doi.org/10.3758/mc.36.3.505" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/18491491/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Waters,%20A.%20J.%20&amp;%20Gobet,%20F.%20Mental%20imagery%20and%20chunks:%20Empirical%20and%20computational%20findings.%20Mem.%20Cognit.36,%20505%E2%80%93517%20(2008).%C2%A010.3758/MC.36.3.505" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR111">
<span class="label">111.</span><cite>Garza, D. L. &amp; Feltz, D. L. Effects of selected mental practice on performance, self-efficacy, and competition confidence of figure skaters. <em>Sport Psychol.</em><strong>12</strong>, 1–15 (1998). 10.1123/tsp.12.1.1</cite> [<a href="https://scholar.google.com/scholar_lookup?Garza,%20D.%20L.%20&amp;%20Feltz,%20D.%20L.%20Effects%20of%20selected%20mental%20practice%20on%20performance,%20self-efficacy,%20and%20competition%20confidence%20of%20figure%20skaters.%20Sport%20Psychol.12,%201%E2%80%9315%20(1998).%C2%A010.1123/tsp.12.1.1" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR112">
<span class="label">112.</span><cite>Bowman, S. L. &amp; Lieberoth, A. Psychology and role-playing games. In <em>Role-Playing Game Studies</em> (eds. Deterding, S. &amp; Zagal, J.) 245–264 (Routledge, 2018).</cite>
</li>
<li id="CR113">
<span class="label">113.</span><cite>Groves, K., Farbood, M. M., Carone, B., Ripollés, P. &amp; Zuanazzi, A. Acoustic features of instrumental movie soundtracks elicit distinct and mostly non-overlapping extra-musical meanings in the mind of the listener. <em>Sci. Rep.</em><strong>15</strong>, 2327 (2025). 10.1038/s41598-025-86089-6
</cite> [<a href="https://doi.org/10.1038/s41598-025-86089-6" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11748619/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39825090/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Groves,%20K.,%20Farbood,%20M.%20M.,%20Carone,%20B.,%20Ripoll%C3%A9s,%20P.%20&amp;%20Zuanazzi,%20A.%20Acoustic%20features%20of%20instrumental%20movie%20soundtracks%20elicit%20distinct%20and%20mostly%20non-overlapping%20extra-musical%20meanings%20in%20the%20mind%20of%20the%20listener.%20Sci.%20Rep.15,%202327%20(2025).%C2%A010.1038/s41598-025-86089-6" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR114">
<span class="label">114.</span><cite>Harner, M. <em>15 Minute Solo Drumming with Call Back</em> (Foundation For Shamanic Studies Inc, 1997).</cite> [<a href="https://scholar.google.com/scholar_lookup?Harner,%20M.%2015%20Minute%20Solo%20Drumming%20with%20Call%20Back%20(Foundation%20For%20Shamanic%20Studies%20Inc,%201997)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR115">
<span class="label">115.</span><cite>Hughes, M. <em>et al.</em> Ableton Reference Manual Version 11. (2022).</cite>
</li>
<li id="CR116">
<span class="label">116.</span><cite>Bryce, J. &amp; Wu, M. The advantages and disadvantages of using a computer-interactive format for music assessment. <em>Res. Stud. Music Educ.</em><strong>3</strong>, 54–58 (1994). 10.1177/1321103X9400300107</cite> [<a href="https://scholar.google.com/scholar_lookup?Bryce,%20J.%20&amp;%20Wu,%20M.%20The%20advantages%20and%20disadvantages%20of%20using%20a%20computer-interactive%20format%20for%20music%20assessment.%20Res.%20Stud.%20Music%20Educ.3,%2054%E2%80%9358%20(1994).%C2%A010.1177/1321103X9400300107" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR117">
<span class="label">117.</span><cite>Gingras, B., Pohler, G. &amp; Fitch, W. T. Exploring shamanic journeying: Repetitive drumming with shamanic instructions induces specific subjective experiences but no larger cortisol decrease than instrumental meditation music. <em>PLoS ONE</em><strong>9</strong>, 1–9 (2014). 10.1371/journal.pone.0102103</cite> [<a href="https://doi.org/10.1371/journal.pone.0102103" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4085008/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/24999623/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Gingras,%20B.,%20Pohler,%20G.%20&amp;%20Fitch,%20W.%20T.%20Exploring%20shamanic%20journeying:%20Repetitive%20drumming%20with%20shamanic%20instructions%20induces%20specific%20subjective%20experiences%20but%20no%20larger%20cortisol%20decrease%20than%20instrumental%20meditation%20music.%20PLoS%20ONE9,%201%E2%80%939%20(2014).%C2%A010.1371/journal.pone.0102103" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR118">
<span class="label">118.</span><cite>Steinmetz, C. csteinmetz1/pyloudnorm. (2019).</cite>
</li>
<li id="CR119">
<span class="label">119.</span><cite>Peirce, J. W. PsychoPy—Psychophysics software in Python. <em>J. Neurosci. Methods</em><strong>162</strong>, 8–13 (2007). 10.1016/j.jneumeth.2006.11.017
</cite> [<a href="https://doi.org/10.1016/j.jneumeth.2006.11.017" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC2018741/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/17254636/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Peirce,%20J.%20W.%20PsychoPy%E2%80%94Psychophysics%20software%20in%20Python.%20J.%20Neurosci.%20Methods162,%208%E2%80%9313%20(2007).%C2%A010.1016/j.jneumeth.2006.11.017" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR120">
<span class="label">120.</span><cite>Tellegen, A. &amp; Atkinson, G. Openness to absorbing and self-altering experiences (‘absorption’), a trait related to hypnotic susceptibility. <em>J. Abnorm. Psychol.</em><strong>93</strong>, 268–277 (1974). 10.1037/h0036681</cite> [<a href="https://doi.org/10.1037/h0036681" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/4844914/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Tellegen,%20A.%20&amp;%20Atkinson,%20G.%20Openness%20to%20absorbing%20and%20self-altering%20experiences%20(%E2%80%98absorption%E2%80%99),%20a%20trait%20related%20to%20hypnotic%20susceptibility.%20J.%20Abnorm.%20Psychol.93,%20268%E2%80%93277%20(1974).%C2%A010.1037/h0036681" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR121">
<span class="label">121.</span><cite>Carleton, R. N., Abrams, M. P. &amp; Asmundson, G. J. G. The attentional resource allocation scale (ARAS): Psychometric properties of a composite measure for dissociation and absorption. <em>Depress. Anxiety</em><strong>27</strong>, 775–786 (2010). 10.1002/da.20656
</cite> [<a href="https://doi.org/10.1002/da.20656" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/20186969/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Carleton,%20R.%20N.,%20Abrams,%20M.%20P.%20&amp;%20Asmundson,%20G.%20J.%20G.%20The%20attentional%20resource%20allocation%20scale%20(ARAS):%20Psychometric%20properties%20of%20a%20composite%20measure%20for%20dissociation%20and%20absorption.%20Depress.%20Anxiety27,%20775%E2%80%93786%20(2010).%C2%A010.1002/da.20656" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR122">
<span class="label">122.</span><cite>Campos, A. &amp; Pérez-Fabello, M. J. Psychometric quality of a revised version vividness of visual imagery questionnaire. <em>Percept. Mot. Skills</em><strong>108</strong>, 798–802 (2009). 10.2466/pms.108.3.798-802
</cite> [<a href="https://doi.org/10.2466/PMS.108.3.798-802" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/19725316/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Campos,%20A.%20&amp;%20P%C3%A9rez-Fabello,%20M.%20J.%20Psychometric%20quality%20of%20a%20revised%20version%20vividness%20of%20visual%20imagery%20questionnaire.%20Percept.%20Mot.%20Skills108,%20798%E2%80%93802%20(2009).%C2%A010.2466/pms.108.3.798-802" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR123">
<span class="label">123.</span><cite>Gelding, R. W. et al. An efficient and adaptive test of auditory mental imagery. <em>Psychol. Res.</em><strong>85</strong>, 1201–1220 (2021). 10.1007/s00426-020-01322-3
</cite> [<a href="https://doi.org/10.1007/s00426-020-01322-3" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8049941/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32356009/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Gelding,%20R.%20W.%20et%20al.%20An%20efficient%20and%20adaptive%20test%20of%20auditory%20mental%20imagery.%20Psychol.%20Res.85,%201201%E2%80%931220%20(2021).%C2%A010.1007/s00426-020-01322-3" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR124">
<span class="label">124.</span><cite>Lovibond, P. F. &amp; Lovibond, S. H. The structure of negative emotional states: Comparison of the Depression Anxiety Stress Scales (DASS) with the Beck Depression and Anxiety Inventories. <em>Behav. Res. Ther.</em><strong>33</strong>, 335–343 (1995). 10.1016/0005-7967(94)00075-U
</cite> [<a href="https://doi.org/10.1016/0005-7967(94)00075-u" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/7726811/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Lovibond,%20P.%20F.%20&amp;%20Lovibond,%20S.%20H.%20The%20structure%20of%20negative%20emotional%20states:%20Comparison%20of%20the%20Depression%20Anxiety%20Stress%20Scales%20(DASS)%20with%20the%20Beck%20Depression%20and%20Anxiety%20Inventories.%20Behav.%20Res.%20Ther.33,%20335%E2%80%93343%20(1995).%C2%A010.1016/0005-7967(94)00075-U" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR125">
<span class="label">125.</span><cite>Ogle, K. &amp; Barber, J. J. Ensuring identifiability in hierarchical mixed effects Bayesian models. <em>Ecol. Appl.</em><strong>30</strong>, e02159 (2020). 10.1002/eap.2159
</cite> [<a href="https://doi.org/10.1002/eap.2159" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32365250/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Ogle,%20K.%20&amp;%20Barber,%20J.%20J.%20Ensuring%20identifiability%20in%20hierarchical%20mixed%20effects%20Bayesian%20models.%20Ecol.%20Appl.30,%20e02159%20(2020).%C2%A010.1002/eap.2159" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR126">
<span class="label">126.</span><cite>R-Core-Team. R: A language and environment for statistical computing. R Foundation for Statistical Computing (2013).</cite>
</li>
<li id="CR127">
<span class="label">127.</span><cite>Bürkner, P. C. brms: An R package for Bayesian multilevel models using Stan. <em>J. Stat. Softw.</em><strong>80</strong>, 1–28 (2017). 10.18637/jss.v080.i01</cite> [<a href="https://scholar.google.com/scholar_lookup?B%C3%BCrkner,%20P.%20C.%20brms:%20An%20R%20package%20for%20Bayesian%20multilevel%20models%20using%20Stan.%20J.%20Stat.%20Softw.80,%201%E2%80%9328%20(2017).%C2%A010.18637/jss.v080.i01" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR128">
<span class="label">128.</span><cite>Arel-Bundock, V., Greifer, N. &amp; Bacher, E. How to Interpret Statistical Models Using marginaleffects in R and Python. <em>J. Stat. Softw.</em> (Forthcoming).</cite>
</li>
<li id="CR129">
<span class="label">129.</span><cite>Jerling, P. &amp; Heyns, M. Exploring guided imagery and music as a well-being intervention: A systematic literature review. <em>Nord. J. Music. Ther.</em><strong>29</strong>, 371–390 (2020). 10.1080/08098131.2020.1737185</cite> [<a href="https://scholar.google.com/scholar_lookup?Jerling,%20P.%20&amp;%20Heyns,%20M.%20Exploring%20guided%20imagery%20and%20music%20as%20a%20well-being%20intervention:%20A%20systematic%20literature%20review.%20Nord.%20J.%20Music.%20Ther.29,%20371%E2%80%93390%20(2020).%C2%A010.1080/08098131.2020.1737185" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR130">
<span class="label">130.</span><cite>Burger, B. &amp; Wöllner, C. Drumming action and perception: How the movements of a professional drummer influence experiences of tempo, time, and expressivity. <em>Music Sci.</em><strong>6</strong>, 20592043231186870 (2023). 10.1177/20592043231186870</cite> [<a href="https://scholar.google.com/scholar_lookup?Burger,%20B.%20&amp;%20W%C3%B6llner,%20C.%20Drumming%20action%20and%20perception:%20How%20the%20movements%20of%20a%20professional%20drummer%20influence%20experiences%20of%20tempo,%20time,%20and%20expressivity.%20Music%20Sci.6,%2020592043231186870%20(2023).%C2%A010.1177/20592043231186870" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adda93_" lang="en" class="data-availability-statement"><h3 class="pmc_sec_title">Data Availability Statement</h3>
<p>All data, analytical scripts, the Ableton project, and musical stimuli are available on OSF, <a href="https://osf.io/2qr4n/?view_only=5738a93396434f72bd54736bc801dbb2" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://osf.io/2qr4n/?view_only=5738a93396434f72bd54736bc801dbb2</a>.</p></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from Scientific Reports are provided here courtesy of <strong>Nature Publishing Group</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1038/s41598-025-12604-4"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/41598_2025_Article_12604.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (2.8 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12373897/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12373897/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12373897%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373897/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12373897/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12373897/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40846722/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12373897/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40846722/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12373897/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12373897/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="XPHcrv59ZBrYRgoaS2pyD28JD5S3MlQreo0A7YJl3tletl6lF1JjJkbzu82cK2ED">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
    

    </body>
</html>
