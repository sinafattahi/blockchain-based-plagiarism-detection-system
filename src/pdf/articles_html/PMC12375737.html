
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            CHASHNIt for enhancing skin disease classification using GAN augmented hybrid model with LIME and SHAP based XAI heatmaps - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="D2E4AFF68AF3269305AFF6004360386B.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="scirep">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12375737/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="Scientific Reports">
<meta name="citation_title" content="CHASHNIt for enhancing skin disease classification using GAN augmented hybrid model with LIME and SHAP based XAI heatmaps">
<meta name="citation_author" content="Saksham Anand">
<meta name="citation_author_institution" content="School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, 600127 India">
<meta name="citation_author" content="Abhiram Sharma">
<meta name="citation_author_institution" content="School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, 600127 India">
<meta name="citation_author" content="B Natarajan">
<meta name="citation_author_institution" content="School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, 600127 India">
<meta name="citation_author" content="Ashwin Singh Slathia">
<meta name="citation_author_institution" content="School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, 600127 India">
<meta name="citation_author" content="Ayush Rathi">
<meta name="citation_author_institution" content="School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, 600127 India">
<meta name="citation_author" content="Krishna Priyadarshan Behara">
<meta name="citation_author_institution" content="School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, 600127 India">
<meta name="citation_author" content="R Elakkiya">
<meta name="citation_author_institution" content="Department of Computer Science, Birla Institute of Technology and Science, Pilani Dubai Campus, Dubai, 345055 United Arab Emirates">
<meta name="citation_publication_date" content="2025 Aug 24">
<meta name="citation_volume" content="15">
<meta name="citation_firstpage" content="31138">
<meta name="citation_doi" content="10.1038/s41598-025-13647-3">
<meta name="citation_pmid" content="40850939">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12375737/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12375737/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12375737/pdf/41598_2025_Article_13647.pdf">
<meta name="description" content="Correct categorization of skin diseases is vital for prompt diagnosis. However, obstacles such as imbalance of data and interpretability of deep learning models limit their use in medical settings. To overcome these setbacks, Combined Hybrid ...">
<meta name="og:title" content="CHASHNIt for enhancing skin disease classification using GAN augmented hybrid model with LIME and SHAP based XAI heatmaps">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="Correct categorization of skin diseases is vital for prompt diagnosis. However, obstacles such as imbalance of data and interpretability of deep learning models limit their use in medical settings. To overcome these setbacks, Combined Hybrid ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12375737/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12375737">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1038/s41598-025-13647-3"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/41598_2025_Article_13647.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12375737%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12375737/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12375737/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12375737/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-scirep.jpg" alt="Scientific Reports logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to Scientific Reports" title="Link to Scientific Reports" shape="default" href="http://www.nature.com/srep" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">Sci Rep</button></div>. 2025 Aug 24;15:31138. doi: <a href="https://doi.org/10.1038/s41598-025-13647-3" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1038/s41598-025-13647-3</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22Sci%20Rep%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sci%20Rep%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22Sci%20Rep%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22Sci%20Rep%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>CHASHNIt for enhancing skin disease classification using GAN augmented hybrid model with LIME and SHAP based XAI heatmaps</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Anand%20S%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Saksham Anand</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Saksham Anand</span></h3>
<div class="p">
<sup>1</sup>School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, 600127 India </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Anand%20S%22%5BAuthor%5D" class="usa-link"><span class="name western">Saksham Anand</span></a>
</div>
</div>
<sup>1,</sup><sup>#</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sharma%20A%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Abhiram Sharma</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">Abhiram Sharma</span></h3>
<div class="p">
<sup>1</sup>School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, 600127 India </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sharma%20A%22%5BAuthor%5D" class="usa-link"><span class="name western">Abhiram Sharma</span></a>
</div>
</div>
<sup>1,</sup><sup>#</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Natarajan%20B%22%5BAuthor%5D" class="usa-link" aria-describedby="id3"><span class="name western">B Natarajan</span></a><div hidden="hidden" id="id3">
<h3><span class="name western">B Natarajan</span></h3>
<div class="p">
<sup>1</sup>School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, 600127 India </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Natarajan%20B%22%5BAuthor%5D" class="usa-link"><span class="name western">B Natarajan</span></a>
</div>
</div>
<sup>1,</sup><sup>✉</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Slathia%20AS%22%5BAuthor%5D" class="usa-link" aria-describedby="id4"><span class="name western">Ashwin Singh Slathia</span></a><div hidden="hidden" id="id4">
<h3><span class="name western">Ashwin Singh Slathia</span></h3>
<div class="p">
<sup>1</sup>School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, 600127 India </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Slathia%20AS%22%5BAuthor%5D" class="usa-link"><span class="name western">Ashwin Singh Slathia</span></a>
</div>
</div>
<sup>1,</sup><sup>#</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Rathi%20A%22%5BAuthor%5D" class="usa-link" aria-describedby="id5"><span class="name western">Ayush Rathi</span></a><div hidden="hidden" id="id5">
<h3><span class="name western">Ayush Rathi</span></h3>
<div class="p">
<sup>1</sup>School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, 600127 India </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Rathi%20A%22%5BAuthor%5D" class="usa-link"><span class="name western">Ayush Rathi</span></a>
</div>
</div>
<sup>1,</sup><sup>#</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Behara%20KP%22%5BAuthor%5D" class="usa-link" aria-describedby="id6"><span class="name western">Krishna Priyadarshan Behara</span></a><div hidden="hidden" id="id6">
<h3><span class="name western">Krishna Priyadarshan Behara</span></h3>
<div class="p">
<sup>1</sup>School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, 600127 India </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Behara%20KP%22%5BAuthor%5D" class="usa-link"><span class="name western">Krishna Priyadarshan Behara</span></a>
</div>
</div>
<sup>1,</sup><sup>#</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Elakkiya%20R%22%5BAuthor%5D" class="usa-link" aria-describedby="id7"><span class="name western">R Elakkiya</span></a><div hidden="hidden" id="id7">
<h3><span class="name western">R Elakkiya</span></h3>
<div class="p">
<sup>2</sup>Department of Computer Science, Birla Institute of Technology and Science, Pilani Dubai Campus, Dubai, 345055 United Arab Emirates </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Elakkiya%20R%22%5BAuthor%5D" class="usa-link"><span class="name western">R Elakkiya</span></a>
</div>
</div>
<sup>2</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="Aff1">
<sup>1</sup>School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, 600127 India </div>
<div id="Aff2">
<sup>2</sup>Department of Computer Science, Birla Institute of Technology and Science, Pilani Dubai Campus, Dubai, 345055 United Arab Emirates </div>
<div class="author-notes p">
<div class="fn" id="_fncrsp93pmc__">
<sup>✉</sup><p class="display-inline">Corresponding author.</p>
</div>
<div class="fn" id="_eqcntrb93pmc__">
<sup>#</sup><p class="display-inline">Contributed equally.</p>
</div>
</div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2025 Apr 16; Accepted 2025 Jul 25; Collection date 2025.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© The Author(s) 2025</div>
<p><strong>Open Access</strong> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="https://creativecommons.org/licenses/by/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://creativecommons.org/licenses/by/4.0/</a>.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12375737  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40850939/" class="usa-link">40850939</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="Abs1"><h2>Abstract</h2>
<p id="Par1">Correct categorization of skin diseases is vital for prompt diagnosis. However, obstacles such as imbalance of data and interpretability of deep learning models limit their use in medical settings. To overcome these setbacks, <em>Combined Hybrid Architecture for Scalable High-performance in Neural Iterations</em> or <em>CHASHNIt</em> is proposed, which is an integration of EfficientNetB7, DenseNet201, and InceptionResNetV2 to outperform current models on every ground. GAN-based data augmentation is used to create synthetic images, to ensure that all classes are equally represented. Sophisticated preprocessing methods such as normalization and feature selection improve data quality and model generalization. Explainable AI methods, i.e., SHAP and LIME, enable model decision-making transparent. A rigorous comparative analysis testifies to the excellence of <em>CHASHNIt</em> compared to other benchmark models with 97.8% accuracy, 98.1% precision, 97.5% recall, 97.6% F1 Score and IoU of 92.3%, which exceeds Swin Transformer, ResNet101, InceptionResNetV2, MobileNetV3, EfficientNetB7, DenseNet201, and ConvNeXt models. The model was trained and tested on a 19,500-image dataset of 23 types of skin diseases with 80:20 split for training and testing. An ablation study testifies to the synergy advantage of the hybrid approach. LIME-SHAP heatmaps confirm the model’s predictive result. <em>CHASHNIt</em> is an advanced automated skin disease classification framework, attaining a balance between scalability, accuracy, and explainability. Computational complexity is the sole drawback, but future developments will optimize efficiency for low-resource devices.</p>
<section id="kwd-group1" lang="en" class="kwd-group"><p><strong>Keywords:</strong> Skin disease classification, Explainable AI, GAN for data augmentation, CHASHNIt hybrid model, Deep learning, Dermatology, LIME, SHAP, Medical image analysis, Interpretability in AI</p></section><section id="kwd-group2" class="kwd-group"><p><strong>Subject terms:</strong> Translational research, Classification and taxonomy, Computational models, Data processing, Image processing</p></section></section><section id="Sec1"><h2 class="pmc_sec_title">Introduction</h2>
<p id="Par2">Skin diseases are a global health concern. Affecting approximately one-third of the world’s population as per Flohr et al.<sup><a href="#CR1" class="usa-link" aria-describedby="CR1">1</a></sup>. According to Karimkheni et al., 2017<sup><a href="#CR2" class="usa-link" aria-describedby="CR2">2</a></sup> account for an estimated 42.9 million Disability Adjusted Life Years (DALYs), with around 95% attributed to years lived with disability. Common skin conditions like fungal infections, acne, eczema have increased in prevalence in the recent years. The diagnosis for skin disease however present various challenges. These may be due to the diversity of conditions and the overlap in symptoms across numerous categories. Many regions lack Dermatological specialists, piling up on the risk of misdiagnoses. The result is that these diseases are affecting individuals across all demographics.</p>
<p id="Par3">These statistics not only represent the clinical importance of dermatological disease, but also the diagnostic deficit in underprivileged populations that do not have dermatological specialization. This calls for interpretable, scalable AI-based alternatives that can aid in timely recognition and referral. Most current deep learning alternatives are, however, deficient in terms of addressing real-world issues like under representation of the rare classes and lack of interpretability of predictions, which serves as an impediment to clinical trust.</p>
<p id="Par4">Deep learning approaches have shown promise in automating skin lesion classification, with convolutional neural networks (CNNs) achieving dermatologist-level performance in several studies. Nevertheless, existing models often struggle with two key challenges which include class imbalance inherent in clinical datasets—rare but clinically significant conditions receive insufficient representation and lack of transparent decision-making, which hinders clinical adoption. While Vision Transformers (ViT) and attention-based ensembles have been proposed, they typically require large training sets or incur high computational overhead, limiting their practicality in smaller clinical cohorts. The literature review showcases several persistent challenges in the field of skin diseases, which include data imbalance, intra–class variability, interclass similarity, interpretability and scalability.</p>
<p id="Par5">Current methods for class imbalance are typically based on oversampling or standard augmentation, which will not necessarily maintain the uniqueness of rare conditions. Likewise, interpretability approaches are rarely quantitatively tested or used in the model pipeline. CHASHNIt proposes GAN-based augmentation specifically designed for underrepresented classes and applies two complementary XAI approaches—SHAP for global understanding and LIME for localized understanding, both of which are quantitatively evaluated against dermatologist labelling.</p>
<p id="Par6">The study aims to overcome these limitations through a hybrid architecture, and introduces a robust image classification system tailored to accurately differentiate between 23 classes of skin diseases that are visually illustrated in Fig. <a href="#Fig1" class="usa-link">1</a> by utilizing advance deep learning models, extracting features from them and integrating them into a Convolutional Neural Network layer.</p>
<figure class="fig xbox font-sm" id="Fig1"><h3 class="obj_head">Fig. 1.</h3>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/01006684ebb5/41598_2025_13647_Fig1_HTML.jpg" loading="lazy" id="MO1" height="565" width="644" alt="Fig. 1"></p>
<div class="p text-right font-secondary"><a href="figure/Fig1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Sample images from dataset.</p></figcaption></figure><p id="Par7">The study makes use of three widely used top-performing deep learning models. EfficientNetB7 balances width, depth, and resolution for various image datasets. Dense connectivity in DenseNet201 keeps parameters low and prevents vanishing gradients. InceptionResNetV2 combines Inception blocks with residual connection of ResNet for efficiency. The proposed model—<em>Combined Hybrid Architecture for Scalable High-performance in Neural Iterations</em>, further reffered to as CHASHNIt or CHASHNI. It combines the strength of EfficientNetB7, DenseNet201 and Inception ResNetV2 and achieves superior classification performance. The model’s efficacy is shown by its high classification accuracy. Apart from that the integration of Explainable AI tools; SHAP and LIME, this research addresses both the accuracy and the usability gaps in the current methodology. CHASHNIt fuses and synthesizes the capabilities of the three models. This culminates into a tri-net framework which achieves an impressive accuracy of 97.8%.</p>
<p id="Par8">CHASHNIt is trained on a dataset comprising of approximately 19,500 images from 23 classes of skin diseases. This study makes use of techniques like normalization, feature selection. The images are standardized to consistent formats and resolutions to ensure uniformity across the dataset. Feature selection are implemented, primarily using class-discriminative saliency filtering and dropout-based pruning within the fused feature space to identify the most relevant attributes.</p>
<p id="Par9">Advanced preprocessing methods of data augmentation, weighted loss functions, and GANs are employed to address these problems. Generative Adversarial Networks synthesize realistic images. It Enhances dataset diversity and reduces class imbalance.</p>
<p id="Par10">An ablation study, a study where one systematically removes or modifies components of a model or system to evaluate their individual contributions to its overall performance. An ablation study to assess the contributions of individual components within the CHASHNI architecture is conducted. Their results illustrate an enhancement of feature extraction with EfficientNetB7. The model is a great performer and has important implications for real-life applications.</p>
<p id="Par11">The evaluation process validates the exemplary performance of the CHASHNIt model on multiple metrics. The model achieves a total accuracy of 97.8%, significantly outperforming other state-of-the-art architectures such as Swin Transformer and ResNet101. Precision, recall, and F1-score values also reflect the superior reliability of CHASHNIt. The excellent Intersection over Union (IoU) value supports the model’s ability to detect skin disease classes accurately with reduced misclassification. These metrics underscore the value of the hybrid architecture in tackling the complexities of multi-class dermatological image classification.</p>
<p id="Par12">The effectiveness of the CHASHNIt model is validated with a comparative analysis with several other leading architectures. EfficientNetB7, DenseNet201, and InceptionResNetV2 individually achieved impressive accuracies however, their combined features within the CHASHNIt framework resulted in a notable performance leap. In a similar manner ConvNeXt, MobileNetV3, and ResNet101 exhibited comparatively lower accuracies.</p>
<p id="Par13">The confusion matrix reveals that the CHASHNIt model exhibits minimal false positives and false negatives across all 23 disease categories. ROC curves for each class demonstrate consistently high performance.</p>
<p id="Par14">XAI tools, SHAP and LIME are employed to enhance explainability. SHAP visualizations identify key features influencing model predictions, such as color variations and lesion textures. LIME overlays provide localized explanations, highlighting regions of interest in images that most strongly influence classification outcomes. These insights ensure the model’s transparency and facilitate its integration into clinical workflows.</p>
<p id="Par15">Despite its achievements, the study acknowledges certain limitations. The reliance on a single dataset may restrict the model’s generalization to other populations and imaging conditions. Future pieces of work shall therefore emphasize loading in various datasets and optimizing the model for edge computing devices. Also, the use of semi-supervised and unsupervised learning can further provide adaptability and performance to the system.</p>
<p id="Par16">The results and analysis presented affirm the CHASHNIt’s potential to revolutionize dermatological diagnostics. Achieving unparalleled accuracy and integrating interpretability tools, the model sets a new benchmark for skin disease classification. Its practical implications and future prospects highlight the relevance and applicability in advancing healthcare outcomes.</p>
<p id="Par17">This study bids several major contributions to dermatological diagnostics: </p>
<ol class="list" style="list-style-type:decimal">
<li><p id="Par18"><em>CHASHNIt, the Combined Hybrid Architecture for Scalable High performance in Neural Iterations</em>, is introduced as a novel framework that <em>integrates EfficientNetB7, DenseNet201 and InceptionResNetV2</em>. This hybrid model achieves an unprecedented classification accuracy of 97.8%, surpassing all existing state of the art models in skin disease classification.</p></li>
<li><p id="Par19">The paper presents advanced data preprocessing techniques of normalization, feature selection and usage of <em>GAN for data augmentation</em> to address class imbalance and intra class variability.</p></li>
<li><p id="Par20">A rigorous <em>comparative analysis</em> with leading architectures, Swin Transformer, ResNet101, and ConvNeXt highlighting <em>CHASHNIt’s superior performance</em>. The model outperforms competitors across all key metrics of accuracy, precision, recall, F1-score, and IoU. An extensive <em>ablation study</em> assesses the contributions of individual components within the CHASHNIt framework proving it’s superior discriminative ability.</p></li>
<li><p id="Par21">The study addresses key challenges in skin disease classification. Data heterogeneity, interclass similarities, and the black box nature of deep learning models are some of the key challenges solved by integration of varied preprocessing techniques. Hybrid modeling and eXplainable AI techniques like LIME and SHAP were employed for the same. These methods enhance interpretability providing localized and global explanations to ensure transparency and clinical applicability.</p></li>
</ol>
<p>CHASHNIt’s practical implications are emphasized through its potential application in telehealth and resource constrained environments. This paper proceeds to explain the method and working of the research clearly. In the second section, the literature reviews are being done in-depth with the consideration of previous studies and if there were prior studies. In “<a href="#Sec3" class="usa-link">Methodology</a>”, the model architecture, training execution, evaluation metrics, and all the steps followed in this study are discussed in detail. In “<a href="#Sec10" class="usa-link">Results</a>”, results are analysed, and discussions are presented concerning performance on the evaluation metrics and comparisons made. In “<a href="#Sec37" class="usa-link">Conclusion</a>”, the paper concludes with findings from this research outlining the direction of future work.</p></section><section id="Sec2"><h2 class="pmc_sec_title">Literature review</h2>
<p id="Par22">Skin disease classification has become a great progression in the diagnosis and treatment of many dermatological conditions. This approach can detect any skin disease efficiently by scanning images from multiple views, which in turn enables early diagnosis.</p>
<p id="Par23">Zhe Wu et. al.<sup><a href="#CR3" class="usa-link" aria-describedby="CR3">3</a></sup> employed the architectures of CNNs to classify six facial skin diseases with the use of the Xiangya–Derm dataset. They demonstrated transfer learning, which also demonstrated excellent recall rates, such as 92.9% for lupus erythematosus. While this strategy benefited from superior diagnostic accuracy and the ability for better generalization, it suffered from a lean dataset and narrow focus on only six diseases. Md. N. Hossen et. al.<sup><a href="#CR4" class="usa-link" aria-describedby="CR4">4</a></sup> used machine learning and image detection to identify diseases like skin cancer and leprosy, aiming for early detection. They demonstrated how automated systems can improve diagnostic accuracy and streamline healthcare administration, but they also highlighted the need for more studies on how to handle the overlapped illness traits and the dataset’s varying quality. Asif et al.<sup><a href="#CR5" class="usa-link" aria-describedby="CR5">5</a></sup> studied the residual blocks and activation functions, such as ReLU that is Rectified Linear Unit and SELU also known as Scaled Exponential Linear Unit in deep neural networks for the classification of skin disease. The outcomes demonstrated that a ResNet model with SELU activation performed the best. These models might have improved the detection accuracy, but the study was not able to detail the dataset and did not address the computational efficacy of the models. Hao et al.<sup><a href="#CR6" class="usa-link" aria-describedby="CR6">6</a></sup> studied ensemble learning methods, including Bagging, Boosting, and Stacking, to improve the effectiveness of skin disease classification. According to their results, ensemble methods outperformed individual classifiers in terms of key performance metrics such as accuracy, precision, and sensitivity, offering reduced overfitting with improved generalization techniques. However, there was a lack of detailing in dataset, which highlighted the ensemble method’s computational complexity. Lee et al.<sup><a href="#CR7" class="usa-link" aria-describedby="CR7">7</a></sup> used a hybrid approach that incorporated CNNs, ECOCs that is knows as Error-Correcting Output Codes, and Support Vector Machines abbreviated as SVMs to differentiate between multiple skin diseases, and it achieved higher accuracy than traditional methods. Their model increased the reliability of detection because of the use of deep learning with SVMs, but the model might have been too complex for use in real-time situations. Zhuanj et al.<sup><a href="#CR8" class="usa-link" aria-describedby="CR8">8</a></sup> presented a comprehensive survey of traditional and deep learning-based methods for skin disease classification. It highlighted the developments in automated techniques, which improved diagnostic accuracy. While providing useful information and identifying some of the important trends, the survey identified some potential gaps, such as missing recent developments and the dataset’s diversity and quality not being sufficient. Balasundaram et al.<sup><a href="#CR9" class="usa-link" aria-describedby="CR9">9</a></sup> used two approaches for skin disease detection: direct classification and lesion classification. They used a multi-label deep neural network that surpassed lesion-based classification and achieved a higher mean average precision of 0.70 in comparison to disease-based classification of 0.42. Although this approach was reliable, but it has some pitfalls in terms of data bias and integration with other diagnostic tools for inclusive evaluation. Adegun et al.<sup><a href="#CR10" class="usa-link" aria-describedby="CR10">10</a></sup> explored optimization techniques like Particle Swarm Optimization also known as PSO and GA namely Genetic Algorithms in order to improve the detection skills of ANNs or Artificial Neural Networks. These techniques helped the network learn faster and work more reliably with improved accuracy, but these approaches were computationally expensive, especially on large datasets. Ahmad et al.<sup><a href="#CR11" class="usa-link" aria-describedby="CR11">11</a></sup> presented a framework by combining ResNet152, InceptionResNet-V2, and a triplet loss function to enhance the classification of skin disease. This framework showed better precision due to learning features that separated similar kinds of disease classes. Although this kind of approach could provide good support for diagnosis, its applicability might have been constrained because of fewer diversities in data. Zhang et al.<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup> explores CNNs that is Convolutional Neural Networks for automating diagnosis of skin disease from images. Their model is shown to have a high accuracy level in identifying the common types of skin conditions, which reduces the need for manual diagnosis and can quickly be detected. This approach improves the care of patients but has some challenges because it has limited data, which impacts its relevance to the general population. Sharma et al.<sup><a href="#CR13" class="usa-link" aria-describedby="CR13">13</a></sup> examine ensemble methods and machine learning to enhance diagnostic efficacy. They increased the diagnosis reliability by integrating various classifiers. However, these combined methods were computationally expensive especially with large datasets. Sasithradevi et al.<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a></sup> used a pre-trained VGG16 which is Visual Geometry Group 16 Model for classifying skin diseases. They show how deep feature extraction can increase classification accuracy and emphasize how transfer learning can be used to reduce the amount of training data needed. Rokade et al.<sup><a href="#CR15" class="usa-link" aria-describedby="CR15">15</a></sup> evaluated the effectiveness of RF that is expanded as Random Forest and KNN that is K-Nearest Neighbors in automating the classification of skin diseases. They discovered that KNN achieved excellent detection accuracy levels with great reliability. However, the limited diversity of data may affect these models accuracy and limit their scalability for real-time applications. Kalpana et al.<sup><a href="#CR16" class="usa-link" aria-describedby="CR16">16</a></sup> find the effectiveness of a pre-trained DenseNet model on the classification of seven skin diseases from dermoscopy images. The model gained an overall accuracy of 88.78%, while one class attained 98% accuracy. Ahammed et al.<sup><a href="#CR17" class="usa-link" aria-describedby="CR17">17</a></sup> used a hybrid CNN-SVM model with 5494 images for classifying skin diseases. The model fetched an average accuracy of 75.25%, with high precision and recall scores, thus being suitably suitable for early detection. Gu et al.<sup><a href="#CR18" class="usa-link" aria-describedby="CR18">18</a></sup> employed an adversarial domain adaptation approach with a progressive transfer learning approach. Their method dealt with domain shift issues and was experimentally validated on the melanoma and cancer detection tasks on two benchmark datasets. Therefore, it provided practical advantages in reducing demands for large amounts of labeled data. However, computational complexity often became a limiting factor for scaling up and deployment in resource-constrained domains. Balasundaram et al.<sup><a href="#CR19" class="usa-link" aria-describedby="CR19">19</a></sup> developed a genetic algorithm-optimized stacking strategy by using a multi-model based on deep learning to improve the classification of skin diseases. However, the strategy’s usefulness in wider situations was limited because it was only trained using one dataset which is the DermNet dataset. Tri-Cong Pham et al.<sup><a href="#CR20" class="usa-link" aria-describedby="CR20">20</a></sup> studied a hybrid approach by combining balanced mini-batch logic, real-time image augmentation, and a customized loss function to address the class imbalance in the classification of skin disease. Using the EfficientNetB4-CLF model, which achieved 89.97% accuracy on a dataset that contained 24,530 dermoscopic images with improved performance. While the method was very effective, but for broader clinical applications its scalability might have been limited due to computational complexity. Vachmanus et al.<sup><a href="#CR21" class="usa-link" aria-describedby="CR21">21</a></sup> explore DeepMetaForage, a framework using vision transformers to integrate image data with metadata such as lesion location and age of the patient for better detection of skin lesions. This multimodal approach improves diagnostic efficiency by taking advantage of both visual and contextual information and outperforms models relying solely on images, but its dependence on good-quality metadata limits its applicability in certain clinical settings. Sharma et al.<sup><a href="#CR22" class="usa-link" aria-describedby="CR22">22</a></sup> uses a hybrid model of deep learning integrated with Densenet201 and InceptionV3 for the classification of cervical cancer using Pap smear images. Their model achieves a 96.54% of accuracy, with 95.91% of precision, 96.54% of recall, and 96.17% of F1-score, and outperforms the previously established standards including ResNet-50, DenseNet-201, and Xception. Combining DenseNet201’s efficient features and InceptionV2’s multi-scale analysis delivers robust performance in diagnosis. However, in contexts with limited resources relying on a GPU-enabled environment may lessen its likelihood.</p>
<p id="Par24">Recent advancements in breast cancer classification have demonstrated the potential of combining ensemble CNN architectures with metaheuristic optimization techniques to significantly improve diagnostic accuracy. For instance, studies utilizing DenseNet-121 and EfficientNet-B5 with optimized hyperparameters have reported near-perfect classification performance on the INbreast dataset, achieving AUC values of 1.0 and sensitivities as high as 99.9%<sup><a href="#CR29" class="usa-link" aria-describedby="CR29">29</a></sup>. Similarly, hybrid models incorporating DenseNet, VGG-16, BiLSTM, and SVMs have shown exceptional generalization across datasets such as MIAS and INbreast, further reinforcing the efficacy of pre-trained CNN-based feature extraction<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup>. These works align with our own approach of leveraging CNN backbones and attention-enhanced architectures to mitigate class imbalance and enhance interpretability.</p>
<p id="Par25">The reviewed studies collectively highlighted multiple strengths and limitations of current approaches to skin disease classification. One noteworthy strength is the use of cutting-edge methods like deep learning, transfer learning, and hybrid models. However, challenges such as high computational costs and limited diversity of datasets might affect the real-time applicability and generalization. Furthermore, while ensemble methods and optimization algorithms improve accuracy, their scalability for clinical use may be not very effective. While pre-trained models like VGC16 and DenseNet reduce resource requirements and offer reliable outcomes, issues of data quality and scalability must be resolved for broader adoption in clinical use.</p>
<p id="Par26">Effective data pre-processing, innovative model architecture, and the integration of explainability are some tools which emerged as areas for critical research to bridge the aforementioned gap. This paper builds upon the foundation by introducing an exceptionally accurate and reliable model.</p>
<p id="Par27">In conclusion, the reviewed literature is categorized into three groups: (1) conventional CNN-based methods of skin disease classification, (2) ensemble and hybrid models for enhancing accuracy, and (3) explainability or class balancing studies. Most of the existing works are, however, deficient in three areas — poor scalability between disease classes, poor handling of class imbalance (especially for rare diseases), and poor integration and evaluation of interpretability tools. CHASHNIt aims to address these compounded shortcomings in a supervised GAN-based augmented hybrid CNN ensemble with dual XAI (LIME and SHAP) evaluations to achieve high prediction accuracy with clinically useful explanations.</p></section><section id="Sec3"><h2 class="pmc_sec_title">Methodology</h2>
<p id="Par28">This study aims to develop a robust and scalable framework to classify skin diseases into 23 distinct classes.</p>
<p id="Par29">The CHASHNI architecture, as visually illustrated in Fig. <a href="#Fig3" class="usa-link">3</a> and algorithmically shown in Algorithm 2 is the core of the study, describing the data flow, objectives, and the novelties. This study mainly emphasizes the interpretations of the two widely known XAI Algorithms LIME and SHAP, when applied upon a superior performing state of the art model. Trained under a vast dataset with 19,500+ images and augmented with GAN and other preprocessing techniques ensures the model to overcome over fitting and under fitting.</p>
<figure class="fig xbox font-sm" id="Fig3"><h3 class="obj_head">Fig. 3.</h3>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Fig3_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/a2737ca2c03e/41598_2025_13647_Fig3_HTML.jpg" loading="lazy" id="MO3" height="440" width="793" alt="Fig. 3"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>CHASHNIt model architecture.</p></figcaption></figure><section id="Sec4"><h3 class="pmc_sec_title">Dataset acquisition</h3>
<p id="Par30">The dataset used for this study was sourced from DermNet, one of the largest open-access repositories that feature dermatological images on the web. This dataset was also used in a study conducted by Bajwa et. al.<sup><a href="#CR25" class="usa-link" aria-describedby="CR25">25</a></sup>. The dataset features a total count of 19,500 full-resolution images accumulated into 23 different classes labeled to indicate different dermatological conditions such as acne, melanoma, psoriasis, and vasculitis, among numerous others. The detailed distribution of the number of images in each class is visualized as illustrated in the Fig. <a href="#Fig2" class="usa-link">2</a>a There are two distinct subsets of images: training and testing with about 15,500 for training and 4000 for testing distributed in approximately 80:20 ratio as also done by Balaji et al.<sup><a href="#CR23" class="usa-link" aria-describedby="CR23">23</a></sup>. DermNet dataset<sup><a href="#CR28" class="usa-link" aria-describedby="CR28">28</a></sup> has over 19000 dermatological images. It includes cases from more than 10 countries. More than 100 dermatologists contributed to it. The dataset covers 600 skin conditions. This dataset is also publicly available on kaggle. Images are verified for quality. Blurry and duplicate images are removed. It is used for research and education. This dataset scores a usability value of 8.75 which indicates its excellent quality and appropriateness to train and validate deep learning algorithms. Each image of the dataset is annotated with detail to ensure it is labeled precisely to increase the reliability of using the dataset in classification activities. The heterogeneity in the data ensures that the model would generalize well and for a very diverse set of skin diseases.</p>
<figure class="fig xbox font-sm" id="Fig2"><h4 class="obj_head">Fig. 2.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Fig2_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/de0532843a81/41598_2025_13647_Fig2_HTML.jpg" loading="lazy" id="MO2" height="251" width="792" alt="Fig. 2"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p><strong>(a)</strong> Dataset distribution across 23 distinct classes. <strong>(b)</strong> Dataset augmented using GAN.</p></figcaption></figure><p id="Par31">This study uses GANs to improve the dataset and address the possible class imbalance issues. Its usage along with sample synthetic images is visually depicted in Fig. <a href="#Fig2" class="usa-link">2</a>b GANs is a family of neural networks that have two components: generator and discriminator. These elements function antagonistically in order to generate realistic synthetic data. In the present study, the generator was developed to create synthetic images of skin diseases by completely understanding the inherent distribution of the dataset, while the discriminator was used to differentiate between authentic and generated images. The adversarial training framework used between these two neural networks allowed the generator to generate high-quality, realistic images similar to the original dataset. GANs have been used for the augmentation of underrepresented classes. That way, it was ensured that there was enough data in the model to effectively learn for all the 23 classes. It helped in the issue of shortage of data on less common conditions such as vascular tumors and vasculitis that are typically insufficiently sampled in dermatology datasets.</p>
<p id="Par32">In order to generate accurate synthetic data, <em>G</em> that is the generator is trained for producing samples which can deceive the discriminator <em>D</em>, generator loss function as shown in Eq. (<a href="#Equ1" class="usa-link">1</a>) is used.</p>
<table class="disp-formula p" id="Equ1"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/e02025fc6f67/41598_2025_13647_Article_Equ1.gif" loading="lazy" height="19" width="200" alt="graphic file with name 41598_2025_13647_Article_Equ1.gif"></td>
<td class="label">1</td>
</tr></table>
<p>The training process can be expresses as a min-max optimization problem too as shown in Eq. (<a href="#Equ2" class="usa-link">2</a>).</p>
<table class="disp-formula p" id="Equ2"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/b82a898a0a67/41598_2025_13647_Article_Equ2.gif" loading="lazy" height="10" width="200" alt="graphic file with name 41598_2025_13647_Article_Equ2.gif"></td>
<td class="label">2</td>
</tr></table></section><section id="Sec5"><h3 class="pmc_sec_title">Data preprocessing</h3>
<p id="Par33">To make sure that the input images were of high quality and were processed in a uniform manner to provide improved performance, the first step, which was known as data preprocessing, was carried out. Image normalization was carried out by rescaling the pixel values to 0 to 1 range using one of the most popular deep learning techniques and is also done in research carried out by R. Karthik et. al.<sup><a href="#CR24" class="usa-link" aria-describedby="CR24">24</a></sup>. This stabilizes and accelerates the training process. This normalization was done by dividing each pixel value by the maximum value of 255, ensuring uniform input data for the model. This set was further divided into training and test subsets, where 80% of the images were assigned for training and 20% for testing purposes. It ensures that the model is always evaluated on unseen data and hence provides a valid measure of how well it would generalize. Heavy application of data augmentation was involved in the preprocessing phase to artificially expand the size as well as the diversity of the training set. Random rotations, along with horizontal and vertical flipping and scaling, have been applied to the images. These augmentations mimic real variations in conditions under which an image is taken, like changes in angle of a camera or the lighting, and simultaneously also reduce overfitting because more scenarios are met during training.</p></section><section id="Sec6"><h3 class="pmc_sec_title">Models selection</h3>
<p id="Par35">To classify the 23 categories of skin disease, six intricate deep learning models along with our combined model were considered-Swin Transformer, ResNet101, InceptionResNetV2, MobileNetV3, EfficientNetB7, and DenseNet201. Each has achieved state-of-the-art image recognition performance; however, there are different strength points for all of them.</p>
<p id="Par36">This research process involves feature extraction, an essential step to distinguish and utilize the relevant patterns in the dataset and let the model decide what’s relevant. Hence, the Combined Hybrid Architecture for Scalable High-performance in Neural Iterations which is abbreviated as CHASHNIt model was designed integrating the capacities of EfficientNetB7, DenseNet201, and InceptionResNetV2. Each of these architectural frameworks has promising benefits to the integrated model. EfficientNetB7 balances network complexity with performance and captures very intricate features with a relatively small parameter count through its compound scaling. DenseNet201 allows dense connectivity to more efficiently reuse features across layers, thereby strengthening low-level patterns that are important to tell similar classes apart. InceptionResNetV2 combined both inception modules that capture the multi-scale features and residual connections which stabilizes learning.</p>
<p id="Par37">Specifically, EfficientNetB7 produces a 7<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq1"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/05c878d129aa/41598_2025_13647_Article_IEq1.gif" loading="lazy" alt="Inline graphic"></span>7<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq2"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/05c878d129aa/41598_2025_13647_Article_IEq1.gif" loading="lazy" alt="Inline graphic"></span>2560 feature map, DenseNet201 yields 7<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq3"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/05c878d129aa/41598_2025_13647_Article_IEq1.gif" loading="lazy" alt="Inline graphic"></span>7<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq4"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/05c878d129aa/41598_2025_13647_Article_IEq1.gif" loading="lazy" alt="Inline graphic"></span>1920, and InceptionResNetV2 outputs 7<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq5"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/05c878d129aa/41598_2025_13647_Article_IEq1.gif" loading="lazy" alt="Inline graphic"></span>7<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq6"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/05c878d129aa/41598_2025_13647_Article_IEq1.gif" loading="lazy" alt="Inline graphic"></span>1536. Prior to concatenation, each feature map was passed through a BatchNorm layer and normalized via MinMax scaling to [0, 1]. The normalized maps were concatenated along the channel axis, forming a 7<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq7"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/05c878d129aa/41598_2025_13647_Article_IEq1.gif" loading="lazy" alt="Inline graphic"></span>7<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq8"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/05c878d129aa/41598_2025_13647_Article_IEq1.gif" loading="lazy" alt="Inline graphic"></span>(2560 + 1920 + 1536) = 7<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq9"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/05c878d129aa/41598_2025_13647_Article_IEq1.gif" loading="lazy" alt="Inline graphic"></span>7<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq10"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/05c878d129aa/41598_2025_13647_Article_IEq1.gif" loading="lazy" alt="Inline graphic"></span>6016 tensor. To reduce channel dimensionality, a 1<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq11"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/05c878d129aa/41598_2025_13647_Article_IEq1.gif" loading="lazy" alt="Inline graphic"></span>1 convolution with 3,072 filters was applied, followed by ReLU activation.</p>
<p id="Par38">CHASHNIt uses the features combined from EfficientNetB7, DenseNet201, and InceptionResNetV2. Feature selection helps to improve model performance by reducing dimensionality and eliminating irrelevant or redundant features. Feature fusion is the process of combining the outputs of different feature extractors to create a unified representation of the input data. This procedure exploits the strengths of the different models, hence the CHASHNIt architecture can learn from a richer variety of features.</p>
<p id="Par39">The overall objective function to jointly defined to optimize the hybrid nature of model along with data augmentation techniques as shown in Eq. (<a href="#Equ3" class="usa-link">3</a>).</p>
<table class="disp-formula p" id="Equ3"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/2462a7cb0c1a/41598_2025_13647_Article_Equ3.gif" loading="lazy" height="17" width="155" alt="graphic file with name 41598_2025_13647_Article_Equ3.gif"></td>
<td class="label">3</td>
</tr></table>
<p>A more general formula with incorporation of all the weights and for different regularization and objective terms is defined as shown in Eq. (<a href="#Equ4" class="usa-link">4</a>).</p>
<table class="disp-formula p" id="Equ4"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/8c9ca03f5391/41598_2025_13647_Article_Equ4.gif" loading="lazy" height="15" width="200" alt="graphic file with name 41598_2025_13647_Article_Equ4.gif"></td>
<td class="label">4</td>
</tr></table>
<p>Weights <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq12"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/b889af766c1d/41598_2025_13647_Article_IEq12.gif" loading="lazy" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq13"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/8185a7af30e8/41598_2025_13647_Article_IEq13.gif" loading="lazy" alt="Inline graphic"></span> in Eqs. (<a href="#Equ3" class="usa-link">3</a>) and (<a href="#Equ4" class="usa-link">4</a>) were determined via grid search on a held-out validation set of 2000 images, maximizing macro F1-score. The grid search covered <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq14"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/2328cce309fa/41598_2025_13647_Article_IEq14.gif" loading="lazy" alt="Inline graphic"></span> in steps of 0.1, and learning rates in the range <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq15"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/cf907821e95f/41598_2025_13647_Article_IEq15.gif" loading="lazy" alt="Inline graphic"></span> to <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq16"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/605753c4630f/41598_2025_13647_Article_IEq16.gif" loading="lazy" alt="Inline graphic"></span>. Convergence was assessed via macro F1-score trends across validation folds.</p>
<p id="Par40">The CHASHNIt model was fine-tuned over 100 epochs with a learning rate of 10<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq17"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/825e613ba9f5/41598_2025_13647_Article_IEq17.gif" loading="lazy" alt="Inline graphic"></span> and batch size of 32. Completion of training this model over the entire 80% of the dataset required 3 hours on a cloud system on kaggle. The system had the computational efficiency equivalent to Intel i7 11th Gen, 4GB of RAM and 6GB GTX 1650 Ti Graphical Processing Unit. Thus, making the CHASHNIt model most suitable for local host deployment with minimal hardware constraints.</p>
<p id="Par41">Learning rate and batch size were selected based on preliminary convergence studies: smaller learning rates led to slower convergence, while larger rates caused unstable training. Tests were also conducted by varying epochs the epochs. 100 epochs achieved optimal validation accuracy without overfitting</p></section><section id="Sec7"><h3 class="pmc_sec_title">Fine-tuning</h3>
<p id="Par42">In the classification context, CHASHNIt was trained with rectified linear unit also known as ReLU as its activation function and the Adam optimization algorithm.</p>
<p id="Par43">While the softmax activation function is also widely used for activation in image classification, ReLU activation function was chosen for better model performance and complexity improvement. The ReLU function is added to the model architecture, making it possible to learn complex patterns in the dataset. The Adam optimizer incorporates adaptive learning rates and momentum, hence enhancing convergence during the training process. The training cycle was divided into two stages. The baseline performance was identified, along with what could improve the model. In the second step, unfreezing the last 50 layers of the model, training them on the data set, is a process referred to as fine-tuning, which updates higher-level features of the model to achieve the characteristics of the data set while maintaining knowledge learned in earlier layers. The model was then validated against the test set to determine how well the refined model performs and is reliable.</p>
<p id="Par44">The performance of CHASHNIt and other models was evaluated the basis of assessment metrics to to achieve an efficient understanding of the functionalities of CHASHNIt.de precision, recall, accuracy, F1 score, and IoU for each category that measure the ability of the model to precisely classify images.</p>
<p id="Par45">Precision calculates the proportion of correctly predicted positive instances out of all the positively predicted instances. Recall measures how well the model can identify all relevant cases of a particular class. Accuracy is a comprehensive measure of the efficiency of the model. F1 score represents the harmonic mean of precision and recall, which acts as a mediator between the trade-off of precision and recall. The IoU measures the overlap between the regions predicted and those in the ground truth, and it provides spatial evaluation of the model.</p>
<p id="Par46">The model’s classification accuracy has been verified using the ROC Curve, a plot of the true positive rate (sensitivity) versus the false positive rate (1-specificity) at different thresholds. The graph is useful as it displays sensitivity versus specificity trade-offs, which is important especially when dealing with unbalanced datasets. The AUC-ROC score is the measure of the model’s ability to distinguish between positive and negative classes where higher values that are nearer 1 indicate superior performance, while values near 0.5 indicate random guessing. This comprehensive analysis provides consistent performance for all skin disease classes, enabling that only appropriate decision thresholds are selected where sensitivity and specificity are balanced which is highly critical for real-world diagnostic applications.</p>
<p id="Par47">Ablation experiments were also employed to study the impact of different architectural components and training strategies in the approach. This study systematically modified or omitted elements of the model systematically to measure their relative contribution to end-to-end performance outcomes.</p>
<p id="Par48">To better assess the classification performance, a Confusion Matrix was used, which provided a detailed breakdown of the model’s predictions across all 23 skin disease classes. The matrix presents actual against predicted class labels so that diagonal entries signify correct classifications and off-diagonal entries signify incorrect classifications. From this study, common error patterns were identified, especially in cases that are difficult to differentiate visually, such as melanoma versus benign nevi and eczema versus atopic dermatitis. From analyzing misclassification, the study aims to improve the model, adapted class weights, and enhanced feature extraction for even improved accuracy. The confusion matrix also allowed for the computing of precision, recall, and F1-score per class. This high level of analysis was really helpful in relaxing CHASHNIt, minimizing false positives and negatives while making it more reliable in real-world dermatological diagnosis.</p>
<figure class="fig xbox font-sm" id="Figa"><h4 class="obj_head">Algorithm 1.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Figa_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/a7c4f07ef5be/41598_2025_13647_Figa_HTML.jpg" loading="lazy" id="MO4" height="371" width="794" alt="Algorithm 1"></a></p>
<div class="p text-right font-secondary"><a href="figure/Figa/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Computation of the enhanced Shapley values for model interpretability (SHAP).</p></figcaption></figure><figure class="fig xbox font-sm" id="Figb"><h4 class="obj_head">Algorithm 2.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Figb_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/c1c359a5827f/41598_2025_13647_Figb_HTML.jpg" loading="lazy" id="MO5" height="539" width="794" alt="Algorithm 2"></a></p>
<div class="p text-right font-secondary"><a href="figure/Figb/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>CHASHNIt model architecture.</p></figcaption></figure></section><section id="Sec8"><h3 class="pmc_sec_title">Explainable AI integration</h3>
<p id="Par51">This study uses explainable AI (XAI) methods to increase model predictions’ interpretability. Two algorithms from XAI, Local Interpretable Model-Agnostic Explanations (LIME) as introduced with the study by M. Azad et al.<sup><a href="#CR27" class="usa-link" aria-describedby="CR27">27</a></sup> along with an Enhanced SHapley Additive exPlanations (SHAP) as described in Algorithm 1 and introduced by N. Kostopoulos et al.<sup><a href="#CR26" class="usa-link" aria-describedby="CR26">26</a></sup>, were then used to create visual explanations of the model’s decision-making. To produce a local surrogate model that locally approximates the model’s target behaviour, LIME modifies the input image and tracks the resulting changes in the model’s output. The resulting heatmaps render into an image which shows the regions which are most responsible for producing a certain prediction, thus depicting a local view of the model’s reasoning. SHAP, or SHapley Additive exPlanations, identifies the contribution of each feature to the model output using concepts from cooperative game theory. Therefore, SHAP values encapsulate an overall sense of importance global to the feature set, allowing insight into the entire behaviour of the model on the dataset.</p>
<p id="Par52">To measure the trade-offs of predicted and true labels, a cross-entropy loss function is used for classification as shown in Eq. (<a href="#Equ5" class="usa-link">5</a>).</p>
<table class="disp-formula p" id="Equ5"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/f4f4d61d21d9/41598_2025_13647_Article_Equ5.gif" loading="lazy" height="51" width="165" alt="graphic file with name 41598_2025_13647_Article_Equ5.gif"></td>
<td class="label">5</td>
</tr></table>
<p>Its robustness could be further improved by introducing weights along with regularization as shown in Eq. (<a href="#Equ6" class="usa-link">6</a>).</p>
<table class="disp-formula p" id="Equ6"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/38883cfe0314/41598_2025_13647_Article_Equ6.gif" loading="lazy" height="37" width="200" alt="graphic file with name 41598_2025_13647_Article_Equ6.gif"></td>
<td class="label">6</td>
</tr></table>
<p>To quantitatively assess explanation quality, we collected dermatologist-annotated lesion masks for 300 randomly selected images. We computed the intersection-over-union (IoU) between LIME/SHAP heatmap regions (binary threshold at top 10 % saliency) and ground-truth masks, yielding mean IoUs of 0.62 (LIME) and 0.68 (SHAP). LIME required an average of 4.2 seconds per image, whereas SHAP averaged 6.5 seconds. Two board-certified dermatologists participated in a blinded evaluation, rating 200 explanation pairs (LIME vs. SHAP) on a 5-point clinical relevance scale. Average scores were 4.1 (SHAP) and 3.7 (LIME). To analyze consistency, we computed Pearson correlations between heatmap saliency vectors across 50 image pairs within each class, observing higher intra-class correlation for SHAP (r = 0.78) than LIME (r = 0.65).</p>
<p id="Par53">The combined effect of sophisticated models, thorough training processes, extensive evaluation metrics, and techniques for explainable AI has provided this method with a robust framework for skin disease classification. The methodology ensures that the model is accurate, reliable, and interpretable, rendering it fit for clinical deployment.</p></section><section id="Sec9"><h3 class="pmc_sec_title">Benchmarking and resource pooling</h3>
<p id="Par54">To evaluate computational requirements, we measured training and inference times on an NVIDIA RTX 3080 GPU and an Intel i7-12700H CPU. EfficientNetB7 required 45 minutes per epoch and consumed approximately 8 GB of GPU memory, whereas the combined CHASHNIt pipeline averaged 1 hour and 20 minutes per epoch with a peak usage of approximately 12 GB. Inference on a single <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq18"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/87b6c50342fa/41598_2025_13647_Article_IEq18.gif" loading="lazy" alt="Inline graphic"></span> image took 150 ms on the GPU and 520 ms on the CPU. These measurements demonstrate that, while CHASHNIt is more resource-intensive than individual backbones, its deployment remains viable on mid-range clinical GPUs when batched processing is employed.</p></section></section><section id="Sec10"><h2 class="pmc_sec_title">Results</h2>
<p id="Par55">This research evaluated the functioning of various deep learning models including Swin Transformer, ResNet101, InceptionResNetV2, MobileNetV3, EfficientNetB7, DenseNet201, ConvNeXt and CHASHNIt, and analyzed their performance using multiple parameters. Advance XAI tools like LIME and SHAP were also deployed to interpret model predictions and deliver an understanding of the decision-making process.</p>
<section id="Sec11"><h3 class="pmc_sec_title">Model performance analysis</h3>
<p id="Par56">The performance of CHASHNIt and other models is summarized in Table <a href="#Tab1" class="usa-link">1</a> through performance metrics. The results indicate an exceptional performance of CHASHNIt model outperforming, achieving an accuracy of 97.8%, precision and recall of 98.1% and 97.5% respectively, and F1-score and IOU of 97.6% and 92.3% respectively.</p>
<section class="tw xbox font-sm" id="Tab1"><h4 class="obj_head">Table 1.</h4>
<div class="caption p"><p>Performance comparison of different models.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Model</th>
<th align="left" colspan="1" rowspan="1">Accuracy (%)</th>
<th align="left" colspan="1" rowspan="1">Precision (%)</th>
<th align="left" colspan="1" rowspan="1">Recall (%)</th>
<th align="left" colspan="1" rowspan="1">F1 score (%)</th>
<th align="left" colspan="1" rowspan="1">IoU (%)</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">CHASHNIt</td>
<td align="left" colspan="1" rowspan="1">97.8</td>
<td align="left" colspan="1" rowspan="1">98.1</td>
<td align="left" colspan="1" rowspan="1">97.5</td>
<td align="left" colspan="1" rowspan="1">97.6</td>
<td align="left" colspan="1" rowspan="1">92.3</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Swin transformer</td>
<td align="left" colspan="1" rowspan="1">90.2</td>
<td align="left" colspan="1" rowspan="1">90.0</td>
<td align="left" colspan="1" rowspan="1">89.5</td>
<td align="left" colspan="1" rowspan="1">89.8</td>
<td align="left" colspan="1" rowspan="1">84.8</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">ResNet101</td>
<td align="left" colspan="1" rowspan="1">89.6</td>
<td align="left" colspan="1" rowspan="1">88.3</td>
<td align="left" colspan="1" rowspan="1">89.7</td>
<td align="left" colspan="1" rowspan="1">87.4</td>
<td align="left" colspan="1" rowspan="1">86.0</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">InceptionResNetV2</td>
<td align="left" colspan="1" rowspan="1">89.3</td>
<td align="left" colspan="1" rowspan="1">89.5</td>
<td align="left" colspan="1" rowspan="1">88.9</td>
<td align="left" colspan="1" rowspan="1">89.0</td>
<td align="left" colspan="1" rowspan="1">84.0</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">MobileNetV3</td>
<td align="left" colspan="1" rowspan="1">88.7</td>
<td align="left" colspan="1" rowspan="1">87.6</td>
<td align="left" colspan="1" rowspan="1">87.0</td>
<td align="left" colspan="1" rowspan="1">87.2</td>
<td align="left" colspan="1" rowspan="1">83.5</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">EfficientNetB7</td>
<td align="left" colspan="1" rowspan="1">88.1</td>
<td align="left" colspan="1" rowspan="1">87.4</td>
<td align="left" colspan="1" rowspan="1">88.4</td>
<td align="left" colspan="1" rowspan="1">86.2</td>
<td align="left" colspan="1" rowspan="1">85.5</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">DenseNet201</td>
<td align="left" colspan="1" rowspan="1">87.5</td>
<td align="left" colspan="1" rowspan="1">88.2</td>
<td align="left" colspan="1" rowspan="1">86.7</td>
<td align="left" colspan="1" rowspan="1">87.0</td>
<td align="left" colspan="1" rowspan="1">83.2</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">ConvNeXt</td>
<td align="left" colspan="1" rowspan="1">86.4</td>
<td align="left" colspan="1" rowspan="1">85.3</td>
<td align="left" colspan="1" rowspan="1">85.0</td>
<td align="left" colspan="1" rowspan="1">85.1</td>
<td align="left" colspan="1" rowspan="1">82.0</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p id="Par57">The superior performance of CHHANIt is a result of collaborative integration of EficientNetB7, DenseNet201, and InceptionResNetV2 models, leveraging the strengths of each model and enhancing the overall performance. This incorporation significantly improves the scalability and accuracy of the model, and enhances feature extraction. The high accuracy demonstrated by CHASHNIt effectively solves the challenge of timely and accurate diagnosis of skin diseases. Although CHASHNIt exhibits exceptional accuracy, its computational complexity is higher than the other lightweighted models like MobileNetV3. This compromise between performance and model complexity highlights the need for resource-efficient optimization to ensure efficient and practical implementation in real world.</p>
<p id="Par58">The uniformity in loss curve and training accuracy graph shown in Fig. <a href="#Fig4" class="usa-link">4</a> highlight model’s exceptional learning capabilities. Lack of sudden shifts and irregular oscillations indicate minimal overfitting and robustness in generalization.</p>
<figure class="fig xbox font-sm" id="Fig4"><h4 class="obj_head">Fig. 4.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Fig4_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/2e0469009cf2/41598_2025_13647_Fig4_HTML.jpg" loading="lazy" id="MO6" height="300" width="794" alt="Fig. 4"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Training accuracy and loss vs epoch.</p></figcaption></figure><p id="Par59">Figure <a href="#Fig5" class="usa-link">5</a> clearly indicates a significant improvement in model’s performance after fine-tuning. Unlocking of additional layers enabled the model to adapt better to the definite dataset.</p>
<figure class="fig xbox font-sm" id="Fig5"><h4 class="obj_head">Fig. 5.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Fig5_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/eb28b1ee20c5/41598_2025_13647_Fig5_HTML.jpg" loading="lazy" id="MO7" height="328" width="793" alt="Fig. 5"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig5/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Fine-tuning accuracy and loss vs epoch.</p></figcaption></figure><p id="Par60">The confusion matrix in Fig. <a href="#Fig6" class="usa-link">6</a>a showcases minimal misclassifications in the 23 classes of diseases. Some common symptoms in Psoriasis and Eczema classes led to sporadic misclassifications.</p>
<figure class="fig xbox font-sm" id="Fig6"><h4 class="obj_head">Fig. 6.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Fig6_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/36e914fc2c55/41598_2025_13647_Fig6_HTML.jpg" loading="lazy" id="MO8" height="406" width="790" alt="Fig. 6"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig6/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p><strong>(a)</strong> Confusion matrix. <strong>(b)</strong> ROC curve.</p></figcaption></figure><p id="Par61">The ROC curves demonstrated in Fig. <a href="#Fig6" class="usa-link">6</a>b persistently display high AUC values. CHASHNIt exhibited values more than 0.95 for each category. This indicates its superior discriminative ability across various disease types. The comparative analysis of CHASHNIt with other models highlights its superiority in distinguishing between similar conditions.</p>
<p id="Par62">All models including CHASHNIt, ResNet50, Swin Transformer and others were trained under identical conditions. Each experiment was repeated five times with different random seeds, and a mean ± 95 % confidence intervals was observed for accuracy, precision, recall, and F1-score. Paired t-tests indicate CHASHNIt’s accuracy is significantly higher than ResNet50 (p = 0.003) and Swin Transformer (p = 0.011). The IoU metric reported corresponds to Class Activation Map (CAM) overlap with dermatologist-annotated lesion masks, thereby justifying its use in a classification context.</p></section><section id="Sec12"><h3 class="pmc_sec_title">Comparative analysis</h3>
<p id="Par63">As it can be seen through Table <a href="#Tab1" class="usa-link">1</a>, CHASHNIt outperforms the rest with 97.8% accuracy which is 7.6% points above the Swin Transformer and 8.2% above the ResNet101 highlighting better generalization and robustness in classification. While Swin Transformer with 90.2% accuracy demonstrates strong performance due to its multi-scale feature extraction capabilities, it still fails to match the overall effectiveness of CHASHNIt. ResNet101 and InceptionResNetV2, despite benefitting from residual connections and inception modules, achieve accuracy of 89.6% and 89.3%, respectively, indicating that their respective architectures are less optimized when independently used for dermatological image classification as compared to the hybrid fusion approach of CHASHNIt.</p>
<p id="Par64">In terms of precision, CHASHNIt attains 98.1%, significantly outperforming Swin Transformer with 90.0% and ResNet101 with 88.3% precision scores. It indicates CHASHNIt’s worth in reducing false positives, which is a necessity in medical application where misclassification can induce unnecessary misclassifications or even wrong treatments. Furthermore, the recall score of 97.5% emphasizes the strength of CHASHNIt in classifying diseased cases when compared to other models such as Swin Transformer which is at 89.5% and ResNet101 which is at 89.7%, which tend to produce higher false negatives. The 97.6% F1-score, a balanced metric of precision and recall, emphasizes the high predictive reliability of the model, especially when compared to rival architectures that fail to achieve a 90% F1-score, with the Swin Transformer registering 89.8% and ResNet101 dropping to 87.4%. CHASHNIt records an IoU score of 92.3%, a huge leap from the Swin Transformer at 84.8% and ResNet101 at 86.0%, thereby registering a higher level of localization and segmentation accuracy in the classification of different types of skin diseases. MobileNetV3, EfficientNetB7, and DenseNet201 all record moderate performance, with different accuracies ranging from 87.5% to 88.7%. Conversely, ConvNeXt ranks at the lower end, with a lower accuracy of 86.4%, precision rate of 85.3%, and IoU score of 82.0%, thereby supporting its relatively lower performance in dermatological classification tasks.</p>
<p id="Par65">The radial graph represented in Fig. <a href="#Fig7" class="usa-link">7</a>a also shows how much CHASHNIt has stood its ground on all the parameters of performance. The shape on the graph that the model produces is well expanded and shows that the accuracy, precision, recall, F1-score, and IoU are all very strong with no significant drop in any area. The radial expansion of CHASHNIt directly correlates with its hybrid architecture’s ability to integrate diverse feature extraction methods, ensuring strong model consistency across all performance dimensions.</p>
<figure class="fig xbox font-sm" id="Fig7"><h4 class="obj_head">Fig. 7.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Fig7_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/81fd528ba21f/41598_2025_13647_Fig7_HTML.jpg" loading="lazy" id="MO9" height="431" width="793" alt="Fig. 7"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig7/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p><strong>(a)</strong> Radial graph. <strong>(b)</strong> Ablation study.</p></figcaption></figure><p id="Par66">The ablation study as shown in Fig. <a href="#Fig7" class="usa-link">7</a>b is conducted carefully to test the performance of all modules within the architecture of CHASHNIt, thereby further solidifying the superiority of its hybrid design. EfficientNetB7, which is famous for its compound scaling efficiency and depth-width-resolution trade-off optimization, achieves 88.1% accuracy, which lags 9.7 percentage points behind that of CHASHNIt. DenseNet201, with dense connectivity and gradient boosting, achieves 87.5% accuracy, denoting improvement in the reuse of features, although not in overall classification refinement. InceptionResNetV2, with the addition of inception modules and residual connections, performs marginally better with 89.3% accuracy; however, it still lags behind CHASHNIt by approximately 8.5 percentage points. This establishes the fact that none of these models are able to perform the same on their own as their hybrid counterpart.</p>
<p id="Par67">In addition to measuring the performance of individual models, ablation study further clarifies notable improvements through feature fusion.</p>
<p id="Par68">Overall, CHASHNIt establishes a new benchmark in artificial intelligence for dermatology, significantly outperforming all existing architectures. The comparison verifies its high accuracy, stability, and explainability, demonstrating its potential as a clinically effective deep-learning model. The radial graph visualization emphasizes CHASHNIt’s consistent superiority, while the ablation study emphasizes the importance of its hybrid architecture.</p></section><section id="Sec13"><h3 class="pmc_sec_title">XAI heatmap analysis</h3>
<p id="Par69">Two algorithmic frameworks namely LIME and SHAP were deployed to explain the decision making process of the models by generating heatmaps. The images start with the left section showing the original image, second section displaying the lime heatmap and third section with SHAP heatmap and desaturated version of the image without any heatmap overlay.</p>
<section id="Sec14"><h4 class="pmc_sec_title">Acne and rosacea</h4>
<p id="Par70">The irregularities on the nasal tip and surrounding areas in the original image of Fig. <a href="#Fig8" class="usa-link">8</a>a indicates the presence of acne or rosacea. The LIME heatmap highlights the regions towards left and right side of the nasal tip with purple tone indicating a significant contribution towards the diagnosis of disease. SHAP highlighted the affected regions near the tip and edges with purple signifying the contribution of the region in diagnosis.</p>
<figure class="fig xbox font-sm" id="Fig8"><h5 class="obj_head">Fig. 8.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Fig8_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/69d51ebcc42c/41598_2025_13647_Fig8_HTML.jpg" loading="lazy" id="MO10" height="147" width="793" alt="Fig. 8"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig8/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p><strong>(a)</strong> Acne and rosacea. <strong>(b)</strong> Actinic keratosis basal cell carcinoma and other malignant lesions.</p></figcaption></figure></section><section id="Sec15"><h4 class="pmc_sec_title">Actinic keratosis basal cell carcinoma and other malignant lesions</h4>
<p id="Par71">The original image in Fig. <a href="#Fig8" class="usa-link">8</a>b indicates the presence of Lesions int the labial mucosa and surrounding areas. LIME highlights the most affected areas in the left and right regions of lower vermilion in purple conveying utmost significance. SHAP highlights the affected regions of lower vermilion as well as the unaffected regions surrounding the middle of vermilion, lingual septum and labium inferius.</p></section><section id="Sec16"><h4 class="pmc_sec_title">Atopic dermatitis</h4>
<p id="Par72">The wrinkles on the skin in original image as demonstrated in Fig. <a href="#Fig9" class="usa-link">9</a>a indicate the presence of Atopic Dermatitis on the fingers and surrounding areas. The LIME heatmap highlights the affected areas on two of the fingers in purple and the third finger in blue. Purple colour indicates the utmost significance of the region in diagnosis. Presence of red and green colour between the fingers indicates noise. SHAP highlights the inflamed and wrinkled areas along with some portion of unaffected areas near the palm.</p>
<figure class="fig xbox font-sm" id="Fig9"><h5 class="obj_head">Fig. 9.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Fig9_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/ab5aa1869f41/41598_2025_13647_Fig9_HTML.jpg" loading="lazy" id="MO11" height="142" width="792" alt="Fig. 9"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig9/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p><strong>(a)</strong> Atopic dermatits. <strong>(b)</strong> Bullous disease.</p></figcaption></figure></section><section id="Sec17"><h4 class="pmc_sec_title">Bullous disease</h4>
<p id="Par73">The red spots on the front and rear regions of axilla in the original image of Fig. <a href="#Fig9" class="usa-link">9</a>b indicates the presence of Bullous disease. The LIME heatmap highlights the two majorly visible affected spots in blue and the other unaffected regions in white. SHAP accurately highlights all the affected regions in dark blue colour.</p></section><section id="Sec18"><h4 class="pmc_sec_title">Cellulitis impetigo and other bacterial infections</h4>
<p id="Par74">Original image in Fig. <a href="#Fig10" class="usa-link">10</a>a shows a bright red region surrounding the anal opening, indicating the effect of infection. LIME heatmap highlights the affected regions surrounding the opening in dark blue indicating utmost significance in detecting the disease. SHAP heatmap highlights the affected areas surrounding the centre as well as the unaffected region near the upper edge deprived of any swelling or redness. Both the frameworks also highlight some unaffected regions along the edges in blue.</p>
<figure class="fig xbox font-sm" id="Fig10"><h5 class="obj_head">Fig. 10.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Fig10_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/e881a58e2329/41598_2025_13647_Fig10_HTML.jpg" loading="lazy" id="MO12" height="139" width="793" alt="Fig. 10"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig10/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p><strong>(a)</strong> Cellulitis impetigo and other bacterial infections. <strong>(b)</strong> Eczema.</p></figcaption></figure></section><section id="Sec19"><h4 class="pmc_sec_title">Eczema</h4>
<p id="Par75">Wrinkles and scars in the original image in Fig. <a href="#Fig10" class="usa-link">10</a>b indicate the presence of Eczema. The LIME heatmap in the second section of the image highlights some of the affected regions in purple and some in blue. SHAP heatmap demonstrates accurate colouration of affected regions in purple with the unaffected regions marked with white.</p></section><section id="Sec20"><h4 class="pmc_sec_title">Exanthems and drug eruptions</h4>
<p id="Par76">The blisters and rashes in original image of Fig. <a href="#Fig11" class="usa-link">11</a>a signify the effects of Exanthems and Drug Eruptions. LIME heatmap highlights the affected regions in the fingers in blue but does not highlight the affected regions near wrists and palm. SHAP highlights the affected regions in fingers as well as palms. The affected regions are accurately highlighted in dark blue colour indicating their significance in diagnosing the infection.</p>
<figure class="fig xbox font-sm" id="Fig11"><h5 class="obj_head">Fig. 11.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Fig11_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/a4d7de5a7c8f/41598_2025_13647_Fig11_HTML.jpg" loading="lazy" id="MO13" height="146" width="793" alt="Fig. 11"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig11/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p><strong>(a)</strong> Exanthems and drug eruption. <strong>(b)</strong> Hair loss alopecia and other hair diseases.</p></figcaption></figure></section><section id="Sec21"><h4 class="pmc_sec_title">Hair loss alopecia and other hair diseases</h4>
<p id="Par77">The original image in Fig. <a href="#Fig11" class="usa-link">11</a>b indicates hair loss and hair disease. The LIME heatmap highlights the affected regions with different colours. The SHAP heatmap majorly uses only three colours for highlighting the regions. This may cause ambiguity in identifying the affected regions.</p></section><section id="Sec22"><h4 class="pmc_sec_title">Herpes and HPV</h4>
<p id="Par78">The presence of lesions near the regions surrounding lingual septum in the original image of Fig. <a href="#Fig12" class="usa-link">12</a>a is a key symptom of Herpes or HPV. The LIME heatmap highlights the affected region in red colour beneath the tongue. SHAP framework accurately highlights the affected regions, mostly beneath the lingua. The most significant regions are highlighted in red and the most insignifcant are marked in black.</p>
<figure class="fig xbox font-sm" id="Fig12"><h5 class="obj_head">Fig. 12.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Fig12_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/b9634c2b2d41/41598_2025_13647_Fig12_HTML.jpg" loading="lazy" id="MO14" height="142" width="793" alt="Fig. 12"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig12/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p><strong>(a)</strong> Herpes and HPV, <strong>(b)</strong> light diseases.</p></figcaption></figure></section><section id="Sec23"><h4 class="pmc_sec_title">Light diseases (pigmentation disorderes)</h4>
<p id="Par79">Original image in Fig. <a href="#Fig12" class="usa-link">12</a>b demonstrates a pigmentation disorder as a dark coloured irregular spot on the skin. The LIME heatmap highlights some of the portion of the image in dark colour. SHAP heatmap highlights only the right portion of the affected region. The black coloured area in the heatmap indicates the region marked as insignificant by the algorithm.</p></section><section id="Sec24"><h4 class="pmc_sec_title">Lupus and other connective tissue diseases</h4>
<p id="Par80">The rashes demonstrated in the original image in Fig. <a href="#Fig13" class="usa-link">13</a>a indicate the presence of connective tissue disease. The LIME heatmap highlights the rash on the second toe in purple and the other rash on the third toe in blue. SHAP framework highlights the both the rash accurately in purple.</p>
<figure class="fig xbox font-sm" id="Fig13"><h5 class="obj_head">Fig. 13.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Fig13_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/97661a3eddb1/41598_2025_13647_Fig13_HTML.jpg" loading="lazy" id="MO15" height="144" width="793" alt="Fig. 13"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig13/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p><strong>(a)</strong> Lupus and other connective tissue diseases. <strong>(b)</strong> Melanoma.</p></figcaption></figure></section><section id="Sec25"><h4 class="pmc_sec_title">Melanoma</h4>
<p id="Par81">The red coloured inflamed spot on the skin as shown in the original image in Fig. <a href="#Fig13" class="usa-link">13</a>b is a visible symptom of Melanoma which plays a key role in the diagnosis of the disease. The LIME framework accurately highlights the affected areas in different colours based on the degree of redness. The SHAP heatmap highlights the entire affected area in same colour.</p></section><section id="Sec26"><h4 class="pmc_sec_title">Nail fungus and other nail diseases</h4>
<p id="Par82">The bright red coloured spot on the lateral nail fold as shown in the image in first section of Fig. <a href="#Fig14" class="usa-link">14</a>a is a key symptom of nail fungus. LIME heatmap highlights the affected areas in dark blue colour. The SHAP framework highlights the whole affected region in a smooth form.</p>
<figure class="fig xbox font-sm" id="Fig14"><h5 class="obj_head">Fig. 14.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Fig14_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/0a0f3e1c87c0/41598_2025_13647_Fig14_HTML.jpg" loading="lazy" id="MO16" height="144" width="792" alt="Fig. 14"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig14/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p><strong>(a)</strong> Nail fungus and other nail diseases. <strong>(b)</strong> Poison ivy and other contact dermatitis.</p></figcaption></figure></section><section id="Sec27"><h4 class="pmc_sec_title">Poison ivy and other contact dermatitis</h4>
<p id="Par83">The hydropic blisters and rashes on the forehead and cheeks as shown in Fig. <a href="#Fig14" class="usa-link">14</a>b indicate the presence of poison ivy dermatitis. The LIME heatmap highlights the affected regions around the buccal and either sides of the forehead in dark blue colour. The SHAP framework accurately highlights the presence of rashes and blisters in dark blue colour.</p></section><section id="Sec28"><h4 class="pmc_sec_title">Psoriasis and lichen planus</h4>
<p id="Par84">The scaly areas on the palpebra in the original image in Fig. <a href="#Fig15" class="usa-link">15</a>a are key symptoms of psoriasis and lichen planus. The LIME heatmap highlights the lower regions of the upper palpebra distinctly. The emphasis on these regions make them highly significant for diagnosis of the disease. The SHAP heatmap highlights the affected areas accurately without any presence of noise in the image. The algorithm significantly brings out the presence of lesions on the skin.</p>
<figure class="fig xbox font-sm" id="Fig15"><h5 class="obj_head">Fig. 15.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Fig15_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/88845f855533/41598_2025_13647_Fig15_HTML.jpg" loading="lazy" id="MO17" height="138" width="793" alt="Fig. 15"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig15/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p><strong>(a)</strong> Psoriasis and lichen planus. <strong>(b)</strong> Scabies and other infestations.</p></figcaption></figure></section><section id="Sec29"><h4 class="pmc_sec_title">Scabies and other infestations</h4>
<p id="Par85">Light red coloured inflammatory spots spread across the legs in the original image of Fig. <a href="#Fig15" class="usa-link">15</a>b indicate the presence of infestations. The LIME heatmap highlights some of the regions of the left leg in dark blue. It highlights the affected regions on the right leg in light blue colour marking them as medically insignificant as compared to the other affected areas. The SHAP heatmap indiscriminately highlights the affected regions of both the legs in dark blue colour. The algorithm considers all of the affected regions at same level of significance.</p></section><section id="Sec30"><h4 class="pmc_sec_title">Seborrheic keratoses and other benign tumors</h4>
<p id="Par86">The rotund skin outgrowth near the concha in the original image in Fig. <a href="#Fig16" class="usa-link">16</a>a is a key symptom of seborrheic keratoses. The LIME heatmap highlights the affected spot with white and light blue colours. The framework identifies the circular highlighted region as a significant factor in identifying the disease. The SHAP framework highlights the affected region near the concha accurately and distinctively. The algorithm marked the other unaffected regions with different colour, reducing the chances of misdiagnosis.</p>
<figure class="fig xbox font-sm" id="Fig16"><h5 class="obj_head">Fig. 16.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Fig16_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/e4e8c927552c/41598_2025_13647_Fig16_HTML.jpg" loading="lazy" id="MO18" height="137" width="793" alt="Fig. 16"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig16/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p><strong>(a)</strong> Seborrheic keratoses and other benign tumors. <strong>(b)</strong> Systemic diseases.</p></figcaption></figure></section><section id="Sec31"><h4 class="pmc_sec_title">Systemic diseases</h4>
<p id="Par87">The black pigmentation on the lateral nail fold and distal edge int the first image of Fig. <a href="#Fig16" class="usa-link">16</a>b is a key symptom of systemic disease. The LIME heatmap highlights the affected regions near the folds and nail body in dark blue colour. The SHAP framework highlights the affected areas accurately in dark colours. The regions comprising of lateral nail folds, nail body and distal edge are considered significant in identifying the disease.</p></section><section id="Sec32"><h4 class="pmc_sec_title">Tinea ringworm and other fungal infections</h4>
<p id="Par88">The original image in Fig. <a href="#Fig17" class="usa-link">17</a>a demonstrates the presence of red lesions following a ring shaped pattern, this is a key symptom of fungal infections like ringworm. The LIME heatmap highlights the affected regions in dark purple shade. The SHAP algorithm accurately highlights the affected areas on the toes and regions surrounding deep peroneal in purple colour.</p>
<figure class="fig xbox font-sm" id="Fig17"><h5 class="obj_head">Fig. 17.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Fig17_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/57cf35d40a09/41598_2025_13647_Fig17_HTML.jpg" loading="lazy" id="MO19" height="136" width="792" alt="Fig. 17"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig17/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p><strong>(a)</strong> Tinea ringworm and other fungal infections. <strong>(b)</strong> Urticaria hives.</p></figcaption></figure></section><section id="Sec33"><h4 class="pmc_sec_title">Urticaria hives</h4>
<p id="Par89">The presence of red coloured welts in the first image of Fig. <a href="#Fig17" class="usa-link">17</a>b plays an important role in diagnosing urticaria hives. The LIME heatmap highlights the affected regions in a disintegrated manner with light blue coloured spots across the area. The SHAP framework accurately highlights affected region with light blue coloured spots on the palm.</p></section><section id="Sec34"><h4 class="pmc_sec_title">Vascular tumors</h4>
<p id="Par90">The red lesion covering the region around superior lacrimal in the original image in Fig. <a href="#Fig18" class="usa-link">18</a>a indicates the presence of vascular tumor in the region. The LIME heatmap highlights the affected regions in dark blue colour. According to the heatmap, the framework identifies the regions near the superior lacrimal and nasal tip as significant for diagnosis of the tumor. The insignificant regions are highlighted in light blue and white colour. SHAP algorithm highlights the affected region near the lacrimal and nasal tip with dark blue colour in a continuous pattern.</p>
<figure class="fig xbox font-sm" id="Fig18"><h5 class="obj_head">Fig. 18.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Fig18_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/9d3968fa7991/41598_2025_13647_Fig18_HTML.jpg" loading="lazy" id="MO20" height="143" width="792" alt="Fig. 18"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig18/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p><strong>(a)</strong> Vascular tumors. <strong>(b)</strong> Vasculitis.</p></figcaption></figure></section><section id="Sec35"><h4 class="pmc_sec_title">Vasculitis</h4>
<p id="Par91">Small light red coloured spots near the radial in the first image of Fig. <a href="#Fig18" class="usa-link">18</a>b play an important role in diagnosing vasculitis. The LIME framework highlights the affected regions in purple colour. The regions near thumb are highlighted as significant regions for the identification of the disease. LIME tends to ignore the affected region lying between the knuckles and the radial by highlighting them in light blue colour. SHAP’s heatmap accurately highlights all the affected regions in purple. The framework highlights the circular spots efficiently, considering all of the affected spots at the same level of significance.</p></section><section id="Sec36"><h4 class="pmc_sec_title">Warts molluscum and other viral infections</h4>
<p id="Par93">The original image in Fig. <a href="#Fig19" class="usa-link">19</a> demonstrates the presence of bristles on the skin which is a key symptom of warts and other viral infections. The LIME heatmap highlights the two of the affected spots in light blue colour. The algorithm misses the affected region in lower medial forefoot and highlights the spot in white marking it as insignificant. The green patches in the either sides of the image indicate the presence of noise in the image. The SHAP heatmap identifies and highlights all of the affected regions in light blue colour. Highlighted regions comprise of medial and lateral forefoot. The insignificant areas are highlighted in purple and white colours.</p>
<figure class="fig xbox font-sm" id="Fig19"><h5 class="obj_head">Fig. 19.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375737_41598_2025_13647_Fig19_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/54b3/12375737/6962072e0a1b/41598_2025_13647_Fig19_HTML.jpg" loading="lazy" id="MO21" height="231" width="793" alt="Fig. 19"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig19/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>LIME and SHAP heatmaps for warts molluscum and other viral infections.</p></figcaption></figure><p id="Par94">Analytical comparison of the two frameworks, SHAP and LIME indicates SHAP’s superior performance as compared to LIME. SHAP demonstrated more accurate and clinically significant outcomes, while LIME was more sensitive to noise which often affected the interpretability. The explainability outputs of CHASHNIt using both LIME and SHAP was evaluated. Quantitative overlap with dermatologist-annotated masks is reported in Section 3. SHAP achieved a mean IoU of 0.68 ± 0.04, whereas LIME scored 0.62 ± 0.05 (p&lt; 0.01, Wilcoxon signed-rank test). Clinician relevance scores (1–5 scale) averaged 4.1 ± 0.3 for SHAP and 3.7 ± 0.4 for LIME (n = 200; p = 0.02), indicating that dermatologists found SHAP slightly more informative.</p>
<p id="Par95">This analysis highlights the role of explainability utilities in ensuring reliability and trust in models. CHASHNIt outperforms all existing models in skin disease classification, yielding unparalleled outcomes in accuracy and XAI integration. The analysis highlights its practical utility, clinical significance, and potential in advancing dermatological diagnosis. Future work could focus on optimizing the model for diverse datasets to enhance its generalizability and clinical implementation.</p></section></section></section><section id="Sec37"><h2 class="pmc_sec_title">Conclusion</h2>
<p id="Par96">This work introduces CHASHNIt, a Combined Hybrid Architecture for Scalable High-performance in Neural Iterations, as a novel deep learning model for skin disease classification, tackling important issues like data imbalance, interpretability, and classification accuracy. The combination of EfficientNetB7, DenseNet201, and InceptionResNetV2 leverages the unique strengths of each architecture using feature extraction, achieving significant classification accuracy enhancement. GAN-based augmentation makes it possible to alleviate class imbalance by generating high-quality synthetic images, which guarantees representative and balanced coverage of all 23 classes of diseases. The addition of Explainable AI techniques increases the model’s usability in a clinical context by SHAP and LIME, which boost decision-making transparency. The suggested framework exhibits outstanding performance with accuracy at 97.8%, precision rate at 98.1%, recall rate at 97.5%, and Intersection over Union or IoU of 92.3%, hence outperforming top models such as Swin Transformer, ResNet101, MobileNetV3, and others. Exhaustive ablation study supports the synergistic gain of the hybrid approach, substantiating the enhanced performance of the model across a range of performance metrics. The efficacy of GAN augmentation and sophisticated preprocessing is also established via comparison, further supporting the reliability of the strategy. In spite of the strengths noted, some obvious limitations are evident. The use of a single information source, in this instance, DermNet, may limit generalizability of findings to other populations and to other imaging diseases. Furthermore, the significant computational demands of the hybrid model also raise questions about practical usability in resource-limited real-world settings. These are areas that underscore the necessity to continue to advance practical usability.</p>
<p id="Par97">Future research will focus on improving computational efficiency by optimizing network architecture and simplifying the model without compromising performance, as well as conducting multi-center clinical trials to assess CHASHNIt’s generalizability across diverse geographic regions and imaging devices. Additionally, deploying CHASHNIt as a cloud-based diagnostic tool is proposed to support small clinics lacking dedicated GPU infrastructure. Leveraging recent advances in SHAP-guided, energy-efficient cloud scheduling<sup><a href="#CR31" class="usa-link" aria-describedby="CR31">31</a></sup>, this approach aims to enable real-time, interpretable predictions with minimal resource overhead.</p>
<p id="Par98">With its established accuracy, interpretability, and class coverage, CHASHNIt is a candidate as a clinical decision-support instrument for dermatology. With its SHAP and LIME usage, it facilitates explainable predictions which is a critical element of clinical trust and its performance on 23 classes renders it deployable in real-world environments, particularly for assist triage or second-opinion use cases. While broader multi-center validation and deployment testing are future goals, CHASHNIt is a technically valid and clinically relevant beginning for explainable AI use in dermatology.</p></section><section id="notes1"><h2 class="pmc_sec_title">Author contributions</h2>
<p>S.A. (Saksham Anand): Conceived the research idea and led the development of the CHASHNIt framework. Authored the Introduction section and designed the overall study structure and flow. A.S. (Abhiram Sharma): Wrote the Literature Review section. Conducted an extensive review of prior studies in skin disease classification, identifying key limitations addressed in this work. A.S.S. (Ashwin Singh Slathia): Drafted the Methodology section, detailing dataset acquisition, preprocessing techniques, model selection, and training execution. Handled model integration and tuning. A.R. (Ayush Rathi): Authored the Results – Model Performance Analysis and Comparative Analysis subsections. Conducted training and benchmarking across all models, and prepared performance metrics and graphs. K.P.B. (Krishna Priyadarshan Behara): Wrote the XAI Heatmap Analysis subsection. Implemented SHAP and LIME visualizations and drafted clinical-style image interpretations across 23 disease classes. B.N. (B Natarajan): Wrote the Abstract and co-wrote the Conclusion section. Also reviewed and edited the manuscript for technical clarity, coherence, and scientific rigor. R.E. (R. Elakkiya): Co-wrote the Conclusion and contributed to the Explainable AI Integration section. Provided supervision throughout the project and ensured alignment with publication standards. All authors reviewed and approved the final manuscript.</p></section><section id="notes2"><h2 class="pmc_sec_title">Funding</h2>
<p>Open access funding provided by Vellore Institute of Technology.</p></section><section id="notes3"><h2 class="pmc_sec_title">Data availability</h2>
<p>The datasets used and analysed during the current study are publicly available from the DermNet repository at http://www.dermnet.com/dermatology-pictures-skin-disease-pictures.</p></section><section id="notes4"><h2 class="pmc_sec_title">Declarations</h2>
<section id="FPar1"><h3 class="pmc_sec_title">Competing interests</h3>
<p id="Par102">The authors declare no competing interests.</p></section></section><section id="fn-group1" class="fn-group"><h2 class="pmc_sec_title">Footnotes</h2>
<div class="fn-group p font-secondary-light font-sm">
<div class="fn p" id="fn1">
<p><strong>Publisher’s note</strong></p>
<p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</div>
<div class="fn p" id="fn2"><p>Saksham Anand, Abhiram Sharma, Ashwin Singh Slathia, Ayush Rathi and Krishna Priyadarshan Behara contributed equally to this work.</p></div>
</div></section><section id="Bib1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="Bib1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="CR1">
<span class="label">1.</span><cite>Flohr, C. &amp; Hay, R. Putting the burden of skin diseases on the global map. <em>Br. J. Dermatol.</em><strong>184</strong>(2), 189–190. 10.1111/bjd.19704 (2021).
</cite> [<a href="https://doi.org/10.1111/bjd.19704" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33544440/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Flohr,%20C.%20&amp;%20Hay,%20R.%20Putting%20the%20burden%20of%20skin%20diseases%20on%20the%20global%20map.%20Br.%20J.%20Dermatol.184(2),%20189%E2%80%93190.%2010.1111/bjd.19704%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR2">
<span class="label">2.</span><cite>Karimkhani, C. et al. Global skin disease morbidity and mortality: An update from the Global Burden of Disease Study 2013. <em>JAMA Dermatol.</em><strong>153</strong>(5), 406. 10.1001/jamadermatol.2016.5538 (2017).
</cite> [<a href="https://doi.org/10.1001/jamadermatol.2016.5538" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC5817488/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/28249066/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Karimkhani,%20C.%20et%20al.%20Global%20skin%20disease%20morbidity%20and%20mortality:%20An%20update%20from%20the%20Global%20Burden%20of%20Disease%20Study%202013.%20JAMA%20Dermatol.153(5),%20406.%2010.1001/jamadermatol.2016.5538%20(2017)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR3">
<span class="label">3.</span><cite>Wu, Z. et al. Studies on different CNN algorithms for face skin disease classification based on clinical images. <em>IEEE Access</em><strong>7</strong>, 66505–66511. 10.1109/ACCESS.2019.2918221 (2019).</cite> [<a href="https://scholar.google.com/scholar_lookup?Wu,%20Z.%20et%20al.%20Studies%20on%20different%20CNN%20algorithms%20for%20face%20skin%20disease%20classification%20based%20on%20clinical%20images.%20IEEE%20Access7,%2066505%E2%80%9366511.%2010.1109/ACCESS.2019.2918221%20(2019)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR4">
<span class="label">4.</span><cite>Hossen, Md. N. et al. Federated machine learning for detection of skin diseases and enhancement of internet of medical things (IoMT) security. <em>IEEE J. Biomed. Health Inform.</em><strong>27</strong>(2), 835–841. 10.1109/JBHI.2022.3149288 (2023).
</cite> [<a href="https://doi.org/10.1109/JBHI.2022.3149288" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35133971/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Hossen,%20Md.%20N.%20et%20al.%20Federated%20machine%20learning%20for%20detection%20of%20skin%20diseases%20and%20enhancement%20of%20internet%20of%20medical%20things%20(IoMT)%20security.%20IEEE%20J.%20Biomed.%20Health%20Inform.27(2),%20835%E2%80%93841.%2010.1109/JBHI.2022.3149288%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR5">
<span class="label">5.</span><cite>Asif, S., Zhao, M., Li, Y., Tang, F. &amp; Zhu, Y. CFI-Net: A Choquet fuzzy integral based ensemble network with PSO-optimized fuzzy measures for diagnosing multiple skin diseases including Mpox. <em>IEEE J. Biomed. Health Inform.</em><strong>28</strong>(9), 5573–5586. 10.1109/JBHI.2024.3411658 (2024).
</cite> [<a href="https://doi.org/10.1109/JBHI.2024.3411658" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38857139/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Asif,%20S.,%20Zhao,%20M.,%20Li,%20Y.,%20Tang,%20F.%20&amp;%20Zhu,%20Y.%20CFI-Net:%20A%20Choquet%20fuzzy%20integral%20based%20ensemble%20network%20with%20PSO-optimized%20fuzzy%20measures%20for%20diagnosing%20multiple%20skin%20diseases%20including%20Mpox.%20IEEE%20J.%20Biomed.%20Health%20Inform.28(9),%205573%E2%80%935586.%2010.1109/JBHI.2024.3411658%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR6">
<span class="label">6.</span><cite>Hao, S. et al. ConvNeXt-ST-AFF: A novel skin disease classification model based on fusion of ConvNeXt and Swin transformer. <em>IEEE Access</em><strong>11</strong>, 117460–117473. 10.1109/ACCESS.2023.3324042 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Hao,%20S.%20et%20al.%20ConvNeXt-ST-AFF:%20A%20novel%20skin%20disease%20classification%20model%20based%20on%20fusion%20of%20ConvNeXt%20and%20Swin%20transformer.%20IEEE%20Access11,%20117460%E2%80%93117473.%2010.1109/ACCESS.2023.3324042%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR7">
<span class="label">7.</span><cite>Lee, K. et al. Multi-task and few-shot learning-based fully automatic deep learning platform for mobile diagnosis of skin diseases. <em>IEEE J. Biomed. Health Inform.</em><strong>27</strong>(1), 176–187. 10.1109/JBHI.2022.3193685 (2023).
</cite> [<a href="https://doi.org/10.1109/JBHI.2022.3193685" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35877797/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Lee,%20K.%20et%20al.%20Multi-task%20and%20few-shot%20learning-based%20fully%20automatic%20deep%20learning%20platform%20for%20mobile%20diagnosis%20of%20skin%20diseases.%20IEEE%20J.%20Biomed.%20Health%20Inform.27(1),%20176%E2%80%93187.%2010.1109/JBHI.2022.3193685%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR8">
<span class="label">8.</span><cite>Zhuang, F. et al. A comprehensive survey on transfer learning. <em>Proc. IEEE</em><strong>109</strong>(1), 43–76. 10.1109/JPROC.2020.3004555 (2021).</cite> [<a href="https://scholar.google.com/scholar_lookup?Zhuang,%20F.%20et%20al.%20A%20comprehensive%20survey%20on%20transfer%20learning.%20Proc.%20IEEE109(1),%2043%E2%80%9376.%2010.1109/JPROC.2020.3004555%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR9">
<span class="label">9.</span><cite>Balasundaram, A., Shaik, A., Alroy, B. R., Singh, A. &amp; Shivaprakash, S. J. Genetic algorithm optimized stacking approach to skin disease detection. <em>IEEE Access</em><strong>12</strong>, 88950–88962. 10.1109/ACCESS.2024.3412791 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Balasundaram,%20A.,%20Shaik,%20A.,%20Alroy,%20B.%20R.,%20Singh,%20A.%20&amp;%20Shivaprakash,%20S.%20J.%20Genetic%20algorithm%20optimized%20stacking%20approach%20to%20skin%20disease%20detection.%20IEEE%20Access12,%2088950%E2%80%9388962.%2010.1109/ACCESS.2024.3412791%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR10">
<span class="label">10.</span><cite>Adegun, A. A. &amp; Viriri, S. FCN-based DenseNet framework for automated detection and classification of skin lesions in dermoscopy images. <em>IEEE Access</em><strong>8</strong>, 150377–150396. 10.1109/ACCESS.2020.3016651 (2020).</cite> [<a href="https://scholar.google.com/scholar_lookup?Adegun,%20A.%20A.%20&amp;%20Viriri,%20S.%20FCN-based%20DenseNet%20framework%20for%20automated%20detection%20and%20classification%20of%20skin%20lesions%20in%20dermoscopy%20images.%20IEEE%20Access8,%20150377%E2%80%93150396.%2010.1109/ACCESS.2020.3016651%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR11">
<span class="label">11.</span><cite>Ahmad, B. et al. Discriminative feature learning for skin disease classification using deep convolutional neural network. <em>IEEE Access</em><strong>8</strong>, 39025–39033. 10.1109/ACCESS.2020.2975198 (2020).</cite> [<a href="https://scholar.google.com/scholar_lookup?Ahmad,%20B.%20et%20al.%20Discriminative%20feature%20learning%20for%20skin%20disease%20classification%20using%20deep%20convolutional%20neural%20network.%20IEEE%20Access8,%2039025%E2%80%9339033.%2010.1109/ACCESS.2020.2975198%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR12">
<span class="label">12.</span><cite>Zhang, J., Xie, Y., Xia, Y. &amp; Shen, C. Attention residual learning for skin lesion classification. <em>IEEE Trans. Med. Imaging</em><strong>38</strong>(9), 2092–2103. 10.1109/TMI.2019.2893944 (2019).
</cite> [<a href="https://doi.org/10.1109/TMI.2019.2893944" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/30668469/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Zhang,%20J.,%20Xie,%20Y.,%20Xia,%20Y.%20&amp;%20Shen,%20C.%20Attention%20residual%20learning%20for%20skin%20lesion%20classification.%20IEEE%20Trans.%20Med.%20Imaging38(9),%202092%E2%80%932103.%2010.1109/TMI.2019.2893944%20(2019)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR13">
<span class="label">13.</span><cite>Sharma, Y., Tiwari, N. K. &amp; Upaddhyay, V. K. EffSVMNet: An efficient hybrid neural network for improved skin disease classification. <em>Smart Health</em><strong>34</strong>, 100520. 10.1016/j.smhl.2024.100520 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Sharma,%20Y.,%20Tiwari,%20N.%20K.%20&amp;%20Upaddhyay,%20V.%20K.%20EffSVMNet:%20An%20efficient%20hybrid%20neural%20network%20for%20improved%20skin%20disease%20classification.%20Smart%20Health34,%20100520.%2010.1016/j.smhl.2024.100520%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR14">
<span class="label">14.</span><cite>Sasithradevi, A. et al. EffiCAT: A synergistic approach to skin disease classification through multi-dataset fusion and attention mechanisms. <em>Biomed. Signal Process. Control</em><strong>100</strong>, 107141. 10.1016/j.bspc.2024.107141 (2025).</cite> [<a href="https://scholar.google.com/scholar_lookup?Sasithradevi,%20A.%20et%20al.%20EffiCAT:%20A%20synergistic%20approach%20to%20skin%20disease%20classification%20through%20multi-dataset%20fusion%20and%20attention%20mechanisms.%20Biomed.%20Signal%20Process.%20Control100,%20107141.%2010.1016/j.bspc.2024.107141%20(2025)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR15">
<span class="label">15.</span><cite>Rokade, S. &amp; Mishra, N. A blockchain-based deep learning system with optimization for skin disease classification. <em>Biomed. Signal Process. Control</em><strong>95</strong>, 106380. 10.1016/j.bspc.2024.106380 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Rokade,%20S.%20&amp;%20Mishra,%20N.%20A%20blockchain-based%20deep%20learning%20system%20with%20optimization%20for%20skin%20disease%20classification.%20Biomed.%20Signal%20Process.%20Control95,%20106380.%2010.1016/j.bspc.2024.106380%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR16">
<span class="label">16.</span><cite>Kalpana, B., Reshmy, A. K., Pandi, S Senthil &amp; Dhanasekaran, S. OESV-KRF: Optimal ensemble support vector kernel random forest based early detection and classification of skin diseases. <em>Biomed. Signal Process. Control</em><strong>85</strong>, 104779. 10.1016/j.bspc.2023.104779 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Kalpana,%20B.,%20Reshmy,%20A.%20K.,%20Pandi,%20S%20Senthil%20&amp;%20Dhanasekaran,%20S.%20OESV-KRF:%20Optimal%20ensemble%20support%20vector%20kernel%20random%20forest%20based%20early%20detection%20and%20classification%20of%20skin%20diseases.%20Biomed.%20Signal%20Process.%20Control85,%20104779.%2010.1016/j.bspc.2023.104779%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR17">
<span class="label">17.</span><cite>Ahammed, M., Mamun, Md. A. &amp; Uddin, M. S. A machine learning approach for skin disease detection and classification using image segmentation. <em>Healthc. Anal.</em><strong>2</strong>, 100122. 10.1016/j.health.2022.100122 (2022).</cite> [<a href="https://scholar.google.com/scholar_lookup?Ahammed,%20M.,%20Mamun,%20Md.%20A.%20&amp;%20Uddin,%20M.%20S.%20A%20machine%20learning%20approach%20for%20skin%20disease%20detection%20and%20classification%20using%20image%20segmentation.%20Healthc.%20Anal.2,%20100122.%2010.1016/j.health.2022.100122%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR18">
<span class="label">18.</span><cite>Gu, Y., Ge, Z., Bonnington, C. P. &amp; Zhou, J. Progressive transfer learning and adversarial domain adaptation for cross-domain skin disease classification. <em>IEEE J. Biomed. Health Inform.</em><strong>24</strong>(5), 1379–1393. 10.1109/JBHI.2019.2942429 (2020).
</cite> [<a href="https://doi.org/10.1109/JBHI.2019.2942429" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31545748/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Gu,%20Y.,%20Ge,%20Z.,%20Bonnington,%20C.%20P.%20&amp;%20Zhou,%20J.%20Progressive%20transfer%20learning%20and%20adversarial%20domain%20adaptation%20for%20cross-domain%20skin%20disease%20classification.%20IEEE%20J.%20Biomed.%20Health%20Inform.24(5),%201379%E2%80%931393.%2010.1109/JBHI.2019.2942429%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR19">
<span class="label">19.</span><cite>Balasundaram, A., Shaik, A., Alroy, B. R., Singh, A. &amp; Shivaprakash, S. J. Genetic algorithm optimized stacking approach to skin disease detection. <em>IEEE Access</em><strong>12</strong>, 88950–88962. 10.1109/ACCESS.2024.3412791 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Balasundaram,%20A.,%20Shaik,%20A.,%20Alroy,%20B.%20R.,%20Singh,%20A.%20&amp;%20Shivaprakash,%20S.%20J.%20Genetic%20algorithm%20optimized%20stacking%20approach%20to%20skin%20disease%20detection.%20IEEE%20Access12,%2088950%E2%80%9388962.%2010.1109/ACCESS.2024.3412791%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR20">
<span class="label">20.</span><cite>Pham, T.-C., Doucet, A., Luong, C.-M., Tran, C.-T. &amp; Hoang, V.-D. Improving skin-disease classification based on customized loss function combined with balanced mini-batch logic and real-time image augmentation. <em>IEEE Access</em><strong>8</strong>, 150725–150737. 10.1109/ACCESS.2020.3016653 (2020).</cite> [<a href="https://scholar.google.com/scholar_lookup?Pham,%20T.-C.,%20Doucet,%20A.,%20Luong,%20C.-M.,%20Tran,%20C.-T.%20&amp;%20Hoang,%20V.-D.%20Improving%20skin-disease%20classification%20based%20on%20customized%20loss%20function%20combined%20with%20balanced%20mini-batch%20logic%20and%20real-time%20image%20augmentation.%20IEEE%20Access8,%20150725%E2%80%93150737.%2010.1109/ACCESS.2020.3016653%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR21">
<span class="label">21.</span><cite>Vachmanus, S., Noraset, T., Piyanonpong, W., Rattananukrom, T. &amp; Tuarob, S. DeepMetaForge: A deep vision-transformer metadata-fusion network for automatic skin lesion classification. <em>IEEE Access</em><strong>11</strong>, 145467–145484. 10.1109/ACCESS.2023.3345225 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Vachmanus,%20S.,%20Noraset,%20T.,%20Piyanonpong,%20W.,%20Rattananukrom,%20T.%20&amp;%20Tuarob,%20S.%20DeepMetaForge:%20A%20deep%20vision-transformer%20metadata-fusion%20network%20for%20automatic%20skin%20lesion%20classification.%20IEEE%20Access11,%20145467%E2%80%93145484.%2010.1109/ACCESS.2023.3345225%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR22">
<span class="label">22.</span><cite>Sharma, A. &amp; Parvathi, R. Enhancing cervical cancer classification: Through a hybrid deep learning approach integrating DenseNet201 and InceptionV3. In <em>IEEE Access</em>. 10.1109/ACCESS.2025.3527677 (2025).</cite>
</li>
<li id="CR23">
<span class="label">23.</span><cite>Balaji, V. R. et al. Skin disease detection and segmentation using dynamic graph cut algorithm and classification through Naive Bayes classifier. <em>Measurement</em><strong>163</strong>, 107922. 10.1016/j.measurement.2020.107922 (2020).</cite> [<a href="https://scholar.google.com/scholar_lookup?Balaji,%20V.%20R.%20et%20al.%20Skin%20disease%20detection%20and%20segmentation%20using%20dynamic%20graph%20cut%20algorithm%20and%20classification%20through%20Naive%20Bayes%20classifier.%20Measurement163,%20107922.%2010.1016/j.measurement.2020.107922%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR24">
<span class="label">24.</span><cite>Karthik, R., Vaichole, T. S., Kulkarni, S. K., Yadav, O. &amp; Khan, F. Eff2Net: An efficient channel attention-based convolutional neural network for skin disease classification. <em>Biomed. Signal Process. Control</em><strong>73</strong>, 103406. 10.1016/j.bspc.2021.103406 (2022).</cite> [<a href="https://scholar.google.com/scholar_lookup?Karthik,%20R.,%20Vaichole,%20T.%20S.,%20Kulkarni,%20S.%20K.,%20Yadav,%20O.%20&amp;%20Khan,%20F.%20Eff2Net:%20An%20efficient%20channel%20attention-based%20convolutional%20neural%20network%20for%20skin%20disease%20classification.%20Biomed.%20Signal%20Process.%20Control73,%20103406.%2010.1016/j.bspc.2021.103406%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR25">
<span class="label">25.</span><cite>Bajwa, Muhammad Naseer et al. Computer-aided diagnosis of skin diseases using deep neural networks. <em>Appl. Sci.</em><strong>10</strong>, 2488. 10.3390/app10072488 (2020).</cite> [<a href="https://scholar.google.com/scholar_lookup?Bajwa,%20Muhammad%20Naseer%20et%20al.%20Computer-aided%20diagnosis%20of%20skin%20diseases%20using%20deep%20neural%20networks.%20Appl.%20Sci.10,%202488.%2010.3390/app10072488%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR26">
<span class="label">26.</span><cite>Kostopoulos, N., Kalogeras, D., Pantazatos, D., Grammatikou, M. &amp; Maglaris, V. SHAP interpretations of tree and neural network DNS classifiers for analyzing DGA family characteristics. <em>IEEE Access</em><strong>11</strong>, 61144–61160. 10.1109/ACCESS.2023.3286313 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Kostopoulos,%20N.,%20Kalogeras,%20D.,%20Pantazatos,%20D.,%20Grammatikou,%20M.%20&amp;%20Maglaris,%20V.%20SHAP%20interpretations%20of%20tree%20and%20neural%20network%20DNS%20classifiers%20for%20analyzing%20DGA%20family%20characteristics.%20IEEE%20Access11,%2061144%E2%80%9361160.%2010.1109/ACCESS.2023.3286313%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR27">
<span class="label">27.</span><cite>Azad, M., Khan, M. F. K. &amp; El-Ghany, S. A. XAI-enhanced machine learning for obesity risk classification: A stacking approach with LIME explanations. <em>IEEE Access</em><strong>13</strong>, 13847–13865. 10.1109/ACCESS.2025.3530840 (2025).</cite> [<a href="https://scholar.google.com/scholar_lookup?Azad,%20M.,%20Khan,%20M.%20F.%20K.%20&amp;%20El-Ghany,%20S.%20A.%20XAI-enhanced%20machine%20learning%20for%20obesity%20risk%20classification:%20A%20stacking%20approach%20with%20LIME%20explanations.%20IEEE%20Access13,%2013847%E2%80%9313865.%2010.1109/ACCESS.2025.3530840%20(2025)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR28">
<span class="label">28.</span><cite>DermNet official website. <a href="https://dermnetnz.org/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://dermnetnz.org/</a>.</cite>
</li>
<li id="CR29">
<span class="label">29.</span><cite>Saber, A. et al. An optimized ensemble model based on meta-heuristic algorithms for effective detection and classification of breast tumors. <em>Neural Comput. Appl.</em><strong>37</strong>, 4881–4894. 10.1007/s00521-024-10719-9 (2025).</cite> [<a href="https://scholar.google.com/scholar_lookup?Saber,%20A.%20et%20al.%20An%20optimized%20ensemble%20model%20based%20on%20meta-heuristic%20algorithms%20for%20effective%20detection%20and%20classification%20of%20breast%20tumors.%20Neural%20Comput.%20Appl.37,%204881%E2%80%934894.%2010.1007/s00521-024-10719-9%20(2025)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR30">
<span class="label">30.</span><cite>Alnowaiser, K., Saber, A., Hassan, E. &amp; Awad, W. A. An optimized model based on adaptive convolutional neural network and grey wolf algorithm for breast cancer diagnosis. <em>PLOS ONE</em><strong>19</strong>(8), e0304868. 10.1371/journal.pone.0304868 (2024).
</cite> [<a href="https://doi.org/10.1371/journal.pone.0304868" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11332925/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39159151/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Alnowaiser,%20K.,%20Saber,%20A.,%20Hassan,%20E.%20&amp;%20Awad,%20W.%20A.%20An%20optimized%20model%20based%20on%20adaptive%20convolutional%20neural%20network%20and%20grey%20wolf%20algorithm%20for%20breast%20cancer%20diagnosis.%20PLOS%20ONE19(8),%20e0304868.%2010.1371/journal.pone.0304868%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR31">
<span class="label">31.</span><cite>Slathia, A. S. et al. SHERA: SHAP-enhanced resource allocation for VM scheduling and efficient cloud computing. In <em>IEEE Access</em>. Vol. 13. 92816–92832 (2025). 10.1109/ACCESS.2025.3568917.</cite>
</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adda93_" lang="en" class="data-availability-statement"><h3 class="pmc_sec_title">Data Availability Statement</h3>
<p>The datasets used and analysed during the current study are publicly available from the DermNet repository at http://www.dermnet.com/dermatology-pictures-skin-disease-pictures.</p></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from Scientific Reports are provided here courtesy of <strong>Nature Publishing Group</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1038/s41598-025-13647-3"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/41598_2025_Article_13647.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (6.3 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12375737/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12375737/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12375737%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12375737/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12375737/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12375737/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40850939/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12375737/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40850939/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12375737/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12375737/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="xf3VaJnAeWtzJBqsw9KVJ0tRFlJUCQJxlM9dVTvNQiJzX8NdbSXDiXWrPHnf9vx4">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
    

    </body>
</html>
