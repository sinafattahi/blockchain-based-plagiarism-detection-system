
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            Navigating tenses in Bengali sentences: A stacked ensemble model for enhanced prediction - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="AE532FF38AF23383052FF3003A2EB41C.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="plosone">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370126/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="PLOS One">
<meta name="citation_title" content="Navigating tenses in Bengali sentences: A stacked ensemble model for enhanced prediction">
<meta name="citation_author" content="Umme Ayman">
<meta name="citation_author_institution" content="Department of CSE, Daffodil International University Daffodil Smart City (DSC), Birulia, Savar, Dhaka, Bangladesh">
<meta name="citation_author" content="Md Nahid Hasan">
<meta name="citation_author_institution" content="Department of CSE, Dhaka International University, Dhaka, Bangladesh">
<meta name="citation_author" content="Ms Nusrat Khan">
<meta name="citation_author_institution" content="Department of CSE, Daffodil International University Daffodil Smart City (DSC), Birulia, Savar, Dhaka, Bangladesh">
<meta name="citation_author" content="Ms Chayti Saha">
<meta name="citation_author_institution" content="Department of CSE, Daffodil International University Daffodil Smart City (DSC), Birulia, Savar, Dhaka, Bangladesh">
<meta name="citation_author" content="Md Fayejullah">
<meta name="citation_author_institution" content="Department of CSE, University of Wollongong, Wollongong, New South Wales, Australia">
<meta name="citation_publication_date" content="2025 Aug 21">
<meta name="citation_volume" content="20">
<meta name="citation_issue" content="8">
<meta name="citation_firstpage" content="e0330186">
<meta name="citation_doi" content="10.1371/journal.pone.0330186">
<meta name="citation_pmid" content="40839646">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370126/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370126/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370126/pdf/pone.0330186.pdf">
<meta name="description" content="Tense classification in Bengali sentences is a fundamental yet unsolved problem of Bangla natural language processing (NLP) which is essential for tasks like machine translation, sentiment analysis, grammar correction, writing assistance and ...">
<meta name="og:title" content="Navigating tenses in Bengali sentences: A stacked ensemble model for enhanced prediction">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="Tense classification in Bengali sentences is a fundamental yet unsolved problem of Bangla natural language processing (NLP) which is essential for tasks like machine translation, sentiment analysis, grammar correction, writing assistance and ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370126/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12370126">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1371/journal.pone.0330186"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/pone.0330186.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12370126%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12370126/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12370126/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370126/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-plosone.png" alt="PLOS One logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to PLOS One" title="Link to PLOS One" shape="default" href="https://doi.org/10.1371/journal.pone.0330186" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">PLoS One</button></div>. 2025 Aug 21;20(8):e0330186. doi: <a href="https://doi.org/10.1371/journal.pone.0330186" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1371/journal.pone.0330186</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22PLoS%20One%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22PLoS%20One%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22PLoS%20One%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22PLoS%20One%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Navigating tenses in Bengali sentences: A stacked ensemble model for enhanced prediction</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Ayman%20U%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Umme Ayman</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Umme Ayman</span></h3>
<div class="p">
<sup>1</sup>Department of CSE, Daffodil International University Daffodil Smart City (DSC), Birulia, Savar, Dhaka, Bangladesh</div>
<div>Data curation, Writing – original draft, Writing – review &amp; editing</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Ayman%20U%22%5BAuthor%5D" class="usa-link"><span class="name western">Umme Ayman</span></a>
</div>
</div>
<sup>1</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Hasan%20MN%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Md Nahid Hasan</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">Md Nahid Hasan</span></h3>
<div class="p">
<sup>2</sup>Department of CSE, Dhaka International University, Dhaka, Bangladesh</div>
<div>Formal analysis, Methodology, Supervision, Visualization</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Hasan%20MN%22%5BAuthor%5D" class="usa-link"><span class="name western">Md Nahid Hasan</span></a>
</div>
</div>
<sup>2,</sup><sup>*</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Khan%20MN%22%5BAuthor%5D" class="usa-link" aria-describedby="id3"><span class="name western">Ms Nusrat Khan</span></a><div hidden="hidden" id="id3">
<h3><span class="name western">Ms Nusrat Khan</span></h3>
<div class="p">
<sup>1</sup>Department of CSE, Daffodil International University Daffodil Smart City (DSC), Birulia, Savar, Dhaka, Bangladesh</div>
<div>Data curation, Writing – review &amp; editing</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Khan%20MN%22%5BAuthor%5D" class="usa-link"><span class="name western">Ms Nusrat Khan</span></a>
</div>
</div>
<sup>1</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Saha%20MC%22%5BAuthor%5D" class="usa-link" aria-describedby="id4"><span class="name western">Ms Chayti Saha</span></a><div hidden="hidden" id="id4">
<h3><span class="name western">Ms Chayti Saha</span></h3>
<div class="p">
<sup>1</sup>Department of CSE, Daffodil International University Daffodil Smart City (DSC), Birulia, Savar, Dhaka, Bangladesh</div>
<div>Data curation, Writing – review &amp; editing</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Saha%20MC%22%5BAuthor%5D" class="usa-link"><span class="name western">Ms Chayti Saha</span></a>
</div>
</div>
<sup>1</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Fayejullah%20M%22%5BAuthor%5D" class="usa-link" aria-describedby="id5"><span class="name western">Md Fayejullah</span></a><div hidden="hidden" id="id5">
<h3><span class="name western">Md Fayejullah</span></h3>
<div class="p">
<sup>3</sup>Department of CSE, University of Wollongong, Wollongong, New South Wales, Australia</div>
<div>Formal analysis, Writing – review &amp; editing</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Fayejullah%20M%22%5BAuthor%5D" class="usa-link"><span class="name western">Md Fayejullah</span></a>
</div>
</div>
<sup>3</sup>
</div>
<div class="cg p">Editor: <span class="name western">Saman Kasmaiee</span><sup>4</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="aff001">
<sup>1</sup>Department of CSE, Daffodil International University Daffodil Smart City (DSC), Birulia, Savar, Dhaka, Bangladesh</div>
<div id="aff002">
<sup>2</sup>Department of CSE, Dhaka International University, Dhaka, Bangladesh</div>
<div id="aff003">
<sup>3</sup>Department of CSE, University of Wollongong, Wollongong, New South Wales, Australia</div>
<div id="edit1">
<sup>4</sup>Amirkabir University of Technology, IRAN, ISLAMIC REPUBLIC OF</div>
<div class="author-notes p">
<div class="fn" id="coi001"><p><strong>Competing Interests: </strong>The authors have declared that no competing interests exist.</p></div>
<div class="fn" id="cor001">
<sup>✉</sup><p class="display-inline">* E-mail: <span>nahid.hasan.bondhan@gmail.com</span></p>
</div>
</div>
<h4 class="font-secondary">Roles</h4>
<div class="p">
<strong class="contrib"><span class="name western">Umme Ayman</span></strong>: <span class="role">Data curation, Writing – original draft, Writing – review &amp; editing</span>
</div>
<div>
<strong class="contrib"><span class="name western">Md Nahid Hasan</span></strong>: <span class="role">Formal analysis, Methodology, Supervision, Visualization</span>
</div>
<div>
<strong class="contrib"><span class="name western">Ms Nusrat Khan</span></strong>: <span class="role">Data curation, Writing – review &amp; editing</span>
</div>
<div>
<strong class="contrib"><span class="name western">Ms Chayti Saha</span></strong>: <span class="role">Data curation, Writing – review &amp; editing</span>
</div>
<div>
<strong class="contrib"><span class="name western">Md Fayejullah</span></strong>: <span class="role">Formal analysis, Writing – review &amp; editing</span>
</div>
<div class="p">
<strong class="contrib"><span class="name western">Saman Kasmaiee</span></strong>: <span class="role">Editor</span>
</div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2025 Jan 8; Accepted 2025 Jul 17; Collection date 2025.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© 2025 Ayman et al</div>
<p>This is an open access article distributed under the terms of the <a href="https://creativecommons.org/licenses/by/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Creative Commons Attribution License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12370126  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40839646/" class="usa-link">40839646</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="abstract1"><h2>Abstract</h2>
<p>Tense classification in Bengali sentences is a fundamental yet unsolved problem of Bangla natural language processing (NLP) which is essential for tasks like machine translation, sentiment analysis, grammar correction, writing assistance and sentence generation. This study addresses this gap by proposing a robust stacked ensemble model designed for accurate automatic tense classification in Bengali sentences. To support this, we construct a novel Bengali corpus “BengaliTenseCorpus” comprising 13,500 manually collected and meticulously labelled sentences, categorized into three tense classes: Present (0), Past (1) and Future (2). The sentences gathered from diverse sources including news articles, songs, poems and novels, went through rigorous preprocessing techniques to preserve linguistic integrity and improve performance on data. The proposed architecture integrates predictions from five base models— Random Forest, Support Vector Machine, XGBoost classifier, Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU) into the meta model— neural network to build a stacked ensemble framework. Experimental results demonstrate that this ensemble model outperforms individual models, achieving a classification accuracy of 85% on test data. This work presents the first large-scale Bengali tense classification system combining machine learning and deep learning methods in a stacked ensemble framework, establishing a strong performance benchmark for Bangla NLP with practical applications in intelligent writing tools, grammar assistance, and language learning. The findings highlight how well ensemble-based systems can capture the intricacies of Bengali verb morphology. To further boost the development of Bangla language models and applications, future extensions of this work may involve expanding the dataset, exploring transformer-based models, and incorporating tense-to-tense morphological conversion.</p></section><section id="sec001"><h2 class="pmc_sec_title">Introduction</h2>
<p>Language is a system of conventional spoken, manual (signed), or written symbols humans use to express themselves [<a href="#pone.0330186.ref001" class="usa-link" aria-describedby="pone.0330186.ref001">1</a>]. Approximately 7,111 living languages exist today. Bangla is one of the most significant languages in the world. Pali and Magdhi Prakrit are the languages that gave rise to Bengali [<a href="#pone.0330186.ref002" class="usa-link" aria-describedby="pone.0330186.ref002">2</a>]. One of the most Eastern Indo-Aryan languages spoken in the Indian subcontinent is Bengali. The Bangla language ranked 7th for the most-used speaking language in the world, with 272.8 million native speakers [<a href="#pone.0330186.ref003" class="usa-link" aria-describedby="pone.0330186.ref003">3</a>]. Despite its prevalence, Bengali’s complex grammatical structure presents significant challenges for computational tasks, particularly in the area of natural language processing (NLP). One critical aspect of Bengali language is its tense system, which is essential for conveying temporal context and ensuring grammatical accuracy [<a href="#pone.0330186.ref004" class="usa-link" aria-describedby="pone.0330186.ref004">4</a>]. Tenses denote the time reference of verbs [<a href="#pone.0330186.ref005" class="usa-link" aria-describedby="pone.0330186.ref005">5</a>], allowing speakers to express actions relative to the present, past, or future [<a href="#pone.0330186.ref006" class="usa-link" aria-describedby="pone.0330186.ref006">6</a>]. Accurate tense classification is crucial for a range of NLP applications, including text classification, machine translation, and sentiment analysis [<a href="#pone.0330186.ref007" class="usa-link" aria-describedby="pone.0330186.ref007">7</a>]. This research focuses specifically on automatic tense classification in Bengali text, a core NLP classification problem aimed at improving the understanding of temporal expressions in Bangla sentences. In Bengali, tense classification is particularly challenging due to the language’s intricate morphology and syntax, making it difficult for humans and machines to automate tense identification and classification accurately. Bengali has unique difficulties for NLP tasks like tense categorization since it is a low-resource language with a rich morphology. The language features complex inflectional morphology, where verb forms change based on tense, aspect, person, number, and honorifics, making rule-based or simplistic statistical models ineffective. Bengali mostly uses suffix modifications to indicate tense, which can be nuanced and context-dependent, in contrast to English, where auxiliary verbs are frequently used to indicate tense. Furthermore, it is more difficult to correctly detect verb locations and tense indicators due to its variable word order and syntactic ambiguities. These problems are made worse by the dearth of annotated language materials and tools. Our suggested stacked ensemble model is especially well-suited to address these challenges by utilizing deep learning models (LSTM and GRU) to capture the temporal dependencies and sequential patterns present in Bengali verb usage, as well as conventional classifiers (like SVM and XGBoost) for pattern recognition. In a linguistically complex language like Bengali, this hybrid technique improves the model’s generalization across a variety of sentence structures and verb conjugations, leading to more accurate tense categorization. Thus, automatic tense classification from Bengali text would be the most remarkable part of the Bangla natural language processing research domain in terms of text classification. Therefore, the clear objective of this study is to develop a stacked ensemble model combining deep learning (LSTM, GRU) and machine learning (SVM, XGBoost) techniques to accurately classify tenses in Bengali text, addressing the linguistic complexities and resource limitations inherent in the Bengali that can enhance downstream applications such as machine translation, educational technologies, and AI-powered communication tools for Bengali-speaking communities. Breaking new ground in Bangla NLP, our pioneering study is the first to tackle tense classification, setting a precedent in linguistic research. Numerous academics have completed various language processing tasks to classify or categorise texts into numerous aspects of natural language processing (NLP) by applying various methods. Kumar Das <em>et al</em>. (2021) [<a href="#pone.0330186.ref008" class="usa-link" aria-describedby="pone.0330186.ref008">8</a>] study on Bengali hate speech detection on Facebook found that machine learning models, including an attention-based decoder, achieved a 77% accuracy rate, indicating potential for further research. Rahman and Chakraborty (2021) [<a href="#pone.0330186.ref009" class="usa-link" aria-describedby="pone.0330186.ref009">9</a>] study uses a deep recurrent neural network with BiLSTM architecture to classify Bangla documents, achieving high accuracy of 98.87%, but highlighting limitations like data scarcity. Ghosh <em>et al</em>. (2022) [<a href="#pone.0330186.ref010" class="usa-link" aria-describedby="pone.0330186.ref010">10</a>] created a machine learning model for detecting depressive social media texts in Bangla, achieving 94.3% accuracy, highlighting the need for diverse datasets and improvements in low-resource languages. Rezaul <em>et al</em>. (2023) [<a href="#pone.0330186.ref011" class="usa-link" aria-describedby="pone.0330186.ref011">11</a>] conducted a multi-class sentiment analysis on Bengali social media comments using a dataset of 42,036 comments. They used a supervised deep learning classifier, achieving an accuracy of 85.8% and an F1 score of 0.86. Rahman <em>et al</em>. (2024) [<a href="#pone.0330186.ref012" class="usa-link" aria-describedby="pone.0330186.ref012">12</a>] used machine learning techniques to analyze sentiment in eLearning texts in Bangla and Romanized Bangla. They achieved high accuracy with XLM-RoBERTa, but faced limitations due to cultural context. Despite these advancements in text classification in various aspects, there is a clear gap in the Bengali NLP landscape, particularly concerning the automatic classification of tenses in Bengali text. Accurate identification and classification of verb tenses are essential for various applications in Bangla language processing and computational linguistics. The complexity of Bengalis verb forms, compounded by its rich morphology, demands more robust and specialised approaches. By focusing on this significance challenges , the research aims to bridge the gap by developing an ensemble model using machine learning and deep learning-based models by utilising a BengaliTense dataset consisting of 13,500 Bengali sentences collected from diverse sources like, Bangla blogs, Facebook pages, magazines and news articles and labeling them into three different classes to employ various data preprocessing techniques over it . The dataset contains Bengali sentences from various sources, labelling them into three classes. The model uses various data preprocessing techniques and models to enhance automatic tense classification in Bengali text. This study aims to fill gaps in existing text classification processes and expand the scope of text analysis tasks in any language related to tense classification. There is little to no work for Bangla tense categorization in the Bangla NLP job. The absence of an appropriate dataset is the main cause of this circumstance. Our unique contribution is the creation of a prediction model to forecast the tense of Bangla text and a dataset to describe the Bangla tense. All relevant data are available from the Mendeley repository at: <a href="https://data.mendeley.com/datasets/w9mdy6tw84/1" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://data.mendeley.com/datasets/w9mdy6tw84/1</a>.</p>
<p>The major contributions of this study are mentioned as follows:</p>
<ul class="list" style="list-style-type:disc">
<li><p>Introducing a dataset “BengaliTenseCorpus: A comprehensive corpus in Bengali texts categorized in Present , Past, and Future” which consists of 13,500 Bengali sentences collected from diverse sources categorised into three classes as Present (0), Past (1), and Future (2). “<a href="https://data.mendeley.com/datasets/w9mdy6tw84/1" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://data.mendeley.com/datasets/w9mdy6tw84/1</a>”</p></li>
<li><p>Several pre-processing techniques have been applied to ensure data quality as well as machine feasibility.</p></li>
<li><p>Machine learning and deep learning models have been studied and selected based on the type of our dataset.</p></li>
<li><p>An ensemble is introduced by the combination of three selected machine learning algorithms, XGB,RF,and SVM , as well as two deep learning algorithms , LSTM and GRU.</p></li>
<li><p>A comparative study is accomplished by analysing the performance of the applied models and our proposed model based on several performance metrics to identify the best performing approach.</p></li>
</ul></section><section id="sec002"><h2 class="pmc_sec_title">Literature review</h2>
<p>Kumar Das <em>et al</em>. (2021) [<a href="#pone.0330186.ref008" class="usa-link" aria-describedby="pone.0330186.ref008">8</a>] investigated hate speech detection in Bengali social media comments, focusing on Facebook. The dataset contains 7,425 comments categorized into seven classes, including hate speech, religious hatred, and political comments. The study used several machine learning models, with the attention-based decoder achieving the best accuracy of 77%. Limitations include the need for improved accuracy and a larger dataset. This research provides a foundation for further work on Bengali hate speech detection using advanced ML techniques.</p>
<p>Asghar <em>et al</em>. (2021) [<a href="#pone.0330186.ref013" class="usa-link" aria-describedby="pone.0330186.ref013">13</a>] introduced the Senti-eSystem, a sentiment-based system combining fuzzy logic and deep neural networks to measure customer satisfaction. Using a dataset of 11,541 tweets from Kaggle, categorized into positive and negative sentiments, the system employs a BiLSTM model with an attention mechanism, achieving 92.86% accuracy, outperforming traditional lexicon-based methods. Limitations include the imbalanced dataset, which could affect performance, and the need for testing across various domains. The authors also note that the dataset size is relatively small for big data applications, suggesting the potential for improvement with larger, more balanced datasets.</p>
<p>Rahman and Chakraborty (2021) [<a href="#pone.0330186.ref009" class="usa-link" aria-describedby="pone.0330186.ref009">9</a>] present a method for classifying Bangla documents using a Deep Recurrent Neural Network with a BiLSTM architecture. They employed a dataset of 40,000 Bangla news articles, categorized into 12 classes, after data cleaning. The model achieved a high accuracy of 98.87%, along with precision, recall, and F1 scores of 0.989. Despite these results, the study highlights limitations like the scarcity of Bangla datasets and the potential drop in performance with larger datasets.</p>
<p>Salehin <em>et al</em>. (2021) [<a href="#pone.0330186.ref014" class="usa-link" aria-describedby="pone.0330186.ref014">14</a>] conducted a comparative study on various text classification approaches for Bangla news articles, using a large dataset of 75,951 articles categorized into 12 classes. The study implemented several machine learning classifiers and neural networks, with LSTM achieving the highest accuracy at 87%, followed by SVM and XGBoost at 77%. Despite these promising results, the paper notes limitations, such as the use of a single dataset type and the risk of overfitting with complex models like LSTM. The research provides valuable insights into Bangla text classification, encouraging further exploration in this area.</p>
<p>Khan <em>et al</em>. (2021) [<a href="#pone.0330186.ref015" class="usa-link" aria-describedby="pone.0330186.ref015">15</a>] conducted sentiment analysis on Bengali Facebook comments to assess fans’ emotions toward celebrities. The dataset comprised 63,000 comments from 12-15 celebrity pages, classified into seven emotion categories: Happy, Sad, Angry, Surprised, Excited, Religious, and Abusive. Various machine learning models were applied, with SVM achieving the highest accuracy of 62%, outperforming Random Forest and K-Nearest Neighbors. The study faced challenges due to an imbalanced dataset, where only 3,000 comments were labeled, affecting overall accuracy.</p>
<p>Bangyal <em>et al</em>. (2021) [<a href="#pone.0330186.ref016" class="usa-link" aria-describedby="pone.0330186.ref016">16</a>] focused on detecting fake news related to COVID-19 using deep learning techniques. They utilized a dataset of 4,072 articles (2,426 true, 1,646 false) and experimented with various models. Logistic regression achieved 75.65% accuracy, while a stacking-based model attained an F1-score of 0.972. The best result was from a hybrid model combining neural and non-neural features, with a random forest classifier reaching 94.49% accuracy. Limitations include the potential dataset biases and questions about the generalizability of the models to other contexts.</p>
<p>The paper by Bhowmik <em>et al</em>. (2021) [<a href="#pone.0330186.ref017" class="usa-link" aria-describedby="pone.0330186.ref017">17</a>] develops a domain-specific lexicon data dictionary (LDD) for Bangla sentiment analysis using 50,000 comments from the restaurant and cricket domains, categorized into positive, negative, and neutral classes. They propose a Bangla Text Sentiment Score (BTSC) algorithm and use machine learning methods like SVM, achieving the highest accuracy of 82.21%. The study’s limitations include difficulty in detecting neutral sentiments and the time-consuming manual construction of lexicons, affecting scalability and overall accuracy.</p>
<p>Bhowmik <em>et al</em>.(2022) [<a href="#pone.0330186.ref018" class="usa-link" aria-describedby="pone.0330186.ref018">18</a>] developed a sentiment analysis model for Bengali text using an extended lexicon dictionary and deep learning techniques, achieving an accuracy of 85.8% with a hybrid CNN-LSTM architecture. The model was fine-tuned with a learning rate of 0.0001, a batch size of 25, and 20 epochs. However, limitations include the model’s lack of generalization due to a limited dataset, which may introduce bias in the results.</p>
<p>Ghosh <em>et al</em>. (2022) [<a href="#pone.0330186.ref010" class="usa-link" aria-describedby="pone.0330186.ref010">10</a>] developed a machine learning model to detect depressive social media texts in Bangla, addressing the lack of existing datasets by creating one with 15,031 samples (4,784 depressive and 10,247 non-depressive posts). They proposed an attention-based BiLSTM-CNN model, achieving 94.3% accuracy, with 92.63% sensitivity and 95.12% specificity. The study highlights the need for more diverse datasets and improvements for low-resource languages like Bangla.</p>
<p>Wadud <em>et al</em>. (2022) [<a href="#pone.0330186.ref019" class="usa-link" aria-describedby="pone.0330186.ref019">19</a>] proposed LSTM-BOOST, an offensive text classification algorithm combining LSTM networks with ensemble learning, to detect offensive Bengali texts on social media. They utilized the Bengali Offensive Text from Social Platforms (BHSSP) dataset with 20,000 posts equally split between offensive and non-offensive content. The model achieved a high F1-score of 92.61%, outperforming other classifiers. However, limitations include difficulty handling long sequence texts and varying accuracy with regional Bengali dialects. Future research aims to address these challenges.</p>
<p>Rahman <em>et al</em>. (2022) [<a href="#pone.0330186.ref020" class="usa-link" aria-describedby="pone.0330186.ref020">20</a>] focused on sentiment classification of Bengali text using the Word2Vec model, categorizing emotions into happy, angry, and excited. They processed a large dataset, excluding English words, to enhance accuracy. The Skip-Gram model achieved the highest accuracy of 75%, outperforming LSTM and CNN. The study faced challenges with the complexity of the Bengali language and noisy datasets, which impacted the overall performance of sentiment classification.</p>
<p>The paper by Chakraborty <em>et al</em>. (2022) [<a href="#pone.0330186.ref021" class="usa-link" aria-describedby="pone.0330186.ref021">21</a>] focuses on sentiment analysis of Bengali Facebook data, using a dataset of 10,819 automatically labeled comments and posts, classified into positive and negative sentiments. Seven classifiers were evaluated, including classical methods like Naive Bayes and Random Forest, and deep learning approaches such as LSTM and CNN. The LSTM model achieved the highest accuracy of 96.95%, outperforming the classical models, with Random Forest achieving 78.37%. While limitations like dataset biases are not discussed, the study demonstrates the superior performance of deep learning for Bengali sentiment analysis.</p>
<p>The paper by Prottasha <em>et al</em>. (2022) [<a href="#pone.0330186.ref022" class="usa-link" aria-describedby="pone.0330186.ref022">22</a>] explores sentiment analysis in the Bangla language using transfer learning with BERT and a hybrid CNN-BiLSTM model. It employs a dataset of 8,952 samples, with 4,325 labeled as positive and the rest negative, sourced from various platforms like social media. The Bangla-BERT model achieved the highest accuracy of 94.15%, outperforming models like Word2Vec and fastText. However, the study noted limitations due to the unbalanced dataset, which may affect the model’s efficiency. Future work will focus on expanding the dataset and enhancing real-world performance.</p>
<p>The paper by Aurpa <em>et al</em>. (2022) [<a href="#pone.0330186.ref023" class="usa-link" aria-describedby="pone.0330186.ref023">23</a>] addresses the detection of abusive Bangla comments on Facebook, using a dataset of 44,001 comments categorized into five classes: sexual, troll, religious, threat, and not bully. Transformer-based deep learning models like BERT and ELECTRA were employed, with BERT achieving the highest test accuracy of 85.00%. The study highlights the lack of labeled datasets for Bangla abusive comments as a limitation, impacting generalizability. This research significantly advances the detection of abusive content in the Bangla language, aiding in better online content moderation.</p>
<p>Rezaul <em>et al</em>. focuses [<a href="#pone.0330186.ref011" class="usa-link" aria-describedby="pone.0330186.ref011">11</a>] on multi-class sentiment analysis (SA) in the Bengali language, addressing the challenges of classifying sentiments expressed in social media comments. It utilizes a dataset of 42,036 Facebook comments, categorized into four classes: sexual, religious, political, and acceptable. The authors propose a supervised deep learning classifier based on CNN and LSTM architectures, achieving a maximum accuracy of 85.8% and an F1 score of 0.86, which outperforms baseline models. However, the study acknowledges limitations such as the peculiarities of Bengali text, the lack of ground truth datasets, and the scarcity of preprocessing tools, which can hinder performance.</p>
<p>Sourav <em>et al</em>. (2023) [<a href="#pone.0330186.ref024" class="usa-link" aria-describedby="pone.0330186.ref024">24</a>] developed a transformer-based model for classifying emotions in Bangla texts, using the Unified Bangla Multi-class Emotion Corpus (UBMEC) with 13,436 samples annotated for six emotion classes. The model achieved a weighted F1-score of 71% for the six classes and 76% for a simplified four-class model using m-BERT. Despite its success, the study highlights limitations such as the small dataset size and room for improvement with more training. The paper is a significant contribution to Bangla emotion classification using transformers.</p>
<p>Jahan <em>et al</em>. (2023) [<a href="#pone.0330186.ref025" class="usa-link" aria-describedby="pone.0330186.ref025">25</a>] developed a method to identify misogynistic content in Bangla on social media, using a dataset of 15,000 comments from Facebook, Instagram, TikTok, and YouTube. The dataset was categorized into misogynistic and non-misogynistic classes, including subcategories like objectification and sexual harassment. The study utilized LSTM and RNN models, with LSTM achieving the highest accuracy of 67%. Limitations include the small dataset size and potential biases from manual labeling. This research contributes to understanding and identifying misogynistic content in Bangla.</p>
<p>The paper by Roy <em>et al</em>. (2023) [<a href="#pone.0330186.ref026" class="usa-link" aria-describedby="pone.0330186.ref026">26</a>] introduces a new Bengali text classification dataset containing 1,756 documents across 38 classes, such as ’Agriculture,’ ’Banking,’ and ’Politics.’ They evaluated various machine learning and deep learning models, with “FastText with SVC” achieving the highest accuracy of 92.61% and a weighted F1-score of 0.92. The main limitation was confusion between similar classes like “Entertainment” and “Entertainment other than cinema and music.” This study provides a valuable benchmark for future research in Bengali text classification.</p>
<p>The paper by Wadud <em>et al</em>. (2023) [<a href="#pone.0330186.ref027" class="usa-link" aria-describedby="pone.0330186.ref027">27</a>] introduces Deep-BERT, a model designed to classify multilingual offensive texts on social media, focusing on English and Bengali. The dataset includes 7000 English and 6500 Bengali comments, categorized into offensive (5085) and non-offensive (8415) classes. The Deep-BERT model achieved the highest accuracy of 93.11%, outperforming other methods like MNB and KNN. The study’s limitations include the lack of a standardized multilingual offensive text corpus, which may impact generalizability. This research advances offensive language detection in a multilingual setting using deep learning techniques.</p>
<p>Rahman <em>et al</em>. (2024) [<a href="#pone.0330186.ref012" class="usa-link" aria-describedby="pone.0330186.ref012">12</a>] conducted sentiment analysis on eLearning texts in Bangla and Romanized Bangla, using three datasets: 3,178 Bangla, 3,090 Romanized Bangla, and 6,268 combined texts, categorized into positive, negative, and neutral classes. They applied machine learning techniques, with XLM-RoBERTa achieving the highest accuracy of 89.46% on the Bangla dataset and 85.81% on the combined dataset, while ANN performed best for Romanized Bangla at 89.59%. The study faced limitations, including cultural context influencing sentiment expression and the need for larger, more diverse datasets. Chowdhury <em>et al</em>.(2024) [<a href="#pone.0330186.ref038" class="usa-link" aria-describedby="pone.0330186.ref038">38</a>] presents a comprehensive study on detecting depression in Bengali social media texts using a diverse set of models, including deep learning (LSTM, BiLSTM, GRU, BiGRU), transformer models (BERT, BanglaBERT, SahajBERT), and large language models (GPT-3.5, GPT-4, DepGPT). The authors introduce a new Bengali Social Media Depressive Dataset (BSMDD) of 21,910 data of two classes , and demonstrate that their fine-tuned model, DepGPT, outperforms other models with a remarkable F1-score of 0.9804 and accuracy 0.9796. A key strength lies in comparing zero-shot and few-shot learning across models, alongside exploring explainable AI for interpretability. However, the paper lacks a deeper analysis of potential annotation biases, dataset representativeness, and generalizability across different social media platforms. Islam <em>et al</em>. (2024) [<a href="#pone.0330186.ref039" class="usa-link" aria-describedby="pone.0330186.ref039">39</a>] introduces a large-scale Bangla sentiment analysis dataset (BangDSA) with over 200,000 manually annotated comments across 15 categories, addressing the lack of comprehensive resources for Bangla NLP. It proposes a novel hybrid feature extraction method, skipBangla-BERT, combining Bangla-BERT and Skipgram, which outperforms traditional approaches. The authors evaluate multiple machine learning, ensemble, and deep learning models, achieving 95.71% accuracy in 3-class sentiment classification using a CNN-BiLSTM architecture. A major strength is the extensive experimentation with 21 feature extraction techniques and statistical validation of results. However, limitations include reliance on manually crawled data from only five platforms, potential annotation biases despite validation, and lack of testing on cross-domain or unseen datasets, affecting generalizability. Future work should explore domain adaptation, transfer learning, and broader linguistic diversity to enhance robustness Mahmud <em>et al</em>. (2024) [<a href="#pone.0330186.ref040" class="usa-link" aria-describedby="pone.0330186.ref040">40</a>] presents an extensive evaluation of machine learning, deep learning, hybrid, and transformer-based models for multilingual cyberbullying detection in Bangla and Chittagonian texts, introducing a new manually annotated dataset of over 10,000 samples. The authors achieve strong results, with XLM-Roberta reaching 84.1% accuracy and the hybrid (CNN+LSTM)+BiLSTM model attaining 82% accuracy, outperforming traditional approaches. A notable contribution is the inclusion of both Bangla and the low-resource Chittagonian language, along with rigorous annotation validation using Krippendorff’s alpha and Cohen’s kappa. However, limitations include reliance on a relatively small dataset sourced primarily from a few social media platforms, raising concerns about representativeness and potential domain bias. Future work could expand dataset diversity, assess deployment feasibility, and explore fairness and bias mitigation in multilingual contexts. Rathnayake <em>et al</em>. (2024) [<a href="#pone.0330186.ref041" class="usa-link" aria-describedby="pone.0330186.ref041">41</a>] showed that socioeconomic indicators can be efficiently modeled using machine learning to comprehend complicated, non-linear interactions that drive gender disparity in Sri Lanka. This encouraged us to reflect on the structured, yet complex patterns inherent in language, such as verb tenses, which often reflect syntactic and morphological dependencies. Despite the fact that we do not deal with socioeconomic factors, the study supported our method of applying machine learning to recognize systematic patterns present in environments with limited resources. The spirit of this study aligns with the objective of our work, which is to use data-driven methods to comprehend and categorize subtle, structurally embedded patterns, in this case, tense variations in Bangla. In a Sri Lankan economic context, Kularathne <em>et al</em>., 2024 [<a href="#pone.0330186.ref042" class="usa-link" aria-describedby="pone.0330186.ref042">42</a>] shows how machine learning can be used to model real-world phenomena with structured yet variable patterns. Similarly, Bengali verb tense classification requires knowledge of both structured rules (grammar) and exceptions (morphological variability). The combination of machine learning and economic indicators for modeling rice production offered a compelling argument for the use of predictive analytics in low-resource contexts. Bengali NLP faces resource scarcity, much like Sri Lanka’s agricultural sector. This study reinforced our decision to rely on models like Random Forest and XGBoost, which have shown success with limited data and complex relationships in time-series or domain-specific forecasting - analogous to how Bengali tense patterns exhibit variability over syntactic and morphological dimensions. The way the authors applied models like XGBoost and decision trees supports our choice to include tree-based classifiers in our ensemble model due to their ability to handle irregular but meaningful patterns in sparse and heterogeneous datasets. Rathnayake <em>et al</em>., 2023 [<a href="#pone.0330186.ref043" class="usa-link" aria-describedby="pone.0330186.ref043">43</a>] established a strong argument for the use of hybrid learning frameworks and model ensembles, especially in fields where large data variation and noise may make deterministic rule-based modeling ineffective. The fact that individual models would not adequately reflect the grammatical richness of Bangla further strengthened our resolve to combine traditional machine learning with deep learning methods like LSTM and GRU. Their proficiency with ensemble methods and CatBoost verifies our approach of stacking models to increase accuracy and generalizability. This affirmed our design decision to capture the complex structure of Bangla verb forms by merging rule-based and deep learning models. This study [<a href="#pone.0330186.ref044" class="usa-link" aria-describedby="pone.0330186.ref044">44</a>] suggests a sentiment analysis model that uses ERNIE for encoding and combines contextual semantics and emotional interactions with BiGRU, attention, and GCN. It outperforms baseline models with a macro-F1 score of 71.90% on the JDDC dataset. However, single-domain data and the lack of multimodal or topic-aware characteristics restrict its use. <a href="#pone.0330186.t001" class="usa-link">Table 1</a> represents the literature summary of related works.</p>
<section class="tw xbox font-sm" id="pone.0330186.t001"><h3 class="obj_head">Table 1. Literature summary of related works.</h3>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">Reference</th>
<th align="left" rowspan="1" colspan="1">Algorithm</th>
<th align="left" rowspan="1" colspan="1">Classes</th>
<th align="left" rowspan="1" colspan="1">Dataset Size</th>
<th align="left" rowspan="1" colspan="1">Accuracy</th>
<th align="left" rowspan="1" colspan="1">Context</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Kumar Das <em>et al</em>. (2021) [<a href="#pone.0330186.ref008" class="usa-link" aria-describedby="pone.0330186.ref008">8</a>]</td>
<td align="left" rowspan="1" colspan="1">Attention-based Decoder</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">7,425</td>
<td align="left" rowspan="1" colspan="1">77%</td>
<td align="left" rowspan="1" colspan="1">Hate speech detection</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Asghar <em>et al</em>. (2021) [<a href="#pone.0330186.ref013" class="usa-link" aria-describedby="pone.0330186.ref013">13</a>]</td>
<td align="left" rowspan="1" colspan="1">BiLSTM with Attention</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">11,541</td>
<td align="left" rowspan="1" colspan="1">92.86%</td>
<td align="left" rowspan="1" colspan="1">Sentiment measurement and customer satisfaction prediction</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Rahman and Chakraborty (2021) [<a href="#pone.0330186.ref009" class="usa-link" aria-describedby="pone.0330186.ref009">9</a>]</td>
<td align="left" rowspan="1" colspan="1">BiLSTM</td>
<td align="left" rowspan="1" colspan="1">12</td>
<td align="left" rowspan="1" colspan="1">40,000</td>
<td align="left" rowspan="1" colspan="1">98.87%</td>
<td align="left" rowspan="1" colspan="1">Bangla documents classification</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Salehin <em>et al</em>. (2021) [<a href="#pone.0330186.ref014" class="usa-link" aria-describedby="pone.0330186.ref014">14</a>]</td>
<td align="left" rowspan="1" colspan="1">LSTM, SVM, XGBoost</td>
<td align="left" rowspan="1" colspan="1">12</td>
<td align="left" rowspan="1" colspan="1">75,951</td>
<td align="left" rowspan="1" colspan="1">87%</td>
<td align="left" rowspan="1" colspan="1">News headline classification</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Khan <em>et al</em>. 2021) [<a href="#pone.0330186.ref015" class="usa-link" aria-describedby="pone.0330186.ref015">15</a>]</td>
<td align="left" rowspan="1" colspan="1">SVM, Random Forest, KNN</td>
<td align="left" rowspan="1" colspan="1">7</td>
<td align="left" rowspan="1" colspan="1">63,000</td>
<td align="left" rowspan="1" colspan="1">62%</td>
<td align="left" rowspan="1" colspan="1">Sentiment and emotion classification</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Bangyal <em>et al</em>. (2021) [<a href="#pone.0330186.ref016" class="usa-link" aria-describedby="pone.0330186.ref016">16</a>]</td>
<td align="left" rowspan="1" colspan="1">Hybrid Neural Model</td>
<td align="left" rowspan="1" colspan="1">1</td>
<td align="left" rowspan="1" colspan="1">4,072</td>
<td align="left" rowspan="1" colspan="1">94.49%</td>
<td align="left" rowspan="1" colspan="1">Fake news detection</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Bhowmik <em>et al</em>. (2021) [<a href="#pone.0330186.ref017" class="usa-link" aria-describedby="pone.0330186.ref017">17</a>]</td>
<td align="left" rowspan="1" colspan="1">SVM</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">50,000</td>
<td align="left" rowspan="1" colspan="1">82.21%</td>
<td align="left" rowspan="1" colspan="1">Sentiment analysis</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Bhowmik <em>et al</em>. (2022) [<a href="#pone.0330186.ref018" class="usa-link" aria-describedby="pone.0330186.ref018">18</a>]</td>
<td align="left" rowspan="1" colspan="1">CNN-LSTM</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">50,000</td>
<td align="left" rowspan="1" colspan="1">85.8%</td>
<td align="left" rowspan="1" colspan="1">Sentiment analysis</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Ghosh <em>et al</em>. (2022) [<a href="#pone.0330186.ref010" class="usa-link" aria-describedby="pone.0330186.ref010">10</a>]</td>
<td align="left" rowspan="1" colspan="1">BiLSTM-CNN</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">15,031</td>
<td align="left" rowspan="1" colspan="1">94.3%</td>
<td align="left" rowspan="1" colspan="1">Depressive social media text detection</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Wadud <em>et al</em>. 2022) [<a href="#pone.0330186.ref019" class="usa-link" aria-describedby="pone.0330186.ref019">19</a>]</td>
<td align="left" rowspan="1" colspan="1">LSTM-BOOST</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">20,000</td>
<td align="left" rowspan="1" colspan="1">F1: 92.61%</td>
<td align="left" rowspan="1" colspan="1">Offensive text classification</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Rahman <em>et al</em>. (2022) [<a href="#pone.0330186.ref020" class="usa-link" aria-describedby="pone.0330186.ref020">20</a>]</td>
<td align="left" rowspan="1" colspan="1">Word2Vec, LSTM, CNN</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">11,000</td>
<td align="left" rowspan="1" colspan="1">75%</td>
<td align="left" rowspan="1" colspan="1">Sentiment classification</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Chakraborty <em>et al</em>. (2022) [<a href="#pone.0330186.ref021" class="usa-link" aria-describedby="pone.0330186.ref021">21</a>]</td>
<td align="left" rowspan="1" colspan="1">LSTM, CNN, Naive Bayes, Random Forest</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">10,819</td>
<td align="left" rowspan="1" colspan="1">96.95%</td>
<td align="left" rowspan="1" colspan="1">Sentiment classification</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Prottasha <em>et al</em>. (2022) [<a href="#pone.0330186.ref022" class="usa-link" aria-describedby="pone.0330186.ref022">22</a>]</td>
<td align="left" rowspan="1" colspan="1">BERT, CNN-BiLSTM</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">8,952</td>
<td align="left" rowspan="1" colspan="1">94.15%</td>
<td align="left" rowspan="1" colspan="1">Sentiment classification</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Aurpa <em>et al</em>. (2022) [<a href="#pone.0330186.ref021" class="usa-link" aria-describedby="pone.0330186.ref021">21</a>
</td>
<td align="left" rowspan="1" colspan="1">BERT, ELECTRA</td>
<td align="left" rowspan="1" colspan="1">5</td>
<td align="left" rowspan="1" colspan="1">44,001</td>
<td align="left" rowspan="1" colspan="1">85%</td>
<td align="left" rowspan="1" colspan="1">Abusive comments detection</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Rezaul <em>et al</em>. (2023) [<a href="#pone.0330186.ref011" class="usa-link" aria-describedby="pone.0330186.ref011">11</a>]</td>
<td align="left" rowspan="1" colspan="1">CNN, LSTM</td>
<td align="left" rowspan="1" colspan="1">4</td>
<td align="left" rowspan="1" colspan="1">42,036</td>
<td align="left" rowspan="1" colspan="1">85.8%</td>
<td align="left" rowspan="1" colspan="1">Sentiment analysis</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Sourav <em>et al</em>. (2023) [<a href="#pone.0330186.ref024" class="usa-link" aria-describedby="pone.0330186.ref024">24</a>]</td>
<td align="left" rowspan="1" colspan="1">(m-BERT)</td>
<td align="left" rowspan="1" colspan="1">6</td>
<td align="left" rowspan="1" colspan="1">13,436</td>
<td align="left" rowspan="1" colspan="1">71%</td>
<td align="left" rowspan="1" colspan="1">Emotion classification</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Jahan <em>et al</em>. 2023) [<a href="#pone.0330186.ref025" class="usa-link" aria-describedby="pone.0330186.ref025">25</a>]</td>
<td align="left" rowspan="1" colspan="1">LSTM, RNN</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">15,000</td>
<td align="left" rowspan="1" colspan="1">67%</td>
<td align="left" rowspan="1" colspan="1">Misogynistic content identification</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Roy <em>et al</em>. (2023) [<a href="#pone.0330186.ref026" class="usa-link" aria-describedby="pone.0330186.ref026">26</a>]</td>
<td align="left" rowspan="1" colspan="1">FastText with SVC</td>
<td align="left" rowspan="1" colspan="1">38</td>
<td align="left" rowspan="1" colspan="1">1,756</td>
<td align="left" rowspan="1" colspan="1">92.61%</td>
<td align="left" rowspan="1" colspan="1">News headline classification</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Wadud <em>et al</em>. (2023) [<a href="#pone.0330186.ref027" class="usa-link" aria-describedby="pone.0330186.ref027">27</a>]</td>
<td align="left" rowspan="1" colspan="1">Deep-BERT</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">13,500</td>
<td align="left" rowspan="1" colspan="1">93.11%</td>
<td align="left" rowspan="1" colspan="1">Offensive text classification</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Rahman <em>et al</em>. (2024) [<a href="#pone.0330186.ref012" class="usa-link" aria-describedby="pone.0330186.ref012">12</a>]</td>
<td align="left" rowspan="1" colspan="1">XLM-RoBERTa, ANN</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">6,268</td>
<td align="left" rowspan="1" colspan="1">89.59%</td>
<td align="left" rowspan="1" colspan="1">Sentiment classification</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Chowdhury <em>et al</em>.(2024) [<a href="#pone.0330186.ref038" class="usa-link" aria-describedby="pone.0330186.ref038">38</a>]</td>
<td align="left" rowspan="1" colspan="1">LSTM, BiLSTM, GRU, BiGRU, BERT, BanglaBERT, SahajBERT, GPT-3.5, GPT-4, DepGpt</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">21910</td>
<td align="left" rowspan="1" colspan="1">97.96%</td>
<td align="left" rowspan="1" colspan="1">Depression detection</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Islam <em>et al</em>. (2024) [<a href="#pone.0330186.ref039" class="usa-link" aria-describedby="pone.0330186.ref039">39</a>]</td>
<td align="left" rowspan="1" colspan="1">skipBangla-BERT, CNN-BiLSTM</td>
<td align="left" rowspan="1" colspan="1">15</td>
<td align="left" rowspan="1" colspan="1">200000</td>
<td align="left" rowspan="1" colspan="1">95.71%</td>
<td align="left" rowspan="1" colspan="1">Sentiment Analysis</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Mahmud <em>et al</em>. (2024) [<a href="#pone.0330186.ref040" class="usa-link" aria-describedby="pone.0330186.ref040">40</a>]</td>
<td align="left" rowspan="1" colspan="1">SVM, Bangla Bert, M-Bert, Bangla ElectraXLM-Roberta, CNN, LSTM. Bi-LSTM</td>
<td align="left" rowspan="1" colspan="1">4</td>
<td align="left" rowspan="1" colspan="1">10000</td>
<td align="left" rowspan="1" colspan="1">84.1%</td>
<td align="left" rowspan="1" colspan="1">Multilingual Cyberbullying Detection</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Rathnayake <em>et al</em>. (2024) [<a href="#pone.0330186.ref041" class="usa-link" aria-describedby="pone.0330186.ref041">41</a>]</td>
<td align="left" rowspan="1" colspan="1">Random Forest (RF), Logistic Regression, Gradient Boosted Trees, XGBoost, Deep Learning Neural Networks</td>
<td align="left" rowspan="1" colspan="1">3</td>
<td align="left" rowspan="1" colspan="1">21756</td>
<td align="left" rowspan="1" colspan="1">87.3%</td>
<td align="left" rowspan="1" colspan="1">Socioeconomic inequality</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Kularathne <em>et al</em>., 2024 [<a href="#pone.0330186.ref042" class="usa-link" aria-describedby="pone.0330186.ref042">42</a>]</td>
<td align="left" rowspan="1" colspan="1">Decision Tree (DT), Support Vector Machine (SVM), Random Forest (RF), Gradient Boosted Decision Trees (GBDT),Logistic Regression, LightGBM, CatBoost</td>
<td align="left" rowspan="1" colspan="1">2</td>
<td align="left" rowspan="1" colspan="1">19116</td>
<td align="left" rowspan="1" colspan="1">83.25%</td>
<td align="left" rowspan="1" colspan="1">Identifying poverty</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Rathnayake <em>et al</em>., 2023 [<a href="#pone.0330186.ref043" class="usa-link" aria-describedby="pone.0330186.ref043">43</a>]</td>
<td align="left" rowspan="1" colspan="1">Adaptive Neuro-Fuzzy Inference System (ANFIS), Multilayer Perceptron (MLP), Genetic Algorithm (GA) for optimization, Support Vector Regression (SVR), Random Forest (RF)</td>
<td align="left" rowspan="1" colspan="1">N/A</td>
<td align="left" rowspan="1" colspan="1">7632</td>
<td align="left" rowspan="1" colspan="1">96.3%</td>
<td align="left" rowspan="1" colspan="1">Forecast air quality</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0330186.t001/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="sec003"><h2 class="pmc_sec_title">Methodology</h2>
<section id="sec004"><h3 class="pmc_sec_title">Dataset collection and properties</h3>
<p>The dataset named “BengaliTenseCorpus: A comprehensive corpus in Bengali texts categorized in Present , Past, and Future” has been sourced from various publicly accessible Bangla blogs, Facebook pages, magazines, books, and news articles, and some of the data are self-made, which ensures a diverse representation of contemporary language use. A critical aspect of the dataset’s curation was maintaining an equal distribution of sentences across three tense categories: past, present, and future. The dataset comprises 13,500 Bangla sentences that are categorized into three classes: present tense with 4,550 sentences, past tense with 4,460, and future tense collection with 4,490 sentences (<a href="#pone.0330186.g001" class="usa-link">Fig 1</a>). For labeling purposes, 3 numerical values are used as - 0, 1, and 2, respectively, for present tense, past tense, and future tense.</p>
<figure class="fig xbox font-sm" id="pone.0330186.g001"><h4 class="obj_head">Fig 1. Statistical analysis of data.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c921/12370126/8ee959749ad2/pone.0330186.g001.jpg" loading="lazy" height="591" width="628" alt="Fig 1"></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330186.g001/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p><a href="#pone.0330186.t002" class="usa-link">Table 2</a> represents the statistical summary of the dataset, which is broken down into three different levels: ‘Present’, ‘Past’, and ‘Future’. Each level summarizes specific statistical measures related to the data distribution. Total number of data points are 4550, 4460, 4490 respectively in ‘Present’, ‘Past’ and ‘Future’ levels. Mean represents the average value of the dataset for each level, 37.75 for Present, 35.03 for Past and 38.63 for Future. The mean and median values indicate that the ‘Future data has a slightly higher average compared to the ‘Present’ and ‘Past’ datasets. Similarly, Std shows how much the data varies from the mean (spread or dispersion of the data), Min shows the minimum value in the dataset and we can also find the 25% (1st Quartile), 50% (Median), 75% (3rd Quartile). The standard deviation is highest for the “Future” data (29.45), suggesting greater variability in future data values. Max represents the maximum value present in the dataset for each level. The maximum value in the “Past” category is significantly higher than in the other two categories, which could indicate outliers or larger events in the past.</p>
<section class="tw xbox font-sm" id="pone.0330186.t002"><h4 class="obj_head">Table 2. Detailed statistical summary of dataset.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">Features</th>
<th align="left" rowspan="1" colspan="1">Present</th>
<th align="left" rowspan="1" colspan="1">Past</th>
<th align="left" rowspan="1" colspan="1">Future</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Count</td>
<td align="left" rowspan="1" colspan="1">4,550</td>
<td align="left" rowspan="1" colspan="1">4,460</td>
<td align="left" rowspan="1" colspan="1">4,490</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Mean</td>
<td align="left" rowspan="1" colspan="1">37.75</td>
<td align="left" rowspan="1" colspan="1">35.03</td>
<td align="left" rowspan="1" colspan="1">38.63</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Std</td>
<td align="left" rowspan="1" colspan="1">25.55</td>
<td align="left" rowspan="1" colspan="1">26.00</td>
<td align="left" rowspan="1" colspan="1">29.45</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Min</td>
<td align="left" rowspan="1" colspan="1">9.00</td>
<td align="left" rowspan="1" colspan="1">9.00</td>
<td align="left" rowspan="1" colspan="1">10.00</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">25%</td>
<td align="left" rowspan="1" colspan="1">21.00</td>
<td align="left" rowspan="1" colspan="1">22.00</td>
<td align="left" rowspan="1" colspan="1">19.00</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">50%</td>
<td align="left" rowspan="1" colspan="1">27.00</td>
<td align="left" rowspan="1" colspan="1">27.00</td>
<td align="left" rowspan="1" colspan="1">25.00</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">75%</td>
<td align="left" rowspan="1" colspan="1">50.00</td>
<td align="left" rowspan="1" colspan="1">35.00</td>
<td align="left" rowspan="1" colspan="1">52.00</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">MAX</td>
<td align="left" rowspan="1" colspan="1">202.00</td>
<td align="left" rowspan="1" colspan="1">262.00</td>
<td align="left" rowspan="1" colspan="1">216.00</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0330186.t002/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p><a href="#pone.0330186.g002" class="usa-link">Fig 2</a> shows the distribution of text lengths for three classes of data: Present, Past, and Future. The x-axis represents the text length, and the y-axis represents the count (frequency) of texts with that length. For Present Tense, the distribution is heavily skewed to the left, with most text lengths concentrated between 0 and 50 characters. The highest frequency occurs at very short lengths (around 10-25 characters), and the number of texts drastically decreases as the text length increases. The distribution has a long tail, showing that very few texts have lengths above 100 characters. Similar to the present tense, the past tense distribution is also skewed left, but the concentration of text length is even shorter than in the present tense. The highest count is at shorter text lengths, around 10-25 characters, and there are far fewer texts with longer lengths (above 50 characters). The distribution falls off steeply after around 30 characters, suggesting a large number of very short texts. Like the other classes, the future tense distribution is left-skewed, but the data shows a broader spread than the past tense. The concentration is still around shorter text lengths, but more texts appear to have medium lengths (50-75 characters). The highest count is around 20-30 characters, but it gradually decreases compared to the sharp fall in the past tense. The tail is slightly longer than the present and past tense distributions, indicating that the future tense texts tend to have more variability in length. All three classes of tenses show left-skewed distributions, meaning most texts are short in length, though there is some variation, particularly in the future tense category.</p>
<figure class="fig xbox font-sm" id="pone.0330186.g002"><h4 class="obj_head">Fig 2. Distribution of text length of each class of the dataset.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370126_pone.0330186.g002.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c921/12370126/14d960465e79/pone.0330186.g002.jpg" loading="lazy" height="228" width="746" alt="Fig 2"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330186.g002/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p><a href="#pone.0330186.g003" class="usa-link">Fig 3</a> represents the Word Cloud for each class of Dataset which visually shows the most frequent words in each dataset, where the size of a word corresponds to its frequency in the dataset. Larger words in the cloud represent higher frequency words for each class.</p>
<figure class="fig xbox font-sm" id="pone.0330186.g003"><h4 class="obj_head">Fig 3. Word cloud for each class of dataset.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370126_pone.0330186.g003.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c921/12370126/c85f498bf417/pone.0330186.g003.jpg" loading="lazy" height="134" width="746" alt="Fig 3"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330186.g003/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p>All relevant data are available from the Mendeley repository at: <a href="https://data.mendeley.com/datasets/w9mdy6tw84/1" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://data.mendeley.com/datasets/w9mdy6tw84/1</a>. The data used in this study were collected from publicly available sources in compliance with the terms and conditions of the original providers. All data were anonymized and aggregated where necessary to ensure no violation of privacy or usage restrictions.</p></section><section id="sec005"><h3 class="pmc_sec_title">Data pre-processing</h3>
<p>Data preprocessing is a very vital fact before starting the classification process. Preprocessing steps are crucial for having an optimal outcome in terms of classification, and outcomes heavily rely on preprocessing. The collected Bengali sentences from diverse sources are not ready to apply machine learning and deep learning approaches without preprocessing, as these are full of noise, lack of coherence, overused punctuation, misspelling, non-standard abbreviations, mixed characters and digits, stop-words, and random use of emojis. Ultimately, classification approaches cannot be applied to these raw data. Thus, it is needed to preprocess the sentences before applying several classification techniques to enhance the overall performances. Several pre-processing steps are applied to our collected data, and these are discussed below as follows:</p>
<ul class="list" style="list-style-type:disc">
<li><p><strong>Primary cleaning:</strong> In the primary cleaning step, coherence checking, misspelling checking approaches are applied to initiate the further pre-processing techniques. Coherence ensures the proper structure of a sentence, misspelling checking ensures the correct form of words in the sentences, and null value handling ensures the presentation of all required sentences as well as entails a balanced dataset.</p></li>
<li><p><strong>Null values Handling:</strong> A small fraction of the rows with null values are identified; remove them from the dataset to ensure quality and integrity of the dataset, reliability and accuracy of the applied classifiers, and computational efficiency.</p></li>
<li><p><strong>Regular expression removals:</strong> This pre-processing technique is applied to identify and eliminate unexpected patterns or characters, removing punctuation, removing HTML tags and tags, eliminating special characters, discarding unnecessary whitespaces, and eliminating numbers. Eventually, this technique ensures a clean and structured dataset, consistent tokenization, and reduces complexity.</p></li>
<li><p><strong>Emoji removals:</strong> Emojis are useless according to context; thus, emojis are removed by using replacement methods of Python’s emoji package to ensure data consistency and relevant textual content management.</p></li>
<li><p><strong>Duplicate value removal:</strong> By applying Python’s duplicate value handling methods, duplicate values are deleted from the dataset to ensure the uniqueness of the data.</p></li>
<li><p><strong>Stop word removal:</strong> Stop words are a collection of some unnecessary words that do not carry any meaning in our context. Thus, a list of stop words has been prepared that contains the useless words for this study, and removing this list ensures the minimal training time of models, and improves the performance of the classifiers.</p></li>
<li><p><strong>Tokenization:</strong> Tokenization, which converts unprocessed text into manageable units (tokens) that machine learning models can analyze, is an essential step in Natural Language Processing (NLP) . It is the basic steps of NLP to simplify the process of models and learn from data, to improve the performance of the classifiers.</p></li>
</ul>
<p><a href="#pone.0330186.g004" class="usa-link">Figs 4</a> and <a href="#pone.0330186.g005" class="usa-link">5</a> shows the preprocessing steps with examples.</p>
<figure class="fig xbox font-sm" id="pone.0330186.g004"><h4 class="obj_head">Fig 4. Data sample.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370126_pone.0330186.g004.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c921/12370126/c134a58f5bef/pone.0330186.g004.jpg" loading="lazy" height="309" width="704" alt="Fig 4"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330186.g004/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><figure class="fig xbox font-sm" id="pone.0330186.g005"><h4 class="obj_head">Fig 5. Data pre-processing techniques.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370126_pone.0330186.g005.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c921/12370126/4c4a0221eb9e/pone.0330186.g005.jpg" loading="lazy" height="740" width="657" alt="Fig 5"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330186.g005/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure></section><section id="sec006"><h3 class="pmc_sec_title">Data annotation</h3>
<p>This study employs manual annotation where human annotators are involved to provide the accurate, relevant, and comprehensive annotations or labels for each entry of the dataset by following guidelines. Three annotators were selected for the accomplishment of the annotation process. The criteria for the annotator selections are that the annotators should be Bengali native speakers as well as have language expertise and linguistic nuances. Actually, the selection criteria included native speakers of Bangla, academic qualifications in Bangla language and linguistics, familiarity with educational content, and ability to discern contexts within this domain. This approach enhances the reliability, validity, and comprehensiveness of tense classification in the Bengali natural language processing domain. Annotators worked individually and independently to avoid bias in labeling or annotating the sentences of the Bengali tense dataset in three forms of tenses: present tense (0), past tense (1), and future (2) by following the Bengali grammatical syntax in terms of tense identification accurately. <a href="#pone.0330186.t003" class="usa-link">Table 3</a> shows the results of annotations as follows: 4550 Bengali sentences are annotated as present (0) tense, 4460 sentences are annotated as past (1) tense, and 4490 Bengali sentences are annotated as future (2) tense.</p>
<section class="tw xbox font-sm" id="pone.0330186.t003"><h4 class="obj_head">Table 3. Annotation Results.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">Annotations/Labels</th>
<th align="left" rowspan="1" colspan="1">Quantity</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">Present (0)</td>
<td align="left" rowspan="1" colspan="1">4550</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Past (1)</td>
<td align="left" rowspan="1" colspan="1">4460</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Future (2)</td>
<td align="left" rowspan="1" colspan="1">4490</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0330186.t003/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="sec007"><h3 class="pmc_sec_title">Model description</h3>
<section id="sec008"><h4 class="pmc_sec_title">Decision tree.</h4>
<p>Decision tree is a commonly used supervised learning method which does not require parameters to do classification tasks. It operates by partitioning the dataset into subsets based on which feature is most informative at each node, creating a tree-like structure of decision rules. The root node represents the entire dataset that is supposed to be splitted into subsets, a decision node or internal node represents a feature, and a leaf node represents an outcome or label. As the splitting criterion, Entropy(Information Gain) is employed to measure the homogeneity of the nodes and decide the best split at each step of the tree construction. Entropy quantifies uncertainty or impurity in a dataset. In <a href="#pone.0330186.e001" class="usa-link">Eq 1</a>, entropy H for a specific dataset T is calculated as:</p>
<table class="disp-formula p" id="pone.0330186.e001"><tr>
<td class="formula"><math id="M1" display="block" overflow="linebreak"><mrow><mrow><mi>H</mi><mo stretchy="false">(</mo><mi>T</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mi>p</mi><mi>l</mi><mi>o</mi><msub><mi>g</mi><mrow><mn>2</mn></mrow></msub><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo><mo>−</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="false">)</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mrow><mn>2</mn></mrow></msub><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>p</mi><mo stretchy="false">)</mo></mrow></mrow></math></td>
<td class="label">(1)</td>
</tr></table>
<p>where p is the probability of a sample belonging to the positive class [<a href="#pone.0330186.ref028" class="usa-link" aria-describedby="pone.0330186.ref028">28</a>].</p></section><section id="sec009"><h4 class="pmc_sec_title">Random forest.</h4>
<p>Random Forest is an ensemble learning method that builds multiple decision trees in the training period and afterward combines their output to get a more accurate and stable prediction. Its bootstrapped sampling and random feature selection provide much more diversity among the base estimators, which enhances the robustness of the final model [<a href="#pone.0330186.ref029" class="usa-link" aria-describedby="pone.0330186.ref029">29</a>]. For classification tasks, the majority vote mechanism is employed by mode which represents the most frequently occurring class among the predictions showing in <a href="#pone.0330186.e005" class="usa-link">Eq 2</a>, where if <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330186.e002"><math id="M2" display="inline" overflow="linebreak"><mrow><msub><mi>T</mi><mrow><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>T</mi><mrow><mn>2</mn></mrow></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>T</mi><mrow><mi>M</mi></mrow></msub></mrow></math></span> are the M trees in Random Forest and <em>C</em><sub><em>i</em></sub>(<em>x</em>)is the class predicted by the <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330186.e003"><math id="M3" display="inline" overflow="linebreak"><mrow><msup><mtext mathvariant="italic">i</mtext><mrow><mtext mathvariant="italic">th</mtext></mrow></msup></mrow></math></span> tree for input <em>x</em>, then the final prediction <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330186.e004"><math id="M4" display="inline" overflow="linebreak"><mrow><mover><mrow><mi>C</mi></mrow><mo stretchy="false">^</mo></mover><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></math></span> is determined by:</p>
<table class="disp-formula p" id="pone.0330186.e005"><tr>
<td class="formula"><math id="M5" display="block" overflow="linebreak"><mrow><mrow><mover><mrow><mi>C</mi></mrow><mo stretchy="false">^</mo></mover><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mo stretchy="false">(</mo><msub><mi>C</mi><mrow><mn>1</mn></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>,</mo><msub><mi>C</mi><mrow><mn>2</mn></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>,</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>.</mo><msub><mi>C</mi><mrow><mi>M</mi></mrow></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mrow></math></td>
<td class="label">(2)</td>
</tr></table></section><section id="sec010"><h4 class="pmc_sec_title">Multinomial Naive Baye.</h4>
<p>Multinomial Naive Bayes is a probabilistic learning technique that uses Bayes’ theorem, assuming independence of features. Despite the simplicity of MNB, it can do surprisingly well even on text datasets with thousands of dimensions. Given the input features, the model determines the posterior probability of each class <em>P</em>(<em>C</em><sub><em>k</em></sub>|<em>x</em>) and assigns the class with the highest probability [<a href="#pone.0330186.ref030" class="usa-link" aria-describedby="pone.0330186.ref030">30</a>].</p>
<table class="disp-formula p" id="pone.0330186.e006"><tr>
<td class="formula"><math id="M6" display="block" overflow="linebreak"><mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>C</mi><mi>k</mi></msub><mo stretchy="false">|</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><msub><mi>C</mi><mi>k</mi></msub><mo stretchy="false">)</mo><msubsup><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></msubsup><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">|</mo><msub><mi>C</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow></mrow></math></td>
<td class="label">(3)</td>
</tr></table>
<p>In <a href="#pone.0330186.e006" class="usa-link">Eq 3</a>, <em>P</em>(<em>C</em><sub><em>k</em></sub>) is the prior probability of class <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330186.e007"><math id="M7" display="inline" overflow="linebreak"><mrow><msub><mi>C</mi><mi>k</mi></msub><mo>,</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">|</mo><msub><mi>C</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow></math></span> is the likelihood of feature <em>x</em><sub><em>i</em></sub> for class <em>C</em><sub><em>k</em></sub> and <em>P</em>(<em>x</em>) is the evidence.</p></section><section id="sec011"><h4 class="pmc_sec_title">Support vector machine.</h4>
<p>While being a powerful supervised learning algorithm, SVM tends to find the optimal hyperplane that best separates the data points into different classes. This hyperplane maximizes the margin between the two classes; this margin is also referred to as the distance between the closest points of the classes to the hyperplane. Basically, SVM operates nonlinear classification by implicitly mapping the input space to higher dimensions using kernel functions. For a given input vector x, the classification decision is based on the sign of the decision function <em>f</em>(<em>x</em>) given is <a href="#pone.0330186.e008" class="usa-link">Eq 4</a>:</p>
<table class="disp-formula p" id="pone.0330186.e008"><tr>
<td class="formula"><math id="M8" display="block" overflow="linebreak"><mrow><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>w</mi><mo>.</mo><mi>x</mi><mo>+</mo><mi>b</mi></mrow></mrow></math></td>
<td class="label">(4)</td>
</tr></table>
<p>Here, w is the weight vector perpendicular to the hyperplane, x is the input feature vector and b is the bias term [<a href="#pone.0330186.ref031" class="usa-link" aria-describedby="pone.0330186.ref031">31</a>].</p></section><section id="sec012"><h4 class="pmc_sec_title">K Nearest neighbor.</h4>
<p>KNN is an instance-based learning algorithm that classifies a data point by the majority class or most common class of its k nearest neighbors in the feature space. These nearest neighbors are determined based on different distance metrics, among which Euclidean distance is the commonly used one, measured as:</p>
<table class="disp-formula p" id="pone.0330186.e009"><tr>
<td class="formula"><math id="M9" display="block" overflow="linebreak"><mrow><mrow><mi>d</mi><mo stretchy="false">(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><msqrt><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mi>y</mi><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></msqrt></mrow></mrow></math></td>
<td class="label">(5)</td>
</tr></table>
<p>In <a href="#pone.0330186.e009" class="usa-link">Eq 5</a>, x and y are two points in the n-dimensional feature space [<a href="#pone.0330186.ref032" class="usa-link" aria-describedby="pone.0330186.ref032">32</a>].</p></section><section id="sec013"><h4 class="pmc_sec_title">XGBoost.</h4>
<p>XGBoost, or Extreme Gradient Boosting, is an efficient and scalable implementation of gradient boosting for decision trees. It creates a group of weak learners as trees in a sequential manner, each correcting the errors of its predecessor. It also includes a regularization function to prevent overfitting besides other advanced features like tree pruning and parallel processing [<a href="#pone.0330186.ref033" class="usa-link" aria-describedby="pone.0330186.ref033">33</a>].</p>
<table class="disp-formula p" id="pone.0330186.e010"><tr>
<td class="formula"><math id="M10" display="block" overflow="linebreak"><mrow><mrow><mi>L</mi><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mi>l</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>,</mo><mover><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><mo stretchy="false">^</mo></mover><mo stretchy="false">)</mo><mo>+</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>K</mi></mrow></munderover><mi>Ω</mi><mo stretchy="false">(</mo><msub><mi>f</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow></mrow></math></td>
<td class="label">(6)</td>
</tr></table>
<p><span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330186.e011"><math id="M11" display="inline" overflow="linebreak"><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></munderover><mi>l</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>,</mo><mover><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><mo stretchy="false">^</mo></mover><mo stretchy="false">)</mo></mrow></math></span> is the loss function that measures the difference between the predicted value <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330186.e012"><math id="M12" display="inline" overflow="linebreak"><mrow><msub><mover><mrow><mi>y</mi></mrow><mo stretchy="false">^</mo></mover><mi>i</mi></msub></mrow></math></span> and the actual value <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330186.e013"><math id="M13" display="inline" overflow="linebreak"><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>,</mo><mi>ω</mi></mrow></math></span> is the regularization term that penalizes the complexity of the model as shown in <a href="#pone.0330186.g006" class="usa-link">Fig 6</a> and <em>f</em><sub><em>k</em></sub> are the individual trees in the <a href="#pone.0330186.e010" class="usa-link">Eq 6</a>.</p>
<figure class="fig xbox font-sm" id="pone.0330186.g006"><h5 class="obj_head">Fig 6. Work flow of XGBoost.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370126_pone.0330186.g006.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c921/12370126/d5a920882578/pone.0330186.g006.jpg" loading="lazy" height="379" width="674" alt="Fig 6"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330186.g006/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure></section><section id="sec014"><h4 class="pmc_sec_title">Recurrent neural networks.</h4>
<p>Recurrent neural networks are a class of artificial neural networks meant to recognize patterns in sequences of text. Unlike the traditional feedforward neural networks, in RNNs, connections form directed cycles. An RNN processes data in a sequential manner by keeping some sort of “memory” or hidden state updated at each time step. This hidden state captures information from the past elements of the sequence. It thus allows the network to know the context, and therefore understand how words in a sentence relate to each other. A common architecture of RNN is characterized by the following component shown in <a href="#pone.0330186.g007" class="usa-link">Fig 7</a>.</p>
<figure class="fig xbox font-sm" id="pone.0330186.g007"><h5 class="obj_head">Fig 7. Simple RNN architecture.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370126_pone.0330186.g007.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c921/12370126/3cca2a70a039/pone.0330186.g007.jpg" loading="lazy" height="422" width="673" alt="Fig 7"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330186.g007/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><ol class="list" style="list-style-type:decimal">
<li><p><strong>Input Layer (<em>x</em></strong><sub><strong><em>t</em></strong></sub><strong>):</strong> At each time step <em>t</em><sub>1</sub>, the input <em>x</em><sub><em>t</em></sub> represents the current word or feature vector in the sequence that is fed into the RNN cell.</p></li>
<li>
<div class="p">
<strong>Hidden Layer (<em>h</em></strong><sub><strong><em>t</em></strong></sub><strong>):</strong> The value of the hidden layer is determined based on the present input <em>x</em><sub><em>t</em></sub> and the previous hidden state value <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330186.e014"><math id="M14" display="inline" overflow="linebreak"><mrow><mi>h</mi><mrow><mo stretchy="false">(</mo><mi>t</mi><mspace width="0.167em"></mspace><mrow><mo>−</mo></mrow><mspace width="0.167em"></mspace><mn>1</mn><mo stretchy="false">)</mo></mrow></mrow></math></span>. Mathematically, this may be represented as:<table class="disp-formula p" id="pone.0330186.e015"><tr>
<td class="formula"><math id="M15" display="block" overflow="linebreak"><mrow><mrow><msub><mi>h</mi><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>h</mi></msub><msub><mi>x</mi><mi>t</mi></msub><mo>+</mo><msub><mi>U</mi><mi>h</mi></msub><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>b</mi><mi>h</mi></msub><mo stretchy="false">)</mo></mrow></mrow></math></td>
<td class="label">(7)</td>
</tr></table>
</div>
<p>In <a href="#pone.0330186.e015" class="usa-link">Eq 7</a>, <em>W</em><sub><em>h</em></sub> and <em>U</em><sub><em>h</em></sub> are weight metrics, <em>b</em><sub><em>h</em></sub> is the bias vector and <em>σ</em> is an activation function (generally used tanh or ReLU).</p>
</li>
<li>
<div class="p">
<strong>Output Layer (<em>y</em></strong><sub><strong><em>t</em></strong></sub><strong>):</strong> This layer gives the output <em>y</em><sub><em>t</em></sub> using the current hidden state <em>h</em><sub><em>t</em></sub>. Since it’s binary classification, mostly it follows through with a sigmoid activation function that gives the probability score.<table class="disp-formula p" id="pone.0330186.e016"><tr>
<td class="formula"><math id="M16" display="block" overflow="linebreak"><mrow><mrow><msub><mi>y</mi><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>y</mi></msub><msub><mi>h</mi><mi>t</mi></msub><mo>+</mo><msub><mi>b</mi><mi>y</mi></msub><mo stretchy="false">)</mo></mrow></mrow></math></td>
<td class="label">(8)</td>
</tr></table>
</div>
<p>In <a href="#pone.0330186.e016" class="usa-link">Eq 8</a>, <em>W</em><sub><em>y</em></sub> is the output layer weight matrix and usually sigmoid is used as activation function <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330186.e017"><math id="M17" display="inline" overflow="linebreak"><mrow><mo stretchy="false">(</mo><mi>σ</mi><mo stretchy="false">)</mo></mrow></math></span> to produce a probability between 0 and 1 for binary class [<a href="#pone.0330186.ref034" class="usa-link" aria-describedby="pone.0330186.ref034">34</a>].</p>
</li>
</ol></section><section id="sec015"><h4 class="pmc_sec_title">Long short-term memory.</h4>
<p>Long Short-Term Memory networks are a special kind of RNN that is designed to overcome some limitations inherent in traditional RNNs in matters related to handling long-term dependence and how to avoid the problem of vanishing gradients. In LSTMs, this is accomplished by embedding an elaborate architecture composed of memory cells and gates, hence allowing them to keep information for longer sequences. The LSTM networks consist of a series of cells; each cell has three kinds of gates-input gate, forget gate, and output gate. Three kinds of gates are controlling the flow of information inside the cell so that the network should know exactly where to retain or drop off certain information [<a href="#pone.0330186.ref035" class="usa-link" aria-describedby="pone.0330186.ref035">35</a>]. The architecture of an LSTM cell is illustrated by the following key components portrayed in <a href="#pone.0330186.g008" class="usa-link">Fig 8</a>.</p>
<figure class="fig xbox font-sm" id="pone.0330186.g008"><h5 class="obj_head">Fig 8. Internal structure of LSTM.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370126_pone.0330186.g008.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c921/12370126/6b06f896a1a3/pone.0330186.g008.jpg" loading="lazy" height="353" width="674" alt="Fig 8"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330186.g008/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><ol class="list" style="list-style-type:decimal">
<li><div class="p">
<strong>Forget Gate (<em>f</em></strong><sub><strong><em>t</em></strong></sub><strong>):</strong> It selects which previous cell state information <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330186.e018"><math id="M18" display="inline" overflow="linebreak"><mrow><mi>C</mi><mo stretchy="false">(</mo><mi>t</mi><mspace width="0.167em"></mspace><mrow><mo>−</mo></mrow><mspace width="0.167em"></mspace><mn>1</mn><mo stretchy="false">)</mo></mrow></math></span> to discard or forget by <a href="#pone.0330186.e019" class="usa-link">Eq 9</a>.<table class="disp-formula p" id="pone.0330186.e019"><tr>
<td class="formula"><math id="M19" display="block" overflow="linebreak"><mrow><mrow><msub><mi>f</mi><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>f</mi></msub><mo>.</mo><mo stretchy="false">[</mo><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>f</mi></msub><mo stretchy="false">)</mo></mrow></mrow></math></td>
<td class="label">(9)</td>
</tr></table>
</div></li>
<li><div class="p">
<strong>Input Gate (<em>i</em></strong><sub><strong><em>t</em></strong></sub><strong>):</strong> It calculates what new information coming from the current input <em>x</em><sub><em>t</em></sub> needs to be stored in the cell state, combining it with the candidate values <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330186.e020"><math id="M20" display="inline" overflow="linebreak"><mrow><mo stretchy="false">(</mo><msub><mover><mrow><mi>C</mi></mrow><mo stretchy="false">^</mo></mover><mi>t</mi></msub><mo stretchy="false">)</mo></mrow></math></span> using <a href="#pone.0330186.e021" class="usa-link">Eq 10a</a> and <a href="#pone.0330186.e022" class="usa-link">10<em>b</em></a><table class="disp-formula p" id="pone.0330186.e021"><tr>
<td class="formula"><math id="M21" display="block" overflow="linebreak"><mrow><mrow><msub><mi>i</mi><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>i</mi></msub><mo>.</mo><mo stretchy="false">[</mo><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></mrow></math></td>
<td class="label">(10a)</td>
</tr></table>
<table class="disp-formula p" id="pone.0330186.e022"><tr>
<td class="formula"><math id="M22" display="block" overflow="linebreak"><mrow><mrow><msub><mover><mrow><mi>C</mi></mrow><mo stretchy="false">^</mo></mover><mi>t</mi></msub><mo>=</mo><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>c</mi></msub><mo>.</mo><mo stretchy="false">[</mo><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>c</mi></msub><mo stretchy="false">)</mo></mrow></mrow></math></td>
<td class="label">(10b)</td>
</tr></table>
</div></li>
<li><div class="p">
<strong>Cell State (<em>C</em></strong><sub><strong><em>t</em></strong></sub><strong>):</strong> This is the memory of the network that gets updated at every time step through the combination of the old cell state and the new candidate values, modulated by the forget and input gates, shown in the <a href="#pone.0330186.e022" class="usa-link">Eq 11</a><table class="disp-formula p" id="pone.0330186.e023"><tr>
<td class="formula"><math id="M23" display="block" overflow="linebreak"><mrow><mrow><msub><mi>C</mi><mi>t</mi></msub><mo>=</mo><msub><mi>f</mi><mi>t</mi></msub><mi>*</mi><msub><mi>C</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>i</mi><mi>t</mi></msub><mo>.</mo><msub><mover><mrow><mi>C</mi></mrow><mo stretchy="false">^</mo></mover><mi>t</mi></msub></mrow></mrow></math></td>
<td class="label">(11)</td>
</tr></table>
</div></li>
<li><div class="p">
<strong>Output Gate (<em>o</em></strong><sub><strong><em>t</em></strong></sub><strong>):</strong> This is the gate controlling the cell state output <em>h</em><sub><em>t</em></sub> based on the updated cell state <em>C</em><sub><em>t</em></sub> and the output gate <em>o</em><sub><em>t</em></sub>.<table class="disp-formula p" id="pone.0330186.e024"><tr>
<td class="formula"><math id="M24" display="block" overflow="linebreak"><mrow><mrow><msub><mi>o</mi><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>o</mi></msub><mo>.</mo><mo stretchy="false">[</mo><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>o</mi></msub><mo stretchy="false">)</mo></mrow></mrow></math></td>
<td class="label">(12a)</td>
</tr></table>
<table class="disp-formula p" id="pone.0330186.e025"><tr>
<td class="formula"><math id="M25" display="block" overflow="linebreak"><mrow><mrow><msub><mi>h</mi><mi>t</mi></msub><mo>=</mo><msub><mi>o</mi><mi>t</mi></msub><mo>.</mo><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo stretchy="false">(</mo><msub><mi>C</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow></mrow></math></td>
<td class="label">(12b)</td>
</tr></table>
</div></li>
</ol></section><section id="sec016"><h4 class="pmc_sec_title">Gated recurrent unit.</h4>
<p>Gated Recurrent Unit is a form of RNN, alleviating some issues that used to exist in traditional RNNs; so does the network architecture for LSTMs. They reduce the complexity by fusing the forget and input gates into an update gate, which simplifies the design, decreases computation, and training time, yet yields quality results over sequence data [<a href="#pone.0330186.ref036" class="usa-link" aria-describedby="pone.0330186.ref036">36</a>]. The major gates in GRUs are the reset gate and the update gate. These two gates help to control the flow of information, which allows the network to capture dependencies in the input sequence. The key components of the GRU cell are visualized in <a href="#pone.0330186.g009" class="usa-link">Fig 9</a>,</p>
<figure class="fig xbox font-sm" id="pone.0330186.g009"><h5 class="obj_head">Fig 9. The architecture of GRU.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c921/12370126/08f102d945f6/pone.0330186.g009.jpg" loading="lazy" height="548" width="798" alt="Fig 9"></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330186.g009/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><ol class="list" style="list-style-type:decimal">
<li><div class="p">
<strong>Reset Gate (<em>r</em></strong><sub><strong><em>t</em></strong></sub><strong>):</strong> Decides how much of the past state to forget by <a href="#pone.0330186.e024" class="usa-link">Eq 13</a>:<table class="disp-formula p" id="pone.0330186.e026"><tr>
<td class="formula"><math id="M26" display="block" overflow="linebreak"><mrow><mrow><msub><mi>r</mi><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>r</mi></msub><mo>.</mo><mo stretchy="false">[</mo><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>r</mi></msub><mo stretchy="false">)</mo></mrow></mrow></math></td>
<td class="label">(13)</td>
</tr></table>
</div></li>
<li>
<div class="p">
<strong>Update Gate (<em>z</em></strong><sub><strong><em>t</em></strong></sub><strong>):</strong> Updates the balance between the previous state <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0330186.e027"><math id="M27" display="inline" overflow="linebreak"><mrow><mi>h</mi><mo stretchy="false">(</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></math></span> and the current state <em>x</em><sub><em>t</em></sub> by using <a href="#pone.0330186.e028" class="usa-link">Eq 14a</a>.<table class="disp-formula p" id="pone.0330186.e028"><tr>
<td class="formula"><math id="M28" display="block" overflow="linebreak"><mrow><mrow><msub><mi>z</mi><mi>t</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>z</mi></msub><mo>.</mo><mo stretchy="false">[</mo><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>z</mi></msub><mo stretchy="false">)</mo></mrow></mrow></math></td>
<td class="label">(14a)</td>
</tr></table>
<table class="disp-formula p" id="pone.0330186.e029"><tr>
<td class="formula"><math id="M29" display="block" overflow="linebreak"><mrow><mrow><msub><mover><mrow><mi>h</mi></mrow><mo stretchy="false">^</mo></mover><mi>t</mi></msub><mo>=</mo><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo stretchy="false">(</mo><mi>W</mi><mo>.</mo><mo stretchy="false">[</mo><msub><mi>r</mi><mi>t</mi></msub><mi>*</mi><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">]</mo><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo></mrow></mrow></math></td>
<td class="label">(14b)</td>
</tr></table>
<table class="disp-formula p" id="pone.0330186.e030"><tr>
<td class="formula"><math id="M30" display="block" overflow="linebreak"><mrow><mrow><msub><mi>h</mi><mi>t</mi></msub><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>z</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mi>*</mi><msub><mi>h</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>z</mi><mi>t</mi></msub><mi>*</mi><msub><mover><mrow><mi>h</mi></mrow><mo stretchy="false">^</mo></mover><mi>t</mi></msub></mrow></mrow></math></td>
<td class="label">(14c)</td>
</tr></table>
</div>
<p>Here, <a href="#pone.0330186.e029" class="usa-link">Eq 14b</a> calculates the candidate for the new hidden state and the new hidden state <em>h</em><sub><em>t</em></sub> is a combination of the old hidden state and the candidate activation, modulated by the update gate represented in <a href="#pone.0330186.e030" class="usa-link">Eq 14c</a> [<a href="#pone.0330186.ref037" class="usa-link" aria-describedby="pone.0330186.ref037">37</a>].</p>
</li>
</ol></section><section id="sec017"><h4 class="pmc_sec_title">Stack ensemble model.</h4>
<p>Transfer-based models always require a huge dataset to produce acceptable accuracy. Even recurrent neural networks require large datasets to perform fairly. Sometimes, smaller machine learning models can perform as well as sophisticated models. In order to facilitate this quality and boost the performance even more, many tiny models are merged. This type of model is called an ensemble model. Generally, ensemble models are classified into three categories bagging, boosting, and stacking. Because of its durability and ability to learn the final result from the output of previous layers, the stacking ensemble model is frequently chosen over the simple majority voting method. The Stack ensemble model consists of two parts. The first one is generally called the base model, and the second one is called the meta-model. The base model can have several machine learning or deep learning models. The job of the meta-model is to combine the answers of the base model to give the final result. Another key part is to choose which models will be used as base models. This task is often referred to as the model selection part. There is no universal law for choosing models for base models but generally, those models are chosen that are diverse in nature. Often models with greater accuracy can help in overall accuracy. The same analogy goes for the meta-model also. Any machine learning or deep neural network base model can be used as a meta-model.</p></section><section id="sec018"><h4 class="pmc_sec_title">Model selection and hyper parameters.</h4>
<p>Both machine learning and deep learning models have been used to measure their performance. A total of 9 models have been used for the model selection part. These models are Naïve Bias, Random Forest, Decision Tree, Support Vector Machine, K-Nearest Neighbor, XGBoost, GRU, and LSTM, and RNN. Multinomial naïve bias is used as it is more suitable for text classification where the parameter alpha is kept at 1.0 and force alpha is True. The following parameters were used to generate the random forest model. The maximum number of trees is 100, and the split criterion is gini. In addition to using the splitter approach ‘best’, the decision tree classifier’s split criterion is also gini. The kernel that is used in the support vector machine is a radial basis function with a degree for the polynomial function is 3. Five neighbors were utilized in the K nearest neighbor model with uniform weights. XGBoost model is generated using all default parameters. One neural network model uses 2 long short-term memory layers one after another. The hidden size of the LSTM was 256, while its input size was 100. After that, it moves through the output layer and three further linear levels. The linear layers have the following architecture (128, 64, 3). With the exception of the output layer, dropout is applied after each linear layer. The dropout value was 0.4, and the in-place option was set to false. The learning rate was 0.001, the batch size was equal to 10, and there were 100 epochs in total. The best weights were recorded while training. The gated recurrent unit was employed by another neural network. Five linear layers were traversed after using two gated recurrent units consecutively. GRU had a hidden size of 256 and an input size of 100. The output layer is the final of the five linear layers. The linear layers’ architecture, which matches the lstm’s layers, was (128, 64, 32, 16, 3). There are 100 epochs, a batch size of 10, and a learning rate of 0.001. With the exception of the output layer, dropout is applied after each linear layer. The dropout value was 0.4, and the in-place option was set to false. The models’ optimal weights were also recorded. The last neural network model was RNN. The model architecture of the RNN model was as follows. Two RNN layers were stacked one after another. The input size for the RNN was 100 and the hidden size was 256. Then a flatten layer is used before passing them to linear layers. 3 linear layers (128, 64, 3) were used with dropout layers in between them except for the final output layer. The dropout rate was 40% with the inplace option being false. The number of epochs was 100 with a learning rate of 0.001 and batch size being 100.</p></section><section id="sec019"><h4 class="pmc_sec_title">Our model.</h4>
<p>A total of 5 models were selected based on their performance to use in our ensemble model. These models were the Random Forest Model, Support Vector Machine, XGBoost classifier, Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU). At the time of model selection part all models were saved. Each model demonstrated strong predictive ability individually, which makes them suitable candidates for contributing diverse and accurate predictions in the ensemble. Our ensemble model consists of machine learning models and deep learning models. These models use different learning biases. This diversity is essential in stacking to ensure the meta-learner can generalize well across prediction errors. In our base model, we utilized these saved models. A neural network is employed for the meta-model, which will integrate the performance of basic models. The neural network consists of 5 layers input layer, hidden layers, and output layer. The size of the input layer is 5 because of the five base models. The output of the five base models will be used as input for the input layer. The number of nodes in the hidden layer was kept at (128, 64, 32, 3) and for the output layer, it was 3 representing three of our labels representing present, past, and future. In training the meta model base models were kept frozen. The input is presented to the base models to predict the output. The predicted output then was used as input for the meta-model and the meta model will be trained by updating its parameters based on its prediction and actual label. The output of the meta model is considered to be the final output. The learning rate for our meta model was 0.001 with 100 epochs for training and the batch size was 100 with regularization r2 = 0.001. Based on train and test accuracy the weights of the best model were stored. The overall architecture of our model can be seen in the <a href="#pone.0330186.g010" class="usa-link">Fig 10</a>.</p>
<figure class="fig xbox font-sm" id="pone.0330186.g010"><h5 class="obj_head">Fig 10. Model architecture.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370126_pone.0330186.g010.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c921/12370126/4f27a4029517/pone.0330186.g010.jpg" loading="lazy" height="232" width="748" alt="Fig 10"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330186.g010/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure></section></section><section id="sec020"><h3 class="pmc_sec_title">Use of generative AI</h3>
<p>The authors have employed generative AI to help with manuscript writing, however, it was not utilized to create the source code or while creating the dataset.</p>
<ul class="list" style="list-style-type:disc">
<li><p>Grammarly: To fix grammatical errors Grammarly software was used. The authors double-checked the suggestions given by the software whether the suggestions would alter the semantic text.</p></li>
<li><p>QuillBot: Some texts were paraphrased using the QuillBot program in the literature review and introduction part and the writers verified the results. We have used QuillBot to paraphrase our own texts. We didn’t upload published works to the tool to produce the literature review. The QuillBot app is only used to reword content in a more appropriate format. It is not used to generate text for introductions or literary reviews.</p></li>
</ul></section></section><section id="sec021"><h2 class="pmc_sec_title">Results and discussion</h2>
<p>This section states the evaluation result of the proposed combined model consisting of machine learning models Random Forest, Support Vector Machine, XGBoost with deep learning models GRU, LSTM on our Bangla Tense dataset. Initially, nine individual experiments of machine learning and deep learning models were conducted to analyze their performance on our dataset and the models are Decision Tree, KNN, Multinomial Naive bayes, Random Forest, RNN, SVM, XGBoost, GRU, LSTM. After that, the five models were chosen to combine based on their performance. <a href="#pone.0330186.t004" class="usa-link">Table 4</a> shows the individual experimental results which were gained by choosing the optimal values for each parameter through necessary trial and error.</p>
<section class="tw xbox font-sm" id="pone.0330186.t004"><h3 class="obj_head">Table 4. Performance analysis of machine learning models.</h3>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">Model</th>
<th align="left" rowspan="1" colspan="1">Level</th>
<th align="left" rowspan="1" colspan="1">Precision</th>
<th align="left" rowspan="1" colspan="1">Recall</th>
<th align="left" rowspan="1" colspan="1">F1-score</th>
<th align="left" rowspan="1" colspan="1">Support</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="3" colspan="1">Decision tree</td>
<td align="left" rowspan="1" colspan="1">0 (Present)</td>
<td align="left" rowspan="1" colspan="1">0.67</td>
<td align="left" rowspan="1" colspan="1">0.69</td>
<td align="left" rowspan="1" colspan="1">0.68</td>
<td align="left" rowspan="1" colspan="1">455</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1 (Past)</td>
<td align="left" rowspan="1" colspan="1">0.78</td>
<td align="left" rowspan="1" colspan="1">0.76</td>
<td align="left" rowspan="1" colspan="1">0.77</td>
<td align="left" rowspan="1" colspan="1">446</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2 (Future)</td>
<td align="left" rowspan="1" colspan="1">0.80</td>
<td align="left" rowspan="1" colspan="1">0.79</td>
<td align="left" rowspan="1" colspan="1">0.79</td>
<td align="left" rowspan="1" colspan="1">449</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">K neighbours</td>
<td align="left" rowspan="1" colspan="1">0 (Present)</td>
<td align="left" rowspan="1" colspan="1">0.46</td>
<td align="left" rowspan="1" colspan="1">0.63</td>
<td align="left" rowspan="1" colspan="1">0.53</td>
<td align="left" rowspan="1" colspan="1">455</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1 (Past)</td>
<td align="left" rowspan="1" colspan="1">0.63</td>
<td align="left" rowspan="1" colspan="1">0.51</td>
<td align="left" rowspan="1" colspan="1">0.56</td>
<td align="left" rowspan="1" colspan="1">446</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2 (Future)</td>
<td align="left" rowspan="1" colspan="1">0.67</td>
<td align="left" rowspan="1" colspan="1">0.56</td>
<td align="left" rowspan="1" colspan="1">0.61</td>
<td align="left" rowspan="1" colspan="1">449</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">Multinomial naive bayes</td>
<td align="left" rowspan="1" colspan="1">0 (Present)</td>
<td align="left" rowspan="1" colspan="1">0.59</td>
<td align="left" rowspan="1" colspan="1">0.56</td>
<td align="left" rowspan="1" colspan="1">0.57</td>
<td align="left" rowspan="1" colspan="1">455</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1 (Past)</td>
<td align="left" rowspan="1" colspan="1">0.66</td>
<td align="left" rowspan="1" colspan="1">0.68</td>
<td align="left" rowspan="1" colspan="1">0.67</td>
<td align="left" rowspan="1" colspan="1">446</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2 (Future)</td>
<td align="left" rowspan="1" colspan="1">0.75</td>
<td align="left" rowspan="1" colspan="1">0.78</td>
<td align="left" rowspan="1" colspan="1">0.76</td>
<td align="left" rowspan="1" colspan="1">449</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">Random forest</td>
<td align="left" rowspan="1" colspan="1">0 (Present)</td>
<td align="left" rowspan="1" colspan="1">0.78</td>
<td align="left" rowspan="1" colspan="1">0.63</td>
<td align="left" rowspan="1" colspan="1">0.70</td>
<td align="left" rowspan="1" colspan="1">455</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1 (Past)</td>
<td align="left" rowspan="1" colspan="1">0.81</td>
<td align="left" rowspan="1" colspan="1">0.85</td>
<td align="left" rowspan="1" colspan="1">0.83</td>
<td align="left" rowspan="1" colspan="1">446</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2 (Future)</td>
<td align="left" rowspan="1" colspan="1">0.78</td>
<td align="left" rowspan="1" colspan="1">0.89</td>
<td align="left" rowspan="1" colspan="1">0.83</td>
<td align="left" rowspan="1" colspan="1">449</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">SVM</td>
<td align="left" rowspan="1" colspan="1">0 (Present)</td>
<td align="left" rowspan="1" colspan="1">0.71</td>
<td align="left" rowspan="1" colspan="1">0.65</td>
<td align="left" rowspan="1" colspan="1">0.68</td>
<td align="left" rowspan="1" colspan="1">455</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1 (Past)</td>
<td align="left" rowspan="1" colspan="1">0.78</td>
<td align="left" rowspan="1" colspan="1">0.78</td>
<td align="left" rowspan="1" colspan="1">0.78</td>
<td align="left" rowspan="1" colspan="1">446</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2 (Future)</td>
<td align="left" rowspan="1" colspan="1">0.76</td>
<td align="left" rowspan="1" colspan="1">0.82</td>
<td align="left" rowspan="1" colspan="1">0.79</td>
<td align="left" rowspan="1" colspan="1">449</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">XGBoost</td>
<td align="left" rowspan="1" colspan="1">0 (Present)</td>
<td align="left" rowspan="1" colspan="1">0.85</td>
<td align="left" rowspan="1" colspan="1">0.47</td>
<td align="left" rowspan="1" colspan="1">0.61</td>
<td align="left" rowspan="1" colspan="1">455</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1 (Past)</td>
<td align="left" rowspan="1" colspan="1">0.75</td>
<td align="left" rowspan="1" colspan="1">0.83</td>
<td align="left" rowspan="1" colspan="1">0.79</td>
<td align="left" rowspan="1" colspan="1">446</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2 (Future)</td>
<td align="left" rowspan="1" colspan="1">0.70</td>
<td align="left" rowspan="1" colspan="1">0.94</td>
<td align="left" rowspan="1" colspan="1">0.80</td>
<td align="left" rowspan="1" colspan="1">449</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0330186.t004/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><section id="sec022"><h3 class="pmc_sec_title">Machine learning models</h3>
<p><a href="#pone.0330186.g011" class="usa-link">Fig 11</a> shows the confusion matrices for the DT, KNN, MNB, RF, SVM, XGB classifiers for our dataset. The confusion matrix for decision tree in <a href="#pone.0330186.g011" class="usa-link">Fig 11</a>(a) shows that 314 instances of class 0 (Present) were correctly classified as 0, but 73 were misclassified as 1 (Past), and 68 were misclassified as 2 (Future). 337 instances of class 1 were correctly classified, but 87 were predicted as 0, and 22 as 2. 355 instances of class 2 were correctly classified, but 71 were predicted as 0, and 23 as 1. The confusion matrix for KNN in <a href="#pone.0330186.g011" class="usa-link">Fig 11</a>(b) shows that 285 instances of class 0 (Present) were correctly classified as 0, but 86 were misclassified as 1 (Past), and 84 were misclassified as 2 (Future). 228 instances of class 1 were correctly classified, but 179 were predicted as 0, and 39 as 2. 250 instances of class 2 were correctly classified, but 151 were predicted as 0, and 48 as 1. The confusion matrix for the multinomial naive bayes classifier in <a href="#pone.0330186.g011" class="usa-link">Fig 11</a>(c) shows that 286 instances of class 0 (Present) were correctly classified as 0, but 81 were misclassified as 1 (Past), and 88 were misclassified as 2 (Future). 378 instances of class 1 were correctly classified, but 41 were predicted as 0, and 27 as 2. 401 instances of class 2 were correctly classified, but 41 were predicted as 0, and 7 as 1. The confusion matrix for the random forest classifier in <a href="#pone.0330186.g011" class="usa-link">Fig 11</a>(d) shows that 286 instances of class 0 (Present) were correctly classified as 0, but 81 were misclassified as 1 (Past), and 88 were misclassified as 2 (Future). 378 instances of class 1 were correctly classified, but 41 were predicted as 0, and 27 as 2. 401 instances of class 2 were correctly classified, but 41 were predicted as 0, and 7 as 1. The confusion matrix for the svm based classifier in <a href="#pone.0330186.g011" class="usa-link">Fig 11</a>(e) shows that 297 instances of class 0 (Present) were correctly classified as 0, but 79 were misclassified as 1 (Past), and 79 were misclassified as 2 (Future). 348 instances of class 1 were correctly classified, but 61 were predicted as 0, and 37 as 2. 368 instances of class 2 were correctly classified, but 61 were predicted as 0, and 19 as 1. The confusion matrix for the xgboost classifier in <a href="#pone.0330186.g011" class="usa-link">Fig 11</a>(f) shows that 215 instances of class 0 (Present) were correctly classified as 0, but 112 were misclassified as 1 (Past), and 128 were misclassified as 2 (Future). 371 instances of class 1 were correctly classified, but 20 were predicted as 0, and 55 as 2. 420 instances of class 2 were correctly classified, but 17 were predicted as 0, and 12 as 1.</p>
<figure class="fig xbox font-sm" id="pone.0330186.g011"><h4 class="obj_head">Fig 11. Confusion matrices for machine learning models (a) DT(b) KNN (c) MNB (d) RF (e) SVM (f) XGB.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370126_pone.0330186.g011.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c921/12370126/78a501479d97/pone.0330186.g011.jpg" loading="lazy" height="383" width="748" alt="Fig 11"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330186.g011/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p>As per the <a href="#pone.0330186.t004" class="usa-link">Table 4</a>, for Decision Tree(DT) ,67% were correctly predicted and 69% were correctly identified as class 0 among 455 actual instances of class 0, 78% were correctly predicted and 76% were correctly identified as class 0 among 446 actual instances of class 1, 80% were correctly predicted and 79% were correctly identified as class 2 among 449 actual instances of class 2. The model performs best for class 2, as it has the highest precision (80%) and recall (79%) compared to the other classes. This indicates that class 2 predictions are the most accurate, and the model can correctly identify the majority of class 2 instances. For KNN, 46% were correctly predicted and 63% were correctly identified as class 0 among 455 actual instances of class 0, 63% were correctly predicted and 51% were correctly identified as class 0 among 446 actual instances of class 1, 67% were correctly predicted and 56% were correctly identified as class 2 among 449 actual instances of class 2. It performs better for class 2 compared to classes 0 and 1, based on precision, recall, and F1-scores. For Multinomial Naive Bayes (MNB), 59% were correctly predicted and 56% were correctly identified as class 0 among 455 actual instances of class 0, 66% were correctly predicted and 68% were correctly identified as class 0 among 446 actual instances of class 1, 75% were correctly predicted and 78% were correctly identified as class 2 among 449 actual instances of class 2. It performs best for class 2 compared to classes 0 and 1, based on precision, recall, and F1-scores. For Random Forest (RF), 78% were correctly predicted and 63% were correctly identified as class 0 among 455 actual instances of class 0, 81% were correctly predicted and 85% were correctly identified as class 0 among 446 actual instances of class 1, 78% were correctly predicted and 89% were correctly identified as class 2 among 449 actual instances of class 2. It performs better for class 1 compared to classes 0 and 2, based on precision, recall, and F1-scores. For Support Vector Machines (SVM), 71% were correctly predicted and 65% were correctly identified as class 0 among 455 actual instances of class 0, 78% were correctly predicted and 78% were correctly identified as class 0 among 446 actual instances of class 1, 76% were correctly predicted and 82% were correctly identified as class 2 among 449 actual instances of class 2. The model performs better for class 1, as it achieves a high and balanced precision and recall, making it more reliable in both predicting and identifying class 1 instances. For Xgboost (Xgb), 85% were correctly predicted and 47% were correctly identified as class 0 among 455 actual instances of class 0, 75% were correctly predicted and 83% were correctly identified as class 0 among 446 actual instances of class 1, 70% were correctly predicted and 94% were correctly identified as class 2 among 449 actual instances of class 2. Considering precision and recall together, class 2 performs better overall due to its higher precision (94%) and reasonably good recall (70%). While class 0 has the highest recall, its much lower precision (47%) indicates more false positives, reducing its overall performance compared to class 2.</p></section><section id="sec023"><h3 class="pmc_sec_title">Deep learning models</h3>
<p><a href="#pone.0330186.g012" class="usa-link">Fig 12</a>(a) shows the confusion matrix for the GRU based classifier for the training data. <a href="#pone.0330186.g012" class="usa-link">Fig 12</a>(b) shows the confusion matrix for the LSTM based classifier for the training data. <a href="#pone.0330186.g012" class="usa-link">Fig 12</a>(c) shows the confusion matrix for the RNN based classifier for the training data. <a href="#pone.0330186.g013" class="usa-link">Fig 13</a>(a) shows the confusion matrix for the GRU for the test data. 299 instances of class 0 (Present) were correctly classified as 0, but 137 were misclassified as 1 (Past), and 19 were misclassified as 2 (Future). 355 instances of class 1 were correctly classified, but 70 were predicted as 0, and 21 as 2. 385 instances of class 2 were correctly classified, but 42 were predicted as 0, and 22 as 1. <a href="#pone.0330186.g013" class="usa-link">Fig 13</a>(b) shows the confusion matrix for the LSTM for the test data. 344 instances of class 0 (Present) were correctly classified as 0, but 82 were misclassified as 1 (Past), and 29 were misclassified as 2 (Future). 326 instances of class 1 were correctly classified, but 101 were predicted as 0, and 19 as 2. 377 instances of class 2 were correctly classified, but 37 were predicted as 0, and 35 as 1. <a href="#pone.0330186.g013" class="usa-link">Fig 13</a>(c) shows the confusion matrix for the RNN classifier for the test data. 363 instances of class 0 (Present) were correctly classified as 0, but 64 were misclassified as 1 (Past), and 28 were misclassified as 2 (Future). 261 instances of class 1 were correctly classified, but 159 were predicted as 0, and 26 as 2. 324 instances of class 2 were correctly classified, but 93 were predicted as 0, and 32 as 1.</p>
<figure class="fig xbox font-sm" id="pone.0330186.g012"><h4 class="obj_head">Fig 12. Confusion matrices for training data for deep learning models (a) GRU classifier (b) LSTM classifier (c) RNN classifier.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370126_pone.0330186.g012.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c921/12370126/7a496056d41a/pone.0330186.g012.jpg" loading="lazy" height="187" width="748" alt="Fig 12"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330186.g012/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><figure class="fig xbox font-sm" id="pone.0330186.g013"><h4 class="obj_head">Fig 13. Confusion matrices for test data for deep learning models (a) GRU classifier (b) LSTM classifier (c) RNN classifier.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370126_pone.0330186.g013.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c921/12370126/bbafb8f7ede0/pone.0330186.g013.jpg" loading="lazy" height="192" width="748" alt="Fig 13"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330186.g013/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p><a href="#pone.0330186.t005" class="usa-link">Table 5</a> represents the performance analysis of GRU, LSTM, and RNN on training data. With a precision of 0.97, recall of 0.92, and F1-score of 0.94, the GRU model does quite well when it comes to future tense prediction. Additionally, it has a good recall of 0.85 and an F1-score of 0.78 when it comes to the past tense. Its accuracy in the present tense, however, is marginally lower at 0.83, yielding an F1-score of 0.77. With F1-scores for Present and Past close to 0.80 and for Future close to 0.92, the LSTM model performs well in all tenses. The RNN model trails behind GRU and LSTM in terms of present tense, future tense, and past tense prediction accuracy. <a href="#pone.0330186.t006" class="usa-link">Table 6</a> illustrates the performance analysis of GRU, LSTM, and RNN on the test data. Where GRU has the highest performance in predicting Future tense with a precision of 0.91, recall of 0.86, and an F1-score of 0.88. Its performance in Present tense is lower, with a precision of 0.76 and an F1-score of 0.71, suggesting it struggles more with differentiating present tense sentences. The Past tense performs moderately well, with an F1-score of 0.72 but slightly higher recall (0.80), suggesting it retrieves more correct past tense sentences but with less precision (0.66). LSTM stands out for its balanced performance across all tenses, especially for the Present and Past tenses. It achieves precision of 0.76 and 0.77, with corresponding F1-scores of 0.76 and 0.77, showing strong capability in maintaining a good balance between precision and recall for both. RNN shows weaker performance in tense classification, with a precision of 0.59 in Present tense and a strong recall of 0.80. Future tense predictions for RNN are still relatively good with an F1-score of 0.78, though not as strong as LSTM or GRU. The average accuracy of GRU, LSTM and RNN was 77.11%, 77.48%, and 70.67%.</p>
<section class="tw xbox font-sm" id="pone.0330186.t005"><h4 class="obj_head">Table 5. Performance analysis of Deep learning models (Training Data).</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">Models</th>
<th align="left" rowspan="1" colspan="1">Level</th>
<th align="left" rowspan="1" colspan="1">Precision</th>
<th align="left" rowspan="1" colspan="1">Recall</th>
<th align="left" rowspan="1" colspan="1">F1-score</th>
<th align="left" rowspan="1" colspan="1">Support</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="3" colspan="1">GRU</td>
<td align="left" rowspan="1" colspan="1">0 (Present)</td>
<td align="left" rowspan="1" colspan="1">0.83</td>
<td align="left" rowspan="1" colspan="1">0.73</td>
<td align="left" rowspan="1" colspan="1">0.77</td>
<td align="left" rowspan="1" colspan="1">2999</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1 (Past)</td>
<td align="left" rowspan="1" colspan="1">0.72</td>
<td align="left" rowspan="1" colspan="1">0.85</td>
<td align="left" rowspan="1" colspan="1">0.78</td>
<td align="left" rowspan="1" colspan="1">2946</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2 (Future)</td>
<td align="left" rowspan="1" colspan="1">0.97</td>
<td align="left" rowspan="1" colspan="1">0.92</td>
<td align="left" rowspan="1" colspan="1">0.94</td>
<td align="left" rowspan="1" colspan="1">2961</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">LSTM</td>
<td align="left" rowspan="1" colspan="1">0 (Present)</td>
<td align="left" rowspan="1" colspan="1">0.79</td>
<td align="left" rowspan="1" colspan="1">0.81</td>
<td align="left" rowspan="1" colspan="1">0.80</td>
<td align="left" rowspan="1" colspan="1">2999</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1 (Past)</td>
<td align="left" rowspan="1" colspan="1">0.80</td>
<td align="left" rowspan="1" colspan="1">0.81</td>
<td align="left" rowspan="1" colspan="1">0.80</td>
<td align="left" rowspan="1" colspan="1">2946</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2 (Future)</td>
<td align="left" rowspan="1" colspan="1">0.94</td>
<td align="left" rowspan="1" colspan="1">0.90</td>
<td align="left" rowspan="1" colspan="1">0.92</td>
<td align="left" rowspan="1" colspan="1">2961</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">RNN</td>
<td align="left" rowspan="1" colspan="1">0 (Present)</td>
<td align="left" rowspan="1" colspan="1">0.62</td>
<td align="left" rowspan="1" colspan="1">0.81</td>
<td align="left" rowspan="1" colspan="1">0.70</td>
<td align="left" rowspan="1" colspan="1">2999</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1 (Past)</td>
<td align="left" rowspan="1" colspan="1">0.75</td>
<td align="left" rowspan="1" colspan="1">0.60</td>
<td align="left" rowspan="1" colspan="1">0.67</td>
<td align="left" rowspan="1" colspan="1">2946</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2 (Future)</td>
<td align="left" rowspan="1" colspan="1">0.88</td>
<td align="left" rowspan="1" colspan="1">0.76</td>
<td align="left" rowspan="1" colspan="1">0.82</td>
<td align="left" rowspan="1" colspan="1">2961</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0330186.t005/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><section class="tw xbox font-sm" id="pone.0330186.t006"><h4 class="obj_head">Table 6. Classification report for all deep learning models on (Test Data).</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">Models</th>
<th align="left" rowspan="1" colspan="1">Level</th>
<th align="left" rowspan="1" colspan="1">Precision</th>
<th align="left" rowspan="1" colspan="1">Recall</th>
<th align="left" rowspan="1" colspan="1">F1-score</th>
<th align="left" rowspan="1" colspan="1">Support</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="3" colspan="1">GRU</td>
<td align="left" rowspan="1" colspan="1">0 (Present)</td>
<td align="left" rowspan="1" colspan="1">0.76</td>
<td align="left" rowspan="1" colspan="1">0.66</td>
<td align="left" rowspan="1" colspan="1">0.71</td>
<td align="left" rowspan="1" colspan="1">455</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1 (Past)</td>
<td align="left" rowspan="1" colspan="1">0.66</td>
<td align="left" rowspan="1" colspan="1">0.80</td>
<td align="left" rowspan="1" colspan="1">0.72</td>
<td align="left" rowspan="1" colspan="1">446</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2 (Future)</td>
<td align="left" rowspan="1" colspan="1">0.91</td>
<td align="left" rowspan="1" colspan="1">0.86</td>
<td align="left" rowspan="1" colspan="1">0.88</td>
<td align="left" rowspan="1" colspan="1">449</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">LSTM</td>
<td align="left" rowspan="1" colspan="1">0 (Present)</td>
<td align="left" rowspan="1" colspan="1">0.76</td>
<td align="left" rowspan="1" colspan="1">0.75</td>
<td align="left" rowspan="1" colspan="1">0.76</td>
<td align="left" rowspan="1" colspan="1">455</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1 (Past)</td>
<td align="left" rowspan="1" colspan="1">0.77</td>
<td align="left" rowspan="1" colspan="1">0.76</td>
<td align="left" rowspan="1" colspan="1">0.77</td>
<td align="left" rowspan="1" colspan="1">446</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2 (Future)</td>
<td align="left" rowspan="1" colspan="1">0.84</td>
<td align="left" rowspan="1" colspan="1">0.87</td>
<td align="left" rowspan="1" colspan="1">0.86</td>
<td align="left" rowspan="1" colspan="1">449</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">RNN</td>
<td align="left" rowspan="1" colspan="1">0 (Present)</td>
<td align="left" rowspan="1" colspan="1">0.59</td>
<td align="left" rowspan="1" colspan="1">0.80</td>
<td align="left" rowspan="1" colspan="1">0.68</td>
<td align="left" rowspan="1" colspan="1">455</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1 (Past)</td>
<td align="left" rowspan="1" colspan="1">0.73</td>
<td align="left" rowspan="1" colspan="1">0.59</td>
<td align="left" rowspan="1" colspan="1">0.65</td>
<td align="left" rowspan="1" colspan="1">446</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2 (Future)</td>
<td align="left" rowspan="1" colspan="1">0.86</td>
<td align="left" rowspan="1" colspan="1">0.72</td>
<td align="left" rowspan="1" colspan="1">0.78</td>
<td align="left" rowspan="1" colspan="1">449</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0330186.t006/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="sec024"><h3 class="pmc_sec_title">Proposed combined model</h3>
<p>Random Forest, Support Vector Machine, XGBoost, LSTM, GRU models are combined together as the proposed model with specific parameters. <a href="#pone.0330186.g014" class="usa-link">Fig 14</a>(a) shows the confusion matrix for the proposed combined classifier for the training data. <a href="#pone.0330186.g014" class="usa-link">Fig 14</a>(b) shows the confusion matrix for the proposed combined model classifier for the test data. 335 instances of class 0 (Present) were correctly classified as 0, but 61 were misclassified as 1 (Past), and 59 were misclassified as 2 (Future). 394 instances of class 1 were correctly classified, but 29 were predicted as 0, and 23 as 2. 410 instances of class 2 were correctly classified, but 29 were predicted as 0, and 10 as 1.</p>
<figure class="fig xbox font-sm" id="pone.0330186.g014"><h4 class="obj_head">Fig 14. Confusion matrix for proposed combined classifier (a) training data (b) test data.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370126_pone.0330186.g014.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c921/12370126/95e50c1dc30d/pone.0330186.g014.jpg" loading="lazy" height="256" width="675" alt="Fig 14"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330186.g014/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p><a href="#pone.0330186.t007" class="usa-link">Table 7</a> represents the performance analysis of the proposed combined model for the training data and test data separately. The model shows near-perfect classification performance on the train data, achieving outstanding results across all tenses with a Precision, Recall, and F1-score around 0.95-0.96 for the Present, Past, and Future categories. But performance falters on test data, especially with the Present and Future tenses. The Present tense shows lesser precision (0.87) and F1-score (0.79), implying greater misclassifications on unseen data, but the Past tense still performs reasonably well with an F1-score of 0.86. A decline in performance is also seen in the Future tense, with an F1-score of 0.87. This suggests that while the model generalizes effectively, testing on new data presents certain difficulties in sustaining the same degree of accuracy. The average accuracy was 85.34%.</p>
<section class="tw xbox font-sm" id="pone.0330186.t007"><h4 class="obj_head">Table 7. Performance analysis of the proposed combined on train data and test data.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">Dataset</th>
<th align="left" rowspan="1" colspan="1">Level</th>
<th align="left" rowspan="1" colspan="1">Precision</th>
<th align="left" rowspan="1" colspan="1">Recall</th>
<th align="left" rowspan="1" colspan="1">F1-score</th>
<th align="left" rowspan="1" colspan="1">Support</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="3" colspan="1">Train Data</td>
<td align="left" rowspan="1" colspan="1">0 (Present)</td>
<td align="left" rowspan="1" colspan="1">0.95</td>
<td align="left" rowspan="1" colspan="1">0.92</td>
<td align="left" rowspan="1" colspan="1">0.94</td>
<td align="left" rowspan="1" colspan="1">2999</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1 (Past)</td>
<td align="left" rowspan="1" colspan="1">0.95</td>
<td align="left" rowspan="1" colspan="1">0.96</td>
<td align="left" rowspan="1" colspan="1">0.95</td>
<td align="left" rowspan="1" colspan="1">2946</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2 (Future)</td>
<td align="left" rowspan="1" colspan="1">0.95</td>
<td align="left" rowspan="1" colspan="1">0.97</td>
<td align="left" rowspan="1" colspan="1">0.96</td>
<td align="left" rowspan="1" colspan="1">2961</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">Test Data</td>
<td align="left" rowspan="1" colspan="1">0 (Present)</td>
<td align="left" rowspan="1" colspan="1">0.87</td>
<td align="left" rowspan="1" colspan="1">0.73</td>
<td align="left" rowspan="1" colspan="1">0.79</td>
<td align="left" rowspan="1" colspan="1">455</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">1 (Past)</td>
<td align="left" rowspan="1" colspan="1">0.83</td>
<td align="left" rowspan="1" colspan="1">0.89</td>
<td align="left" rowspan="1" colspan="1">0.86</td>
<td align="left" rowspan="1" colspan="1">446</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">2 (Future)</td>
<td align="left" rowspan="1" colspan="1">0.83</td>
<td align="left" rowspan="1" colspan="1">0.92</td>
<td align="left" rowspan="1" colspan="1">0.87</td>
<td align="left" rowspan="1" colspan="1">449</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0330186.t007/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p><a href="#pone.0330186.g015" class="usa-link">Fig 15</a> shows the accuracies of the used machine learning classifiers (Naive Bayes, Random Forest, Decision Tree, Support Vector Machine, K Nearest Neighbor, XGBoost) for the test data which are 67.037%, 78.8889%, 74.5185%, 75.1111%, 56.5185% and 74.5185% respectively. On the other hand, the training accuracy is 82.596%, test accuracy is 77.11% for the GRU based model. The training accuracy is 83.45.%, test accuracy is 77.48% for the LSTM model. The training accuracy is 73.669% and test accuracy is 70.67% for the RNN model.</p>
<figure class="fig xbox font-sm" id="pone.0330186.g015"><h4 class="obj_head">Fig 15. Accuracy of existing machine learning models.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c921/12370126/190180d500e4/pone.0330186.g015.jpg" loading="lazy" height="479" width="632" alt="Fig 15"></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330186.g015/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p>Finally, for the proposed combined model shown in <a href="#pone.0330186.g016" class="usa-link">Fig 16</a>(a) and <a href="#pone.0330186.g016" class="usa-link">16</a>(b) depicts the accuracy and loss curve of the proposed combined model over 20 epochs. The model’s test accuracy peaks at 85.34%, while the training accuracy rises to 95%. This suggests the model is learning well but may need more fine-tuning on untested data. The training loss decreases, indicating the model is reducing errors on the training set. The test loss remains flat, suggesting improved generalization and mild overfitting, where the model performs better on training data than test data. In <a href="#pone.0330186.g016" class="usa-link">Fig 16</a>(c), The model’s performance is evaluated for three classes on the ROC curve: negative, positive, and neutral, each with an AUC score. The model is more effective at differentiating between classes, with the Neutral class having the highest AUC (0.97). The Positive class follows with an AUC of 0.95, and the Negative class has the lowest but still significant AUC of 0.93. The model’s excellent predictive ability is demonstrated in all classes, with Neutral forecasts showing particularly impressive performance.</p>
<figure class="fig xbox font-sm" id="pone.0330186.g016"><h4 class="obj_head">Fig 16. Proposed combined model (a) training and test accuracy (b) training and test loss (c) ROC curve of proposed combined model.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12370126_pone.0330186.g016.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/c921/12370126/fc8782e62aca/pone.0330186.g016.jpg" loading="lazy" height="252" width="747" alt="Fig 16"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0330186.g016/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure></section></section><section id="sec025"><h2 class="pmc_sec_title">Conclusion</h2>
<p>In order to meet a critical requirement in natural language processing (NLP) applications for one of the most widely spoken languages in the world, this work presents a novel stacked ensemble model for Bengali tense prediction. The study demonstrates the potential of ensemble approaches in resolving challenging language problems by utilizing the recently engendered BengaliTense dataset, which consists of 13,500 annotated phrases divided into three classes: Present, Past, and Future. To ensure excellent data quality and dependability for experimentation, the dataset was painstakingly preprocessed using methods including contextual annotation, noise removal, and missing data handling. The strengths of several classifiers, including XGBoost, Random Forest, SVM, GRU, and LSTM, are combined in the suggested ensemble model to create a strong framework. By achieving an accuracy of 85% on the test set, this hybrid strategy outperformed standalone models. The ensemble’s practical usefulness in real-world applications is shown by its ability to handle Bengali’s morphological richness and tense-specific changes. Additionally, comparison analyses provided information about the particular advantages and disadvantages of each model, demonstrating the ensemble’s superior generalization across a range of linguistic structures.</p>
<p>While the results are promising, some limitations were identified, including challenges with unseen data and the need for larger and more diverse datasets. Future research should focus on expanding the dataset, incorporating advanced models such as transformers, and exploring morphological tense conversion for a comprehensive approach to Bengali NLP. The proposed ensemble model performs well but shows limited generalization on unseen data, and the dataset may not capture all Bengali dialects. Transformer-based models were not explored, and standardized benchmarks are lacking. Future work will address these issues by expanding the dataset, integrating advanced models, and exploring tense morphology. In future work, we aim to incorporate token-level attribution methods such as SHAP analysis.</p>
<p>This work lays a strong foundation for subsequent studies in the field and contributes significantly to the development of inclusive language technologies.</p></section><section id="ack1" class="ack"><h2 class="pmc_sec_title">Acknowledgments</h2>
<p>Students at Daffodil International University are appreciated for their assistance in creating the dataset.</p></section><section id="notes1"><h2 class="pmc_sec_title">Data Availability</h2>
<p>The dataset supporting the findings of this study is publicly available in Mendeley Data at <a href="https://doi.org/10.17632/w9mdy6tw84.1" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://doi.org/10.17632/w9mdy6tw84.1</a>.</p></section><section id="funding-statement1" lang="en"><h2 class="pmc_sec_title">Funding Statement</h2>
<p>The author(s) received no specific funding for this work.</p></section><section id="ref-list1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="ref-list1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="pone.0330186.ref001">
<span class="label">1.</span><cite>Chomsky N. Language and other cognitive systems. What is special about language?
Language Learning and Development. 2011;7(4):263–78. doi: 10.1080/15475441.2011.584041</cite> [<a href="https://doi.org/10.1080/15475441.2011.584041" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Language%20Learning%20and%20Development&amp;title=Language%20and%20other%20cognitive%20systems.%20What%20is%20special%20about%20language?&amp;author=N%20Chomsky&amp;volume=7&amp;issue=4&amp;publication_year=2011&amp;pages=263-78&amp;doi=10.1080/15475441.2011.584041&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref002">
<span class="label">2.</span><cite>New World Encyclopedia. Bengali language; <a href="https://www.newworldencyclopedia.org/entry/Bengali_language/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.newworldencyclopedia.org/entry/Bengali_language/</a></cite>
</li>
<li id="pone.0330186.ref003">
<span class="label">3.</span><cite>Visual Capitalist. The 100 Most Spoken Languages Around the World. <a href="https://www.visualcapitalist.com/100-most-spoken-languages/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.visualcapitalist.com/100-most-spoken-languages/</a>.</cite>
</li>
<li id="pone.0330186.ref004">
<span class="label">4.</span><cite>Slifka J. Tense/lax vowel classification using dynamic spectral cues. In: Proceedings of the 15th ICPhS. 2003. p. 921–4.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings%20of%20the%2015th%20ICPhS&amp;author=J%20Slifka&amp;publication_year=2003&amp;pages=921-4&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref005">
<span class="label">5.</span><cite>Binnick RI. The Oxford Handbook of Tense and Aspect. Oxford University Press; 2012. 10.1093/oxfordhb/9780195381979.001.0001</cite> [<a href="https://doi.org/10.1093/oxfordhb/9780195381979.001.0001" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?title=The%20Oxford%20Handbook%20of%20Tense%20and%20Aspect&amp;author=RI%20Binnick&amp;publication_year=2012&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref006">
<span class="label">6.</span><cite>Ding Y, Wang T. Environmental affection-driven English tense analysis: a healthcare exercise-based corpus case study over public English environment. J Environ Public Health. 2022;2022:9497554. doi: 10.1155/2022/9497554

</cite> [<a href="https://doi.org/10.1155/2022/9497554" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9206547/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35726325/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Environ%20Public%20Health&amp;title=Environmental%20affection-driven%20English%20tense%20analysis:%20a%20healthcare%20exercise-based%20corpus%20case%20study%20over%20public%20English%20environment&amp;author=Y%20Ding&amp;author=T%20Wang&amp;volume=2022&amp;publication_year=2022&amp;pages=9497554&amp;pmid=35726325&amp;doi=10.1155/2022/9497554&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref007">
<span class="label">7.</span><cite>Eisenstein J. Introduction to natural language processing. The MIT Press; 2019.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=Introduction%20to%20natural%20language%20processing&amp;author=J%20Eisenstein&amp;publication_year=2019&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref008">
<span class="label">8.</span><cite>Das AK, Al Asif A, Paul A, Hossain MdN. Bangla hate speech detection on social media using attention-based recurrent neural network. Journal of Intelligent Systems. 2021;30(1):578–91. doi: 10.1515/jisys-2020-0060</cite> [<a href="https://doi.org/10.1515/jisys-2020-0060" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Journal%20of%20Intelligent%20Systems&amp;title=Bangla%20hate%20speech%20detection%20on%20social%20media%20using%20attention-based%20recurrent%20neural%20network&amp;author=AK%20Das&amp;author=A%20Al%20Asif&amp;author=A%20Paul&amp;author=MdN%20Hossain&amp;volume=30&amp;issue=1&amp;publication_year=2021&amp;pages=578-91&amp;doi=10.1515/jisys-2020-0060&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref009">
<span class="label">9.</span><cite>Rahman S, Chakraborty P. Bangla document classification using deep recurrent neural network with BiLSTM. In: Proceedings of International Conference on Machine Intelligence and Data Science Applications: MIDAS 2020, 2021. p. 507–19.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Proceedings%20of%20International%20Conference%20on%20Machine%20Intelligence%20and%20Data%20Science%20Applications:%20MIDAS%202020&amp;author=S%20Rahman&amp;author=P%20Chakraborty&amp;publication_year=2021&amp;pages=507-19&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref010">
<span class="label">10.</span><cite>Ghosh T, Banna MdHA, Nahian MdJA, Uddin MN, Kaiser MS, Mahmud M. An attention-based hybrid architecture with explainability for depressive social media text detection in Bangla. Expert Systems with Applications. 2023;213:119007. doi: 10.1016/j.eswa.2022.119007</cite> [<a href="https://doi.org/10.1016/j.eswa.2022.119007" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Expert%20Systems%20with%20Applications&amp;title=An%20attention-based%20hybrid%20architecture%20with%20explainability%20for%20depressive%20social%20media%20text%20detection%20in%20Bangla&amp;author=T%20Ghosh&amp;author=MdHA%20Banna&amp;author=MdJA%20Nahian&amp;author=MN%20Uddin&amp;author=MS%20Kaiser&amp;volume=213&amp;publication_year=2023&amp;pages=119007&amp;doi=10.1016/j.eswa.2022.119007&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref011">
<span class="label">11.</span><cite>Haque R, Islam N, Tasneem M, Das AK. Multi-class sentiment classification on Bengali social media comments using machine learning. International Journal of Cognitive Computing in Engineering. 2023;4:21–35. doi: 10.1016/j.ijcce.2023.01.001</cite> [<a href="https://doi.org/10.1016/j.ijcce.2023.01.001" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=International%20Journal%20of%20Cognitive%20Computing%20in%20Engineering&amp;title=Multi-class%20sentiment%20classification%20on%20Bengali%20social%20media%20comments%20using%20machine%20learning&amp;author=R%20Haque&amp;author=N%20Islam&amp;author=M%20Tasneem&amp;author=AK%20Das&amp;volume=4&amp;publication_year=2023&amp;pages=21-35&amp;doi=10.1016/j.ijcce.2023.01.001&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref012">
<span class="label">12.</span><cite>Akash Rahman M, Begum M, Mahmud T, Hossain MS, Andersson K. Analyzing sentiments in eLearning: a comparative study of Bangla and romanized Bangla text using transformers. IEEE Access. 2024;12:89144–62. doi: 10.1109/access.2024.3419024</cite> [<a href="https://doi.org/10.1109/access.2024.3419024" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Access&amp;title=Analyzing%20sentiments%20in%20eLearning:%20a%20comparative%20study%20of%20Bangla%20and%20romanized%20Bangla%20text%20using%20transformers&amp;author=M%20Akash%20Rahman&amp;author=M%20Begum&amp;author=T%20Mahmud&amp;author=MS%20Hossain&amp;author=K%20Andersson&amp;volume=12&amp;publication_year=2024&amp;pages=89144-62&amp;doi=10.1109/access.2024.3419024&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref013">
<span class="label">13.</span><cite>Asghar MZ, Subhan F, Ahmad H, Khan WZ, Hakak S, Gadekallu TR, et al. Senti‐eSystem: a sentiment‐based eSystem‐using hybridized fuzzy and deep neural network for measuring customer satisfaction. Softw Pract Exp. 2020;51(3):571–94. doi: 10.1002/spe.2853</cite> [<a href="https://doi.org/10.1002/spe.2853" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Softw%20Pract%20Exp&amp;title=Senti%E2%80%90eSystem:%20a%20sentiment%E2%80%90based%20eSystem%E2%80%90using%20hybridized%20fuzzy%20and%20deep%20neural%20network%20for%20measuring%20customer%20satisfaction&amp;author=MZ%20Asghar&amp;author=F%20Subhan&amp;author=H%20Ahmad&amp;author=WZ%20Khan&amp;author=S%20Hakak&amp;volume=51&amp;issue=3&amp;publication_year=2020&amp;pages=571-94&amp;doi=10.1002/spe.2853&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref014">
<span class="label">14.</span><cite>Salehin K, Alam MK, Nabi MdA, Ahmed F, Ashraf FB. A comparative study of different text classification approaches for bangla news classification. In: 2021 24th International Conference on Computer and Information Technology (ICCIT). 2021. p. 1–6. 10.1109/iccit54785.2021.9689843</cite> [<a href="https://doi.org/10.1109/iccit54785.2021.9689843" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=2021%2024th%20International%20Conference%20on%20Computer%20and%20Information%20Technology%20(ICCIT)&amp;author=K%20Salehin&amp;author=MK%20Alam&amp;author=MdA%20Nabi&amp;author=F%20Ahmed&amp;author=FB%20Ashraf&amp;publication_year=2021&amp;pages=1-6&amp;doi=10.1109/iccit54785.2021.9689843&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref015">
<span class="label">15.</span><cite>Khan MdSS, Rafa SR, Abir AEH, Das AK. Sentiment analysis on Bengali Facebook comments to predict fan’s emotions towards a celebrity. J eng adv. 2021:118–24. doi: 10.38032/jea.2021.03.001</cite> [<a href="https://doi.org/10.38032/jea.2021.03.001" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20eng%20adv&amp;title=Sentiment%20analysis%20on%20Bengali%20Facebook%20comments%20to%20predict%20fan%E2%80%99s%20emotions%20towards%20a%20celebrity&amp;author=MdSS%20Khan&amp;author=SR%20Rafa&amp;author=AEH%20Abir&amp;author=AK%20Das&amp;publication_year=2021&amp;pages=118-24&amp;doi=10.38032/jea.2021.03.001&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref016">
<span class="label">16.</span><cite>Bangyal WH, Qasim R, Rehman NU, Ahmad Z, Dar H, Rukhsar L. Detection of fake news text classification on COVID-19 using deep learning approaches. Computational and Mathematical Methods in Medicine. 2021;2021(1):5514220.
</cite> [<a href="https://doi.org/10.1155/2021/5514220" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8608495/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34819990/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Computational%20and%20Mathematical%20Methods%20in%20Medicine&amp;title=Detection%20of%20fake%20news%20text%20classification%20on%20COVID-19%20using%20deep%20learning%20approaches&amp;author=WH%20Bangyal&amp;author=R%20Qasim&amp;author=NU%20Rehman&amp;author=Z%20Ahmad&amp;author=H%20Dar&amp;volume=2021&amp;issue=1&amp;publication_year=2021&amp;pages=5514220&amp;pmid=34819990&amp;doi=10.1155/2021/5514220&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref017">
<span class="label">17.</span><cite>Bhowmik NR, Arifuzzaman M, Mondal MRH, Islam MS. Bangla text sentiment analysis using supervised machine learning with extended Lexicon dictionary. NLPRE. 2021;1(3–4):34. doi: 10.2991/nlpr.d.210316.001</cite> [<a href="https://doi.org/10.2991/nlpr.d.210316.001" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=NLPRE&amp;title=Bangla%20text%20sentiment%20analysis%20using%20supervised%20machine%20learning%20with%20extended%20Lexicon%20dictionary&amp;author=NR%20Bhowmik&amp;author=M%20Arifuzzaman&amp;author=MRH%20Mondal&amp;author=MS%20Islam&amp;volume=1&amp;publication_year=2021&amp;pages=34&amp;doi=10.2991/nlpr.d.210316.001&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref018">
<span class="label">18.</span><cite>Bhowmik NR, Arifuzzaman M, Mondal MRH. Sentiment analysis on Bangla text using extended lexicon dictionary and deep learning algorithms. Array. 2022;13:100123. doi: 10.1016/j.array.2021.100123</cite> [<a href="https://doi.org/10.1016/j.array.2021.100123" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Array&amp;title=Sentiment%20analysis%20on%20Bangla%20text%20using%20extended%20lexicon%20dictionary%20and%20deep%20learning%20algorithms&amp;author=NR%20Bhowmik&amp;author=M%20Arifuzzaman&amp;author=MRH%20Mondal&amp;volume=13&amp;publication_year=2022&amp;pages=100123&amp;doi=10.1016/j.array.2021.100123&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref019">
<span class="label">19.</span><cite>Wadud MdAH, Kabir MM, Mridha MF, Ali MA, Hamid MdA, Monowar MM. How can we manage offensive text in social media - a text classification approach using LSTM-BOOST. International Journal of Information Management Data Insights. 2022;2(2):100095. doi: 10.1016/j.jjimei.2022.100095</cite> [<a href="https://doi.org/10.1016/j.jjimei.2022.100095" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=International%20Journal%20of%20Information%20Management%20Data%20Insights&amp;title=How%20can%20we%20manage%20offensive%20text%20in%20social%20media%20-%20a%20text%20classification%20approach%20using%20LSTM-BOOST&amp;author=MdAH%20Wadud&amp;author=MM%20Kabir&amp;author=MF%20Mridha&amp;author=MA%20Ali&amp;author=MdA%20Hamid&amp;volume=2&amp;issue=2&amp;publication_year=2022&amp;pages=100095&amp;doi=10.1016/j.jjimei.2022.100095&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref020">
<span class="label">20.</span><cite>Rahman M, Talukder MdRA, Setu LA, Das AK. A dynamic strategy for classifying sentiment from Bengali text by utilizing Word2vector model. Journal of Information Technology Research. 2022;15(1):1–17. doi: 10.4018/jitr.299919</cite> [<a href="https://doi.org/10.4018/jitr.299919" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Journal%20of%20Information%20Technology%20Research&amp;title=A%20dynamic%20strategy%20for%20classifying%20sentiment%20from%20Bengali%20text%20by%20utilizing%20Word2vector%20model&amp;author=M%20Rahman&amp;author=MdRA%20Talukder&amp;author=LA%20Setu&amp;author=AK%20Das&amp;volume=15&amp;issue=1&amp;publication_year=2022&amp;pages=1-17&amp;doi=10.4018/jitr.299919&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref021">
<span class="label">21.</span><cite>Chakraborty P, Nawar F, Chowdhury HA. Sentiment analysis of Bengali facebook data using classical and deep learning approaches. Innovation in Electrical Power Engineering, Communication, and Computing Technology: Proceedings of Second IEPCCT 2021. Springer; 2022. p. 209–18.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=Innovation%20in%20Electrical%20Power%20Engineering,%20Communication,%20and%20Computing%20Technology:%20Proceedings%20of%20Second%20IEPCCT%202021&amp;author=P%20Chakraborty&amp;author=F%20Nawar&amp;author=HA%20Chowdhury&amp;publication_year=2022&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref022">
<span class="label">22.</span><cite>Prottasha NJ, Sami AA, Kowsher M, Murad SA, Bairagi AK, Masud M, et al. Transfer learning for sentiment analysis using BERT based supervised fine-tuning. Sensors (Basel). 2022;22(11):4157. doi: 10.3390/s22114157

</cite> [<a href="https://doi.org/10.3390/s22114157" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9185586/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35684778/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Sensors%20(Basel)&amp;title=Transfer%20learning%20for%20sentiment%20analysis%20using%20BERT%20based%20supervised%20fine-tuning&amp;author=NJ%20Prottasha&amp;author=AA%20Sami&amp;author=M%20Kowsher&amp;author=SA%20Murad&amp;author=AK%20Bairagi&amp;volume=22&amp;issue=11&amp;publication_year=2022&amp;pages=4157&amp;pmid=35684778&amp;doi=10.3390/s22114157&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref023">
<span class="label">23.</span><cite>Aurpa TT, Sadik R, Ahmed MS. Abusive Bangla comments detection on Facebook using transformer-based deep learning models. Soc Netw Anal Min. 2021;12(1). doi: 10.1007/s13278-021-00852-x</cite> [<a href="https://doi.org/10.1007/s13278-021-00852-x" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Soc%20Netw%20Anal%20Min&amp;title=Abusive%20Bangla%20comments%20detection%20on%20Facebook%20using%20transformer-based%20deep%20learning%20models&amp;author=TT%20Aurpa&amp;author=R%20Sadik&amp;author=MS%20Ahmed&amp;volume=12&amp;issue=1&amp;publication_year=2021&amp;doi=10.1007/s13278-021-00852-x&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref024">
<span class="label">24.</span><cite>Sourav MSU, Wang H, Mahmud MS, Zheng H. Transformer-based text classification on unified Bangla multi-class emotion corpus. arXiv preprint
2022. <a href="https://arxiv.org/abs/2210.06405" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://arxiv.org/abs/2210.06405</a></cite> [<a href="https://scholar.google.com/scholar_lookup?journal=arXiv%20preprint&amp;title=Transformer-based%20text%20classification%20on%20unified%20Bangla%20multi-class%20emotion%20corpus&amp;author=MSU%20Sourav&amp;author=H%20Wang&amp;author=MS%20Mahmud&amp;author=H%20Zheng&amp;publication_year=2022&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref025">
<span class="label">25.</span><cite>Jahan SSS, Rab R, Dutta P, Khan HMMH, Badhon MSK, Hassan SB, et al. Computing and Informatics. 2023;42(4):993–1012.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Computing%20and%20Informatics&amp;author=SSS%20Jahan&amp;author=R%20Rab&amp;author=P%20Dutta&amp;author=HMMH%20Khan&amp;author=MSK%20Badhon&amp;volume=42&amp;issue=4&amp;publication_year=2023&amp;pages=993-1012&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref026">
<span class="label">26.</span><cite>Roy A, Sarkar K, Mandal CK. Bengali text classification: a new multi-class dataset and performance evaluation of machine learning and deep learning models. 2023.</cite>
</li>
<li id="pone.0330186.ref027">
<span class="label">27.</span><cite>Anwar Hussen Wadud Md, F. Mridha M, Shin J, Nur K, Kumar Saha A. Deep-BERT: transfer learning for classifying multilingual offensive texts on social media. Computer Systems Science and Engineering. 2023;44(2):1775–91. doi: 10.32604/csse.2023.027841</cite> [<a href="https://doi.org/10.32604/csse.2023.027841" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Computer%20Systems%20Science%20and%20Engineering&amp;title=Deep-BERT:%20transfer%20learning%20for%20classifying%20multilingual%20offensive%20texts%20on%20social%20media&amp;author=Md%20Anwar%20Hussen%20Wadud&amp;author=M%20F.%20Mridha&amp;author=J%20Shin&amp;author=K%20Nur&amp;author=A%20Kumar%20Saha&amp;volume=44&amp;issue=2&amp;publication_year=2023&amp;pages=1775-91&amp;doi=10.32604/csse.2023.027841&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref028">
<span class="label">28.</span><cite>Su J, Zhang H. A fast decision tree learning algorithm. Aaai. 2006. 
6:500–5.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Aaai&amp;title=A%20fast%20decision%20tree%20learning%20algorithm&amp;author=J%20Su&amp;author=H%20Zhang&amp;volume=6&amp;publication_year=2006&amp;pages=500-5&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref029">
<span class="label">29.</span><cite>Liu Y, Wang Y, Zhang J. New machine learning algorithm: random forest. Information Computing and Applications: Third International Conference, ICICA 2012, Chengde, China, September 14-16, 2012. Proceedings 3. Springer; 2012. p. 246–52.</cite> [<a href="https://scholar.google.com/scholar_lookup?title=Information%20Computing%20and%20Applications:%20Third%20International%20Conference,%20ICICA%202012,%20Chengde,%20China,%20September%2014-16,%202012.%20Proceedings%203&amp;author=Y%20Liu&amp;author=Y%20Wang&amp;author=J%20Zhang&amp;publication_year=2012&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref030">
<span class="label">30.</span><cite>Singh G, Kumar B, Gaur L, Tyagi A. Comparison between multinomial and Bernoulli naïve Bayes for text classification. In: 2019 International conference on automation, computational and technology management (ICACTM). 2019. p. 593–6.</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=2019%20International%20conference%20on%20automation,%20computational%20and%20technology%20management%20(ICACTM)&amp;author=G%20Singh&amp;author=B%20Kumar&amp;author=L%20Gaur&amp;author=A%20Tyagi&amp;publication_year=2019&amp;pages=593-6&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref031">
<span class="label">31.</span><cite>Yu H, Kim S. SVM Tutorial — Classification, Regression and Ranking. Handbook of Natural Computing. Berlin, Heidelberg: Springer; 2012. p. 479–506. 10.1007/978-3-540-92910-9_15</cite> [<a href="https://doi.org/10.1007/978-3-540-92910-9_15" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?title=Handbook%20of%20Natural%20Computing&amp;author=H%20Yu&amp;author=S%20Kim&amp;publication_year=2012&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref032">
<span class="label">32.</span><cite>Zhang S, Li X, Zong M, Zhu X, Cheng D. Learning k for kNN classification. ACM Trans Intell Syst Technol. 2017;8(3):1–19. doi: 10.1145/2990508</cite> [<a href="https://doi.org/10.1145/2990508" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=ACM%20Trans%20Intell%20Syst%20Technol&amp;title=Learning%20k%20for%20kNN%20classification&amp;author=S%20Zhang&amp;author=X%20Li&amp;author=M%20Zong&amp;author=X%20Zhu&amp;author=D%20Cheng&amp;volume=8&amp;issue=3&amp;publication_year=2017&amp;pages=1-19&amp;doi=10.1145/2990508&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref033">
<span class="label">33.</span><cite>Babajide Mustapha I, Saeed F. Bioactive molecule prediction using extreme gradient boosting. Molecules. 2016;21(8):983. doi: 10.3390/molecules21080983

</cite> [<a href="https://doi.org/10.3390/molecules21080983" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6273295/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27483216/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Molecules&amp;title=Bioactive%20molecule%20prediction%20using%20extreme%20gradient%20boosting&amp;author=I%20Babajide%20Mustapha&amp;author=F%20Saeed&amp;volume=21&amp;issue=8&amp;publication_year=2016&amp;pages=983&amp;pmid=27483216&amp;doi=10.3390/molecules21080983&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref034">
<span class="label">34.</span><cite>Sherstinsky A. Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) network. Physica D: Nonlinear Phenomena. 2020;404:132306. doi: 10.1016/j.physd.2019.132306</cite> [<a href="https://doi.org/10.1016/j.physd.2019.132306" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Physica%20D:%20Nonlinear%20Phenomena&amp;title=Fundamentals%20of%20Recurrent%20Neural%20Network%20(RNN)%20and%20Long%20Short-Term%20Memory%20(LSTM)%20network&amp;author=A%20Sherstinsky&amp;volume=404&amp;publication_year=2020&amp;pages=132306&amp;doi=10.1016/j.physd.2019.132306&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref035">
<span class="label">35.</span><cite>Zhao Z, Chen W, Wu X, Chen PCY, Liu J. LSTM network: a deep learning approach for short‐term traffic forecast. IET Intelligent Trans Sys. 2017;11(2):68–75. doi: 10.1049/iet-its.2016.0208</cite> [<a href="https://doi.org/10.1049/iet-its.2016.0208" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IET%20Intelligent%20Trans%20Sys&amp;title=LSTM%20network:%20a%20deep%20learning%20approach%20for%20short%E2%80%90term%20traffic%20forecast&amp;author=Z%20Zhao&amp;author=W%20Chen&amp;author=X%20Wu&amp;author=PCY%20Chen&amp;author=J%20Liu&amp;volume=11&amp;issue=2&amp;publication_year=2017&amp;pages=68-75&amp;doi=10.1049/iet-its.2016.0208&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref036">
<span class="label">36.</span><cite>Mohsen S. Recognition of human activity using GRU deep learning algorithm. Multimed Tools Appl. 2023;82(30):47733–49. doi: 10.1007/s11042-023-15571-y</cite> [<a href="https://doi.org/10.1007/s11042-023-15571-y" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Multimed%20Tools%20Appl&amp;title=Recognition%20of%20human%20activity%20using%20GRU%20deep%20learning%20algorithm&amp;author=S%20Mohsen&amp;volume=82&amp;issue=30&amp;publication_year=2023&amp;pages=47733-49&amp;doi=10.1007/s11042-023-15571-y&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref037">
<span class="label">37.</span><cite>Dey R, Salem FM. Gate-variants of Gated Recurrent Unit (GRU) neural networks. In: 2017 IEEE 60th International Midwest Symposium on Circuits and Systems (MWSCAS). 2017. p. 1597–600. 10.1109/mwscas.2017.8053243</cite> [<a href="https://doi.org/10.1109/mwscas.2017.8053243" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=2017%20IEEE%2060th%20International%20Midwest%20Symposium%20on%20Circuits%20and%20Systems%20(MWSCAS)&amp;author=R%20Dey&amp;author=FM%20Salem&amp;publication_year=2017&amp;pages=1597-600&amp;doi=10.1109/mwscas.2017.8053243&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref038">
<span class="label">38.</span><cite>Chowdhury AK, Sujon SR, Shafi MdSS, Ahmmad T, Ahmed S, Hasib KM, et al. Harnessing large language models over transformer models for detecting Bengali depressive social media text: a comprehensive study. Natural Language Processing Journal. 2024;7:100075. doi: 10.1016/j.nlp.2024.100075</cite> [<a href="https://doi.org/10.1016/j.nlp.2024.100075" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Natural%20Language%20Processing%20Journal&amp;title=Harnessing%20large%20language%20models%20over%20transformer%20models%20for%20detecting%20Bengali%20depressive%20social%20media%20text:%20a%20comprehensive%20study&amp;author=AK%20Chowdhury&amp;author=SR%20Sujon&amp;author=MdSS%20Shafi&amp;author=T%20Ahmmad&amp;author=S%20Ahmed&amp;volume=7&amp;publication_year=2024&amp;pages=100075&amp;doi=10.1016/j.nlp.2024.100075&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref039">
<span class="label">39.</span><cite>Islam MdS, Alam KM. Sentiment analysis of Bangla language using a new comprehensive dataset BangDSA and the novel feature metric skipBangla-BERT. Natural Language Processing Journal. 2024;7:100069. doi: 10.1016/j.nlp.2024.100069</cite> [<a href="https://doi.org/10.1016/j.nlp.2024.100069" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Natural%20Language%20Processing%20Journal&amp;title=Sentiment%20analysis%20of%20Bangla%20language%20using%20a%20new%20comprehensive%20dataset%20BangDSA%20and%20the%20novel%20feature%20metric%20skipBangla-BERT&amp;author=MdS%20Islam&amp;author=KM%20Alam&amp;volume=7&amp;publication_year=2024&amp;pages=100069&amp;doi=10.1016/j.nlp.2024.100069&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref040">
<span class="label">40.</span><cite>Mahmud T, Ptaszynski M, Masui F. Exhaustive study into machine learning and deep learning methods for multilingual cyberbullying detection in Bangla and Chittagonian texts. Electronics. 2024;13(9):1677. doi: 10.3390/electronics13091677</cite> [<a href="https://doi.org/10.3390/electronics13091677" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Electronics&amp;title=Exhaustive%20study%20into%20machine%20learning%20and%20deep%20learning%20methods%20for%20multilingual%20cyberbullying%20detection%20in%20Bangla%20and%20Chittagonian%20texts&amp;author=T%20Mahmud&amp;author=M%20Ptaszynski&amp;author=F%20Masui&amp;volume=13&amp;issue=9&amp;publication_year=2024&amp;pages=1677&amp;doi=10.3390/electronics13091677&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref041">
<span class="label">41.</span><cite>Kularathne S, Perera A, Rathnayake N, Rathnayake U, Hoshino Y. Analyzing the impact of socioeconomic indicators on gender inequality in Sri Lanka: a machine learning-based approach. PLoS One. 2024;19(12):e0312395. doi: 10.1371/journal.pone.0312395

</cite> [<a href="https://doi.org/10.1371/journal.pone.0312395" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11671024/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39724101/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=PLoS%20One&amp;title=Analyzing%20the%20impact%20of%20socioeconomic%20indicators%20on%20gender%20inequality%20in%20Sri%20Lanka:%20a%20machine%20learning-based%20approach&amp;author=S%20Kularathne&amp;author=A%20Perera&amp;author=N%20Rathnayake&amp;author=U%20Rathnayake&amp;author=Y%20Hoshino&amp;volume=19&amp;issue=12&amp;publication_year=2024&amp;pmid=39724101&amp;doi=10.1371/journal.pone.0312395&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref042">
<span class="label">42.</span><cite>Kularathne S, Rathnayake N, Herath M, Rathnayake U, Hoshino Y. Impact of economic indicators on rice production: a machine learning approach in Sri Lanka. PLoS One. 2024;19(6):e0303883. doi: 10.1371/journal.pone.0303883

</cite> [<a href="https://doi.org/10.1371/journal.pone.0303883" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11192421/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38905194/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=PLoS%20One&amp;title=Impact%20of%20economic%20indicators%20on%20rice%20production:%20a%20machine%20learning%20approach%20in%20Sri%20Lanka&amp;author=S%20Kularathne&amp;author=N%20Rathnayake&amp;author=M%20Herath&amp;author=U%20Rathnayake&amp;author=Y%20Hoshino&amp;volume=19&amp;issue=6&amp;publication_year=2024&amp;pmid=38905194&amp;doi=10.1371/journal.pone.0303883&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref043">
<span class="label">43.</span><cite>Rathnayake N, Rathnayake U, Dang TL, Hoshino Y. Water level prediction using soft computing techniques: a case study in the Malwathu Oya, Sri Lanka. PLoS One. 2023;18(4):e0282847. doi: 10.1371/journal.pone.0282847

</cite> [<a href="https://doi.org/10.1371/journal.pone.0282847" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10132539/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37099590/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=PLoS%20One&amp;title=Water%20level%20prediction%20using%20soft%20computing%20techniques:%20a%20case%20study%20in%20the%20Malwathu%20Oya,%20Sri%20Lanka&amp;author=N%20Rathnayake&amp;author=U%20Rathnayake&amp;author=TL%20Dang&amp;author=Y%20Hoshino&amp;volume=18&amp;issue=4&amp;publication_year=2023&amp;pmid=37099590&amp;doi=10.1371/journal.pone.0282847&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0330186.ref044">
<span class="label">44.</span><cite>Huang Z, Liu H, Zhu J, Min J. Customer sentiment recognition in conversation based on contextual semantic and affective interaction information. Applied Sciences. 2023;13(13):7807. doi: 10.3390/app13137807</cite> [<a href="https://doi.org/10.3390/app13137807" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Applied%20Sciences&amp;title=Customer%20sentiment%20recognition%20in%20conversation%20based%20on%20contextual%20semantic%20and%20affective%20interaction%20information&amp;author=Z%20Huang&amp;author=H%20Liu&amp;author=J%20Zhu&amp;author=J%20Min&amp;volume=13&amp;issue=13&amp;publication_year=2023&amp;pages=7807&amp;doi=10.3390/app13137807&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
</ul></section></section></section><article class="sub-article" id="pone.0330186.r001"><section class="pmc-layout__citation font-secondary font-xs"><div>PLoS One. doi: <a href="https://doi.org/10.1371/journal.pone.0330186.r001" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1371/journal.pone.0330186.r001</a>
</div></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Decision Letter 0</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Rathnayake%20N%22%5BAuthor%5D" class="usa-link" aria-describedby="id6"><span class="name western">Namal Rathnayake</span></a><div hidden="hidden" id="id6">
<h3><span class="name western">Namal Rathnayake</span></h3>
<div>Academic Editor</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Rathnayake%20N%22%5BAuthor%5D" class="usa-link"><span class="name western">Namal Rathnayake</span></a>
</div>
</div>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a.c" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="clp_a.c" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a.c" class="d-panel p" style="display: none">
<h4 class="font-secondary">Roles</h4>
<div class="p">
<strong class="contrib"><span class="name western">Namal Rathnayake</span></strong>: <span class="role">Academic Editor</span>
</div>
</div>
<div id="clp_a.c" class="d-panel p" style="display: none">
<div>© 2025 Namal Rathnayake</div>
<p>This is an open access article distributed under the terms of the <a href="https://creativecommons.org/licenses/by/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Creative Commons Attribution License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div></div>
</div></section><section class="body sub-article-body"><hr class="headless">
<p>
<em>9 Apr 2025</em>
</p>
<p>PONE-D-24-57203Navigating Tenses in Bengali Sentences: A Stacked Ensemble Model for Enhanced PredictionPLOS ONE</p>
<p>Dear Dr. Hasan,</p>
<p>Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE’s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.</p>
<p>Please submit your revised manuscript by May 24 2025 11:59PM. If you will need more time than this to complete your revisions, please reply to this message or contact the journal office at <span>plosone@plos.org</span>. When you're ready to submit your revision, log on to <a href="https://www.editorialmanager.com/pone/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.editorialmanager.com/pone/</a> and select the 'Submissions Needing Revision' folder to locate your manuscript file.</p>
<p>Please include the following items when submitting your revised manuscript:</p>
<ul class="list" style="list-style-type:disc">
<li><p>A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). You should upload this letter as a separate file labeled 'Response to Reviewers'.</p></li>
<li><p>A marked-up copy of your manuscript that highlights changes made to the original version. You should upload this as a separate file labeled 'Revised Manuscript with Track Changes'.</p></li>
<li><p>An unmarked version of your revised paper without tracked changes. You should upload this as a separate file labeled 'Manuscript'.</p></li>
</ul>
<p>If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter. Guidelines for resubmitting your figure files are available below the reviewer comments at the end of this letter.</p>
<p>If applicable, we recommend that you deposit your laboratory protocols in protocols.io to enhance the reproducibility of your results. Protocols.io assigns your protocol its own identifier (DOI) so that it can be cited independently in the future. For instructions see: <a href="https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols</a>. Additionally, PLOS ONE offers an option for publishing peer-reviewed Lab Protocol articles, which describe protocols hosted on protocols.io. Read more information on sharing protocols at <a href="https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://plos.org/protocols?utm_medium=editorial-email&amp;utm_source=authorletters&amp;utm_campaign=protocols</a>.</p>
<p>We look forward to receiving your revised manuscript.</p>
<p>Kind regards,</p>
<p>Namal Rathnayake, Ph.D.</p>
<p>Academic Editor</p>
<p>PLOS ONE</p>
<p>
<strong>Journal Requirements:</strong>
</p>
<p>1. When submitting your revision, we need you to address these additional requirements.</p>
<p>Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at <a href="https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf</a> and <a href="https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf</a> 2. In your Methods section, please include additional information about your dataset and ensure that you have included a statement specifying whether the collection and analysis method complied with the terms and conditions for the source of the data. 3. Please note that PLOS ONE has specific guidelines on code sharing for submissions in which author-generated code underpins the findings in the manuscript. In these cases, we expect all author-generated code to be made available without restrictions upon publication of the work. Please review our guidelines at <a href="https://journals.plos.org/plosone/s/materials-and-software-sharing#loc-sharing-code" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://journals.plos.org/plosone/s/materials-and-software-sharing#loc-sharing-code</a> and ensure that your code is shared in a way that follows best practice and facilitates reproducibility and reuse. 4. We note that your Data Availability Statement is currently as follows: All relevant data are within the manuscript and its Supporting Information files. Please confirm at this time whether or not your submission contains all raw data required to replicate the results of your study. Authors must share the “minimal data set” for their submission. PLOS defines the minimal data set to consist of the data required to replicate all study findings reported in the article, as well as related metadata and methods (<a href="https://journals.plos.org/plosone/s/data-availability#loc-minimal-data-set-definition" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://journals.plos.org/plosone/s/data-availability#loc-minimal-data-set-definition</a>). For example, authors should submit the following data: - The values behind the means, standard deviations and other measures reported;- The values used to build graphs;- The points extracted from images for analysis. Authors do not need to submit their entire data set if only a portion of the data was used in the reported study. If your submission does not contain these data, please either upload them as Supporting Information files or deposit them to a stable, public repository and provide us with the relevant URLs, DOIs, or accession numbers. For a list of recommended repositories, please see <a href="https://journals.plos.org/plosone/s/recommended-repositories" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://journals.plos.org/plosone/s/recommended-repositories</a>. If there are ethical or legal restrictions on sharing a de-identified data set, please explain them in detail (e.g., data contain potentially sensitive information, data are owned by a third-party organization, etc.) and who has imposed them (e.g., an ethics committee). Please also provide contact information for a data access committee, ethics committee, or other institutional body to which data requests may be sent. If data are owned by a third party, please indicate how others may request data access. 5. PLOS requires an ORCID iD for the corresponding author in Editorial Manager on papers submitted after December 6th, 2016. Please ensure that you have an ORCID iD and that it is validated in Editorial Manager. To do this, go to ‘Update my Information’ (in the upper left-hand corner of the main menu), and click on the Fetch/Validate link next to the ORCID field. This will take you to the ORCID site and allow you to create a new iD or authenticate a pre-existing iD in Editorial Manager.</p>
<p>
<strong>Additional Editor Comments:</strong>
</p>
<p>Rewrite abstract and intro to specify task, dataset, model, metrics, and novelty. Add baseline comparisons, explain model architecture, handle class imbalance, discuss Bengali language challenges, interpretability, and justify the contribution clearly.</p>
<p><strong>Comments from PLOS Editorial Office: </strong>We note that one or more reviewers has recommended that you cite specific previously published works. As always, we recommend that you please review and evaluate the requested works to determine whether they are relevant and should be cited. It is not a requirement to cite these works. We appreciate your attention to this request.</p>
<p>[Note: HTML markup is below. Please do not edit.]</p>
<p>Reviewers' comments:</p>
<p>Reviewer's Responses to Questions</p>
<p>

<strong>Comments to the Author</strong>
</p>
<p>1. Is the manuscript technically sound, and do the data support the conclusions?</p>
<p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. </p>
<p>Reviewer #1: Yes</p>
<p>Reviewer #2: Partly</p>
<p>**********</p>
<p>2. Has the statistical analysis been performed appropriately and rigorously? </p>
<p>Reviewer #1: Yes</p>
<p>Reviewer #2: No</p>
<p>**********</p>
<p>3. Have the authors made all data underlying the findings in their manuscript fully available?</p>
<p>The <a href="http://www.plosone.org/static/policies.action#sharing" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">PLOS Data policy</a> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.</p>
<p>Reviewer #1: Yes</p>
<p>Reviewer #2: No</p>
<p>**********</p>
<p>4. Is the manuscript presented in an intelligible fashion and written in standard English?</p>
<p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.</p>
<p>Reviewer #1: Yes</p>
<p>Reviewer #2: No</p>
<p>**********</p>
<p>5. Review Comments to the Author</p>
<p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)</p>
<p><strong>Reviewer #1: </strong>Abstract needs complete rewrite. Add concrete info on model type, dataset used, accuracy achieved, and contribution.</p>
<p>In intro, Clearly state the objective. Literature is not well synthesized. Review of recent deep learning NLP works for Bengali is missing.</p>
<p>No clear novelty. Stacking models is not new. Authors must explicitly say: “Our novel contribution is…” and justify how this differs from prior Bengali NLP work.</p>
<p>There is no detail on train-test split, feature preprocessing, or hyperparameter settings.</p>
<p>Authors mention base learners but don’t explain architecture or why those were chosen. Provide diagrams or a clear pipeline.</p>
<p>What metric is used for “highest accuracy” (line 91)? Is it F1? Precision?</p>
<p>Add a limitations paragraph.</p>
<p>Replace sentences like “paves the way for further research” (line 108) with real actionable outcomes. Avoid over-generalization.</p>
<p>Needs professional proofreading.</p>
<p>Read these studies to further enrich your study, (<a href="https://doi.org/10.1371/journal.pone.0312395" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://doi.org/10.1371/journal.pone.0312395</a>) Supports your paper's socioeconomic perspective, especially how economic indicators shape inequality using ML. (<a href="https://doi.org/10.1371/journal.pone.0303883" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://doi.org/10.1371/journal.pone.0303883</a>) Demonstrates use of ML with economic indicators in the Sri Lankan context, aligning with your economic modeling. (<a href="https://doi.org/10.1371/journal.pone.0282847" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://doi.org/10.1371/journal.pone.0282847</a>) Reinforces your use of hybrid models like ANFIS and soft computing in Sri Lankan environmental data modeling.</p>
<p><strong>Reviewer #2: </strong>Navigating Tenses in Bengali Sentences: A Stacked Ensemble Model for Enhanced</p>
<p>Prediction</p>
<p>1. You mention broad goals around improving accuracy and language modeling for</p>
<p>Bengali, but you never define the specific task (e.g., classification? sentiment?</p>
<p>named entity recognition?) in clear terms at the beginning. Define the target NLP</p>
<p>task explicitly and connect it to your broader motivation, whether it's education,</p>
<p>policy, or social impact in Bengali-speaking regions.</p>
<p>2. You claim your stacked model performs better, but there’s no comparison with a</p>
<p>baseline model (e.g., logistic regression, SVM, or even a single deep model).</p>
<p>This makes it impossible to assess whether the stacking architecture adds real</p>
<p>value. Include results from simpler models to show performance gains.</p>
<p>3. There’s no mention of whether the dataset is balanced. If your dataset has</p>
<p>skewed classes (which is common in real-world Bengali text), then accuracy</p>
<p>alone is misleading. Did you use class weights, oversampling, or SMOTE? This</p>
<p>should be discussed and reflected in metrics like F1 or recall per class.</p>
<p>4. Beyond noting the language, you don’t discuss the linguistic characteristics of</p>
<p>Bengali that make this NLP task uniquely challenging (e.g., rich morphology, low-</p>
<p>resource nature, ambiguous syntax). Add some language-specific insights to</p>
<p>justify why your model is suitable and necessary.</p>
<p>5. Given that your stacked model is complex, how do you explain or interpret its</p>
<p>predictions? Even a brief mention of SHAP values, attention weights, or feature</p>
<p>importance would increase trust and make the model more actionable for</p>
<p>policymakers or users in the region.</p>
<p>6. Refer to this work, relevant to your socio-contextual motivation of language-</p>
<p>based emotion/sentiment classification in noisy settings.</p>
<p>DOI: 10.1038/s41598-024-67269-2</p>
<p>**********</p>
<p>6. PLOS authors have the option to publish the peer review history of their article (<a href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">what does this mean?</a>). If published, this will include your full peer review and any attached files.</p>
<p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
<p><strong>Do you want your identity to be public for this peer review?</strong> For information about this choice, including consent withdrawal, please see our <a href="https://www.plos.org/privacy-policy" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Privacy Policy</a>.</p>
<p>Reviewer #1: No</p>
<p>Reviewer #2: No</p>
<p>**********</p>
<p>[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files.]</p>
<p>While revising your submission, please upload your figure files to the Preflight Analysis and Conversion Engine (PACE) digital diagnostic tool, <a href="https://pacev2.apexcovantage.com/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://pacev2.apexcovantage.com/</a>. PACE helps ensure that figures meet PLOS requirements. To use PACE, you must first register as a user. Registration is free. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email PLOS at <span>figures@plos.org</span>. Please note that Supporting Information files do not need this step.</p></section></article><article class="sub-article" id="pone.0330186.r002"><section class="pmc-layout__citation font-secondary font-xs"><div>PLoS One. 2025 Aug 21;20(8):e0330186. doi: <a href="https://doi.org/10.1371/journal.pone.0330186.r002" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1371/journal.pone.0330186.r002</a>
</div></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Author response to Decision Letter 1</h1></hgroup><ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="anp_a.d" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a.d" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="anp_a.d" class="d-panel p" style="display: none"><div class="notes p"><section id="historyfront-stub2" class="history"><p>Collection date 2025.</p></section></div></div>
<div id="clp_a.d" class="d-panel p" style="display: none"><div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div></div>
</div>
<div></div>
</div></section><section class="body sub-article-body"><hr class="headless">
<p>
<em>9 Jun 2025</em>
</p>
<p>Title: “Navigating Tenses in Bengali Sentences: A Stacked Ensemble Model for Enhanced</p>
<p>Prediction” (Submission ID: PONE-D-24-57203)</p>
<p># Response to Reviewer 1: (Color code= Red)</p>
<p>#Point 1:</p>
<p>Abstract needs complete rewrite. Add concrete info on model type, dataset used, accuracy</p>
<p>achieved, and contribution.</p>
<p>Author Response:</p>
<p>Thank you for your valuable and constructive feedback. In response to your comment, we have completely</p>
<p>revised the abstract to clearly articulate the scope, methodology, and contributions of our work. The updated</p>
<p>abstract now specifies the NLP task of Bengali tense classification and its relevance to downstream</p>
<p>applications. We describe the construction of a novel dataset, “BengaliTenseCorpus,” comprising 13,500</p>
<p>manually labeled sentences across three tense categories. Additionally, we detail our proposed stacked</p>
<p>ensemble model integrating five base classifiers (Random Forest, SVM, XGBoost, LSTM, and GRU) with</p>
<p>a neural network meta-learner, and report the achieved test accuracy of 85%. We also highlight the novelty</p>
<p>of combining machine learning and deep learning techniques for this task and outline future directions.</p>
<p>These additions ensure the abstract conveys the model type, dataset used, accuracy obtained, and the overall</p>
<p>contribution of our work, in line with your suggestion.</p>
<p>Author Action:</p>
<p>Based on the reviewer’s comments, we have updated our Abstract Section to meet the reviewer’s</p>
<p>concerns.</p>
<p>#Point 2:</p>
<p>In intro, Clearly state the objective. Literature is not well synthesized. Review of recent deep</p>
<p>learning NLP works for Bengali is missing.</p>
<p>Author Response:</p>
<p>Thank you for your thoughtful feedback. In response, we have revised the introduction to explicitly state</p>
<p>the main objective of the study as developing a robust stacked ensemble model for automatic tense</p>
<p>classification in Bengali sentences and its significance in the context of Bangla NLP. Additionally, we</p>
<p>have strengthened the literature review by synthesizing existing works more cohesively and</p>
<p>incorporating several recent studies that apply deep learning techniques to Bengali language tasks, such</p>
<p>as classification, prediction, and detection. These additions provide a clearer context for our contribution</p>
<p>and ensure that the background is both comprehensive and current. We believe these revisions directly</p>
<p>address the reviewer’s concerns and enhance the clarity and relevance of the introduction.</p>
<p>Author Action:</p>
<p>Based on the reviewer’s comments, we have updated our Introduction Section and Literature</p>
<p>Review Section to meet the reviewer’s concerns.#Point 3:</p>
<p>No clear novelty. Stacking models is not new. Authors must explicitly say: “Our novel contribution</p>
<p>is…” and justify how this differs from prior Bengali NLP work.</p>
<p>Author Response:</p>
<p>Thank you for your kind remarks. There is little to no work present in the predictive model to</p>
<p>predict the tense of Bangla text. The sole reason for this problem is the lack of a valid dataset. Our</p>
<p>novel contribution is to create a meaningful dataset for Bangla tense prediction and create a</p>
<p>predictive model around it</p>
<p>Author Action:</p>
<p>We have included our novel contribution statement at the end of the introduction section according to</p>
<p>the reviewer's suggestions.</p>
<p>#Point 4:</p>
<p>There is no detail on train test split, feature preprocessing, or hyperparameter settings.</p>
<p>Author Response:</p>
<p>Thank you for your valuable feedback.</p>
<p>Author Action:</p>
<p>With the renamed subsection of "Model Selection and Hyper Parameters," all information</p>
<p>pertaining to the train-test split and hyper hyperparameter setup is added to the methodology</p>
<p>section. Likewise, details regarding feature processing are included in the methodology part of the</p>
<p>paragraph titled "Data Pre-processing".</p>
<p>#Point 5:</p>
<p>Authors mention base learners but don’t explain architecture or why those were chosen. Provide</p>
<p>diagrams or a clear pipeline.</p>
<p>Author Response:</p>
<p>We selected base models based on their empirical performance during cross-validation. Each</p>
<p>model demonstrated strong predictive ability individually, which makes them suitable candidates</p>
<p>for contributing diverse and accurate predictions in the ensemble. Our ensemble model consists of</p>
<p>machine learning models and deep learning models. These models use different learning biases.</p>
<p>This diversity is essential in stacking to ensure the meta-learner can generalize well across</p>
<p>prediction errors. A clear pipeline is presented in Figure 10.</p>
<p>Author Action:</p>
<p>A brief discussion of our preferred models while creating the ensemble model is given in “Our Model”</p>
<p>subsection.</p>
<p>#Point 6:</p>
<p>What metric is used for “highest accuracy” (line 91)? Is it F1? Precision?</p>
<p>Author Response:</p>
<p>Thank you for your feedback. The accuracy score of such a model is referred to as the highest</p>
<p>accuracy. For that model, the F1 score, precision, and recall were all 0.989.Author Action:</p>
<p>We have rewritten the sentence accordingly.</p>
<p>#Point 7:</p>
<p>Add a Limitation Paragraph.</p>
<p>Author Response:</p>
<p>We appreciate reviewers' valuable insight.</p>
<p>Author Action:</p>
<p>A paragraph has been added at the end of the conclusion section to discuss the limitations and future</p>
<p>work.</p>
<p>#Point 8:</p>
<p>Replace sentences like “paves the way for further research” (line 108) with real actionable</p>
<p>outcomes. Avoid over generalization. Needs professional proofreading.</p>
<p>Author Response:</p>
<p>In response, we have revised overgeneralized statements such as “paves the way for further</p>
<p>research” (line 108) and replaced them with specific, actionable outcomes related to dataset</p>
<p>expansion, transformer-based model integration, and tense morphology conversion. Additionally,</p>
<p>the entire manuscript has been carefully proofread and refined to improve clarity, precision, and</p>
<p>professionalism in language. We believe these changes enhance both the quality and specificity of</p>
<p>the manuscript.</p>
<p>Author Action:</p>
<p>Based on the reviewer’s comments, we have replaced the statement with constructive outcome.</p>
<p>#Point 9:</p>
<p>Read these studies to further enrich your study, (<a href="https://doi.org/10.1371/journal.pone.0312395" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://doi.org/10.1371/journal.pone.0312395</a>)</p>
<p>Supports your paper's socioeconomic perspective, especially how economic indicators shape</p>
<p>inequality using ML. (<a href="https://doi.org/10.1371/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://doi.org/10.1371/</a> journal.pone.0303883) Demonstrates use of ML</p>
<p>with economic indicators in the Sri Lankan context, aligning with your economic modeling.</p>
<p>(<a href="https://doi.org/10.1371/journal.pone.0282847" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://doi.org/10.1371/journal.pone.0282847</a>) Reinforces your use of hybrid models like ANFIS</p>
<p>and soft computing in Sri Lankan environmental data modeling.</p>
<p>Author Response:</p>
<p>Thank you for recommending these valuable studies. We have reviewed all three articles and</p>
<p>incorporated relevant insights into the manuscript to strengthen the socioeconomic and</p>
<p>methodological context of our work. Specifically, we referenced the use of machine learning in</p>
<p>economic inequality modeling and hybrid approaches like ANFIS in environmental data analysis,</p>
<p>particularly in low-resource contexts similar to ours. These additions have enriched the</p>
<p>background and discussion sections and helped to better position our contribution within existing</p>
<p>literature.</p>
<p>Author Action:</p>
<p>Based on the reviewer’s comments, we have updated the literature review.# Response to Reviewer 2: (Color code= Green)</p>
<p>#Point 1:</p>
<p>You mention broad goals around improving accuracy and language modeling for Bengali, but you</p>
<p>never define the specific task (e.g., classification? sentiment? named entity recognition?) in clear</p>
<p>terms at the beginning. Define the target NLP task explicitly and connect it to your broader</p>
<p>motivation, whether it's education, policy, or social impact in Bengali speaking regions.</p>
<p>Author Response:</p>
<p>In response, we have revised the introduction to clearly define the target NLP task as automatic tense</p>
<p>classification in Bengali text. We have explicitly stated this task early in the introduction and connected it</p>
<p>to broader motivations such as improving educational tools, supporting grammar correction, and enabling</p>
<p>more inclusive and effective NLP technologies for Bengali-speaking communities. This clarification helps</p>
<p>to better frame the scope and societal relevance of our work.</p>
<p>Author Action:</p>
<p>Updated the introduction to explicitly define the target NLP task as automatic tense classification</p>
<p>and linked it to broader motivations such as educational support, grammar correction, and</p>
<p>enhancing NLP applications for Bengali-speaking communities.</p>
<p>#Point 2:</p>
<p>You claim your stacked model performs better, but there’s no comparison with a baseline model</p>
<p>(e.g., logistic regression, SVM, or even a single deep model). This makes it impossible to assess</p>
<p>whether the stacking architecture adds real value. Include results from simpler models to show</p>
<p>performance gains.</p>
<p>Author Response:</p>
<p>We thank the reviewers for their valuable insights. We included a detailed comparison table of</p>
<p>several machine learning models (6 models) and deep learning (3 models) models' performance in</p>
<p>the “Results and Discussion” section, with accuracy, recall, and F-1 scores. In every case, our</p>
<p>proposed stacking ensemble model outperformed all the machine learning and deep learning</p>
<p>models.</p>
<p>Author Action:</p>
<p>We included a paragraph stating the information in the “Proposed Combined Model” section.#Point 3:</p>
<p>There’s no mention of whether the dataset is balanced. If your dataset has skewed classes (which</p>
<p>is common in real world Bengali text), then accuracy alone is misleading. Did you use class</p>
<p>weights, oversampling, or SMOTE? This should be discussed and reflected in metrics like F1 or</p>
<p>recall per class.</p>
<p>Author Response:</p>
<p>Thank you for this valuable observation. Our dataset was balanced. For that reason, we didn’t</p>
<p>require any oversampling techniques. The support value that reflects the per-class instance is</p>
<p>present in every table for every model in the “Results and Discussion” section.</p>
<p>Author Response:</p>
<p>We have also included the dataset information about balancing in “Dataset Collection and</p>
<p>Properties” subsection.</p>
<p>#Point 4:</p>
<p>Beyond noting the language, you don’t discuss the linguistic characteristics of Bengali that make</p>
<p>this NLP task uniquely challenging (e.g., rich morphology, low resource nature, ambiguous</p>
<p>syntax). Add some language specific insights to justify why your model is suitable and necessary.</p>
<p>Author Response:</p>
<p>Thank you for this valuable observation. In response, we have revised the introduction to include</p>
<p>a detailed discussion of Bengali’s linguistic characteristics that make tense classification</p>
<p>particularly challenging. Specifically, we address its rich inflectional morphology, low-resource</p>
<p>nature, syntactic ambiguity, and the predominance of suffix-based tense marking. We also explain</p>
<p>how our stacked ensemble model is well-suited to handle these complexities by combining deep</p>
<p>learning for sequence modeling and machine learning for robust pattern recognition. These</p>
<p>additions help clarify the necessity and relevance of our approach</p>
<p>Author Action:</p>
<p>We have Revised the introduction to include a detailed explanation of Bengali's linguistic features,</p>
<p>such as its rich morphology, low-resource status, and syntactic ambiguity, and justified the</p>
<p>suitability of the proposed stacked ensemble model in addressing these challenges.</p>
<p>#Point 5:</p>
<p>Given that your stacked model is complex, how do you explain or interpret its predictions? Even</p>
<p>a brief mention of SHAP values, attention weights, or feature importance would increase trust and</p>
<p>make the model more actionable for policymakers or users in the region.</p>
<p>Author Response:</p>
<p>We appreciate the reviewer’s emphasis on model interpretability, particularly given the complexity</p>
<p>of our stacked ensemble and the importance of actionable insights for policymakers. While SHAP</p>
<p>analysis is challenging to apply directly to our current ensemble due to the heterogeneous natureof the base models and their text processing pipelines, we agree that interpretability is critical for</p>
<p>transparency and trust. In future work, we aim to incorporate token-level attribution methods such</p>
<p>as SHAP.</p>
<p>Author Action:</p>
<p>Added as Future Work in the Conclusion section.</p>
<p>#Point 6:</p>
<p>Refer to this work, relevant to your socio contextual motivation of language based</p>
<p>emotion/sentiment classification in noisy settings. DOI: 10.1038/s41598-024-67269-2</p>
<p>Author Response:</p>
<p>In response, we have tried to reach this paper. We found a similar paper titled “Customer Sentiment</p>
<p>Recognition in Conversation Based on Contextual Semantic and Affective Interaction</p>
<p>Information”</p>
<p>Author Action:</p>
<p>We have included the paper in Literature Review section</p>
<p>Again, thank you for your kind cooperation and consideration.</p>
<p>Best Regards,</p>
<p>Md. Nahid Hasan</p>
<p>Corresponding Author</p>
<section class="sm xbox font-sm" id="pone.0330186.s001"><div class="caption p">
<span>Attachment</span><p>Submitted filename: <em>Response to Reviewers_PONE-D-24-57203.pdf</em></p>
</div>
<div class="media p"><div class="caption">
<a href="/articles/instance/12370126/bin/pone.0330186.s001.pdf" data-ga-action="click_feat_suppl" class="usa-link">pone.0330186.s001.pdf</a><sup> (202.5KB, pdf) </sup>
</div></div></section></section></article><article class="sub-article" id="pone.0330186.r003"><section class="pmc-layout__citation font-secondary font-xs"><div>PLoS One. doi: <a href="https://doi.org/10.1371/journal.pone.0330186.r003" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1371/journal.pone.0330186.r003</a>
</div></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Decision Letter 1</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kasmaiee%20S%22%5BAuthor%5D" class="usa-link" aria-describedby="id7"><span class="name western">Saman Kasmaiee</span></a><div hidden="hidden" id="id7">
<h3><span class="name western">Saman Kasmaiee</span></h3>
<div>Academic Editor</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kasmaiee%20S%22%5BAuthor%5D" class="usa-link"><span class="name western">Saman Kasmaiee</span></a>
</div>
</div>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a.e" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="clp_a.e" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a.e" class="d-panel p" style="display: none">
<h4 class="font-secondary">Roles</h4>
<div class="p">
<strong class="contrib"><span class="name western">Saman Kasmaiee</span></strong>: <span class="role">Academic Editor</span>
</div>
</div>
<div id="clp_a.e" class="d-panel p" style="display: none">
<div>© 2025 Saman Kasmaiee</div>
<p>This is an open access article distributed under the terms of the <a href="https://creativecommons.org/licenses/by/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Creative Commons Attribution License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div></div>
</div></section><section class="body sub-article-body"><hr class="headless">
<p>
<em>29 Jul 2025</em>
</p>
<p>Navigating Tenses in Bengali Sentences: A Stacked Ensemble Model for Enhanced Prediction</p>
<p>PONE-D-24-57203R1</p>
<p>Dear Dr. Hasan,</p>
<p>We’re pleased to inform you that your manuscript has been judged scientifically suitable for publication and will be formally accepted for publication once it meets all outstanding technical requirements.</p>
<p>Within one week, you’ll receive an e-mail detailing the required amendments. When these have been addressed, you’ll receive a formal acceptance letter and your manuscript will be scheduled for publication.</p>
<p>An invoice will be generated when your article is formally accepted. Please note, if your institution has a publishing partnership with PLOS and your article meets the relevant criteria, all or part of your publication costs will be covered. Please make sure your user information is up-to-date by logging into Editorial Manager at <a href="https://www.editorialmanager.com/pone/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Editorial Manager®</a> and clicking the ‘Update My Information' link at the top of the page. If you have any questions relating to publication charges, please contact our Author Billing department directly at <span>authorbilling@plos.org</span>.</p>
<p>If your institution or institutions have a press office, please notify them about your upcoming paper to help maximize its impact. If they’ll be preparing press materials, please inform our press team as soon as possible -- no later than 48 hours after receiving the formal acceptance. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact <span>onepress@plos.org</span>.</p>
<p>Kind regards,</p>
<p>Saman Kasmaiee, Ph.D.</p>
<p>Academic Editor</p>
<p>PLOS ONE</p>
<p>Additional Editor Comments (optional):</p>
<p>Reviewers' comments:</p>
<p>Reviewer's Responses to Questions</p>
<p>

<strong>Comments to the Author</strong>
</p>
<p>1. If the authors have adequately addressed your comments raised in a previous round of review and you feel that this manuscript is now acceptable for publication, you may indicate that here to bypass the “Comments to the Author” section, enter your conflict of interest statement in the “Confidential to Editor” section, and submit your "Accept" recommendation.</p>
<p>Reviewer #3: All comments have been addressed</p>
<p>**********</p>
<p>2. Is the manuscript technically sound, and do the data support the conclusions?</p>
<p>The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. </p>
<p>Reviewer #3: Yes</p>
<p>**********</p>
<p>3. Has the statistical analysis been performed appropriately and rigorously? </p>
<p>Reviewer #3: Yes</p>
<p>**********</p>
<p>4. Have the authors made all data underlying the findings in their manuscript fully available?</p>
<p>The <a href="http://www.plosone.org/static/policies.action#sharing" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">PLOS Data policy</a> requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.</p>
<p>Reviewer #3: Yes</p>
<p>**********</p>
<p>5. Is the manuscript presented in an intelligible fashion and written in standard English?</p>
<p>PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.</p>
<p>Reviewer #3: Yes</p>
<p>**********</p>
<p>6. Review Comments to the Author</p>
<p>Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)</p>
<p>Reviewer #3: The authors have done a good job in addressing the raised issues. It would be great if they could address the issue of inter-annotator agreement score for the manual labelling and error analysis, and also compress teh "preprocessing" section.</p>
<p>**********</p>
<p>7. PLOS authors have the option to publish the peer review history of their article (<a href="https://journals.plos.org/plosone/s/editorial-and-peer-review-process#loc-peer-review-history" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">what does this mean?</a>). If published, this will include your full peer review and any attached files.</p>
<p>If you choose “no”, your identity will remain anonymous but your review may still be made public.</p>
<p><strong>Do you want your identity to be public for this peer review?</strong> For information about this choice, including consent withdrawal, please see our <a href="https://www.plos.org/privacy-policy" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Privacy Policy</a>.</p>
<p>Reviewer #3: No</p>
<p>**********</p></section></article><article class="sub-article" id="pone.0330186.r004"><section class="pmc-layout__citation font-secondary font-xs"><div>PLoS One. doi: <a href="https://doi.org/10.1371/journal.pone.0330186.r004" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1371/journal.pone.0330186.r004</a>
</div></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Acceptance letter</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kasmaiee%20S%22%5BAuthor%5D" class="usa-link" aria-describedby="id8"><span class="name western">Saman Kasmaiee</span></a><div hidden="hidden" id="id8">
<h3><span class="name western">Saman Kasmaiee</span></h3>
<div>Academic Editor</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kasmaiee%20S%22%5BAuthor%5D" class="usa-link"><span class="name western">Saman Kasmaiee</span></a>
</div>
</div>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a.f" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="clp_a.f" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a.f" class="d-panel p" style="display: none">
<h4 class="font-secondary">Roles</h4>
<div class="p">
<strong class="contrib"><span class="name western">Saman Kasmaiee</span></strong>: <span class="role">Academic Editor</span>
</div>
</div>
<div id="clp_a.f" class="d-panel p" style="display: none">
<div>© 2025 Saman Kasmaiee</div>
<p>This is an open access article distributed under the terms of the <a href="https://creativecommons.org/licenses/by/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Creative Commons Attribution License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div></div>
</div></section><section class="body sub-article-body"><hr class="headless">
<p>PONE-D-24-57203R1</p>
<p>PLOS ONE</p>
<p>Dear Dr. Hasan,</p>
<p>I'm pleased to inform you that your manuscript has been deemed suitable for publication in PLOS ONE. Congratulations! Your manuscript is now being handed over to our production team.</p>
<p>At this stage, our production department will prepare your paper for publication. This includes ensuring the following:</p>
<p>* All references, tables, and figures are properly cited</p>
<p>* All relevant supporting information is included in the manuscript submission,</p>
<p>* There are no issues that prevent the paper from being properly typeset</p>
<p>You will receive further instructions from the production team, including instructions on how to review your proof when it is ready. Please keep in mind that we are working through a large volume of accepted articles, so please give us a few days to review your paper and let you know the next and final steps.</p>
<p>Lastly, if your institution or institutions have a press office, please let them know about your upcoming paper now to help maximize its impact. If they'll be preparing press materials, please inform our press team within the next 48 hours. Your manuscript will remain under strict press embargo until 2 pm Eastern Time on the date of publication. For more information, please contact <span>onepress@plos.org</span>.</p>
<p>You will receive an invoice from PLOS for your publication fee after your manuscript has reached the completed accept phase. If you receive an email requesting payment before acceptance or for any other service, this may be a phishing scheme. Learn how to identify phishing emails and protect your accounts at <a href="https://explore.plos.org/phishing" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://explore.plos.org/phishing</a>.</p>
<p>If we can help with anything else, please email us at <span>customercare@plos.org</span>.</p>
<p>Thank you for submitting your work to PLOS ONE and supporting open access.</p>
<p>Kind regards,</p>
<p>PLOS ONE Editorial Office Staff</p>
<p>on behalf of</p>
<p>Dr. Saman Kasmaiee</p>
<p>Academic Editor</p>
<p>PLOS ONE</p></section></article><article class="sub-article" id="_ad93_"><section class="pmc-layout__citation font-secondary font-xs"><div></div></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Associated Data</h1></hgroup><ul class="d-buttons inline-list"></ul>
<div class="d-panels font-secondary-light"></div>
<div></div>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
</div></section><section class="body sub-article-body"><section id="_adsm93_" lang="en" class="supplementary-materials"><h2 class="pmc_sec_title">Supplementary Materials</h2>
<section class="sm xbox font-sm" id="db_ds_supplementary-material1_reqid_"><div class="caption p">
<span>Attachment</span><p>Submitted filename: <em>Response to Reviewers_PONE-D-24-57203.pdf</em></p>
</div>
<div class="media p"><div class="caption">
<a href="/articles/instance/12370126/bin/pone.0330186.s001.pdf" data-ga-action="click_feat_suppl" class="usa-link">pone.0330186.s001.pdf</a><sup> (202.5KB, pdf) </sup>
</div></div></section></section><section id="_adda93_" lang="en" class="data-availability-statement"><h2 class="pmc_sec_title">Data Availability Statement</h2>
<p>The dataset supporting the findings of this study is publicly available in Mendeley Data at <a href="https://doi.org/10.17632/w9mdy6tw84.1" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://doi.org/10.17632/w9mdy6tw84.1</a>.</p></section></section></article><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from PLOS One are provided here courtesy of <strong>PLOS</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1371/journal.pone.0330186"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/pone.0330186.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (6.1 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12370126/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12370126/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12370126%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12370126/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12370126/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12370126/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40839646/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12370126/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40839646/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12370126/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12370126/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="2hJ4bq43HwLFA19QpNHy4Wd57UmsDTkX4l4L5TeM0zP50SqYZHohnQTTZjxpkINm">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
        <script type="module" crossorigin="" src="/static/assets/math-574fdcc6.js"></script>
    
    

    </body>
</html>
