
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            Bayesian reconstruction of rapidly scanned mid-infrared optoacoustic signals enables fast, label-free chemical microscopy - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="AE532F4F8AF22A43052F4F000F436E48.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="sciadv">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12372899/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="Science Advances">
<meta name="citation_title" content="Bayesian reconstruction of rapidly scanned mid-infrared optoacoustic signals enables fast, label-free chemical microscopy">
<meta name="citation_author" content="Constantin Berger">
<meta name="citation_author_institution" content="Institute of Biological and Medical Imaging, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.">
<meta name="citation_author_institution" content="Institute of Computational Biology, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.">
<meta name="citation_author_institution" content="Chair of Biological Imaging, Central Institute for Translational Cancer Research (TranslaTUM), School of Medicine and Health and School of Computation, Information, and Technology, Technical University of Munich, Munich, Germany.">
<meta name="citation_author" content="Myeongseop Kim">
<meta name="citation_author_institution" content="Institute of Biological and Medical Imaging, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.">
<meta name="citation_author_institution" content="Chair of Biological Imaging, Central Institute for Translational Cancer Research (TranslaTUM), School of Medicine and Health and School of Computation, Information, and Technology, Technical University of Munich, Munich, Germany.">
<meta name="citation_author" content="Lukas Scheel-Platz">
<meta name="citation_author_institution" content="Institute of Biological and Medical Imaging, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.">
<meta name="citation_author_institution" content="Institute of Computational Biology, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.">
<meta name="citation_author_institution" content="Chair of Biological Imaging, Central Institute for Translational Cancer Research (TranslaTUM), School of Medicine and Health and School of Computation, Information, and Technology, Technical University of Munich, Munich, Germany.">
<meta name="citation_author_institution" content="Ludwig Maximilian University of Munich, Munich, Germany.">
<meta name="citation_author" content="Andreas Eigenberger">
<meta name="citation_author_institution" content="Department of Plastic, Hand, and Reconstructive Surgery, University Medical Center Regensburg, Regensburg, Germany.">
<meta name="citation_author" content="Lukas Prantl">
<meta name="citation_author_institution" content="Department of Plastic, Hand, and Reconstructive Surgery, University Medical Center Regensburg, Regensburg, Germany.">
<meta name="citation_author" content="Panhang Liu">
<meta name="citation_author_institution" content="Institute of Biological and Medical Imaging, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.">
<meta name="citation_author_institution" content="Chair of Biological Imaging, Central Institute for Translational Cancer Research (TranslaTUM), School of Medicine and Health and School of Computation, Information, and Technology, Technical University of Munich, Munich, Germany.">
<meta name="citation_author" content="Vipul Gujrati">
<meta name="citation_author_institution" content="Institute of Biological and Medical Imaging, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.">
<meta name="citation_author_institution" content="Chair of Biological Imaging, Central Institute for Translational Cancer Research (TranslaTUM), School of Medicine and Health and School of Computation, Information, and Technology, Technical University of Munich, Munich, Germany.">
<meta name="citation_author" content="Vasilis Ntziachristos">
<meta name="citation_author_institution" content="Institute of Biological and Medical Imaging, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.">
<meta name="citation_author_institution" content="Chair of Biological Imaging, Central Institute for Translational Cancer Research (TranslaTUM), School of Medicine and Health and School of Computation, Information, and Technology, Technical University of Munich, Munich, Germany.">
<meta name="citation_author_institution" content="Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich, Munich, Germany.">
<meta name="citation_author" content="Dominik Jüstel">
<meta name="citation_author_institution" content="Institute of Biological and Medical Imaging, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.">
<meta name="citation_author_institution" content="Institute of Computational Biology, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.">
<meta name="citation_author_institution" content="Chair of Biological Imaging, Central Institute for Translational Cancer Research (TranslaTUM), School of Medicine and Health and School of Computation, Information, and Technology, Technical University of Munich, Munich, Germany.">
<meta name="citation_author" content="Miguel A Pleitez">
<meta name="citation_author_institution" content="Institute of Biological and Medical Imaging, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.">
<meta name="citation_author_institution" content="Chair of Biological Imaging, Central Institute for Translational Cancer Research (TranslaTUM), School of Medicine and Health and School of Computation, Information, and Technology, Technical University of Munich, Munich, Germany.">
<meta name="citation_publication_date" content="2025 Aug 22">
<meta name="citation_volume" content="11">
<meta name="citation_issue" content="34">
<meta name="citation_firstpage" content="eadu7319">
<meta name="citation_doi" content="10.1126/sciadv.adu7319">
<meta name="citation_pmid" content="40845115">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12372899/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12372899/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12372899/pdf/sciadv.adu7319.pdf">
<meta name="description" content="Hyperspectral optoacoustic microscopy (OAM) enables obtaining images with label-free biomolecular contrast, offering excellent perspectives as a diagnostic tool to assess freshly excised and unprocessed biological samples. However, time-consuming ...">
<meta name="og:title" content="Bayesian reconstruction of rapidly scanned mid-infrared optoacoustic signals enables fast, label-free chemical microscopy">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="Hyperspectral optoacoustic microscopy (OAM) enables obtaining images with label-free biomolecular contrast, offering excellent perspectives as a diagnostic tool to assess freshly excised and unprocessed biological samples. However, time-consuming ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12372899/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12372899">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1126/sciadv.adu7319"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/sciadv.adu7319.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12372899%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12372899/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12372899/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12372899/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-sciadv.gif" alt="Science Advances logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to Science Advances" title="Link to Science Advances" shape="default" href="http://advances.sciencemag.org/" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">Sci Adv</button></div>. 2025 Aug 22;11(34):eadu7319. doi: <a href="https://doi.org/10.1126/sciadv.adu7319" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1126/sciadv.adu7319</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22Sci%20Adv%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sci%20Adv%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22Sci%20Adv%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22Sci%20Adv%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Bayesian reconstruction of rapidly scanned mid-infrared optoacoustic signals enables fast, label-free chemical microscopy</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Berger%20C%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Constantin Berger</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Constantin Berger</span></h3>
<div class="p">
<sup><sup>1</sup></sup>Institute of Biological and Medical Imaging, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.</div>
<div class="p">
<sup><sup>2</sup></sup>Institute of Computational Biology, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.</div>
<div class="p">
<sup><sup>3</sup></sup>Chair of Biological Imaging, Central Institute for Translational Cancer Research (TranslaTUM), School of Medicine and Health and School of Computation, Information, and Technology, Technical University of Munich, Munich, Germany.</div>
<div>Conceptualization, Formal analysis, Investigation, Methodology, Project administration, Software, Validation, Visualization, Writing - original draft, Writing - review &amp; editing</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Berger%20C%22%5BAuthor%5D" class="usa-link"><span class="name western">Constantin Berger</span></a>
</div>
</div>
<sup>1,</sup><sup>2,</sup><sup>3</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kim%20M%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Myeongseop Kim</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">Myeongseop Kim</span></h3>
<div class="p">
<sup><sup>1</sup></sup>Institute of Biological and Medical Imaging, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.</div>
<div class="p">
<sup><sup>3</sup></sup>Chair of Biological Imaging, Central Institute for Translational Cancer Research (TranslaTUM), School of Medicine and Health and School of Computation, Information, and Technology, Technical University of Munich, Munich, Germany.</div>
<div>Investigation, Validation, Writing - original draft, Writing - review &amp; editing</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kim%20M%22%5BAuthor%5D" class="usa-link"><span class="name western">Myeongseop Kim</span></a>
</div>
</div>
<sup>1,</sup><sup>3</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Scheel-Platz%20L%22%5BAuthor%5D" class="usa-link" aria-describedby="id3"><span class="name western">Lukas Scheel-Platz</span></a><div hidden="hidden" id="id3">
<h3><span class="name western">Lukas Scheel-Platz</span></h3>
<div class="p">
<sup><sup>1</sup></sup>Institute of Biological and Medical Imaging, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.</div>
<div class="p">
<sup><sup>2</sup></sup>Institute of Computational Biology, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.</div>
<div class="p">
<sup><sup>3</sup></sup>Chair of Biological Imaging, Central Institute for Translational Cancer Research (TranslaTUM), School of Medicine and Health and School of Computation, Information, and Technology, Technical University of Munich, Munich, Germany.</div>
<div class="p">
<sup><sup>4</sup></sup>Ludwig Maximilian University of Munich, Munich, Germany.</div>
<div>Conceptualization, Methodology, Software, Validation, Writing - original draft, Writing - review &amp; editing</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Scheel-Platz%20L%22%5BAuthor%5D" class="usa-link"><span class="name western">Lukas Scheel-Platz</span></a>
</div>
</div>
<sup>1,</sup><sup>2,</sup><sup>3,</sup><sup>4</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Eigenberger%20A%22%5BAuthor%5D" class="usa-link" aria-describedby="id4"><span class="name western">Andreas Eigenberger</span></a><div hidden="hidden" id="id4">
<h3><span class="name western">Andreas Eigenberger</span></h3>
<div class="p">
<sup><sup>5</sup></sup>Department of Plastic, Hand, and Reconstructive Surgery, University Medical Center Regensburg, Regensburg, Germany.</div>
<div>Resources, Writing - original draft</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Eigenberger%20A%22%5BAuthor%5D" class="usa-link"><span class="name western">Andreas Eigenberger</span></a>
</div>
</div>
<sup>5</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Prantl%20L%22%5BAuthor%5D" class="usa-link" aria-describedby="id5"><span class="name western">Lukas Prantl</span></a><div hidden="hidden" id="id5">
<h3><span class="name western">Lukas Prantl</span></h3>
<div class="p">
<sup><sup>5</sup></sup>Department of Plastic, Hand, and Reconstructive Surgery, University Medical Center Regensburg, Regensburg, Germany.</div>
<div>Resources, Writing - review &amp; editing</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Prantl%20L%22%5BAuthor%5D" class="usa-link"><span class="name western">Lukas Prantl</span></a>
</div>
</div>
<sup>5</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Liu%20P%22%5BAuthor%5D" class="usa-link" aria-describedby="id6"><span class="name western">Panhang Liu</span></a><div hidden="hidden" id="id6">
<h3><span class="name western">Panhang Liu</span></h3>
<div class="p">
<sup><sup>1</sup></sup>Institute of Biological and Medical Imaging, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.</div>
<div class="p">
<sup><sup>3</sup></sup>Chair of Biological Imaging, Central Institute for Translational Cancer Research (TranslaTUM), School of Medicine and Health and School of Computation, Information, and Technology, Technical University of Munich, Munich, Germany.</div>
<div>Writing - original draft</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Liu%20P%22%5BAuthor%5D" class="usa-link"><span class="name western">Panhang Liu</span></a>
</div>
</div>
<sup>1,</sup><sup>3</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Gujrati%20V%22%5BAuthor%5D" class="usa-link" aria-describedby="id7"><span class="name western">Vipul Gujrati</span></a><div hidden="hidden" id="id7">
<h3><span class="name western">Vipul Gujrati</span></h3>
<div class="p">
<sup><sup>1</sup></sup>Institute of Biological and Medical Imaging, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.</div>
<div class="p">
<sup><sup>3</sup></sup>Chair of Biological Imaging, Central Institute for Translational Cancer Research (TranslaTUM), School of Medicine and Health and School of Computation, Information, and Technology, Technical University of Munich, Munich, Germany.</div>
<div>Resources, Writing - review &amp; editing</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Gujrati%20V%22%5BAuthor%5D" class="usa-link"><span class="name western">Vipul Gujrati</span></a>
</div>
</div>
<sup>1,</sup><sup>3</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Ntziachristos%20V%22%5BAuthor%5D" class="usa-link" aria-describedby="id8"><span class="name western">Vasilis Ntziachristos</span></a><div hidden="hidden" id="id8">
<h3><span class="name western">Vasilis Ntziachristos</span></h3>
<div class="p">
<sup><sup>1</sup></sup>Institute of Biological and Medical Imaging, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.</div>
<div class="p">
<sup><sup>3</sup></sup>Chair of Biological Imaging, Central Institute for Translational Cancer Research (TranslaTUM), School of Medicine and Health and School of Computation, Information, and Technology, Technical University of Munich, Munich, Germany.</div>
<div class="p">
<sup><sup>6</sup></sup>Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich, Munich, Germany.</div>
<div>Conceptualization, Funding acquisition, Resources</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Ntziachristos%20V%22%5BAuthor%5D" class="usa-link"><span class="name western">Vasilis Ntziachristos</span></a>
</div>
</div>
<sup>1,</sup><sup>3,</sup><sup>6</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22J%C3%BCstel%20D%22%5BAuthor%5D" class="usa-link" aria-describedby="id9"><span class="name western">Dominik Jüstel</span></a><div hidden="hidden" id="id9">
<h3><span class="name western">Dominik Jüstel</span></h3>
<div class="p">
<sup><sup>1</sup></sup>Institute of Biological and Medical Imaging, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.</div>
<div class="p">
<sup><sup>2</sup></sup>Institute of Computational Biology, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.</div>
<div class="p">
<sup><sup>3</sup></sup>Chair of Biological Imaging, Central Institute for Translational Cancer Research (TranslaTUM), School of Medicine and Health and School of Computation, Information, and Technology, Technical University of Munich, Munich, Germany.</div>
<div>Conceptualization, Funding acquisition, Supervision, Visualization, Writing - review &amp; editing</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22J%C3%BCstel%20D%22%5BAuthor%5D" class="usa-link"><span class="name western">Dominik Jüstel</span></a>
</div>
</div>
<sup>1,</sup><sup>2,</sup><sup>3,</sup><sup>*</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Pleitez%20MA%22%5BAuthor%5D" class="usa-link" aria-describedby="id10"><span class="name western">Miguel A Pleitez</span></a><div hidden="hidden" id="id10">
<h3><span class="name western">Miguel A Pleitez</span></h3>
<div class="p">
<sup><sup>1</sup></sup>Institute of Biological and Medical Imaging, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.</div>
<div class="p">
<sup><sup>3</sup></sup>Chair of Biological Imaging, Central Institute for Translational Cancer Research (TranslaTUM), School of Medicine and Health and School of Computation, Information, and Technology, Technical University of Munich, Munich, Germany.</div>
<div>Conceptualization, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Resources, Supervision, Validation, Visualization, Writing - original draft, Writing - review &amp; editing</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Pleitez%20MA%22%5BAuthor%5D" class="usa-link"><span class="name western">Miguel A Pleitez</span></a>
</div>
</div>
<sup>1,</sup><sup>3,</sup><sup>*</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="aff1">
<sup><sup>1</sup></sup>Institute of Biological and Medical Imaging, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.</div>
<div id="aff2">
<sup><sup>2</sup></sup>Institute of Computational Biology, Bioengineering Center, Helmholtz Zentrum München, Neuherberg, Germany.</div>
<div id="aff3">
<sup><sup>3</sup></sup>Chair of Biological Imaging, Central Institute for Translational Cancer Research (TranslaTUM), School of Medicine and Health and School of Computation, Information, and Technology, Technical University of Munich, Munich, Germany.</div>
<div id="aff4">
<sup><sup>4</sup></sup>Ludwig Maximilian University of Munich, Munich, Germany.</div>
<div id="aff5">
<sup><sup>5</sup></sup>Department of Plastic, Hand, and Reconstructive Surgery, University Medical Center Regensburg, Regensburg, Germany.</div>
<div id="aff6">
<sup><sup>6</sup></sup>Munich Institute of Robotics and Machine Intelligence (MIRMI), Technical University of Munich, Munich, Germany.</div>
<div class="author-notes p"><div class="fn" id="cor1">
<sup>*</sup><p class="display-inline">Corresponding author. Email: <span>dominik.juestel@tum.de</span> (D.J.); <span>miguel.pleitez@tum.de</span> (M.A.P.)</p>
</div></div>
<h4 class="font-secondary">Roles</h4>
<div class="p">
<strong class="contrib"><span class="name western">Constantin Berger</span></strong>: <span class="role">Conceptualization, Formal analysis, Investigation, Methodology, Project administration, Software, Validation, Visualization, Writing - original draft, Writing - review &amp; editing</span>
</div>
<div>
<strong class="contrib"><span class="name western">Myeongseop Kim</span></strong>: <span class="role">Investigation, Validation, Writing - original draft, Writing - review &amp; editing</span>
</div>
<div>
<strong class="contrib"><span class="name western">Lukas Scheel-Platz</span></strong>: <span class="role">Conceptualization, Methodology, Software, Validation, Writing - original draft, Writing - review &amp; editing</span>
</div>
<div>
<strong class="contrib"><span class="name western">Andreas Eigenberger</span></strong>: <span class="role">Resources, Writing - original draft</span>
</div>
<div>
<strong class="contrib"><span class="name western">Lukas Prantl</span></strong>: <span class="role">Resources, Writing - review &amp; editing</span>
</div>
<div>
<strong class="contrib"><span class="name western">Panhang Liu</span></strong>: <span class="role">Writing - original draft</span>
</div>
<div>
<strong class="contrib"><span class="name western">Vipul Gujrati</span></strong>: <span class="role">Resources, Writing - review &amp; editing</span>
</div>
<div>
<strong class="contrib"><span class="name western">Vasilis Ntziachristos</span></strong>: <span class="role">Conceptualization, Funding acquisition, Resources</span>
</div>
<div>
<strong class="contrib"><span class="name western">Dominik Jüstel</span></strong>: <span class="role">Conceptualization, Funding acquisition, Supervision, Visualization, Writing - review &amp; editing</span>
</div>
<div>
<strong class="contrib"><span class="name western">Miguel A Pleitez</span></strong>: <span class="role">Conceptualization, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Resources, Supervision, Validation, Visualization, Writing - original draft, Writing - review &amp; editing</span>
</div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2024 Nov 19; Accepted 2025 Jul 22; Collection date 2025 Aug 22.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>Copyright © 2025 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works. Distributed under a Creative Commons Attribution NonCommercial License 4.0 (CC BY-NC).</div>
<p>This is an open-access article distributed under the terms of the <a href="https://creativecommons.org/licenses/by-nc/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Creative Commons Attribution-NonCommercial license</a>, which permits use, distribution, and reproduction in any medium, so long as the resultant use is <strong>not</strong> for commercial advantage and provided the original work is properly cited.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12372899  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40845115/" class="usa-link">40845115</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="abstract1"><h2>Abstract</h2>
<p>Hyperspectral optoacoustic microscopy (OAM) enables obtaining images with label-free biomolecular contrast, offering excellent perspectives as a diagnostic tool to assess freshly excised and unprocessed biological samples. However, time-consuming raster scanning image formation currently limits the translation potential of OAM into the clinical setting, for instance, in intraoperative histopathological assessments, where micrographs of excised tissue need to be taken within a few minutes for fast clinical decision-making. Here, we present a non–data-driven computational framework tailored to enable fast OAM by rapid data acquisition and model-based image reconstruction, termed Bayesian raster-computed optoacoustic microscopy (BayROM). Unlike data-driven approaches, BayROM does not require training datasets, but instead, it uses probabilistic model-based reconstruction to facilitate fast high-resolution imaging. We show that BayROM enables acquiring micrographs 10 times faster on average than conventional raster scanning microscopy and provides sufficient image quality to facilitate the intraoperative histological assessment of processed fat grafts for autologous fat transfer.</p></section><section class="abstract" id="abstract2"><hr class="headless">
<p>Bayesian raster-computed optoacoustic microscopy facilitates rapid intraoperative assessment of unprocessed biological samples.</p></section><section id="sec1"><h2 class="pmc_sec_title">INTRODUCTION</h2>
<p>Intraoperative histopathological examinations are crucial for precise surgical decision-making, for instance, in tumor margin analysis (<a href="#R1" class="usa-link" aria-describedby="R1"><em>1</em></a>). The clinically established workflow for histological assessment usually consists of immunohistochemical or hematoxylin and eosin stains applied to excised tissue samples, followed by an examination via bright-field microscopy (<a href="#R2" class="usa-link" aria-describedby="R2"><em>2</em></a>). Tissue staining uncovers biomolecular features required for histopathological examinations, such as tumor margin assessments or quality guidance for autologous fat transfer. Autologous fat transfer is an innovative therapeutic procedure that is increasingly used in plastic and aesthetic medicine, primarily aimed at promoting tissue regeneration and restoring volume. In addition to its regenerative applications, this technique plays a crucial role in breast reconstruction following tumor removal, where transplanted autologous fat provides both aesthetic and functional benefits. Specially mechanically processed fat graft, called cell-enriched lipotransfer (CELT or CELT<sup>plus</sup>), shows strong capabilities to improve tissue regeneration and rejuvenation (<a href="#R3" class="usa-link" aria-describedby="R3"><em>3</em></a>). However, the enrichment process currently lacks an intraoperative imaging step that can provide histological metrics on the processed fat graft as a predictive marker for therapeutic success and to avoid complications. Conventional workflows for histological assessments are currently insufficient to analyze molecular and morphological compositions of freshly excised tissues in real-time due to the time-consuming and laborious preparation steps, which can delay or hinder surgical decision-making (<a href="#R4" class="usa-link" aria-describedby="R4"><em>4</em></a>). In addition, while current fast histology techniques used in, for instance, intraoperative tumor margin assessment are rapid (~10 min), they often come with the risk of inaccuracies, as they lack the necessary molecular specificity of conventional histology examinations (<a href="#R5" class="usa-link" aria-describedby="R5"><em>5</em></a>).</p>
<p>As an alternative to conventional histology, label-free optoacoustic microscopy (OAM) has been proposed as a method for rapid intraoperative histology due to its ability to obtain intrinsic molecular contrast that enables avoiding the tissue preparation steps usually required for exogenous staining (<a href="#R6" class="usa-link" aria-describedby="R6"><em>6</em></a>, <a href="#R7" class="usa-link" aria-describedby="R7"><em>7</em></a>). In particular, optoacoustic hyperspectral imaging, i.e., sequential imaging at multiple excitation wavelengths over a spectral range, is key for tissue classification based on spectral hallmarks. However, although label-free OAM for histological examination saves time in tissue preparation, acquiring optoacoustic micrographs is often more time consuming than routinely used bright-field microscopy as image formation in many OAM systems is achieved by point-by-point raster scanning. Although technologies for wide-field OAM were proposed to bypass the need for time-consuming raster scanning, these methods often suffer from poor spatial resolution and shallow imaging depth (<a href="#R8" class="usa-link" aria-describedby="R8"><em>8</em></a>). Low imaging speed is one of the major limiting factors of OAM toward its implementation as an intraoperative histopathological assessment procedure, especially for hyperspectral imaging where time cost scales linearly with the number of excitation wave numbers acquired (<a href="#R4" class="usa-link" aria-describedby="R4"><em>4</em></a>). Hyperspectral optoacoustic image formation with fast data acquisition, i.e., within a time range of a few minutes, is crucial to allow for faster surgical decision-making than conventional tissue staining methods (<a href="#R9" class="usa-link" aria-describedby="R9"><em>9</em></a>).</p>
<p>To facilitate fast label-free OAM, several hardware-based methods have been developed, for instance, optoacoustic microtomography (<a href="#R10" class="usa-link" aria-describedby="R10"><em>10</em></a>), which allows the acquisition of numerous wide-field image volumes per second. Nevertheless, optoacoustic microtomography leads to complex optical forward problems, making image formation more prone to artifacts compared to OAM with single-spot illumination combined with raster scanning. Further hardware-based solutions include accelerated raster scanning by optical setups involving voice coil stages (<a href="#R11" class="usa-link" aria-describedby="R11"><em>11</em></a>), microelectromechanical systems (<a href="#R7" class="usa-link" aria-describedby="R7"><em>7</em></a>, <a href="#R12" class="usa-link" aria-describedby="R12"><em>12</em></a>, <a href="#R13" class="usa-link" aria-describedby="R13"><em>13</em></a>), polygonal mirror scanners (<a href="#R14" class="usa-link" aria-describedby="R14"><em>14</em></a>), and galvanometer scanners (<a href="#R15" class="usa-link" aria-describedby="R15"><em>15</em></a>). However, in the context of raster scanning OAM, hardware-based solutions cannot be applied without substantial limitations, such as imaging artifacts that originate, for instance, from narrow field-of-views (FOVs). Another common limitation of hardware-based strategies for accelerating imaging speed in OAM is the sensitivity variation caused by the misalignment of the excitation beam with the detection area of the ultrasound transducer typically used for OA detection. In particular, confocal alignment of the excitation laser beam with the transducer is of special relevance in mid-infrared (mid-IR) OAM and spectroscopy (<a href="#R16" class="usa-link" aria-describedby="R16"><em>16</em></a>), where reflective objectives are preferred against diffractive optics to avoid achromatic aberration due to the wide spectral range detected (for instance, between 2850 and 1000 cm<sup>−1</sup>). The use of reflective objectives in mid-IR OAM renders using, for instance, galvanometer scanning ineffective because of the narrow FOV that can be imaged at each location, requiring mosaicking techniques and postprocessing correction of the abovementioned transducer’s sensitivity field and laser beam excitation misalignment (<a href="#R17" class="usa-link" aria-describedby="R17"><em>17</em></a>). However, the optical and acoustic properties of mid-IR OAM in terms of signal-to-noise ratio (SNR), resolution, and the homogenous transducer sensitivity field are crucial for enabling the assessment of freshly excised and unprocessed biological samples. Hence, an alternative method for increased imaging speed of raster scanning OAM, which can overcome the limitations of existing hardware-based solutions, is required to advance the field of fast intraoperative histology.</p>
<p>A strategy to enhance imaging speed while maintaining the advantages of single-point raster scanning of OAM systems, such as mid-IR OAM, is the use of rapid raster scanning in combination with computational methods. Rapid raster scanning can be achieved by (i) sparse scanning, i.e., acquiring only a fraction of all pixel intensities, and (ii) low averaging of optoacoustic signals per pixel and consequently reconstructing full images based on sparse and noisy data. To reconstruct full images based on sparse data, i.e., compensate for the inherent information loss, data-driven methods involving machine learning (ML) and deep learning (DL) have been applied (<a href="#R18" class="usa-link" aria-describedby="R18"><em>18</em></a>–<a href="#R21" class="usa-link" aria-describedby="R21"><em>21</em></a>). ML and especially DL are effective tools in the realm of image processing and enhancement, including denoising (<a href="#R22" class="usa-link" aria-describedby="R22"><em>22</em></a>–<a href="#R25" class="usa-link" aria-describedby="R25"><em>25</em></a>). However, in learning-based methods, the model architectures often used operate as black-box models and do not provide the necessary transparency to ensure artifact-free images, particularly for out-of-distribution data, i.e., sample types that were not covered by the training data (<a href="#R26" class="usa-link" aria-describedby="R26"><em>26</em></a>–<a href="#R29" class="usa-link" aria-describedby="R29"><em>29</em></a>). To mitigate the risk of imaging artifacts for a broad range of sample types, data-driven methods would require large amounts of training data, which are often unavailable or impractical to collect in OAM. Thus, although data-driven computational methods have shown promising capabilities for image reconstruction from incomplete data, they cannot ensure artifact-free images for a broad range of sample types due to the lack of big training data in OAM. An alternative to data-driven methods includes, for instance, compressed sensing techniques, where prior information about the sample is integrated via sparsity assumptions (<a href="#R30" class="usa-link" aria-describedby="R30"><em>30</em></a>, <a href="#R31" class="usa-link" aria-describedby="R31"><em>31</em></a>). Compressed sensing has, for example, been used in the realm of electron microscopy to reduce electron doses by sparse imaging (<a href="#R32" class="usa-link" aria-describedby="R32"><em>32</em></a>, <a href="#R33" class="usa-link" aria-describedby="R33"><em>33</em></a>). Another non–data-driven method that has been established for electron microscopy is beta process factor analysis (BPFA) (<a href="#R34" class="usa-link" aria-describedby="R34"><em>34</em></a>). BPFA is a dictionary-learning method that can, for instance, be used for image reconstruction from sparse data. Dictionary-learning methods constitute a group of techniques that have furthermore been used for image denoising without requiring noise estimates (<a href="#R35" class="usa-link" aria-describedby="R35"><em>35</em></a>). Because of a lack of accuracy combined with the high computational time required for dictionary-learning approaches, further methods, including regularized least-squares image reconstruction, were proposed (<a href="#R36" class="usa-link" aria-describedby="R36"><em>36</em></a>). However, neither regularized least-squares methods, dictionary-learning, nor compressed sensing methods usually provide parameters for uncertainty quantification and, thus, similarly to data-driven methods, cannot deliver a quality assessment for reconstructed images to ensure artifact-free imaging. Furthermore, the previously summarized methods address either image reconstruction from sparsely sampled data or image denoising but mostly do not target both at the same time. Hence, a transparent alternative for computational reconstruction and denoising for rapid raster-scanned OAM data, including a quality-check readout, is required to push the boundaries of label-free imaging toward its integration into intraoperative workflows.</p>
<p>We hypothesized that by implementing rapid data acquisition in combination with model-based image reconstruction, we could accelerate the imaging speed of OAM over conventional raster scanning. In addition, by applying model-based image reconstruction, we could circumvent the limitations imposed for learning-based methods, i.e., the need for big data and/or the nontransparency of neural networks. For this purpose, we developed a computational imaging method termed Bayesian raster-computed optoacoustic microscopy (BayROM). BayROM facilitates the reconstruction of images based on rapid and thus incomplete raster scanning data, while not being required to train a model, and thus bypasses the need for large amounts of training data in OAM. Instead of implicitly learning priors via a dataset, BayROM uses an explicit prior model resembling knowledge about the imaged specimen. To maintain similar image quality as in full raster scanning, BayROM reconstructs images after rapid data acquisition supported by a parameterizable model, including optomechanical system properties by means of variational Bayes, and thereby achieves a 10-fold increase in imaging speed compared to conventional raster scanning in OAM.</p>
<p>Here, we showcase BayROM in the context of fast label-free biomolecular imaging by mid-IR hyperspectral microscopy, demonstrating its capability to reduce imaging time from the timescale of hours to only a few minutes. We validated BayROM’s ability for fast tissue imaging on several mouse organ tissues as well as synthetic phantoms. Moreover, to demonstrate the use of BayROM for clinical practice, we investigated its capability to assess fresh fat grafts for autologous fat transfer, where a fast molecular imaging modality could substantially contribute to further improving treatment outcomes and reducing the need for follow-up surgeries. Here, we show that BayROM can provide high-resolution molecular images within only a few minutes, enabling the differentiation between CELT<sup>plus</sup> and nanofat. Nanofat is an enhanced fat graft with insufficiently removed released lipids that can cause complications, including oil cysts (<a href="#R37" class="usa-link" aria-describedby="R37"><em>37</em></a>). While conventional histology methods fail to provide such assessment of fat grafts intraoperatively, we demonstrate the potential of BayROM for intraoperative decision-making in plastic surgery to potentially improve therapeutic responses and avoid complications and consequent follow-up surgeries.</p></section><section id="sec2"><h2 class="pmc_sec_title">RESULTS</h2>
<section id="sec3"><h3 class="pmc_sec_title">Working principle of BayROM</h3>
<p><a href="#F1" class="usa-link">Figure 1</a> graphically illustrates the working principle of BayROM as compared to conventional raster scanning in OAM. Raster scanning OAM measures the optoacoustic signal intensity in each pixel location to compose an image. BayROM increases imaging speed in OAM by systematically skipping raster scanning lines during optoacoustic signal acquisition and compensates for the missing information using Bayesian image reconstruction. Therein, a prior model constrains the reconstruction of unscanned areas to plausible values based on the scanned areas. Our knowledge of the measurement process (encoded in the forward model) and the measurement noise allows us to calculate to what degree a candidate image is compatible with the observed data. Furthermore, a priori knowledge about the imaged specimen is included in the form of a generative prior model, which statistically describes the structural properties of images in the harmonic/Fourier domain (see Materials and Methods). On the basis of the prior model and likelihood, we can express the plausibility of an image given the acquired data using Bayes’ theorem. Bayes’ theorem allows assigning a plausibility score (posterior probability) from 0 (the image is incompatible with the data, prior knowledge, or both) to 1 (only this image is compatible with the prior knowledge and the observed data). On the basis of the mean and standard deviation of the posterior probability distribution, we can generate image reconstructions, including pixel-wise uncertainty estimates. We approximate the posterior distribution using the metric Gaussian variational inference (MGVI) algorithm (<a href="#R38" class="usa-link" aria-describedby="R38"><em>38</em></a>), which generates a set of posterior samples. We subsequently calculate posterior means and standard deviations based on the posterior samples. The reconstructed image is derived from the posterior mean, while the posterior standard deviation gives a lower bound of the pixel-wise uncertainty in the reconstruction, which can be used to obtain a quality control metric of reconstructed images. More details on the theoretic principle of BayROM are given in Materials and Methods. Uncertainty-based quality control facilitates the evaluation of reconstructions without the need to compare to a usually unavailable ground truth (GT) measurement. Therefore, we use the mean relative standard deviation (MRSD) of the posterior distribution as a metric to reflect the reconstruction uncertainty. Using the MRSD, our Bayesian imaging framework allows for quality-controlled image reconstruction based on rapid raster scanning to enable fast optoacoustic imaging.</p>
<figure class="fig xbox font-sm" id="F1"><h4 class="obj_head">Fig. 1. Fast label-free imaging using rapid raster scanning and Bayesian image reconstruction.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12372899_sciadv.adu7319-f1.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/0560/12372899/5ac9aadaddf1/sciadv.adu7319-f1.jpg" loading="lazy" height="919" width="750" alt="Fig. 1."></a></p>
<div class="p text-right font-secondary"><a href="figure/F1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>(<strong>A</strong>) OAM workflow. Raster-scanning OAM enables label-free imaging of unprocessed, freshly excised tissue samples. However, raster scanning is a tedious procedure that prevents fast intraoperative decision-making due to time-consuming data acquisition. (<strong>B</strong>) Workflow of Bayesian raster computed optoacoustic microscopy (BayROM). Rapid raster scanning can be applied to decrease the data acquisition time by a factor of 10. Image reconstruction is required to obtain high-resolution micrographs based on the compressed data. (<strong>C</strong>) Image reconstruction workflow. The probabilistic reconstruction framework creates plausible images given the reduced but rapidly acquired data. The plausibility of image candidates can be assessed using the Bayesian posterior probability <em>p</em>(<strong>i|d</strong>), which is proportional to the product between the likelihood <em>p</em>(<strong>d|i</strong>) and the prior <em>p</em>(<strong>i</strong>). The likelihood evaluates the compatibility of image candidates with observed data given by the forward model. The prior model (correlated field prior) compensates for the information loss due to rapid scanning. The mean of the posterior approximated using MGVI serves as the reconstructed image, while the approximated posterior variance provides a metric for quality control.</p></figcaption></figure></section><section id="sec4"><h3 class="pmc_sec_title">Imaging characterization and evaluation in synthetic samples</h3>
<p>First, we characterized BayROM’s accuracy by comparing BayROM reconstructed micrographs of a synthetic test target (carbon tape; see Materials and Methods for details) with full raster scanning images, used as GT, of the same sample. <a href="#F2" class="usa-link">Figure 2A</a> shows GT and corresponding BayROM reconstructed micrographs (2 mm–by–2 mm FOV and 5-μm pixel size) for the test target at 2850 cm<sup>−1</sup> excitation. While full raster scanning (GT) required 23.43 min for acquisition, data acquisition with 92.5% data reduction, i.e., only 7.5% of the amount of data needed for full raster scanning, required only 2.15 min, thus achieving an ~10-fold speedup with an excellent reconstruction accuracy as determined by a structural similarity index measure (SSIM) of 0.978 between GT and BayROM reconstructed micrographs. <a href="#F2" class="usa-link">Figure 2A</a> brings more details on the reconstruction results, including a back projection image shown to visualize the usable information contained in the rapidly acquired data (see <a href="#F2" class="usa-link">Fig. 2B</a>). Furthermore, <a href="#F2" class="usa-link">Fig. 2A</a> exhibits the posterior distribution represented by the posterior samples, posterior mean, and posterior standard deviation. The pattern of the posterior standard deviation follows the sample structure, which reflects localization uncertainties related to the point spread function (PSF). Such localization uncertainties can mainly be found at sharp intensity edges since the PSF leads to smoothed scanning data that represent such edges and thus cause uncertainties in their reconstruction. In addition to quantitative assessment of the reconstruction accuracy using the SSIM, <a href="#F2" class="usa-link">Fig. 2C</a> exhibits a qualitative comparison using overlay and cross-sectional intensity plots with no noticeable deviations, confirming accurate reconstruction. <a href="#F2" class="usa-link">Figure 2D</a> shows that the reconstruction intensities (i.e., the values of the micrograph after reconstruction) cover the full dynamic range of the GT and follow an almost linear power-law relationship with the GT values, which is important for quantitative imaging where contrast levels in a micrograph indicate optical absorption of the sample at a given wave number. Furthermore, <a href="#F2" class="usa-link">Fig. 2E</a> visualizes the distribution of the pixel-wise relative standard deviation (RSD), i.e., the ratios between the posterior standard deviation and the posterior mean for all pixels in the image. The overall uncertainty given by the MRSD amounts to 4.7% and thus indicates high confidence in the algorithm to reconstruct the images.</p>
<figure class="fig xbox font-sm" id="F2"><h4 class="obj_head">Fig. 2. Reconstruction analysis and characterization on a test phantom.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12372899_sciadv.adu7319-f2.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/0560/12372899/f09882bd628b/sciadv.adu7319-f2.jpg" loading="lazy" height="582" width="780" alt="Fig. 2."></a></p>
<div class="p text-right font-secondary"><a href="figure/F2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>(<strong>A</strong>) Visual comparison of back-projected data (BP), reconstruction (RC), and ground truth (GT). The back projection shows a horizontal line pattern, which originates from the data reduction. The SSIM between reconstruction and GT is 0.978, while the root mean square error (RMSE) and the peak signal-to-noise ratio (PSNR) between GT and reconstruction are 10.21 μV and 19.91 dB, respectively. (<strong>B</strong>) Visualization of the posterior distribution. The posterior mean and variance are obtained based on a pixel-wise assessment of the posterior samples. The posterior standard deviation shows a horizontal line pattern, which reflects higher uncertainties in skipped lines due to the sparse data acquisition and increased uncertainty on the boundaries of tissue structures due to PSF-related localization uncertainty. (<strong>C</strong>) Overlay of reconstruction and GT. The overlay as well as the cross-sectional line plots in both the <em>x</em> and <em>y</em> directions confirm an almost perfect reconstruction of the GT. (<strong>D</strong>) Intensity comparison between reconstruction and GT. The distribution of intensities in the GT image versus the reconstructed image is well aligned on the centerline, meaning that there is negligibly low bias in the intensity profile of the reconstruction. MAE, mean absolute error. (<strong>E</strong>) Histogram of the pixel-wise RSD. The MRSD suggests an average reconstruction uncertainty of 4.7%. (<strong>F</strong>) Data reduction analysis. A change in the level of data reduction results in a similar mean of the pixel-wise error between reconstruction and GT. However, the error distribution gets expanded, as indicated by the bars. An overall data reduction level of 92.5% was used to generate the results shown in (A) to (E).</p></figcaption></figure><p>Next, we studied the effects of varying data reduction parameters on the reconstruction quality to determine a suitable configuration for optimal image quality and imaging speedup. The data reduction is mainly determined by the sparsity parameter, which describes how many raster lines are skipped to increase the data acquisition speed. The data acquisition speed scales linearly with the level of sparsity, i.e., if half of the raster lines are being skipped, then data acquisition will be twice as fast. To generate the results shown in <a href="#F2" class="usa-link">Fig. 2 (A to E)</a>, we skipped three of four raster lines compared to full scanning, i.e., 75% sparsity. With the given sparsity levels, the distances between the raster lines remain smaller than the imaged structures, such that the relevant structural information of the imaged sample is still captured while the scanning speed is increased. The sparsity of 75% leads to an overall data reduction of 92.5%, since, in addition to sparsity, we decreased the averaging level per pixel compared to full raster scanning. High averaging per pixel causes slow stage movements along the imaged raster lines, and, thus, we decreased the averaging level so that the stage could operate at maximum speed. To study the effects of changing the number of skipped lines, we analyzed sparsity levels of 50% (every second raster line imaged), 75% (every fourth raster line imaged), and 87.5% (every eighth line skipped), which lead to overall data reduction levels of 85%, 92.5%, and 96.6%. The speedup resulting from the rapid data acquisition depends on the level of data reduction and increases with increasing data reduction. At the same time, image quality decreases with increasing data reduction levels. We compared the reconstruction qualities corresponding to data reduction levels of 85%, 92.5%, and 96.6%, leading to acquisition speedup factors of ~5, 10, and 20, respectively. <a href="#F2" class="usa-link">Figure 2F</a> visualizes the error distributions of the reconstructions, referring to the pixel-wise absolute errors between reconstructions and GT, corresponding to each data reduction level. The analysis of the reconstruction error distribution with respect to the data reduction level shows that the mean reconstruction error remains similar between the compared data reduction levels. However, the maximum reconstruction errors increase notably with increasing data reduction. In general, the choice of a data reduction level and, thus, the resulting speedup constitutes a trade-off in image quality and imaging speed that strongly depends on the application and thus needs to be seen as a parameter of BayROM and chosen accordingly. The results displayed in <a href="#F2" class="usa-link">Fig. 2</a> demonstrate the capabilities of BayROM to accurately reconstruct images based on rapid data acquisition under consideration of varying data reduction parameters and inherent imaging speedups.</p>
<p>To further characterize the image enhancement capabilities of the reconstruction mechanism, we analyzed BayROM’s resolution along with the SNR in reconstructed micrographs. Figure S1 (A to E) exhibits the estimated resolution of BayROM. It can be observed that the resolution of full raster scanning micrographs is, on average, 3.1 to 4.0 μm, while for BayROM, the estimated resolution is, on average, 4.5 to 5.6 μm. Furthermore, BayROM shows a lower resolution in the sparsely sampled axis, as indicated by the high variance of resolution estimates compared to the densely sampled axis. BayROM’s overall resolution is 0.5 to 2.5 μm lower than full raster scanning because of the regularization effect of the reconstruction mechanism. Although regularization causes a slightly decreased resolution, it enables denoising the reduced scanning data, i.e., maintains high SNR in the reconstructions despite noisy data due to rapid scanning. To demonstrate the denoising capabilities of BayROM, we analyzed the SNR of optoacoustic signals before and after image reconstruction. Figure S1 (F and G) shows that BayROM’s data SNR, i.e., the SNR of the acquired optoacoustic intensities per pixel, is significantly lower, while its image SNR, i.e., the SNR of the pixel intensities after image reconstruction, is slightly higher than for the case of full raster scanning. With BayROM’s image SNR of 53 compared to 48 for full raster scanning, we can confirm that BayROM not only maintains but also slightly increases the image SNR compared to full scanning despite substantially more noise due to less averaging per pixel. Although we confirmed that BayROM has only a slightly decreased resolution compared to full scanning and shows promising denoising capabilities, the analysis could potentially differ when being examined under different conditions, i.e., different data reduction settings, a larger FOV, or a more heterogeneous sample.</p></section><section id="sec5"><h3 class="pmc_sec_title">Fast hyperspectral imaging of unprocessed white adipose tissue</h3>
<p>To demonstrate the capabilities of BayROM for fast imaging of biological specimens, we assessed the imaging speed as well as the reconstruction accuracy of images obtained for white adipose tissue (WAT) excised from mice at multiple excitation wave numbers (i.e., at multiple contrast channels). Specifically, we imaged fixed epididymal WAT taken from Friend leukemia virus B mice for an FOV of 1 mm by 1 mm and a pixel size of 2.5 μm at selected wave numbers, including 2856 and 1550 cm<sup>−1</sup>, which provide mainly contrast for lipids and proteins, respectively. <a href="#F3" class="usa-link">Figure 3 (A to F)</a> shows more details about the imaging performance, including an overlay of the reconstructions for each channel compared with the corresponding GTs. <a href="#F3" class="usa-link">Figure 3C</a> shows cross-sectional intensity plots of the GT and reconstructed image in both the <em>x</em> and <em>y</em> directions, demonstrating accurate reconstruction. <a href="#F3" class="usa-link">Figure 3D</a> shows the GT and reconstruction intensity values of all excitation wave numbers in a scatterplot, indicating no noticeable biases, thus suggesting linear behavior between GT and reconstructed pixel intensities in the entire value range. For an overall data reduction of 92.5%, i.e., three of four raster lines skipped, BayROM achieves ~10 times faster data acquisition while maintaining high image quality expressed by an SSIM of 0.950 by comparison with the GT. Similar to the characterization based on the carbon sample, we analyzed different data reduction levels, i.e., 85%, 92.5%, and 96.6%, to assess their corresponding performances. <a href="#F3" class="usa-link">Figure 3 (E and F)</a> shows reconstructed hyperspectral images of gonadal WAT imaged in an FOV of 1 mm by 1 mm with a pixel size of 2.5 μm. While all data reduction levels lead to SSIMs above 0.8, the data reduction of 96.6% shows that the structures of the adipocytes are becoming less recognizable in some parts of the image (SSIM of 0.805). While the 85% data reduction results in the highest SSIM value of 0.950, only a speedup factor of ~5 was achieved. Thus, imaging at a data reduction level of 92.5% offers, with a speedup factor of ~10 and an SSIM of 0.934, the best compromise between imaging speed and minimal deviations from GT. In this way, BayROM imaging enables higher information throughputs than full raster scanning, i.e., imaging more channels over time and thus facilitating fast hyperspectral imaging, i.e., the sequential image acquisition at different excitation wave numbers, which is specifically relevant to assess the biomolecular composition of imaged specimens.</p>
<figure class="fig xbox font-sm" id="F3"><h4 class="obj_head">Fig. 3. Validation of BayROM based on biological samples.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12372899_sciadv.adu7319-f3.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/0560/12372899/4fdd18039328/sciadv.adu7319-f3.jpg" loading="lazy" height="916" width="752" alt="Fig. 3."></a></p>
<div class="p text-right font-secondary"><a href="figure/F3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>(<strong>A</strong>) Comparison of hyperspectral images of WAT using full raster scanning (GT) and BayROM (RC). The average RMSE and the average PSNR between GT and BayROM are 12.44 μV and 35.1 dB. au, arbitrary unit; h, hours. (<strong>B</strong>) Comparison of zoomed-in areas between GT and BayROM. (<strong>C</strong>) Comparison of reconstruction and GT using cross-sectional intensity plots in the <em>x</em> and <em>y</em> directions for each excitation wave number. (<strong>D</strong>) Quantitative comparison of reconstruction and GT with indicated MAE. (<strong>E</strong>) Comparison of data reduction levels. A data reduction level of 92.5% enables high reconstruction quality and ~10 times faster data acquisition. (<strong>F</strong>) Comparison of pixel-wise errors for data reduction levels shown in (E). (<strong>G</strong> and <strong>H</strong>) Image comparisons of large FOVs, i.e., 5 mm by 5 mm, and small FOVs, i.e., 1 mm by 1 mm, of mouse muscle, and pancreatic tissues imaged using full raster scanning (GT) and BayROM (92.5% data reduction). For the muscle tissue scans, the average RMSE and PSNR between GT and BayROM are 11.91 μV and 32.96 dB for the large FOVs, and 6.836 μV and 34.04 dB for the small FOVs. For the pancreatic tissue scans, the average RMSE and the average PSNR between GT and BayROM are 34.42 μV and 28.12 dB for the large FOVs, and 15.79 μV and 33.02 dB for the small FOVs. (<strong>I</strong> and <strong>J</strong>) Image comparisons of large FOVs, i.e., 5 mm by 5 mm, of mouse liver and kidney tissues imaged using full raster scanning (GT) and BayROM. For the liver tissue scans, the average RMSE and the average PSNR between GT and BayROM are 8.304 μV and 31.24 dB. For the kidney tissue scans, the average RMSE and the average PSNR between GT and BayROM are 5.853 μV and 36.89 dB.</p></figcaption></figure><p>Having achieved the ability to acquire images 10 times faster than with conventional raster scanning, we applied BayROM for hyperspectral imaging. This was demonstrated by sequential raster-scanning a WAT sample for an FOV of 1 mm by 1 mm and 5-μm pixel size at 80 different excitation wave numbers in two spectral ranges covering lipid (2800 to 2925 cm<sup>−1</sup>) and protein contrast (1500 to 1700 cm<sup>−1</sup>). On the basis of an overall data reduction level of 92.5%, we reconstructed each channel to compose an image stack. In fig. S2 (A and B), we visualized the GT image of WAT acquired by full faster scanning based on two channels (2856 and 1550 cm<sup>−1</sup>) as well as the corresponding 80-channel BayROM image stack, denoted as hypercube. The hypercube contains the complete spatial and spectral information of the sample, i.e., each pixel on the hypercube comprises the mid-IR spectrum for the corresponding location in the sample. The spectral stability of hypercubes generated using BayROM, i.e., the accuracy of reconstructed spectra obtained from rapidly acquired data, was assessed by comparing the spectra obtained with the reconstructed hypercube at selected pixels with the GT spectra acquired from the same locations. We visualized the spectra from the BayROM hypercube in comparison with the GT spectra in fig. S2 (D to G), confirming that BayROM achieves accurate reconstructions of spectra, quantified by the mean relative error, which amounts to 4.4% for the adipocyte spectra and 1.7% for the extracellular matrix (ECM) spectra. To further analyze the imaged tissue, we used the GT spectra taken from the locations marked in fig. S2A representing adipocytes and ECM and performed linear spectral unmixing to generate a spatial mapping of the resulting mixing coefficients visualized in fig. S2C. The spatial mapping of unmixing coefficients can be used to assess the biological composition of the imaged sample, which, according to the unmixing, consists of 66.4% adipocytes and 33.6% ECM. In summary, we confirmed the hyperspectral imaging capability of BayROM, which is crucial for analytic downstream tasks, i.e., methods for data analysis applied after imaging, such as biological assessments based on spectral unmixing.</p></section><section id="sec6"><h3 class="pmc_sec_title">Validation of generalization based on mouse organ tissues</h3>
<p>To analyze and validate the capabilities of BayROM on a broad range of biologically relevant sample types, we measured fixed tissues from several mouse organs. Specifically, we compared GT images obtained using full raster scanning with BayROM images based on two wave numbers, i.e., 2856 and 1550 cm<sup>−1</sup>, to assess the lipid and protein contrast of the samples. <a href="#F3" class="usa-link">Figure 3 (G to J)</a> shows the results of muscle, pancreatic, liver, and kidney tissue scans. To prove the generalizability of BayROM, we demonstrate images of a 5 mm–by–5 mm FOV (large FOV) as well as a 1 mm–by–1 mm FOV (small FOV) for the muscle tissue and pancreatic tissue samples to showcase BayROM’s application to particular structures in different scales. Furthermore, the same correlated field parameters were used to obtain the results displayed in <a href="#F3" class="usa-link">Fig. 3 (G to J)</a>, i.e., the same parametrization was used for all images to confirm that BayROM is able to generalize to various sample types without parameter tuning. With average SSIM values ranging from 0.81 to 0.94 and total speedup factors ranging from 8.2 to 12.86, the results indicate that BayROM has the ability to successfully image various biological features, including connective tissue and adipocytes in the pancreatic sample, fiber structure in the muscle sample, and vessel structure in the liver sample. In summary, the presented results provide valuable insights into the generalizability and confirm that BayROM has substantial capabilities to reconstruct high-resolution images for arbitrary sample types while substantially increasing the imaging speed compared to full raster scanning.</p></section><section id="sec7"><h3 class="pmc_sec_title">Optoacoustic quality guidance for autologous fat transfer using BayROM</h3>
<p>Having confirmed that BayROM enables fast, high-resolution molecular imaging of biological specimens, we assessed its capabilities to provide histological quality metrics for autologous fat transfer. Autologous fat transfer substantially enhances the overall quality of life for patients by aiding in the restoration of natural breast contour and improving tissue quality. Furthermore, autologous fat transfer is effectively applied in the treatment of conditions such as scar contracture, systemic sclerosis, and chronic wound healing (<a href="#R39" class="usa-link" aria-describedby="R39"><em>39</em></a>, <a href="#R40" class="usa-link" aria-describedby="R40"><em>40</em></a>). The principle of autologous fat transfer consists of the accumulation of stromal vascular cells, particularly adipose-derived stem cells, and ECM components using an intraoperative enrichment process to reduce the lipid content from depot adipocytes in lipoaspirate.</p>
<p>We applied BayROM to fresh, mechanically processed fat grafts aiming to establish quantitative quality control for autologous fat transfer. <a href="#F4" class="usa-link">Figure 4</a> shows a representative example (from <em>n</em> = 3 independent measurements with similar results, as shown in fig. S3) comparing CELT<sup>plus</sup> and nanofat micrographs obtained by BayROM as well as full scanning. CELT<sup>plus</sup> is an enhanced fat graft obtained by mechanical processing of lipoaspirate to avoid nanofat transfer, which provides the risk of complications such as, for instance, oil cysts due to insufficiently removed released lipids. Although the mechanical processing for CELT<sup>plus</sup> aims to remove released lipids largely, the intraoperative enhancement protocol can only be standardized to a limited extent and thus can lead to insufficient removal of impurities and free lipids, i.e., nanofat. High-quality enhancement of fat grafts is required for treatment success and can only be confirmed via histological assessments. <a href="#F4" class="usa-link">Figure 4 (A and B)</a> shows micrographs at 2856 and 1550 cm<sup>−1</sup> selected to assess the lipid and protein contrasts of CELT<sup>plus</sup> and nanofat, respectively. The images were first obtained for a large FOV to reduce selection bias. From the large FOV, a zoomed image at a smaller FOV is obtained to further analyze small structures in more detail. BayROM achieves an increase of more than an eight times in imaging speed for the large FOVs and an increase of almost 14 times for the small FOVs compared to full raster scanning, resulting in a scanning time of 3 to 5 min per image.</p>
<figure class="fig xbox font-sm" id="F4"><h4 class="obj_head">Fig. 4. Optoacoustic quality guidance of autologous fat transfer using BayROM.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12372899_sciadv.adu7319-f4.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/0560/12372899/4c5a8d6f4366/sciadv.adu7319-f4.jpg" loading="lazy" height="531" width="785" alt="Fig. 4."></a></p>
<div class="p text-right font-secondary"><a href="figure/F4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>(<strong>A</strong>) Image comparisons of large FOVs, i.e., 4.5 mm by 4.5 mm (left column), and small FOVs, i.e., 1 mm by 1 mm (right column), of CELT<sup>plus</sup> imaged using full raster scanning (GT) and BayROM (92.5% data reduction). The average RMSE and the average PSNR between GT and BayROM are 39.28 μV and 22.63 dB for the FOVs, and 13.27 μV and 31.04 dB for the small FOVs. (<strong>B</strong>) Image comparisons of large FOVs, i.e., 4.5 mm by 4.5 mm (left column), and small FOVs, i.e., 1 mm by 1 mm (right column), of nanofat imaged using full raster scanning (GT) and BayROM. The RMSE and the average PSNR between GT and BayROM are 34.15 μV and 26.67 dB for the large FOVs, and 11.25 μV and 32.62 dB for the small FOVs. (<strong>C</strong> and <strong>D</strong>) Intensity distributions of lipid and protein signals in large FOV images of CELT<sup>plus</sup> obtained using full raster scanning (GT) and BayROM. (<strong>E</strong> and <strong>F</strong>) Intensity distributions of lipid and protein signals in large FOV images of nanofat obtained using full raster scanning (GT) and BayROM.</p></figcaption></figure><p>As evident from <a href="#F4" class="usa-link">Fig. 4 (A and B)</a>, both the BayROM images and the full scans of CELT<sup>plus</sup> show highly compacted structures, including homogeneously distributed adipocytes, identifiable by their univacuolar lipid droplets, which are strongly embedded in the ECM. These adipocytes tend to be smaller than those typically found in adipose tissue depots. In contrast to CELT<sup>plus</sup>, nanofat exhibits a notable presence of free lipids beside less prominent regions containing ECM and adipocytes. The free lipids present in nanofat could not be removed during the mechanical enrichment process. Besides the morphological differences between CELT<sup>plus</sup> and nanofat, the images furthermore allow assessing the intensity distributions of both channels, which gives additional insights into the molecular compositions of both samples. <a href="#F4" class="usa-link">Figure 4 (C to F)</a> shows that the distributions calculated based on the BayROM images match the GT distributions. Comparing lipid and protein intensity distributions between CELT<sup>plus</sup> and nanofat, the protein channel shows distinctly higher signals for nanofat than for CELT<sup>plus</sup>. A predominately strong protein signal could indicate impurities caused by blood that are more present in nanofat than CELT<sup>plus</sup>. Overall, the results suggest that BayROM enables a clear morphological and molecular distinction between CELT<sup>plus</sup> and nanofat based on the two-channel images and their corresponding intensity distributions. By providing fast, label-free images at imaging times below 5 min, BayROM could facilitate the quality assessment of mechanically processed fat grafts and thus enable interoperative decision-making for autologous fat transfer within a surgically reasonable time frame.</p></section></section><section id="sec8"><h2 class="pmc_sec_title">DISCUSSION</h2>
<p>We showed that rapid data acquisition in OAM combined with Bayesian image reconstruction using BayROM leads to ~10 times faster imaging speed compared to full raster scanning while preserving image quality. Specifically, we validated BayROM based on synthetic samples and selected tissues from mouse organs that BayROM retains accurate reconstructions when compared to GT images acquired using full raster scanning. Raster scanning OAM is considered a low-throughput imaging technique due to its slow imaging speed. Slow imaging speed in OAM is a key limitation preventing its translation into clinical workflows despite its proven label-free molecular imaging capabilities. We demonstrated BayROM’s translational potential for the case of autologous fat transfer, enabling rapid intraoperative histopathological assessment of fresh, unprocessed specimens. Thereby, BayROM achieves to overcome time-consuming image acquisition while avoiding limitations associated with hardware-based solutions, i.e., transducer defocusing, and bypassing the need for large datasets required by learning-based approaches that involve neural networks.</p>
<p>Model-based image reconstruction by BayROM is a non–data-driven approach that compensates for the data reduction using a generative prior model. Unlike learning-based approaches, BayROM does not require domain-specific training datasets to reliably compensate for missing information without the risk of generating artifacts. This main advantage of BayROM makes the tedious and often infeasible collection of large training datasets in OAM unnecessary. In addition, shifting from black-box DL-based reconstruction approaches to Bayesian image reconstruction offers more transparency by incorporating quality control parameters, i.e., the reconstruction uncertainty, for assessing the uncertainty associated with reconstruction results. However, image reconstruction with BayROM requires more computational effort/time than DL-based solutions. A high computational effort is required because model-based image reconstruction by BayROM is achieved using MGVI, a variational inference algorithm that solves a high-dimensional optimization problem. Contrary to data-driven DL-based solutions, where image reconstruction could be achieved by single forward propagation processes of neural networks, variational inference is solved in iterative loops. Nonetheless, fast image reconstruction using BayROM could be achieved by (i) increasing the computational power used for image reconstruction, (ii) optimizing hardware using graphics processing units for parallelized implementations of computational operations, etc., or (iii) approximate reconstruction, meaning that the posterior distribution is approximated with fewer iterations of the MGVI algorithm, making reconstructions faster than full reconstruction. To showcase the effects of approximate reconstruction, we analyzed the reconstruction accuracy for approximated versus full image reconstruction (fig. S4). To do this, we used three instead of five iterations of MGVI combined with eight instead of 16 samples drawn from the posterior distribution to reconstruct the images presented in <a href="#F3" class="usa-link">Fig. 3 (A to F)</a>. Approximate reconstruction was carried out in only 2 min and 38 s compared to 10 min and 6 s needed for full reconstruction. The result shows that, even with approximate reconstruction, similar reconstruction residuals can be achieved compared to standard reconstruction while saving ~75% of the computational time. However, the maximum uncertainty in the approximate reconstruction is approximately twofold compared to the standard reconstruction method, which shows that the approximate solution provides less confidence about the resulting image than the full reconstruction and thus needs to be applied with the awareness that the imaging is potentially less accurate. In addition to approximate reconstruction, a potential strategy for accelerated computing could be realized by parallelizing the reconstruction of multiple image channels associated with different excitation wavelengths. When combining solutions 1, 2, and 3, we expect that the computational time required for image reconstruction using BayROM could be substantially lowered to obtain images within a few seconds instead of several minutes. While a hardware-efficient implementation is subject to further research to enable fast image reconstruction, the currently required computational time, which was necessary to assess the fat grafts presented in <a href="#F4" class="usa-link">Fig. 4</a>, is in the order of magnitude of 2 to 4 min per channel using approximate reconstruction. Hence, even without further developments, image reconstruction within a few minutes would currently delay but not hinder intraoperative decision-making using BayROM.</p>
<p>BayROM provides a parameterizable imaging framework that can be tuned to meet the specific needs of the application. The adjustable parameters include the data reduction setting, i.e., the number of skipped raster lines, as well as the pixel-wise averaging level, and define the imaging speed but also parameters referring to the reconstruction, such as the latent variables of the prior model (see Materials and Methods). However, since the correlated field model is tuned to act as a weakly informative prior, the appearance and quality of reconstructed images are not strongly influenced by the parameterization of the prior model. Instead, the reconstruction mechanism is rather affected by the correlation structure along the densely sampled axis, which gets projected to the sparsely sampled axis. Since most biological samples have similar correlation structures in all directions, such behavior aids highly resolved reconstruction without relying on a precise parameterization of the prior model for specific sample types. Benefiting from the ability to assess the correlation structure of images based on reduced data, we confirmed BayROM’s capabilities to generalize to various sample types (see <a href="#F3" class="usa-link">Fig. 3, G to J</a>) without reparameterization.</p>
<p>Despite the generalization capabilities, the mechanism of capturing an overall correlation structure of images also provides the risk of artifacts, which is especially the case for images that express strongly differing correlation structures in different image areas. Figure S5 demonstrates two examples with blur and noisy artifacts resulting from different correlation structures expressed over the imaged FOV. Figure S5 (A and B) shows blurred fine structures, which can be the consequence of the reconstruction method capturing the dominant bulk areas and projecting their correlation structure also to areas with fine structures. Conversely, fig. S5 (C and D) shows an example where a bulk area in the BayROM image is noisier than the comparably smooth structure in the GT image. Such noisy bulk structures can be explained by the predominant correlation structures of small features in the images that are projected onto the bulk areas and make them appear as noisy. To avoid such reconstruction artifacts, it is important to choose sparsity parameters such that the acquired data provide enough information about the structures of interest to enable their successful reconstruction. Hence, a thorough choice of parameters has to be made for data reduction levels to match the requirements of the clinical application and potential computational downstream analysis.</p>
<p>The overall benefit of our work is faster OAM imaging based on rapid data acquisition compared to conventional raster scanning OAM imaging. BayROM provides a parameterizable imaging framework that does not require the collection of training data, unlike related data-driven methods for image reconstruction based on reduced data. Furthermore, BayROM does not suffer from stitching artifacts in larger FOVs, such as common hardware-based solutions for fast scanning. A combination of optomechanical speedup methods with BayROM could potentially enable synergy between the hardware-based and software-based methods to further increase the data acquisition speed toward high-speed and high-throughput OAM applications. On the other hand, the overall limitation of BayROM is the high computational effort required for image reconstruction compared to DL methods. The next step is a hardware-optimized and parallelized implementation to be operated using more computational power to assess the imaging performance for clinical applications. An additional promising clinical application could be tumor margin segmentation based on fast hyperspectral imaging, which would be an important step toward the clinical implementation of BayROM with optimized computation.</p>
<p>In summary, we showed that BayROM, a rapid imaging method combined with a probabilistic image reconstruction algorithm, enables about 10 times faster data acquisition and accurate reconstructions, which we validated based on several mouse organ tissues. The impact of faster data acquisition is that increased scanning speed of raster scanning OAM by a factor of 10 could enable its integration into surgical workflows, such as quality guidance for autologous fat transfer. Although here, the application of BayROM for quality-guided autologous fat transfer was demonstrated only as a proof-of-concept, we were able to retrieve morphological and molecular differences between CELT<sup>plus</sup> and nanofat. To move BayROM toward its clinical implementation, the next steps involve a clinical trial with a larger patient cohort to statistically investigate and validate the parameters retrieved for quality guidance of fat grafts. In conclusion, BayROM can facilitate the intraoperative histopathological assessment of freshly derived specimens showing great potential to enable fast surgical decision-making based on label-free molecular imaging.</p></section><section id="sec9"><h2 class="pmc_sec_title">MATERIALS AND METHODS</h2>
<section id="sec10"><h3 class="pmc_sec_title">Molecular contrast formation and optomechanical setup</h3>
<p>The ability of biological molecules to convert light to sound via the optoacoustic effect strongly depends on the arrangement and interaction of their constituent atoms and atomic bonds, as well as the wavelength of the light interacting with them. For this reason, biological molecules have characteristic optoacoustic spectral fingerprints, which OAM exploits to generate label-free molecular contrast. The types of molecules present in a sample, their spatial distribution, and local concentrations all shape a sample’s ability to generate optoacoustic signals. OAM measures this position- and excitation wavelength–dependent optoacoustic signal generation ability, henceforth called the optoacoustic signal strength field <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m1" display="inline" overflow="linebreak"><mrow><mtext>OASS</mtext><mrow><mo stretchy="true">(</mo><mi>x</mi><mo>,</mo><mi mathvariant="normal">λ</mi><mo stretchy="true">)</mo></mrow></mrow></math></span> . Molecular prevalences in tissues can be deduced by identifying molecular fingerprints in the optoacoustic signal strength field.</p>
<p>Mid-infrared optoacoustic microscopy (MiROM) (<a href="#R16" class="usa-link" aria-describedby="R16"><em>16</em></a>), the OAM technique used in this work, uses a broadly tunable quantum cascade laser (MIRcat, Daylight Solutions) to probe the optoacoustic signal strength field of a sample with mid-IR radiation in the wave number range of 2941 to 909 cm<sup>−1</sup> (3.4 to 11 μm). The sample is placed on a mid-IR transparent zinc sulfide window (Crystal) and illuminated from below. The laser beam is focused on a plane located in the imaged sample using a 0.5–numerical aperture reflective objective (36×; Newport Corporation) to confine the optical excitation to a small tissue volume. To sense the generated optoacoustic signal, we placed a focused ultrasound transducer (Imasonic) with a central frequency of 20 MHz above the tissue and coaligned to the focal spot of the mid-IR laser, capturing the optoacoustic signals through a coupling medium (deionized water). The optoacoustic signals are acquired using a data acquisition card (Gage Applied) after being amplified by a 63-dB low-noise amplifier (MITEQ) and processed by a 50-MHz low-pass filter (Mini-Circuits). The mid-IR laser has a repetition rate of 100 kHz and a pulse duration of 20 ns. Three exemplary wavelengths were used to assess the molecular response in investigated samples: 2856 cm<sup>−1</sup> causing symmetric stretching of CH<sub>2</sub> functional groups, 1550 cm<sup>−1</sup> causing N─H bending/C─N stretching, and 1470 cm<sup>−1</sup> causing CH<sub>2</sub>/CH<sub>3</sub> bending.</p>
<p>Raster scanning OAM maps the optoacoustic signal strength field by spatially raster-scanning the sample for each selected excitation wavelength. In each pixel location (indexed by the pixel coordinates <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m2" display="inline" overflow="linebreak"><mrow><mi>k</mi><mo>∈</mo><mrow><mo stretchy="true">{</mo><mn>1</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>n</mi><mo stretchy="true">}</mo></mrow></mrow></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m3" display="inline" overflow="linebreak"><mrow><mi>l</mi><mo>∈</mo><mrow><mo stretchy="true">{</mo><mn>1</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>m</mi><mo stretchy="true">}</mo></mrow></mrow></math></span> ), the optoacoustic signal strength field is probed with multiple laser pulses (indexed by the pulse number <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m4" display="inline" overflow="linebreak"><mrow><mi>j</mi><mo>∈</mo><mrow><mo stretchy="true">{</mo><mn>1</mn><mo>,</mo><mo>…</mo><mo>,</mo><mn>50</mn><mo stretchy="true">}</mo></mrow></mrow></math></span> ), yielding a set of optoacoustic transient signals <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m5" display="inline" overflow="linebreak"><mrow><msubsup><mtext>OAT</mtext><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow><mi>j</mi></msubsup><mrow><mo stretchy="true">(</mo><mi>t</mi><mo stretchy="true">)</mo></mrow></mrow></math></span> . These transient signals are subsequently averaged with respect to the laser pulses to increase the SNR, resulting in the averaged optoacoustic transient signal <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m6" display="inline" overflow="linebreak"><mrow><mtext>OA</mtext><msub><mi mathvariant="normal">T</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow></msub><mrow><mo stretchy="true">(</mo><mi>t</mi><mo stretchy="true">)</mo></mrow></mrow></math></span> . To form a MiROM micrograph</p>
<table class="disp-formula p" id="E1"><tr>
<td class="formula"><math id="m7" display="block" overflow="linebreak"><mrow><msup><mi mathvariant="bold">i</mi><mo mathvariant="bold-italic">∗</mo></msup><mo>=</mo><mrow><mo stretchy="true">(</mo><mtable><mtr><mtd><msubsup><mi>i</mi><mrow><mn>1</mn><mo>,</mo><mn>2</mn></mrow><mo>∗</mo></msubsup></mtd><mtd><mo>⋯</mo></mtd><mtd><msubsup><mi>i</mi><mrow><mn>1</mn><mo>,</mo><mi>m</mi></mrow><mo>∗</mo></msubsup></mtd></mtr><mtr><mtd><mo>⋮</mo></mtd><mtd><mo>⋱</mo></mtd><mtd><mo>⋮</mo></mtd></mtr><mtr><mtd><msubsup><mi>i</mi><mrow><mi>n</mi><mo>,</mo><mn>1</mn></mrow><mo>∗</mo></msubsup></mtd><mtd><mo>⋯</mo></mtd><mtd><msubsup><mi>i</mi><mrow><mi>n</mi><mo>,</mo><mi>m</mi></mrow><mo>∗</mo></msubsup></mtd></mtr></mtable><mo stretchy="true">)</mo></mrow></mrow></math></td>
<td class="label">(1)</td>
</tr></table>
<p>with <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m8" display="inline" overflow="linebreak"><mrow><mi>n</mi><mo>·</mo><mi>m</mi></mrow></math></span> pixels (henceforth called “image”), the peak-to-peak amplitudes of the averaged optoacoustic transient signals <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m9" display="inline" overflow="linebreak"><mrow><mtext>OA</mtext><msub><mi mathvariant="normal">T</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow></msub><mrow><mo stretchy="true">(</mo><mi>t</mi><mo stretchy="true">)</mo></mrow></mrow></math></span> are extracted as the image pixel values</p>
<table class="disp-formula p" id="E2"><tr>
<td class="formula"><math id="m10" display="block" overflow="linebreak"><mtable><mtr><mtd columnalign="left"><mrow><mtable><mtr><mtd columnalign="left"><mrow><msubsup><mi>i</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow><mo>∗</mo></msubsup><mo>=</mo><munder><mtext>max</mtext><mi>t</mi></munder><mrow><mo stretchy="true">[</mo><mtext>OA</mtext><msub><mi mathvariant="normal">T</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow></msub><mrow><mo stretchy="true">(</mo><mi>t</mi><mo stretchy="true">)</mo></mrow><mo stretchy="true">]</mo></mrow><mo>−</mo><munder><mtext>min</mtext><mi>t</mi></munder><mrow><mo stretchy="true">[</mo><mtext>OA</mtext><msub><mi mathvariant="normal">T</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow></msub><mrow><mo stretchy="true">(</mo><mi>t</mi><mo stretchy="true">)</mo></mrow><mo stretchy="true">]</mo></mrow><mo>,</mo><mspace width="0.5em"></mspace><mo>∀</mo><mi>k</mi><mo>∈</mo><mrow><mo stretchy="true">{</mo><mn>1</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>n</mi><mo stretchy="true">}</mo></mrow><mo>,</mo><mi>l</mi><mo>∈</mo><mrow><mo stretchy="true">{</mo><mn>1</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>m</mi><mo stretchy="true">}</mo></mrow></mrow></mtd></mtr></mtable></mrow></mtd></mtr></mtable></math></td>
<td class="label">(2)</td>
</tr></table>
<p>We speed up data acquisition by skipping raster scanning lines <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m11" display="inline" overflow="linebreak"><mrow><mi>l</mi></mrow></math></span> (sparsity) and reducing the number of optoacoustic transient signals acquired in each measurement location from 50 to 15 (decreased averaging). This acquisition approach yields reduced observations</p>
<table class="disp-formula p" id="E3"><tr>
<td class="formula"><math id="m12" display="block" overflow="linebreak"><mtable><mtr><mtd columnalign="left"><mrow><mtable><mtr><mtd columnalign="left"><mrow><msub><mi>d</mi><mrow><mi>k</mi><mo>,</mo><mi>v</mi></mrow></msub><mo>=</mo><munder><mtext>max</mtext><mi>t</mi></munder><mrow><mo stretchy="true">[</mo><mtext>OA</mtext><msubsup><mi mathvariant="normal">T</mi><mrow><mi>k</mi><mo>,</mo><mi>v</mi></mrow><mo>′</mo></msubsup><mrow><mo stretchy="true">(</mo><mi>t</mi><mo stretchy="true">)</mo></mrow><mo stretchy="true">]</mo></mrow><mo>−</mo><munder><mtext>min</mtext><mi>t</mi></munder><mrow><mo stretchy="true">[</mo><mtext>OA</mtext><msubsup><mi mathvariant="normal">T</mi><mrow><mi>k</mi><mo>,</mo><mi>v</mi></mrow><mo>′</mo></msubsup><mrow><mo stretchy="true">(</mo><mi>t</mi><mo stretchy="true">)</mo></mrow><mo stretchy="true">]</mo></mrow><mo>,</mo></mrow></mtd></mtr><mtr><mtd columnalign="left"><mrow><mo>∀</mo><mi>k</mi><mo>∈</mo><mrow><mo stretchy="true">{</mo><mn>1</mn><mo>,</mo><mo>…</mo><mo>,</mo><mi>n</mi><mo stretchy="true">}</mo></mrow><mo>,</mo><mi>v</mi><mo>∈</mo><mrow><mo stretchy="true">{</mo><mn>1</mn><mo>,</mo><mi>w</mi><mo>+</mo><mn>1</mn><mo>,</mo><mn>2</mn><mspace width="0.25em"></mspace><mi>w</mi><mo>+</mo><mn>1</mn><mo>,</mo><mo>…</mo><mo stretchy="true">}</mo></mrow></mrow></mtd></mtr></mtable></mrow></mtd></mtr></mtable></math></td>
<td class="label">(3)</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m13" display="inline" overflow="linebreak"><mrow><mtext>OA</mtext><msubsup><mi mathvariant="normal">T</mi><mrow><mi>k</mi><mo>,</mo><mi>v</mi></mrow><mo>′</mo></msubsup><mrow><mo stretchy="true">(</mo><mi>t</mi><mo stretchy="true">)</mo></mrow></mrow></math></span> denotes the averaged optoacoustic transient signals formed from 15 laser pulses, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m14" display="inline" overflow="linebreak"><mrow><mi>w</mi></mrow></math></span> denotes the raster scanning line acquisition stride. When measuring every fourth raster scan line ( <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m15" display="inline" overflow="linebreak"><mrow><mi>w</mi><mo>=</mo><mn>4</mn></mrow></math></span> ), the amount of data acquired reduces by 92.5% with respect to a full scan.</p>
<p>The rapid measurements permit a substantial speedup of the data acquisition process but are realized at the cost of information loss with respect to the baseline. The increased stride between raster scanning lines creates areas in the micrograph where the optoacoustic signal strength field is not directly probed, and the reduction in repeated transient measurements leads to a reduced SNR in the data <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m16" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">d</mi></mrow></math></span> . Consequently, reconstructing dense micrographs <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m17" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">i</mi></mrow></math></span> based on the reduced data <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m18" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">d</mi></mrow></math></span> is an ill-posed inverse problem (i.e., does not have a unique solution), which we address in the framework of Bayesian image reconstruction.</p></section><section id="sec11"><h3 class="pmc_sec_title">Exploitation of structural regularities in imaged samples</h3>
<p>Many samples of interest for OAM have characteristic structural regularities, such as the grain structure of carbon tape or the arrangement, sizes, and shapes of adipocytes in WAT. The core concept of BayROM is that OAM images can be reconstructed faithfully from reduced data if the imaged samples exhibit structural regularities, which can be used to deduce the image values in areas without measurements from measurements in other areas. For example, knowledge of the typical shape and size of adipocytes in WATs allows predicting the full contour of a partially imaged adipocyte.</p>
<p>In general, i.e., for arbitrary samples, such structural regularities are not known a priori. Nevertheless, to reconstruct a broad range of samples, BayROM estimates the structural regularities of the imaged sample during the image reconstruction process based on the available data <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m19" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">d</mi></mrow></math></span> and forms the image using the estimated regularities. For this purpose, we model the image as a (nonlinearly transformed) Gaussian random field with approximately Matérn covariance structure. The covariance structure encodes the structural regularities of the image and is inferred in the image reconstruction process. Although exploiting the structural regularities of the sample constrains the solution space, the imaging problem remains ill-posed.</p></section><section id="sec12"><h3 class="pmc_sec_title">Bayesian image reconstruction</h3>
<p>Given that there is no unique solution to the image reconstruction problem, we pursue a probabilistic image reconstruction approach. We recover the discrete posterior probability distribution of images <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m20" display="inline" overflow="linebreak"><mrow><mi>p</mi><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">i</mi><mo>∣</mo><mi mathvariant="bold">d</mi><mo stretchy="true">)</mo></mrow></mrow></math></span> , which expresses how likely it is that a full OAM scan would produce the image <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m21" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">i</mi></mrow></math></span> given that a rapid scan has produced the data <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m22" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">d</mi></mrow></math></span> . On the basis of the posterior distribution of images, we can estimate the expected image for a full OAM scan (via the posterior mean) and the uncertainty of this estimate (via the posterior variance).</p>
<p>Following Bayes’ theorem, the posterior probability of an image <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m23" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">i</mi></mrow></math></span> is proportional to the product of the so-called likelihood <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m24" display="inline" overflow="linebreak"><mrow><mi>p</mi><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">d</mi><mspace width="-0.1em"></mspace><mo>∣</mo><mspace width="-0.1em"></mspace><mi mathvariant="bold">i</mi><mo stretchy="true">)</mo></mrow></mrow></math></span> and prior probability distribution <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m25" display="inline" overflow="linebreak"><mrow><mi>p</mi><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">i</mi><mo stretchy="true">)</mo></mrow></mrow></math></span></p>
<table class="disp-formula p" id="E4"><tr>
<td class="formula"><math id="m26" display="block" overflow="linebreak"><mrow><mi>p</mi><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">i</mi><mspace width="-0.1em"></mspace><mo>∣</mo><mspace width="-0.1em"></mspace><mi mathvariant="bold">d</mi><mo stretchy="true">)</mo></mrow><mo>∝</mo><mi>p</mi><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">d</mi><mspace width="-0.1em"></mspace><mo>∣</mo><mspace width="-0.1em"></mspace><mi mathvariant="bold">i</mi><mo stretchy="true">)</mo></mrow><mo>·</mo><mi>p</mi><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">i</mi><mo stretchy="true">)</mo></mrow></mrow></math></td>
<td class="label">(4)</td>
</tr></table>
<p>The likelihood encodes how probable it is to observe the data <strong>d</strong> for a sample that a full scan would produce the image <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m27" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">i</mi></mrow></math></span> , given our knowledge about the measurement process. The prior probability distribution encodes our a priori knowledge about studied samples and their associated OAM images, such as the fact that the images are strictly positive-valued. We also encode our expectation that the images will have relevant structural regularities in the prior.</p>
<p>Computing posterior statistics given <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m28" display="inline" overflow="linebreak"><mrow><mi>p</mi><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">i</mi><mspace width="-0.1em"></mspace><mo>∣</mo><mspace width="-0.1em"></mspace><mi mathvariant="bold">d</mi><mo stretchy="true">)</mo></mrow></mrow></math></span> is challenging because of the high dimensionality of the images. We use variational inference to approximate the posterior distribution <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m29" display="inline" overflow="linebreak"><mrow><mi>p</mi><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">i</mi><mspace width="-0.1em"></mspace><mo>∣</mo><mspace width="-0.1em"></mspace><mi mathvariant="bold">d</mi><mo stretchy="true">)</mo></mrow></mrow></math></span> with a parametric distribution <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m30" display="inline" overflow="linebreak"><mrow><msub><mi>Q</mi><mi mathvariant="bold">ϕ</mi></msub><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">i</mi><mo stretchy="true">)</mo></mrow><mo>,</mo></mrow></math></span> which is constructed so that efficient computation of its distribution statistics becomes possible. The posterior mean and standard deviation can then be estimated using <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m31" display="inline" overflow="linebreak"><mrow><msub><mi>Q</mi><mi mathvariant="normal">ϕ</mi></msub><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">i</mi><mo stretchy="true">)</mo></mrow></mrow></math></span> . Variational inference approximates the true posterior distribution by minimizing the Kullback-Leibler (KL) divergence</p>
<table class="disp-formula p" id="E5"><tr>
<td class="formula"><math id="m32" display="block" overflow="linebreak"><mrow><msub><mi>D</mi><mtext>KL</mtext></msub><mrow><mo stretchy="true">(</mo><msub><mi>Q</mi><mi mathvariant="bold">ϕ</mi></msub><mo stretchy="true">‖</mo><mi>p</mi><mo stretchy="true">)</mo></mrow><mo>=</mo><munder><mo>∑</mo><mi mathvariant="bold">i</mi></munder><msub><mi>Q</mi><mi mathvariant="bold">ϕ</mi></msub><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">i</mi><mo stretchy="true">)</mo></mrow><mtext>log</mtext><mrow><mo stretchy="true">[</mo><mfrac><mrow><msub><mi>Q</mi><mi mathvariant="bold">ϕ</mi></msub><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">i</mi><mo stretchy="true">)</mo></mrow></mrow><mrow><mi>p</mi><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">i</mi><mspace width="-0.1em"></mspace><mo>∣</mo><mspace width="-0.1em"></mspace><mi mathvariant="bold">d</mi><mo stretchy="true">)</mo></mrow></mrow></mfrac><mo stretchy="true">]</mo></mrow></mrow></math></td>
<td class="label">(5)</td>
</tr></table>
<p>between the posterior and the variational distribution <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m33" display="inline" overflow="linebreak"><mrow><msub><mi>Q</mi><mi mathvariant="bold">ϕ</mi></msub><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">i</mi><mo stretchy="true">)</mo></mrow><mo>.</mo></mrow></math></span> We use an algorithm optimized for high-dimensional spaces, MGVI (<a href="#R38" class="usa-link" aria-describedby="R38"><em>38</em></a>), which represents the variational distribution <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m34" display="inline" overflow="linebreak"><mrow><msub><mi>Q</mi><mi mathvariant="bold">ϕ</mi></msub><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">i</mi><mo stretchy="true">)</mo></mrow></mrow></math></span> as a vector of latent samples <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m35" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">ϕ</mi><mo mathvariant="bold-italic">=</mo><mrow><mo stretchy="true">(</mo><msub><mi mathvariant="bold">ψ</mi><mn>1</mn></msub><mo>,</mo><msub><mi mathvariant="bold">ψ</mi><mn>2</mn></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi mathvariant="bold">ψ</mi><msub><mi>n</mi><mtext>MGVI</mtext></msub></msub><mo stretchy="true">)</mo></mrow></mrow></math></span> . The image reconstruction process was implemented in the probabilistic inference framework Numerical Information Field Theory (NIFTy) (<a href="#R41" class="usa-link" aria-describedby="R41"><em>41</em></a>, <a href="#R42" class="usa-link" aria-describedby="R42"><em>42</em></a>) and was executed on an M2 MacBook Pro (Apple).</p></section><section id="sec13"><h3 class="pmc_sec_title">System forward model and likelihood definition</h3>
<p>We model the measurement process of rapid OAM with the combination of a deterministic system response <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m36" display="inline" overflow="linebreak"><mi>R</mi><mfenced><mi mathvariant="bold">i</mi></mfenced></math></span> and additive stochastic noise <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m37" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">n</mi></mrow></math></span></p>
<table class="disp-formula p" id="E6"><tr>
<td class="formula"><math id="m38" display="block" overflow="linebreak"><mi mathvariant="bold">d</mi><mo>=</mo><mi>R</mi><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">i</mi><mo stretchy="true">)</mo></mrow><mo>+</mo><mi mathvariant="bold">n</mi></math></td>
<td class="label">(6)</td>
</tr></table>
<p>The deterministic system response includes, on the one hand, the effect of the PSF of the system and, on the other hand, the choice of measurement locations implied by the stage trajectories. The system PSF was characterized based on an image taken from a 1-μm (subresolution) polystyrene sphere (<a href="#R16" class="usa-link" aria-describedby="R16"><em>16</em></a>). Numerically, the operator <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m39" display="inline" overflow="linebreak"><mi>R</mi></math></span> is implemented as sequentially applying a PSF convolution operator <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m40" display="inline" overflow="linebreak"><msub><mi>R</mi><mtext>PSF</mtext></msub></math></span> (which convolves the image <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m41" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">i</mi></mrow></math></span> with a two-dimensional Gaussian kernel with a standard deviation of 5 μm in both spatial dimensions) and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m42" display="inline" overflow="linebreak"><msub><mi>R</mi><mtext>stages</mtext></msub></math></span> , which models the distribution of measurement locations and selectively copies values of the PSF-convolved image <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m43" display="inline" overflow="linebreak"><msub><mrow><mo stretchy="true">(</mo><msub><mi>R</mi><mtext>PSF</mtext></msub><mspace width="0.25em"></mspace><mi mathvariant="bold">i</mi><mo stretchy="true">)</mo></mrow><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow></msub></math></span> to entries of the simulated data vector <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m44" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">d</mi></mrow></math></span> . The additive noise <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m45" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">n</mi></mrow></math></span> was characterized based on the dark noise of the system, which is measured by acquiring an image while blocking the quantum cascade laser beam and assessing the distribution of the pixel intensities. The dark noise was found to be independent and identically distributed Gaussian noise with a standard deviation of <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m46" display="inline" overflow="linebreak"><mrow><mi mathvariant="normal">σ</mi><mo>=</mo><mn>9.318</mn><mo>×</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>7</mn></mrow></msup><mspace width="0.25em"></mspace><mi mathvariant="normal">V</mi></mrow></math></span> . In summary, the rapid OAM measurement is modeled as</p>
<table class="disp-formula p" id="E7"><tr>
<td class="formula"><math id="m47" display="block" overflow="linebreak"><mi mathvariant="bold">d</mi><mo>=</mo><mtext mathvariant="italic">R</mtext><mtext mathvariant="bold">i</mtext><mo>+</mo><mi mathvariant="bold">n</mi><mo>=</mo><mrow><mo stretchy="true">(</mo><msub><mi>R</mi><mtext>stages</mtext></msub><mo>∘</mo><msub><mi>R</mi><mtext>PSF</mtext></msub><mo stretchy="true">)</mo></mrow><mi mathvariant="bold">i</mi><mo>+</mo><mi mathvariant="bold">n</mi></math></td>
<td class="label">(7)</td>
</tr></table>
<p>Accordingly, the likelihood <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m48" display="inline" overflow="linebreak"><mrow><mi>p</mi><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">d</mi><mspace width="-0.1em"></mspace><mo>∣</mo><mspace width="-0.1em"></mspace><mi mathvariant="bold">i</mi><mo stretchy="true">)</mo></mrow></mrow></math></span> is given by</p>
<table class="disp-formula p" id="E8"><tr>
<td class="formula"><math id="m49" display="block" overflow="linebreak"><mi>p</mi><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">d</mi><mspace width="-0.1em"></mspace><mo>∣</mo><mspace width="-0.1em"></mspace><mi mathvariant="bold">i</mi><mo stretchy="true">)</mo></mrow><mo>=</mo><mi>G</mi><mrow><mo stretchy="true">[</mo><mi mathvariant="bold">d</mi><mo>−</mo><mi>R</mi><mi mathvariant="bold">i</mi><mo>∣</mo><mi mathvariant="bold">μ</mi><mo>=</mo><mn>0</mn><mo>,</mo><mi mathvariant="bold">N</mi><mo>=</mo><msup><mi mathvariant="normal">σ</mi><mn>2</mn></msup><mi mathvariant="bold">I</mi><mo stretchy="true">]</mo></mrow></math></td>
<td class="label">(8)</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m50" display="inline" overflow="linebreak"><mrow><mi>G</mi></mrow></math></span> is a Gaussian distribution with mean <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m51" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">μ</mi><mo mathvariant="bold-italic">=</mo><mn mathvariant="normal">0</mn></mrow></math></span> and covariance<span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m52" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">N</mi><mo mathvariant="bold">=</mo><msup><mi mathvariant="normal">σ</mi><mn>2</mn></msup><mi mathvariant="bold">I</mi></mrow></math></span>.</p></section><section id="sec14"><h3 class="pmc_sec_title">Image prior implementation</h3>
<p>Following (<a href="#R38" class="usa-link" aria-describedby="R38"><em>38</em></a>), we implement the image prior as a hierarchical generative model <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m53" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">i</mi><mo>=</mo><mi>f</mi><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">ψ</mi><mo stretchy="true">)</mo></mrow></mrow></math></span> , which deterministically transforms latent parameters <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m54" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">ψ</mi></mrow></math></span> into images <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m55" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">i</mi></mrow></math></span> . As stated in the “Exploitation of structural regularities in imaged samples” section, the images are modeled as a Gaussian random field <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m56" display="inline" overflow="linebreak"><mrow><mtext>GF</mtext></mrow></math></span> with approximately Matérn covariance structure, which is nonlinearly transformed to model the strict positivity of OAM images</p>
<table class="disp-formula p" id="E9"><tr>
<td class="formula"><math id="m57" display="block" overflow="linebreak"><mrow><mi>f</mi><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">ψ</mi><mo stretchy="true">)</mo></mrow><mo>=</mo><mi>r</mi><mo>·</mo><mtext>sigmoid</mtext><mrow><mo stretchy="true">[</mo><mtext>GF</mtext><mrow><mo stretchy="true">(</mo><msup><mi mathvariant="bold">ψ</mi><mtext>GF</mtext></msup><mo stretchy="true">)</mo></mrow><mo>+</mo><mi>s</mi><mrow><mo stretchy="true">(</mo><msup><mi mathvariant="bold">ψ</mi><mi>s</mi></msup><mo stretchy="true">)</mo></mrow><mo stretchy="true">]</mo></mrow></mrow></math></td>
<td class="label">(9)</td>
</tr></table>
<p>Here, <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m58" display="inline" overflow="linebreak"><mrow><mi>r</mi></mrow></math></span> is a constant scaling factor setting the maximal obtainable image value. The sigmoid function ensures positivity of the generated images, while <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m59" display="inline" overflow="linebreak"><mrow><mi>s</mi></mrow></math></span> is an additive offset that controls the average pixel value. The optimal additive offset for a given data vector <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m60" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">d</mi></mrow></math></span> is inferred during reconstruction and a priori follows a Gaussian distribution with mean <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m61" display="inline" overflow="linebreak"><mrow><msub><mi mathvariant="normal">μ</mi><mi>s</mi></msub><mo>=</mo><mn>0.5</mn></mrow></math></span> and standard deviation <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m62" display="inline" overflow="linebreak"><mrow><msub><mi mathvariant="normal">σ</mi><mi>s</mi></msub><mo>=</mo><mn>0.25</mn></mrow></math></span>.</p>
<p>The Gaussian random field <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m63" display="inline" overflow="linebreak"><mrow><mtext>GF</mtext><mrow><mo stretchy="true">(</mo><msup><mi mathvariant="bold">ψ</mi><mtext>GF</mtext></msup><mo stretchy="true">)</mo></mrow></mrow></math></span> is meant to capture and exploit the correlation structure of the image as described above. It is constructed via the Hartley amplitude field <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m64" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">A</mi><mrow><mo stretchy="true">(</mo><msup><mi mathvariant="bold">ψ</mi><mtext>GF</mtext></msup><mo stretchy="true">)</mo></mrow></mrow></math></span> , which is a harmonic representation similar to Fourier mode amplitudes based on the Hartley transform (HT)</p>
<table class="disp-formula p" id="E10"><tr>
<td class="formula"><math id="m65" display="block" overflow="linebreak"><mrow><mtext>GF</mtext><mrow><mo stretchy="true">(</mo><msup><mi mathvariant="bold">ψ</mi><mtext>GF</mtext></msup><mo stretchy="true">)</mo></mrow><mo>=</mo><mtext>HT</mtext><mrow><mo stretchy="true">[</mo><mi mathvariant="bold">A</mi><mrow><mo stretchy="true">(</mo><msup><mi mathvariant="bold">ψ</mi><mtext>GF</mtext></msup><mo stretchy="true">)</mo></mrow><mo stretchy="true">]</mo></mrow></mrow></math></td>
<td class="label">(10)</td>
</tr></table>
<p>We model <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m119" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">A</mi></mrow></math></span> as being separable into a length-scale dependent Hartley spectrum function <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m66" display="inline" overflow="linebreak"><mrow><mi mathvariant="normal">E</mi><mrow><mo stretchy="true">(</mo><mspace width="-0.1em"></mspace><mo>∣</mo><mspace width="-0.1em"></mspace><mi mathvariant="bold">k</mi><mspace width="-0.1em"></mspace><mo>∣</mo><mspace width="-0.1em"></mspace><mo stretchy="true">)</mo></mrow></mrow></math></span> and a Gaussian random field <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m67" display="inline" overflow="linebreak"><mrow><msup><mi mathvariant="bold">ψ</mi><mi mathvariant="bold">ξ</mi></msup></mrow></math></span> . Here, <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m68" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">k</mi><mo>=</mo><mrow><mo stretchy="true">(</mo><mi>k</mi><mo>,</mo><mi>l</mi><mo stretchy="true">)</mo></mrow></mrow></math></span> is the wave vector indexing the Hartley modes. The Hartley spectrum function captures the smoothed spectral power distribution in <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m120" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">A</mi></mrow></math></span>, while the Gaussian random field <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m69" display="inline" overflow="linebreak"><mrow><msup><mi mathvariant="bold">ψ</mi><mi mathvariant="bold">ξ</mi></msup></mrow></math></span> captures deviations of the Hartley amplitudes <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m121" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">A</mi></mrow></math></span> from <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m70" display="inline" overflow="linebreak"><mrow><mi mathvariant="normal">E</mi></mrow></math></span> . Correspondingly, the Hartley amplitudes <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m71" display="inline" overflow="linebreak"><mrow><msub><mi mathvariant="normal">A</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow></msub></mrow></math></span> is defined as</p>
<table class="disp-formula p" id="E11"><tr>
<td class="formula"><math id="m72" display="block" overflow="linebreak"><mrow><msub><mi mathvariant="normal">A</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow></msub><mo mathvariant="bold">=</mo><msub><mi mathvariant="normal">E</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow></msub><mrow><mo stretchy="true">(</mo><msup><mi mathvariant="normal">ψ</mi><mi>a</mi></msup><mo>,</mo><msup><mi mathvariant="normal">ψ</mi><mi>b</mi></msup><mo>,</mo><msup><mi mathvariant="normal">ψ</mi><mi>c</mi></msup><mo stretchy="true">)</mo></mrow><mo>·</mo><msubsup><mi mathvariant="normal">ψ</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow><mi mathvariant="bold">ξ</mi></msubsup></mrow></math></td>
<td class="label">(11)</td>
</tr></table>
<p><span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m73" display="inline" overflow="linebreak"><mrow><mi mathvariant="normal">E</mi><mrow><mo stretchy="true">(</mo><mspace width="-0.1em"></mspace><mo>∣</mo><mspace width="-0.1em"></mspace><mi mathvariant="bold">k</mi><mspace width="-0.1em"></mspace><mo>∣</mo><mspace width="-0.1em"></mspace><mo stretchy="true">)</mo></mrow></mrow></math></span> is constructed as a Matérn spectrum with learnable parameters <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m74" display="inline" overflow="linebreak"><mrow><mi>a</mi><mrow><mo stretchy="true">(</mo><msup><mi mathvariant="normal">ψ</mi><mi>a</mi></msup><mo stretchy="true">)</mo></mrow></mrow></math></span> , <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m75" display="inline" overflow="linebreak"><mrow><mi>b</mi><mrow><mo stretchy="true">(</mo><msup><mi mathvariant="normal">ψ</mi><mi>b</mi></msup><mo stretchy="true">)</mo></mrow></mrow></math></span> , and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m76" display="inline" overflow="linebreak"><mrow><mi mathvariant="normal">c</mi><mrow><mo stretchy="true">(</mo><msup><mi mathvariant="normal">ψ</mi><mi>c</mi></msup><mo stretchy="true">)</mo></mrow></mrow></math></span></p>
<table class="disp-formula p" id="E12"><tr>
<td class="formula"><math id="m77" display="block" overflow="linebreak"><mrow><msub><mi mathvariant="normal">E</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow></msub><mo>=</mo><mi>a</mi><msup><mrow><mo stretchy="true">[</mo><mn>1</mn><mo>+</mo><msup><mrow><mo stretchy="true">(</mo><mfrac><msqrt><mrow><msup><mi>k</mi><mn>2</mn></msup><mo>+</mo><msup><mi>l</mi><mn>2</mn></msup></mrow></msqrt><mi>b</mi></mfrac><mo stretchy="true">)</mo></mrow><mn>2</mn></msup><mo stretchy="true">]</mo></mrow><mfrac><mi>c</mi><mn>4</mn></mfrac></msup></mrow></math></td>
<td class="label">(12)</td>
</tr></table>
<p>This formulation of GF allows us to incorporate the a priori expectation of Matérn covariance for the image while permitting the reconstruction to produce images with covariance structures deviating from the Matérn form if the data suggest it. The priors for the Hartley spectrum function parameters <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m78" display="inline" overflow="linebreak"><mrow><mi>a</mi></mrow></math></span> , <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m79" display="inline" overflow="linebreak"><mrow><mi>b</mi></mrow></math></span> , and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m80" display="inline" overflow="linebreak"><mrow><mi>c</mi></mrow></math></span> are chosen as weakly informative to minimize the risk of biasing the reconstruction.</p>
<p>In summary, the hierarchical image model <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m81" display="inline" overflow="linebreak"><mrow><mi>f</mi><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">Φ</mi><mo stretchy="true">)</mo></mrow></mrow></math></span> nonlinearly transforms latent parameter vectors <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m82" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">ψ</mi><mo mathvariant="bold">=</mo><mrow><mo stretchy="true">(</mo><msup><mi mathvariant="bold">ψ</mi><mi mathvariant="bold">ξ</mi></msup><mo>,</mo><msup><mi mathvariant="normal">ψ</mi><mi>a</mi></msup><mo>,</mo><msup><mi mathvariant="normal">ψ</mi><mi>b</mi></msup><mo>,</mo><msup><mi mathvariant="normal">ψ</mi><mi>c</mi></msup><mo>,</mo><msup><mi mathvariant="normal">ψ</mi><mi>s</mi></msup><mo stretchy="true">)</mo></mrow></mrow></math></span> into images <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m83" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">i</mi></mrow></math></span> , which a priori exhibit Matérn covariance. Inserting <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m84" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">i</mi><mo>=</mo><mi>f</mi><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">ψ</mi><mo stretchy="true">)</mo></mrow></mrow></math></span> into the measurement equation</p>
<table class="disp-formula p" id="E13"><tr>
<td class="formula"><math id="m85" display="block" overflow="linebreak"><mtable><mtr><mtd columnalign="left"><mrow><mi mathvariant="bold">d</mi><mo>=</mo><mi mathvariant="bold">Ri</mi><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">ψ</mi><mo stretchy="true">)</mo></mrow><mo>+</mo><mi mathvariant="bold">n</mi><mo mathvariant="bold">=</mo><mrow><mo stretchy="true">(</mo><msub><mi mathvariant="bold">R</mi><mtext>stages</mtext></msub><mo>∘</mo><msub><mi mathvariant="bold">R</mi><mtext>PSF</mtext></msub><mo>∘</mo><mi>f</mi><mo stretchy="true">)</mo></mrow><mspace width="0.25em"></mspace><mi mathvariant="bold">ψ</mi><mo mathvariant="bold">+</mo><mi mathvariant="bold">n</mi></mrow></mtd></mtr></mtable></math></td>
<td class="label">(13)</td>
</tr></table>
<p>the image reconstruction problem can be reformulated as reconstructing the posterior distribution of the latent parameters <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m86" display="inline" overflow="linebreak"><mrow><mi>p</mi><mrow><mo stretchy="true">(</mo><mi mathvariant="bold">ψ</mi><mspace width="-0.1em"></mspace><mo>∣</mo><mspace width="-0.1em"></mspace><mi mathvariant="bold">d</mi><mo stretchy="true">)</mo></mrow></mrow></math></span> , which has practical benefits as outlined in (<a href="#R43" class="usa-link" aria-describedby="R43"><em>43</em></a>).</p></section><section id="sec15"><h3 class="pmc_sec_title">Postprocessing</h3>
<p>The outcome of the MGVI, i.e., a set of posterior samples <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m87" display="inline" overflow="linebreak"><mrow><mi mathvariant="normal">ϕ</mi><mo mathvariant="bold-italic">=</mo><mrow><mo stretchy="true">(</mo><msub><mi mathvariant="bold">ψ</mi><mn>1</mn></msub><mo>,</mo><msub><mi mathvariant="bold">ψ</mi><mn>2</mn></msub><mo>,</mo><mo>…</mo><mo>,</mo><msub><mi mathvariant="bold">ψ</mi><msub><mi>n</mi><mtext>MGVI</mtext></msub></msub><mo stretchy="true">)</mo></mrow></mrow></math></span> , is used to compute the posterior meanimage <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m88" display="inline" overflow="linebreak"><mrow><msub><mi mathvariant="bold">i</mi><mtext>RC</mtext></msub></mrow></math></span></p>
<table class="disp-formula p" id="E14"><tr>
<td class="formula"><math id="m89" display="block" overflow="linebreak"><mrow><msub><mi mathvariant="bold">i</mi><mtext>RC</mtext></msub><mo>=</mo><mfrac><mn>1</mn><msub><mi>n</mi><mtext>MGVI</mtext></msub></mfrac><mstyle displaystyle="true"><munderover><mo stretchy="true">∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>n</mi><mtext>MGVI</mtext></msub></munderover></mstyle><mi>f</mi><mrow><mo stretchy="true">(</mo><msub><mi mathvariant="bold">ψ</mi><mi>i</mi></msub><mo stretchy="true">)</mo></mrow></mrow></math></td>
<td class="label">(14)</td>
</tr></table>
<p><span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m90" display="inline" overflow="linebreak"><mrow><msub><mi mathvariant="bold">i</mi><mtext>RC</mtext></msub></mrow></math></span> serves as reconstructed images after applying additional postprocessing steps. Postprocessing includes cropping the edges of the image, which were added to the reconstructed micrographs in the numerical convolution with the PSF. Furthermore, if needed, the reconstructed images are interpolated using linear interpolation to allow pixel-wise comparison of the reconstruction based on reduced data with the GT images. For visualization, contrast-limited adaptive histogram equalization (CLAHE) was applied to micrographs to emphasize image contrast. Images <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m91" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">i</mi></mrow></math></span> that were processed with CLAHE are indicated as <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m92" display="inline" overflow="linebreak"><mrow><mover accent="true"><mi mathvariant="bold">i</mi><mo stretchy="true">^</mo></mover></mrow></math></span> . The reported computational times include the full image generation processes, i.e., reconstruction and postprocessing. However, the indicated imaging times do not include the computational time.</p></section><section id="sec16"><h3 class="pmc_sec_title">Uncertainty quantification</h3>
<p>To quantify the overall uncertainty in reconstructed images, the MRSD was used. The MRSD is calculated based on the estimated posterior mean <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m93" display="inline" overflow="linebreak"><mrow><msubsup><mi>i</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow><mtext>RC</mtext></msubsup></mrow></math></span> and standard deviation <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m94" display="inline" overflow="linebreak"><mrow><msubsup><mi>u</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow><mtext>RC</mtext></msubsup></mrow></math></span> for each pixel</p>
<table class="disp-formula p" id="E15"><tr>
<td class="formula"><math id="m95" display="block" overflow="linebreak"><mrow><mtext>MRSD</mtext><mo>=</mo><mfrac><mn>1</mn><mrow><mi>m</mi><mo>·</mo><mi>n</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo stretchy="true">∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover></mstyle><mstyle displaystyle="true"><munderover><mo stretchy="true">∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><mfrac><msubsup><mi>u</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow><mtext>RC</mtext></msubsup><msubsup><mi>i</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow><mtext>RC</mtext></msubsup></mfrac></mrow></math></td>
<td class="label">(15)</td>
</tr></table>
<p>Since the MRSD expresses the average uncertainty relative to the reconstructed intensity values for the entire image, it can be used as a quality metric for reconstructed images without the comparison to a GT image.</p></section><section id="sec17"><h3 class="pmc_sec_title">Hyperspectral linear unmixing</h3>
<p>For a demonstration of spectral unmixing based on the hypercube acquired using BayROM, linear unmixing was performed pixel-wise. Therefore, the spectra obtained using single-point optoacoustic spectroscopy were grouped into adipose tissue and ECM and averaged. The model for linear unmixing assumes that each pixel’s spectrum is composed of a linear combination of both the adipose tissue and the ECM average spectrum. Therefore, the mixing coefficients were restricted to non-zero and determined using pixel-wise least-squares minimization. The result provides two coefficients for each pixel, which were mapped to the image using an overlay to visualize the unmixing result.</p></section><section id="sec18"><h3 class="pmc_sec_title">Evaluation metrics</h3>
<p>The quantitative evaluation of BayROM is twofold. Because of the trade-off between the acquisition speed and the image quality, we report a speedup factor on the one hand and image quality metrics on the other hand. The speedup factor denotes the ratio between the data acquisition time of the full raster scans and the rapid scans. On the other hand, to quantify the image quality, i.e., the reconstruction accuracy, we report the SSIM, the root mean square error (RMSE), and the peak signal-to-noise ratio (PSNR) between the reconstructed images and the GTs. The SSIM is defined as</p>
<table class="disp-formula p" id="E16"><tr>
<td class="formula"><math id="m96" display="block" overflow="linebreak"><mrow><mtext>SSIM</mtext><mo>=</mo><mfrac><mrow><mrow><mo stretchy="true">(</mo><mn>2</mn><msub><mi mathvariant="normal">μ</mi><mtext>RC</mtext></msub><msub><mi mathvariant="normal">μ</mi><mtext>GT</mtext></msub><mo>+</mo><msub><mi>c</mi><mn>1</mn></msub><mo stretchy="true">)</mo></mrow><mrow><mo stretchy="true">(</mo><mn>2</mn><msub><mi mathvariant="normal">σ</mi><mrow><mtext>RC</mtext><mo>,</mo><mtext>GT</mtext></mrow></msub><mo>+</mo><msub><mi>c</mi><mn>2</mn></msub><mo stretchy="true">)</mo></mrow></mrow><mrow><mrow><mo stretchy="true">(</mo><msubsup><mi mathvariant="normal">μ</mi><mtext>RC</mtext><mn>2</mn></msubsup><mo>+</mo><msubsup><mi mathvariant="normal">μ</mi><mtext>GT</mtext><mn>2</mn></msubsup><mo>+</mo><msub><mi>c</mi><mn>1</mn></msub><mo stretchy="true">)</mo></mrow><mrow><mo stretchy="true">(</mo><msubsup><mi mathvariant="normal">σ</mi><mtext>RC</mtext><mn>2</mn></msubsup><mo>+</mo><msubsup><mi mathvariant="normal">σ</mi><mtext>GT</mtext><mn>2</mn></msubsup><mo>+</mo><msub><mi>c</mi><mn>2</mn></msub><mo stretchy="true">)</mo></mrow></mrow></mfrac></mrow></math></td>
<td class="label">(16)</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m97" display="inline" overflow="linebreak"><mrow><msub><mi mathvariant="normal">μ</mi><mtext>RC</mtext></msub></mrow></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m98" display="inline" overflow="linebreak"><mrow><msub><mi mathvariant="normal">μ</mi><mtext>GT</mtext></msub></mrow></math></span> are the mean values of the reconstructed GT images, <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m99" display="inline" overflow="linebreak"><mrow><msub><mi mathvariant="normal">σ</mi><mtext>RC</mtext></msub></mrow></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m100" display="inline" overflow="linebreak"><mrow><msub><mi mathvariant="normal">σ</mi><mtext>GT</mtext></msub></mrow></math></span> are the variances of the reconstructed GT images, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m101" display="inline" overflow="linebreak"><mrow><msub><mi mathvariant="normal">σ</mi><mrow><mtext>RC</mtext><mo>,</mo><mtext>GT</mtext></mrow></msub></mrow></math></span> is the covariance between reconstruction and GT. The variables <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m102" display="inline" overflow="linebreak"><mrow><msub><mi>c</mi><mn>1</mn></msub><mo>=</mo><mn>0.0001</mn></mrow></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m103" display="inline" overflow="linebreak"><mrow><msub><mi>c</mi><mn>2</mn></msub><mo>=</mo><mn>0.0009</mn></mrow></math></span> stabilize the division by small denominators. The RMSE error is defined as</p>
<table class="disp-formula p" id="E17"><tr>
<td class="formula"><math id="m104" display="block" overflow="linebreak"><mrow><mtext>RMSE</mtext><mo>=</mo><msqrt><mrow><mfrac><mn>1</mn><mrow><mi>m</mi><mo>·</mo><mi>n</mi></mrow></mfrac><mstyle displaystyle="true"><munderover><mo stretchy="true">∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover></mstyle><mstyle displaystyle="true"><munderover><mo stretchy="true">∑</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover></mstyle><mrow><mo stretchy="true">(</mo><msubsup><mi>i</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow><mtext>GT</mtext></msubsup><mo>−</mo><msubsup><mi>i</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow><mtext>RC</mtext></msubsup><mo stretchy="true">)</mo></mrow></mrow></msqrt></mrow></math></td>
<td class="label">(17)</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m105" display="inline" overflow="linebreak"><mrow><msubsup><mi>i</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow><mtext>GT</mtext></msubsup></mrow></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m106" display="inline" overflow="linebreak"><mrow><msubsup><mi>i</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow><mtext>RC</mtext></msubsup></mrow></math></span> denote the intensity values of the GT image and the reconstruction for each pixel, respectively. The PSNR is defined as</p>
<table class="disp-formula p" id="E18"><tr>
<td class="formula"><math id="m107" display="block" overflow="linebreak"><mrow><mtext>PSNR</mtext><mo>=</mo><mn>20</mn><mo>·</mo><msub><mtext>log</mtext><mn>10</mn></msub><mrow><mo stretchy="true">(</mo><mfrac><msub><mi>i</mi><mtext>max</mtext></msub><mtext>RMSE</mtext></mfrac><mo stretchy="true">)</mo></mrow></mrow></math></td>
<td class="label">(18)</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m108" display="inline" overflow="linebreak"><mrow><msub><mi>i</mi><mtext>max</mtext></msub></mrow></math></span> denotes the maximum possible intensity value.</p></section><section id="sec19"><h3 class="pmc_sec_title">Signal-to-noise ratio</h3>
<p>We used the SNR to characterize the data acquired using full raster scanning and rapid scanning. Thereby, we denote the SNR of unprocessed signals corresponding to a single pixel as data SNR. The data SNR is defined as</p>
<table class="disp-formula p" id="E19"><tr>
<td class="formula"><math id="m109" display="block" overflow="linebreak"><mrow><mtext>DSNR</mtext><mo>=</mo><mfrac><msub><mi mathvariant="normal">μ</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow></msub><msub><mi mathvariant="normal">σ</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow></msub></mfrac></mrow></math></td>
<td class="label">(19)</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m110" display="inline" overflow="linebreak"><mrow><msub><mi mathvariant="normal">μ</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow></msub></mrow></math></span> denotes the peak-to-peak amplitude of the averaged optoacoustic signal, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m111" display="inline" overflow="linebreak"><mrow><msub><mi mathvariant="normal">σ</mi><mrow><mi>k</mi><mo>,</mo><mi>l</mi></mrow></msub></mrow></math></span> is the standard deviation of the peak-to-peak amplitudes of each optoacoustic signal that is subject to be averaged and mapped to a pixel <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m112" display="inline" overflow="linebreak"><mrow><mrow><mo stretchy="true">{</mo><mspace width="-0.1em"></mspace><mi>k</mi><mo>,</mo><mi>l</mi><mspace width="-0.1em"></mspace><mo stretchy="true">}</mo></mrow></mrow></math></span> . Furthermore, we reported the image SNR as the SNR in the image space, i.e., after image formation. Thereby, the image SNR is defined as</p>
<table class="disp-formula p" id="E20"><tr>
<td class="formula"><math id="m113" display="block" overflow="linebreak"><mrow><mtext>ISNR</mtext><mo>=</mo><mfrac><mrow><mtext>mean</mtext><mrow><mo stretchy="true">(</mo><mover accent="true"><mi mathvariant="bold">i</mi><mo stretchy="true">~</mo></mover><mo stretchy="true">)</mo></mrow></mrow><mrow><mtext>std</mtext><mrow><mo stretchy="true">(</mo><mover accent="true"><mi mathvariant="bold">i</mi><mo stretchy="true">~</mo></mover><mo stretchy="true">)</mo></mrow></mrow></mfrac></mrow></math></td>
<td class="label">(20)</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m114" display="inline" overflow="linebreak"><mrow><mover accent="true"><mi mathvariant="bold">i</mi><mo stretchy="true">~</mo></mover></mrow></math></span> is a selected subregion in an image <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m115" display="inline" overflow="linebreak"><mrow><mi mathvariant="bold">i</mi></mrow></math></span> that is expected to have identical intensities. <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m116" display="inline" overflow="linebreak"><mrow><mtext>mean</mtext><mrow><mo stretchy="true">(</mo><mover accent="true"><mi mathvariant="bold">i</mi><mo stretchy="true">~</mo></mover><mo stretchy="true">)</mo></mrow></mrow></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m117" display="inline" overflow="linebreak"><mrow><mtext>std</mtext><mrow><mo stretchy="true">(</mo><mover accent="true"><mi mathvariant="bold">i</mi><mo stretchy="true">~</mo></mover><mo stretchy="true">)</mo></mrow></mrow></math></span> denote the mean intensity and the standard deviation of intensities in the subregion <span xmlns:mml="http://www.w3.org/1998/Math/MathML"><math id="m118" display="inline" overflow="linebreak"><mrow><mover accent="true"><mi mathvariant="bold">i</mi><mo stretchy="true">~</mo></mover></mrow></math></span>.</p></section><section id="sec20"><h3 class="pmc_sec_title">Resolution</h3>
<p>To characterize BayROM’s capabilities of precise image reconstruction, we computed resolution estimates based on the edge spread functions (ESFs) obtained from a synthetic sample with sharp intensity transitions. To obtain resolution estimates, we used the first derivative of a line profile perpendicular to a sharp intensity transition and defined the full width at half maximum of a Gaussian fit to the ESF as the resolution.</p></section><section id="sec21"><h3 class="pmc_sec_title">Animal tissue preparation</h3>
<p>Male B6(Cg)-Tyr<sup>c-2J</sup>/J mice were maintained under specific pathogen-free conditions with a 12-hour light/dark cycle at a controlled ambient temperature (20° to 24°C). Standard rodent chow and sterile-filtered water were provided ad libitum throughout the study. After 38 weeks of feeding, all mice were euthanized via intraperitoneal injection of 0.8-ml anesthetic cocktail (composition: 6 ml of NaCl, 1 ml of ketamine, and 0.25 ml of xylazine). After blood removal, muscle tissues, pancreatic tissues, liver tissues, and kidney tissues were excised and immediately fixed in 4% paraformaldehyde phosphate-buffered saline solution at room temperature for subsequent analyses. For BayROM imaging, tissue specimens were prepared as follows: The samples were placed in a custom-designed dish equipped with a 12.7-mm-diameter ZnSe window. Ultrasonic gel was uniformly applied to the tissue surface to avoid air bubbles and ensure sufficient sound coupling. The gel-covered tissue was sealed with polyethylene film, followed by the addition of D<sub>2</sub>O as an optical coupling medium. All animal experiments were approved by the government of Upper Bavaria and carried out in accordance with the approved guidelines under the following file number: TV 55.2-2532.Vet_02-20-121.</p></section><section id="sec22"><h3 class="pmc_sec_title">Human fat graft preparation</h3>
<p>Human lipoaspirate was obtained with informed patient consent and approval from the Ethics Committee of the University of Regensburg, Germany (24-3640-101, amendment number 24-3640_1-101). Discarded tissue from elective liposuction procedures was used for sample collection. The procedure was performed using water jet–assisted liposuction (body-jet evo, Human Med AG, Schwerin, Germany) as previously described (<a href="#R3" class="usa-link" aria-describedby="R3"><em>3</em></a>), using a pulsatile jet of saline (0.9% NaCl containing epinephrine at 1:200,000) to gently dislodge adipose tissue. Suction peaks below 0.5 bar were avoided. Postharvest, samples were centrifuged at 1600<em>g</em> relative centrifugal force for 2 min (ROTOFIX 32 A, Andreas Hettich GmbH &amp; Co. KG, Tuttlingen, Germany) to remove residual saline, completely for CELT<sup>plus</sup> and partially for nanofat preparation. To ensure comparability, all processing steps followed the CELT protocol (<a href="#R3" class="usa-link" aria-describedby="R3"><em>3</em></a>), except for mechanical emulsification. For CELT<sup>plus</sup>, the lipoaspirate was passed five times between two 10-ml syringes through a 2.1-mm connector and then five additional times through a 1.0-mm constriction. For nanofat processing, less force and a wider connector (2.1 to ~1.5 mm) were used. All samples were recentrifuged under identical conditions. In CELT<sup>plus</sup> samples, a distinct oil phase (&gt;50% of the total volume) was removed postcentrifugation. In nanofat samples, no separable oil phase was observed, and the entire volume was retained.</p></section></section><section id="ack1" class="ack"><h2 class="pmc_sec_title">Acknowledgments</h2>
<p>We thank M. C. Goess for providing adipose tissue samples for the validation study. Furthermore, we thank S. Lee for attentive reading and improvements of the manuscript.</p>
<section id="sec23"><p><strong>Funding:</strong> C.B., M.K., and M.A.P. received funding from the Deutsche Forschungsgemeinschaft (DFG) - 455422993 as part of the Research Unit FOR 5298 (iMAGO, subproject TP3, GZ: PL825/3-1). L.S.-P. and D.J. received funding from the European Research Council (ERC) under the European Union’s Horizon Europe research and innovation program under grant agreement no. 101041936 (EchoLux). The development of the microscopy system has received funding from the DFG, Germany (Gottfried Wilhelm Leibniz Prize 2013; NT 3/10-1), as well as from the ERC under the European Union’s Horizon 2020 research and innovation program under grant agreement no. 694968 (PREMSOT).</p></section><section id="sec24"><p><strong>Author contributions:</strong> Conceptualization: C.B., L.S.-P., D.J., M.A.P., and V.N. Formal analysis: C.B. Funding acquisition: V.N., D.J., and M.A.P. Investigation: C.B. and M.K. Methodology: C.B. and L.S.-P. Project administration: C.B. and M.A.P. Software: C.B. and L.S.-P. Resources: A.E., L.P., P.L., V.G., V.N., and M.A.P. Supervision: D.J. and M.A.P. Validation: C.B., M.K., and L.S.-P. Visualization: C.B., D.J., and M.A.P. Writing—original draft: C.B., M.K., L.S.-P., A.E., P.L., and M.A.P. Writing—review and editing: C.B., M.K., L.S.-P., L.P., V.G., D.J., and M.A.P.</p></section><section id="sec25"><p><strong>Competing interests:</strong> V.N. and M.A.P. are founders and equity owners of sThesis GmbH. V.N. is a founder and equity owner of Maurus OY, iThera Medical GmbH, Spear UG, and I3 Inc. A patent application (WO 2019 149 744 A1) licensed to sThesis GmbH, relevant to the technology discussed in this paper, has been filed. The other authors declare that they have no competing interests.</p></section><section id="sec26"><p><strong>Data and materials availability:</strong> The source code for image reconstruction used for BayROM was published along with an example image on Zenodo (<a href="https://doi.org/10.5281/zenodo.15222977" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://doi.org/10.5281/zenodo.15222977</a>). All data needed to evaluate the conclusions in the paper are present in the paper and/or the Supplementary Materials.</p></section></section><section id="sec27"><h2 class="pmc_sec_title">Supplementary Materials</h2>
<section id="sec28"><h3 class="pmc_sec_title">This PDF file includes:</h3>
<section class="sm xbox font-sm" id="supplementary-material1"><div class="caption p"><p>Figs. S1 to S5</p></div>
<div class="media p"><div class="caption">
<a href="/articles/instance/12372899/bin/sciadv.adu7319_sm.pdf" data-ga-action="click_feat_suppl" class="usa-link">sciadv.adu7319_sm.pdf</a><sup> (12.5MB, pdf) </sup>
</div></div></section></section></section><section id="ref-list1" class="ref-list"><h2 class="pmc_sec_title">REFERENCES AND NOTES</h2>
<section id="ref-list1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="R1">
<span class="label">1.</span><cite>Sambri A., Caldari E., Fiore M., Zucchini R., Giannini C., Pirini M. G., Spinnato P., Cappelli A., Donati D. M., De Paolis M., 
Margin assessment in soft tissue sarcomas: Review of the literature. Cancers (Basel)
13, 
1687 (2021).
</cite> [<a href="https://doi.org/10.3390/cancers13071687" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8038240/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33918457/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Cancers%20(Basel)&amp;title=Margin%20assessment%20in%20soft%20tissue%20sarcomas:%20Review%20of%20the%20literature&amp;volume=13&amp;publication_year=2021&amp;pages=1687&amp;pmid=33918457&amp;doi=10.3390/cancers13071687&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R2">
<span class="label">2.</span><cite>Alturkistani H. A., Tashkandi F. M., Mohammedsaleh Z. M., 
Histological stains: A literature review and case study. Glob. J. Health Sci.
8, 
72–79 (2015).</cite> [<a href="https://doi.org/10.5539/gjhs.v8n3p72" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4804027/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/26493433/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Glob.%20J.%20Health%20Sci.&amp;title=Histological%20stains:%20A%20literature%20review%20and%20case%20study&amp;volume=8&amp;publication_year=2015&amp;pages=72-79&amp;pmid=26493433&amp;doi=10.5539/gjhs.v8n3p72&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R3">
<span class="label">3.</span><cite>Prantl L., Eigenberger A., Reinhard R., Siegmund A., Heumann K., Felthaus O., 
Cell-enriched lipotransfer (CELT) improves tissue regeneration and rejuvenation without substantial manipulation of the adipose tissue graft. Cells
11, 
3159 (2022).
</cite> [<a href="https://doi.org/10.3390/cells11193159" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9563290/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36231121/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Cells&amp;title=Cell-enriched%20lipotransfer%20(CELT)%20improves%20tissue%20regeneration%20and%20rejuvenation%20without%20substantial%20manipulation%20of%20the%20adipose%20tissue%20graft&amp;volume=11&amp;publication_year=2022&amp;pages=3159&amp;pmid=36231121&amp;doi=10.3390/cells11193159&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R4">
<span class="label">4.</span><cite>Voskuil F. J., Vonk J., van der Vegt B., Kruijff S., Ntziachristos V., van der Zaag P. J., Witjes M. J. H., van Dam G. M., 
Intraoperative imaging in pathology-assisted surgery. Nat. Biomed. Eng.
6, 
503–514 (2022).
</cite> [<a href="https://doi.org/10.1038/s41551-021-00808-8" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34750537/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Nat.%20Biomed.%20Eng.&amp;title=Intraoperative%20imaging%20in%20pathology-assisted%20surgery&amp;volume=6&amp;publication_year=2022&amp;pages=503-514&amp;pmid=34750537&amp;doi=10.1038/s41551-021-00808-8&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R5">
<span class="label">5.</span><cite>Pertzborn D., Nguyen H.-N., Hüttmann K., Prengel J., Ernst G., Guntinas-Lichius O., von Eggeling F., Hoffmann F., 
Intraoperative assessment of tumor margins in tissue sections with hyperspectral imaging and machine learning. Cancers (Basel)
15, 
213 (2022).
</cite> [<a href="https://doi.org/10.3390/cancers15010213" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9818424/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36612208/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Cancers%20(Basel)&amp;title=Intraoperative%20assessment%20of%20tumor%20margins%20in%20tissue%20sections%20with%20hyperspectral%20imaging%20and%20machine%20learning&amp;volume=15&amp;publication_year=2022&amp;pages=213&amp;pmid=36612208&amp;doi=10.3390/cancers15010213&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R6">
<span class="label">6.</span><cite>Cao R., Nelson S. D., Davis S., Liang Y., Luo Y., Zhang Y., Crawford B., Wang L. V., 
Label-free intraoperative histology of bone tissue via deep-learning-assisted ultraviolet photoacoustic microscopy. Nat. Biomed. Eng.
7, 
124–134 (2023).
</cite> [<a href="https://doi.org/10.1038/s41551-022-00940-z" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10321243/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36123403/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Nat.%20Biomed.%20Eng.&amp;title=Label-free%20intraoperative%20histology%20of%20bone%20tissue%20via%20deep-learning-assisted%20ultraviolet%20photoacoustic%20microscopy&amp;volume=7&amp;publication_year=2023&amp;pages=124-134&amp;pmid=36123403&amp;doi=10.1038/s41551-022-00940-z&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R7">
<span class="label">7.</span><cite>Baik J. W., Kim H., Son M., Choi J., Kim K. G., Baek J. H., Park Y. H., An J., Choi H. Y., Ryu S. Y., Kim J. Y., Byun K., Kim C., 
Intraoperative label-free photoacoustic histopathology of clinical specimens. Laser Photonics Rev.
15, 
2100124 (2021).</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Laser%20Photonics%20Rev.&amp;title=Intraoperative%20label-free%20photoacoustic%20histopathology%20of%20clinical%20specimens&amp;volume=15&amp;publication_year=2021&amp;pages=2100124&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R8">
<span class="label">8.</span><cite>Jeon S., Kim J., Lee D., Baik J. W., Kim C., 
Review on practical photoacoustic microscopy. Photoacoustics
15, 
100141 (2019).
</cite> [<a href="https://doi.org/10.1016/j.pacs.2019.100141" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6710377/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31463194/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Photoacoustics&amp;title=Review%20on%20practical%20photoacoustic%20microscopy&amp;volume=15&amp;publication_year=2019&amp;pages=100141&amp;pmid=31463194&amp;doi=10.1016/j.pacs.2019.100141&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R9">
<span class="label">9.</span><cite>Liu Z., Chen L., Cheng H., Ao J., Xiong J., Liu X., Chen Y., Mao Y., Ji M., 
Virtual formalin-fixed and paraffin-embedded staining of fresh brain tissue via stimulated Raman CycleGAN model. Sci. Adv.
10, 
eadn3426 (2024).
</cite> [<a href="https://doi.org/10.1126/sciadv.adn3426" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10971418/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38536925/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Sci.%20Adv.&amp;title=Virtual%20formalin-fixed%20and%20paraffin-embedded%20staining%20of%20fresh%20brain%20tissue%20via%20stimulated%20Raman%20CycleGAN%20model&amp;volume=10&amp;publication_year=2024&amp;pages=eadn3426&amp;pmid=38536925&amp;doi=10.1126/sciadv.adn3426&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R10">
<span class="label">10.</span><cite>Deán-Ben X. L., López-Schier H., Razansky D., 
Optoacoustic micro-tomography at 100 volumes per second. Sci. Rep.
7, 
6850 (2017).
</cite> [<a href="https://doi.org/10.1038/s41598-017-06554-9" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC5537301/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/28761048/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Sci.%20Rep.&amp;title=Optoacoustic%20micro-tomography%20at%20100%20volumes%20per%20second&amp;volume=7&amp;publication_year=2017&amp;pages=6850&amp;pmid=28761048&amp;doi=10.1038/s41598-017-06554-9&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R11">
<span class="label">11.</span><cite>Wang L., Maslov K., Yao J., Rao B., Wang L. V., 
Fast voice-coil scanning optical-resolution photoacoustic microscopy. Opt. Lett.
36, 
139–141 (2011).
</cite> [<a href="https://doi.org/10.1364/OL.36.000139" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3086411/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/21263479/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Opt.%20Lett.&amp;title=Fast%20voice-coil%20scanning%20optical-resolution%20photoacoustic%20microscopy&amp;volume=36&amp;publication_year=2011&amp;pages=139-141&amp;pmid=21263479&amp;doi=10.1364/OL.36.000139&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R12">
<span class="label">12.</span><cite>Chen M., Duan X., Lan B., Vu T., Zhu X., Rong Q., Yang W., Hoffmann U., Zou J., Yao J., 
High-speed functional photoacoustic microscopy using a water-immersible two-axis torsion-bending scanner. Photoacoustics
24, 
100309 (2021).
</cite> [<a href="https://doi.org/10.1016/j.pacs.2021.100309" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8674646/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34956833/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Photoacoustics&amp;title=High-speed%20functional%20photoacoustic%20microscopy%20using%20a%20water-immersible%20two-axis%20torsion-bending%20scanner&amp;volume=24&amp;publication_year=2021&amp;pages=100309&amp;pmid=34956833&amp;doi=10.1016/j.pacs.2021.100309&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R13">
<span class="label">13.</span><cite>Kim J. Y., Lee C., Park K., Lim G., Kim C., 
Fast optical-resolution photoacoustic microscopy using a 2-axis water-proofing MEMS scanner. Sci. Rep.
5, 
7932 (2015).
</cite> [<a href="https://doi.org/10.1038/srep07932" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4300456/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/25604654/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Sci.%20Rep.&amp;title=Fast%20optical-resolution%20photoacoustic%20microscopy%20using%20a%202-axis%20water-proofing%20MEMS%20scanner&amp;volume=5&amp;publication_year=2015&amp;pages=7932&amp;pmid=25604654&amp;doi=10.1038/srep07932&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R14">
<span class="label">14.</span><cite>Chen J., Zhang Y., He L., Liang Y., Wang L., 
Wide-field polygon-scanning photoacoustic microscopy of oxygen saturation at 1-MHz A-line rate. Photoacoustics
20, 
100195 (2020).
</cite> [<a href="https://doi.org/10.1016/j.pacs.2020.100195" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7300162/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32577378/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Photoacoustics&amp;title=Wide-field%20polygon-scanning%20photoacoustic%20microscopy%20of%20oxygen%20saturation%20at%201-MHz%20A-line%20rate&amp;volume=20&amp;publication_year=2020&amp;pages=100195&amp;pmid=32577378&amp;doi=10.1016/j.pacs.2020.100195&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R15">
<span class="label">15.</span><cite>Kim J. Y., Lee C., Park K., Han S., Kim C., 
High-speed and high-SNR photoacoustic microscopy based on a galvanometer mirror in non-conducting liquid. Sci. Rep.
6, 
34803 (2016).
</cite> [<a href="https://doi.org/10.1038/srep34803" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC5052531/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27708379/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Sci.%20Rep.&amp;title=High-speed%20and%20high-SNR%20photoacoustic%20microscopy%20based%20on%20a%20galvanometer%20mirror%20in%20non-conducting%20liquid&amp;volume=6&amp;publication_year=2016&amp;pages=34803&amp;pmid=27708379&amp;doi=10.1038/srep34803&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R16">
<span class="label">16.</span><cite>Pleitez M. A., Khan A. A., Soldà A., Chmyrov A., Reber J., Gasparin F., Seeger M. R., Schätz B., Herzig S., Scheideler M., Ntziachristos V., 
Label-free metabolic imaging by mid-infrared optoacoustic microscopy in living cells. Nat. Biotechnol.
38, 
293–296 (2020).
</cite> [<a href="https://doi.org/10.1038/s41587-019-0359-9" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31873214/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Nat.%20Biotechnol.&amp;title=Label-free%20metabolic%20imaging%20by%20mid-infrared%20optoacoustic%20microscopy%20in%20living%20cells&amp;volume=38&amp;publication_year=2020&amp;pages=293-296&amp;pmid=31873214&amp;doi=10.1038/s41587-019-0359-9&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R17">
<span class="label">17.</span><cite>Zhang B., Sun M., Yang Y., Chen L., Zou X., Yang T., Hua Y., Ji M., 
Rapid, large-scale stimulated Raman histology with strip mosaicing and dual-phase detection. Biomed. Opt. Express
9, 
2604–2613 (2018).
</cite> [<a href="https://doi.org/10.1364/BOE.9.002604" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6154204/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/30258676/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Biomed.%20Opt.%20Express&amp;title=Rapid,%20large-scale%20stimulated%20Raman%20histology%20with%20strip%20mosaicing%20and%20dual-phase%20detection&amp;volume=9&amp;publication_year=2018&amp;pages=2604-2613&amp;pmid=30258676&amp;doi=10.1364/BOE.9.002604&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R18">
<span class="label">18.</span><cite>Davoudi N., Deán-Ben X. L., Razansky D., 
Deep learning optoacoustic tomography with sparse data. Nat. Mach. Intell.
1, 
453–460 (2019).</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Nat.%20Mach.%20Intell.&amp;title=Deep%20learning%20optoacoustic%20tomography%20with%20sparse%20data&amp;volume=1&amp;publication_year=2019&amp;pages=453-460&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R19">
<span class="label">19.</span><cite>Zhou J., He D., Shang X., Guo Z., Chen S.-L., Luo J., 
Photoacoustic microscopy with sparse data by convolutional neural networks. Photoacoustics
22, 
100242 (2021).
</cite> [<a href="https://doi.org/10.1016/j.pacs.2021.100242" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7973247/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33763327/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Photoacoustics&amp;title=Photoacoustic%20microscopy%20with%20sparse%20data%20by%20convolutional%20neural%20networks&amp;volume=22&amp;publication_year=2021&amp;pages=100242&amp;pmid=33763327&amp;doi=10.1016/j.pacs.2021.100242&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R20">
<span class="label">20.</span><cite>DiSpirito A. III, Li D., Vu T., Chen M., Zhang D., Luo J., Horstmeyer R., Yao J., 
Reconstructing undersampled photoacoustic microscopy images using deep learning. IEEE Trans. Med. Imaging
40, 
562–570 (2021).
</cite> [<a href="https://doi.org/10.1109/TMI.2020.3031541" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7858223/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33064648/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans.%20Med.%20Imaging&amp;title=Reconstructing%20undersampled%20photoacoustic%20microscopy%20images%20using%20deep%20learning&amp;volume=40&amp;publication_year=2021&amp;pages=562-570&amp;pmid=33064648&amp;doi=10.1109/TMI.2020.3031541&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R21">
<span class="label">21.</span><cite>Vu T., DiSpirito A. III, Li D., Wang Z., Zhu X., Chen M., Jiang L., Zhang D., Luo J., Zhang Y. S., Zhou Q., Horstmeyer R., Yao J., 
Deep image prior for undersampling high-speed photoacoustic microscopy. Photoacoustics
22, 
100266 (2021).
</cite> [<a href="https://doi.org/10.1016/j.pacs.2021.100266" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8056431/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33898247/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Photoacoustics&amp;title=Deep%20image%20prior%20for%20undersampling%20high-speed%20photoacoustic%20microscopy&amp;volume=22&amp;publication_year=2021&amp;pages=100266&amp;pmid=33898247&amp;doi=10.1016/j.pacs.2021.100266&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R22">
<span class="label">22.</span><cite>He D., Zhou J., Shang X., Tang X., Luo J., Chen S.-L., 
De-noising of photoacoustic microscopy images by attentive generative adversarial network. IEEE Trans. Med. Imaging
42, 
1349–1362 (2023).
</cite> [<a href="https://doi.org/10.1109/TMI.2022.3227105" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37015584/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans.%20Med.%20Imaging&amp;title=De-noising%20of%20photoacoustic%20microscopy%20images%20by%20attentive%20generative%20adversarial%20network&amp;volume=42&amp;publication_year=2023&amp;pages=1349-1362&amp;pmid=37015584&amp;doi=10.1109/TMI.2022.3227105&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R23">
<span class="label">23.</span><cite>Siregar S., Nagaoka R., Haq I. U., Saijo Y., 
Non local means denoising in photoacoustic imaging. Jpn. J. Appl. Phys.
57, 
07LB06 (2018).</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Jpn.%20J.%20Appl.%20Phys.&amp;title=Non%20local%20means%20denoising%20in%20photoacoustic%20imaging&amp;volume=57&amp;publication_year=2018&amp;pages=07LB06&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R24">
<span class="label">24.</span><cite>Allman D., Reiter A., Bell M. A. L., 
Photoacoustic source detection and reflection artifact removal enabled by deep learning. IEEE Trans. Med. Imaging
37, 
1464–1477 (2018).
</cite> [<a href="https://doi.org/10.1109/TMI.2018.2829662" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6075868/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/29870374/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans.%20Med.%20Imaging&amp;title=Photoacoustic%20source%20detection%20and%20reflection%20artifact%20removal%20enabled%20by%20deep%20learning&amp;volume=37&amp;publication_year=2018&amp;pages=1464-1477&amp;pmid=29870374&amp;doi=10.1109/TMI.2018.2829662&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R25">
<span class="label">25.</span><cite>Hariri A., Alipour K., Mantri Y., Schulze J. P., Jokerst J. V., 
Deep learning improves contrast in low-fluence photoacoustic imaging. Biomed. Opt. Express
11, 
3360–3373 (2020).
</cite> [<a href="https://doi.org/10.1364/BOE.395683" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7316023/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32637260/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Biomed.%20Opt.%20Express&amp;title=Deep%20learning%20improves%20contrast%20in%20low-fluence%20photoacoustic%20imaging&amp;volume=11&amp;publication_year=2020&amp;pages=3360-3373&amp;pmid=32637260&amp;doi=10.1364/BOE.395683&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R26">
<span class="label">26.</span><cite>Bouchard C., Wiesner T., Deschênes A., Bilodeau A., Turcotte B., Gagné C., Lavoie-Cardinal F., 
Resolution enhancement with a task-assisted GAN to guide optical nanoscopy image analysis and acquisition. Nat. Mach. Intell.
5, 
830–844 (2023).
</cite> [<a href="https://doi.org/10.1038/s42256-023-00689-3" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10442226/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37615032/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Nat.%20Mach.%20Intell.&amp;title=Resolution%20enhancement%20with%20a%20task-assisted%20GAN%20to%20guide%20optical%20nanoscopy%20image%20analysis%20and%20acquisition&amp;volume=5&amp;publication_year=2023&amp;pages=830-844&amp;pmid=37615032&amp;doi=10.1038/s42256-023-00689-3&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R27">
<span class="label">27.</span><cite>Yang Q., Yan P., Zhang Y., Yu H., Shi Y., Mou X., Kalra M. K., Zhang Y., Sun L., Wang G., 
Low-dose CT image denoising using a generative adversarial network with Wasserstein distance and perceptual loss. IEEE Trans. Med. Imaging
37, 
1348–1357 (2018).
</cite> [<a href="https://doi.org/10.1109/TMI.2018.2827462" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6021013/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/29870364/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans.%20Med.%20Imaging&amp;title=Low-dose%20CT%20image%20denoising%20using%20a%20generative%20adversarial%20network%20with%20Wasserstein%20distance%20and%20perceptual%20loss&amp;volume=37&amp;publication_year=2018&amp;pages=1348-1357&amp;pmid=29870364&amp;doi=10.1109/TMI.2018.2827462&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R28">
<span class="label">28.</span><cite>Mishra D., Chaudhury S., Sarkar M., Soin A. S., 
Ultrasound image enhancement using structure oriented adversarial network. IEEE Signal Process Lett.
25, 
1349–1353 (2018).</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Signal%20Process%20Lett.&amp;title=Ultrasound%20image%20enhancement%20using%20structure%20oriented%20adversarial%20network&amp;volume=25&amp;publication_year=2018&amp;pages=1349-1353&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R29">
<span class="label">29.</span><cite>Suzuki K., 
Overview of deep learning in medical imaging. Radiol. Phys. Technol.
10, 
257–273 (2017).
</cite> [<a href="https://doi.org/10.1007/s12194-017-0406-5" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/28689314/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Radiol.%20Phys.%20Technol.&amp;title=Overview%20of%20deep%20learning%20in%20medical%20imaging&amp;volume=10&amp;publication_year=2017&amp;pages=257-273&amp;pmid=28689314&amp;doi=10.1007/s12194-017-0406-5&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R30">
<span class="label">30.</span><cite>Donoho D. L., 
Compressed sensing. IEEE Trans. Inf. Theory
52, 
1289–1306 (2006).</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans.%20Inf.%20Theory&amp;title=Compressed%20sensing&amp;volume=52&amp;publication_year=2006&amp;pages=1289-1306&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R31">
<span class="label">31.</span><cite>Haltmeier M., Berer T., Moon S., Burgholzer P., 
Compressed sensing and sparsity in photoacoustic tomography. J. Opt.
18, 
114004 (2016).</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=J.%20Opt.&amp;title=Compressed%20sensing%20and%20sparsity%20in%20photoacoustic%20tomography&amp;volume=18&amp;publication_year=2016&amp;pages=114004&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R32">
<span class="label">32.</span><cite>A. Béché, B. Goris, B. Freitag, J. Verbeeck, “Compressed sensing for beam sensitive materials imaging in Scanning Transmission Electron Microscopy” in <em>European Microscopy Congress 2016: Proceedings</em> (Wiley, 2016); 10.1002/9783527808465.emc2016.6174.</cite> [<a href="https://doi.org/10.1002/9783527808465.emc2016.6174" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>]</li>
<li id="R33">
<span class="label">33.</span><cite>H. S. Anderson, J. Ilic-Helms, B. Rohrer, J. Wheeler, K. Larson, “Sparse Imaging for Fast Electron Microscopy” in <em>Computational Imaging XI</em>, C. A. Bouman, I. Pollak, P. J. Wolfe, Eds. (SPIE, 2013) vol. 8657, pp. 86570C.</cite> [<a href="https://scholar.google.com/scholar_lookup?H.%20S.%20Anderson,%20J.%20Ilic-Helms,%20B.%20Rohrer,%20J.%20Wheeler,%20K.%20Larson,%20%E2%80%9CSparse%20Imaging%20for%20Fast%20Electron%20Microscopy%E2%80%9D%20in%20Computational%20Imaging%20XI,%20C.%20A.%20Bouman,%20I.%20Pollak,%20P.%20J.%20Wolfe,%20Eds.%20(SPIE,%202013)%20vol.%208657,%20pp.%2086570C." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R34">
<span class="label">34.</span><cite>Ortega E., Nicholls D., Browning N. D., de Jonge N., 
High temporal-resolution scanning transmission electron microscopy using sparse-serpentine scan pathways. Sci. Rep.
11, 
22722 (2021).
</cite> [<a href="https://doi.org/10.1038/s41598-021-02052-1" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8608981/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34811427/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Sci.%20Rep.&amp;title=High%20temporal-resolution%20scanning%20transmission%20electron%20microscopy%20using%20sparse-serpentine%20scan%20pathways&amp;volume=11&amp;publication_year=2021&amp;pages=22722&amp;pmid=34811427&amp;doi=10.1038/s41598-021-02052-1&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R35">
<span class="label">35.</span><cite>Ju F., Sun Y., Gao J., Hu Y., Yin B., 
Nonparametric tensor dictionary learning with beta process priors. Neurocomputing
218, 
120–130 (2016).</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Neurocomputing&amp;title=Nonparametric%20tensor%20dictionary%20learning%20with%20beta%20process%20priors&amp;volume=218&amp;publication_year=2016&amp;pages=120-130&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R36">
<span class="label">36.</span><cite>Monier E., Oberlin T., Brun N., Li X., Tencé M., Dobigeon N., 
Fast reconstruction of atomic-scale STEM-EELS images from sparse sampling. Ultramicroscopy
215, 
112993 (2020).
</cite> [<a href="https://doi.org/10.1016/j.ultramic.2020.112993" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32516700/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Ultramicroscopy&amp;title=Fast%20reconstruction%20of%20atomic-scale%20STEM-EELS%20images%20from%20sparse%20sampling&amp;volume=215&amp;publication_year=2020&amp;pages=112993&amp;pmid=32516700&amp;doi=10.1016/j.ultramic.2020.112993&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R37">
<span class="label">37.</span><cite>Tran V. V. T., Hong K. Y., Jin X., Chang H., 
Histological comparison of nanofat and lipoconcentrate: Enhanced effects of lipoconcentrate on adipogenesis and angiogenesis. Aesthetic Plast. Surg.
48, 
752–763 (2024).
</cite> [<a href="https://doi.org/10.1007/s00266-023-03583-w" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/37648930/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Aesthetic%20Plast.%20Surg.&amp;title=Histological%20comparison%20of%20nanofat%20and%20lipoconcentrate:%20Enhanced%20effects%20of%20lipoconcentrate%20on%20adipogenesis%20and%20angiogenesis&amp;volume=48&amp;publication_year=2024&amp;pages=752-763&amp;pmid=37648930&amp;doi=10.1007/s00266-023-03583-w&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R38">
<span class="label">38.</span><cite>J. Knollmüller, T. A. Enßlin, Metric Gaussian variational inference. arXiv: 1901.11033 (2019).</cite>
</li>
<li id="R39">
<span class="label">39.</span><cite>Nseir I., Delaunay F., Latrobe C., Bonmarchand A., Coquerel-Beghin D., Auquit-Auckbur I., 
Use of adipose tissue and stromal vascular fraction in hand surgery. Orthop. Traumatol. Surg. Res.
103, 
927–932 (2017).
</cite> [<a href="https://doi.org/10.1016/j.otsr.2017.05.017" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/28645702/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Orthop.%20Traumatol.%20Surg.%20Res.&amp;title=Use%20of%20adipose%20tissue%20and%20stromal%20vascular%20fraction%20in%20hand%20surgery&amp;volume=103&amp;publication_year=2017&amp;pages=927-932&amp;pmid=28645702&amp;doi=10.1016/j.otsr.2017.05.017&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R40">
<span class="label">40.</span><cite>Eigenberger A., Felthaus O., Schratzenstaller T., Haerteis S., Utpatel K., Prantl L., 
The effects of shear force-based processing of lipoaspirates on white adipose tissue and the differentiation potential of adipose derived stem cells. Cells
11, 
2543 (2022).
</cite> [<a href="https://doi.org/10.3390/cells11162543" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9406387/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/36010620/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Cells&amp;title=The%20effects%20of%20shear%20force-based%20processing%20of%20lipoaspirates%20on%20white%20adipose%20tissue%20and%20the%20differentiation%20potential%20of%20adipose%20derived%20stem%20cells&amp;volume=11&amp;publication_year=2022&amp;pages=2543&amp;pmid=36010620&amp;doi=10.3390/cells11162543&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R41">
<span class="label">41.</span><cite>Selig M., Bell M. R., Junklewitz H., Oppermann N., Reinecke M., Greiner M., Pachajoa C., Enßlin T. A., 
NIFTY – Numerical Information Field Theory. Astron Astrophys
554, 
A26 (2013).</cite> [<a href="https://scholar.google.com/scholar_lookup?journal=Astron%20Astrophys&amp;title=NIFTY%20%E2%80%93%20Numerical%20Information%20Field%20Theory&amp;volume=554&amp;publication_year=2013&amp;pages=A26&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="R42">
<span class="label">42.</span><cite>T. Steininger, J. Dixit, P. Frank, M. Greiner, S. Hutschenreuter, J. Knollmüller, R. Leike, N. Porqueres, D. Pumpe, M. Reinecke, M. Šraml, C. Varady, T. Enßlin, NIFTy 3 - Numerical Information Field Theory - A Python framework for multicomponent signal inference on HPC clusters. arXiv:1708.01073 (2017).</cite>
</li>
<li id="R43">
<span class="label">43.</span><cite>J. Knollmüller, T. A. Enßlin, Encoding prior knowledge in the structure of the likelihood. arXiv:1812.04403 (2018).</cite>
</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adsm93_" lang="en" class="supplementary-materials"><h3 class="pmc_sec_title">Supplementary Materials</h3>
<section class="sm xbox font-sm" id="db_ds_supplementary-material1_reqid_"><div class="caption p"><p>Figs. S1 to S5</p></div>
<div class="media p"><div class="caption">
<a href="/articles/instance/12372899/bin/sciadv.adu7319_sm.pdf" data-ga-action="click_feat_suppl" class="usa-link">sciadv.adu7319_sm.pdf</a><sup> (12.5MB, pdf) </sup>
</div></div></section></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from Science Advances are provided here courtesy of <strong>American Association for the Advancement of Science</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1126/sciadv.adu7319"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/sciadv.adu7319.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (2.6 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12372899/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12372899/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12372899%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12372899/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12372899/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12372899/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40845115/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12372899/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40845115/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12372899/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12372899/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="K0sLYkyCBGybWsVhnyJGpsDCR6igUIq0GH7GCygN3OvvSL7csNGWuvOCTSbWkqls">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
        <script type="module" crossorigin="" src="/static/assets/math-574fdcc6.js"></script>
    
    

    </body>
</html>
