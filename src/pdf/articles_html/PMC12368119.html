
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            Automatic detection of cognitive events using machine learning and understanding models’ interpretations of human cognition - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="D2E4AD888AF2F2B305AD88004605499F.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="scirep">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12368119/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="Scientific Reports">
<meta name="citation_title" content="Automatic detection of cognitive events using machine learning and understanding models’ interpretations of human cognition">
<meta name="citation_author" content="Quang Dang">
<meta name="citation_author_institution" content="Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, Baltimore, MD 21250 USA">
<meta name="citation_author" content="Murat Kucukosmanoglu">
<meta name="citation_author_institution" content="D-Prime LLC, McLean, VA 22101 USA">
<meta name="citation_author" content="Michael Anoruo">
<meta name="citation_author_institution" content="Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, Baltimore, MD 21250 USA">
<meta name="citation_author" content="Golshan Kargosha">
<meta name="citation_author_institution" content="D-Prime LLC, McLean, VA 22101 USA">
<meta name="citation_author" content="Sarah Conklin">
<meta name="citation_author_institution" content="Center for Women’s Biobehavioral Health Research, Department of Psychiatry, University of Pittsburgh Medical Center, Pittsburgh, PA 15219 USA">
<meta name="citation_author" content="Justin Brooks">
<meta name="citation_author_institution" content="Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, Baltimore, MD 21250 USA">
<meta name="citation_author_institution" content="D-Prime LLC, McLean, VA 22101 USA">
<meta name="citation_publication_date" content="2025 Aug 20">
<meta name="citation_volume" content="15">
<meta name="citation_firstpage" content="30506">
<meta name="citation_doi" content="10.1038/s41598-025-16165-4">
<meta name="citation_pmid" content="40836059">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12368119/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12368119/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12368119/pdf/41598_2025_Article_16165.pdf">
<meta name="description" content="The pupillary response is a valuable indicator of cognitive workload, capturing fluctuations in attention and arousal governed by the autonomic nervous system. Cognitive events, defined as the initiation of mental processes, are closely linked to ...">
<meta name="og:title" content="Automatic detection of cognitive events using machine learning and understanding models’ interpretations of human cognition">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="The pupillary response is a valuable indicator of cognitive workload, capturing fluctuations in attention and arousal governed by the autonomic nervous system. Cognitive events, defined as the initiation of mental processes, are closely linked to ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12368119/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12368119">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1038/s41598-025-16165-4"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/41598_2025_Article_16165.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12368119%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12368119/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12368119/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12368119/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-scirep.jpg" alt="Scientific Reports logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to Scientific Reports" title="Link to Scientific Reports" shape="default" href="http://www.nature.com/srep" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">Sci Rep</button></div>. 2025 Aug 20;15:30506. doi: <a href="https://doi.org/10.1038/s41598-025-16165-4" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1038/s41598-025-16165-4</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22Sci%20Rep%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sci%20Rep%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22Sci%20Rep%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22Sci%20Rep%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Automatic detection of cognitive events using machine learning and understanding models’ interpretations of human cognition</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Dang%20Q%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Quang Dang</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Quang Dang</span></h3>
<div class="p">
<sup>1</sup>Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, Baltimore, MD 21250 USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Dang%20Q%22%5BAuthor%5D" class="usa-link"><span class="name western">Quang Dang</span></a>
</div>
</div>
<sup>1,</sup><sup>✉</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kucukosmanoglu%20M%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Murat Kucukosmanoglu</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">Murat Kucukosmanoglu</span></h3>
<div class="p">
<sup>2</sup>D-Prime LLC, McLean, VA 22101 USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kucukosmanoglu%20M%22%5BAuthor%5D" class="usa-link"><span class="name western">Murat Kucukosmanoglu</span></a>
</div>
</div>
<sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Anoruo%20M%22%5BAuthor%5D" class="usa-link" aria-describedby="id3"><span class="name western">Michael Anoruo</span></a><div hidden="hidden" id="id3">
<h3><span class="name western">Michael Anoruo</span></h3>
<div class="p">
<sup>1</sup>Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, Baltimore, MD 21250 USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Anoruo%20M%22%5BAuthor%5D" class="usa-link"><span class="name western">Michael Anoruo</span></a>
</div>
</div>
<sup>1</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kargosha%20G%22%5BAuthor%5D" class="usa-link" aria-describedby="id4"><span class="name western">Golshan Kargosha</span></a><div hidden="hidden" id="id4">
<h3><span class="name western">Golshan Kargosha</span></h3>
<div class="p">
<sup>2</sup>D-Prime LLC, McLean, VA 22101 USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kargosha%20G%22%5BAuthor%5D" class="usa-link"><span class="name western">Golshan Kargosha</span></a>
</div>
</div>
<sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Conklin%20S%22%5BAuthor%5D" class="usa-link" aria-describedby="id5"><span class="name western">Sarah Conklin</span></a><div hidden="hidden" id="id5">
<h3><span class="name western">Sarah Conklin</span></h3>
<div class="p">
<sup>3</sup>Center for Women’s Biobehavioral Health Research, Department of Psychiatry, University of Pittsburgh Medical Center, Pittsburgh, PA 15219 USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Conklin%20S%22%5BAuthor%5D" class="usa-link"><span class="name western">Sarah Conklin</span></a>
</div>
</div>
<sup>3</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Brooks%20J%22%5BAuthor%5D" class="usa-link" aria-describedby="id6"><span class="name western">Justin Brooks</span></a><div hidden="hidden" id="id6">
<h3><span class="name western">Justin Brooks</span></h3>
<div class="p">
<sup>1</sup>Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, Baltimore, MD 21250 USA </div>
<div class="p">
<sup>2</sup>D-Prime LLC, McLean, VA 22101 USA </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Brooks%20J%22%5BAuthor%5D" class="usa-link"><span class="name western">Justin Brooks</span></a>
</div>
</div>
<sup>1,</sup><sup>2</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="Aff1">
<sup>1</sup>Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore County, Baltimore, MD 21250 USA </div>
<div id="Aff2">
<sup>2</sup>D-Prime LLC, McLean, VA 22101 USA </div>
<div id="Aff3">
<sup>3</sup>Center for Women’s Biobehavioral Health Research, Department of Psychiatry, University of Pittsburgh Medical Center, Pittsburgh, PA 15219 USA </div>
<div class="author-notes p"><div class="fn" id="_fncrsp93pmc__">
<sup>✉</sup><p class="display-inline">Corresponding author.</p>
</div></div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2025 Feb 10; Accepted 2025 Aug 13; Collection date 2025.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© The Author(s) 2025</div>
<p><strong>Open Access</strong> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="https://creativecommons.org/licenses/by/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://creativecommons.org/licenses/by/4.0/</a>.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12368119  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40836059/" class="usa-link">40836059</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="Abs1"><h2>Abstract</h2>
<p id="Par1">The pupillary response is a valuable indicator of cognitive workload, capturing fluctuations in attention and arousal governed by the autonomic nervous system. Cognitive events, defined as the initiation of mental processes, are closely linked to cognitive workload as they trigger cognitive responses. In this study, we detect cognitive events for the task-evoked pupillary response across four domains (vigilance, emotion processing, numerical reasoning, and short-term memory). The problem is framed as a binary classification. We train one generalized model and four task-specific models on 1-s pupil diameter and gaze position segments. Five models achieve MCC between 0.43 and 0.75. We report three key findings: (1) the generalized model reduces the specificity to enhance the sensitivity, illustrating the trade-off from specialization to generalization; (2) the permutation feature importance analyses show that both pupil dilation and gaze position contribute to model predictions, with task-specific models focusing on task-specific structure patterns to predict while the generalized model is using human cognitive responses; and (3) in an online simulation environment, models performance decreases by approximately 0.05 on MCC. The findings highlight the potential of machine learning applied to pupillary signals for rapid, individualized detection of cognitive events.</p>
<section id="kwd-group1" lang="en" class="kwd-group"><p><strong>Keywords:</strong> Cognitive events detection, Cognitive classification, Feature importance, Neural networks, Explainable AI, Machine learning, Deep learning</p></section><section id="kwd-group2" class="kwd-group"><p><strong>Subject terms:</strong> Human behaviour, Machine learning, Cognitive control, Computer science</p></section></section><section id="Sec1"><h2 class="pmc_sec_title">Introduction</h2>
<p id="Par2">Cognitive workload, the mental effort or cognitive demand associated with a specific task, constitutes a fundamental concept in human cognitive neuroscience. Interdisciplinary efforts to quantify cognitive workload in real time are of widespread interest with broad applications. It is a cornerstone concept in human cognitive neuroscience with widespread interest and diverse applications<sup><a href="#CR1" class="usa-link" aria-describedby="CR1">1</a></sup>. Understanding an individual’s cognitive workload provides insight into their mental state and cognitive status, enhancing personalized learning and real-time cognitive assessments. Innovative analytic tools and approaches such as machine learning have emerged for analyzing and estimating levels of cognitive workload from physiological signals obtained with electrophysiology<sup><a href="#CR2" class="usa-link" aria-describedby="CR2">2</a></sup>, electrocardiography<sup><a href="#CR3" class="usa-link" aria-describedby="CR3">3</a>,<a href="#CR4" class="usa-link" aria-describedby="CR4">4</a></sup>, electrodermal activity<sup><a href="#CR5" class="usa-link" aria-describedby="CR5">5</a></sup>, and eye tracking<sup><a href="#CR6" class="usa-link" aria-describedby="CR6">6</a></sup>.</p>
<p id="Par3">While multiple researchers classify the cognitive workload using machine learning<sup><a href="#CR7" class="usa-link" aria-describedby="CR7">7</a>–<a href="#CR9" class="usa-link" aria-describedby="CR9">9</a></sup>, there is no universal agreement on a method for quantifying the threshold between low and high workload. The results can vary depending on the dataset and methodology used. For example, Gupta et al. introduce a method for estimating cognitive workload using EEG data, functional brain connectivity, and deep learning algorithms<sup><a href="#CR2" class="usa-link" aria-describedby="CR2">2</a></sup>. Their approach achieves a classification accuracy of 80.87%. In this paper, we focus on predicting cognitive events using task?evoked pupillary responses (TEPR) as the dataset. Although several studies predict cognitive events using machine learning approaches<sup><a href="#CR10" class="usa-link" aria-describedby="CR10">10</a>,<a href="#CR11" class="usa-link" aria-describedby="CR11">11</a></sup>, the majority of researchers rely on EEG data to make these predictions, commonly known as event?related potentials<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup>. Multiple studies highlight the importance of TEPR in measuring cognitive workload<sup><a href="#CR6" class="usa-link" aria-describedby="CR6">6</a>,<a href="#CR13" class="usa-link" aria-describedby="CR13">13</a>,<a href="#CR14" class="usa-link" aria-describedby="CR14">14</a></sup> as an index of psychophysiologic arousal. However, it remains an open question whether a machine learning approach can utilize the TEPR as a cognitive event detector (i.e. detecting the onset of a cognitive task stimulus)</p>
<p id="Par4">TEPR is a change in pupil diameter that occurs in response to cognitive load. Evidence suggests that TEPR reflects the amount of cognitive effort required to perform the task. TEPR is observed during widespread cognitive processes<sup><a href="#CR15" class="usa-link" aria-describedby="CR15">15</a></sup> and has been proposed to function as both a gauge and a filter to optimize cognitive functioning<sup><a href="#CR16" class="usa-link" aria-describedby="CR16">16</a></sup>. TEPR focuses on attention<sup><a href="#CR17" class="usa-link" aria-describedby="CR17">17</a></sup>, auditory discrimination<sup><a href="#CR18" class="usa-link" aria-describedby="CR18">18</a></sup>, mathematical problem solving, visual working memory, long-term memory tasks<sup><a href="#CR19" class="usa-link" aria-describedby="CR19">19</a></sup>, multiple object tracking<sup><a href="#CR20" class="usa-link" aria-describedby="CR20">20</a></sup>, decision-making<sup><a href="#CR21" class="usa-link" aria-describedby="CR21">21</a></sup>, naming tasks<sup><a href="#CR22" class="usa-link" aria-describedby="CR22">22</a></sup>, and vigilance<sup><a href="#CR23" class="usa-link" aria-describedby="CR23">23</a></sup>. The dynamic changes in TEPR serve as essential tools for understanding cognitive processes, individual differences in cognitive abilities, resource allocation, and preferences<sup><a href="#CR24" class="usa-link" aria-describedby="CR24">24</a></sup>.</p>
<p id="Par5">In this paper, we aim to predict the onset of cognitive events that is the start of each TERP. While the majority of TEPR-related research focuses on estimating cognitive workload, only a limited number of studies investigate the prediction of cognitive event onset using TEPR data. Predicting cognitive events has several advantages over predicting cognitive workload. The cognitive workload requires a longer time to fully manifest as it reflects the mental effort required to complete a specific task. The prediction timeframe for workload varies based on the task’s duration and structure. In addition, the model typically predicts “low” or “high” states, which can be debatable to quantify the cognitive workload.</p>
<p id="Par6">In contrast, cognitive events are the external load because they introduce new information that requires mental processing and response. Predicting cognitive events offers the advantage of using shorter data segments. The average time for the pupil to fully react to a cognitive event is about 0.6–0.75 s<sup><a href="#CR25" class="usa-link" aria-describedby="CR25">25</a></sup>, and our target window is 1 s. In this timeframe, the physiological signal required for recognizing the cognitive events is fully manifested. Another advantage of cognitive events is the availability of ground-truth data. In TEPR, stimulus onset times are the ground truth because they indicate the start of cognitive events. Our prediction task is similar to event-related potential. The distinction is that event-related potentials are acquired from the EEG signal and the event can be from the cognitive, sensory, or motor domain<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup>. The cognitive events, in this paper, are limited to TERP and are measured exclusively through pupillary responses in TEPR.</p>
<p id="Par7">Several physiological signals are widely used to study human cognition, including electrocardiograms (ECG), electroencephalograms (EEG), and pupillometry. However, ECG and EEG present limitations for the scope of this study. ECG requires a longer time frame to measure features, e.g. approximately 30 s to calculate heart rate and heart variability<sup><a href="#CR26" class="usa-link" aria-describedby="CR26">26</a></sup>, approximately 5 min to calculate the frequency domain of heart rate variability<sup><a href="#CR27" class="usa-link" aria-describedby="CR27">27</a></sup>. Our target window for cognitive events is less than 5 s. EEG signals have a low signal-to-noise ratio, and difficulty in interpreting<sup><a href="#CR28" class="usa-link" aria-describedby="CR28">28</a></sup>. EEG data collection equipment is often expensive, cumbersome, and invasive for daily life usage. In contrast, eye-tracking equipment provides a noninvasive method for real-time pupillary measurement, using screen-mounted or wearable devices. The pupillary signal enables analysis within shorter time windows, with as little as 1 s of data<sup><a href="#CR29" class="usa-link" aria-describedby="CR29">29</a></sup>, and can provide insights into neurocognitive processes by capturing gaze patterns, pupil dilation, and saccade eye movements<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup>.</p>
<p id="Par8">This study addresses two central research questions: (1) Can pupillary signals be used to predict cognitive events, and how well do such predictions generalize across different cognitive domains? (2) Does the machine learning model detect cognitive stimuli based on cognitive responses, or does it rely on unrelated features that do not reflect cognitive processing?</p>
<p id="Par9">From an engineering perspective, we build machine learning models that take the pupillary signal (pupil diameter and gaze data) as inputs. The data comes from four TEPR tasks that sample four cognitive domains: vigilance, emotion processing, numerical processing, and short-term memory. We construct CNN models that can predict stimulus onset times, using 1-s segments of pupillary data. By translating the two research questions into two engineering objectives and adding one applied objective, we have three primary objectives for this study: </p>
<ol class="list" style="list-style-type:decimal">
<li><p id="Par10">We construct five machine learning models: four task-specific models corresponding to four cognitive tasks, and one generalized model trained on the entire dataset. We evaluate the performance of these five models and analyze the trade-off between task-specific specialization and cross-task generalization.</p></li>
<li><p id="Par11">We analyze the feature importance in each model. These features include human cognitive responses and unique task structures in each task. We evaluate the contribution of each feature to the model’s predictions.</p></li>
<li><p id="Par12">We assess the models’ performance in an online environment to assess their usability in real-time scenarios. Analyzing the trade-offs between online and offline environments allows us to understand the usability and limitations of the models in practical settings.</p></li>
</ol></section><section id="Sec2"><h2 class="pmc_sec_title">Results</h2>
<section id="Sec3"><h3 class="pmc_sec_title">Exploratory data analysis</h3>
<p id="Par14">This first section presented the exploratory data analysis. This section was necessary because some information would be needed for the sampling process in the “<a href="#Sec13" class="usa-link">Methodology</a>” and “<a href="#Sec8" class="usa-link">Discussion</a>” section. With more detail in the “<a href="#Sec14" class="usa-link">Material</a>” section, the dataset had four TEPR tasks: Dot Probe Task (DPT), Mental Arithmetic (MA), Psychomotor Vigilance Task (PVT), and Visual Working Memory (VWM). The stimulus onset time (ST) was the start of each trial. Focusing on pupil diameter, the majority of participants showed a median pupil diameter ranging from 3.5 to 4.5 mm with outliers, with outliers exceeding 5.5 mm or falling below 3 mm. The Fig. <a href="#Fig1" class="usa-link">1</a> showed the common pattern of pupil diameter response around ST.</p>
<figure class="fig xbox font-sm" id="Fig1"><h4 class="obj_head">Fig. 1.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12368119_41598_2025_16165_Fig1_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/a6b84b4a844c/41598_2025_16165_Fig1_HTML.jpg" loading="lazy" id="MO1" height="215" width="669" alt="Fig. 1"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>The mean pupil diameter changed after ST. The X-axis was time relative to the ST, while the Y-axis showed the change of the pupil diameter. Each line represented one task, and the “All-tasks” line showed the overall average for 4 tasks. Panel (<strong>a</strong>) averaged across 57 participants, panel (<strong>b</strong>) averaged across 3 tasks MA, PVT, and VWM, and panel (<strong>c</strong>) averaged for only the DPT task. In both panels (<strong>b</strong>) and (<strong>c</strong>), each line corresponded to one participant (color code shared). We limited 10 participants for display purposes.</p></figcaption></figure><p id="Par15">In panel a of Fig. <a href="#Fig1" class="usa-link">1</a>, all tasks except PVT showed an initial constriction lasting approximately 0.6 s, followed by dilation. By the end of this period, pupil diameter exceeded its initial size at ST, reflecting increased cognitive workload and sympathetic activation in response to new information<sup><a href="#CR31" class="usa-link" aria-describedby="CR31">31</a>,<a href="#CR32" class="usa-link" aria-describedby="CR32">32</a></sup>.</p>
<p id="Par16">The panel b showed the average response for ten participants on MA, PVT, and VWM tasks while the panel c showed the average response for DPT exclusively. We limited the visualization to the 10 participants with the most available data for display purposes. In DPT tasks, the pupil diameter constricted significantly compared to the other three tasks, attributed to the pupillary light reflex (PLR). In the DPT task, the screen displayed before the ST was relatively dim compared to when the ST was presented, resulting in a sudden increase in brightness, and triggering the PLR. This response accounted for most of the observed pupil constriction during the DPT task. After re-dilation, pupil diameter in some participants exceeded baseline levels, indicating cognitive workload similar to the other tasks.</p>
<p id="Par17">Moving on gaze position, Fig. <a href="#Fig2" class="usa-link">2</a> showed the average gaze position data for all participants using the same processing method as Fig. <a href="#Fig1" class="usa-link">1</a>. The unit was screen coordinates, where (0,0) represented the top-left corner and (1000,1000) indicated the bottom-right corner. The average values for Gaze X and Gaze Y were − 1.53 and 4.18, respectively; the average standard deviations for Gaze X was 77 and for Gaze Y was 60, respectively.</p>
<figure class="fig xbox font-sm" id="Fig2"><h4 class="obj_head">Fig. 2.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12368119_41598_2025_16165_Fig2_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/7c9c2507f17b/41598_2025_16165_Fig2_HTML.jpg" loading="lazy" id="MO2" height="340" width="651" alt="Fig. 2"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Mean gaze position changed after ST for each task. Panels for DPT, PVT, MA, and VWM displayed task-specific, while the “All-tasks” panel showed the average across all four tasks. The X-axis represented time relative to ST, and the Y-axis indicated the difference between gaze position at ST and at corresponding time points..</p></figcaption></figure><p id="Par18">Although the DPT tasks showed minimal eye movement within the time of interest, the MA and PVT tasks displayed saccadic eye movements between 0 and 0.5 s after ST, reflecting participants’ rapid gaze shifts toward new visual information. This shifting focus took about 0.5 s before the participant began processing the information presented.</p>
<p id="Par19">In the VWM tasks, after averaging, we observed high-frequency signals. The high frequencies were not due to noise but attributable to the multiple patterns that were caused by the structure of the VWM tasks. Unlike the other tasks, where participants focused on a specific point of interest after ST, the VWM tasks had varying difficulty levels, ranging from easy (one image) to hard (six images). This led to diverse gaze patterns and a lack of a consistent trend across the tasks.</p></section><section id="Sec4"><h3 class="pmc_sec_title">Machine learning architecture comparison</h3>
<p id="Par21">Table <a href="#Tab1" class="usa-link">1</a> showed the comparison of 4 architectures: convolution neural network (CNN), bidirectional long short-term memory (BiLSTM), simple recurrent neural network (RNN), and multilayer perceptron (MLP). We used three evaluation metrics: accuracy (ACC), F1 score (F1), and Matthews Correlation Coefficient (MCC), with MCC as the primary metric. As mentioned in the “<a href="#Sec15" class="usa-link">Sampling method</a>” section, we framed the problem as binary classification where the “0” sample indicated the absence of ST and the “1” sample indicated the presence of ST. Because the dataset was imbalanced in favor of the “0” samples, we applied the Synthetic Minority Oversampling Technique (SMOTE) technique to re-balance the class sample population. The SMOTE technique was applied to only the training set, but not to the testing set. As a result, during training, five models saw an equal number of “0” and “1” samples. Therefore, during the prediction, there was no statistical bias between the population between the “0” and “1” classes. Four task-specific models (“DPT”, “MA”, “PVT”, “VWM”) were trained and tested on their respective tasks, while the “All-task” model was trained and tested on the entire dataset.</p>
<section class="tw xbox font-sm" id="Tab1"><h4 class="obj_head">Table 1.</h4>
<div class="caption p"><p>Machine learning architecture comparison and result.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead>
<tr>
<th align="left" rowspan="2" colspan="2"></th>
<th align="left" colspan="3" rowspan="1">CNN</th>
<th align="left" colspan="3" rowspan="1">BiLSTM</th>
<th align="left" colspan="3" rowspan="1">RNN</th>
<th align="left" colspan="3" rowspan="1">MLP</th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1">ACC</th>
<th align="left" colspan="1" rowspan="1">F1</th>
<th align="left" colspan="1" rowspan="1">MCC</th>
<th align="left" colspan="1" rowspan="1">ACC</th>
<th align="left" colspan="1" rowspan="1">F1</th>
<th align="left" colspan="1" rowspan="1">MCC</th>
<th align="left" colspan="1" rowspan="1">ACC</th>
<th align="left" colspan="1" rowspan="1">F1</th>
<th align="left" colspan="1" rowspan="1">MCC</th>
<th align="left" colspan="1" rowspan="1">ACC</th>
<th align="left" colspan="1" rowspan="1">F1</th>
<th align="left" colspan="1" rowspan="1">MCC</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="5" colspan="1"> Model</td>
<td align="left" colspan="1" rowspan="1">“All-task”</td>
<td align="left" colspan="1" rowspan="1">0.78</td>
<td align="left" colspan="1" rowspan="1">0.73</td>
<td align="left" colspan="1" rowspan="1">0.55</td>
<td align="left" colspan="1" rowspan="1">0.78</td>
<td align="left" colspan="1" rowspan="1">0.73</td>
<td align="left" colspan="1" rowspan="1">0.55</td>
<td align="left" colspan="1" rowspan="1">0.62</td>
<td align="left" colspan="1" rowspan="1">0.54</td>
<td align="left" colspan="1" rowspan="1">0.22</td>
<td align="left" colspan="1" rowspan="1">0.77</td>
<td align="left" colspan="1" rowspan="1">0.73</td>
<td align="left" colspan="1" rowspan="1">0.54</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">“DPT”</td>
<td align="left" colspan="1" rowspan="1">0.88</td>
<td align="left" colspan="1" rowspan="1">0.83</td>
<td align="left" colspan="1" rowspan="1">0.75</td>
<td align="left" colspan="1" rowspan="1">0.89</td>
<td align="left" colspan="1" rowspan="1">0.83</td>
<td align="left" colspan="1" rowspan="1">0.75</td>
<td align="left" colspan="1" rowspan="1">0.64</td>
<td align="left" colspan="1" rowspan="1">0.55</td>
<td align="left" colspan="1" rowspan="1">0.26</td>
<td align="left" colspan="1" rowspan="1">0.87</td>
<td align="left" colspan="1" rowspan="1">0.82</td>
<td align="left" colspan="1" rowspan="1">0.72</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">“MA”</td>
<td align="left" colspan="1" rowspan="1">0.88</td>
<td align="left" colspan="1" rowspan="1">0.72</td>
<td align="left" colspan="1" rowspan="1">0.65</td>
<td align="left" colspan="1" rowspan="1">0.81</td>
<td align="left" colspan="1" rowspan="1">0.64</td>
<td align="left" colspan="1" rowspan="1">0.56</td>
<td align="left" colspan="1" rowspan="1">0.72</td>
<td align="left" colspan="1" rowspan="1">0.53</td>
<td align="left" colspan="1" rowspan="1">0.43</td>
<td align="left" colspan="1" rowspan="1">0.85</td>
<td align="left" colspan="1" rowspan="1">0.67</td>
<td align="left" colspan="1" rowspan="1">0.60</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">“PVT”</td>
<td align="left" colspan="1" rowspan="1">0.84</td>
<td align="left" colspan="1" rowspan="1">0.70</td>
<td align="left" colspan="1" rowspan="1">0.59</td>
<td align="left" colspan="1" rowspan="1">0.82</td>
<td align="left" colspan="1" rowspan="1">0.71</td>
<td align="left" colspan="1" rowspan="1">0.60</td>
<td align="left" colspan="1" rowspan="1">0.65</td>
<td align="left" colspan="1" rowspan="1">0.57</td>
<td align="left" colspan="1" rowspan="1">0.39</td>
<td align="left" colspan="1" rowspan="1">0.84</td>
<td align="left" colspan="1" rowspan="1">0.72</td>
<td align="left" colspan="1" rowspan="1">0.60</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">“VWM”</td>
<td align="left" colspan="1" rowspan="1">0.73</td>
<td align="left" colspan="1" rowspan="1">0.56</td>
<td align="left" colspan="1" rowspan="1">0.43</td>
<td align="left" colspan="1" rowspan="1">0.66</td>
<td align="left" colspan="1" rowspan="1">0.53</td>
<td align="left" colspan="1" rowspan="1">0.41</td>
<td align="left" colspan="1" rowspan="1">0.60</td>
<td align="left" colspan="1" rowspan="1">0.49</td>
<td align="left" colspan="1" rowspan="1">0.35</td>
<td align="left" colspan="1" rowspan="1">0.75</td>
<td align="left" colspan="1" rowspan="1">0.58</td>
<td align="left" colspan="1" rowspan="1">0.46</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p id="Par22">The results showed that the RNN architecture underperformed relative to the others. The other three architectures had similar performance levels within the margin of error. Therefore, for the remainder of the paper, we will focus exclusively on the CNN architecture, because CNN achieved marginally better results and benefited from faster computation due to its inherent parallelism while the BiLSTM processed data sequentially, as each time step depended on its previous step.</p></section><section id="Sec5"><h3 class="pmc_sec_title">CNN model performance</h3>
<p id="Par24">When the performance of the five CNN models in Table <a href="#Tab1" class="usa-link">1</a>, measured in MCC, the model ranking from worst to best was: “VWM”, “All-task”, “PVT”, “MA”, and “DPT” with the MCC of 0.43, 0.55, 0.59, 0.65, and 0.75 respectively. In general, the performance drop in the generalized “All-task” model compared to the specialized models (“VWM”, “MA”, “PVT”, and “DPT”) was expected. Four models, excluding “VWM”, achieved an MCC above 0.5, which was considered a good score. In Table <a href="#Tab2" class="usa-link">2</a>, we further broke down the results into specificity and sensitivity metrics to reveal the trade-offs between generalization and specialization.</p>
<section class="tw xbox font-sm" id="Tab2"><h4 class="obj_head">Table 2.</h4>
<div class="caption p"><p>Additional metric for five CNN models.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead>
<tr>
<th align="left" rowspan="2" colspan="2"></th>
<th align="left" colspan="4" rowspan="1">Metrics</th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1">Specificity</th>
<th align="left" colspan="1" rowspan="1">Sensitivity</th>
<th align="left" colspan="1" rowspan="1">Pearson</th>
<th align="left" colspan="1" rowspan="1">McNemar P-value</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="5" colspan="1"> Model</td>
<td align="left" colspan="1" rowspan="1">“All-task”</td>
<td align="left" colspan="1" rowspan="1">0.80</td>
<td align="left" colspan="1" rowspan="1">0.75</td>
<td align="left" colspan="1" rowspan="1">1.0</td>
<td align="left" colspan="1" rowspan="1">1.0</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">“DPT”</td>
<td align="left" colspan="1" rowspan="1">0.91</td>
<td align="left" colspan="1" rowspan="1">0.84</td>
<td align="left" colspan="1" rowspan="1">0.88</td>
<td align="left" colspan="1" rowspan="1">&lt; 0.001</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">“MA”</td>
<td align="left" colspan="1" rowspan="1">0.95</td>
<td align="left" colspan="1" rowspan="1">0.65</td>
<td align="left" colspan="1" rowspan="1">0.69</td>
<td align="left" colspan="1" rowspan="1">&lt; 0.001</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">“PVT”</td>
<td align="left" colspan="1" rowspan="1">0.89</td>
<td align="left" colspan="1" rowspan="1">0.70</td>
<td align="left" colspan="1" rowspan="1">0.77</td>
<td align="left" colspan="1" rowspan="1">&lt; 0.001</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">“VWM”</td>
<td align="left" colspan="1" rowspan="1">0.93</td>
<td align="left" colspan="1" rowspan="1">0.43</td>
<td align="left" colspan="1" rowspan="1">0.65</td>
<td align="left" colspan="1" rowspan="1">&lt; 0.001</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p id="Par25">In Table <a href="#Tab2" class="usa-link">2</a>, the generalized “All-task” model had the lowest specificity (0.80) and the second highest sensitivity value (0.75), behind the “DPT” model. By adding a variety of task types, the sensitivity increased at the expense of specificity. This demonstrated the trade-off between specialization (single-task) and generalization (four-task).</p>
<p id="Par26">We included the Pearson correlation coefficient and the p-value of the McNemar test to compare each specialized model against the generalized “All-task” model. The McNemar p-values for all four specialized models were less than 1E-3, indicating that their predictions were statistically distinguishable from the prediction of the generalized model. In addition, Pearson correlation coefficients showed that the predictions of the four specialized models were moderately to strongly correlated with the “All-task” model predictions. For the “All-task” model, both the Pearson correlation coefficient and the McNemar test p-value were 1.0 because of self-comparison.</p>
<p id="Par27">The “VWM” model displayed the lowest performance with an MCC score of 0.43. Its specificity value was compatible with that of the other three specialized models (“MA”, “PVT”, and “DPT”). Its low performance was due to a high number of false negatives. In the “<a href="#Sec8" class="usa-link">Discussion</a>” section, we discussed how the difficulty in predicting “1” samples for the “VWM” model was likely caused by differences in activation regions within the human brain.</p>
<p id="Par28">The next analysis examined the amount of data required to predict cognitive events. Table <a href="#Tab3" class="usa-link">3</a> showed the “All-task” model’s performance using a CNN architecture in four sample durations: 0.5 s, 1 s, 2 s, and 3  s. All other variables remained constant, except for the sample duration. The results showed that the windows of 0.5 s and 3 s underperformed. The 0.5-s window provided insufficient information for accurate prediction. The 3-s window included data that was not relevant (i.e. far distant from cognitive events), which introduced more noise than benefit to the model. The optimal window fell between 1 s and 2 s, with the 2-s duration marginally outperforming the 1-s duration. We chose 1-s windows as the primary duration due to diminishing returns. From 1 to 2 s, windows would require twice as much data and doubled prediction latency, and improved by only approximately 0.04 in MCC.</p>
<section class="tw xbox font-sm" id="Tab3"><h4 class="obj_head">Table 3.</h4>
<div class="caption p"><p>CNN model “All-task” with different duration.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead>
<tr>
<th align="left" rowspan="2" colspan="2"></th>
<th align="left" colspan="5" rowspan="1">“All-task” model</th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1">ACC</th>
<th align="left" colspan="1" rowspan="1">F1</th>
<th align="left" colspan="1" rowspan="1">MCC</th>
<th align="left" colspan="1" rowspan="1">Specificity</th>
<th align="left" colspan="1" rowspan="1">Sensitivity</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="4" colspan="1"> Model</td>
<td align="left" colspan="1" rowspan="1">0.5-s</td>
<td align="left" colspan="1" rowspan="1">0.72</td>
<td align="left" colspan="1" rowspan="1">0.65</td>
<td align="left" colspan="1" rowspan="1">0.42</td>
<td align="left" colspan="1" rowspan="1">0.74</td>
<td align="left" colspan="1" rowspan="1">0.69</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">1-s</td>
<td align="left" colspan="1" rowspan="1">0.78</td>
<td align="left" colspan="1" rowspan="1">0.73</td>
<td align="left" colspan="1" rowspan="1">0.55</td>
<td align="left" colspan="1" rowspan="1">0.80</td>
<td align="left" colspan="1" rowspan="1">0.75</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">2-s</td>
<td align="left" colspan="1" rowspan="1">0.8</td>
<td align="left" colspan="1" rowspan="1">0.76</td>
<td align="left" colspan="1" rowspan="1">0.59</td>
<td align="left" colspan="1" rowspan="1">0.79</td>
<td align="left" colspan="1" rowspan="1">0.80</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">3-s</td>
<td align="left" colspan="1" rowspan="1">0.73</td>
<td align="left" colspan="1" rowspan="1">0.71</td>
<td align="left" colspan="1" rowspan="1">0.47</td>
<td align="left" colspan="1" rowspan="1">0.74</td>
<td align="left" colspan="1" rowspan="1">0.72</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="Sec6"><h3 class="pmc_sec_title">Feature importance</h3>
<p id="Par29">We analyzed the factors influencing the model predictions by examining feature importance. Feature importance provided insights into which features the machine learning model relied on when making predictions. If pupil diameter was the primary predictor, it suggested that the model used human cognitive reaction for predicting. On the opposite, if the Gaze position was the dominant factor, it indicated that the model’s predictions were influenced more by the task structure itself, like when participants shifted their gaze position toward a specific point on the screen after the ST appeared.</p>
<p id="Par30">Figure <a href="#Fig3" class="usa-link">3</a> displayed feature importance permutation results for five models, using the calculation method mentioned in the “<a href="#Sec17" class="usa-link">Evaluation metric and feature importance algorithms</a>” section. We performed a T-statistic test between each feature and baseline. All p-values were less than 1E-3. This indicated that all features contributed to the prediction.</p>
<figure class="fig xbox font-sm" id="Fig3"><h4 class="obj_head">Fig. 3.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12368119_41598_2025_16165_Fig3_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/bd87eeef6fd4/41598_2025_16165_Fig3_HTML.jpg" loading="lazy" id="MO3" height="289" width="669" alt="Fig. 3"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>The figure shows feature importance for five models, with each panel corresponding to a specific model. The three features, Pupil Diameter, Gaze X, and Gaze Y, plotted with the performance drop after distortion. The “Baseline” column reports the non-distorted performance for comparison. All values reported in MCC.</p></figcaption></figure><p id="Par31">In the “MA”, “PVT”, and “VWM” models, we observed that gaze positions (Gaze X and Gaze Y) were the primary factors influencing the models’ predictions. In the “DPT” model, the pupil diameter was most significant contributing feature, with its contribution surpassing that of the other four tasks. Given the PLR effect occurred in the DPT task, the pupil diameter contributed in the DPT task more than to any other tasks, and the model mostly relied on PLR to make predictions. We considered PLR effect was part of the task’s structure because it only appeared in DPT tasks. Therefore, each task-specific model utilized its unique task structure to make predictions.</p>
<p id="Par32">In the generalized “All-task” model, pupil diameter and gaze position each contributed approximately half of the predictions. In the “<a href="#Sec8" class="usa-link">Discussion</a>” section, we argued that the generalized model gave more weight to the cognitive reaction factor. For a single task, the task structure would overshadow cognitive reactions, but as the variety of tasks increased, the contribution of human cognitive reactions became more important.</p>
<p id="Par33">The next question concerned whether the five models could rely solely on cognitive reactions to make predictions, without the task structure. We repeated all the experiments, with the only difference being the removal of gaze position features (Gaze X and Gaze Y). Table <a href="#Tab4" class="usa-link">4</a> had the same setup as Tables <a href="#Tab2" class="usa-link">2</a> and <a href="#Tab1" class="usa-link">1</a> for the CNN model, but without the gaze position features (Gaze X and Gaze Y), only pupil diameter. All performance metrics decreased because of the reduced amount of available data. The “DPT” model was excluded from the comparison due to the PLR effect. The four remaining models showed performance above the random guessing line, indicating that cognitive reactions alone could support prediction. The “All-task” model achieved the highest performance with a decrease of about 0.08 in MCC. The task-specific model “MA”, “PVT”, and “VWM” decreased between 0.13 to 0.24 in MCC without the support of gaze position. In addition, the Pearson correlation coefficient dropped to between 0.5 and 0.6, indicating reduced agreement between the models. These findings indicated that the generalized “All-task” model relied more on cognitive reactions than the specialized models.</p>
<section class="tw xbox font-sm" id="Tab4"><h4 class="obj_head">Table 4.</h4>
<div class="caption p"><p>Result for five CNN models using only pupil diameter feature.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead>
<tr>
<th align="left" rowspan="2" colspan="2"></th>
<th align="left" colspan="7" rowspan="1">CNN model</th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1">ACC</th>
<th align="left" colspan="1" rowspan="1">F1</th>
<th align="left" colspan="1" rowspan="1">MCC</th>
<th align="left" colspan="1" rowspan="1">Specificity</th>
<th align="left" colspan="1" rowspan="1">Sensitivity</th>
<th align="left" colspan="1" rowspan="1">Pearson</th>
<th align="left" colspan="1" rowspan="1">McNemar P-value</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="5" colspan="1"> Model</td>
<td align="left" colspan="1" rowspan="1">“All-task”</td>
<td align="left" colspan="1" rowspan="1">0.74</td>
<td align="left" colspan="1" rowspan="1">0.69</td>
<td align="left" colspan="1" rowspan="1">0.47</td>
<td align="left" colspan="1" rowspan="1">0.78</td>
<td align="left" colspan="1" rowspan="1">0.70</td>
<td align="left" colspan="1" rowspan="1">1.0</td>
<td align="left" colspan="1" rowspan="1">1.0</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">“DPT”</td>
<td align="left" colspan="1" rowspan="1">–</td>
<td align="left" colspan="1" rowspan="1">–</td>
<td align="left" colspan="1" rowspan="1">–</td>
<td align="left" colspan="1" rowspan="1">–</td>
<td align="left" colspan="1" rowspan="1">–</td>
<td align="left" colspan="1" rowspan="1">–</td>
<td align="left" colspan="1" rowspan="1">–</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">“MA”</td>
<td align="left" colspan="1" rowspan="1">0.78</td>
<td align="left" colspan="1" rowspan="1">0.53</td>
<td align="left" colspan="1" rowspan="1">0.41</td>
<td align="left" colspan="1" rowspan="1">0.91</td>
<td align="left" colspan="1" rowspan="1">0.44</td>
<td align="left" colspan="1" rowspan="1">0.57</td>
<td align="left" colspan="1" rowspan="1">&lt; 0.001</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">“PVT”</td>
<td align="left" colspan="1" rowspan="1">0.77</td>
<td align="left" colspan="1" rowspan="1">0.66</td>
<td align="left" colspan="1" rowspan="1">0.44</td>
<td align="left" colspan="1" rowspan="1">0.85</td>
<td align="left" colspan="1" rowspan="1">0.58</td>
<td align="left" colspan="1" rowspan="1">0.56</td>
<td align="left" colspan="1" rowspan="1">&lt; 0.001</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">“VWM”</td>
<td align="left" colspan="1" rowspan="1">0.71</td>
<td align="left" colspan="1" rowspan="1">0.47</td>
<td align="left" colspan="1" rowspan="1">0.30</td>
<td align="left" colspan="1" rowspan="1">0.88</td>
<td align="left" colspan="1" rowspan="1">0.38</td>
<td align="left" colspan="1" rowspan="1">0.51</td>
<td align="left" colspan="1" rowspan="1">&lt; 0.001</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="Sec7"><h3 class="pmc_sec_title">Online environment simulation</h3>
<p id="Par34">The previous results were evaluated in an experiment environment, where we had access to the complete dataset, allowing us to segment and evaluate time-series data. However, in real-time scenarios, data was not available at the start of experiments and was less controllable. The online environment required a different approach, where data became available incrementally, and models had to make predictions on the fly. To simulate the online environment, we modified the normalization process. Instead of using the entire dataset for normalization, we used the initial 60 s of data as a baseline and normalized the entire dataset using that baseline. This baseline continued to update as more data became available. For the sampling process, we used a 1-s data window and predicted once every 0.1 s. The remaining methodology was unchanged.</p>
<p id="Par35">Displaying all results would be impractical. Figure <a href="#Fig4" class="usa-link">4</a> showed a sample prediction of the “All-task” model for a 60-s interval for four different datasets from an arbitrary participant. For context, the average performance across participants was: <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq1"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/e6c0f03e11f7/d33e1026.gif" loading="lazy" id="d33e1026" alt="Inline graphic"></span> in accuracy, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq2"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/bef2b85f6ee8/d33e1032.gif" loading="lazy" id="d33e1032" alt="Inline graphic"></span> in F1 score, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq3"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/49e4ea564d53/d33e1038.gif" loading="lazy" id="d33e1038" alt="Inline graphic"></span> in MCC. The model predicted the majority of ST accurately. The most missing STs were from the “VWM” dataset. This highlights the “VWM” dataset’s lower performance relative to the other three.</p>
<figure class="fig xbox font-sm" id="Fig4"><h4 class="obj_head">Fig. 4.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12368119_41598_2025_16165_Fig4_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/4e917b04c053/41598_2025_16165_Fig4_HTML.jpg" loading="lazy" id="MO4" height="530" width="669" alt="Fig. 4"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Real-time prediction using the “All-task” model on a single participant. The performance metrics for this participant are displayed in the title. The initial 60 s (0–60 s) are reserved for data normalization, and the subsequent 60 s (60–120 s) display prediction. The red dotted line indicated ST, and the blue line indicates the model’s predicted probability: 1 was ST presence, 0 was ST absence, and values near 0.5 reflect uncertainty in prediction.</p></figcaption></figure><p id="Par36">In instances where no ST, the model outputted probabilities below 0.5, indicating the absence of cognitive events. Occasionally, we observed peaks in model predictions exceeding the 0.5 threshold, suggesting potential cognitive events. While many of these instances were likely misclassifications, we could not discount the possibility of cognitive events originating outside the trial window or from participant’s internal thoughts. This phenomenon was particularly noticeable in the MA dataset where, after the initial peak corresponding to the ST, we observed secondary peaks approximately 4–5 s later. For example, in the MA dataset panel of Fig. <a href="#Fig4" class="usa-link">4</a>, the first ST occurred around 78 s, with the initial peak in predictions around 78–80  s. Then, a second peak was around 82 s. Similar occurrences scattered throughout the MA dataset. The first peak (ST) corresponded to the participant seeing the math problems, and the second peak might relate to the participant attempting to solve them. This suggested the possibility of unrecorded cognitive workloads outside the trial context.</p>
<p id="Par37">The results for the five models in the online environment: “All-task”, “DPT”, “MA”, “PVT”, and “VWM”, were 0.49, 0.71, 0.60, 0.55, and 0.40 respectively, measured in MCC. Compared to Table <a href="#Tab1" class="usa-link">1</a>, all models experienced a decrease of approximately 0.05 in MCC. This illustrates the trade-off between offline and online environments.</p></section></section><section id="Sec8"><h2 class="pmc_sec_title">Discussion</h2>
<p id="Par38">To summarize the results, the performance of the five models (“All-task”, “DPT”, “MA”, “PVT”, and “VWM”) were 0.55, 0.75, 0.65, 0.59, and 0.43 measured by MCC respectively. Transitioning from specialization to generalization led to a decrease in specificity while increasing sensitivity. When predicting from a single task, the unique task structure was the primary contributor to the prediction. As more tasks were introduced, the contribution of human cognitive reactions increased. In the online simulation environment, the performance dropped by about 0.05 in MCC across all models.</p>
<section id="Sec9"><h3 class="pmc_sec_title">Factor influence the model prediction</h3>
<p id="Par39">The unique task structure referred to participants directing their gaze to a specific location when the ST was presented. The PLR effect in DPT was also considered as the structure of the task, as it only appeared in the DPT task. The PLR effect was characterized by a rapid constriction followed by a fast re-dilation of the pupil diameter<sup><a href="#CR33" class="usa-link" aria-describedby="CR33">33</a></sup>. The human cognitive reaction was indicated when the pupil diameter increased, reflecting the activation of the sympathetic nervous system which responded to an increase in workload when participants processed ST<sup><a href="#CR31" class="usa-link" aria-describedby="CR31">31</a>,<a href="#CR32" class="usa-link" aria-describedby="CR32">32</a></sup>. This increase in pupil diameter was small, on the order of a few tenths of a millimeter<sup><a href="#CR29" class="usa-link" aria-describedby="CR29">29</a></sup>.</p>
<p id="Par40">While training individual tasks, four specialized models relied on unique task structures for prediction. From Table <a href="#Tab4" class="usa-link">4</a>, we observed that the model could use human cognitive reaction for prediction, but they relied on task structures. This phenomenon was logical, as task structures were more easily detectable than cognitive reactions. The differences in pupil diameter due to cognitive reactions were minimal, often only a few tenths of a millimeter<sup><a href="#CR29" class="usa-link" aria-describedby="CR29">29</a></sup>. It was a weak factor that could be overshadowed by the unique task structure.</p>
<p id="Par41">In contrast, the “All-task” model needed to find a common pattern across all samples, which was the human cognitive reaction. The human cognitive reaction played a more significant role in the “All-task” model, as evidenced in Fig. <a href="#Fig3" class="usa-link">3</a>. While the four task-specific models depended on unique patterns within their respective tasks, the absence of task-type information in the input prevented the model from identifying which sample belonged to which task. As the variety of tasks increased, we expected the “All-task” model to increasingly rely on human cognitive reactions.</p>
<section id="Sec10"><h4 class="pmc_sec_title">Brain region activation differences between VWM and DPT, MA, and PVT tasks</h4>
<p id="Par42">In all results, the “VWN” model had the lowest performance with a non-trivial gap. In Table <a href="#Tab2" class="usa-link">2</a>, compared to other models, the “VMN” model was on the same specificity level, but its sensitivity was significantly lower. The largest differences between the “VWM” and the other three tasks were attributed to the fundamentally different brain activation regions involved.</p>
<p id="Par43">The DPT, MA, and PVT tasks engaged different aspects of attention, such as selective attention, sustained attention, and attentional disengagement. In contrast, VWM was a cognitive process that involved storing and manipulating visual information in short-term memory.</p>
<p id="Par44">These attention-related tasks, like DPT, MA, and PVT, likely involved the anterior cingulate cortex (ACC), a brain region associated with various cognitive functions such as conflict monitoring<sup><a href="#CR34" class="usa-link" aria-describedby="CR34">34</a></sup>, error detection<sup><a href="#CR35" class="usa-link" aria-describedby="CR35">35</a></sup>, response selection<sup><a href="#CR36" class="usa-link" aria-describedby="CR36">36</a></sup>, and executive control<sup><a href="#CR37" class="usa-link" aria-describedby="CR37">37</a></sup>. The ACC also regulated emotional processes like affective appraisal and emotional regulation, adapting attention to task demands and emotional context<sup><a href="#CR38" class="usa-link" aria-describedby="CR38">38</a></sup>.</p>
<p id="Par45">VWM, however, might rely more on brain regions like the posterior parietal cortex<sup><a href="#CR39" class="usa-link" aria-describedby="CR39">39</a></sup> and prefrontal cortex<sup><a href="#CR40" class="usa-link" aria-describedby="CR40">40</a></sup>, which are involved in encoding, maintaining, and manipulating visual information in a short-term memory buffer. The posterior parietal cortex handled spatial attention and representation<sup><a href="#CR41" class="usa-link" aria-describedby="CR41">41</a></sup>, while the prefrontal cortex managed executive control and working memory updating<sup><a href="#CR42" class="usa-link" aria-describedby="CR42">42</a></sup>. VWM might not heavily involve the ACC compared to the other tasks, as it did not involve as much conflict, error, or emotional processing.</p>
<p id="Par46">Differences in cortical activation may influence the strength and timing of pupillary responses, particularly through ACC, which modulates the arousal-related locus coeruleus-norepinephrine (LC-NE) system. According to Adaptive Gain Theory, highly conflicting tasks that involved the ACC triggered activation of the LC-NE system<sup><a href="#CR43" class="usa-link" aria-describedby="CR43">43</a></sup>, and the phase of LC-NE activity was shown to predict changes in pupil diameter<sup><a href="#CR44" class="usa-link" aria-describedby="CR44">44</a></sup>. Tasks involving the ACC tended to produce large and stereotyped pupil dilation at ST, while tasks like VWM, which rely more on posterior parietal and prefrontal regions than the ACC, might have a weaker or more monotonic change in pupil diameter. This raises the question of whether such differences in brain region activation could directly impact the pupillary responses used for classification. Whether the LC-NE system alone contributed a significant factor to the pupillary signal and altering model performance remained unclear. Further testing and analysis are required to confirm this relationship.</p></section></section></section><section id="Sec11"><h2 class="pmc_sec_title">Limitation</h2>
<p id="Par47">The experiments were conducted in a lab-controlled environment. The online environment simulation was an attempt to replicate real-time scenarios but had limitations because all four tasks were conducted in a lab-controlled setting. Real-life noises and data could not be stimulated. Certain features might not have been as effective outside these environments. For example, gaze position features, where participants focused on specific locations on a screen, might have limitations in real-world settings. In real-world scenarios, points of interest were not the same on a screen. Gaze position was included in the study as it provided information for detecting saccadic and fixation eye movements. We anticipated that in real-world environments, cognitive reactions would be the primary contributing factor, as they reflect cognitive workload and are generalizable. This expectation was supported by the findings from the “All-task” model, which showed that cognitive reaction was an important factor in making predictions.</p>
<p id="Par48">In addition, because demographic information was not provided, the results could be biased toward specific subgroups and might not have accurately reflected the general population.</p></section><section id="Sec12"><h2 class="pmc_sec_title">Conclusion</h2>
<p id="Par49">In this study, we developed and evaluated five CNN models using pupillary data to predict stimulus onset times for four different cognitive tasks. We built one generalized model “All-task” and four specialized models. The study highlighted several key findings: </p>
<ol class="list" style="list-style-type:decimal">
<li><p id="Par50">The results for the five models (“All-task”, “DPT”, “MA”, “PVT”, and “VWM”) were 0.55, 0.75, 0.65, 0.59, and 0.43, respectively, measured in MCC. When multiple cognitive tasks had been integrated into training, specificity decreased while sensitivity increased. This reflected the trade-off between specialization and generalization.</p></li>
<li><p id="Par51">In the specialized models, it was possible to use human cognitive reactions for prediction; however, the models prioritized the unique task structure patterns. As we integrated more cognitive tasks into training, human cognitive reactions contributed more and more to the predictions.</p></li>
<li><p id="Par52">In the online environment simulation, the performance of all five models decreased by approximately 0.05 in MCC. This highlighted the trade-off between a dynamic environment and data availability.</p></li>
</ol>
<p>For future work, our focus was on enhancing models by incorporating a broader range of participant-specific data. We plan to integrate a wider variety of tasks into training to improve generalization. Furthermore, several known factors influenced pupil diameter, such as body mass<sup><a href="#CR45" class="usa-link" aria-describedby="CR45">45</a></sup>, lighting conditions<sup><a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup>, age<sup><a href="#CR47" class="usa-link" aria-describedby="CR47">47</a></sup>, and medication<sup><a href="#CR48" class="usa-link" aria-describedby="CR48">48</a></sup>. In future modeling efforts, we intend to incorporate these factors.</p>
<p id="Par53">The implications of this research had potential applications in real-time detection of cognitively demanding tasks and accurate determination of stimulus onset times, including individual stress level identification. This research could enhance human-computer interaction, improve healthcare systems, develop personalized learning experiences, optimize learning outcomes, and allocate workload based on individual cognitive needs.</p></section><section id="Sec13"><h2 class="pmc_sec_title">Methodology</h2>
<section id="Sec14"><h3 class="pmc_sec_title">Material</h3>
<p id="Par54">The dataset was part of the Cognitive Resilience and Sleep History research project. Fifty-seven participants volunteered in the research experiment at the University of California, Santa Barbara. No demographic data was provided. The Human Participants Committee of the University of California Santa Barbara (#IRB00000307) and the Army Research Laboratory Human Research Protections Office approved all study procedures. All experiments were conducted in accordance with the approved guidelines and regulations. All participants provided written informed consent.</p>
<p id="Par55">Each participant followed a standardized protocol, beginning with a relaxation period of 6 min (referred to as “REST”), followed by the completion of four distinct cognitive tasks. Participants could return for up to 10 sessions on separate days (median = 6, SD = 3.33).</p>
<p id="Par56">Four cognitive tasks were widely recognized cognitive assessments; they were designed to probe various aspects of mental functioning. A brief overview of each task was described below:</p>
<p id="Par57"><strong>Dot Probe Task (DPT):</strong> This task involved the display of two facial images, each categorized by emotion (angry, happy, or neutral). A subsequent visual probe would appear, and participants asked to identify the probe’s location (left or right). The DPT measured how much faster participants responded to angry stimuli compared to neutral stimuli. DPT is a classic assessment of selective attention (160 trials per session).</p>
<p id="Par58"><strong>Mental Arithmetic (MA):</strong> Participants solved modular arithmetic problems, with varied in difficulty level (easy and hard). MA tasks were considered a core component of human logical thinking and related to attention, working memory, processing speed, MA ability, and executive function. The difficulty level was presented randomly (40 trials per session).</p>
<p id="Par59"><strong>Psychomotor Vigilance Task (PVT):</strong> Participants pressed a key when a visual stimulus appeared on the screen. The PVT was a classic measure of sustained attention that measures how participants respond to a simple visual stimulus for an extended period of time (77 trials per session).</p>
<p id="Par60"><strong>Visual Working Memory (VWM):</strong> Participants memorized a stimulus image and compared it to a second image. The second image could be similar or different. Participants were asked to determine whether the second image matched the first, with difficulty levels varying (1 item for easy level to 6 items for hard level). Each session had 48 trials.</p>
<p id="Par61">Data was recorded at 250 Hz, capturing pupil diameter, gaze position (Gaze X, Gaze Y). Additionally, behavior data were collected, including the initiation time of each trial (Stimulus Time, ST), and task-specific information. In this paper, ST was used as a primary predictor of cognitive events.</p></section><section id="Sec15"><h3 class="pmc_sec_title">Sampling method</h3>
<p id="Par62">The goal was to auto-detect cognitive events. ST signified the beginning of each trial, marking new information for participants to process. Therefore, each ST was a cognitive event, and we wanted to predict the location of the ST. The input data had 1-s intervals of three time-series features (Pupil Diameter, Gaze X, and Gaze Y), each recorded at a sampling rate of 250 Hz. The problem was framed as a binary classification task, where the model’s output yielded a probability ranging from 0 (absence of ST) to 1 (presence of ST).</p>
<p id="Par63">To account for individual differences, we standardized the dataset per participant and session. Participants had different pupil diameters and reacted differently toward ST and PLR. For participants with multiple repeated sessions, we treated each session as a separate entity due to differences in pupil diameter between sessions. These differences may have resulted from factors such as variations in equipment calibration, lighting conditions, or participants’ mental states. To address this, standardization involved calculating the mean and standard deviation of each session, scaling the data to set the mean of data at 0, and the standard deviation at 1. This approach helped minimize the individual variations.</p>
<p id="Par64">Let the time of ST was at 0 s, for each ST, two samples were generated: sample labeled “0” (absence of ST) from − 1 to 0 s and one sample labeled “1” (presence of ST) from 0.5 to 1.5 s. We chose the start time of 0.5 s to minimize the influence of the PLR that may occur with stimulus presentation<sup><a href="#CR16" class="usa-link" aria-describedby="CR16">16</a>,<a href="#CR46" class="usa-link" aria-describedby="CR46">46</a></sup>. Typically, the initial constriction phase of the pupil took about 0.9 to 1-s<sup><a href="#CR33" class="usa-link" aria-describedby="CR33">33</a>,<a href="#CR49" class="usa-link" aria-describedby="CR49">49</a></sup>. However, in our dataset, we found that the pupil reached its minimum diameter in approximately 0.6–0.7 s. Since our goal was to capture cognitive responses, we chose to avoid the majority of the constriction phase. In addition, as discussed in “<a href="#Sec3" class="usa-link">Exploratory data analysis</a>” section, the 0 to 0.5-s window corresponded to saccadic eye movements, during which participants shifted their focus to newly presented information. The pupil dilation occurred after 0.5 s when participants began processing the stimulus. Therefore, we determined that a time frame of 0.5–1.5 s was appropriate to predict cognitive events.</p>
<p id="Par65">Next, we randomly selected a 1-s window from “REST” data, and labeled it as a “0” sample. All “REST” data samples were non-overlapping. The process for sample generation was illustrated Fig. <a href="#Fig5" class="usa-link">5</a>.</p>
<figure class="fig xbox font-sm" id="Fig5"><h4 class="obj_head">Fig. 5.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12368119_41598_2025_16165_Fig5_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/58e7e4d08642/41598_2025_16165_Fig5_HTML.jpg" loading="lazy" id="MO5" height="373" width="767" alt="Fig. 5"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig5/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Sample generation process. The panel (<strong>a</strong>) displayed on task data. The black dotted line was the Stimulus Time (ST). For every ST, the generation process generated one “0” sample (yellow) and one “1” sample (red). The panel (<strong>b</strong>) displayed REST data, where non-overlapping “0” samples were randomly generated. Each sample contained 1 s of data.</p></figcaption></figure><p id="Par66">Following data sampling, any missing data samples were removed. Missing data was caused when the eye-tracking devices failed to capture participants’ pupil signals, either because participants looked away from the screen or due to technical errors. After removing invalid samples, the dataset exhibited an imbalance, with “0” class samples being the majority. The percentage for the “1” class was 40%, 34%, 23%, 28%, and 40% for All-task, DPT, MA, PVT, and VWM, receptively. We applied SMOTE (Synthetic Minority Oversampling Technique) to rebalance only the training dataset, while the testing dataset remained unchanged. After SMOTE, the class distribution in the training set was 1:1. This helped the models avoid statistical bias toward either class.</p>
<p id="Par67">Then, we split the fifty-seven participants into five folds. Two folds had 12 participants each and three folds had 11 participants each. Unlike the standardization process, the splits were made at the participant level rather than at the session level or sample level to avoid data leakage. Splitting by samples could allow samples from the same participant to appear in both the training and testing set, causing data leakage and artificially inflating model performance. After splitting, we applied five-fold cross-validation. In each iteration, three folds were used for training, one fold for validation, and one fold for testing.</p></section><section id="Sec16"><h3 class="pmc_sec_title">Models architecture</h3>
<p id="Par68">All four model architectures shared a common overall structure and used the same loss function. The distinctions were laid in their specific layer. The layer for each architecture was detailed below, where <em>x</em> denoted the input, <em>b</em> was the bias and <em>y</em> was the output, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq4"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/dbad5f9d7f55/d33e1291.gif" loading="lazy" id="d33e1291" alt="Inline graphic"></span> was the ReLU activation function and <em>M</em> was a dropout matrix with a dropout rate of 0.3.</p>
<p id="Par69"><strong>CNN:</strong> The architecture was a sequential convolutional neural network (CNN). Each layer included a convolutional layer with a ReLU activation function, followed by a max-pooling layer, and a dropout layer. The mathematical representation for each layer was expressed as follows:</p>
<table class="disp-formula p" id="Equ1"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/867ebcbc2851/d33e1304.gif" loading="lazy" id="d33e1304" alt="graphic file with name d33e1304.gif"></td>
<td class="label">1</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq5"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/71a9fe066a9e/d33e1311.gif" loading="lazy" id="d33e1311" alt="Inline graphic"></span> represented the 1D convolution tensor with a filter size of 5, stride 1, and 64 output channels. <em>P</em> was the max-pooling operation with size 2.</p>
<p id="Par70"><strong>BiLSTM:</strong> The architecture was a bidirectional long short-term memory with each layer that could be expressed in mathematical terms as follows:</p>
<table class="disp-formula p" id="Equ2"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/d311c6a7c11e/d33e1324.gif" loading="lazy" id="d33e1324" alt="graphic file with name d33e1324.gif"></td>
<td class="label">2</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq6"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/b7b783125414/d33e1331.gif" loading="lazy" id="d33e1331" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq7"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/8f31a5793cf7/d33e1337.gif" loading="lazy" id="d33e1337" alt="Inline graphic"></span> were forward and backward LSTM layers, each with a hidden dimension of 64.</p>
<p id="Par71"><strong>RNN:</strong> The architecture was a simple recurrent neural network (RNN). The hidden state update and final output were given by:</p>
<table class="disp-formula p" id="Equ3"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/b5efbf8262d7/d33e1347.gif" loading="lazy" id="d33e1347" alt="graphic file with name d33e1347.gif"></td>
<td class="label">3</td>
</tr></table>
<p>where <em>t</em> was the time-step that was recurrent from 1 to 250. <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq8"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/1ce4c82e497b/d33e1357.gif" loading="lazy" id="d33e1357" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq9"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/4e3a58abc03e/d33e1363.gif" loading="lazy" id="d33e1363" alt="Inline graphic"></span> were the input <em>x</em> and the hidden state <em>h</em> at timestep <em>t</em>. <em>h</em> had the dimension of 128. <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq10"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/9a1110e14c16/d33e1382.gif" loading="lazy" id="d33e1382" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq11"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/98ee2c6188ed/d33e1388.gif" loading="lazy" id="d33e1388" alt="Inline graphic"></span> were the weight matrix for the input <em>x</em> and hidden state <em>h</em>, respectively. The output <em>y</em> was equal to <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq12"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/5beaa1f78c55/d33e1404.gif" loading="lazy" id="d33e1404" alt="Inline graphic"></span>, the hidden state in timestep 250.</p>
<p id="Par72"><strong>MLP:</strong> The architecture was a multilayer perceptron. Each perceptron layer could be expressed in mathematical terms as follows:</p>
<table class="disp-formula p" id="Equ4"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/c5184a625ba5/d33e1414.gif" loading="lazy" id="d33e1414" alt="graphic file with name d33e1414.gif"></td>
<td class="label">4</td>
</tr></table>
<p><em>W</em> was the weight matrix with hidden dimension 128.</p>
<p id="Par73">All four architectures shared the same general structure and produced two outputs: a classification output <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq13"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/f3f8b9048b72/d33e1425.gif" loading="lazy" id="d33e1425" alt="Inline graphic"></span> and a pupil diameter output <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq14"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/ce87f43408ff/d33e1431.gif" loading="lazy" id="d33e1431" alt="Inline graphic"></span>. The <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq15"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/f3f8b9048b72/d33e1437.gif" loading="lazy" id="d33e1437" alt="Inline graphic"></span> generated a probability score ranging between 0 and 1, where 0 value indicated the absence of ST, and 1 value indicated the presence of ST. It was the main output for optimization. The <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq16"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/ce87f43408ff/d33e1443.gif" loading="lazy" id="d33e1443" alt="Inline graphic"></span> output aimed to reconstruct the pupil diameter from the input sample. It was used solely for review and error-checking purposes. The architecture equation was defined as:</p>
<table class="disp-formula p" id="Equ5"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/8a3d26a636c3/d33e1449.gif" loading="lazy" id="d33e1449" alt="graphic file with name d33e1449.gif"></td>
<td class="label">5</td>
</tr></table>
<p>where <em>X</em> was the input sample with three dimensions (N, 250, 3), except for the MLP, which received a reshaped size of (N,750). N was the number of samples, the second dimension was the temporal dimension corresponding to 1 s at 250 Hz, and the third dimension was 3 features (Pupil Diameter, Gaze X, and Gaze Y). Since the MLP could not process temporal sequences directly, the temporal and feature dimensions were merged (i.e., <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq17"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/627cfc550429/d33e1460.gif" loading="lazy" id="d33e1460" alt="Inline graphic"></span>. The layers <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq18"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/5496a0a7862b/d33e1466.gif" loading="lazy" id="d33e1466" alt="Inline graphic"></span> were architecture-specific and differed depending on the model (as described in Eqs. <a href="#Equ1" class="usa-link">1</a>–<a href="#Equ4" class="usa-link">4</a>). The <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq19"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/795cb085fc4c/d33e1478.gif" loading="lazy" id="d33e1478" alt="Inline graphic"></span> referred to the average pooling operation applied exclusively to the temporal dimension, without affecting the other dimensions, to reduce the temporal dimension. This averaging pooling was not applicable in the MLP architecture. The <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq20"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/da5cc521874f/d33e1485.gif" loading="lazy" id="d33e1485" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq21"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/4e6fb6089418/d33e1491.gif" loading="lazy" id="d33e1491" alt="Inline graphic"></span> were the weight and the bias for the final linear layer. The <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq22"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/f3f8b9048b72/d33e1497.gif" loading="lazy" id="d33e1497" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq23"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/ce87f43408ff/d33e1503.gif" loading="lazy" id="d33e1503" alt="Inline graphic"></span> were the output of the architecture.</p>
<p id="Par74">All models trained using the same composite loss function that combined cross-entropy loss, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq24"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/07d92350a0d5/d33e1511.gif" loading="lazy" id="d33e1511" alt="Inline graphic"></span> for the classification output <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq25"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/f3f8b9048b72/d33e1517.gif" loading="lazy" id="d33e1517" alt="Inline graphic"></span> and <em>L</em>1 loss <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq26"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/bbb7903e1c5e/d33e1526.gif" loading="lazy" id="d33e1526" alt="Inline graphic"></span> for the pupil diameter output <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq27"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/ce87f43408ff/d33e1532.gif" loading="lazy" id="d33e1532" alt="Inline graphic"></span>. The overall loss function could be expressed as:</p>
<table class="disp-formula p" id="Equ6"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/83c3aba834c0/d33e1539.gif" loading="lazy" id="d33e1539" alt="graphic file with name d33e1539.gif"></td>
<td class="label">6</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq28"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/2aabd379ce4a/d33e1546.gif" loading="lazy" id="d33e1546" alt="Inline graphic"></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq29"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/dbad5f9d7f55/d33e1552.gif" loading="lazy" id="d33e1552" alt="Inline graphic"></span> were the Sigmoid and ReLU activation functions respectively. The <em>Y</em> was the ground true classification label (either 0 or 1). <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq30"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/93c553648825/d33e1561.gif" loading="lazy" id="d33e1561" alt="Inline graphic"></span> was a constant scalar, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq31"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/9f710e675cee/d33e1567.gif" loading="lazy" id="d33e1567" alt="Inline graphic"></span> was the ground true for the input sample containing only the Pupil Diameter feature after removing the Gaze X and Gaze Y features. The <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq32"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/ce87f43408ff/d33e1574.gif" loading="lazy" id="d33e1574" alt="Inline graphic"></span> output was designed for error-checking purposes. If the models were unable to reconstruct the original output from its last layer, it signaled a potential mathematical error within the architecture. However, this should not affect the overall performance of the model. The coefficient <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq33"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/73975112fc4a/d33e1580.gif" loading="lazy" id="d33e1580" alt="Inline graphic"></span> was selected to be small enough to not affect the classification performance, and non-zero to ensure that the model does not neglect the reconstruction task. After testing, we determined that 0.004 was appropriate for the coefficient <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq34"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/73975112fc4a/d33e1586.gif" loading="lazy" id="d33e1586" alt="Inline graphic"></span>.</p>
<p id="Par75">We trained five distinct models for each architecture described above. The key distinction between these models was the training data used. Four models were task-specific, namely “DPT”, “PVT”, “MA”, and “VWM”, trained exclusively on data from their respective tasks. In contrast, the “All-task” model was trained on the entire available training dataset, aiming to evaluate the architecture’s ability to generalize across various tasks.</p></section><section id="Sec17"><h3 class="pmc_sec_title">Evaluation metric and feature importance algorithms</h3>
<p id="Par76">We selected the Matthews Correlation Coefficient (MCC) as the primary metric. This choice was made because the dataset was imbalanced. MCC was known for its robustness in handling imbalanced datasets<sup><a href="#CR50" class="usa-link" aria-describedby="CR50">50</a>,<a href="#CR51" class="usa-link" aria-describedby="CR51">51</a></sup>. Alongside MCC, we included several secondary metrics such as accuracy, F1 score, sensitivity, and specificity.</p>
<p id="Par77">For the third objective mentioned in the “<a href="#Sec1" class="usa-link">Introduction</a>” section, we aimed to understand the factors influencing our model’s predictions by performing a feature importance analysis. This analysis helped identify which feature contributed the most weight to the output. We used the Permutation Feature Importance algorithm<sup><a href="#CR52" class="usa-link" aria-describedby="CR52">52</a></sup> to compute feature importance.</p>
<p id="Par78">Initially, we established a baseline score, denoted <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq35"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/e8aed165cbdc/d33e1616.gif" loading="lazy" id="d33e1616" alt="Inline graphic"></span>. We evaluated testing samples without any alterations. <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq36"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/e8aed165cbdc/d33e1622.gif" loading="lazy" id="d33e1622" alt="Inline graphic"></span> was measured in terms of MCC. Then, we assessed the score for each feature. To accomplish this, we randomly shuffled all data within a specific feature, keeping all other features unchanged. This process allowed us to isolate the impact of the feature under examination. Following this, we conducted predictions and computed the score for these perturbed samples <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq37"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/7e92da4fc9a3/d33e1628.gif" loading="lazy" id="d33e1628" alt="Inline graphic"></span> anticipating a decrease in performance compared to <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq38"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/e8aed165cbdc/d33e1634.gif" loading="lazy" id="d33e1634" alt="Inline graphic"></span>. The decrease in performance was quantified and subtracted from <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq39"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/e8aed165cbdc/d33e1640.gif" loading="lazy" id="d33e1640" alt="Inline graphic"></span>. This iterative process was repeated for all features. To ensure the reliability of these feature importance metrics, we repeated these experiments 100 times <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq40"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/4b18744866a0/d33e1647.gif" loading="lazy" id="d33e1647" alt="Inline graphic"></span> and calculated the mean and standard deviation across all features, as expressed in Eq. (<a href="#Equ7" class="usa-link">7</a>):</p>
<table class="disp-formula p" id="Equ7"><tr>
<td class="formula"><img class="graphic" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/67475991068c/d33e1656.gif" loading="lazy" id="d33e1656" alt="graphic file with name d33e1656.gif"></td>
<td class="label">7</td>
</tr></table>
<p>where, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq41"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/fd8ff31eb09d/d33e1663.gif" loading="lazy" id="d33e1663" alt="Inline graphic"></span> represented the importance score for feature <em>j</em>, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq42"><img class="inline" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/9a4d/12368119/3ac9791f9fe9/d33e1672.gif" loading="lazy" id="d33e1672" alt="Inline graphic"></span> was the MCC score for feature <em>j</em> in the <em>i</em>-th iteration.</p></section></section><section id="ack1" class="ack"><h2 class="pmc_sec_title">Acknowledgements</h2>
<p>The authors would like to express our gratitude to Phil Beach, Mario Mendoza, Hannah Erro, and Zoe Rathbun for their contributions to data generation and study coordination. The authors thank Steven Thurman for his helpful comments. The authors also acknowledge the Army Research Laboratory for sponsoring this dataset. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the US DEVCOM Army Research Laboratory or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein.</p></section><section id="notes1"><h2 class="pmc_sec_title">Author contributions</h2>
<p>QD, MK and MA performed the research; QD wrote the manuscript; QD, MK, MA and GK edited the manuscript; JB and SC conceptualized and designed the research; All authors reviewed the manuscript.</p></section><section id="notes2"><h2 class="pmc_sec_title">Data availability</h2>
<p>The data can be provided upon a reasonable request to the corresponding author. The request may subject to approval by the US Army DEVCOM Army Research Laboratory and the Human Participants Committee of the University of California, Santa Barbara.</p></section><section id="notes3"><h2 class="pmc_sec_title">Declarations</h2>
<section id="FPar1"><h3 class="pmc_sec_title">Competing interests</h3>
<p id="Par82">The authors declare no competing interests.</p></section></section><section id="fn-group1" class="fn-group"><h2 class="pmc_sec_title">Footnotes</h2>
<div class="fn-group p font-secondary-light font-sm"><div class="fn p" id="fn1">
<p><strong>Publisher’s note</strong></p>
<p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</div></div></section><section id="Bib1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="Bib1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="CR1">
<span class="label">1.</span><cite>Chikhi, S., Matton, N. &amp; Blanchet, S. EEG power spectral measures of cognitive workload: A meta-analysis. <em>Psychophysiology</em><strong>59</strong>, e14009. 10.1111/psyp.14009 (2022).
</cite> [<a href="https://doi.org/10.1111/psyp.14009" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35128686/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Chikhi,%20S.,%20Matton,%20N.%20&amp;%20Blanchet,%20S.%20EEG%20power%20spectral%20measures%20of%20cognitive%20workload:%20A%20meta-analysis.%20Psychophysiology59,%20e14009.%2010.1111/psyp.14009%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR2">
<span class="label">2.</span><cite>Gupta, A., Siddhad, G., Pandey, V., Roy, P. P. &amp; Kim, B.-G. Subject-specific cognitive workload classification using EEG-based functional connectivity and deep learning. <em>Sensors</em><strong>21</strong>, 6710. 10.3390/s21206710 (2021).
</cite> [<a href="https://doi.org/10.3390/s21206710" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8541420/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34695921/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Gupta,%20A.,%20Siddhad,%20G.,%20Pandey,%20V.,%20Roy,%20P.%20P.%20&amp;%20Kim,%20B.-G.%20Subject-specific%20cognitive%20workload%20classification%20using%20EEG-based%20functional%20connectivity%20and%20deep%20learning.%20Sensors21,%206710.%2010.3390/s21206710%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR3">
<span class="label">3.</span><cite>Eilebrecht, B. et al. The relevance of HRV parameters for driver workload detection in real world driving. In <em>2012 Computing in Cardiology</em>, 409–412 (2012). ISSN: 2325-8853.</cite>
</li>
<li id="CR4">
<span class="label">4.</span><cite>O’Reilly, R. C., Munakata, Y., Frank, M. J. &amp; Hazy, T. E. <em>Computational Cognitive Neuroscience</em> 4th edn. (Online Book, 2012). <a href="https://CompCogNeuro.org" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://CompCogNeuro.org</a></cite>
</li>
<li id="CR5">
<span class="label">5.</span><cite>Kosch, T., Karolus, J., Ha, H. &amp; Schmidt, A. Your skin resists: Exploring electrodermal activity as workload indicator during manual assembly. In <em> Proceedings of the ACM SIGCHI Symposium on Engineering Interactive Computing Systems, EICS ’19</em>, 1–5 (Association for Computing Machinery, 2019). 10.1145/3319499.3328230.</cite>
</li>
<li id="CR6">
<span class="label">6.</span><cite>Klingner, J., Kumar, R. &amp; Hanrahan, P. Measuring the task-evoked pupillary response with a remote eye tracker. In <em> Proceedings of the 2008 Symposium on Eye Tracking Research and Applications, ETRA ’08</em>, 69–72 (Association for Computing Machinery, 2008). 10.1145/1344471.1344489</cite>
</li>
<li id="CR7">
<span class="label">7.</span><cite>Gupta, S. S. et al. Classification of cross task cognitive workload using deep recurrent network with modelling of temporal dynamics. <em>Biomed. Signal Process. Control</em><strong>70</strong>, 103070. 10.1016/j.bspc.2021.103070 (2021).</cite> [<a href="https://scholar.google.com/scholar_lookup?Gupta,%20S.%20S.%20et%20al.%20Classification%20of%20cross%20task%20cognitive%20workload%20using%20deep%20recurrent%20network%20with%20modelling%20of%20temporal%20dynamics.%20Biomed.%20Signal%20Process.%20Control70,%20103070.%2010.1016/j.bspc.2021.103070%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR8">
<span class="label">8.</span><cite>Lobo, J. L. et al. Cognitive workload classification using eye-tracking and EEG data. In <em> Proceedings of the International Conference on Human–Computer Interaction in Aerospace</em>, 1–8 (2016).</cite>
</li>
<li id="CR9">
<span class="label">9.</span><cite>Blanco, J. A. et al. Quantifying cognitive workload in simulated flight using passive, dry EEG measurements. <em>IEEE Trans. Cogn. Dev. Syst.</em><strong>10</strong>, 373–383. 10.1109/TCDS.2016.2628702 (2018).</cite> [<a href="https://scholar.google.com/scholar_lookup?Blanco,%20J.%20A.%20et%20al.%20Quantifying%20cognitive%20workload%20in%20simulated%20flight%20using%20passive,%20dry%20EEG%20measurements.%20IEEE%20Trans.%20Cogn.%20Dev.%20Syst.10,%20373%E2%80%93383.%2010.1109/TCDS.2016.2628702%20(2018)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR10">
<span class="label">10.</span><cite>Kalafatovich, J., Lee, M. &amp; Lee, S.-W. Prediction of memory retrieval performance using EAR-EEG signals. In <em> 2020 42nd Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</em>, 3363–3366. 10.1109/EMBC44109.2020.9175990 (2020).</cite> [<a href="https://doi.org/10.1109/EMBC44109.2020.9175990" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/33018725/" class="usa-link">PubMed</a>]</li>
<li id="CR11">
<span class="label">11.</span><cite>Vinay, A., Lerch, A. &amp; Leslie, G. Mind the beat: Detecting audio onsets from EEG recordings of music listening. In <em> ICASSP 2021—2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 231–235. 10.1109/ICASSP39728.2021.9414245 (2021).</cite>
</li>
<li id="CR12">
<span class="label">12.</span><cite>Luck, S. J. <em>An Introduction to the Event-Related Potential Technique</em> 2nd edn. (MIT Press, 2014).</cite> [<a href="https://scholar.google.com/scholar_lookup?Luck,%20S.%20J.%20An%20Introduction%20to%20the%20Event-Related%20Potential%20Technique%202nd%20edn.%20(MIT%20Press,%202014)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR13">
<span class="label">13.</span><cite>Rafiqi, S. et al. PupilWare: Towards pervasive cognitive load measurement using commodity devices. In <em> Proceedings of the 8th ACM International Conference on PErvasive Technologies Related to Assistive Environments, PETRA ’15</em>, 1–8 (Association for Computing Machinery, 2015). 10.1145/2769493.2769506</cite>
</li>
<li id="CR14">
<span class="label">14.</span><cite>Pfleging, B., Fekety, D. K., Schmidt, A. &amp; Kun, A. L. <em>A Model Relating Pupil Diameter to Mental Workload and Lighting Conditions, CHI ’16</em> (Association for Computing Machinery, 2016).</cite>
</li>
<li id="CR15">
<span class="label">15.</span><cite>van der Wel, P. &amp; van Steenbergen, H. Pupil dilation as an index of effort in cognitive control tasks: A review. <em>Psychon. Bull. Rev.</em><strong>25</strong>, 2005–2015. 10.3758/s13423-018-1432-y (2018).
</cite> [<a href="https://doi.org/10.3758/s13423-018-1432-y" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6267528/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/29435963/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?van%20der%20Wel,%20P.%20&amp;%20van%20Steenbergen,%20H.%20Pupil%20dilation%20as%20an%20index%20of%20effort%20in%20cognitive%20control%20tasks:%20A%20review.%20Psychon.%20Bull.%20Rev.25,%202005%E2%80%932015.%2010.3758/s13423-018-1432-y%20(2018)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR16">
<span class="label">16.</span><cite>Ebitz, R. B. &amp; Moore, T. Both a gauge and a filter: Cognitive modulations of pupil size. <em>Front. Neurol.</em><strong>9</strong>, 1190. 10.3389/fneur.2018.01190 (2018).
</cite> [<a href="https://doi.org/10.3389/fneur.2018.01190" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6350273/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/30723454/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Ebitz,%20R.%20B.%20&amp;%20Moore,%20T.%20Both%20a%20gauge%20and%20a%20filter:%20Cognitive%20modulations%20of%20pupil%20size.%20Front.%20Neurol.9,%201190.%2010.3389/fneur.2018.01190%20(2018)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR17">
<span class="label">17.</span><cite>Unsworth, N., Robison, M. K. &amp; Miller, A. L. Pupillary correlates of fluctuations in sustained attention. <em>J. Cogn. Neurosci.</em><strong>30</strong>, 1241–1253. 10.1162/jocn_a_01251 (2018).
</cite> [<a href="https://doi.org/10.1162/jocn_a_01251" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/29488845/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Unsworth,%20N.,%20Robison,%20M.%20K.%20&amp;%20Miller,%20A.%20L.%20Pupillary%20correlates%20of%20fluctuations%20in%20sustained%20attention.%20J.%20Cogn.%20Neurosci.30,%201241%E2%80%931253.%2010.1162/jocn_a_01251%20(2018)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR18">
<span class="label">18.</span><cite>Baldock, J., Kapadia, S. &amp; van Steenbrugge, W. The task-evoked pupil response in divided auditory attention tasks. <em>J. Am. Acad. Audiol.</em><strong>30</strong>, 264–272. 10.3766/jaaa.17060 (2019).
</cite> [<a href="https://doi.org/10.3766/jaaa.17060" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/30461386/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Baldock,%20J.,%20Kapadia,%20S.%20&amp;%20van%20Steenbrugge,%20W.%20The%20task-evoked%20pupil%20response%20in%20divided%20auditory%20attention%20tasks.%20J.%20Am.%20Acad.%20Audiol.30,%20264%E2%80%93272.%2010.3766/jaaa.17060%20(2019)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR19">
<span class="label">19.</span><cite>Hoffing, R. A. C. et al. Dissociable mappings of tonic and phasic pupillary features onto cognitive processes involved in mental arithmetic. <em>PLoS One</em><strong>15</strong>, e0230517. 10.1371/journal.pone.0230517 (2020).
</cite> [<a href="https://doi.org/10.1371/journal.pone.0230517" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC7089555/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/32203562/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Hoffing,%20R.%20A.%20C.%20et%20al.%20Dissociable%20mappings%20of%20tonic%20and%20phasic%20pupillary%20features%20onto%20cognitive%20processes%20involved%20in%20mental%20arithmetic.%20PLoS%20One15,%20e0230517.%2010.1371/journal.pone.0230517%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR20">
<span class="label">20.</span><cite>Alnæs, D. et al. Pupil size signals mental effort deployed during multiple object tracking and predicts brain activity in the dorsal attention network and the locus coeruleus. <em>J. Vis.</em><strong>14</strong>, 1. 10.1167/14.4.1 (2014).
</cite> [<a href="https://doi.org/10.1167/14.4.1" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/24692319/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Aln%C3%A6s,%20D.%20et%20al.%20Pupil%20size%20signals%20mental%20effort%20deployed%20during%20multiple%20object%20tracking%20and%20predicts%20brain%20activity%20in%20the%20dorsal%20attention%20network%20and%20the%20locus%20coeruleus.%20J.%20Vis.14,%201.%2010.1167/14.4.1%20(2014)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR21">
<span class="label">21.</span><cite>Lempert, K. M., Chen, Y. L. &amp; Fleming, S. M. Relating pupil dilation and metacognitive confidence during auditory decision-making. <em>PLoS One</em><strong>10</strong>, e0126588. 10.1371/journal.pone.0126588 (2015).
</cite> [<a href="https://doi.org/10.1371/journal.pone.0126588" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC4423945/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/25950839/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Lempert,%20K.%20M.,%20Chen,%20Y.%20L.%20&amp;%20Fleming,%20S.%20M.%20Relating%20pupil%20dilation%20and%20metacognitive%20confidence%20during%20auditory%20decision-making.%20PLoS%20One10,%20e0126588.%2010.1371/journal.pone.0126588%20(2015)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR22">
<span class="label">22.</span><cite>Loo, K. Individual differences in pupil dilation during naming task. In <em>Proceedings of the Annual Meeting of the Cognitive Science Society</em> (2016).</cite>
</li>
<li id="CR23">
<span class="label">23.</span><cite>Martin, J. T., Whittaker, A. H. &amp; Johnston, S. J. Pupillometry and the vigilance decrement: Task-evoked but not baseline pupil measures reflect declining performance in visual vigilance tasks. <em>Eur. J. Neurosci.</em><strong>55</strong>, 778–799. 10.1111/ejn.15585 (2022).
</cite> [<a href="https://doi.org/10.1111/ejn.15585" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9306885/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34978115/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Martin,%20J.%20T.,%20Whittaker,%20A.%20H.%20&amp;%20Johnston,%20S.%20J.%20Pupillometry%20and%20the%20vigilance%20decrement:%20Task-evoked%20but%20not%20baseline%20pupil%20measures%20reflect%20declining%20performance%20in%20visual%20vigilance%20tasks.%20Eur.%20J.%20Neurosci.55,%20778%E2%80%93799.%2010.1111/ejn.15585%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR24">
<span class="label">24.</span><cite>Beatty, J. Task-evoked pupillary responses, processing load, and the structure of processing resources. <em>Psychol. Bull.</em><strong>91</strong>, 276–292. 10.1037/0033-2909.91.2.276 (1982).
</cite> [<a href="https://pubmed.ncbi.nlm.nih.gov/7071262/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Beatty,%20J.%20Task-evoked%20pupillary%20responses,%20processing%20load,%20and%20the%20structure%20of%20processing%20resources.%20Psychol.%20Bull.91,%20276%E2%80%93292.%2010.1037/0033-2909.91.2.276%20(1982)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR25">
<span class="label">25.</span><cite>Koevoet, D. et al. The intensity of internal and external attention assessed with pupillometry. <em>J. Cogn.</em><strong>7</strong>, 8. 10.5334/joc.336 (2024).
</cite> [<a href="https://doi.org/10.5334/joc.336" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC10786008/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38223232/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Koevoet,%20D.%20et%20al.%20The%20intensity%20of%20internal%20and%20external%20attention%20assessed%20with%20pupillometry.%20J.%20Cogn.7,%208.%2010.5334/joc.336%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR26">
<span class="label">26.</span><cite>Salahuddin, L., Cho, J., Jeong, M. G. &amp; Kim, D. Ultra short term analysis of heart rate variability for monitoring mental stress in mobile settings. In <em> 2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society</em>, 4656–4659. 10.1109/IEMBS.2007.4353378 (2007).</cite> [<a href="https://doi.org/10.1109/IEMBS.2007.4353378" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/18003044/" class="usa-link">PubMed</a>]</li>
<li id="CR27">
<span class="label">27.</span><cite>Shaffer, F. &amp; Ginsberg, J. P. An overview of heart rate variability metrics and norms. <em>Front. Public Health</em><strong>5</strong>, 258. 10.3389/fpubh.2017.00258 (2017).
</cite> [<a href="https://doi.org/10.3389/fpubh.2017.00258" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC5624990/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/29034226/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Shaffer,%20F.%20&amp;%20Ginsberg,%20J.%20P.%20An%20overview%20of%20heart%20rate%20variability%20metrics%20and%20norms.%20Front.%20Public%20Health5,%20258.%2010.3389/fpubh.2017.00258%20(2017)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR28">
<span class="label">28.</span><cite>Sadiya, S., Alhanai, T. &amp; Ghassemi, M. M. Artifact detection and correction in EEG data: a review. In <em>2021 10th International IEEE/EMBS Conference on Neural Engineering (NER)</em>, 495–498. 10.1109/NER49283.2021.9441341 (2021).</cite>
</li>
<li id="CR29">
<span class="label">29.</span><cite>Cohen Hoffing, R., Garcia, J., Vettel, J. &amp; Thurman, S. Investigating the consistency of pupil-linked cognitive processes across multiple disparate tasks. <em>J. Vis.</em><strong>22</strong>, 3111. 10.1167/jov.22.14.3111 (2022).</cite> [<a href="https://scholar.google.com/scholar_lookup?Cohen%20Hoffing,%20R.,%20Garcia,%20J.,%20Vettel,%20J.%20&amp;%20Thurman,%20S.%20Investigating%20the%20consistency%20of%20pupil-linked%20cognitive%20processes%20across%20multiple%20disparate%20tasks.%20J.%20Vis.22,%203111.%2010.1167/jov.22.14.3111%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR30">
<span class="label">30.</span><cite>Holmqvist, K. &amp; Andersson, R. <em>Eye-tracking: A Comprehensive Guide to Methods, Paradigms and Measures</em> (Lund Eye-Tracking Research Institute, 2017).</cite>
</li>
<li id="CR31">
<span class="label">31.</span><cite>Ferencová, N. et al. Eye pupil—a window into central autonomic regulation via emotional/cognitive processing. <em>Physiol. Res.</em><strong>70</strong>, S669–S682. 10.33549/physiolres.934749 (2021).
</cite> [<a href="https://doi.org/10.33549/physiolres.934749" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC9054187/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/35199551/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Ferencov%C3%A1,%20N.%20et%20al.%20Eye%20pupil%E2%80%94a%20window%20into%20central%20autonomic%20regulation%20via%20emotional/cognitive%20processing.%20Physiol.%20Res.70,%20S669%E2%80%93S682.%2010.33549/physiolres.934749%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR32">
<span class="label">32.</span><cite>Alshanskaia, E. I. et al. Pupillometry and autonomic nervous system responses to cognitive load and false feedback: An unsupervised machine learning approach. <em>Front. Neurosci.</em><strong>18</strong>, 1445697. 10.3389/fnins.2024.1445697 (2024).
</cite> [<a href="https://doi.org/10.3389/fnins.2024.1445697" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11405740/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39290713/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Alshanskaia,%20E.%20I.%20et%20al.%20Pupillometry%20and%20autonomic%20nervous%20system%20responses%20to%20cognitive%20load%20and%20false%20feedback:%20An%20unsupervised%20machine%20learning%20approach.%20Front.%20Neurosci.18,%201445697.%2010.3389/fnins.2024.1445697%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR33">
<span class="label">33.</span><cite>Belliveau, A. P., Somani, A. N. &amp; Dossani, R. H. Pupillary light reflex. In <em> StatPearls [Internet]</em> (2023). <a href="https://www.ncbi.nlm.nih.gov/books/NBK537180/" class="usa-link" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">https://www.ncbi.nlm.nih.gov/books/NBK537180/</a> [Updated 2023 Jul 25].</cite> [<a href="https://pubmed.ncbi.nlm.nih.gov/30725865/" class="usa-link">PubMed</a>]</li>
<li id="CR34">
<span class="label">34.</span><cite>Braem, S. et al. The role of anterior cingulate cortex in the affective evaluation of conflict. <em>J. Cogn. Neurosci.</em><strong>29</strong>, 137–149. 10.1162/jocn_a_01023 (2017).
</cite> [<a href="https://doi.org/10.1162/jocn_a_01023" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC5341786/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27575278/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Braem,%20S.%20et%20al.%20The%20role%20of%20anterior%20cingulate%20cortex%20in%20the%20affective%20evaluation%20of%20conflict.%20J.%20Cogn.%20Neurosci.29,%20137%E2%80%93149.%2010.1162/jocn_a_01023%20(2017)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR35">
<span class="label">35.</span><cite>Orr, C. &amp; Hester, R. Error-related anterior cingulate cortex activity and the prediction of conscious error awareness. <em>Front. Hum. Neurosci.</em><strong>6</strong>, 177. 10.3389/fnhum.2012.00177 (2012).
</cite> [<a href="https://doi.org/10.3389/fnhum.2012.00177" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3377932/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/22723775/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Orr,%20C.%20&amp;%20Hester,%20R.%20Error-related%20anterior%20cingulate%20cortex%20activity%20and%20the%20prediction%20of%20conscious%20error%20awareness.%20Front.%20Hum.%20Neurosci.6,%20177.%2010.3389/fnhum.2012.00177%20(2012)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR36">
<span class="label">36.</span><cite>Turken, A. U. &amp; Swick, D. Response selection in the human anterior cingulate cortex. <em>Nat. Neurosci.</em><strong>2</strong>, 920–924. 10.1038/13224 (1999).
</cite> [<a href="https://doi.org/10.1038/13224" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/10491614/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Turken,%20A.%20U.%20&amp;%20Swick,%20D.%20Response%20selection%20in%20the%20human%20anterior%20cingulate%20cortex.%20Nat.%20Neurosci.2,%20920%E2%80%93924.%2010.1038/13224%20(1999)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR37">
<span class="label">37.</span><cite>Michelet, D. et al. Opioid-sparing effect of ketamine in children: A meta-analysis and trial sequential analysis of published studies. <em>Pediatr. Drugs</em><strong>18</strong>, 421–433 (2016).</cite> [<a href="https://doi.org/10.1007/s40272-016-0196-y" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27688125/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Michelet,%20D.%20et%20al.%20Opioid-sparing%20effect%20of%20ketamine%20in%20children:%20A%20meta-analysis%20and%20trial%20sequential%20analysis%20of%20published%20studies.%20Pediatr.%20Drugs18,%20421%E2%80%93433%20(2016)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR38">
<span class="label">38.</span><cite>Etkin, A., Egner, T. &amp; Kalisch, R. Emotional processing in anterior cingulate and medial prefrontal cortex. <em>Trends Cogn. Sci.</em><strong>15</strong>, 85–93. 10.1016/j.tics.2010.11.004 (2011).
</cite> [<a href="https://doi.org/10.1016/j.tics.2010.11.004" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3035157/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/21167765/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Etkin,%20A.,%20Egner,%20T.%20&amp;%20Kalisch,%20R.%20Emotional%20processing%20in%20anterior%20cingulate%20and%20medial%20prefrontal%20cortex.%20Trends%20Cogn.%20Sci.15,%2085%E2%80%9393.%2010.1016/j.tics.2010.11.004%20(2011)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR39">
<span class="label">39.</span><cite>Pisella, L., Rossetti, Y. &amp; Rode, G. Optic ataxia in Bálint–Holmes syndrome. <em>Ann. Phys. Rehabil. Med.</em><strong>60</strong>, 148–154. 10.1016/j.rehab.2016.01.003 (2017).
</cite> [<a href="https://doi.org/10.1016/j.rehab.2016.01.003" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/26874578/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Pisella,%20L.,%20Rossetti,%20Y.%20&amp;%20Rode,%20G.%20Optic%20ataxia%20in%20B%C3%A1lint%E2%80%93Holmes%20syndrome.%20Ann.%20Phys.%20Rehabil.%20Med.60,%20148%E2%80%93154.%2010.1016/j.rehab.2016.01.003%20(2017)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR40">
<span class="label">40.</span><cite>Voytek, B. &amp; Knight, R. T. Prefrontal cortex and basal ganglia contributions to visual working memory. <em>Proc. Natl. Acad. Sci.</em><strong>107</strong>, 18167–18172. 10.1073/pnas.1007277107 (2010).
</cite> [<a href="https://doi.org/10.1073/pnas.1007277107" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC2964236/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/20921401/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Voytek,%20B.%20&amp;%20Knight,%20R.%20T.%20Prefrontal%20cortex%20and%20basal%20ganglia%20contributions%20to%20visual%20working%20memory.%20Proc.%20Natl.%20Acad.%20Sci.107,%2018167%E2%80%9318172.%2010.1073/pnas.1007277107%20(2010)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR41">
<span class="label">41.</span><cite>Szczepanski, S. M., Konen, C. S. &amp; Kastner, S. Mechanisms of spatial attention control in frontal and parietal cortex. <em>J. Neurosci.</em><strong>30</strong>, 148–160. 10.1523/JNEUROSCI.3862-09.2010 (2010).
</cite> [<a href="https://doi.org/10.1523/JNEUROSCI.3862-09.2010" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC2809378/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/20053897/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Szczepanski,%20S.%20M.,%20Konen,%20C.%20S.%20&amp;%20Kastner,%20S.%20Mechanisms%20of%20spatial%20attention%20control%20in%20frontal%20and%20parietal%20cortex.%20J.%20Neurosci.30,%20148%E2%80%93160.%2010.1523/JNEUROSCI.3862-09.2010%20(2010)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR42">
<span class="label">42.</span><cite>D’Ardenne, K. et al. Role of prefrontal cortex and the midbrain dopamine system in working memory updating. <em>Proc. Natl. Acad. Sci.</em><strong>109</strong>, 19900–19909. 10.1073/pnas.1116727109 (2012).
</cite> [<a href="https://doi.org/10.1073/pnas.1116727109" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3523834/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/23086162/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?D%E2%80%99Ardenne,%20K.%20et%20al.%20Role%20of%20prefrontal%20cortex%20and%20the%20midbrain%20dopamine%20system%20in%20working%20memory%20updating.%20Proc.%20Natl.%20Acad.%20Sci.109,%2019900%E2%80%9319909.%2010.1073/pnas.1116727109%20(2012)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR43">
<span class="label">43.</span><cite>Aston-Jones, G. &amp; Cohen, J. An integrative theory of locus coeruleus-norepinephrine function: Adaptive gain and optimal performance. <em>Annu. Rev. Neurosci.</em><strong>28</strong>, 403–450. 10.1146/annurev.neuro.28.061604.135709 (2005).
</cite> [<a href="https://doi.org/10.1146/annurev.neuro.28.061604.135709" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/16022602/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Aston-Jones,%20G.%20&amp;%20Cohen,%20J.%20An%20integrative%20theory%20of%20locus%20coeruleus-norepinephrine%20function:%20Adaptive%20gain%20and%20optimal%20performance.%20Annu.%20Rev.%20Neurosci.28,%20403%E2%80%93450.%2010.1146/annurev.neuro.28.061604.135709%20(2005)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR44">
<span class="label">44.</span><cite>Gilzenrat, M. S., Nieuwenhuis, S., Jepma, M. &amp; Cohen, J. D. Pupil diameter tracks changes in control state predicted by the adaptive gain theory of locus coeruleus function. <em>Cogn. Affect. Behav. Neurosci.</em><strong>10</strong>, 252–269. 10.3758/CABN.10.2.252 (2010).
</cite> [<a href="https://doi.org/10.3758/CABN.10.2.252" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC3403821/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/20498349/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Gilzenrat,%20M.%20S.,%20Nieuwenhuis,%20S.,%20Jepma,%20M.%20&amp;%20Cohen,%20J.%20D.%20Pupil%20diameter%20tracks%20changes%20in%20control%20state%20predicted%20by%20the%20adaptive%20gain%20theory%20of%20locus%20coeruleus%20function.%20Cogn.%20Affect.%20Behav.%20Neurosci.10,%20252%E2%80%93269.%2010.3758/CABN.10.2.252%20(2010)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR45">
<span class="label">45.</span><cite>Segal, O., Barak Lanciano, S. &amp; Nussinovitch, U. Association between body mass index and pupillary light reflex indices. <em>Obes. Med.</em><strong>32</strong>, 100417. 10.1016/j.obmed.2022.100417 (2022).</cite> [<a href="https://scholar.google.com/scholar_lookup?Segal,%20O.,%20Barak%20Lanciano,%20S.%20&amp;%20Nussinovitch,%20U.%20Association%20between%20body%20mass%20index%20and%20pupillary%20light%20reflex%20indices.%20Obes.%20Med.32,%20100417.%2010.1016/j.obmed.2022.100417%20(2022)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR46">
<span class="label">46.</span><cite>Bremner, F. D. Pupillometric evaluation of the dynamics of the pupillary response to a brief light stimulus in healthy subjects. <em>Investig. Ophthalmol. Vis. Sci.</em><strong>53</strong>, 7343–7347. 10.1167/iovs.12-10881 (2012).
</cite> [<a href="https://doi.org/10.1167/iovs.12-10881" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/23036998/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Bremner,%20F.%20D.%20Pupillometric%20evaluation%20of%20the%20dynamics%20of%20the%20pupillary%20response%20to%20a%20brief%20light%20stimulus%20in%20healthy%20subjects.%20Investig.%20Ophthalmol.%20Vis.%20Sci.53,%207343%E2%80%937347.%2010.1167/iovs.12-10881%20(2012)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR47">
<span class="label">47.</span><cite>Guillon, M. et al. The effects of age, refractive status, and luminance on pupil size. <em>Optom. Vis. Sci.</em><strong>93</strong>, 1093–1100. 10.1097/OPX.0000000000000893 (2016).
</cite> [<a href="https://doi.org/10.1097/OPX.0000000000000893" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC5006796/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27232893/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Guillon,%20M.%20et%20al.%20The%20effects%20of%20age,%20refractive%20status,%20and%20luminance%20on%20pupil%20size.%20Optom.%20Vis.%20Sci.93,%201093%E2%80%931100.%2010.1097/OPX.0000000000000893%20(2016)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR48">
<span class="label">48.</span><cite>Naicker, P., Anoopkumar-Dukie, S., Grant, G. D., Neumann, D. L. &amp; Kavanagh, J. J. Central cholinergic pathway involvement in the regulation of pupil diameter, blink rate and cognitive function. <em>Neuroscience</em><strong>334</strong>, 180–190. 10.1016/j.neuroscience.2016.08.009 (2016).
</cite> [<a href="https://doi.org/10.1016/j.neuroscience.2016.08.009" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/27531858/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Naicker,%20P.,%20Anoopkumar-Dukie,%20S.,%20Grant,%20G.%20D.,%20Neumann,%20D.%20L.%20&amp;%20Kavanagh,%20J.%20J.%20Central%20cholinergic%20pathway%20involvement%20in%20the%20regulation%20of%20pupil%20diameter,%20blink%20rate%20and%20cognitive%20function.%20Neuroscience334,%20180%E2%80%93190.%2010.1016/j.neuroscience.2016.08.009%20(2016)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR49">
<span class="label">49.</span><cite>Carrick, F. R. et al. The pupillary light reflex as a biomarker of concussion. <em>Life</em><strong>11</strong>, 1104. 10.3390/life11101104 (2021).
</cite> [<a href="https://doi.org/10.3390/life11101104" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC8537991/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34685475/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Carrick,%20F.%20R.%20et%20al.%20The%20pupillary%20light%20reflex%20as%20a%20biomarker%20of%20concussion.%20Life11,%201104.%2010.3390/life11101104%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR50">
<span class="label">50.</span><cite>Chicco, D. &amp; Jurman, G. The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation. <em>BMC Genom.</em><strong>21</strong>, 6. 10.1186/s12864-019-6413-7 (2020).</cite> [<a href="https://doi.org/10.1186/s12864-019-6413-7" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC6941312/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31898477/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Chicco,%20D.%20&amp;%20Jurman,%20G.%20The%20advantages%20of%20the%20Matthews%20correlation%20coefficient%20(MCC)%20over%20F1%20score%20and%20accuracy%20in%20binary%20classification%20evaluation.%20BMC%20Genom.21,%206.%2010.1186/s12864-019-6413-7%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR51">
<span class="label">51.</span><cite>Boughorbel, S., Jarray, F. &amp; El-Anbari, M. Optimal classifier for imbalanced data using Matthews Correlation Coefficient metric. <em>PLoS One</em><strong>12</strong>, e0177678. 10.1371/journal.pone.0177678 (2017).
</cite> [<a href="https://doi.org/10.1371/journal.pone.0177678" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC5456046/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/28574989/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Boughorbel,%20S.,%20Jarray,%20F.%20&amp;%20El-Anbari,%20M.%20Optimal%20classifier%20for%20imbalanced%20data%20using%20Matthews%20Correlation%20Coefficient%20metric.%20PLoS%20One12,%20e0177678.%2010.1371/journal.pone.0177678%20(2017)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR52">
<span class="label">52.</span><cite>Pedregosa, F. et al. Scikit-learn: Machine learning in Python. <em>J. Mach. Learn. Res.</em><strong>12</strong>, 2825–2830 (2011).</cite> [<a href="https://scholar.google.com/scholar_lookup?Pedregosa,%20F.%20et%20al.%20Scikit-learn:%20Machine%20learning%20in%20Python.%20J.%20Mach.%20Learn.%20Res.12,%202825%E2%80%932830%20(2011)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adda93_" lang="en" class="data-availability-statement"><h3 class="pmc_sec_title">Data Availability Statement</h3>
<p>The data can be provided upon a reasonable request to the corresponding author. The request may subject to approval by the US Army DEVCOM Army Research Laboratory and the Human Participants Committee of the University of California, Santa Barbara.</p></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from Scientific Reports are provided here courtesy of <strong>Nature Publishing Group</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1038/s41598-025-16165-4"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/41598_2025_Article_16165.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (3.5 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12368119/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12368119/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12368119%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12368119/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12368119/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12368119/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40836059/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12368119/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40836059/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12368119/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12368119/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="MKEVgcer4NytoTHEtSDf3NX5jJGzz6Y9Qje51SRE6PLAylNtFc80Vr2ksh9qe1Kv">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
    

    </body>
</html>
