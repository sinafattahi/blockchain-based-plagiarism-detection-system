
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            Exploring the impact of display types of information about autonomous driving in semi-autonomous vehicles on drivers’ situation awareness and take-over performance under different driving scenarios - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="AE532ED98AF221B3052ED900192DCCAA.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="plosone">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373254/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="PLOS One">
<meta name="citation_title" content="Exploring the impact of display types of information about autonomous driving in semi-autonomous vehicles on drivers’ situation awareness and take-over performance under different driving scenarios">
<meta name="citation_author" content="Chengmin Zhou">
<meta name="citation_author_institution" content="College of Furnishings and Industrial Design, Nanjing Forestry University, Nanjing, Jiangsu, China">
<meta name="citation_author_institution" content="Jiangsu Co-innovation Center of Efficient Processing and Utilization of Forest Resources, Nanjing, China">
<meta name="citation_author" content="Yuxuan Luo">
<meta name="citation_author_institution" content="College of Furnishings and Industrial Design, Nanjing Forestry University, Nanjing, Jiangsu, China">
<meta name="citation_author_institution" content="Jiangsu Co-innovation Center of Efficient Processing and Utilization of Forest Resources, Nanjing, China">
<meta name="citation_author" content="Jake Kaner">
<meta name="citation_author_institution" content="School of Art and Design, Nottingham Trent University, Nottingham, United Kingdom">
<meta name="citation_publication_date" content="2025 Aug 22">
<meta name="citation_volume" content="20">
<meta name="citation_issue" content="8">
<meta name="citation_firstpage" content="e0329760">
<meta name="citation_doi" content="10.1371/journal.pone.0329760">
<meta name="citation_pmid" content="40845037">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373254/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373254/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373254/pdf/pone.0329760.pdf">
<meta name="description" content="With the advent of the era of autonomous driving, designing an effective and appropriate autonomous driving information display is crucial for ensuring driving safety. Head-up Display (HUD) is regarded as a promising way for presenting in-vehicle ...">
<meta name="og:title" content="Exploring the impact of display types of information about autonomous driving in semi-autonomous vehicles on drivers’ situation awareness and take-over performance under different driving scenarios">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="With the advent of the era of autonomous driving, designing an effective and appropriate autonomous driving information display is crucial for ensuring driving safety. Head-up Display (HUD) is regarded as a promising way for presenting in-vehicle ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373254/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12373254">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1371/journal.pone.0329760"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/pone.0329760.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12373254%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12373254/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12373254/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373254/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-plosone.png" alt="PLOS One logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to PLOS One" title="Link to PLOS One" shape="default" href="https://doi.org/10.1371/journal.pone.0329760" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">PLoS One</button></div>. 2025 Aug 22;20(8):e0329760. doi: <a href="https://doi.org/10.1371/journal.pone.0329760" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1371/journal.pone.0329760</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22PLoS%20One%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22PLoS%20One%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22PLoS%20One%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22PLoS%20One%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>Exploring the impact of display types of information about autonomous driving in semi-autonomous vehicles on drivers’ situation awareness and take-over performance under different driving scenarios</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Zhou%20C%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Chengmin Zhou</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Chengmin Zhou</span></h3>
<div class="p">
<sup>1</sup>College of Furnishings and Industrial Design, Nanjing Forestry University, Nanjing, Jiangsu, China</div>
<div class="p">
<sup>2</sup>Jiangsu Co-innovation Center of Efficient Processing and Utilization of Forest Resources, Nanjing, China</div>
<div>Conceptualization, Funding acquisition, Methodology, Project administration, Writing – original draft</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Zhou%20C%22%5BAuthor%5D" class="usa-link"><span class="name western">Chengmin Zhou</span></a>
</div>
</div>
<sup>1,</sup><sup>2,</sup><sup>*</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Luo%20Y%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Yuxuan Luo</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">Yuxuan Luo</span></h3>
<div class="p">
<sup>1</sup>College of Furnishings and Industrial Design, Nanjing Forestry University, Nanjing, Jiangsu, China</div>
<div class="p">
<sup>2</sup>Jiangsu Co-innovation Center of Efficient Processing and Utilization of Forest Resources, Nanjing, China</div>
<div>Data curation, Formal analysis, Investigation, Visualization, Writing – original draft</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Luo%20Y%22%5BAuthor%5D" class="usa-link"><span class="name western">Yuxuan Luo</span></a>
</div>
</div>
<sup>1,</sup><sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kaner%20J%22%5BAuthor%5D" class="usa-link" aria-describedby="id3"><span class="name western">Jake Kaner</span></a><div hidden="hidden" id="id3">
<h3><span class="name western">Jake Kaner</span></h3>
<div class="p">
<sup>3</sup>School of Art and Design, Nottingham Trent University, Nottingham, United Kingdom</div>
<div>Writing – review &amp; editing</div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Kaner%20J%22%5BAuthor%5D" class="usa-link"><span class="name western">Jake Kaner</span></a>
</div>
</div>
<sup>3</sup>
</div>
<div class="cg p">Editor: <span class="name western">Zhihong (Arry) Yao</span><sup>4</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="aff001">
<sup>1</sup>College of Furnishings and Industrial Design, Nanjing Forestry University, Nanjing, Jiangsu, China</div>
<div id="aff002">
<sup>2</sup>Jiangsu Co-innovation Center of Efficient Processing and Utilization of Forest Resources, Nanjing, China</div>
<div id="aff003">
<sup>3</sup>School of Art and Design, Nottingham Trent University, Nottingham, United Kingdom</div>
<div id="edit1">
<sup>4</sup>Southwest Jiaotong University, CHINA</div>
<div class="author-notes p">
<div class="fn" id="coi001"><p><strong>Competing Interests: </strong>The authors have declared that no competing interests exist.</p></div>
<div class="fn" id="cor001">
<sup>✉</sup><p class="display-inline">* E-mail: <span>zcm78@163.com</span></p>
</div>
</div>
<h4 class="font-secondary">Roles</h4>
<div class="p">
<strong class="contrib"><span class="name western">Chengmin Zhou</span></strong>: <span class="role">Conceptualization, Funding acquisition, Methodology, Project administration, Writing – original draft</span>
</div>
<div>
<strong class="contrib"><span class="name western">Yuxuan Luo</span></strong>: <span class="role">Data curation, Formal analysis, Investigation, Visualization, Writing – original draft</span>
</div>
<div>
<strong class="contrib"><span class="name western">Jake Kaner</span></strong>: <span class="role">Writing – review &amp; editing</span>
</div>
<div class="p">
<strong class="contrib"><span class="name western">Zhihong (Arry) Yao</span></strong>: <span class="role">Editor</span>
</div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2025 Apr 8; Accepted 2025 Jul 21; Collection date 2025.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© 2025 Zhou et al</div>
<p>This is an open access article distributed under the terms of the <a href="https://creativecommons.org/licenses/by/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Creative Commons Attribution License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12373254  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40845037/" class="usa-link">40845037</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="abstract1"><h2>Abstract</h2>
<p>With the advent of the era of autonomous driving, designing an effective and appropriate autonomous driving information display is crucial for ensuring driving safety. Head-up Display (HUD) is regarded as a promising way for presenting in-vehicle information in the future. This study conducted a simulation experiment to explore the impacts of three types of autonomous driving information displays on HUD on Situation Awareness (SA) and take-over performance, while considering the complexity of different driving scenarios. The experiment used in this study adopted a Latin square experimental design and employed an integrated eye-tracking technology with self-reporting and the Situation Awareness Global Assessment Technique (SAGAT). The results show that although young drivers perform better with the Augmented Reality (AR) display in various complex scenarios, particularly in high-complexity scenarios (the fixation duration with AR display was significantly shorter than that with Pseudo-3D (P3D) display; P = 0.012). However, the advantages of the AR display will weaken as the complexity of the scenarios decreases. Additionally, the Surround Recognition (SR) display is more likely to reduce drivers’ SA (the fixation counts on the SR display was significantly higher than that on the P3D and AR displays; P &lt; 0.001) and take-over efficiency (the take-over reaction time for the SR display was significantly longer than that for the AR display; P = 0.09), especially in medium-complexity scenarios. Meanwhile, male participants pay more attention to the autonomous driving information on HUD. Nevertheless, there is no obvious difference between males and females in terms of specific preferences for the types of displays. The results of this study are expected to provide some inspiration for the design of autonomous driving information on HUD.</p></section><section id="sec001"><h2 class="pmc_sec_title">Introduction</h2>
<p>With the large-scale application of artificial intelligence and 5G networks, product automation is revolutionizing various fields. Human-computer interaction in modern electric intelligent vehicles is primarily challenged by complex driving tasks [<a href="#pone.0329760.ref001" class="usa-link" aria-describedby="pone.0329760.ref001">1</a>,<a href="#pone.0329760.ref002" class="usa-link" aria-describedby="pone.0329760.ref002">2</a>]. Research has shown that autonomous driving technologies can effectively reduce accidents caused by driver error [<a href="#pone.0329760.ref003" class="usa-link" aria-describedby="pone.0329760.ref003">3</a>].</p>
<p>Currently, the autonomous driving technology system can be divided into two major technical paradigms, namely the basic type and the enhanced type, according to the SAE J3016 standard. Basic autonomous driving covers levels from L1 (Driver Assistance) to L2 (Semi-autonomous Driving), and its technical characteristics are manifested as single-dimensional control capabilities. For example, Adaptive Cruise Control (ACC) for longitudinal control, Lane Keeping System (LKS) for lateral control, and Automatic Emergency Braking (AEB) for safety intervention. Through the function combination strategy (e.g., ACC + LKS = Lane Centering Control, LCC), such systems can achieve coordinated lateral and longitudinal control in specific scenarios [<a href="#pone.0329760.ref004" class="usa-link" aria-describedby="pone.0329760.ref004">4</a>]. Enhanced autonomous driving focuses on the technological evolution at the L2+ level, serving as the core form of the transition from L2 to L3 (Conditional Autonomous Driving), but it is still at the semi-autonomous driving level. In essence, it is a combination of multi-modal environmental perception and pre-set domain control capabilities. Relying on high-precision maps or computer vision algorithms, it can achieve complex functions such as automatic lane changing and autonomous overtaking in limited scenarios within the Operational Design Domain (ODD) like highways [<a href="#pone.0329760.ref005" class="usa-link" aria-describedby="pone.0329760.ref005">5</a>]. Advanced Driver Assistance Systems (ADAS), as a representative of L2+ autonomous driving, have developed rapidly in the past decade and are becoming increasingly popular worldwide [<a href="#pone.0329760.ref006" class="usa-link" aria-describedby="pone.0329760.ref006">6</a>,<a href="#pone.0329760.ref007" class="usa-link" aria-describedby="pone.0329760.ref007">7</a>].</p>
<p>Existing research has generally demonstrated that autonomous driving technologies can acquire information about changing environments more efficiently than humans and demonstrate rational driving behaviors [<a href="#pone.0329760.ref008" class="usa-link" aria-describedby="pone.0329760.ref008">8</a>,<a href="#pone.0329760.ref009" class="usa-link" aria-describedby="pone.0329760.ref009">9</a>]. Nonetheless, there is still a lack of consumer trust in autonomous driving technology, as evidenced by the volume of user data and the numerous reports of L2+ assisted driving malfunctions from different automakers [<a href="#pone.0329760.ref010" class="usa-link" aria-describedby="pone.0329760.ref010">10</a>]. Therefore, manual driving involvement must still be taken into account in contemporary semi-autonomous driving system designs [<a href="#pone.0329760.ref011" class="usa-link" aria-describedby="pone.0329760.ref011">11</a>,<a href="#pone.0329760.ref012" class="usa-link" aria-describedby="pone.0329760.ref012">12</a>]. In the design of the Human-Machine Interface (HMI) for L2+ semi-autonomous electric vehicles, it is essential to adopt a multi-modal information presentation strategy to ensure that drivers maintain sufficient Situation Awareness (SA) capabilities during the handover of vehicle control [<a href="#pone.0329760.ref013" class="usa-link" aria-describedby="pone.0329760.ref013">13</a>]. Research shows that in the lower levels of automated driving, the driver should maintain maximum focus on the road and that Head-up display (HUD) is the most effective means of providing information [<a href="#pone.0329760.ref014" class="usa-link" aria-describedby="pone.0329760.ref014">14</a>]. With the advancement of technology, electric vehicles are increasingly utilizing various in-vehicle HUDs, including the Widescreen Head-Up Display (W-HUD) and the Augmented Reality Head-Up Display (AR-HUD). It’s becoming common practice in new-generation electric cars in the Chinese market to show various autonomous driving-related data through the HUD.</p>
<p>The core differences between the W-HUD and theAR-HUD lie in information presentation and spatial depth. The W-HUD projects static driving information (eg., vehicle speed, navigation prompts) to a virtual image distance (VID) of 2.5 meters via optical reflection. Its technical characteristics are limited by the field of view (FOV) and the static nature of the displayed content [<a href="#pone.0329760.ref015" class="usa-link" aria-describedby="pone.0329760.ref015">15</a>]. In contrast, AR-HUD leverages waveguide technology and AR algorithms to achieve dynamic 3D projection at a viewing distance exceeding 10 meters, directly fusing navigation, warnings, and other information with the real driving environment.</p>
<p>SA was first employed to evaluate the proficiency of machine operators, but it is now acknowledged as a crucial factor in the automobile industry, specifically in autonomous driving technologies. It offers valuable insights into the driver’s condition and driving proficiency [<a href="#pone.0329760.ref016" class="usa-link" aria-describedby="pone.0329760.ref016">16</a>]. In dynamic driving operations, SA has a significant impact on human decision-making processes. It requires comprehensive, accurate, and real-time information acquisition by the driver about the surrounding driving environment and situation, including the process of acquiring the elements of the environment (SA level 1-SAL1), understanding them (SA level 2-SAL2), and making predictions about their future state (SA level 3-SAL3) [<a href="#pone.0329760.ref017" class="usa-link" aria-describedby="pone.0329760.ref017">17</a>,<a href="#pone.0329760.ref018" class="usa-link" aria-describedby="pone.0329760.ref018">18</a>]. SAL3 is the highest level in a hierarchical arrangement of these three levels. The SA system has the characteristic of dual subjects, encompassing both the human perception dimension of the driver and the machine perception dimension of the intelligent system [<a href="#pone.0329760.ref019" class="usa-link" aria-describedby="pone.0329760.ref019">19</a>]. The system’s and the driver’s respective SA skills will trade off as automated driving technology advances. Most electric intelligent vehicles include L2+ level automated driving technology, which requires constant SA exchanges between the driver and the system in order to achieve secure and productive cooperative driving. Designing visual signals is a frequent strategy to assist drivers in regaining and maintaining SA [<a href="#pone.0329760.ref020" class="usa-link" aria-describedby="pone.0329760.ref020">20</a>]. For instance, the layout of the display system, which provides spatial information about the car and its surroundings, improves the driver’s sense of awareness [<a href="#pone.0329760.ref021" class="usa-link" aria-describedby="pone.0329760.ref021">21</a>]. Almost all electric intelligent vehicles equipped with autonomous driving functions have visual displays of autonomous driving information. However, if the provision of additional information leads to a decrease in the driver’s SA capabilities, it may be detrimental [<a href="#pone.0329760.ref022" class="usa-link" aria-describedby="pone.0329760.ref022">22</a>]. Thus, more investigation is required to determine how autonomous driving information display types affect driver safety.</p>
<p>The main function of the autopilot take-over task is to initiate a Take-over Request (TOR) from the system, asking that the driver resume control of the vehicle in the event of a real-time driving situation outside the ODD or for reasons determined by the autopilot system itself. The driver’s SA capacity to determine the next course of action is also greatly influenced by the objective road circumstances. Traffic density, weather, and road conditions are objective driving environment characteristics that might affect a driver’s driving take-over performance [<a href="#pone.0329760.ref023" class="usa-link" aria-describedby="pone.0329760.ref023">23</a>]. While driving in high-density environments and inclement weather can make it more difficult for drivers to react and maneuver, they can also make it more common for them to perform braking, deceleration, and lane changes. The influence of traffic environment characteristics on the efficiency of driving take-overs presents a non-linear two-way regulatory effect. This shortens the time between an object’s proximity to another vehicle and the driver’s reaction to the operation [<a href="#pone.0329760.ref024" class="usa-link" aria-describedby="pone.0329760.ref024">24</a>]. Furthermore, driving environments that are excessively basic and monotonous might also impair drivers’ ability to drive safely [<a href="#pone.0329760.ref025" class="usa-link" aria-describedby="pone.0329760.ref025">25</a>]. This is why it’s critical to consider the possibility of reduced cognitive function associated with repetitive driving tasks. Studying how exterior factors and the autonomous driving information display on the HUD interact to influence driver take-over responses in a brief amount of time is critical.</p>
<p>This study integrates existing research paradigms to establish an evaluation system for autonomous driving information display types on HUDs, incorporating scenario complexity. It focuses on determining the effects of different existing HUD autonomous driving information display types on young drivers’ SA ability under multilevel complexity driving scenarios and their effects on their take-over performance under multilevel complexity take-over scenarios. The study addresses two scientific questions: 1. What type of autonomous driving information display is helpful for enhancing the driver’s SA ability and take-over ability? 2. Will the advantages and disadvantages of different autonomous driving information display types change according to the variation in the complexity of the driving scenarios?</p>
<p>Based on an eye-tracking technique and SAGAT questionnaire reports, respectively, an experiment was carried out to examine the roles of different display styles in situations of various complexity. The objective of this approach is to provide empirical evidence for optimizing existing autonomous driving information displays on HUDs and offer recommendations for the development of such displays.</p></section><section id="sec002"><h2 class="pmc_sec_title">Methods and process</h2>
<section id="sec003"><h3 class="pmc_sec_title">Display the type of automatic driving information</h3>
<p>This study concentrates on determining the significant impact of the design of autonomous driving information on the HUD on drivers, rather than evaluating the specific design of the display of autonomous driving information. The three categories of information displayed on the HUD are selected from popular automobile brands in the Chinese market according to different display types of autonomous driving information, which mainly include environmental information and vehicle information display. The first type of display scheme is the Pseudo-Three-Dimensional (P3D) spatial perception based on the W-HUD. With the application of high-definition sensor fusion technology, the automatic driving information presented on the W-HUD has realized the intuitive mapping of key road conditions, from a P3D display without a car (e.g., NIO ES6) to a P3D display with a car (e.g., AITO M5). The second type is to project Situational Recognition (SR) autonomous driving information onto the HUD. With the development of real-time rendering technology, SR interface displays are widely adopted in the current Chinese automotive market. Compared with the traditional P3D information presentation, details such as the body outline and turn signal flashing on the SR interface are clearly visible (e.g., Li L9). Even road directions, traffic signs, and even potential traffic conflict points are visualized to the driver (e.g., ONVO L60). The third type is autonomous driving information designed on AR-HUD. AR technology can seamlessly integrate virtual navigation guidance, vehicle status, and surrounding environment perception information into real road scenes (e.g., Panasonic CES 2021). Meanwhile, more and more manufacturers are leveraging AR technology to make navigation and other information more entertaining (e.g., AITO M9). <a href="#pone.0329760.g001" class="usa-link">Fig 1</a> lists the three display types of autonomous driving information on the HUD in the Chinese vehicle market.</p>
<figure class="fig xbox font-sm" id="pone.0329760.g001"><h4 class="obj_head">Fig 1. Three display types of autonomous driving information on the HUD in the Chinese vehicle market.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373254_pone.0329760.g001.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4fe0/12373254/636d127d2e5b/pone.0329760.g001.jpg" loading="lazy" height="313" width="730" alt="Fig 1"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329760.g001/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p>To minimize the impact of the differences in autonomous driving functions on the driver’s SA and take-over performance, the variables of autonomous driving functions are fixed according to the existing display types of autonomous driving information on the HUD. This study only takes into account vehicle interfaces with AEB, ACC and LKA functions. We have summarized and designed three different HUD interfaces as shown in <a href="#pone.0329760.g002" class="usa-link">Fig 2</a>.</p>
<figure class="fig xbox font-sm" id="pone.0329760.g002"><h4 class="obj_head">Fig 2. Displays types of autonomous driving information: a) P3D display on the W-HUD; b) SR display on the W-HUD; c) display on the AR-HUD.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373254_pone.0329760.g002.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4fe0/12373254/2c0334690989/pone.0329760.g002.jpg" loading="lazy" height="153" width="724" alt="Fig 2"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329760.g002/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p>Type A (P3D) is the automatic driving information presented on the W-HUD in P3D graphics, mainly static display of lane lines and self-driving vehicles.</p>
<p>Type B (SR) is the SR interface projected onto the W-HUD to dynamically display multiple lane lines, autonomous vehicles, and other traffic participants.</p>
<p>Type C (AR) is autonomous driving information superimposed on a real road scene, and virtual displays of lane lines and other traffic participants’ prompts.</p></section><section id="sec004"><h3 class="pmc_sec_title">Scene complexity</h3>
<p>The complexity of the scenario may have a bigger detrimental effect on driver safety, according to research, than the HUD’s actual design [<a href="#pone.0329760.ref026" class="usa-link" aria-describedby="pone.0329760.ref026">26</a>]. Three categories were created for the scene in this study using the scene system description model based on PEGASUS: road attributes, traffic attributes, and general environmental condition attributes, as shown in <a href="#pone.0329760.g003" class="usa-link">Fig 3</a>. Also used are the publicly accessible datasets from the Wolfe (2020) study, which comprises 503 8-second movies shot from an automobile recorder’s point of view [<a href="#pone.0329760.ref027" class="usa-link" aria-describedby="pone.0329760.ref027">27</a>]. Considering the differences in road scenarios between China and the United States, the traffic signs, intersection designs, and driver interaction behaviors in the original scenarios have been adapted to local conditions to ensure the equivalence of the complexity assessment framework between the road environments of China and the United States. Based on the driving scenario images secondarily screened from the dataset, which include different weather conditions, seasons, and times on urban, rural, and highway sections, key elements are extracted to form scene factors, as shown in <a href="#pone.0329760.g004" class="usa-link">Fig 4</a>, which complements and improves the framework of the complex element model of semi-autonomous driving scenarios.</p>
<figure class="fig xbox font-sm" id="pone.0329760.g003"><h4 class="obj_head">Fig 3. A path analysis model of the relationship between various scenario elements and traffic scenarios.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373254_pone.0329760.g003.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4fe0/12373254/4553bf684166/pone.0329760.g003.jpg" loading="lazy" height="357" width="660" alt="Fig 3"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329760.g003/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><figure class="fig xbox font-sm" id="pone.0329760.g004"><h4 class="obj_head">Fig 4. Conditional autonomous driving scenario complexity hierarchy.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373254_pone.0329760.g004.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4fe0/12373254/c20b3e3d8b38/pone.0329760.g004.jpg" loading="lazy" height="287" width="706" alt="Fig 4"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329760.g004/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p>When conditional autonomous driving scenarios are graded for complexity, factors such as the surrounding environment, road conditions, traffic flow, and driving conditions are combined to create a complicated driving environment. The Entropy Weight Method (EWM) is an objective weighting approach based on information entropy, which can integrate subjective with objective data. It determines weights by quantifying the information dispersion of indicators, providing an objective basis for decision-making analysis in multi-dimensional complex systems [<a href="#pone.0329760.ref028" class="usa-link" aria-describedby="pone.0329760.ref028">28</a>]. The principle is to utilize the amount of information provided by the indicator for weighting. For each given indicator, a higher entropy number indicates less discreteness, less information provided, less impact on the evaluation’s main goal, and a lower weight allocated to it. At present, scholars have applied EWM to the research of autonomous driving decision-making and driving scenarios. Pan (2022) employed the EWM to evaluate the operational characteristics of multi-lane turbo roundabouts and select optimal schemes [<a href="#pone.0329760.ref029" class="usa-link" aria-describedby="pone.0329760.ref029">29</a>]. Fu (2023) calculated a comprehensive weight coefficient for driving characteristic events through EWM, providing support for subsequent autonomous driving decisions [<a href="#pone.0329760.ref030" class="usa-link" aria-describedby="pone.0329760.ref030">30</a>]. To provide an effective basis for complexity analysis of conditional autonomous driving scenarios, this study adopted EWM to objectively determine the weight coefficients of various influencing factors in the driving scenario complexity evaluation system. Relevant experts were invited to score the importance of influencing factors, such as road conditions and traffic flow. The scoring values were then calculated to compute the scenario complexity level based on comprehensive indicators, resulting in conditional autonomous driving scenarios with different complexity levels.</p>
<p>A seven-point Likert scale was used to collect expert evaluations of the scenario elements. Ten experienced drivers were invited between May 20th, 2024 and May 22nd, 2024. This study strictly adhered to ethical guidelines, and the Ethics Committee of Nanjing Forestry University (Science and Technology Department of Nanjing Forestry University) has evaluated and authorized this protocol (Permit Number: 2024-05-16-11). All participants in this study were aware of its background, methodological procedures, results, and purpose, and had signed a written informed consent to participate in the study. In this study, drivers are classified as novices with less than 500 miles of driving experience and non-novices with more than 500 miles of driving experience [<a href="#pone.0329760.ref031" class="usa-link" aria-describedby="pone.0329760.ref031">31</a>]. The complexity judgment matrix is then built when the scene factor weights under the various elements are determined. After obtaining the expert rating data, it is necessary to construct a judgment matrix for the complexity weights of different factors, which is calculated as follows:</p>
<table class="disp-formula p" id="pone.0329760.e001"><tr>
<td class="formula"><math id="M1" display="block" overflow="linebreak"><mrow><mrow><msup><mrow><mi>X</mi></mrow><mrow><mi>*</mi></mrow></msup><mo>=</mo><mo>[</mo><mtable><mtr><mtd><msubsup><mrow><mi>X</mi></mrow><mrow><mn>11</mn></mrow><mrow><mi>*</mi></mrow></msubsup></mtd><mtd><mo>⋯</mo></mtd><mtd><msubsup><mrow><mi>X</mi></mrow><mrow><mn>1</mn><mi>j</mi></mrow><mrow><mi>*</mi></mrow></msubsup></mtd><mtd><mo>⋯</mo></mtd><mtd><msubsup><mrow><mi>x</mi></mrow><mrow><mn>1</mn><mi>n</mi></mrow><mrow><mi>*</mi></mrow></msubsup></mtd></mtr><mtr><mtd><msubsup><mrow><mi>X</mi></mrow><mrow><mi>i</mi><mn>1</mn></mrow><mrow><mi>*</mi></mrow></msubsup></mtd><mtd><mo>⋯</mo></mtd><mtd><msubsup><mrow><mi>X</mi></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mi>*</mi></mrow></msubsup></mtd><mtd><mo>⋯</mo></mtd><mtd><msubsup><mrow><mi>x</mi></mrow><mrow><mi>i</mi><mi>n</mi></mrow><mrow><mi>*</mi></mrow></msubsup></mtd></mtr><mtr><mtd><msubsup><mrow><mi>X</mi></mrow><mrow><mi>m</mi><mn>1</mn></mrow><mrow><mi>*</mi></mrow></msubsup></mtd><mtd><mo>⋯</mo></mtd><mtd><msubsup><mrow><mi>X</mi></mrow><mrow><mi>m</mi><mi>j</mi></mrow><mrow><mi>*</mi></mrow></msubsup></mtd><mtd><mo>⋯</mo></mtd><mtd><msubsup><mrow><mi>x</mi></mrow><mrow><mi>m</mi><mi>n</mi></mrow><mrow><mi>*</mi></mrow></msubsup></mtd></mtr></mtable><mo>]</mo></mrow></mrow></math></td>
<td class="label">(1)</td>
</tr></table>
<p>Where m is the number of evaluation objects, n is the number of evaluation factors and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0329760.e002"><math id="M2" display="inline" overflow="linebreak"><mrow><msubsup><mrow><mi>X</mi></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mi>*</mi></mrow></msubsup></mrow></math></span> is the value of the jth factor for the ith evaluation object. The judgment orthogonal matrix is also normalized as follows:</p>
<table class="disp-formula p" id="pone.0329760.e003"><tr>
<td class="formula"><math id="M3" display="block" overflow="linebreak"><mrow><mrow><msup><mrow><mi>X</mi></mrow><mrow><mi>i</mi></mrow></msup><mo>=</mo><mfrac><mrow><msubsup><mrow><mi>X</mi></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mi>*</mi></mrow></msubsup><mo>−</mo><mo>min</mo><msubsup><mrow><mi>X</mi></mrow><mrow><mi>j</mi></mrow><mrow><mi>*</mi></mrow></msubsup></mrow><mrow><mo>max</mo><mo>{</mo><mtable><mtr><mtd><msubsup><mrow><mi>X</mi></mrow><mrow><mi>j</mi></mrow><mrow><mi>*</mi></mrow></msubsup></mtd></mtr></mtable><mo>}</mo><mo>−</mo><mo>min</mo><mo>{</mo><mtable><mtr><mtd><msubsup><mrow><mi>X</mi></mrow><mrow><mi>j</mi></mrow><mrow><mi>*</mi></mrow></msubsup></mtd></mtr></mtable><mo>}</mo></mrow></mfrac></mrow></mrow></math></td>
<td class="label">(2)</td>
</tr></table>
<p>Where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0329760.e004"><math id="M4" display="inline" overflow="linebreak"><mrow><msup><mrow><mtext mathvariant="italic">X</mtext></mrow><mrow><mtext mathvariant="italic">i</mtext></mrow></msup></mrow></math></span> is the normalized value in the matrix, i is the serial number of the evaluation object, and j is the serial number of the evaluation factor. The weight of the jth factor of the ith evaluation object is introduced and calculated as follows:</p>
<table class="disp-formula p" id="pone.0329760.e005"><tr>
<td class="formula"><math id="M5" display="block" overflow="linebreak"><mrow><mrow><msub><mrow><mi>X</mi></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mrow><msubsup><mrow><mi>X</mi></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mi>*</mi></mrow></msubsup></mrow><mrow><mstyle displaystyle="false" scriptlevel="0"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></msubsup><msubsup><mrow><mi>X</mi></mrow><mrow><mi>i</mi><mi>j</mi></mrow><mrow><mi>*</mi></mrow></msubsup></mstyle></mrow></mfrac></mrow></mrow></math></td>
<td class="label">(3)</td>
</tr></table>
<p>The information entropy value (<em>e</em><sub><em>j</em></sub>), information entropy redundancy (<em>g</em><sub><em>j</em></sub>), and factor weights (<em>w</em><sub><em>j</em></sub>) of the jth factor are then calculated using <a href="#pone.0329760.e006" class="usa-link">Eqs (4)</a>–(<a href="#pone.0329760.e008" class="usa-link">6</a>) as follows:</p>
<table class="disp-formula p" id="pone.0329760.e006"><tr>
<td class="formula"><math id="M6" display="block" overflow="linebreak"><mrow><mrow><msub><mrow><mi>e</mi></mrow><mrow><mi>j</mi></mrow></msub><mo>=</mo><mi>K</mi><mstyle displaystyle="false" scriptlevel="0"><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>n</mi></mrow></msubsup><msub><mrow><mi>p</mi></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>ln</mi><mo>(</mo><mtable><mtr><mtd><msub><mrow><mi>p</mi></mrow><mrow><mi>i</mi><mi>j</mi></mrow></msub></mtd></mtr></mtable><mo>)</mo></mstyle></mrow></mrow></math></td>
<td class="label">(4)</td>
</tr></table>
<table class="disp-formula p" id="pone.0329760.e007"><tr>
<td class="formula"><math id="M7" display="block" overflow="linebreak"><mrow><mrow><msub><mrow><mi>g</mi></mrow><mrow><mi>j</mi></mrow></msub><mo>=</mo><mn>1</mn><mo>−</mo><msub><mrow><mi>e</mi></mrow><mrow><mi>j</mi></mrow></msub></mrow></mrow></math></td>
<td class="label">(5)</td>
</tr></table>
<table class="disp-formula p" id="pone.0329760.e008"><tr>
<td class="formula"><math id="M8" display="block" overflow="linebreak"><mrow><mrow><msub><mrow><mi>w</mi></mrow><mrow><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mrow><msub><mrow><mi>g</mi></mrow><mrow><mi>j</mi></mrow></msub></mrow><mrow><mstyle displaystyle="false" scriptlevel="0"><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>m</mi></mrow></msubsup><msub><mrow><mi>g</mi></mrow><mrow><mi>j</mi></mrow></msub></mstyle></mrow></mfrac><mspace width="0.222em"></mspace><mspace width="0.222em"></mspace><mo>(</mo><mtable><mtr><mtd><mn>1</mn><mo>≤</mo><mi>j</mi><mo>≤</mo><mi>m</mi></mtd></mtr></mtable><mo>)</mo></mrow></mrow></math></td>
<td class="label">(6)</td>
</tr></table>
<p>Where <em>k</em> &gt; 0, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0329760.e009"><math id="M9" display="inline" overflow="linebreak"><mrow><mi>k</mi><mo>=</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mi>ln</mi><mi>n</mi></mrow></mfrac></mrow></math></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0329760.e010"><math id="M10" display="inline" overflow="linebreak"><mrow><msub><mrow><mi>e</mi></mrow><mrow><mi>j</mi></mrow></msub><mo>≥</mo><mn>0</mn></mrow></math></span>. The information entropy of each scene element component and the entropy weights of each design index are determined using <a href="#pone.0329760.e001" class="usa-link">Eqs (1)</a>–(<a href="#pone.0329760.e008" class="usa-link">6</a>). <a href="#pone.0329760.t001" class="usa-link">Table 1</a> displays the compiled results.</p>
<section class="tw xbox font-sm" id="pone.0329760.t001"><h4 class="obj_head">Table 1. Conditional autonomous driving scenario complexity factor perceptual weights.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">Target layer</th>
<th align="left" rowspan="1" colspan="1">First level factor</th>
<th align="left" rowspan="1" colspan="1">Second level factor</th>
<th align="left" rowspan="1" colspan="1">Third level factor</th>
<th align="left" rowspan="1" colspan="1">Information Entropy(<em>H</em><sub><em>j</em></sub>)</th>
<th align="left" rowspan="1" colspan="1">Weight(<em>W</em><sub><em>j</em></sub>)</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="24" colspan="1">Scene complexity</td>
<td align="left" rowspan="10" colspan="1">Road Properties</td>
<td align="left" rowspan="2" colspan="1">Number of roads</td>
<td align="left" rowspan="1" colspan="1">Single Lane</td>
<td align="left" rowspan="1" colspan="1">0.927</td>
<td align="left" rowspan="1" colspan="1">1.955</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Multi-Lane</td>
<td align="left" rowspan="1" colspan="1">0.916</td>
<td align="left" rowspan="1" colspan="1">2.235</td>
</tr>
<tr>
<td align="left" rowspan="2" colspan="1">Elevation</td>
<td align="left" rowspan="1" colspan="1">Gentle slope</td>
<td align="left" rowspan="1" colspan="1">0.884</td>
<td align="left" rowspan="1" colspan="1">3.112</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Steep slope</td>
<td align="left" rowspan="1" colspan="1">0.880</td>
<td align="left" rowspan="1" colspan="1">3.217</td>
</tr>
<tr>
<td align="left" rowspan="2" colspan="1">Junction</td>
<td align="left" rowspan="1" colspan="1">Ingress and egress</td>
<td align="left" rowspan="1" colspan="1">0.917</td>
<td align="left" rowspan="1" colspan="1">2.216</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Intersection</td>
<td align="left" rowspan="1" colspan="1">0.828</td>
<td align="left" rowspan="1" colspan="1">4.600</td>
</tr>
<tr>
<td align="left" rowspan="2" colspan="1">Roadblocks</td>
<td align="left" rowspan="1" colspan="1">Static roadblocks</td>
<td align="left" rowspan="1" colspan="1">0.880</td>
<td align="left" rowspan="1" colspan="1">3.217</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Dynamic roadblocks</td>
<td align="left" rowspan="1" colspan="1">0.803</td>
<td align="left" rowspan="1" colspan="1">5.252</td>
</tr>
<tr>
<td align="left" rowspan="2" colspan="1">Road conditions</td>
<td align="left" rowspan="1" colspan="1">Flat</td>
<td align="left" rowspan="1" colspan="1">0.888</td>
<td align="left" rowspan="1" colspan="1">2.989</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Potholes</td>
<td align="left" rowspan="1" colspan="1">0.881</td>
<td align="left" rowspan="1" colspan="1">3.186</td>
</tr>
<tr>
<td align="left" rowspan="8" colspan="1">Transportation Properties</td>
<td align="left" rowspan="2" colspan="1">Number of traffic participants</td>
<td align="left" rowspan="1" colspan="1">small number</td>
<td align="left" rowspan="1" colspan="1">0.929</td>
<td align="left" rowspan="1" colspan="1">1.906</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Numerous</td>
<td align="left" rowspan="1" colspan="1">0.861</td>
<td align="left" rowspan="1" colspan="1">3.708</td>
</tr>
<tr>
<td align="left" rowspan="2" colspan="1">Speed of traffic participant</td>
<td align="left" rowspan="1" colspan="1">Low speed</td>
<td align="left" rowspan="1" colspan="1">0.918</td>
<td align="left" rowspan="1" colspan="1">2.203</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">High speed</td>
<td align="left" rowspan="1" colspan="1">0.916</td>
<td align="left" rowspan="1" colspan="1">2.235</td>
</tr>
<tr>
<td align="left" rowspan="4" colspan="1">Type of traffic participant</td>
<td align="left" rowspan="1" colspan="1">Pedestrian participants</td>
<td align="left" rowspan="1" colspan="1">0.927</td>
<td align="left" rowspan="1" colspan="1">1.955</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Small motor vehicle</td>
<td align="left" rowspan="1" colspan="1">0.759</td>
<td align="left" rowspan="1" colspan="1">6.434</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Large motor vehicles</td>
<td align="left" rowspan="1" colspan="1">0.673</td>
<td align="left" rowspan="1" colspan="1">8.734</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Non-motorized vehicles</td>
<td align="left" rowspan="1" colspan="1">0.907</td>
<td align="left" rowspan="1" colspan="1">2.492</td>
</tr>
<tr>
<td align="left" rowspan="6" colspan="1">General environmental condition Properties</td>
<td align="left" rowspan="2" colspan="1">visibility</td>
<td align="left" rowspan="1" colspan="1">Low</td>
<td align="left" rowspan="1" colspan="1">0.579</td>
<td align="left" rowspan="1" colspan="1">11.259</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">High</td>
<td align="left" rowspan="1" colspan="1">0.918</td>
<td align="left" rowspan="1" colspan="1">2.203</td>
</tr>
<tr>
<td align="left" rowspan="4" colspan="1">Weather</td>
<td align="left" rowspan="1" colspan="1">Rain</td>
<td align="left" rowspan="1" colspan="1">0.673</td>
<td align="left" rowspan="1" colspan="1">8.734</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Snowy</td>
<td align="left" rowspan="1" colspan="1">0.759</td>
<td align="left" rowspan="1" colspan="1">6.436</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Haze</td>
<td align="left" rowspan="1" colspan="1">0.753</td>
<td align="left" rowspan="1" colspan="1">6.610</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Sunny</td>
<td align="left" rowspan="1" colspan="1">0.883</td>
<td align="left" rowspan="1" colspan="1">3.113</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0329760.t001/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p>The detailed driving take-over scenarios are analyzed, and the complexity levels are determined using extensive metrics to produce conditional autonomous driving scenarios at various levels of complexity. We cluster three complexity scenario tiers: low, medium, and high. The low-level complexity scenarios are distinguished by safe driving conditions, minimal peri-vehicle components, and low traffic density. A greater number of peri-vehicle environmental elements, stationary impediments, and the risk of vehicle closeness due to obstacle avoidance are characteristics of scenarios with medium-level complexity. Enhanced traffic congestion, more environmental impediments, decreased environmental visibility, and dynamic, unpredictable obstacle features such as abrupt vehicle cut-ins and pedestrian intrusions are characteristics of high-level complexity situations.</p></section><section id="sec005"><h3 class="pmc_sec_title">Participants</h3>
<p>The sample size is important to the reliability and representativeness of the study findings. Therefore, the sample size needed to be estimated and determined before the experiment. Based on the effect size results from previous studies examining differences in SA test and eye movements, such as the stimulation of AR technology on subjects’ SA [<a href="#pone.0329760.ref032" class="usa-link" aria-describedby="pone.0329760.ref032">32</a>] and the stimulation of HUD colors on subjects’ eye movement data [<a href="#pone.0329760.ref033" class="usa-link" aria-describedby="pone.0329760.ref033">33</a>], and incorporating Cohen’s findings [<a href="#pone.0329760.ref034" class="usa-link" aria-describedby="pone.0329760.ref034">34</a>], sample size estimation was conducted using GPower software [<a href="#pone.0329760.ref035" class="usa-link" aria-describedby="pone.0329760.ref035">35</a>], specifically selecting the ANOVA: Repeated measures, within-between interaction type. The parameters included an alpha level of 0.05, a power level of 0.8, a medium effect size of 0.35, and a group count of 3. This setup yielded a total sample size requirement of 12 participants.</p>
<p>Eighteen young drivers were chosen to participate in this experiment (9 males: 5 novices, 4 non-novices; 9 females: 6 novices, 3 non-novices), with a male-to-female ratio of 1:1. They participated in the experiment from June 12th to June 18th, 2024. These subjects ranged in age from 24 to 29 years old on average (M = 23.85, SD = 3.91). This is because the younger generation constitutes the primary market for intelligent electric vehicles [<a href="#pone.0329760.ref036" class="usa-link" aria-describedby="pone.0329760.ref036">36</a>], and their driving behaviors and technological acceptance have direct reference significance for the design and R&amp;D of autonomous driving in electric vehicles. A valid driver’s license and independent driving experience are essential requirements for all participants. When recruiting participants, the driving experiences of the participants were made equivalent to the extent possible. Every individual underwent experimental testing, was right-handed, and had normal or corrected vision. Participants in the study were free to discontinue participation at any time. In addition, this experiment strictly adhered to the ethical guidelines. Before participants engaged in the experiment, the procedures were thoroughly explained to them to ensure that the experiment would not pose any risks to the subjects, and written informed consent was obtained from all participants. The Ethics Committee of Nanjing Forestry University (Science and Technology Department of Nanjing Forestry University) has evaluated and authorized this experiment (Permit Number: 2024-05-16-10).</p></section><section id="sec006"><h3 class="pmc_sec_title">Experimental design</h3>
<p>To limit the impact of extraneous variables, including experimental order and grouping, on the experiment and to reduce statistical random errors, a 3×3 Latin-square design based on balanced experimental order was employed for experimental planning in this work. Two statistically non-interacting external variables were the type of autonomous driving information display and scene complexity. Each external variable was split into three equal levels for the Latin-square layout. Three distinct complexity levels (low-level, medium-level, and high-level) of the three displays (type A, type B, and type C) were investigated for their impact on drivers’ SA ability and take-over performance in <a href="#pone.0329760.t002" class="usa-link">Table 2</a>. Furthermore, a variety of techniques (such as eye-movement data and SA questionnaires) were used to gather quantitative and qualitative information from each participant.</p>
<section class="tw xbox font-sm" id="pone.0329760.t002"><h4 class="obj_head">Table 2. 3x3 Latin square design.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead>
<tr>
<th align="left" rowspan="2" colspan="1">Scene complexity</th>
<th align="left" colspan="3" rowspan="1">Experimental object</th>
</tr>
<tr>
<th align="left" rowspan="1" colspan="1">Group A</th>
<th align="left" rowspan="1" colspan="1">Group B</th>
<th align="left" rowspan="1" colspan="1">Group C</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">low-level</td>
<td align="left" rowspan="1" colspan="1">type A</td>
<td align="left" rowspan="1" colspan="1">type B</td>
<td align="left" rowspan="1" colspan="1">type C</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">medium-level</td>
<td align="left" rowspan="1" colspan="1">type B</td>
<td align="left" rowspan="1" colspan="1">type C</td>
<td align="left" rowspan="1" colspan="1">type A</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">high-level</td>
<td align="left" rowspan="1" colspan="1">type C</td>
<td align="left" rowspan="1" colspan="1">type A</td>
<td align="left" rowspan="1" colspan="1">type B</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0329760.t002/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p>Since a 3rd-order Latin square design was adopted in this experiment, 18 subjects were divided into three groups, with 6 people in each group. They respectively carried out the simulation experiments of Group A, Group B, and Group C. In each group, the male-to-female ratio of the subjects was equal at 1:1, and the distribution of driving experience was basically similar.</p>
<section id="sec007"><h4 class="pmc_sec_title">Independent variables.</h4>
<p>In this investigation, two primary external independent factors were noted: the first was the kind of autonomous driving information display (type A, type B, and type C). The second was the driving scenario’s complexity (low-level, medium-level, high-level). Gender (male, female) was the between-subjects independent variable. From the driving scene video footage of Wolfe (2020), nine videos (including six no event videos and three event videos) were chosen based on the previously described forms of scene complexity [<a href="#pone.0329760.ref027" class="usa-link" aria-describedby="pone.0329760.ref027">27</a>]. In addition, the event video selects three of the most representative accident scenarios that require a driver to take over, including a forward vehicle collision, The sudden cut-in of lateral vehicles ahead, and an adjacent vehicle occupies the lane, as shown in <a href="#pone.0329760.g005" class="usa-link">Fig 5</a>. They were divided into three separate scene complexity groups: Group A, Group B, and Group C. To avoid order effects, the material in each group’s various complexity scenarios was randomly arranged before the trial began. <a href="#pone.0329760.g006" class="usa-link">Fig 6</a> shows an example of Group C scene material. Adobe After Effects 2022 was used to attach three types of autonomous driving information, type A, type B, and type C, to the HUD display types for each group of nine video clips, while video watermarks were removed and driving audio was added to prevent interference with the subjects while providing them with an immersive autopilot experience.</p>
<figure class="fig xbox font-sm" id="pone.0329760.g005"><h5 class="obj_head">Fig 5. Three accident scenarios: a) forward vehicle collision; b) The sudden cut-in of lateral vehicles ahead; c) adjacent vehicle occupies the lane.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373254_pone.0329760.g005.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4fe0/12373254/fe246a2c53d9/pone.0329760.g005.jpg" loading="lazy" height="568" width="760" alt="Fig 5"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329760.g005/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><figure class="fig xbox font-sm" id="pone.0329760.g006"><h5 class="obj_head">Fig 6. Example of Group C scene material.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373254_pone.0329760.g006.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4fe0/12373254/c2ed013cec62/pone.0329760.g006.jpg" loading="lazy" height="408" width="704" alt="Fig 6"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329760.g006/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure></section><section id="sec008"><h4 class="pmc_sec_title">Dependent variables.</h4>
<p>The following sets of dependent variables were observed to provide answers to the two study hypotheses that were presented in the preceding part, eye-movement data and the SA questionnaire in the situational awareness portion, and take-over reaction time in the take-over performance section.</p>
<p>SA. For SA in non-take-over scenarios, the fixation duration of all gazes inside the Area of Interest (AOI) that corresponds to the location of the HUD element of each type of autonomous driving information display is the dependent variable [<a href="#pone.0329760.ref037" class="usa-link" aria-describedby="pone.0329760.ref037">37</a>]. The fixation duration refers to the time during which the foveal region of the visual field of the eye stays in the same place. During a longer fixation duration, there is a higher level of attention paid to that element. However, it may also indicate that this element imposes higher requirements on the cognitive abilities of the subjects [<a href="#pone.0329760.ref038" class="usa-link" aria-describedby="pone.0329760.ref038">38</a>,<a href="#pone.0329760.ref039" class="usa-link" aria-describedby="pone.0329760.ref039">39</a>]. The second dependent variable is the fixation counts within the AOI. The Situation Awareness Global Assessment Technique (SAGAT) score is the dependent variable for situational awareness in the take-over scenario [<a href="#pone.0329760.ref040" class="usa-link" aria-describedby="pone.0329760.ref040">40</a>]. Two questions were assigned to each of the three perceptual levels—sensing (SA-1), understanding (SA-2), and projecting (SA-3) that Endsley proposed. Example SA questions are provided in <a href="#pone.0329760.t003" class="usa-link">Table 3</a>.</p>
<section class="tw xbox font-sm" id="pone.0329760.t003"><h5 class="obj_head">Table 3. SAGAT Assessment Sample Questions.</h5>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">Perceptual Level</th>
<th align="left" rowspan="1" colspan="1">Question content</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="2" colspan="1">Perception (SA-1)</td>
<td align="left" rowspan="1" colspan="1">1. Which direction did you observr the traffic coming from? (Multiple choice)</td>
</tr>
<tr><td align="left" rowspan="1" colspan="1">2. What is the speed limit you observed on this section of road? (Single choice)</td></tr>
<tr>
<td align="left" rowspan="2" colspan="1">Comprehension (SA-2)</td>
<td align="left" rowspan="1" colspan="1">3. Which direction did you judge to be dangerous, leading to your decision to take over the vehicle? (Single choice)</td>
</tr>
<tr><td align="left" rowspan="1" colspan="1">4. Which direction do you need to drive at the next intersection? (Single choice)</td></tr>
<tr>
<td align="left" rowspan="2" colspan="1">Projection (SA-3)</td>
<td align="left" rowspan="1" colspan="1">5. Which other vehicle in which direction is closest to you when you decide to take over the vehicle? (Single choice)</td>
</tr>
<tr><td align="left" rowspan="1" colspan="1">6. After you’ve gained control of the vehicle, what should you do next? (Single choice)</td></tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0329760.t003/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p>Take-over performance. The driving take-over reaction time, which was obtained from the eye movement data, served as the primary indicator of take-over performance in this investigation. The time difference between the take-over time point and the earliest proper time point of the take-over (the time point of the first noticeable departure from the cue) was primarily used to determine the driving take-over reaction time, as shown in <a href="#pone.0329760.g007" class="usa-link">Fig 7</a>. In this experiment, clicking the mouse or pressing the space bar is recorded as a correct take-over (representing a hand movement).</p>
<figure class="fig xbox font-sm" id="pone.0329760.g007"><h5 class="obj_head">Fig 7. Schematic flow chart of driving take-over reaction experiment.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373254_pone.0329760.g007.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4fe0/12373254/e9d8a0bb9349/pone.0329760.g007.jpg" loading="lazy" height="280" width="775" alt="Fig 7"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329760.g007/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure></section></section><section id="sec009"><h3 class="pmc_sec_title">Experimental set-up</h3>
<p>This experiment was carried out in a closed laboratory setting, free from outside distractions. The experimental setup for the study consisted of a set of desktop Tobii eye-trackers for human-computer interaction and psychology, manufactured by Tobii, Sweden, with a sampling frequency of 50 Hz and a gaze localization accuracy of 0.5. The mechanism was used to record the movements of the eye. To show the experimental simulations and collect experimental data, the Tobii Studio software was coupled and integrated with the ErGolab human-computer platform. The HP desktop PC running Windows 10 Professional and the HP 1680*1050 monitor were used to display the material stimuli. Both the basic interview and the SA questionnaire were completed on separate paper forms. During the experiment, participants sat approximately 65 centimeters away from the central screen and adjusted their viewing distance appropriately. <a href="#pone.0329760.g008" class="usa-link">Fig 8</a> shows a schematic diagram of the experimental setup.</p>
<figure class="fig xbox font-sm" id="pone.0329760.g008"><h4 class="obj_head">Fig 8. Experiment setting.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373254_pone.0329760.g008.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4fe0/12373254/171c3bcc6721/pone.0329760.g008.jpg" loading="lazy" height="332" width="660" alt="Fig 8"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329760.g008/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure></section><section id="sec010"><h3 class="pmc_sec_title">Procedure</h3>
<p>The experiment’s flow for the lone subject is depicted in <a href="#pone.0329760.g009" class="usa-link">Fig 9</a>.</p>
<figure class="fig xbox font-sm" id="pone.0329760.g009"><h4 class="obj_head">Fig 9. Experimental flow.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373254_pone.0329760.g009.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4fe0/12373254/c180c7d44e67/pone.0329760.g009.jpg" loading="lazy" height="370" width="660" alt="Fig 9"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329760.g009/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p>A questionnaire on their driving experience and fundamental data was sent out to those taking part. The goal of the experiment was fully explained to the subjects. Once they were fully aware of the procedure, participants were told to begin practicing. Each participant would practice before the official experiment until they felt at ease with the procedure. The exercises adhered to the same precise protocol as the formal experiment; the material that was delivered was the only variation.</p>
<p>Before beginning the experiment, the researcher checked to ensure each participant was in a suitable seated setting and understood the task. The next step consisted of a five-point binocular calibration. When the calibration was complete, it was indicated on a guide page. Once they understood what needed to be done for the task at hand, individuals were told to press the space button to continue. The stimulus material emerges after a 1000 ms fixed cross and a 250 ms blank mask. Participants were instructed to look at the center cross when the gaze cross appeared to prevent variations in eye gazing. Participants were permitted to see the content with several HUDs at the start of the stimulus. The experimenter paused the current experiment for a SA test of the frozen scene once the participant had gained control. Each stimulus was given for 8000 ms and could be discontinued at any point. The material for the next complexity scenario was obtained by the researcher with a mouse click once the participants had responded to the SA questions in a take-over scene. Every individual underwent the same lighting conditions and adhered to a standardized experimental protocol. The experiment took about twenty minutes to complete. After the experiment, the use of their experimental data and the protection measures will be explained to the participants.</p></section></section><section id="sec011"><h2 class="pmc_sec_title">Results</h2>
<p>All participants were sampled during eye movements in this experiment, and all experimental data from the final eighteen subjects were used for data analysis. To strictly protect the privacy of participants, all collected raw data were thoroughly anonymized before analysis. For details of the eye-tracking experiment data, please refer to the <a href="#pone.0329760.s001" class="usa-link">S1 File</a>. The SPSS software version 25 was used for statistical analysis. Analysis of variance (ANOVA) was used to examine all the variables. Every multivariate test criterion in the results satisfied the same F-statistic. For all analyses, the effect sizes were measured using partial eta-squared (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0329760.e011"><math id="M11" display="inline" overflow="linebreak"><mrow><msup><mi>η</mi><mrow><mn>2</mn></mrow></msup></mrow></math></span>), and the significance level was set at 0.05. Based on the Levene test, all data satisfied the chi-square and normal distribution assumptions. Using one or more of the reported variable dependents. The two study questions are the focus of this experimental investigation.</p>
<section id="sec012"><h3 class="pmc_sec_title">Situational awareness</h3>
<p>Because the participants’ take-over time points differed in the take-over scenario, potentially influencing the analysis’s findings, the eye movement data within the AOI was only used to examine driver situational awareness in the no-take-over scenario material. Under the take-over scenario material was analyzed only by studying the accuracy of the SAGAT questionnaire. <a href="#pone.0329760.t004" class="usa-link">Table 4</a> represents the mean (SDs) of fixation duration, fixation counts, and SAGAT test accuracy given by the independent variables for each scenario.</p>
<section class="tw xbox font-sm" id="pone.0329760.t004"><h4 class="obj_head">Table 4. Mean (SD) of fixation duration, fixation counts, and SAGAT accuracy according to scene complexity and autonomous driving information display type.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead>
<tr>
<th align="left" rowspan="3" colspan="1">Display type</th>
<th align="left" rowspan="3" colspan="1">Scene complexity</th>
<th align="left" colspan="4" rowspan="1">No take-over</th>
<th align="left" colspan="2" rowspan="1">Take-over</th>
</tr>
<tr>
<th align="left" colspan="2" rowspan="1">Fixation Duration(s)</th>
<th align="left" colspan="2" rowspan="1">Fixation Counts</th>
<th align="left" colspan="2" rowspan="1">SAGAT test accuracy(%)</th>
</tr>
<tr>
<th align="left" rowspan="1" colspan="1">Male</th>
<th align="left" rowspan="1" colspan="1">Female</th>
<th align="left" rowspan="1" colspan="1">Male</th>
<th align="left" rowspan="1" colspan="1">Female</th>
<th align="left" rowspan="1" colspan="1">Male</th>
<th align="left" rowspan="1" colspan="1">Female</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="3" colspan="1">type A</td>
<td align="left" rowspan="1" colspan="1">low-level</td>
<td align="left" rowspan="1" colspan="1">2.58 (0.85)</td>
<td align="left" rowspan="1" colspan="1">2.71 (0.59)</td>
<td align="left" rowspan="1" colspan="1">8.00 (3.04)</td>
<td align="left" rowspan="1" colspan="1">5.67 (2.26)</td>
<td align="left" rowspan="1" colspan="1">0.72 (0.18)</td>
<td align="left" rowspan="1" colspan="1">0.61 (0.10)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">medium-level</td>
<td align="left" rowspan="1" colspan="1">0.75 (0.55)</td>
<td align="left" rowspan="1" colspan="1">0.69 (0.22)</td>
<td align="left" rowspan="1" colspan="1">2.83 (2.02)</td>
<td align="left" rowspan="1" colspan="1">3.33 (0.29)</td>
<td align="left" rowspan="1" colspan="1">0.75 (0.14)</td>
<td align="left" rowspan="1" colspan="1">0.67 (0.34)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">high-level</td>
<td align="left" rowspan="1" colspan="1">3.77 (0.24)</td>
<td align="left" rowspan="1" colspan="1">1.37 (0.38)</td>
<td align="left" rowspan="1" colspan="1">6.33 (0.29)</td>
<td align="left" rowspan="1" colspan="1">4.17 (0.28)</td>
<td align="left" rowspan="1" colspan="1">0.64 (0.27)</td>
<td align="left" rowspan="1" colspan="1">0.64 (0.05)</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">type B</td>
<td align="left" rowspan="1" colspan="1">low-level</td>
<td align="left" rowspan="1" colspan="1">4.39 (1.38)</td>
<td align="left" rowspan="1" colspan="1">2.86 (1.86)</td>
<td align="left" rowspan="1" colspan="1">5.17 (1.76)</td>
<td align="left" rowspan="1" colspan="1">6.83 (2.02)</td>
<td align="left" rowspan="1" colspan="1">0.70 (0.05)</td>
<td align="left" rowspan="1" colspan="1">0.44 (0.20)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">medium-level</td>
<td align="left" rowspan="1" colspan="1">2.04 (1.21)</td>
<td align="left" rowspan="1" colspan="1">2.31 (0.94)</td>
<td align="left" rowspan="1" colspan="1">9.33 (5.01)</td>
<td align="left" rowspan="1" colspan="1">6.67 (1.04)</td>
<td align="left" rowspan="1" colspan="1">0.61 (0.17)</td>
<td align="left" rowspan="1" colspan="1">0.56 (0.10)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">high-level</td>
<td align="left" rowspan="1" colspan="1">1.87 (1.08)</td>
<td align="left" rowspan="1" colspan="1">1.35 (0.48)</td>
<td align="left" rowspan="1" colspan="1">4.50 (1.80)</td>
<td align="left" rowspan="1" colspan="1">5.83 (2.02)</td>
<td align="left" rowspan="1" colspan="1">0.28 (0.05)</td>
<td align="left" rowspan="1" colspan="1">0.19 (0.17)</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">type C</td>
<td align="left" rowspan="1" colspan="1">low-level</td>
<td align="left" rowspan="1" colspan="1">3.10 (1.83)</td>
<td align="left" rowspan="1" colspan="1">2.40 (1.00)</td>
<td align="left" rowspan="1" colspan="1">5.50 (0.00)</td>
<td align="left" rowspan="1" colspan="1">6.83 (1.26)</td>
<td align="left" rowspan="1" colspan="1">0.92 (0.14)</td>
<td align="left" rowspan="1" colspan="1">0.94 (0.10)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">medium-level</td>
<td align="left" rowspan="1" colspan="1">1.96 (1.81)</td>
<td align="left" rowspan="1" colspan="1">0.73 (0.64)</td>
<td align="left" rowspan="1" colspan="1">2.67 (1.53)</td>
<td align="left" rowspan="1" colspan="1">3.33 (3.01)</td>
<td align="left" rowspan="1" colspan="1">0.80 (0.05)</td>
<td align="left" rowspan="1" colspan="1">0.80 (0.05)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">high-level</td>
<td align="left" rowspan="1" colspan="1">0.73 (0.39)</td>
<td align="left" rowspan="1" colspan="1">1.26 (0.69)</td>
<td align="left" rowspan="1" colspan="1">2.33 (1.26)</td>
<td align="left" rowspan="1" colspan="1">3.00 (1.32)</td>
<td align="left" rowspan="1" colspan="1">0.92 (0.14)</td>
<td align="left" rowspan="1" colspan="1">0.75 (0.25)</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0329760.t004/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><section id="sec013"><h4 class="pmc_sec_title">Fixation duration.</h4>
<p>When comparing the fixation duration of participants on different types of autonomous driving information displays, as shown in <a href="#pone.0329760.g010" class="usa-link">Fig 10</a>, the effects of gender [F(1,36) = 4.74, p = 0.036, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0329760.e012"><math id="M12" display="inline" overflow="linebreak"><mrow><msup><mi>η</mi><mrow><mn>2</mn></mrow></msup></mrow></math></span> = 0.116] and scenario complexity [F(2,36) = 11.94, p = 0.000, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0329760.e013"><math id="M13" display="inline" overflow="linebreak"><mrow><msup><mi>η</mi><mrow><mn>2</mn></mrow></msup></mrow></math></span> = 0.399] were found to be the most significant. The data showed that the fixation duration of males was significantly longer than that of females. Compared with medium and high-complexity scenarios, participants spent significantly more fixation duration on autonomous driving information in low-complexity scenarios.</p>
<figure class="fig xbox font-sm" id="pone.0329760.g010"><h5 class="obj_head">Fig 10. The mean and standard error of fixation duration for type A, type B, and type C autonomous driving information display types under various scenario complexities.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373254_pone.0329760.g010.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4fe0/12373254/de3975749fd2/pone.0329760.g010.jpg" loading="lazy" height="556" width="730" alt="Fig 10"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329760.g010/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p>Additionally, the interaction effect between information display type and scenario complexity was also significant [F(4,36) = 2.77, p = 0.042, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0329760.e014"><math id="M14" display="inline" overflow="linebreak"><mrow><msup><mi>η</mi><mrow><mn>2</mn></mrow></msup></mrow></math></span> = 0.236]. When fixing the scenario complexity, in medium-complexity scenarios, the fixation duration of type A was significantly shorter than that of type B. In high-complexity scenarios, the fixation duration of type C was significantly shorter than that of type A.</p>
<p>When fixing the display type, for type A, the fixation duration in medium-complexity scenarios was significantly lower than that in low and high-complexity scenarios. For type B, the fixation duration in high-complexity scenarios was significantly higher than that in low and medium-complexity scenarios. For type C, the fixation duration in low-complexity scenarios was significantly higher than that in medium and high-complexity scenarios.</p></section><section id="sec014"><h4 class="pmc_sec_title">Fixation counts.</h4>
<p>When comparing the fixation counts of participants on different types of autonomous driving information displays, as shown in <a href="#pone.0329760.g011" class="usa-link">Fig 11</a>, the effects of scenario complexity [F(2,36) = 4.77, p = 0.015, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0329760.e015"><math id="M15" display="inline" overflow="linebreak"><mrow><msup><mi>η</mi><mrow><mn>2</mn></mrow></msup></mrow></math></span> = 0.21] and display type [F(2,36) = 6.41, p = 0.004, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0329760.e016"><math id="M16" display="inline" overflow="linebreak"><mrow><msup><mi>η</mi><mrow><mn>2</mn></mrow></msup></mrow></math></span> = 0.263] were observed to be the most significant. The data showed that low-complexity scenarios attracted more fixation counts than medium and high-complexity scenarios.</p>
<figure class="fig xbox font-sm" id="pone.0329760.g011"><h5 class="obj_head">Fig 11. The mean and standard error of fixation counts for type A, type B, and type C autonomous driving information display types under various scenario complexities.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373254_pone.0329760.g011.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4fe0/12373254/43d0092f982d/pone.0329760.g011.jpg" loading="lazy" height="556" width="730" alt="Fig 11"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329760.g011/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p>Additionally, the interaction effect between information display type and scenario complexity was also significant [F(4,36) = 4.32, p = 0.006, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0329760.e017"><math id="M17" display="inline" overflow="linebreak"><mrow><msup><mi>η</mi><mrow><mn>2</mn></mrow></msup></mrow></math></span> = 0.324]. When fixing the scenario complexity, in medium-complexity scenarios, type B attracted more fixation counts than type C and type A. In high-complexity scenarios, type C attracted fewer fixation counts than type A and type B.</p>
<p>When fixing the display type, for type A, the fixation counts in medium-complexity scenarios was significantly fewer than that in low-complexity scenarios. For type B, the fixation counts in medium-complexity scenarios was significantly more than that in high-complexity scenarios. For type C, the fixation counts in low-complexity scenarios was significantly more than those in medium and high-complexity scenarios.</p></section><section id="sec015"><h4 class="pmc_sec_title">SAGAT accuracy.</h4>
<p>When comparing the SAGAT level questionnaire measurement results of participants on different types of autonomous driving information displays, as shown in <a href="#pone.0329760.g012" class="usa-link">Fig 12</a>, the results showed that scenario complexity [F(2,36) = 6.07, p = 0.005, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0329760.e018"><math id="M18" display="inline" overflow="linebreak"><mrow><msup><mi>η</mi><mrow><mn>2</mn></mrow></msup></mrow></math></span> = 0.252], display type [F(2,36) = 34.08, p = 0.001, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0329760.e019"><math id="M19" display="inline" overflow="linebreak"><mrow><msup><mi>η</mi><mrow><mn>2</mn></mrow></msup></mrow></math></span> = 0.654], and gender [F(1,36) = 4.21, p = 0.048, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0329760.e020"><math id="M20" display="inline" overflow="linebreak"><mrow><msup><mi>η</mi><mrow><mn>2</mn></mrow></msup></mrow></math></span> = 0.105] had the most significant effects on SA accuracy. The data showed that participants’ SA accuracy in low-complexity scenarios was significantly higher than that in medium and high-complexity scenarios. Additionally, their SA accuracy for type C was significantly higher than that for type A and type B. Furthermore, males had significantly higher SA accuracy than females.</p>
<figure class="fig xbox font-sm" id="pone.0329760.g012"><h5 class="obj_head">Fig 12. The mean and standard error of SAGAT accuracy for type A, type B, and type C autonomous driving information display types under various scenario complexities.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373254_pone.0329760.g012.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4fe0/12373254/22239eb035f9/pone.0329760.g012.jpg" loading="lazy" height="519" width="713" alt="Fig 12"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329760.g012/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p>Additionally, the interaction effect between information display type and scenario complexity was also significant [F(4,36) = 3.57, p = 0.015, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0329760.e021"><math id="M21" display="inline" overflow="linebreak"><mrow><msup><mi>η</mi><mrow><mn>2</mn></mrow></msup></mrow></math></span> = 0.284]. When fixing the scenario complexity, in low-complexity scenarios, type C had higher SA accuracy than type A and type B in terms of comprehension and prediction. In medium-complexity scenarios, there was no significant difference among the three display types. In high-complexity scenarios, both type A and type C were significantly better than type B in the three aspects of perception, comprehension, and prediction.</p></section></section><section id="sec016"><h3 class="pmc_sec_title">Take-over performance: take-over reaction time</h3>
<p>The data labeled in the public database by Wolfe (2020) was used as a reference to determine the earliest correct time point of take-over for the take-over material at varied scene complexities (<a href="#pone.0329760.t005" class="usa-link">Table 5</a>) [<a href="#pone.0329760.ref027" class="usa-link" aria-describedby="pone.0329760.ref027">27</a>]. <a href="#pone.0329760.t006" class="usa-link">Table 6</a> displays the mean (SDs) of the computed take-over reaction times for the six participants for each group of experiments after the take-over reaction times for each group in the experimental data have been arranged.</p>
<section class="tw xbox font-sm" id="pone.0329760.t005"><h4 class="obj_head">Table 5. Point in time of the first visible deviation from the trail in each scenario.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead><tr>
<th align="left" rowspan="1" colspan="1">Scene complexity</th>
<th align="left" rowspan="1" colspan="1">First Visible Cue of Deviation (s)</th>
<th align="left" rowspan="1" colspan="1">Description of hazard</th>
</tr></thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1">low-level</td>
<td align="left" rowspan="1" colspan="1">5.33</td>
<td align="left" rowspan="1" colspan="1">The vehicle runs a red light</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">medium-level</td>
<td align="left" rowspan="1" colspan="1">5.5</td>
<td align="left" rowspan="1" colspan="1">The leading vehicle collides with the vehicle ahead</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">high-level</td>
<td align="left" rowspan="1" colspan="1">3.5</td>
<td align="left" rowspan="1" colspan="1">A vehicle in the right lane drifts into the lane of travel</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0329760.t005/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><section class="tw xbox font-sm" id="pone.0329760.t006"><h4 class="obj_head">Table 6. Mean (SDs) of take-over reaction times according to scene complexity and type of autonomous driving information display.</h4>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<colgroup span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
<col align="left" valign="middle" span="1">
</colgroup>
<thead>
<tr>
<th align="left" rowspan="2" colspan="1">Display type</th>
<th align="left" rowspan="2" colspan="1">Scene complexity</th>
<th align="left" colspan="2" rowspan="1">take-over reaction time(s)</th>
</tr>
<tr>
<th align="left" rowspan="1" colspan="1">Male</th>
<th align="left" rowspan="1" colspan="1">Female</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="3" colspan="1">type A</td>
<td align="left" rowspan="1" colspan="1">low-level</td>
<td align="left" rowspan="1" colspan="1">0.80 (0.25)</td>
<td align="left" rowspan="1" colspan="1">0.54 (0.23)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">medium-level</td>
<td align="left" rowspan="1" colspan="1">1.20 (0.54)</td>
<td align="left" rowspan="1" colspan="1">0.74 (0.25)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">high-level</td>
<td align="left" rowspan="1" colspan="1">0.48 (0.03)</td>
<td align="left" rowspan="1" colspan="1">1.07 (0.12)</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">type B</td>
<td align="left" rowspan="1" colspan="1">low-level</td>
<td align="left" rowspan="1" colspan="1">0.93 (0.41)</td>
<td align="left" rowspan="1" colspan="1">1.79 (1.00)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">medium-level</td>
<td align="left" rowspan="1" colspan="1">1.39 (0.57)</td>
<td align="left" rowspan="1" colspan="1">2.07 (0.82)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">high-level</td>
<td align="left" rowspan="1" colspan="1">0.69 (0.20)</td>
<td align="left" rowspan="1" colspan="1">0.79 (0.71)</td>
</tr>
<tr>
<td align="left" rowspan="3" colspan="1">type C</td>
<td align="left" rowspan="1" colspan="1">low-level</td>
<td align="left" rowspan="1" colspan="1">0.54 (0.37)</td>
<td align="left" rowspan="1" colspan="1">1.25 (0.98)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">medium-level</td>
<td align="left" rowspan="1" colspan="1">0.66 (0.31)</td>
<td align="left" rowspan="1" colspan="1">0.88 (0.40)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">high-level</td>
<td align="left" rowspan="1" colspan="1">0.44 (0.26)</td>
<td align="left" rowspan="1" colspan="1">0.75 (0.22)</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/pone.0329760.t006/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p>When comparing the take-over reaction time results of participants for different types of autonomous driving information displays in each take-over scenario, as shown in <a href="#pone.0329760.g013" class="usa-link">Fig 13</a>, it was observed that gender [F(1,36) = 5.24, p = 0.028, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0329760.e022"><math id="M22" display="inline" overflow="linebreak"><mrow><msup><mi>η</mi><mrow><mn>2</mn></mrow></msup></mrow></math></span> = 0.127], display type [F(2,36) = 6.941, p = 0.003, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0329760.e023"><math id="M23" display="inline" overflow="linebreak"><mrow><msup><mi>η</mi><mrow><mn>2</mn></mrow></msup></mrow></math></span> = 0.278], and scenario complexity [F(2,36) = 5.827, p = 0.006, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="pone.0329760.e024"><math id="M24" display="inline" overflow="linebreak"><mrow><msup><mi>η</mi><mrow><mn>2</mn></mrow></msup></mrow></math></span> = 0.245] had the most significant effects on take-over reaction time. Additionally, no significant interaction effect was found among participants’ gender, display type, and scenario complexity.</p>
<figure class="fig xbox font-sm" id="pone.0329760.g013"><h4 class="obj_head">Fig 13. The mean and standard error of take-over reaction time for type A, type B, and type C autonomous driving information display types under various scenario complexities.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12373254_pone.0329760.g013.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/4fe0/12373254/0b7c954ad3f4/pone.0329760.g013.jpg" loading="lazy" height="551" width="730" alt="Fig 13"></a></p>
<div class="p text-right font-secondary"><a href="figure/pone.0329760.g013/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></figure><p>The data showed that in terms of scenario complexity, participants’ take-over reaction time in high-complexity scenarios was significantly shorter than that in low and medium-complexity scenarios. In terms of display type, there was a significant difference in take-over reaction time between type B and type C in medium-complexity scenarios. In other scenarios, there was no significant difference among type A, type B, and type C. In terms of gender, for type B and type C, male participants had significantly faster take-over reaction time than females.</p></section></section><section id="sec017"><h2 class="pmc_sec_title">Discussion</h2>
<p>This work aims to determine the optimal display types of autonomous driving information on the HUD suitable for young drivers in different driving environments, and provide insights for the design of autonomous driving information on the HUD. When considering the two research questions in the introduction, the experiment yielded some interesting findings.</p>
<p>The eye tracking method revealed that under normal driving conditions, drivers paid less visual attention to the AR presentation of information in situations with different levels of complexity. Moreover, the take-over scenario demonstrated that in all three complexity settings, the accuracy of AR-type’s SA reporting was generally higher. The majority of the study’s conclusions are in line with earlier investigations. Researchers in a variety of industries have demonstrated how AR display-style interfaces can enhance users’ SA. For instance, Rowen (2019) discovered that AR devices can considerably enhance users’ situational awareness abilities in dynamic contexts, including SA-1 and SA-2 [<a href="#pone.0329760.ref041" class="usa-link" aria-describedby="pone.0329760.ref041">41</a>]. The current study’s findings partly agree with those of earlier research conducted in various complexity scenarios. A variety of intricate scenarios could be the cause of this. The results of a study showed that the level of SA during night driving was significantly improved compared with that during daytime driving, while the improvement of the SA level during daytime driving was not significant. This demonstrates the different effects that changes in environmental complexity can have on drivers’ SA levels [<a href="#pone.0329760.ref042" class="usa-link" aria-describedby="pone.0329760.ref042">42</a>]. Therefore, we found that the lower the complexity of the scene was, the smaller the difference in the impact on drivers between AR display and simple P3D display would be, conversely, a better performance of AR display is achieved. Meanwhile, the SR display effect is the worst of the three display kinds. A study found that when objects approach at different distances from the observer but with the same speed and trajectories, it can be challenging for the observer to determine the relative speeds of the two objects, among other things [<a href="#pone.0329760.ref043" class="usa-link" aria-describedby="pone.0329760.ref043">43</a>]. This explains why drivers must exert greater mental effort to appraise other traffic participants in SR displays when they are shown in front of them at the same speed and trajectory as the SR automobile model on the HUD.</p>
<p>It was discovered that AR displays outperformed P3D and SR displays in terms of driver take-over performance across all complexity levels, particularly in high-complexity scenarios. This result is in line with the findings of You (2024) who showed that drivers’ reaction times in both human-driven and autopilot modes can be greatly shortened by AR display information and that this can increase human drivers’ confidence in the autopilot system [<a href="#pone.0329760.ref044" class="usa-link" aria-describedby="pone.0329760.ref044">44</a>]. Furthermore, the current study discovered that the driver’s take-over performance rose with scenario complexity, irrespective of the type of autonomous driving information display that the driver encountered. This performance is consistent with earlier research on driving, such as Zhang (2013) who observed that drivers’ safety margins and speeds were more conservative as road complexity rose, indicating that they were also paying more attention [<a href="#pone.0329760.ref045" class="usa-link" aria-describedby="pone.0329760.ref045">45</a>]. It can therefore be inferred that the AR display is the best option for the current type of autonomous driving information display in various complexity scenarios. However, further research is needed to investigate the more specific expressions of autonomous driving information in the AR interface.</p>
<p>Meanwhile, in addition to the findings regarding the study’s two research questions, this experiment has also yielded some interesting additional discoveries concerning the gender factor. Previous research has shown that the visual colors of HUD interfaces produce differences in gender perception [<a href="#pone.0329760.ref033" class="usa-link" aria-describedby="pone.0329760.ref033">33</a>]. Since all HUD types display the same visual of autonomous driving information to the driver in this experiment, potential differences in perception of different display types by different genders in scenarios of varying complexity could be observed. Eye-tracking techniques have revealed that males always have higher visual attention than females for autonomous driving information in HUD. Furthermore, males are always faster than females in take-over. This may share some similarities with the findings of Loeb (2019) [<a href="#pone.0329760.ref046" class="usa-link" aria-describedby="pone.0329760.ref046">46</a>]. In their study, when an autonomous vehicle unexpectedly drove toward a closed highway exit, the crash rate among males (38%) was lower than that among females (43%). This indicates that in emergency take-over scenarios, male drivers exhibit higher take-over efficiency than female drivers. This may be related to the significant differences they exhibited at the SA-2 and SA-3 levels. Simultaneously, SR displays have the greatest visual attraction for both males and females, showing that both males and females are not suitable for using SR displays. These findings show that gender may be an important factor affecting autonomous driving information processing and response, which is worthy of further exploration. However, due to the limitations and specificity of the sample size in this study, more experiments are needed to obtain gender-based perceptual differences in the display types of autonomous driving information on HUD.</p>
<p>To sum up, our findings indicate that the most effective ergonomic option for enhancing the young driver’s take-over performance and SA skills is AR-displayed autonomous driving information, particularly in cases with a high degree of complexity. However, not every car has AR-HUD as standard equipment (e.g., AR-HUD is a premium option on the Volkswagen ID4 models). As a result, according to the results of this study, on the W-HUD, it is recommended to use a P3D type to display autonomous driving information.</p>
<p>There are some limitations to this study. First, one limitation of this study is that the experiment was conducted in a laboratory environment. Although the experimental setup was designed based on the results of previous studies [<a href="#pone.0329760.ref047" class="usa-link" aria-describedby="pone.0329760.ref047">47</a>,<a href="#pone.0329760.ref048" class="usa-link" aria-describedby="pone.0329760.ref048">48</a>], and to enhance the immersion and realism for participants during the experiment, this study used real-world recorded driving videos that met the requirements (the video materials were designed to cover diverse road features and climatic conditions as much as possible), rather than simulated scenarios. But the limitations of the laboratory and equipment make it impossible to capture all the characteristics of the natural driving environment, nor can they fully replicate the unpredictable risks and drivers’ psychological pressures in real driving. This limits the realization of a more realistic driving simulation experience and also makes the conclusions of this study mainly applicable to controlled dynamic scenarios similar to the experimental conditions. For the application of the conclusions in real environments, future studies should explore the effects of different autonomous driving information displays on the HUDs in actual driving environments to collect more precise and objective data (including verification across a broader range of regions and climates). Furthermore, misjudging the driver’s position of other traffic participants can result from the FOV of the HUD’s optical imaging deviating from the driver’s perceived position [<a href="#pone.0329760.ref049" class="usa-link" aria-describedby="pone.0329760.ref049">49</a>], a factor that was overlooked in this investigation.</p>
<p>The other main limitation of this study is that although we demonstrated the three main types of autonomous driving information display on the HUDs available in the market in the experiment and their performances in scenarios with different levels of complexity, we did not discuss in detail the specific HUD information design schemes, nor did we propose entirely new display principles or interaction models. Future work can build on the results of this study to explore new interaction mechanisms. Meanwhile, the impact of merging various autonomous driving information display formats on car HUD (e.g., the AITO M9 model’s combination of AR and SR displays) might also be studied further.</p>
<p>Finally, the participants in this study were concentrated in the young group aged 24 to 29. Although this group represents the main consumer segment of the current electric vehicle market in most regions, limitations in their driving experience, risk perception, and other characteristics may fail to reflect the performance of drivers of other age groups. This limitation may restrict the generalizability of the conclusions to electric vehicle drivers across all age groups. Future studies can include samples from a broader range of age groups to enhance the generalizability of the findings. Meanwhile, comparing the differences in how drivers of different age groups process autonomous driving information on the HUD is another research direction worthy of further exploration through corresponding experimental designs.</p></section><section id="sec018"><h2 class="pmc_sec_title">Conclusion</h2>
<p>The purpose of this study was to examine the effects of different autonomous driving information display types on HUD that are currently on the Chinese market on participant take-over efficiency and SA under scenarios with different levels of complexity. Based on the existing solutions in the market, three representative display types of autonomous driving information on the HUD were extracted and designed. The EWM was used to classify the semi-autonomous driving scenarios’ complexity into low, medium, and high levels. An eye-movement-based experiment was carried out to assess the effects of three different types of display schemes and three different complexity scenarios on the driver. The AR-HUD has the best potential to increase driver safety awareness when compared to the P3D and SR display formats on the W-HUD, and this advantage will be strengthened as the complexity of the scene increases. Furthermore, in high-complexity scenarios, the driver take-over is more efficient than in low-complexity scenarios, and males are always faster than females in taking over. For autonomous driving information in the HUD, males always pay more visual attention than females, but both males and females are more suitable for using AR display and P3D display. Before applying the ideal autonomous driving information display scheme to car HUD design, designers must take into account the driving environment of the vehicle, the type of HUD, and the gender of the drivers.</p>
<p>The study’s findings can be used to improve the decision-making on the display types of autonomous driving information on HUD based on different levels of scenario complexity similar to those in this experiment. This may enable different autonomous driving information display types to be displayed more effectively in relation to various scenario elements, lessening user cognitive load and saving the company money on development. The aforementioned results have implications for enhancing the autonomous driving information’s SA in HUDs. In the future, concerning the general laws and complexity issues of appropriate autonomous driving information display types in controlled scenarios with different complexities summarized from the experiments, the experimental procedures can be further enhanced and varied in more diverse scenario experiments to expand the applicable scope of the research.</p></section><section id="sec019"><h2 class="pmc_sec_title">Supporting information</h2>
<section class="sm xbox font-sm" id="pone.0329760.s001"><div class="caption p">
<span>S1 File. Supplementary raw data file of eye-tracking experiment for subjects.</span><p>(XLSX)</p>
</div>
<div class="media p"><div class="caption">
<a href="/articles/instance/12373254/bin/pone.0329760.s001.xlsx" data-ga-action="click_feat_suppl" class="usa-link">pone.0329760.s001.xlsx</a><sup> (216.3KB, xlsx) </sup>
</div></div></section></section><section id="ack1" class="ack"><h2 class="pmc_sec_title">Acknowledgments</h2>
<p>This study was assisted by experimental participants as well as volunteers. We are grateful to all those who participated in this study and suggested improvements.</p></section><section id="notes1"><h2 class="pmc_sec_title">Data Availability</h2>
<p>All relevant data are within the paper and its <a href="#sec019" class="usa-link">Supporting information</a> files.</p></section><section id="funding-statement1" lang="en"><h2 class="pmc_sec_title">Funding Statement</h2>
<p>This work was supported by the 2020 Jiangsu Postgraduate International Smart Health Furniture Design and Engineering project (Grant No. 202002). This work was also supported by the 2022 International Cooperation Joint Laboratory for Production, Education, Research, and Application of Ecological Health Care on Home Furnishing (Grant No. 20220602) and the Qing Lan Project (Grant No. 2022QL06). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></section><section id="ref-list1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="ref-list1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="pone.0329760.ref001">
<span class="label">1.</span><cite>Hu L, Zhou X, Zhang X, Wang F, Li Q, Wu W. A review on key challenges in intelligent vehicles: Safety and driver-oriented features. IET Intelligent Trans Sys.
2021;15(9):1093–105. doi: 10.1049/itr2.12088</cite> [<a href="https://doi.org/10.1049/itr2.12088" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IET%20Intelligent%20Trans%20Sys.&amp;title=A%20review%20on%20key%20challenges%20in%20intelligent%20vehicles:%20Safety%20and%20driver-oriented%20features&amp;author=L%20Hu&amp;author=X%20Zhou&amp;author=X%20Zhang&amp;author=F%20Wang&amp;author=Q%20Li&amp;volume=15&amp;issue=9&amp;publication_year=2021&amp;pages=1093-105&amp;doi=10.1049/itr2.12088&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref002">
<span class="label">2.</span><cite>Pettersson I, Ju W. Design techniques for exploring automotive interaction in the drive towards automation. In: Proceedings of the 2017 Conference on Designing Interactive Systems. 2017. p. 147–60. 10.1145/3064663.3064666</cite> [<a href="https://doi.org/10.1145/3064663.3064666" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>]</li>
<li id="pone.0329760.ref003">
<span class="label">3.</span><cite>Poczter SL, Jankovic LM. The Google car: driving toward a better future?. JBCS.
2013;10(1):7. doi: 10.19030/jbcs.v10i1.8324</cite> [<a href="https://doi.org/10.19030/jbcs.v10i1.8324" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=JBCS.&amp;title=The%20Google%20car:%20driving%20toward%20a%20better%20future?&amp;author=SL%20Poczter&amp;author=LM%20Jankovic&amp;volume=10&amp;issue=1&amp;publication_year=2013&amp;pages=7&amp;doi=10.19030/jbcs.v10i1.8324&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref004">
<span class="label">4.</span><cite>Varotto SF, Mons C, Hogema JH, Christoph M, van Nes N, Martens MH. Do adaptive cruise control and lane keeping systems make the longitudinal vehicle control safer? Insights into speeding and time gaps shorter than one second from a naturalistic driving study with SAE Level 2 automation. Transportation Research Part C: Emerging Technologies.
2022;141:103756. doi: 10.1016/j.trc.2022.103756</cite> [<a href="https://doi.org/10.1016/j.trc.2022.103756" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Transportation%20Research%20Part%20C:%20Emerging%20Technologies.&amp;title=Do%20adaptive%20cruise%20control%20and%20lane%20keeping%20systems%20make%20the%20longitudinal%20vehicle%20control%20safer?%20Insights%20into%20speeding%20and%20time%20gaps%20shorter%20than%20one%20second%20from%20a%20naturalistic%20driving%20study%20with%20SAE%20Level%202%20automation&amp;author=SF%20Varotto&amp;author=C%20Mons&amp;author=JH%20Hogema&amp;author=M%20Christoph&amp;author=N%20van%20Nes&amp;volume=141&amp;publication_year=2022&amp;pages=103756&amp;doi=10.1016/j.trc.2022.103756&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref005">
<span class="label">5.</span><cite>Hussain R, Zeadally S. Autonomous cars: research results, issues, and future challenges. IEEE Commun Surv Tutorials.
2019;21(2):1275–313. doi: 10.1109/comst.2018.2869360</cite> [<a href="https://doi.org/10.1109/comst.2018.2869360" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Commun%20Surv%20Tutorials.&amp;title=Autonomous%20cars:%20research%20results,%20issues,%20and%20future%20challenges&amp;author=R%20Hussain&amp;author=S%20Zeadally&amp;volume=21&amp;issue=2&amp;publication_year=2019&amp;pages=1275-313&amp;doi=10.1109/comst.2018.2869360&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref006">
<span class="label">6.</span><cite>de Winter JCF, Happee R, Martens MH, Stanton NA. Effects of adaptive cruise control and highly automated driving on workload and situation awareness: a review of the empirical evidence. Transportation Research Part F: Traffic Psychology and Behaviour.
2014;27:196–217. doi: 10.1016/j.trf.2014.06.016</cite> [<a href="https://doi.org/10.1016/j.trf.2014.06.016" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Transportation%20Research%20Part%20F:%20Traffic%20Psychology%20and%20Behaviour.&amp;title=Effects%20of%20adaptive%20cruise%20control%20and%20highly%20automated%20driving%20on%20workload%20and%20situation%20awareness:%20a%20review%20of%20the%20empirical%20evidence&amp;author=JCF%20de%20Winter&amp;author=R%20Happee&amp;author=MH%20Martens&amp;author=NA%20Stanton&amp;volume=27&amp;publication_year=2014&amp;pages=196-217&amp;doi=10.1016/j.trf.2014.06.016&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref007">
<span class="label">7.</span><cite>Banks VA, Stanton NA. Keep the driver in control: automating automobiles of the future. Appl Ergon.
2016;53 Pt B:389–95. doi: 10.1016/j.apergo.2015.06.020

</cite> [<a href="https://doi.org/10.1016/j.apergo.2015.06.020" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/26141907/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Appl%20Ergon.&amp;title=Keep%20the%20driver%20in%20control:%20automating%20automobiles%20of%20the%20future&amp;author=VA%20Banks&amp;author=NA%20Stanton&amp;publication_year=2016&amp;pages=389-95&amp;pmid=26141907&amp;doi=10.1016/j.apergo.2015.06.020&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref008">
<span class="label">8.</span><cite>Bazilinskyy P, Sakuma T, de Winter J. What driving style makes pedestrians think a passing vehicle is driving automatically?. Appl Ergon.
2021;95:103428. doi: 10.1016/j.apergo.2021.103428

</cite> [<a href="https://doi.org/10.1016/j.apergo.2021.103428" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/34020096/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Appl%20Ergon.&amp;title=What%20driving%20style%20makes%20pedestrians%20think%20a%20passing%20vehicle%20is%20driving%20automatically?&amp;author=P%20Bazilinskyy&amp;author=T%20Sakuma&amp;author=J%20de%20Winter&amp;volume=95&amp;publication_year=2021&amp;pages=103428&amp;pmid=34020096&amp;doi=10.1016/j.apergo.2021.103428&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref009">
<span class="label">9.</span><cite>Louw T, Markkula G, Boer E, Madigan R, Carsten O, Merat N. Coming back into the loop: Drivers’ perceptual-motor performance in critical events after automated driving. Accid Anal Prev.
2017;108:9–18. doi: 10.1016/j.aap.2017.08.011

</cite> [<a href="https://doi.org/10.1016/j.aap.2017.08.011" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/28837837/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Accid%20Anal%20Prev.&amp;title=Coming%20back%20into%20the%20loop:%20Drivers%E2%80%99%20perceptual-motor%20performance%20in%20critical%20events%20after%20automated%20driving&amp;author=T%20Louw&amp;author=G%20Markkula&amp;author=E%20Boer&amp;author=R%20Madigan&amp;author=O%20Carsten&amp;volume=108&amp;publication_year=2017&amp;pages=9-18&amp;pmid=28837837&amp;doi=10.1016/j.aap.2017.08.011&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref010">
<span class="label">10.</span><cite>Nastjuk I, Herrenkind B, Marrone M, Brendel AB, Kolbe LM. What drives the acceptance of autonomous driving? An investigation of acceptance factors from an end-user’s perspective. Technological Forecasting and Social Change.
2020;161:120319. doi: 10.1016/j.techfore.2020.120319</cite> [<a href="https://doi.org/10.1016/j.techfore.2020.120319" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Technological%20Forecasting%20and%20Social%20Change.&amp;title=What%20drives%20the%20acceptance%20of%20autonomous%20driving?%20An%20investigation%20of%20acceptance%20factors%20from%20an%20end-user%E2%80%99s%20perspective&amp;author=I%20Nastjuk&amp;author=B%20Herrenkind&amp;author=M%20Marrone&amp;author=AB%20Brendel&amp;author=LM%20Kolbe&amp;volume=161&amp;publication_year=2020&amp;pages=120319&amp;doi=10.1016/j.techfore.2020.120319&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref011">
<span class="label">11.</span><cite>Techer F, Ojeda L, Barat D, Marteau J-Y, Rampillon F, Feron S, et al. Anger and highly automated driving in urban areas: the role of time pressure. Transportation Research Part F: Traffic Psychology and Behaviour.
2019;64:353–60. doi: 10.1016/j.trf.2019.05.016</cite> [<a href="https://doi.org/10.1016/j.trf.2019.05.016" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Transportation%20Research%20Part%20F:%20Traffic%20Psychology%20and%20Behaviour.&amp;title=Anger%20and%20highly%20automated%20driving%20in%20urban%20areas:%20the%20role%20of%20time%20pressure&amp;author=F%20Techer&amp;author=L%20Ojeda&amp;author=D%20Barat&amp;author=J-Y%20Marteau&amp;author=F%20Rampillon&amp;volume=64&amp;publication_year=2019&amp;pages=353-60&amp;doi=10.1016/j.trf.2019.05.016&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref012">
<span class="label">12.</span><cite>Xing Y, Lv C, Cao D, Hang P. Toward human-vehicle collaboration: review and perspectives on human-centered collaborative automated driving. Transportation Research Part C: Emerging Technologies.
2021;128:103199. doi: 10.1016/j.trc.2021.103199</cite> [<a href="https://doi.org/10.1016/j.trc.2021.103199" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Transportation%20Research%20Part%20C:%20Emerging%20Technologies.&amp;title=Toward%20human-vehicle%20collaboration:%20review%20and%20perspectives%20on%20human-centered%20collaborative%20automated%20driving&amp;author=Y%20Xing&amp;author=C%20Lv&amp;author=D%20Cao&amp;author=P%20Hang&amp;volume=128&amp;publication_year=2021&amp;pages=103199&amp;doi=10.1016/j.trc.2021.103199&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref013">
<span class="label">13.</span><cite>Endsley MR. Toward a theory of situation awareness in dynamic systems. Hum Factors.
1995;37(1):32–64. doi: 10.1518/001872095779049543</cite> [<a href="https://doi.org/10.1518/001872095779049543" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Hum%20Factors.&amp;title=Toward%20a%20theory%20of%20situation%20awareness%20in%20dynamic%20systems&amp;author=MR%20Endsley&amp;volume=37&amp;issue=1&amp;publication_year=1995&amp;pages=32-64&amp;doi=10.1518/001872095779049543&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref014">
<span class="label">14.</span><cite>Carsten O, Martens MH. How can humans understand their automated cars? HMI principles, problems and solutions. Cogn Tech Work.
2018;21(1):3–20. doi: 10.1007/s10111-018-0484-0</cite> [<a href="https://doi.org/10.1007/s10111-018-0484-0" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Cogn%20Tech%20Work.&amp;title=How%20can%20humans%20understand%20their%20automated%20cars?%20HMI%20principles,%20problems%20and%20solutions&amp;author=O%20Carsten&amp;author=MH%20Martens&amp;volume=21&amp;issue=1&amp;publication_year=2018&amp;pages=3-20&amp;doi=10.1007/s10111-018-0484-0&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref015">
<span class="label">15.</span><cite>Fan C, Kong L, Yang B, Wan X. Design of dual-focal-plane AR-HUD optical system based on a single picture generation unit and two freeform mirrors. Photonics.
2023;10(11):1192. doi: 10.3390/photonics10111192</cite> [<a href="https://doi.org/10.3390/photonics10111192" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Photonics.&amp;title=Design%20of%20dual-focal-plane%20AR-HUD%20optical%20system%20based%20on%20a%20single%20picture%20generation%20unit%20and%20two%20freeform%20mirrors&amp;author=C%20Fan&amp;author=L%20Kong&amp;author=B%20Yang&amp;author=X%20Wan&amp;volume=10&amp;issue=11&amp;publication_year=2023&amp;pages=1192&amp;doi=10.3390/photonics10111192&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref016">
<span class="label">16.</span><cite>Stojmenova Pečečnik K, Tomažič S, Sodnik J. Design of head-up display interfaces for automated vehicles. International Journal of Human-Computer Studies.
2023;177:103060. doi: 10.1016/j.ijhcs.2023.103060</cite> [<a href="https://doi.org/10.1016/j.ijhcs.2023.103060" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=International%20Journal%20of%20Human-Computer%20Studies.&amp;title=Design%20of%20head-up%20display%20interfaces%20for%20automated%20vehicles&amp;author=K%20Stojmenova%20Pe%C4%8De%C4%8Dnik&amp;author=S%20Toma%C5%BEi%C4%8D&amp;author=J%20Sodnik&amp;volume=177&amp;publication_year=2023&amp;pages=103060&amp;doi=10.1016/j.ijhcs.2023.103060&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref017">
<span class="label">17.</span><cite>Endsley MR, Garland DJ. Situation awareness analysis and measurement. CRC Press; 2000. 10.1201/b12461</cite> [<a href="https://doi.org/10.1201/b12461" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>]</li>
<li id="pone.0329760.ref018">
<span class="label">18.</span><cite>Miller D, Sun A, Ju W. Situation awareness with different levels of automation. In: 2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC). 2014. p. 688–93. 10.1109/smc.2014.6973989</cite> [<a href="https://doi.org/10.1109/smc.2014.6973989" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>]</li>
<li id="pone.0329760.ref019">
<span class="label">19.</span><cite>Johannsdottir KR, Herdman CM. The role of working memory in supporting drivers’ situation awareness for surrounding traffic. Hum Factors.
2010;52(6):663–73. doi: 10.1177/0018720810385427

</cite> [<a href="https://doi.org/10.1177/0018720810385427" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/21284368/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Hum%20Factors.&amp;title=The%20role%20of%20working%20memory%20in%20supporting%20drivers%E2%80%99%20situation%20awareness%20for%20surrounding%20traffic&amp;author=KR%20Johannsdottir&amp;author=CM%20Herdman&amp;volume=52&amp;issue=6&amp;publication_year=2010&amp;pages=663-73&amp;pmid=21284368&amp;doi=10.1177/0018720810385427&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref020">
<span class="label">20.</span><cite>Scholtz JC, Antonishek B, Young JD. Implementation of a situation awareness assessment tool for evaluation of human–robot interfaces. IEEE Trans Syst, Man, Cybern A.
2005;35(4):450–9. doi: 10.1109/tsmca.2005.850589</cite> [<a href="https://doi.org/10.1109/tsmca.2005.850589" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans%20Syst,%20Man,%20Cybern%20A.&amp;title=Implementation%20of%20a%20situation%20awareness%20assessment%20tool%20for%20evaluation%20of%20human%E2%80%93robot%20interfaces&amp;author=JC%20Scholtz&amp;author=B%20Antonishek&amp;author=JD%20Young&amp;volume=35&amp;issue=4&amp;publication_year=2005&amp;pages=450-9&amp;doi=10.1109/tsmca.2005.850589&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref021">
<span class="label">21.</span><cite>Sonoda K, Wada T. Displaying system situation awareness increases driver trust in automated driving. IEEE Trans Intell Veh.
2017;2(3):185–93. doi: 10.1109/tiv.2017.2749178</cite> [<a href="https://doi.org/10.1109/tiv.2017.2749178" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans%20Intell%20Veh.&amp;title=Displaying%20system%20situation%20awareness%20increases%20driver%20trust%20in%20automated%20driving&amp;author=K%20Sonoda&amp;author=T%20Wada&amp;volume=2&amp;issue=3&amp;publication_year=2017&amp;pages=185-93&amp;doi=10.1109/tiv.2017.2749178&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref022">
<span class="label">22.</span><cite>de Jong T. Cognitive load theory, educational research, and instructional design: some food for thought. Instr Sci.
2009;38(2):105–34. doi: 10.1007/s11251-009-9110-0</cite> [<a href="https://doi.org/10.1007/s11251-009-9110-0" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Instr%20Sci.&amp;title=Cognitive%20load%20theory,%20educational%20research,%20and%20instructional%20design:%20some%20food%20for%20thought&amp;author=T%20de%20Jong&amp;volume=38&amp;issue=2&amp;publication_year=2009&amp;pages=105-34&amp;doi=10.1007/s11251-009-9110-0&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref023">
<span class="label">23.</span><cite>Dindar S, Kaewunruen S, An M. A hierarchical Bayesian-based model for hazard analysis of climate effect on failures of railway turnout components. Reliability Engineering &amp; System Safety.
2022;218:108130. doi: 10.1016/j.ress.2021.108130</cite> [<a href="https://doi.org/10.1016/j.ress.2021.108130" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Reliability%20Engineering%20&amp;%20System%20Safety.&amp;title=A%20hierarchical%20Bayesian-based%20model%20for%20hazard%20analysis%20of%20climate%20effect%20on%20failures%20of%20railway%20turnout%20components&amp;author=S%20Dindar&amp;author=S%20Kaewunruen&amp;author=M%20An&amp;volume=218&amp;publication_year=2022&amp;pages=108130&amp;doi=10.1016/j.ress.2021.108130&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref024">
<span class="label">24.</span><cite>Ahmad BI, Langdon PM, Skrypchuk L, Godsill SJ. How does eye-gaze relate to gesture movement in an automotive pointing task?. Advances in Intelligent Systems and Computing. Springer; 2017. p. 423–34. 10.1007/978-3-319-60441-1_42</cite> [<a href="https://doi.org/10.1007/978-3-319-60441-1_42" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>]</li>
<li id="pone.0329760.ref025">
<span class="label">25.</span><cite>Harrington K, Large DR, Burnett G, Georgiou O. Exploring the use of mid-air ultrasonic feedback to enhance automotive user interfaces. In: Proceedings of the 10th International Conference on Automotive User Interfaces and Interactive Vehicular Applications. 2018. p. 11–20. 10.1145/3239060.3239089</cite> [<a href="https://doi.org/10.1145/3239060.3239089" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>]</li>
<li id="pone.0329760.ref026">
<span class="label">26.</span><cite>Currano R, Park SY, Moore DJ, Lyons K, Sirkin D. Little road driving HUD: heads-up display complexity influences drivers’ perceptions of automated vehicles. In: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 2021. p. 1–15. 10.1145/3411764.3445575</cite> [<a href="https://doi.org/10.1145/3411764.3445575" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>]</li>
<li id="pone.0329760.ref027">
<span class="label">27.</span><cite>Wolfe B, Seppelt B, Mehler B, Reimer B, Rosenholtz R. Rapid holistic perception and evasion of road hazards. J Exp Psychol Gen.
2020;149(3):490–500. doi: 10.1037/xge0000665

</cite> [<a href="https://doi.org/10.1037/xge0000665" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31343185/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Exp%20Psychol%20Gen.&amp;title=Rapid%20holistic%20perception%20and%20evasion%20of%20road%20hazards&amp;author=B%20Wolfe&amp;author=B%20Seppelt&amp;author=B%20Mehler&amp;author=B%20Reimer&amp;author=R%20Rosenholtz&amp;volume=149&amp;issue=3&amp;publication_year=2020&amp;pages=490-500&amp;pmid=31343185&amp;doi=10.1037/xge0000665&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref028">
<span class="label">28.</span><cite>Qian J, Yi J, Zhang J, Cheng Y, Liu J. An entropy weight-based lower confidence bounding optimization approach for engineering product design. Applied Sciences.
2020;10(10):3554. doi: 10.3390/app10103554</cite> [<a href="https://doi.org/10.3390/app10103554" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Applied%20Sciences.&amp;title=An%20entropy%20weight-based%20lower%20confidence%20bounding%20optimization%20approach%20for%20engineering%20product%20design&amp;author=J%20Qian&amp;author=J%20Yi&amp;author=J%20Zhang&amp;author=Y%20Cheng&amp;author=J%20Liu&amp;volume=10&amp;issue=10&amp;publication_year=2020&amp;pages=3554&amp;doi=10.3390/app10103554&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref029">
<span class="label">29.</span><cite>Pan B, Chai H, Liu J, Shao Y, Liu S, Zhang R. Evaluating operational features of multilane turbo roundabouts with an entropy method. J Transp Eng, Part A: Systems.
2022;148(10). doi: 10.1061/jtepbs.0000684</cite> [<a href="https://doi.org/10.1061/jtepbs.0000684" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=J%20Transp%20Eng,%20Part%20A:%20Systems.&amp;title=Evaluating%20operational%20features%20of%20multilane%20turbo%20roundabouts%20with%20an%20entropy%20method&amp;author=B%20Pan&amp;author=H%20Chai&amp;author=J%20Liu&amp;author=Y%20Shao&amp;author=S%20Liu&amp;volume=148&amp;issue=10&amp;publication_year=2022&amp;doi=10.1061/jtepbs.0000684&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref030">
<span class="label">30.</span><cite>Fu S, Fu H. Modeling and TOPSIS-GRA algorithm for autonomous driving decision-making under 5G-V2X infrastructure. Computers, Materials &amp; Continua.
2023;75(1):1051–71. doi: 10.32604/cmc.2023.034495</cite> [<a href="https://doi.org/10.32604/cmc.2023.034495" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Computers,%20Materials%20&amp;%20Continua.&amp;title=Modeling%20and%20TOPSIS-GRA%20algorithm%20for%20autonomous%20driving%20decision-making%20under%205G-V2X%20infrastructure&amp;author=S%20Fu&amp;author=H%20Fu&amp;volume=75&amp;issue=1&amp;publication_year=2023&amp;pages=1051-71&amp;doi=10.32604/cmc.2023.034495&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref031">
<span class="label">31.</span><cite>McCartt AT, Shabanova VI, Leaf WA. Driving experience, crashes and traffic citations of teenage beginning drivers. Accid Anal Prev.
2003;35(3):311–20. doi: 10.1016/s0001-4575(02)00006-4

</cite> [<a href="https://doi.org/10.1016/s0001-4575(02)00006-4" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/12643948/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Accid%20Anal%20Prev.&amp;title=Driving%20experience,%20crashes%20and%20traffic%20citations%20of%20teenage%20beginning%20drivers&amp;author=AT%20McCartt&amp;author=VI%20Shabanova&amp;author=WA%20Leaf&amp;volume=35&amp;issue=3&amp;publication_year=2003&amp;pages=311-20&amp;pmid=12643948&amp;doi=10.1016/s0001-4575(02)00006-4&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref032">
<span class="label">32.</span><cite>Houweling KP, Mallam SC, van de Merwe K, Nordby K. The effects of augmented reality on operator situation awareness and head-down time. Appl Ergon.
2024;116:104213. doi: 10.1016/j.apergo.2023.104213

</cite> [<a href="https://doi.org/10.1016/j.apergo.2023.104213" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38154227/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Appl%20Ergon.&amp;title=The%20effects%20of%20augmented%20reality%20on%20operator%20situation%20awareness%20and%20head-down%20time&amp;author=KP%20Houweling&amp;author=SC%20Mallam&amp;author=K%20van%20de%20Merwe&amp;author=K%20Nordby&amp;volume=116&amp;publication_year=2024&amp;pages=104213&amp;pmid=38154227&amp;doi=10.1016/j.apergo.2023.104213&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref033">
<span class="label">33.</span><cite>Li Y, Wang Y, Song F, Liu Y. Assessing gender perception differences in color combinations in digital visual interfaces using eye tracking – the case of HUD. International Journal of Human–Computer Interaction.
2023;40(20):6591–607. doi: 10.1080/10447318.2023.2258020</cite> [<a href="https://doi.org/10.1080/10447318.2023.2258020" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=International%20Journal%20of%20Human%E2%80%93Computer%20Interaction.&amp;title=Assessing%20gender%20perception%20differences%20in%20color%20combinations%20in%20digital%20visual%20interfaces%20using%20eye%20tracking%20%E2%80%93%20the%20case%20of%20HUD&amp;author=Y%20Li&amp;author=Y%20Wang&amp;author=F%20Song&amp;author=Y%20Liu&amp;volume=40&amp;issue=20&amp;publication_year=2023&amp;pages=6591-607&amp;doi=10.1080/10447318.2023.2258020&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref034">
<span class="label">34.</span><cite>Cohen J. A power primer. Psychol Bull.
1992;112(1):155–9. doi: 10.1037//0033-2909.112.1.155

</cite> [<a href="https://doi.org/10.1037//0033-2909.112.1.155" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/19565683/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Psychol%20Bull.&amp;title=A%20power%20primer&amp;author=J%20Cohen&amp;volume=112&amp;issue=1&amp;publication_year=1992&amp;pages=155-9&amp;pmid=19565683&amp;doi=10.1037//0033-2909.112.1.155&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref035">
<span class="label">35.</span><cite>Faul F, Erdfelder E, Lang A-G, Buchner A. G*Power 3: a flexible statistical power analysis program for the social, behavioral, and biomedical sciences. Behav Res Methods.
2007;39(2):175–91. doi: 10.3758/bf03193146

</cite> [<a href="https://doi.org/10.3758/bf03193146" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/17695343/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Behav%20Res%20Methods.&amp;title=G*Power%203:%20a%20flexible%20statistical%20power%20analysis%20program%20for%20the%20social,%20behavioral,%20and%20biomedical%20sciences&amp;author=F%20Faul&amp;author=E%20Erdfelder&amp;author=A-G%20Lang&amp;author=A%20Buchner&amp;volume=39&amp;issue=2&amp;publication_year=2007&amp;pages=175-91&amp;pmid=17695343&amp;doi=10.3758/bf03193146&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref036">
<span class="label">36.</span><cite>Raj A, Kumar RR. Understanding and enhancing electric vehicle adoption in india: a practice-oriented approach. IEEE Eng Manag Rev.
2024;52(6):19–22. doi: 10.1109/emr.2024.3453554</cite> [<a href="https://doi.org/10.1109/emr.2024.3453554" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Eng%20Manag%20Rev.&amp;title=Understanding%20and%20enhancing%20electric%20vehicle%20adoption%20in%20india:%20a%20practice-oriented%20approach&amp;author=A%20Raj&amp;author=RR%20Kumar&amp;volume=52&amp;issue=6&amp;publication_year=2024&amp;pages=19-22&amp;doi=10.1109/emr.2024.3453554&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref037">
<span class="label">37.</span><cite>Gao W, Shen S, Ji Y, Tian Y. Human perception of the emotional expressions of humanoid robot body movements: evidence from survey and eye-tracking measurements. Biomimetics (Basel).
2024;9(11):684. doi: 10.3390/biomimetics9110684

</cite> [<a href="https://doi.org/10.3390/biomimetics9110684" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="/articles/PMC11591740/" class="usa-link">PMC free article</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/39590256/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Biomimetics%20(Basel).&amp;title=Human%20perception%20of%20the%20emotional%20expressions%20of%20humanoid%20robot%20body%20movements:%20evidence%20from%20survey%20and%20eye-tracking%20measurements&amp;author=W%20Gao&amp;author=S%20Shen&amp;author=Y%20Ji&amp;author=Y%20Tian&amp;volume=9&amp;issue=11&amp;publication_year=2024&amp;pages=684&amp;pmid=39590256&amp;doi=10.3390/biomimetics9110684&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref038">
<span class="label">38.</span><cite>Velichkovsky BM. Heterarchy of cognition: the depths and the highs of a framework for memory research. Memory.
2002;10(5–6):405–19. doi: 10.1080/09658210244000234

</cite> [<a href="https://doi.org/10.1080/09658210244000234" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/12396653/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Memory.&amp;title=Heterarchy%20of%20cognition:%20the%20depths%20and%20the%20highs%20of%20a%20framework%20for%20memory%20research&amp;author=BM%20Velichkovsky&amp;volume=10&amp;publication_year=2002&amp;pages=405-19&amp;pmid=12396653&amp;doi=10.1080/09658210244000234&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref039">
<span class="label">39.</span><cite>Rayner K. Eye movements in reading and information processing: 20 years of research. Psychol Bull.
1998;124(3):372–422. doi: 10.1037/0033-2909.124.3.372

</cite> [<a href="https://doi.org/10.1037/0033-2909.124.3.372" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/9849112/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Psychol%20Bull.&amp;title=Eye%20movements%20in%20reading%20and%20information%20processing:%2020%20years%20of%20research&amp;author=K%20Rayner&amp;volume=124&amp;issue=3&amp;publication_year=1998&amp;pages=372-422&amp;pmid=9849112&amp;doi=10.1037/0033-2909.124.3.372&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref040">
<span class="label">40.</span><cite>Endsley MR. A systematic review and meta-analysis of direct objective measures of situation awareness: a comparison of SAGAT and SPAM. Hum Factors.
2021;63(1):124–50. doi: 10.1177/0018720819875376

</cite> [<a href="https://doi.org/10.1177/0018720819875376" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31560575/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Hum%20Factors.&amp;title=A%20systematic%20review%20and%20meta-analysis%20of%20direct%20objective%20measures%20of%20situation%20awareness:%20a%20comparison%20of%20SAGAT%20and%20SPAM&amp;author=MR%20Endsley&amp;volume=63&amp;issue=1&amp;publication_year=2021&amp;pages=124-50&amp;pmid=31560575&amp;doi=10.1177/0018720819875376&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref041">
<span class="label">41.</span><cite>Rowen A, Grabowski M, Rancy J-P. Through the looking glass(es): impacts of wearable augmented reality displays on operators in a safety-critical system. IEEE Trans Human-Mach Syst.
2019;49(6):652–60. doi: 10.1109/thms.2019.2944384</cite> [<a href="https://doi.org/10.1109/thms.2019.2944384" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=IEEE%20Trans%20Human-Mach%20Syst.&amp;title=Through%20the%20looking%20glass(es):%20impacts%20of%20wearable%20augmented%20reality%20displays%20on%20operators%20in%20a%20safety-critical%20system&amp;author=A%20Rowen&amp;author=M%20Grabowski&amp;author=J-P%20Rancy&amp;volume=49&amp;issue=6&amp;publication_year=2019&amp;pages=652-60&amp;doi=10.1109/thms.2019.2944384&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref042">
<span class="label">42.</span><cite>Cheng Y, Zhong X, Tian L. Does the AR-HUD system affect driving behaviour? An eye-tracking experiment study. Transportation Research Interdisciplinary Perspectives.
2023;18:100767. doi: 10.1016/j.trip.2023.100767</cite> [<a href="https://doi.org/10.1016/j.trip.2023.100767" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Transportation%20Research%20Interdisciplinary%20Perspectives.&amp;title=Does%20the%20AR-HUD%20system%20affect%20driving%20behaviour?%20An%20eye-tracking%20experiment%20study&amp;author=Y%20Cheng&amp;author=X%20Zhong&amp;author=L%20Tian&amp;volume=18&amp;publication_year=2023&amp;pages=100767&amp;doi=10.1016/j.trip.2023.100767&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref043">
<span class="label">43.</span><cite>Rushton SK, Duke PA. Observers cannot accurately estimate the speed of an approaching object in flight. Vision Res.
2009;49(15):1919–28. doi: 10.1016/j.visres.2008.12.012

</cite> [<a href="https://doi.org/10.1016/j.visres.2008.12.012" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/19146869/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Vision%20Res.&amp;title=Observers%20cannot%20accurately%20estimate%20the%20speed%20of%20an%20approaching%20object%20in%20flight&amp;author=SK%20Rushton&amp;author=PA%20Duke&amp;volume=49&amp;issue=15&amp;publication_year=2009&amp;pages=1919-28&amp;pmid=19146869&amp;doi=10.1016/j.visres.2008.12.012&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref044">
<span class="label">44.</span><cite>You F, Zhang J, Zhang J, Shen L, Fang W, Cui W, et al. A novel cooperation-guided warning of invisible danger from AR-HUD to enhance driver’s perception. International Journal of Human–Computer Interaction.
2023;40(8):1873–91. doi: 10.1080/10447318.2023.2233734</cite> [<a href="https://doi.org/10.1080/10447318.2023.2233734" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=International%20Journal%20of%20Human%E2%80%93Computer%20Interaction.&amp;title=A%20novel%20cooperation-guided%20warning%20of%20invisible%20danger%20from%20AR-HUD%20to%20enhance%20driver%E2%80%99s%20perception&amp;author=F%20You&amp;author=J%20Zhang&amp;author=J%20Zhang&amp;author=L%20Shen&amp;author=W%20Fang&amp;volume=40&amp;issue=8&amp;publication_year=2023&amp;pages=1873-91&amp;doi=10.1080/10447318.2023.2233734&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref045">
<span class="label">45.</span><cite>Zhang Y, Kaber DB. An empirical assessment of driver motivation and emotional states in perceived safety margins under varied driving conditions. Ergonomics.
2013;56(2):256–67. doi: 10.1080/00140139.2012.739208

</cite> [<a href="https://doi.org/10.1080/00140139.2012.739208" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/23231697/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Ergonomics.&amp;title=An%20empirical%20assessment%20of%20driver%20motivation%20and%20emotional%20states%20in%20perceived%20safety%20margins%20under%20varied%20driving%20conditions&amp;author=Y%20Zhang&amp;author=DB%20Kaber&amp;volume=56&amp;issue=2&amp;publication_year=2013&amp;pages=256-67&amp;pmid=23231697&amp;doi=10.1080/00140139.2012.739208&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref046">
<span class="label">46.</span><cite>Loeb H, Belwadi A, Maheshwari J, Shaikh S. Age and gender differences in emergency takeover from automated to manual driving on simulator. Traffic Inj Prev.
2019;20(sup2):S163–5. doi: 10.1080/15389588.2019.1661677

</cite> [<a href="https://doi.org/10.1080/15389588.2019.1661677" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/31663790/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Traffic%20Inj%20Prev.&amp;title=Age%20and%20gender%20differences%20in%20emergency%20takeover%20from%20automated%20to%20manual%20driving%20on%20simulator&amp;author=H%20Loeb&amp;author=A%20Belwadi&amp;author=J%20Maheshwari&amp;author=S%20Shaikh&amp;volume=20&amp;publication_year=2019&amp;pmid=31663790&amp;doi=10.1080/15389588.2019.1661677&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref047">
<span class="label">47.</span><cite>Li L, Yang Z, Zeng J, Carlos CQJ. Evaluating driver preferences for in-vehicle displays during distracted driving using driving simulators. Electronics.
2024;13(8):1428. doi: 10.3390/electronics13081428</cite> [<a href="https://doi.org/10.3390/electronics13081428" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Electronics.&amp;title=Evaluating%20driver%20preferences%20for%20in-vehicle%20displays%20during%20distracted%20driving%20using%20driving%20simulators&amp;author=L%20Li&amp;author=Z%20Yang&amp;author=J%20Zeng&amp;author=CQJ%20Carlos&amp;volume=13&amp;issue=8&amp;publication_year=2024&amp;pages=1428&amp;doi=10.3390/electronics13081428&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref048">
<span class="label">48.</span><cite>Shi J, Chai C, Cai R, Wei H, Zhou Y, Fan H, et al. Effects of various in-vehicle human–machine interfaces on drivers’ takeover performance and gaze pattern in conditionally automated vehicles. International Journal of Human-Computer Studies.
2024;192:103362. doi: 10.1016/j.ijhcs.2024.103362</cite> [<a href="https://doi.org/10.1016/j.ijhcs.2024.103362" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=International%20Journal%20of%20Human-Computer%20Studies.&amp;title=Effects%20of%20various%20in-vehicle%20human%E2%80%93machine%20interfaces%20on%20drivers%E2%80%99%20takeover%20performance%20and%20gaze%20pattern%20in%20conditionally%20automated%20vehicles&amp;author=J%20Shi&amp;author=C%20Chai&amp;author=R%20Cai&amp;author=H%20Wei&amp;author=Y%20Zhou&amp;volume=192&amp;publication_year=2024&amp;pages=103362&amp;doi=10.1016/j.ijhcs.2024.103362&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="pone.0329760.ref049">
<span class="label">49.</span><cite>Smith G, Meehan JW, Day RH. The effect of accommodation on retinal image size. Hum Factors.
1992;34(3):289–301. doi: 10.1177/001872089203400304
</cite> [<a href="https://doi.org/10.1177/001872089203400304" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/1634241/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?journal=Hum%20Factors.&amp;title=The%20effect%20of%20accommodation%20on%20retinal%20image%20size&amp;author=G%20Smith&amp;author=JW%20Meehan&amp;author=RH%20Day&amp;volume=34&amp;issue=3&amp;publication_year=1992&amp;pages=289-301&amp;pmid=1634241&amp;doi=10.1177/001872089203400304&amp;" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adsm93_" lang="en" class="supplementary-materials"><h3 class="pmc_sec_title">Supplementary Materials</h3>
<section class="sm xbox font-sm" id="db_ds_supplementary-material1_reqid_"><div class="caption p">
<span>S1 File. Supplementary raw data file of eye-tracking experiment for subjects.</span><p>(XLSX)</p>
</div>
<div class="media p"><div class="caption">
<a href="/articles/instance/12373254/bin/pone.0329760.s001.xlsx" data-ga-action="click_feat_suppl" class="usa-link">pone.0329760.s001.xlsx</a><sup> (216.3KB, xlsx) </sup>
</div></div></section></section><section id="_adda93_" lang="en" class="data-availability-statement"><h3 class="pmc_sec_title">Data Availability Statement</h3>
<p>All relevant data are within the paper and its <a href="#sec019" class="usa-link">Supporting information</a> files.</p></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from PLOS One are provided here courtesy of <strong>PLOS</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1371/journal.pone.0329760"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/pone.0329760.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (7.9 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12373254/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12373254/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12373254%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12373254/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12373254/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12373254/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40845037/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12373254/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40845037/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12373254/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12373254/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="SiMbKfev4j0NB2sbdIw8DNVyNPswVpSFlxJHcMhoLWDBwMXNPYJ6wrRqNUgE3As3">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
        <script type="module" crossorigin="" src="/static/assets/math-574fdcc6.js"></script>
    
    

    </body>
</html>
