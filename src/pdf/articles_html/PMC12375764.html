
<!DOCTYPE html>
<html lang="en" >
    <head >

        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="HandheldFriendly" content="True" />
        <meta name="MobileOptimized" content="320" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />

        
        

        
        
  <link rel="stylesheet" href="/static/assets/style-8258669d.css" />
<script type="module" crossorigin="" src="/static/assets/base_style-f4a99799.js"></script>

  <link rel="stylesheet" href="/static/assets/style-ef962842.css" />
<link rel="stylesheet" href="/static/assets/style-3ade8b5c.css" />
<script type="module" crossorigin="" src="/static/assets/article_style-d757a0dd.js"></script>

  
  
    <style>
  
  
  @media screen and (min-width: 64em) {
    div.pmc-wm {
      background: repeat-y;
      background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='20' height='350' xmlns:xlink='http://www.w3.org/1999/xlink'%3E%3Cdefs%3E%3Cfilter x='-.02' y='0' width='1.05' height='1' id='c'%3E%3CfeFlood flood-color='%23FFF'/%3E%3CfeComposite in='SourceGraphic'/%3E%3C/filter%3E%3Ctext id='b' font-family='Helvetica' font-size='11pt' style='opacity:1;fill:%23005ea2;stroke:none;text-anchor:middle' x='175' y='14'%3E%3C/text%3E%3Cpath id='a' style='fill:%23005ea2' d='M0 8h350v3H0z'/%3E%3C/defs%3E%3Cuse xlink:href='%23a' transform='rotate(90 10 10)'/%3E%3Cuse xlink:href='%23b' transform='rotate(90 10 10)' filter='url(%23c)'/%3E%3C/svg%3E");
      padding-left: 3rem;
    }
  }
</style>

  



        
            <link rel="apple-touch-icon"
                  sizes="180x180"
                  href="/static/img/favicons/apple-touch-icon.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="48x48"
                  href="/static/img/favicons/favicon-48x48.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="32x32"
                  href="/static/img/favicons/favicon-32x32.png" />
            <link rel="icon"
                  type="image/png"
                  sizes="16x16"
                  href="/static/img/favicons/favicon-16x16.png" />
            <link rel="manifest" href="/static/img/favicons/site.webmanifest" />
            <link rel="mask-icon"
                  href="/static/img/favicons/safari-pinned-tab.svg"
                  color="#0071bc" />
            <meta name="msapplication-config"
                  content="/static/img/favicons/browserconfig.xml" />
            <meta name="theme-color" content="#ffffff" />
        

        <title>
            A star modulation network for wireless image semantic transmission - PMC
        </title>

        
        
  
  <!-- Logging params: Pinger defaults -->
<meta name="ncbi_app" content="cloudpmc-viewer" />
<meta name="ncbi_db" content="pmc" />
<meta name="ncbi_phid" content="15251F5E8AEF58A3051F5E0006C55D68.m_1" />
<meta name="ncbi_pinger_stat_url" content="https://pmc.ncbi.nlm.nih.gov/stat" />
<!-- Logging params: Pinger custom -->
<meta name="ncbi_pdid" content="article" />
  
    <link rel="preconnect" href="https://www.google-analytics.com" />

    
        <link rel="preconnect" href="https://cdn.ncbi.nlm.nih.gov" />
    

    <!-- Include USWDS Init Script -->
    <script src="/static/assets/uswds-init.js"></script>


    <meta name="ncbi_domain" content="scirep">
<meta name="ncbi_type" content="fulltext">
<meta name="ncbi_pcid" content="journal">
<meta name="ncbi_feature" content="associated_data">
<link rel="canonical" href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12375764/">
<meta name="robots" content="INDEX,NOFOLLOW,NOARCHIVE">
<meta name="citation_journal_title" content="Scientific Reports">
<meta name="citation_title" content="A star modulation network for wireless image semantic transmission">
<meta name="citation_author" content="Xiangcheng Li">
<meta name="citation_author_institution" content="The School of Computer, Electronics and Information, Guangxi University, Nannning, 53004 China">
<meta name="citation_author_institution" content="The Guangxi Key Laboratory of Multimedia Communication and Network Technology, Guangxi University, Nannning, 530004 China">
<meta name="citation_author" content="Dongri Ban">
<meta name="citation_author_institution" content="The School of Computer, Electronics and Information, Guangxi University, Nannning, 53004 China">
<meta name="citation_author" content="Zhaokai Ruan">
<meta name="citation_author_institution" content="The School of Computer, Electronics and Information, Guangxi University, Nannning, 53004 China">
<meta name="citation_author" content="Xiuyu Yue">
<meta name="citation_author_institution" content="The School of Computer, Electronics and Information, Guangxi University, Nannning, 53004 China">
<meta name="citation_author" content="Haiqiang Chen">
<meta name="citation_author_institution" content="The School of Computer, Electronics and Information, Guangxi University, Nannning, 53004 China">
<meta name="citation_author_institution" content="The Guangxi Key Laboratory of Multimedia Communication and Network Technology, Guangxi University, Nannning, 530004 China">
<meta name="citation_author" content="Youming Sun">
<meta name="citation_author_institution" content="The School of Computer, Electronics and Information, Guangxi University, Nannning, 53004 China">
<meta name="citation_author_institution" content="The Guangxi Key Laboratory of Multimedia Communication and Network Technology, Guangxi University, Nannning, 530004 China">
<meta name="citation_publication_date" content="2025 Aug 24">
<meta name="citation_volume" content="15">
<meta name="citation_firstpage" content="31127">
<meta name="citation_doi" content="10.1038/s41598-025-16753-4">
<meta name="citation_pmid" content="40850988">
<meta name="citation_abstract_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12375764/">
<meta name="citation_fulltext_html_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12375764/">
<meta name="citation_pdf_url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12375764/pdf/41598_2025_Article_16753.pdf">
<meta name="description" content="In recent years, semantic communication based on deep joint source-channel coding (DEEPJSCC) has been demonstrated and widely investigated. However, existing DEEPJSCC schemes suffer from low efficiency in mining latent semantic representations, as ...">
<meta name="og:title" content="A star modulation network for wireless image semantic transmission">
<meta name="og:type" content="article">
<meta name="og:site_name" content="PubMed Central (PMC)">
<meta name="og:description" content="In recent years, semantic communication based on deep joint source-channel coding (DEEPJSCC) has been demonstrated and widely investigated. However, existing DEEPJSCC schemes suffer from low efficiency in mining latent semantic representations, as ...">
<meta name="og:url" content="https://pmc.ncbi.nlm.nih.gov/articles/PMC12375764/">
<meta name="og:image" content="https://cdn.ncbi.nlm.nih.gov/pmc/cms/images/pmc-card-share.jpg?_=0">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@ncbi">
    
    

    </head>
    <body >
        
    <a class="usa-skipnav " href="#main-content">
      Skip to main content
    </a>


        
            

<section class="usa-banner " aria-label="Official website of the United States government" >
    <div class="usa-accordion">
        <header class="usa-banner__header">
            <div class="usa-banner__inner">
                <div class="grid-col-auto">
                    <img aria-hidden="true"
                         class="usa-banner__header-flag"
                         src="/static/img/us_flag.svg"
                         alt="" />
                </div>

                <div class="grid-col-fill tablet:grid-col-auto" aria-hidden="true">
                    <p class="usa-banner__header-text">
                        An official website of the United States government
                    </p>
                    <span class="usa-banner__header-action">Here's how you know</span>
                </div>

                



















    
        <button
            type="button"
        
    
    class="usa-accordion__button usa-banner__button
           

           
               
               
               
               
            

           
           
           
           "
    aria-expanded="false"
    aria-controls="gov-banner-default"
    
    data-testid="storybook-django-banner"
    
    >
    
        

        
                    <span class="usa-banner__button-text">Here's how you know</span>
                

        
    
        
            </button>
        


            </div>
        </header>

        <div class="usa-banner__content usa-accordion__content"
             id="gov-banner-default"
             hidden>
            <div class="grid-row grid-gap-lg">
                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-dot-gov.svg"
                         alt=""
                         aria-hidden="true" />
                    <div class="usa-media-block__body">
                        <p>
                            <strong>Official websites use .gov</strong>
                            <br />
                            A
                            <strong>.gov</strong> website belongs to an official
                            government organization in the United States.
                        </p>
                    </div>
                </div>

                <div class="usa-banner__guidance tablet:grid-col-6">
                    <img class="usa-banner__icon usa-media-block__img"
                         src="/static/img/icon-https.svg"
                         alt=""
                         aria-hidden="true" />

                    <div class="usa-media-block__body">
                        <p>
                            <strong>Secure .gov websites use HTTPS</strong>
                            <br />
                            A <strong>lock</strong> (
                            <span class="icon-lock">
                                <svg xmlns="http://www.w3.org/2000/svg"
                                     width="52"
                                     height="64"
                                     viewBox="0 0 52 64"
                                     class="usa-banner__lock-image"
                                     role="graphics-symbol"
                                     aria-labelledby="banner-lock-description"
                                     focusable="false">
                                    <title id="banner-lock-title">Lock</title>
                                    <desc id="banner-lock-description">
                                    Locked padlock icon
                                    </desc>
                                    <path fill="#000000"
                                          fill-rule="evenodd"
                                          d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z" />
                                </svg>
</span>) or <strong>https://</strong> means you've safely
                                connected to the .gov website. Share sensitive
                                information only on official, secure websites.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

        

        
    
    
    

<div class="usa-overlay">
</div>



<header class="usa-header usa-header--extended usa-header--wide" data-header data-testid="header"    >
    <div class="ncbi-header">
        <div class="ncbi-header__container">
            <a class="ncbi-header__logo-container"
               href="https://www.ncbi.nlm.nih.gov/">
                <img alt="NCBI home page"
                     class="ncbi-header__logo-image"
                     src="/static/img/ncbi-logos/nih-nlm-ncbi--white.svg"
                     width="410"
                     height="100" />
            </a>

            <!-- Mobile menu hamburger button -->
            



















    
        <button
            type="button"
        
    
    class="usa-menu-btn ncbi-header__hamburger-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Show menu"
    data-testid="navMenuButton"
    
    >
    
        

        
                <svg aria-hidden="true"
                     class="ncbi-hamburger-icon"
                     fill="none"
                     focusable="false"
                     height="21"
                     viewBox="0 0 31 21"
                     width="31"
                     xmlns="http://www.w3.org/2000/svg">
                    <path clip-rule="evenodd"
                          d="M0.125 20.75H30.875V17.3333H0.125V20.75ZM0.125 12.2083H30.875V8.79167H0.125V12.2083ZM0.125 0.25V3.66667H30.875V0.25H0.125Z"
                          fill="#F1F1F1"
                          fill-rule="evenodd" />
                </svg>
            

        
    
        
            </button>
        



            
                <!-- Desktop buttons-->
                <div class="ncbi-header__desktop-buttons">
                    
                        <!-- Desktop search button -->
                        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button
           "
    aria-expanded="false"
    aria-controls="search-field-desktop-navigation"
    aria-label="Show search overlay"
    data-testid="toggleSearchPanelButton"
    data-toggle-search-panel-button
    >
    
        

        
                            



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#search" />
    </svg>


                            Search
                        

        
    
        
            </button>
        


                    

                    <!-- Desktop login dropdown -->
                    
                        <div class="ncbi-header__login-dropdown">
                            



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--unstyled ncbi-header__desktop-button ncbi-header__login-dropdown-button
           "
    aria-expanded="false"
    aria-controls="login-dropdown-menu"
    aria-label="Show login menu"
    data-testid="toggleLoginMenuDropdown"
    data-desktop-login-button
    >
    
        

        
                                



    <svg class="usa-icon " role="graphics-symbol" aria-hidden="true" >
        
        <use xlink:href="/static/img/sprite.svg#person" />
    </svg>



                                <span data-login-dropdown-text>Log in</span>

                                <!-- Dropdown icon pointing up -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-less ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-up-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_less" />
    </svg>



                                <!-- Dropdown icon pointing down -->
                                



    <svg class="usa-icon ncbi-header__login-dropdown-icon ncbi-header__login-dropdown-icon--expand-more ncbi-header__login-dropdown-icon--hidden" role="graphics-symbol" aria-hidden="true" data-login-dropdown-down-arrow>
        
        <use xlink:href="/static/img/sprite.svg#expand_more" />
    </svg>


                            

        
    
        
            </button>
        



                            <!-- Login dropdown menu -->
                            <ul class="usa-nav__submenu ncbi-header__login-dropdown-menu"
                                id="login-dropdown-menu"
                                data-desktop-login-menu-dropdown
                                hidden>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                                    </li>
                                
                                    <li class="usa-nav__submenu-item">
                                        <!-- Uses custom style overrides to render external and document links. -->
                                        









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                                    </li>
                                
                                <li class="usa-nav__submenu-item">
                                    



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           usa-button--outline ncbi-header__login-dropdown-logout-button
           "
    
    
    
    data-testid="desktopLogoutButton"
    data-desktop-logout-button
    >
    
        

        Log out

        
    
        
            </button>
        


                                </li>
                            </ul>
                        </div>
                    
                </div>
            
        </div>
    </div>

    <!-- Search panel -->
    
        <div class="ncbi-search-panel ncbi--show-only-at-desktop"
             data-header-search-panel
             hidden>
            <div class="ncbi-search-panel__container">
                <form action="https://www.ncbi.nlm.nih.gov/search/all/"
                      
                      autocomplete="off"
                      class="usa-search usa-search--big ncbi-search-panel__form"
                      data-testid="desktop-navigation-search-form"
                      method="GET"
                      role="search">
                    <label class="usa-sr-only" for="search-field-desktop-navigation">
                        Search…
                    </label>
                    <input class="usa-input"
                           id="search-field-desktop-navigation"
                           name="term"
                           
                               placeholder="Search NCBI"
                           
                           type="search"
                           value="" />
                    



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                        <span class="usa-search__submit-text">
                            Search NCBI
                        </span>
                    

        
    
        
            </button>
        


                </form>

                
            </div>
        </div>
    

    <nav aria-label="Primary navigation" class="usa-nav">
        <p class="usa-sr-only" id="primary-navigation-sr-only-title">
            Primary site navigation
        </p>

        <!-- Mobile menu close button -->
        



















    
        <button
            type="button"
        
    
    class="usa-nav__close ncbi-nav__close-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    aria-label="Close navigation menu"
    data-testid="navCloseButton"
    
    >
    
        

        
            <img src="/static/img/usa-icons/close.svg" alt="Close" />
        

        
    
        
            </button>
        



        
            <!-- Mobile search component -->
            <form class="usa-search usa-search--small ncbi--hide-at-desktop margin-top-6"
                  action="https://www.ncbi.nlm.nih.gov/search/all/"
                  
                  autocomplete="off"
                  data-testid="mobile-navigation-search-form"
                  method="GET"
                  role="search">
                <label class="usa-sr-only" for="search-field-mobile-navigation">
                    Search
                </label>

                <input class="usa-input"
                       id="search-field-mobile-navigation"
                       type="search"
                       
                           placeholder="Search NCBI"
                       
                       name="term" />

                



















    
        <button
            type="submit"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           
           "
    
    
    
    
    
    >
    
        

        
                    <!-- This SVG should be kept inline and not replaced with a link to the icon as otherwise it will render in the wrong color -->
                    <img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0Ij48cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZmlsbD0iI2ZmZiIgZD0iTTE1LjUgMTRoLS43OWwtLjI4LS4yN0E2LjQ3MSA2LjQ3MSAwIDAgMCAxNiA5LjUgNi41IDYuNSAwIDEgMCA5LjUgMTZjMS42MSAwIDMuMDktLjU5IDQuMjMtMS41N2wuMjcuMjh2Ljc5bDUgNC45OUwyMC40OSAxOWwtNC45OS01em0tNiAwQzcuMDEgMTQgNSAxMS45OSA1IDkuNVM3LjAxIDUgOS41IDUgMTQgNy4wMSAxNCA5LjUgMTEuOTkgMTQgOS41IDE0eiIvPjwvc3ZnPg=="
                         class="usa-search__submit-icon"
                         alt="Search" />
                

        
    
        
            </button>
        


            </form>

            
        

        <!-- Primary navigation menu items -->
        <!-- This usa-nav__inner wrapper is required to correctly style the navigation items on Desktop -->
        

        
            <div class="ncbi-nav__mobile-login-menu ncbi--hide-at-desktop"
                 data-mobile-login-menu
                 hidden>
                <p class="ncbi-nav__mobile-login-menu-status">
                    Logged in as:
                    <strong class="ncbi-nav__mobile-login-menu-email"
                            data-mobile-login-email-text></strong>
                </p>
                <ul class="usa-nav__primary usa-accordion">
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/" class="usa-link  "  >
        

        
            Dashboard
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/myncbi/collections/bibliography/" class="usa-link  "  >
        

        
            Publications
        

        
    </a>


                        </li>
                    
                        <li class="usa-nav__primary-item">
                            









    <a href="https://www.ncbi.nlm.nih.gov/account/settings/" class="usa-link  "  >
        

        
            Account settings
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        

        



















    
        <button
            type="button"
        
    
    class="usa-button
           

           
               
               
               
               
            

           
           
           ncbi-nav__mobile-login-button ncbi--hide-at-desktop
           "
    
    
    
    data-testid="mobileLoginButton"
    data-mobile-login-button
    >
    
        

        Log in

        
    
        
            </button>
        


    </nav>
</header>

    
    
        

<section class="pmc-header pmc-header--basic" aria-label="PMC Header with search box">
    <div class="pmc-nav-container">
        <div class="pmc-header__bar">
           <div class="pmc-header__logo">
               <a href="/" title="Home" aria-label="PMC Home"></a>
           </div>
            <button
                    type="button"
                    class="usa-button usa-button--unstyled pmc-header__search__button"
                    aria-label="Open search"
                    data-ga-category="search"
                    data-ga-action="PMC"
                    data-ga-label="pmc_search_panel_mobile"
            >
                <svg class="usa-icon width-4 height-4 pmc-icon__open" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#search"></use>
                </svg>
                <svg class="usa-icon width-4 height-4 pmc-icon__close" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
            </button>
        </div>
        <div class="pmc-header__search">
            


<form class="usa-search usa-search--extra usa-search--article-right-column  pmc-header__search__form" id="pmc-search-form" autocomplete="off" role="search">
<label class="usa-sr-only" for="pmc-search">Search PMC Full-Text Archive</label>
<span class="autoComplete_wrapper flex-1">
<input class="usa-input width-full maxw-none" required="required" placeholder="Search PMC Full-Text Archive" id="pmc-search"  type="search" name="term" data-autocomplete-url="https://pmc.ncbi.nlm.nih.gov/autocomp/search/autocomp/"/>
</span>
<button
class="usa-button"
type="submit"
formaction="https://www.ncbi.nlm.nih.gov/pmc/"
data-ga-category="search"
data-ga-action="PMC"
data-ga-label="PMC_search_button"
>
<span class="usa-search__submit-text">Search in PMC</span>
<img
src="/static/img/usa-icons-bg/search--white.svg"
class="usa-search__submit-icon"
alt="Search"
/>
</button>
</form>
            <div class="display-flex flex-column tablet:flex-row tablet:flex-justify flex-justify-center flex-align-center width-full desktop:maxw-44">
                <ul class="pmc-header__search__menu">
                    <li>
                        
                            <a class="usa-link" href="/journals/" data-ga-action="featured_link" data-ga-label="journal list">
                                Journal List
                            </a>
                        
                    </li>
                    <li>
                        
                            <a class="usa-link" href="/about/userguide/" data-ga-action="featured_link"
                            data-ga-label="user guide">
                                User Guide
                            </a>
                        
                    </li>
                </ul>
                
                    <button form="pmc-search-form" formaction="https://pmc.ncbi.nlm.nih.gov/search/" type="submit" class="usa-button usa-button--unstyled hover:text-no-underline text-no-underline width-auto margin-top-1 tablet:margin-top-0">
     <span class="bg-green-label padding-05 text-white">New</span><span class="text-underline text-primary">Try this search in PMC Beta Search</span>
</button>
                
            </div>
        </div>
    </div>
</section>

    


        
        

       
  <div class="usa-section padding-top-0 desktop:padding-top-6 pmc-article-section" data-article-db="pmc" data-article-id="12375764">

    

   



<div class="grid-container pmc-actions-bar" aria-label="Actions bar" role="complementary">
    <div class="grid-row">
        <div class="grid-col-fill display-flex">
             <div class="display-flex">
                <ul class="usa-list usa-list--unstyled usa-list--horizontal">
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <button
                                type="button"
                                class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                                aria-label="Open resources"
                                data-extra-class="is-visible-resources"
                                data-ga-category="resources_accordion"
                                data-ga-action="click"
                                data-ga-label="mobile_icon"
                        >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#more_vert"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex mob">
                        <a
                                href="https://doi.org/10.1038/s41598-025-16753-4"
                                class="usa-link display-flex usa-tooltip"
                                role="button"
                                target="_blank"
                                rel="noreferrer noopener"
                                title="View on publisher site"
                                data-position="bottom"
                                aria-label="View on publisher site"
                                data-ga-category="actions"
                                data-ga-action="click"
                                data-ga-label="publisher_link_mobile"
                        >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#launch"></use>
                                </svg>
                        </a>
                    </li>
                    
                    
                        <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                             <a
                                     href="pdf/41598_2025_Article_16753.pdf"
                                     class="usa-link display-flex usa-tooltip"
                                     role="button"
                                     title="Download PDF"
                                     data-position="bottom"
                                     aria-label="Download PDF"
                                     data-ga-category="actions"
                                     data-ga-action="click"
                                     data-ga-label="pdf_download_mobile"
                             >
                                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                                </svg>
                            </a>
                        </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button
                            class="usa-button usa-button--unstyled  usa-tooltip collections-dialog-trigger collections-button display-flex collections-button-empty"
                            title="Add to Collections"
                            data-position="bottom"
                            aria-label="Save article in MyNCBI collections."
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="collections_button_mobile"
                            data-collections-open-dialog-enabled="false"
                            data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12375764%2F%3Freport%3Dclassic%23open-collections-dialog"
                            data-in-collections="false"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="margin-right-2 mobile-lg:margin-right-4 display-flex">
                        <button role="button" class="usa-button usa-button--unstyled usa-tooltip citation-dialog-trigger display-flex"
                            aria-label="Open dialog with citation text in different styles"
                            title="Cite"
                            data-position="bottom"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="cite_mobile"
                            data-all-citations-url="/resources/citations/12375764/"
                            data-citation-style="nlm"
                            data-download-format-link="/resources/citations/12375764/export/"
                        >
                            <svg class="usa-icon width-4 height-4 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                            </svg>
                        </button>
                    </li>
                    
                    <li class="pmc-permalink display-flex" >
                         <button
                                 type="button"
                                 title="Permalink"
                                 data-position="bottom"
                                 class="usa-button usa-button--unstyled display-flex usa-tooltip"
                                 aria-label="Show article permalink"
                                 aria-expanded="false"
                                 aria-haspopup="true"
                                 data-ga-category="actions"
                                 data-ga-action="open"
                                 data-ga-label="permalink_mobile"
                         >
                            <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                                <use xlink:href="/static/img/sprite.svg#share"></use>
                            </svg>
                        </button>
                        

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12375764/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
                    </li>
                </ul>
            </div>
            <button
                    type="button"
                    class="usa-button pmc-sidenav__container__open usa-button--unstyled width-auto display-flex"
                    aria-label="Open article navigation"
                    data-extra-class="is-visible-in-page"
                    data-ga-category="actions"
                    data-ga-action="open"
                    data-ga-label="article_nav_mobile"
            >
                <svg class="usa-icon width-4 height-4" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#list"></use>
                </svg>
            </button>
        </div>
    </div>
</div>
    <div class="grid-container desktop:padding-left-6">
      <div id="article-container" class="grid-row grid-gap">
        <div class="grid-col-12 desktop:grid-col-8 order-2 pmc-layout__content">
            <div class="grid-container padding-left-0 padding-right-0">
                <div class="grid-row desktop:margin-left-neg-6">
                    <div class="grid-col-12">
                        <div class="pmc-layout__disclaimer" role="complementary" aria-label="Disclaimer note">
    As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,
    the contents by NLM or the National Institutes of Health.<br/>
    Learn more:
    <a class="usa-link" data-ga-category="Link click" data-ga-action="Disclaimer" data-ga-label="New disclaimer box" href="/about/disclaimer/">PMC Disclaimer</a>
    |
    <a class="usa-link" data-ga-category="Link click" data-ga-action="PMC Copyright Notice" data-ga-label="New disclaimer box" href="/about/copyright/">
        PMC Copyright Notice
    </a>
</div>
                    </div>
                </div>
                <div class="grid-row pmc-wm desktop:margin-left-neg-6">
                    <!-- Main content -->
                    <main
                      id="main-content"
                      class="usa-layout-docs__main usa-layout-docs grid-col-12 pmc-layout pmc-prose padding-0"
                    >

                      
                        <section class="pmc-journal-banner text-center line-height-none" aria-label="Journal banner"><img src="https://cdn.ncbi.nlm.nih.gov/pmc/banners/logo-scirep.jpg" alt="Scientific Reports logo" usemap="#pmc-banner-imagemap" width="500" height="75"><map name="pmc-banner-imagemap"><area alt="Link to Scientific Reports" title="Link to Scientific Reports" shape="default" href="http://www.nature.com/srep" target="_blank" rel="noopener noreferrer"></map></section><article lang="en"><section aria-label="Article citation and metadata"><section class="pmc-layout__citation font-secondary font-xs"><div>
<div class="display-inline-block"><button type="button" class="cursor-pointer text-no-underline bg-transparent border-0 padding-0 text-left margin-0 text-normal text-primary" aria-controls="journal_context_menu">Sci Rep</button></div>. 2025 Aug 24;15:31127. doi: <a href="https://doi.org/10.1038/s41598-025-16753-4" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">10.1038/s41598-025-16753-4</a>
</div>
<nav id="journal_context_menu" hidden="hidden"><ul class="menu-list font-family-ui" role="menu">
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22Sci%20Rep%22%5Bjour%5D" class="usa-link" role="menuitem">Search in PMC</a></li>
<li role="presentation"><a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sci%20Rep%22%5Bjour%5D" lang="en" class="usa-link" role="menuitem">Search in PubMed</a></li>
<li role="presentation"><a href="https://www.ncbi.nlm.nih.gov/nlmcatalog?term=%22Sci%20Rep%22%5BTitle%20Abbreviation%5D" class="usa-link" role="menuitem">View in NLM Catalog</a></li>
<li role="presentation"><a href="?term=%22Sci%20Rep%22%5Bjour%5D" class="usa-link" role="menuitem" data-add-to-search="true">Add to search</a></li>
</ul></nav></section><section class="front-matter"><div class="ameta p font-secondary font-xs">
<hgroup><h1>A star modulation network for wireless image semantic transmission</h1></hgroup><div class="cg p">
<a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Li%20X%22%5BAuthor%5D" class="usa-link" aria-describedby="id1"><span class="name western">Xiangcheng Li</span></a><div hidden="hidden" id="id1">
<h3><span class="name western">Xiangcheng Li</span></h3>
<div class="p">
<sup>1</sup>The School of Computer, Electronics and Information, Guangxi University, Nannning, 53004 China </div>
<div class="p">
<sup>2</sup>The Guangxi Key Laboratory of Multimedia Communication and Network Technology, Guangxi University, Nannning, 530004 China </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Li%20X%22%5BAuthor%5D" class="usa-link"><span class="name western">Xiangcheng Li</span></a>
</div>
</div>
<sup>1,</sup><sup>2,</sup><sup>#</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Ban%20D%22%5BAuthor%5D" class="usa-link" aria-describedby="id2"><span class="name western">Dongri Ban</span></a><div hidden="hidden" id="id2">
<h3><span class="name western">Dongri Ban</span></h3>
<div class="p">
<sup>1</sup>The School of Computer, Electronics and Information, Guangxi University, Nannning, 53004 China </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Ban%20D%22%5BAuthor%5D" class="usa-link"><span class="name western">Dongri Ban</span></a>
</div>
</div>
<sup>1,</sup><sup>#</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Ruan%20Z%22%5BAuthor%5D" class="usa-link" aria-describedby="id3"><span class="name western">Zhaokai Ruan</span></a><div hidden="hidden" id="id3">
<h3><span class="name western">Zhaokai Ruan</span></h3>
<div class="p">
<sup>1</sup>The School of Computer, Electronics and Information, Guangxi University, Nannning, 53004 China </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Ruan%20Z%22%5BAuthor%5D" class="usa-link"><span class="name western">Zhaokai Ruan</span></a>
</div>
</div>
<sup>1</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Yue%20X%22%5BAuthor%5D" class="usa-link" aria-describedby="id4"><span class="name western">Xiuyu Yue</span></a><div hidden="hidden" id="id4">
<h3><span class="name western">Xiuyu Yue</span></h3>
<div class="p">
<sup>1</sup>The School of Computer, Electronics and Information, Guangxi University, Nannning, 53004 China </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Yue%20X%22%5BAuthor%5D" class="usa-link"><span class="name western">Xiuyu Yue</span></a>
</div>
</div>
<sup>1</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Chen%20H%22%5BAuthor%5D" class="usa-link" aria-describedby="id5"><span class="name western">Haiqiang Chen</span></a><div hidden="hidden" id="id5">
<h3><span class="name western">Haiqiang Chen</span></h3>
<div class="p">
<sup>1</sup>The School of Computer, Electronics and Information, Guangxi University, Nannning, 53004 China </div>
<div class="p">
<sup>2</sup>The Guangxi Key Laboratory of Multimedia Communication and Network Technology, Guangxi University, Nannning, 530004 China </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Chen%20H%22%5BAuthor%5D" class="usa-link"><span class="name western">Haiqiang Chen</span></a>
</div>
</div>
<sup>1,</sup><sup>2</sup>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sun%20Y%22%5BAuthor%5D" class="usa-link" aria-describedby="id6"><span class="name western">Youming Sun</span></a><div hidden="hidden" id="id6">
<h3><span class="name western">Youming Sun</span></h3>
<div class="p">
<sup>1</sup>The School of Computer, Electronics and Information, Guangxi University, Nannning, 53004 China </div>
<div class="p">
<sup>2</sup>The Guangxi Key Laboratory of Multimedia Communication and Network Technology, Guangxi University, Nannning, 530004 China </div>
<div class="p">Find articles by <a href="https://pubmed.ncbi.nlm.nih.gov/?term=%22Sun%20Y%22%5BAuthor%5D" class="usa-link"><span class="name western">Youming Sun</span></a>
</div>
</div>
<sup>1,</sup><sup>2,</sup><sup>✉,</sup><sup>#</sup>
</div>
<ul class="d-buttons inline-list">
<li><button class="d-button" aria-controls="aip_a" aria-expanded="false">Author information</button></li>
<li><button class="d-button" aria-controls="anp_a" aria-expanded="false">Article notes</button></li>
<li><button class="d-button" aria-controls="clp_a" aria-expanded="false">Copyright and License information</button></li>
</ul>
<div class="d-panels font-secondary-light">
<div id="aip_a" class="d-panel p" style="display: none">
<div class="p" id="Aff1">
<sup>1</sup>The School of Computer, Electronics and Information, Guangxi University, Nannning, 53004 China </div>
<div id="Aff2">
<sup>2</sup>The Guangxi Key Laboratory of Multimedia Communication and Network Technology, Guangxi University, Nannning, 530004 China </div>
<div class="author-notes p">
<div class="fn" id="_fncrsp93pmc__">
<sup>✉</sup><p class="display-inline">Corresponding author.</p>
</div>
<div class="fn" id="_eqcntrb93pmc__">
<sup>#</sup><p class="display-inline">Contributed equally.</p>
</div>
</div>
</div>
<div id="anp_a" class="d-panel p" style="display: none"><div class="notes p"><section id="historyarticle-meta1" class="history"><p>Received 2025 May 16; Accepted 2025 Aug 19; Collection date 2025.</p></section></div></div>
<div id="clp_a" class="d-panel p" style="display: none">
<div>© The Author(s) 2025</div>
<p><strong>Open Access</strong> This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://creativecommons.org/licenses/by-nc-nd/4.0/</a>.</p>
<div class="p"><a href="/about/copyright/" class="usa-link">PMC Copyright notice</a></div>
</div>
</div>
<div>PMCID: PMC12375764  PMID: <a href="https://pubmed.ncbi.nlm.nih.gov/40850988/" class="usa-link">40850988</a>
</div>
</div></section></section><section aria-label="Article content"><section class="body main-article-body"><section class="abstract" id="Abs1"><h2>Abstract</h2>
<p id="Par1">In recent years, semantic communication based on deep joint source-channel coding (DEEPJSCC) has been demonstrated and widely investigated. However, existing DEEPJSCC schemes suffer from low efficiency in mining latent semantic representations, as well as large model size, high computational complexity, and redundant parameters. To address these issues, we meticulously establish a lightweight DEEPJSCC framework for wireless image semantic transmission, termed STARJSCC. The proposed method achieves flexible wireless image transmission by introducing an improved channel state adaptive module (CSA Mod) to adapt to different channel conditions, combined with a decoupled static semantic compression (SC) mask to control different transmission rates. Experimental results show that the STARJSCC framework outperforms other baseline schemes in terms of performance and adaptability across various transmission rates and signal-to-noise ratio (SNR) levels, achieving up to 2.73 dB improvement on high-resolution test set. Moreover, this solution significantly reduces model parameters, computational complexity, and storage overhead, providing a potential solution for high-quality wireless image transmission in resource-constrained scenarios.</p>
<section id="kwd-group1" lang="en" class="kwd-group"><p><strong>Keywords:</strong> Joint source-channel coding, Channel state adaptation, Channel bandwidth ratio adaptation, Lightweight</p></section><section id="kwd-group2" class="kwd-group"><p><strong>Subject terms:</strong> Information technology, Information theory and computation</p></section></section><section id="Sec1"><h2 class="pmc_sec_title">Introduction</h2>
<p id="Par2">With the iterative innovation of information technology and the disruptive evolution of computational paradigms, the deep integration of communication technology and artificial intelligence (AI) is propelling human society into a new era of intelligent interconnection of all things<sup><a href="#CR1" class="usa-link" aria-describedby="CR1">1</a>–<a href="#CR4" class="usa-link" aria-describedby="CR4">4</a></sup>. In this process, the inevitable strain on bandwidth resources and explosive growth of data transmission present fundamental challenges to traditional transmission frameworks based on Shannon’s information theory<sup><a href="#CR5" class="usa-link" aria-describedby="CR5">5</a></sup>. Semantic communication, an emerging communication paradigm centered on information meaning, aims not merely to ensure accurate transmission of data symbols, but to place greater emphasis on the receiving end’s comprehension and effective utilization of informational intent and semantics<sup><a href="#CR6" class="usa-link" aria-describedby="CR6">6</a>,<a href="#CR7" class="usa-link" aria-describedby="CR7">7</a></sup>. This concept is similar to technologies such as zero-knowledge proof and homomorphic encryption in blockchain<sup><a href="#CR8" class="usa-link" aria-describedby="CR8">8</a></sup>, which attempt to strip away the surface representation of data and directly operate on or convey the underlying logic or meaning. Semantic communication transcends the conventional focus on “signal fidelity” in traditional communication systems, shifting towards “semantic fidelity” as its primary objective, thereby enhancing communication efficiency and intelligent capabilities.</p>
<p id="Par3">In traditional communication systems, source coding and channel coding are designed as two independent functional modules. For instance, in conventional wireless image transmission systems, the transmission process is typically divided into two primary stages: image compression (employing standards like JPEG<sup><a href="#CR9" class="usa-link" aria-describedby="CR9">9</a></sup>, JPEG2000<sup><a href="#CR10" class="usa-link" aria-describedby="CR10">10</a></sup> and BPG<sup><a href="#CR11" class="usa-link" aria-describedby="CR11">11</a></sup>) and data transmission (utilizing error-correcting codes such as LDPC<sup><a href="#CR12" class="usa-link" aria-describedby="CR12">12</a></sup>, Turbo codes<sup><a href="#CR13" class="usa-link" aria-describedby="CR13">13</a></sup>, and Polar codes<sup><a href="#CR14" class="usa-link" aria-describedby="CR14">14</a></sup>). Such a decoupled approach facilitates the flexible design, development, and maintenance of communication systems through modular optimization. However, the separated source-channel coding (SSCC) paradigm inherently prevents synergistic operation to achieve optimal overall communication capacity from the perspective of system optimality. Moreover, under low signal-to-noise ratio (SNR) conditions where channel decoding fails to ensure zero bit error rate (BER), this architecture is prone to the “cliff effect” – a phenomenon characterized by abrupt performance degradation beyond critical SNR thresholds. Consequently, in recent years, as semantic communication technologies have demonstrated their potential in improving wireless network performance, neural/deep learning-based end-to-end optimized joint source-channel coding (JSCC) for data transmission has emerged as an active research domain within semantic communications. This approach demonstrates consistent superiority over the SSCC paradigm across various tasks including text<sup><a href="#CR15" class="usa-link" aria-describedby="CR15">15</a></sup>, speech<sup><a href="#CR16" class="usa-link" aria-describedby="CR16">16</a></sup>, and image processing<sup><a href="#CR17" class="usa-link" aria-describedby="CR17">17</a>–<a href="#CR26" class="usa-link" aria-describedby="CR26">26</a></sup>, particularly in scenarios requiring semantic-aware transmission robustness.</p>
<p id="Par4">As one of the pioneering works in this domain, a CNN-based deep JSCC scheme (DEEPJSCC) for wireless image transmission was first proposed in Ref<sup><a href="#CR17" class="usa-link" aria-describedby="CR17">17</a></sup>.. By constructing a CNN-parameterized encoder-decoder architecture and adopting an end-to-end jointly optimized training strategy, this approach transcended the theoretical limitations of SSCC designs in conventional systems, demonstrating superior performance over SSCC schemes in both Gaussian and Rayleigh fading channels. Building upon this foundation, Ref<sup><a href="#CR18" class="usa-link" aria-describedby="CR18">18</a></sup>. expanded the research boundaries of deep joint coding by innovatively proposing a feedback-enabled semantic-aware image transmission system (DEEPJSCC-f). Through the introduction of a dual-mode channel feedback mechanism (incorporating ideal noiseless feedback and practical noisy feedback), the system dynamically adjusts encoder-side semantic feature extraction strategies to strengthen receiver-side image quality, though it should be noted that feedback does not theoretically increase the capacity of memoryless communication channels. To mitigate the performance degradation caused by channel SNR mismatch in DEEPJSCC, Xu et al.<sup><a href="#CR19" class="usa-link" aria-describedby="CR19">19</a></sup> proposed attention-enhanced JSCC (ADJSCC), which employed attention modules to recalibrate channel characteristics, enabling dynamic adjustment of source coding compression ratios and channel coding rates according to varying SNR conditions. Subsequently, Yuan et al.<sup><a href="#CR20" class="usa-link" aria-describedby="CR20">20</a></sup>refined the ADJSCC methodology into channel-blind JSCC (CBJSCC), achieving superior performance across different SNR levels without requiring prior channel state information. The work in Ref<sup><a href="#CR21" class="usa-link" aria-describedby="CR21">21</a></sup>. optimized wireless image transmission efficiency and quality through dynamic responses to channel conditions and image content, realizing adaptive rate control in deep learning-based JSCC models. However, these adaptive schemes primarily focus on either rate control or SNR adaptation, but not both concurrently. To address this limitation, a flexible dual-adaptive JSCC scheme (DEEPJSCC-V) was proposed in Ref<sup><a href="#CR22" class="usa-link" aria-describedby="CR22">22</a></sup>., integrating ADJSCC methodologies with adaptive masking mechanisms. This hybrid architecture enables transmission scheme adjustments based on both SNR variations and channel bandwidth ratios (CBR), demonstrating enhanced robustness albeit at the cost of marginal performance degradation compared to single-parameter adaptation approaches. On the other hand, JSCC frameworks based on Transformer architectures<sup><a href="#CR23" class="usa-link" aria-describedby="CR23">23</a>–<a href="#CR25" class="usa-link" aria-describedby="CR25">25</a></sup> and Mamba state-space models<sup><a href="#CR26" class="usa-link" aria-describedby="CR26">26</a></sup> have recently emerged as a prominent research direction due to their exceptional capability in capturing long-term dependencies and semantic representation capacities. However, these methods are excluded from our performance discussion due to their substantially larger model sizes (quantitative comparisons are provided in subsequent sections) compared to CNN-based solutions, which makes them unfavorable for deployment on edge devices.</p>
<p id="Par5">The aforementioned systems have demonstrated the immense potential of deep learning technologies in semantic communications. However, in DEEPJSCC and its variants<sup><a href="#CR17" class="usa-link" aria-describedby="CR17">17</a>–<a href="#CR22" class="usa-link" aria-describedby="CR22">22</a></sup>, the inherent limitations of conventional convolutions for feature extraction significantly compromise semantic information extraction efficiency, communication resource utilization, and system robustness. Specifically, the quadratic growth of parameters and computational complexity with increasing input channels and kernel dimensions leads to inefficient feature extraction. Furthermore, the lack of explicit model size consideration during design restricts their applicability in resource-constrained semantic communication scenarios (e.g., mobile terminals, IoT devices, edge nodes), where computational and memory budgets are strictly limited. Regarding channel state adaptation, the conventional squeeze-and-excitation (SE) channel attention mechanism<sup><a href="#CR27" class="usa-link" aria-describedby="CR27">27</a></sup> primarily focuses on global information extraction while inadequately exploiting the value of local patterns. Consequently, in semantic communications, designing a channel attention mechanism capable of effectively fusing global and local information without significantly increasing computational complexity remains an unresolved yet critically important research challenge. Such a mechanism demands efficient operation while enabling rational weight allocation to achieve comprehensive yet precise information capture and utilization, particularly crucial for semantic-aware systems requiring balanced performance between feature granularity and processing efficiency.</p>
<p id="Par6">To address the aforementioned challenges, this paper proposes an efficient semantic coding-decoding network based on star operation for wireless image transmission, termed STARJSCC. The star operation maps input features into an ultra-high-dimensional nonlinear feature space<sup><a href="#CR28" class="usa-link" aria-describedby="CR28">28</a></sup>, thereby amplifying the model’s representational capacity. By leveraging star blocks to extract semantic features and project them into this high-dimensional nonlinear space, our approach simultaneously improves the characterization of latent semantic features and boosts model capacity while maintaining computational efficiency. Our primary innovations are summarized as follows:</p>
<ul class="list" style="list-style-type:disc">
<li><p id="Par7">A encoder-decoder architecture based on star-operation modulation network is designed. Considering the challenges associated with model size and complexity, the proposed scheme retains a convolution-based design approach. Distinctively, we develop a novel JSCC backbone network by integrating the star operation for feature fusion and leveraging the strengths of depthwise convolutions. This architecture is anticipated to enhance the model’s semantic feature representation capacity and transmission performance while significantly reducing model parameters and computational complexity.</p></li>
<li><p id="Par8">A channel state adaptive module (CSA Mod) based on dynamic fine-grained attention mechanism is proposed. To enhance transmission quality and reconstruction fidelity by adapting to real-time channel conditions, we propose a critical plug-in module in STARJSCC, termed CSA Mod. This module refines the SENet architecture by introducing interactions between global and local features while incorporating SNR information as a guidance factor, thereby achieving channel state adaptation.</p></li>
</ul></section><section id="Sec2"><h2 class="pmc_sec_title">System model design</h2>
<section id="Sec3"><h3 class="pmc_sec_title">The system model of STARJSCC</h3>
<p id="Par9">As a fundamental paradigm in semantic communication systems, the DEEPJSCC framework achieves semantic-level joint source-channel modeling through the synergistic optimization of an end-to-end neural encoder-decoder. The input image is mapped by the joint source-channel encoder into a form suitable for transmission over wireless channels. After undergoing specific CBR and channel conditions, the receiver aims to reconstruct the original semantic information via the decoder, minimizing the semantic discrepancy between the reconstructed and input images. This approach emphasizes semantic fidelity while balancing communication efficiency and robustness.</p>
<p id="Par10">Figure <a href="#Fig1" class="usa-link">1</a> illustrates the system model of STARJSCC. The essential part of it consists of a joint encoder <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq1"><math id="d33e425"><msub><mi>E</mi><mi>θ</mi></msub></math></span> and a joint decoder <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq2"><math id="d33e436"><msub><mi>D</mi><mi>φ</mi></msub></math></span>, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq3"><math id="d33e447"><mi>θ</mi></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq4"><math id="d33e456"><mi>φ</mi></math></span> denote the trainable parameters of the encoder and decoder, respectively. Moreover, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq5"><math id="d33e466"><mrow><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mi>N</mi></msup></mrow></math></span> denotes input image, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq6"><math id="d33e484"><mi mathvariant="double-struck">R</mi></math></span> is real number field and its dimensionality <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq7"><math id="d33e494"><mrow><mi>N</mi><mo>=</mo><mi>C</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>W</mi></mrow></math></span>, with <em>C</em>, <em>H</em>, and <em>W</em> representing the number of channels, height, and width of the input image, respectively. During the encoding process, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq8"><math id="d33e520"><msub><mi>E</mi><mi>θ</mi></msub></math></span> maps the input information <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq9"><math id="d33e531"><mrow><mi mathvariant="bold-italic">x</mi></mrow></math></span> and the SNR into an <em>N</em>-dimensional complex-valued semantic code (CSC) <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq10"><math id="d33e545"><mrow><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">C</mi></mrow><mi>N</mi></msup></mrow></math></span>, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq11"><math id="d33e563"><mi mathvariant="double-struck">C</mi></math></span> denotes the complex number set. The encoding process is formulated as:</p>
<table class="disp-formula p" id="Equ1"><tr>
<td class="formula"><math id="d33e574" display="block"><mrow><mtable><mtr><mtd columnalign="right"><mrow><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo>=</mo><msub><mi>E</mi><mi>θ</mi></msub><mfenced close=")" open="("><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo>,</mo><mi>ε</mi><mo>,</mo><mi>γ</mi></mfenced><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">C</mi></mrow><mi>N</mi></msup><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">1</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq12"><math id="d33e610"><mi>ε</mi></math></span> is the SNR and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq13"><math id="d33e619"><mi>γ</mi></math></span> is the CBR of the input data, respectively. Before transmission through the wireless channel, the real and imaginary parts of the masked CSC <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq14"><math id="d33e628"><mrow><mi mathvariant="bold-italic">y</mi></mrow></math></span> are extracted and concatenated to form the input signal. After channel processing, the output is reconstructed by concatenating the real and imaginary parts into a single real-valued vector, which serves as the input for the subsequent stage.</p>
<figure class="fig xbox font-sm" id="Fig1"><h4 class="obj_head">Fig. 1.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375764_41598_2025_16753_Fig1_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b56f/12375764/c8abf242fe55/41598_2025_16753_Fig1_HTML.jpg" loading="lazy" id="MO1" height="180" width="668" alt="Fig. 1"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Overview of STARJSCC system model for wireless image transmission.</p></figcaption></figure><p id="Par11">To enable the model to control transmission rate according to different CBR values, the CSC <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq15"><math id="d33e641"><mrow><mi mathvariant="bold-italic">y</mi></mrow></math></span> needs to be processed through the semantic compression (SC) operation. During this process, the system generates a semantic mask tensor <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq16"><math id="d33e652"><mrow><mrow><mi mathvariant="bold-italic">ρ</mi></mrow><mo>∈</mo><msup><mfenced close="}" open="{"><mn>0</mn><mo>,</mo><mn>1</mn></mfenced><mi>N</mi></msup></mrow></math></span> conditioned on the CBR with input value <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq17"><math id="d33e671"><mi>γ</mi></math></span>. Each element of the tensor <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq18"><math id="d33e680"><mrow><mi mathvariant="bold-italic">ρ</mi></mrow></math></span> is determined by the following formulation:</p>
<table class="disp-formula p" id="Equ2"><tr>
<td class="formula"><math id="d33e692" display="block"><mrow><mtable><mtr><mtd columnalign="right"><mrow><mrow><msub><mi mathvariant="bold-italic">ρ</mi><mi mathvariant="bold-italic">i</mi></msub></mrow><mo>=</mo><mfenced open="{"><mrow><mtable><mtr><mtd columnalign="left"><mn>1</mn></mtd><mtd columnalign="left"><mrow><mspace width="0.333333em"></mspace><mtext>if</mtext><mspace width="0.333333em"></mspace><mi>i</mi><mo>&lt;</mo><mi>k</mi></mrow></mtd></mtr><mtr><mtd columnalign="left"><mrow><mrow></mrow><mn>0</mn></mrow></mtd><mtd columnalign="left"><mrow><mspace width="0.333333em"></mspace><mtext>otherwise</mtext><mspace width="0.333333em"></mspace></mrow></mtd></mtr></mtable></mrow></mfenced><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">2</td>
</tr></table>
<p>The SC process applied to <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq19"><math id="d33e738"><mrow><mi mathvariant="bold-italic">y</mi></mrow></math></span> can be formulated as:</p>
<table class="disp-formula p" id="Equ3"><tr>
<td class="formula"><math id="d33e750" display="block"><mrow><mtable><mtr><mtd columnalign="right"><mrow><msup><mrow><mrow><mi mathvariant="bold-italic">y</mi></mrow></mrow><mo>′</mo></msup><mo>=</mo><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo>·</mo><mrow><mi mathvariant="bold-italic">ρ</mi></mrow><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">C</mi></mrow><mi>k</mi></msup><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">3</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq20"><math id="d33e784"><mo>·</mo></math></span> denotes dot product operation. The compressed semantic feature dimension is given by <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq21"><math id="d33e793"><mrow><mi>k</mi><mo>=</mo><mi>γ</mi><mo>×</mo><mi>N</mi></mrow></math></span>. When <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq22"><math id="d33e807"><mrow><mrow><msub><mi mathvariant="bold-italic">ρ</mi><mi mathvariant="bold-italic">i</mi></msub></mrow><mo>=</mo><mn>1</mn></mrow></math></span>, the <em>i</em>-th semantic symbol is selected for transmission; whereas <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq23"><math id="d33e828"><mrow><mrow><msub><mi mathvariant="bold-italic">ρ</mi><mi mathvariant="bold-italic">i</mi></msub></mrow><mo>=</mo><mn>0</mn></mrow></math></span> indicates that the <em>i</em>-th symbol is discarded as non-informative. After that, the first <em>k</em> elements of CSC <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq24"><math id="d33e851"><mrow><mi mathvariant="bold-italic">y</mi></mrow></math></span> are selected by mask tensor <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq25"><math id="d33e862"><mrow><mi mathvariant="bold-italic">ρ</mi></mrow></math></span>, generating the masked semantic information <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq26"><math id="d33e873"><msup><mrow><mrow><mi mathvariant="bold-italic">y</mi></mrow></mrow><mo>′</mo></msup></math></span>.</p>
<p id="Par12">To satisfy the imposed power constraint <em>P</em>, the masked semantic information <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq27"><math id="d33e892"><msup><mrow><mrow><mi mathvariant="bold-italic">y</mi></mrow></mrow><mo>′</mo></msup></math></span> must be power normalized before transmission, formulated as follows:</p>
<table class="disp-formula p" id="Equ4"><tr>
<td class="formula"><math id="d33e907" display="block"><mrow><mtable><mtr><mtd columnalign="right"><mrow><mover accent="true"><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo stretchy="false">~</mo></mover><mo>=</mo><msqrt><mrow><mi mathvariant="italic">kP</mi></mrow></msqrt><mo>×</mo><mfrac><msup><mrow><mrow><mi mathvariant="bold-italic">y</mi></mrow></mrow><mo>′</mo></msup><mrow><msup><mrow><mrow><mi mathvariant="bold-italic">y</mi></mrow></mrow><mrow><mo>′</mo><mrow></mrow><mo>∗</mo></mrow></msup><msup><mrow><mrow><mi mathvariant="bold-italic">y</mi></mrow></mrow><mo>′</mo></msup></mrow></mfrac><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">4</td>
</tr></table>
<p>where k is the number of semantic symbols to be transmitted, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq28"><math id="d33e956"><msup><mrow><mrow><mi mathvariant="bold-italic">y</mi></mrow></mrow><mrow><mo>′</mo><mrow></mrow><mo>∗</mo></mrow></msup></math></span> represents the complex conjugate of <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq29"><math id="d33e973"><msup><mrow><mrow><mi mathvariant="bold-italic">y</mi></mrow></mrow><mo>′</mo></msup></math></span>.</p>
<p id="Par13">During transmission over physical channels, these semantic features are corrupted by stochastic noise to emulating the semantic interference encountered in practical communication scenarios. In this work, we consider the widely-used additive white Gaussian noise (AWGN) channel, whose transfer function can be expressed as:</p>
<table class="disp-formula p" id="Equ5"><tr>
<td class="formula"><math id="d33e990" display="block"><mrow><mtable><mtr><mtd columnalign="right"><mrow><msup><mover accent="true"><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo stretchy="false">~</mo></mover><mo>′</mo></msup><mo>=</mo><mi>h</mi><mfenced close=")" open="("><mover accent="true"><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo stretchy="false">~</mo></mover><mo>,</mo><mi>ε</mi><mo>,</mo><mi>γ</mi></mfenced><mo>=</mo><mover accent="true"><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo stretchy="false">~</mo></mover><mo>+</mo><mi>n</mi><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">5</td>
</tr></table>
<p>where <em>n</em> is zero-mean complex Gaussian noise with variance <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq30"><math id="d33e1037"><msup><mi>σ</mi><mn>2</mn></msup></math></span>, i.e., <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq31"><math id="d33e1048"><mrow><mi>n</mi><mo>∼</mo><mi mathvariant="double-struck">C</mi><mi mathvariant="double-struck">N</mi><mfenced close=")" open="("><mn>0</mn><mo>,</mo><msup><mi>σ</mi><mn>2</mn></msup></mfenced></mrow></math></span>.</p>
<p id="Par14">Building on the preceding steps, we apply zero-padding to the received semantic information <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq32"><math id="d33e1071"><msup><mover accent="true"><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo stretchy="false">~</mo></mover><mo>′</mo></msup></math></span> transmitted through the wireless channel. This ensures that only the semantic symbols selected for transmission are affected by interference, while the rest retain zero values. Similar to the SC process, an identical mask tensor <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq33"><math id="d33e1087"><mrow><mrow><mi mathvariant="bold-italic">ρ</mi></mrow><mo>∈</mo><msup><mfenced close="}" open="{"><mn>0</mn><mo>,</mo><mn>1</mn></mfenced><mi>k</mi></msup></mrow></math></span> is first produced based on the input CBR <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq34"><math id="d33e1106"><mi>γ</mi></math></span>. The detailed operation can be mathematically expressed as:</p>
<table class="disp-formula p" id="Equ6"><tr>
<td class="formula"><math id="d33e1116" display="block"><mrow><mtable><mtr><mtd columnalign="right"><mrow><mover accent="true"><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo stretchy="false">^</mo></mover><mo>=</mo><msup><mover accent="true"><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo stretchy="false">~</mo></mover><mo>′</mo></msup><mo>·</mo><mrow><mi mathvariant="bold-italic">ρ</mi></mrow><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">6</td>
</tr></table>
<p>Finally, the semantic decoder <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq35"><math id="d33e1149"><msub><mi>D</mi><mi>φ</mi></msub></math></span> at the receiver reconstructs the original data based on the semantic information <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq36"><math id="d33e1161"><mover accent="true"><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo stretchy="false">^</mo></mover></math></span>. The decoded output <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq37"><math id="d33e1175"><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover></math></span> can be formulated as:</p>
<table class="disp-formula p" id="Equ7"><tr>
<td class="formula"><math id="d33e1190" display="block"><mrow><mtable><mtr><mtd columnalign="right"><mrow><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover><mo>=</mo><msub><mi>D</mi><mi>φ</mi></msub><mfenced close=")" open="("><mover accent="true"><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo stretchy="false">^</mo></mover><mo>,</mo><mi>ε</mi><mo>,</mo><mi>γ</mi></mfenced><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">7</td>
</tr></table>
<p>Within the STARJSCC semantic communication model described above, the channel SNR serves as a critical factor influencing image semantic reconstruction, typically governed by the noise power. The SNR <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq38"><math id="d33e1225"><mi>ε</mi></math></span> is mathematically defined as:</p>
<table class="disp-formula p" id="Equ8"><tr>
<td class="formula"><math id="d33e1235" display="block"><mrow><mtable><mtr><mtd columnalign="right"><mrow><mi>ε</mi><mo>=</mo><mn>10</mn><msub><mo>log</mo><mn>10</mn></msub><mfrac><mi>P</mi><msup><mi>σ</mi><mn>2</mn></msup></mfrac><mrow><mo stretchy="false">(</mo><mi>d</mi><mi>B</mi><mo stretchy="false">)</mo></mrow><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">8</td>
</tr></table>
<p>We employ a loss function <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq39"><math id="d33e1267"><mi mathvariant="script">L</mi></math></span> to jointly optimize the parameters of the encoder <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq40"><math id="d33e1278"><msub><mi>E</mi><mi>θ</mi></msub></math></span> and decoder <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq41"><math id="d33e1289"><msub><mi>D</mi><mi>φ</mi></msub></math></span>. This loss function is defined as the sum of mean squared errors (MSE) between the original information and the reconstructed outputs, expressed as follows:</p>
<table class="disp-formula p" id="Equ9"><tr>
<td class="formula"><math id="d33e1301" display="block"><mrow><mtable><mtr><mtd columnalign="right"><mrow><msub><mi mathvariant="script">L</mi><mrow><mi>θ</mi><mo>,</mo><mi>φ</mi></mrow></msub><mfenced close=")" open="("><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo>,</mo><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover></mfenced><mo>=</mo><mi>d</mi><mfenced close=")" open="("><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo>,</mo><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover></mfenced><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mn>0</mn></mrow><mi>N</mi></munderover><msup><mfenced close="∥" open="∥"><msub><mrow><mi mathvariant="bold-italic">x</mi></mrow><mi>i</mi></msub><mo>-</mo><msub><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover><mi>i</mi></msub></mfenced><mn>2</mn></msup><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">9</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq42"><math id="d33e1372"><mrow><mi>d</mi><mfenced close=")" open="("><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo>,</mo><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover></mfenced></mrow></math></span> denotes the MSE between the input image and the reconstructed image, and <em>N</em> represents the dimensionality of the images <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq43"><math id="d33e1396"><msub><mrow><mi mathvariant="bold-italic">x</mi></mrow><mi>i</mi></msub></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq44"><math id="d33e1410"><msub><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover><mi>i</mi></msub></math></span>.</p>
<p id="Par15">The objective of our training process is to minimize the loss function <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq45"><math id="d33e1428"><mi mathvariant="script">L</mi></math></span>. By iteratively applying the backpropagation algorithm, the encoder parameters <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq46"><math id="d33e1438"><mi>θ</mi></math></span> and decoder parameters <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq47"><math id="d33e1447"><mi>φ</mi></math></span> are gradually updated so that the loss value tends to its global minimum:</p>
<table class="disp-formula p" id="Equ10"><tr>
<td class="formula"><math id="d33e1457" display="block"><mrow><mtable><mtr><mtd columnalign="right"><mrow><mfenced close=")" open="("><mmultiscripts><mi>θ</mi><mrow></mrow><mrow><mrow></mrow><mo>∗</mo></mrow></mmultiscripts><mo>,</mo><mmultiscripts><mi>φ</mi><mrow></mrow><mrow><mrow></mrow><mo>∗</mo></mrow></mmultiscripts></mfenced><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>i</mi><mi>n</mi><msub><mi mathvariant="double-struck">E</mi><mrow><mi>θ</mi><mo>,</mo><mi>ε</mi><mo>,</mo><mi>γ</mi></mrow></msub><mfenced close="]" open="["><msub><mi mathvariant="script">L</mi><mrow><mi>θ</mi><mo>,</mo><mi>φ</mi></mrow></msub><mfenced close=")" open="("><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo>,</mo><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover><mo>,</mo><mi>ε</mi><mo>,</mo><mi>γ</mi></mfenced></mfenced><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">10</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq48"><math id="d33e1524"><mmultiscripts><mi>θ</mi><mrow></mrow><mrow><mrow></mrow><mo>∗</mo></mrow></mmultiscripts></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq49"><math id="d33e1539"><mmultiscripts><mi>φ</mi><mrow></mrow><mrow><mrow></mrow><mo>∗</mo></mrow></mmultiscripts></math></span> denote the optimal encoder and decoder parameters, respectively. During the training of a deep neural network, the network parameters are progressively refined until the loss value stabilizes and ceases to decrease significantly, at which point the neural network attains a convergent state.</p></section><section id="Sec4"><h3 class="pmc_sec_title">The overall architecture of STARJSCC</h3>
<p id="Par16">Figure <a href="#Fig2" class="usa-link">2</a> delineates the overall architecture of the proposed STARJSCC for wireless image transmission. Within the joint encoder-decoder of this architecture, the Star Blocks and CSA Mod serve as the pivotal components driving its functionality.</p>
<figure class="fig xbox font-sm" id="Fig2"><h4 class="obj_head">Fig. 2.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375764_41598_2025_16753_Fig2_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b56f/12375764/239efd74b21f/41598_2025_16753_Fig2_HTML.jpg" loading="lazy" id="MO2" height="400" width="735" alt="Fig. 2"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>The overall architecture design of our STARJSCC for wireless image transmission.</p></figcaption></figure><p id="Par17">The encoder takes an RGB image <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq50"><math id="d33e1569"><mrow><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><mi>H</mi><mo>×</mo><mi>W</mi><mo>×</mo><mn>3</mn></mrow></msup></mrow></math></span> as input. Initially, the image is processed through a convolutional (Conv) layer with <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq51"><math id="d33e1592"><mrow><mi>k</mi><mi>e</mi><mi>r</mi><mi>n</mi><mi>e</mi><mi>l</mi><mi>_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>=</mo><mn>9</mn></mrow></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq52"><math id="d33e1615"><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo>=</mo><mn>2</mn></mrow></math></span> to extract hierarchical features and downsample. This operation reduces the spatial resolution of the input to <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq53"><math id="d33e1632"><mrow><mfrac><mi>H</mi><mn>2</mn></mfrac><mo>×</mo><mfrac><mi>W</mi><mn>2</mn></mfrac><mo>×</mo><msub><mi>C</mi><mn>1</mn></msub></mrow></math></span>, where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq54"><math id="d33e1652"><msub><mi>C</mi><mn>1</mn></msub></math></span> denotes the number of output channels after the Conv layer. Subsequently, the semantic features of input image are further learned through <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq55"><math id="d33e1664"><msub><mi>n</mi><mn>1</mn></msub></math></span> successive Star Blocks, during which the dimensionality of it remains unchanged. Finally, the CSA Mod integrates the learned semantic features with the channel state via attention mechanism, adaptively recalibrating the weight distribution to achieve channel state adaptation. The aforementioned steps are collectively referred to as Stage 1. The encoding process comprises three stages, where the operations of Stages 2 and Stage 3 are similar to Stage 1, except that the Conv layer is replaced with a Down Sample layer. At each stage, the spatial resolution of the input is progressively reduced to lower computational complexity and facilitate the extraction of higher-level semantic features.</p>
<p id="Par18">Following three stages of deep semantic feature extraction and learning, the CSC <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq56"><math id="d33e1677"><mrow><mi mathvariant="bold-italic">y</mi></mrow></math></span> of input image is obtained. Prior to transmission over the wireless channel, the SC masking operation and power normalization procedure described in the preceding subsection are applied to <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq57"><math id="d33e1688"><mrow><mi mathvariant="bold-italic">y</mi></mrow></math></span> to achieve transmission rate control. Finally, the received semantic information <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq58"><math id="d33e1699"><msup><mover accent="true"><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo stretchy="false">~</mo></mover><mo>′</mo></msup></math></span>, transmitted over the wireless channel, is subjected to zero padding to obtain the decoder’s input <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq59"><math id="d33e1715"><mover accent="true"><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo stretchy="false">^</mo></mover></math></span>.</p>
<p id="Par19">The decoder adopts a symmetrical design to the encoder, with the objective of analyzing and learning the received semantic information. Through a series of feature processing and reconstruction operations, it ultimately outputs a reconstructed image <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq60"><math id="d33e1731"><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover></math></span> with dimensions <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq61"><math id="d33e1745"><mrow><mi>H</mi><mo>×</mo><mi>W</mi><mo>×</mo><mn>3</mn></mrow></math></span>, which should closely approximate the original input image <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq62"><math id="d33e1759"><mrow><mi mathvariant="bold-italic">x</mi></mrow></math></span>. Corresponding to the Down Sampling layers in the encoder, the decoder employs Up Sampling layers to progressively restore the spatial resolution of the image. Ultimately, a transposed convolutional (Trans Conv) layer transforms the semantic features into the reconstructed image.</p>
<p id="Par20">In this paper, we adopt Star Blocks as the primary semantic feature extraction module. As illustrated in Fig. <a href="#Fig3" class="usa-link">3</a>a, each Star Block consists of two depthwise convolution (DW-Conv) layers and three fully connected (FC) layers. For normalization, we employ generalized divisive normalization (GDN)<sup><a href="#CR29" class="usa-link" aria-describedby="CR29">29</a></sup>, which is better suited for image reconstruction tasks. Regarding the activation function, the parametric rectified linear unit (PReLU)<sup><a href="#CR30" class="usa-link" aria-describedby="CR30">30</a></sup>, which is commonly adopted in the DEEPJSCC framework and its variants, is considered. The two branches within the Star Block leverage element-wise multiplication (i.e., star operation) to fuse semantic features. This design not only enhances the efficiency of the model in extracting image semantic features but also strengthens its representational capacity for latent semantic features. This is because the star operation enables high-dimensional, nonlinear semantic feature mapping while circumventing the limitations of traditional approaches, which typically require a substantial increase in network width or computational overhead<sup><a href="#CR28" class="usa-link" aria-describedby="CR28">28</a></sup>. Additionally, the Down Sample modules used in the Stage 2 and Stage 3 of the encoder, as well as the corresponding Up Sample modules in the decoder, are illustrated in Fig. <a href="#Fig3" class="usa-link">3</a>b and c, respectively. The Down Sample module consists of a convolutional layer with <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq63"><math id="d33e1791"><mrow><mi>k</mi><mi>e</mi><mi>r</mi><mi>n</mi><mi>e</mi><mi>l</mi><mi>_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>=</mo><mn>5</mn></mrow></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq64"><math id="d33e1814"><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo>=</mo><mn>2</mn></mrow></math></span>, followed by a GDN layer. The Up Sampling module comprises a transposed convolutional layer with <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq65"><math id="d33e1831"><mrow><mi>k</mi><mi>e</mi><mi>r</mi><mi>n</mi><mi>e</mi><mi>l</mi><mi>_</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>=</mo><mn>5</mn></mrow></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq66"><math id="d33e1854"><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo>=</mo><mn>2</mn></mrow></math></span>, followed by an IGDN (Inverse GDN) layer.</p>
<figure class="fig xbox font-sm" id="Fig3"><h4 class="obj_head">Fig. 3.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375764_41598_2025_16753_Fig3_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b56f/12375764/d1749a508770/41598_2025_16753_Fig3_HTML.jpg" loading="lazy" id="MO3" height="488" width="620" alt="Fig. 3"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>(<strong>a</strong>) A fundamental Star Block. (<strong>b</strong>) Down Sample module used in the encoder. (<strong>c</strong>) Up Sample module used in the decoder.</p></figcaption></figure><p id="Par21">In summary, the proposed model employs a symmetrical encoder-decoder architecture that integrates Conv layer, Trans Conv layer, Star Blocks, CSA Mod, Down Sample and Up Sample operations. This design enables effective extraction, encoding, and decoding of semantic features during wireless channel transmission, thereby achieving efficient image communication and high-fidelity reconstruction.</p></section><section id="Sec5"><h3 class="pmc_sec_title">Proposed channel state adaptive module</h3>
<p id="Par22">Constructing a model capable of adapting to diverse channel environments without requiring fine-tuning to achieve efficient image semantic transmission remains a significant challenge in the domain of semantic communication. To optimize transmission quality and reconstruction fidelity, a critical plug-in module is proposed in our work, namely CSA Mod. By leveraging accurate modeling and prediction of input SNR, the CSA Mod dynamically adjusts its parameters and configurations in real time. This optimizes its adaptation to varying channel conditions, ensuring efficient and stable semantic transmission.</p>
<p id="Par23">In ADJSCC<sup><a href="#CR19" class="usa-link" aria-describedby="CR19">19</a></sup> and DEEPJSCC-V<sup><a href="#CR22" class="usa-link" aria-describedby="CR22">22</a></sup>, the traditional SE channel attention mechanism is employed to achieve SNR adaptation. However, it relies on FC layers to extract global features while lacking effective interaction and fusion with local information, resulting in suboptimal weights allocation for features critical to semantic reconstruction. Inspired by Ref<sup><a href="#CR31" class="usa-link" aria-describedby="CR31">31</a></sup>., we introduce the CSA Mod, which is designed based on dynamic fine-grained attention. This module efficiently integrates global and local features and optimizes weight assignment to extract more discriminative image features, thereby providing precise feature representations for image semantic reconstruction. The design is illustrated in Fig. <a href="#Fig4" class="usa-link">4</a>. The CSA Mod leverages a correlation matrix to capture interdependencies between global and local semantic information to facilitating their interaction and enabling more effective allocation of feature weights. Additionally, by incorporating channel SNR as a reference factor for attention weight updates through an auxiliary network, the model learns diverse channel states, which in turn improves the robustness of the entire semantic communication system.</p>
<figure class="fig xbox font-sm" id="Fig4"><h4 class="obj_head">Fig. 4.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375764_41598_2025_16753_Fig4_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b56f/12375764/d24829a4f8c9/41598_2025_16753_Fig4_HTML.jpg" loading="lazy" id="MO4" height="318" width="668" alt="Fig. 4"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig4/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Network structure of the proposed CSA Mod.</p></figcaption></figure><p id="Par24">The fundamental principle of the CSA Mod is to enable multi-scale feature interaction and adaptive channel attention allocation through global-local contrastive modeling, which in turn strengthens the expressive capability of semantic features. The implementation workflow is described in detail as follows:</p>
<ol class="list" style="list-style-type:decimal">
<li><div class="p" id="Par26">Global aggregation: Given an input semantic feature <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq67"><math id="d33e1928"><mrow><mi>S</mi><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><mi>H</mi><mo>×</mo><mi>W</mi><mo>×</mo><mi>C</mi></mrow></msup></mrow></math></span>, a global feature vector <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq68"><math id="d33e1949"><mrow><mi>F</mi><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><mi>C</mi><mo>×</mo><mn>1</mn><mo>×</mo><mn>1</mn></mrow></msup></mrow></math></span> is generated via global average pooling (GAP) operation. The <em>n</em>-th channel element of <em>F</em> denoted as <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq69"><math id="d33e1976"><msub><mi>F</mi><mi>n</mi></msub></math></span> can be expressed as: <table class="disp-formula p" id="Equ11"><tr>
<td class="formula"><math id="d33e1989" display="block"><mrow><mtable><mtr><mtd columnalign="right"><mrow><msub><mi>F</mi><mi>n</mi></msub><mo>=</mo><mi>G</mi><mi>A</mi><mi>P</mi><mfenced close=")" open="("><msub><mi>S</mi><mi>n</mi></msub></mfenced><mo>=</mo><mfrac><mn>1</mn><mrow><mi>H</mi><mo>×</mo><mi>W</mi></mrow></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>H</mi></munderover><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>W</mi></munderover><msub><mi>S</mi><mi>n</mi></msub><mfenced close=")" open="("><mi>i</mi><mo>,</mo><mi>j</mi></mfenced><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">11</td>
</tr></table> where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq70"><math id="d33e2043"><mrow><msub><mi>S</mi><mi>n</mi></msub><mfenced close=")" open="("><mi>i</mi><mo>,</mo><mi>j</mi></mfenced></mrow></math></span> is the value of the <em>n</em>-th channel feature map at position <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq71"><math id="d33e2062"><mfenced close=")" open="("><mi>i</mi><mo>,</mo><mi>j</mi></mfenced></math></span>, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq72"><math id="d33e2074"><mrow><mi>G</mi><mi>A</mi><mi>P</mi><mfenced close=")" open="("><msub><mi>S</mi><mi>n</mi></msub></mfenced></mrow></math></span> represents the global average pooling function, defined as: <table class="disp-formula p" id="Equ12"><tr>
<td class="formula"><math id="d33e2091" display="block"><mrow><mtable><mtr><mtd columnalign="right"><mrow><mi>G</mi><mi>A</mi><mi>P</mi><mfenced close=")" open="("><mi>x</mi></mfenced><mo>=</mo><mfrac><mn>1</mn><mrow><mi>H</mi><mo>×</mo><mi>W</mi></mrow></mfrac><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>H</mi></munderover><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mi>W</mi></munderover><mi>x</mi><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><mi>C</mi><mo>×</mo><mn>1</mn><mo>×</mo><mn>1</mn></mrow></msup><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">12</td>
</tr></table>
</div></li>
<li><div class="p" id="Par27">Feature decomposition: The feature <em>F</em> is decomposed into <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq73"><math id="d33e2151"><msub><mi>F</mi><mrow><mi mathvariant="italic">gc</mi></mrow></msub></math></span> (global contrastive features) and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq74"><math id="d33e2164"><msub><mi>F</mi><mrow><mi mathvariant="italic">lc</mi></mrow></msub></math></span> (local contrastive features), preserving global and local semantic information, respectively. The diag and band operations are then employed to extract global and local semantic features, enabling explicit modeling of multi-scale contextual dependencies. As follows: In order to capture local channel information while ensure a small number of model parameters, a band matrix <em>B</em> is employed for localized channel interaction. Let <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq75"><math id="d33e2180"><mrow><mi>B</mi><mo>=</mo><mo stretchy="false">[</mo><msub><mi>b</mi><mn>1</mn></msub><mo>,</mo><msub><mi>b</mi><mn>2</mn></msub><mo>,</mo><msub><mi>b</mi><mn>3</mn></msub><mo>,</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>,</mo><msub><mi>b</mi><mi>k</mi></msub><mo stretchy="false">]</mo></mrow></math></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq76"><math id="d33e2218"><msub><mi>F</mi><mrow><mi mathvariant="italic">lc</mi></mrow></msub></math></span> is given by <table class="disp-formula p" id="Equ13"><tr>
<td class="formula"><math id="d33e2232" display="block"><mrow><mtable><mtr><mtd columnalign="right"><mrow><msub><mi>F</mi><mrow><mi mathvariant="italic">lc</mi></mrow></msub><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>k</mi></munderover><mi>F</mi><mo>·</mo><msub><mi>b</mi><mi>i</mi></msub><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">13</td>
</tr></table> where <em>k</em> represents the number of adjacent channel numbers. To capture global channel information and enhance the model’s representational capacity for global contexts, a diagonal matrix <em>D</em> is introduced to precisely characterize the interdependencies among all channels, thereby enabling effective extraction of global features. Let <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq77"><math id="d33e2270"><mrow><mi>D</mi><mo>=</mo><mo stretchy="false">[</mo><msub><mi>d</mi><mn>1</mn></msub><mo>,</mo><msub><mi>d</mi><mn>2</mn></msub><mo>,</mo><msub><mi>d</mi><mn>3</mn></msub><mo>,</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>.</mo><mo>,</mo><msub><mi>d</mi><mi>k</mi></msub><mo stretchy="false">]</mo></mrow></math></span>, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq78"><math id="d33e2307"><msub><mi>F</mi><mrow><mi mathvariant="italic">gc</mi></mrow></msub></math></span> is given by <table class="disp-formula p" id="Equ14"><tr>
<td class="formula"><math id="d33e2322" display="block"><mrow><mtable><mtr><mtd columnalign="right"><mrow><msub><mi>F</mi><mrow><mi mathvariant="italic">gc</mi></mrow></msub><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>c</mi></munderover><mi>F</mi><mo>·</mo><msub><mi>d</mi><mi>i</mi></msub><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">14</td>
</tr></table> where <em>c</em> denotes the number of channels.</div></li>
<li><div class="p" id="Par28">Transposed mutual interaction: The global contrastive feature <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq79"><math id="d33e2362"><msub><mi>F</mi><mrow><mi mathvariant="italic">gc</mi></mrow></msub></math></span> and local contrastive feature <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq80"><math id="d33e2375"><msub><mi>F</mi><mrow><mi mathvariant="italic">lc</mi></mrow></msub></math></span> are multiplied with the transposed counterparts of each other (<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq81"><math id="d33e2388"><msubsup><mi>F</mi><mrow><mi mathvariant="italic">gc</mi></mrow><mi>T</mi></msubsup></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq82"><math id="d33e2402"><msubsup><mi>F</mi><mrow><mi mathvariant="italic">lc</mi></mrow><mi>T</mi></msubsup></math></span>), respectively, to generate two distinct contrastive feature matrices. This operation strengthens the interaction between global and local features by explicitly modeling their cross-dimensional dependencies. The cross-correlation operation is employed to capture correlations across varying granularities between global and local information, formulated as follows: <table class="disp-formula p" id="Equ15"><tr>
<td class="formula"><math id="d33e2417" display="block"><mrow><mtable><mtr><mtd columnalign="right"><mrow><mi>Q</mi><mo>=</mo><msub><mi>F</mi><mrow><mi mathvariant="italic">gc</mi></mrow></msub><mo>·</mo><msubsup><mi>F</mi><mrow><mi mathvariant="italic">lc</mi></mrow><mi>T</mi></msubsup><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">15</td>
</tr></table> where <em>Q</em> denotes the correlation matrix.</div></li>
<li><div class="p" id="Par29">Feature integration and control: Row-wise summation is performed on the two contrastive feature matrices, generating two sets of weight vectors. A learnable factor <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq83"><math id="d33e2454"><mi>η</mi></math></span> and the Sigmoid function are employed to adjust the relative importance of them, followed by a weighted fusion to produce the integrated channel weight <em>W</em>. Additionally, an auxiliary network is introduced to extract SNR information as a reference term for weight adjustment. Considering the model complexity, this network comprises two FC layers and activation function. The extracted SNR is fused with the channel weight <em>W</em> via an attention-based fusion operation, enabling the model to learn and adapt to wireless channel conditions, ultimately yielding the refined attention weight factor <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq84"><math id="d33e2469"><mmultiscripts><mi>W</mi><mrow></mrow><mrow><mrow></mrow><mo>∗</mo></mrow></mmultiscripts></math></span>. The detailed procedure is outlined as follows: <table class="disp-formula p" id="Equ16"><tr>
<td class="formula"><math id="d33e2484" display="block"><mrow><mtable><mtr><mtd></mtd><mtd columnalign="left"><mrow><msubsup><mi>F</mi><mrow><mi mathvariant="italic">gc</mi></mrow><mi>ω</mi></msubsup><mo>=</mo><munderover><mo>∑</mo><mrow><mi>j</mi></mrow><mi>c</mi></munderover><msub><mi>Q</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>,</mo><mi>i</mi><mo>∈</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>3</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>c</mi><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">16a</td>
</tr></table>
<table class="disp-formula p" id="Equ17"><tr>
<td class="formula"><math id="d33e2530" display="block"><mrow><mtable><mtr><mtd></mtd><mtd columnalign="left"><mrow><msubsup><mi>F</mi><mrow><mi mathvariant="italic">lc</mi></mrow><mi>ω</mi></msubsup><mo>=</mo><munderover><mo>∑</mo><mrow><mi>j</mi></mrow><mi>c</mi></munderover><msub><mfenced close=")" open="("><msub><mi>F</mi><mrow><mi mathvariant="italic">lc</mi></mrow></msub><mo>·</mo><msubsup><mi>F</mi><mrow><mi mathvariant="italic">gc</mi></mrow><mi>T</mi></msubsup></mfenced><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>=</mo><munderover><mo>∑</mo><mrow><mi>j</mi></mrow><mi>c</mi></munderover><msubsup><mi>Q</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mi>T</mi></msubsup><mo>,</mo><mi>i</mi><mo>∈</mo><mn>1</mn><mo>,</mo><mn>2</mn><mo>,</mo><mn>3</mn><mo>,</mo><mo>⋯</mo><mo>,</mo><mi>c</mi><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">16b</td>
</tr></table>
<table class="disp-formula p" id="Equ18"><tr>
<td class="formula"><math id="d33e2602" display="block"><mrow><mtable><mtr><mtd></mtd><mtd columnalign="left"><mrow><mi>W</mi><mo>=</mo><mi>σ</mi><mfenced close=")" open="("><mi>σ</mi><mfenced close=")" open="("><mi>η</mi></mfenced><mo>×</mo><mi>σ</mi><mfenced close=")" open="("><msubsup><mi>F</mi><mrow><mi mathvariant="italic">gc</mi></mrow><mi>ω</mi></msubsup></mfenced><mo>+</mo><mfenced close=")" open="("><mn>1</mn><mo>-</mo><mi>σ</mi><mfenced close=")" open="("><mi>η</mi></mfenced></mfenced><mo>×</mo><mi>σ</mi><mfenced close=")" open="("><msubsup><mi>F</mi><mrow><mi mathvariant="italic">lc</mi></mrow><mi>ω</mi></msubsup></mfenced></mfenced><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">16c</td>
</tr></table>
<table class="disp-formula p" id="Equ19"><tr>
<td class="formula"><math id="d33e2649" display="block"><mrow><mtable><mtr><mtd></mtd><mtd columnalign="left"><mrow><mmultiscripts><mi>W</mi><mrow></mrow><mrow><mrow></mrow><mo>∗</mo></mrow></mmultiscripts><mo>=</mo><msup><mrow><mi mathvariant="script">F</mi></mrow><mrow><mn>1</mn><mo>×</mo><mn>1</mn></mrow></msup><mfenced close=")" open="("><mi>W</mi><mo>,</mo><mi>ε</mi></mfenced></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">16d</td>
</tr></table> where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq85"><math id="d33e2682"><msubsup><mi>F</mi><mrow><mi mathvariant="italic">gc</mi></mrow><mi>ω</mi></msubsup></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq86"><math id="d33e2696"><msubsup><mi>F</mi><mrow><mi mathvariant="italic">lc</mi></mrow><mi>ω</mi></msubsup></math></span> denote the fused global and local channel weights, respectively, <em>c</em> represents the number of channels, and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq87"><math id="d33e2713"><msup><mrow><mi mathvariant="script">F</mi></mrow><mrow><mn>1</mn><mo>×</mo><mn>1</mn></mrow></msup></math></span> corresponds to the 1<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq88"><math id="d33e2730"><mo>×</mo></math></span>1 convolutional operation.</div></li>
<li><div class="p" id="Par30">Feature recalibration: The final weight vector is multiplied with the original semantic feature to get output semantic feature <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq89"><math id="d33e2744"><mmultiscripts><mi>S</mi><mrow></mrow><mrow><mrow></mrow><mo>∗</mo></mrow></mmultiscripts></math></span>. As follows: <table class="disp-formula p" id="Equ20"><tr>
<td class="formula"><math id="d33e2759" display="block"><mrow><mtable><mtr><mtd columnalign="right"><mrow><mmultiscripts><mi>S</mi><mrow></mrow><mrow><mrow></mrow><mo>∗</mo></mrow></mmultiscripts><mo>=</mo><mmultiscripts><mi>W</mi><mrow></mrow><mrow><mrow></mrow><mo>∗</mo></mrow></mmultiscripts><mo>⊗</mo><mi>S</mi><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">17</td>
</tr></table>
</div></li>
</ol></section><section id="Sec6"><h3 class="pmc_sec_title">Training methodology</h3>
<p id="Par31">In the preceding sections, we presented the overall architecture of the wireless image transmission system, the data transmission pipeline of STARJSCC, and the adopted solutions. To validate the effectiveness of the proposed methodology, a carefully designed training scheme is required to derive the STARJSCC model. The training process is outlined as follows:</p>
<p id="Par32">At the macro level, the system model takes dataset samples as input, with the final outputs being the optimized model parameters <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq90"><math id="d33e2794"><mmultiscripts><mi>θ</mi><mrow></mrow><mrow><mrow></mrow><mo>∗</mo></mrow></mmultiscripts></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq91"><math id="d33e2808"><mmultiscripts><mi>φ</mi><mrow></mrow><mrow><mrow></mrow><mo>∗</mo></mrow></mmultiscripts></math></span>, enabling the model to autonomously learn the joint source-channel encoding process. Specifically, the model parameters <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq92"><math id="d33e2822"><mi>θ</mi></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq93"><math id="d33e2831"><mi>φ</mi></math></span> are initialized, and the dataset is loaded. Iterative training is then conducted across multiple epochs.</p>
<p id="Par33">During each training batch, the input data is firstly partitioned into <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq94"><math id="d33e2842"><mrow><mrow><msub><mi mathvariant="bold-italic">X</mi><mi mathvariant="bold-italic">b</mi></msub></mrow><mo>=</mo><mo stretchy="false">[</mo><msub><mrow><mi mathvariant="bold-italic">x</mi></mrow><mn>1</mn></msub><mo>,</mo><msub><mrow><mi mathvariant="bold-italic">x</mi></mrow><mn>2</mn></msub><mo>,</mo><msub><mrow><mi mathvariant="bold-italic">x</mi></mrow><mn>3</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><msub><mrow><mi mathvariant="bold-italic">x</mi></mrow><mi>b</mi></msub><mo stretchy="false">]</mo></mrow></math></span>. After that, the CBR <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq95"><math id="d33e2888"><mi>γ</mi></math></span> and the SNR <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq96"><math id="d33e2897"><mi>ϵ</mi></math></span> are randomly generated from the range [1/20, 1/4] and [0, 25] dB, respectively. This stochastic training strategy ensures the model adapts to varying channel states and different CBR values through decoupled attention mechanism and static SC masking scheme. The encoder <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq97"><math id="d33e2906"><msub><mi>E</mi><mi>θ</mi></msub></math></span> encodes <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq98"><math id="d33e2917"><msub><mi>X</mi><mi>b</mi></msub></math></span> using <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq99"><math id="d33e2929"><mi>γ</mi></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq100"><math id="d33e2938"><mi>ϵ</mi></math></span> to get CSC <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq101"><math id="d33e2947"><mrow><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo>=</mo><mo stretchy="false">[</mo><msub><mrow><mi mathvariant="bold-italic">y</mi></mrow><mn>1</mn></msub><mo>,</mo><msub><mrow><mi mathvariant="bold-italic">y</mi></mrow><mn>2</mn></msub><mo>,</mo><msub><mrow><mi mathvariant="bold-italic">y</mi></mrow><mn>3</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><msub><mrow><mi mathvariant="bold-italic">y</mi></mrow><mi>b</mi></msub><mo stretchy="false">]</mo></mrow></math></span>, and then the masked semantic information <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq102"><math id="d33e2990"><msup><mrow><mrow><mi mathvariant="bold-italic">y</mi></mrow></mrow><mo>′</mo></msup></math></span> is generated by Eq. (<a href="#Equ2" class="usa-link">2</a>) and Eq. (<a href="#Equ3" class="usa-link">3</a>). Finally, the decoder <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq103"><math id="d33e3011"><msub><mi>D</mi><mi>φ</mi></msub></math></span> decodes the noise-corrupted semantic information <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq104"><math id="d33e3022"><mrow><mover accent="true"><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo stretchy="false">^</mo></mover><mo>=</mo><mrow><mo stretchy="false">[</mo><msub><mover accent="true"><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo stretchy="false">^</mo></mover><mn>1</mn></msub><mo>,</mo><msub><mover accent="true"><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo stretchy="false">^</mo></mover><mn>2</mn></msub><mo>,</mo><msub><mover accent="true"><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo stretchy="false">^</mo></mover><mn>3</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><msub><mover accent="true"><mrow><mi mathvariant="bold-italic">y</mi></mrow><mo stretchy="false">^</mo></mover><mi>b</mi></msub><mo stretchy="false">]</mo></mrow></mrow></math></span>, which is transmitted over the wireless channel, into the reconstructed data <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq105"><math id="d33e3080"><mrow><mover accent="true"><mrow><mi mathvariant="bold-italic">X</mi></mrow><mo stretchy="false">^</mo></mover><mo>=</mo><mrow><mo stretchy="false">[</mo><msub><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover><mn>1</mn></msub><mo>,</mo><msub><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover><mn>2</mn></msub><mo>,</mo><msub><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover><mn>3</mn></msub><mo>,</mo><mo>⋯</mo><mo>,</mo><msub><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover><mi>b</mi></msub><mo stretchy="false">]</mo></mrow></mrow></math></span>.</p>
<p id="Par34">Prior to concluding each training batch, the MSE loss <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq106"><math id="d33e3140"><mrow><msub><mi mathvariant="script">L</mi><mi>i</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msup><mfenced close="∥" open="∥"><msub><mrow><mi mathvariant="bold-italic">x</mi></mrow><mi>i</mi></msub><mo>-</mo><msub><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover><mi>i</mi></msub></mfenced><mn>2</mn></msup></mrow></math></span> is computed for each sample, and the epoch-averaged loss <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq107"><math id="d33e3174"><mrow><mi mathvariant="script">L</mi><mo>=</mo><mfrac><mn>1</mn><mi>b</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi></mrow><mi>b</mi></msubsup><msub><mi mathvariant="script">L</mi><mi>i</mi></msub></mrow></math></span> is derived. The gradient information from <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq108"><math id="d33e3198"><mi mathvariant="script">L</mi></math></span> is utilized to update the model parameters <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq109"><math id="d33e3208"><mi>θ</mi></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq110"><math id="d33e3217"><mi>φ</mi></math></span> via backpropagation. In the end, the complete training procedure is summarized in Algorithm 1.</p>
<figure class="fig xbox font-sm" id="Figa"><h4 class="obj_head">Algorithm 1.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375764_41598_2025_16753_Figa_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b56f/12375764/8baabd4a63a7/41598_2025_16753_Figa_HTML.jpg" loading="lazy" id="MO5" height="296" width="669" alt="Algorithm 1"></a></p>
<div class="p text-right font-secondary"><a href="figure/Figa/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Training Process for the STARJSCC</p></figcaption></figure></section></section><section id="Sec7"><h2 class="pmc_sec_title">Experimental results</h2>
<p id="Par36">In this section, we first provide a comprehensive description of the simulation experimental configuration. Subsequently, we present the results of the simulation experiments, which aim to validate the effectiveness and robustness of our STARJSCC model in executing transmission tasks under diverse channel conditions. Furthermore, ablation study is conducted to investigate the impact of different block designs on the experimental outcomes. Finally, a comparative analysis is carried out between the ADJSCC, DEEPJSCC-V, and our STARJSCC models, focusing on critical metrics such as model parameters and storage requirements.</p>
<section id="Sec8"><h3 class="pmc_sec_title">Experimental setup</h3>
<section id="Sec9"><h4 class="pmc_sec_title">Dataset selection</h4>
<p id="Par37">In our simulation experiments, two datasets with distinct resolutions are considered. For the low-resolution images, the CIFAR10 dataset<sup><a href="#CR32" class="usa-link" aria-describedby="CR32">32</a></sup> is employed, which comprises 32<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq111"><math id="d33e3250"><mo>×</mo></math></span>32-pixel color images spanning 10 different categories with a total of 60,000 images. These images are partitioned into 50,000 training images and 10,000 test images. Since the focus of our study is on communication tasks, category labels are usually ignored during the experiments. The training set is used for model optimization, while the test set serve to evaluate model performance. For high-resolution images, the DIV2K dataset<sup><a href="#CR33" class="usa-link" aria-describedby="CR33">33</a></sup> is adopted, containing 900 images, each exceeding 2000<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq112"><math id="d33e3263"><mo>×</mo></math></span>1000 pixels. As for the testing phase, the Kodak dataset<sup><a href="#CR34" class="usa-link" aria-describedby="CR34">34</a></sup> which includes 24 color images of 768<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq113"><math id="d33e3277"><mo>×</mo></math></span>512 pixels and CLIC2020 testset<sup><a href="#CR35" class="usa-link" aria-describedby="CR35">35</a></sup> with approximate 2 K resolution images are selected to assess the model’s performance on high-resolution images. This dataset selection strategy ensures a comprehensive evaluation of the proposed model’s performance and robustness across varying image resolutions in transmission tasks.</p></section><section id="Sec10"><h4 class="pmc_sec_title">Metrics</h4>
<p id="Par38">To comprehensively evaluate the end-to-end semantic transmission performance of the proposed STARJSCC model against comparable methods, we employed two well-established evaluation metrics: the pixel-level measurement, peak signal-to-noise ratio (PSNR); and the perception-oriented assessment, structural similarity index (SSIM)<sup><a href="#CR36" class="usa-link" aria-describedby="CR36">36</a></sup>.</p>
<p id="Par39">For PSNR, defined as the ratio of the peak signal power to the mean noise power, it is formulated as follows:</p>
<table class="disp-formula p" id="Equ21"><tr>
<td class="formula"><math id="d33e3301" display="block"><mrow><mtable><mtr><mtd columnalign="right"><mrow><mi>P</mi><mi>S</mi><mi>N</mi><mi>R</mi><mo>=</mo><mn>10</mn><msub><mo>log</mo><mn>10</mn></msub><mfrac><mrow><mi>M</mi><mi>A</mi><msup><mi>X</mi><mn>2</mn></msup></mrow><mrow><mi mathvariant="italic">MSE</mi></mrow></mfrac><mfenced close=")" open="("><mi>d</mi><mi>B</mi></mfenced><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">18</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq114"><math id="d33e3337"><mrow><mi>M</mi><mi>S</mi><mi>E</mi><mo>=</mo><mi>d</mi><mo stretchy="false">(</mo><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo>,</mo><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover><mo stretchy="false">)</mo></mrow></math></span> represents the mean squared error between the input image <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq115"><math id="d33e3365"><mrow><mi mathvariant="bold-italic">x</mi></mrow></math></span> and the reconstructed image <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq116"><math id="d33e3376"><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover></math></span>, and <em>MAX</em> denotes the maximum possible pixel value. All experiments were conducted on 24-bit-depth RGB images, where each color channel (red, green, blue) is allocated 8 bits. Consequently, <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq117"><math id="d33e3394"><mrow><mi>M</mi><mi>A</mi><mi>X</mi><mo>=</mo><msup><mn>2</mn><mn>8</mn></msup><mo>-</mo><mn>1</mn><mo>=</mo><mn>255</mn></mrow></math></span>.</p>
<p id="Par40">SSIM is computed as follows:</p>
<table class="disp-formula p" id="Equ22"><tr>
<td class="formula"><math id="d33e3417" display="block"><mrow><mtable><mtr><mtd columnalign="right"><mrow><mi>S</mi><mi>S</mi><mi>I</mi><mi>M</mi><mfenced close=")" open="("><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo>,</mo><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover></mfenced><mo>=</mo><mfrac><mrow><mfenced close=")" open="("><mn>2</mn><msub><mi>μ</mi><mrow><mi mathvariant="bold-italic">x</mi></mrow></msub><msub><mi>μ</mi><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover></msub><mo>+</mo><msub><mi>c</mi><mn>1</mn></msub></mfenced><mfenced close=")" open="("><mn>2</mn><msub><mi>σ</mi><mrow><mrow><mi mathvariant="bold-italic">x</mi></mrow><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover></mrow></msub><mo>+</mo><msub><mi>c</mi><mn>2</mn></msub></mfenced></mrow><mrow><mfenced close=")" open="("><msubsup><mi>μ</mi><mrow><mrow><mi mathvariant="bold-italic">x</mi></mrow></mrow><mn>2</mn></msubsup><mo>+</mo><msubsup><mi>μ</mi><mrow><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover></mrow><mn>2</mn></msubsup><mo>+</mo><msub><mi>c</mi><mn>1</mn></msub></mfenced><mfenced close=")" open="("><msubsup><mi>σ</mi><mrow><mrow><mi mathvariant="bold-italic">x</mi></mrow></mrow><mn>2</mn></msubsup><mo>+</mo><msubsup><mi>σ</mi><mrow><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover></mrow><mn>2</mn></msubsup><mo>+</mo><msub><mi>c</mi><mn>2</mn></msub></mfenced></mrow></mfrac><mo>,</mo></mrow></mtd></mtr></mtable></mrow></math></td>
<td class="label">19</td>
</tr></table>
<p>where <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq118"><math id="d33e3533"><msub><mi>μ</mi><mrow><mi mathvariant="bold-italic">x</mi></mrow></msub></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq119"><math id="d33e3546"><msub><mi>μ</mi><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover></msub></math></span> represent the mean values of the original image <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq120"><math id="d33e3562"><mrow><mi mathvariant="bold-italic">x</mi></mrow></math></span> and the reconstructed image <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq121"><math id="d33e3573"><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover></math></span>, respectively. <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq122"><math id="d33e3588"><msubsup><mi>σ</mi><mrow><mrow><mi mathvariant="bold-italic">x</mi></mrow></mrow><mn>2</mn></msubsup></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq123"><math id="d33e3603"><msubsup><mi>σ</mi><mrow><mover accent="true"><mrow><mi mathvariant="bold-italic">x</mi></mrow><mo stretchy="false">^</mo></mover></mrow><mn>2</mn></msubsup></math></span> denote the variances of the original and reconstructed images, quantifying their intensity distributions. The constants <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq124"><math id="d33e3621"><msub><mi>c</mi><mn>1</mn></msub></math></span> and <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq125"><math id="d33e3632"><msub><mi>c</mi><mn>2</mn></msub></math></span> are stabilization terms introduced to prevent division by near-zero values, ensuring numerical stability during computation.</p></section><section id="Sec11"><h4 class="pmc_sec_title">Training details</h4>
<p id="Par41">The Adam optimizer<sup><a href="#CR37" class="usa-link" aria-describedby="CR37">37</a></sup> is employed to update model parameters, where the weight decay and learning rate are set to <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq126"><math id="d33e3651"><mrow><mn>5</mn><mo>×</mo><msup><mn>10</mn><mrow><mo>-</mo><mn>4</mn></mrow></msup></mrow></math></span>. During the training process, a StepLR scheduler is employed to dynamically adjust the learning rate, thereby mitigating the risk of convergence to local optima. The scheduler configuration utilize a step size of 100 epochs and a multiplicative factor of 0.5. This implementation reduces the learning rate by 50% at every 100-epoch interval, with the maximum training duration set to 400 epochs. After each epoch, validation is performed with gradient updates disabled to evaluate the model’s performance on the validation set.</p>
<p id="Par42">For training on the CIFAR10 dataset, the batch size is set to 64. For the DIV2K dataset, due to its higher demands on GPU memory and computational resources, the batch size is reduced to 4. Additionally, these images are resized to 256<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq127"><math id="d33e3669"><mo>×</mo></math></span>256 pixels during training to facilitate model optimization. This configuration aims to balance training efficiency and model performance, ensuring optimal training outcomes across datasets of varying resolutions. To maintain architectural consistency, both high and low resolution images are processed using a three-stage STARJSCC scheme with parameters <span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq128"><math id="d33e3678"><mrow><mrow><mo stretchy="false">[</mo><msub><mi>n</mi><mn>1</mn></msub><mo>,</mo><msub><mi>n</mi><mn>2</mn></msub><mo>,</mo><msub><mi>n</mi><mn>3</mn></msub><mo stretchy="false">]</mo></mrow><mo>=</mo><mrow><mo stretchy="false">[</mo><mn>2</mn><mo stretchy="false">]</mo></mrow><mo>,</mo><mrow><mo stretchy="false">[</mo><mn>3</mn><mo stretchy="false">]</mo></mrow><mo>,</mo><mrow><mo stretchy="false">[</mo><mn>6</mn><mo stretchy="false">]</mo></mrow></mrow></math></span>. All experiments were conducted on a Linux system utilizing the PyTorch framework and a single NVIDIA RTX 3060 GPU.</p></section></section><section id="Sec12"><h3 class="pmc_sec_title">Results analysis</h3>
<p id="Par43">The proposed STARJSCC scheme is compared with the ADJSCC and DEEPJSCC-V methods. To mitigate the impact of stochastic channel noise on experimental results during performance evaluation, 10 transmission trials are conducted for each image, and the average PSNR and SSIM values are computed. This approach not only facilitates the acquisition of stable performance metrics but also ensures the reliability and comparability of the experimental outcomes.</p>
<section id="Sec13"><h4 class="pmc_sec_title">Low-resolution experimental results</h4>
<p id="Par44">The proposed STARJSCC model is comprehensively evaluated under AWGN channel conditions, and its performance is rigorously analyzed through comparative experiments across varying SNR levels. Figure <a href="#Fig5" class="usa-link">5</a> presents a performance comparison of the CIFAR10 dataset under AWGN channel conditions across varying SNR levels. Specifically, Fig. <a href="#Fig5" class="usa-link">5</a>a illustrates the PSNR performance of the proposed STARJSCC model against ADJSCC and DEEPJSCC-V at CBR = 1/12 and CBR = 1/6. It is evident that the STARJSCC model outperforms DEEPJSCC-V under both CBR settings. Compared to ADJSCC, the proposed model demonstrates comparable or superior adaptability to channel states. Notably, although STARJSCC does not surpass ADJSCC at low SNR levels, it achieves significant reductions in model complexity (detailed analysis is provided later). Furthermore, STARJSCC can adapt to different CBR values in a single model, a capability absent in ADJSCC. Figure <a href="#Fig5" class="usa-link">5</a>b depicts the SSIM performance comparison under the same conditions. The SSIM results exhibit a trend consistent with Figure <a href="#Fig5" class="usa-link">5</a>a, the better channel conditions, the more obvious performance advantage of STARJSCC becomes.</p>
<figure class="fig xbox font-sm" id="Fig5"><h5 class="obj_head">Fig. 5.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375764_41598_2025_16753_Fig5_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b56f/12375764/1fdfe675c1d8/41598_2025_16753_Fig5_HTML.jpg" loading="lazy" id="MO6" height="285" width="704" alt="Fig. 5"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig5/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>(<strong>a</strong>) PSNR performance curves versus the SNR over AWGN channel. (<strong>b</strong>) SSIM performance curves versus the SNR over AWGN channel. Where the CBR = 1/12 and 1/6 for CIFAR10 dataset.</p></figcaption></figure><p id="Par45">Figure <a href="#Fig6" class="usa-link">6</a> illustrates the performance comparison of the CIFAR10 test set under AWGN channel conditions across varying CBR. The proposed STARJSCC and DEEPJSCC-V models are evaluated and compared at SNR levels of 1 dB, 4 dB, and 10 dB to assess their adaptability and robustness to different CBR conditions. The results demonstrate that the proposed model significantly outperforms DEEPJSCC-V in terms of both PSNR and SSIM under most conditions, while maintaining comparable performance even under extremely adverse channel scenarios.</p>
<figure class="fig xbox font-sm" id="Fig6"><h5 class="obj_head">Fig. 6.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375764_41598_2025_16753_Fig6_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b56f/12375764/83dea4ed93dc/41598_2025_16753_Fig6_HTML.jpg" loading="lazy" id="MO7" height="285" width="710" alt="Fig. 6"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig6/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>(<strong>a</strong>) PSNR performance curves versus the CBR over AWGN channel. (<strong>b</strong>) SSIM performance curves versus the CBR over AWGN channel. Where the SNR = 1dB, 4dB and 10dB for CIFAR10 dataset.</p></figcaption></figure></section><section id="Sec14"><h4 class="pmc_sec_title">High-resolution experimental results</h4>
<p id="Par46">To further validate the superiority of the proposed STARJSCC model in high-resolution semantic transmission, additional tests are conducted using the Kodak and CLIC2020 dataset. For high-resolution images, inputs are preprocessed by cropping to 512<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq129"><math id="d33e3781"><mo>×</mo></math></span>512 pixels, with other experimental settings consistent with the low-resolution tests. Figure <a href="#Fig7" class="usa-link">7</a> presents the performance comparison of the Kodak and CLIC2020 dataset under AWGN channel conditions across varying SNR levels. The results demonstrate that the STARJSCC scheme exhibits even more pronounced advantages in high-resolution image transmission. Specifically, Fig. <a href="#Fig7" class="usa-link">7</a>a and b illustrates the high-resolution PSNR performance of STARJSCC against ADJSCC and DEEPJSCC-V at CBR = 1/12 and 1/6. The proposed STARJSCC outperforms both DEEPJSCC-V and ADJSCC, with the performance gap widening as SNR increases, reaching a maximum advantage of 2.73 dB. Figure <a href="#Fig7" class="usa-link">7</a>c and d compares the high-resolution SSIM performance under the same settings. The STARJSCC model consistently achieves higher SSIM values than ADJSCC and DEEPJSCC-V, with a maximum SSIM gain of 0.01577 over DEEPJSCC-V. At CBR = 1/12, STARJSCC demonstrates significant SSIM advantages at lower SNR levels, though this margin diminishes as SNR increases. This phenomenon arises because semantic feature loss becomes more pronounced at lower CBR, inherently limiting the achievable reconstruction fidelity. Conversely, STARJSCC maintains substantial performance gains across all SNR levels at CBR = 1/6, with improvements becoming increasingly prominent as SNR rises.</p>
<figure class="fig xbox font-sm" id="Fig7"><h5 class="obj_head">Fig. 7.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375764_41598_2025_16753_Fig7_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b56f/12375764/717188398d1e/41598_2025_16753_Fig7_HTML.jpg" loading="lazy" id="MO8" height="595" width="710" alt="Fig. 7"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig7/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>(<strong>a</strong>)-(<strong>b</strong>) PSNR performance curves versus the SNR over AWGN channel. (<strong>c</strong>)-(<strong>d</strong>) SSIM performance curves versus the SNR over AWGN channel. Where the CBR = 1/12 and 1/6 for Kodak and CLIC2020 dataset.</p></figcaption></figure><p id="Par47">Figure <a href="#Fig8" class="usa-link">8</a> illustrates the performance comparison of the Kodak and CLIC2020 dataset under AWGN channel conditions across varying CBR conditions. Similar to the low-resolution test results, the proposed model exhibits strong adaptability under diverse CBR constraints, consistently outperforming DEEPJSCC-V across three distinct SNR levels. Specifically, for PSNR, the performance advantage of STARJSCC becomes increasingly pronounced as CBR increases, achieving a maximum performance gap of 2.15 dB. For SSIM, the highest improvement reaches 0.02267 under SNR = 1 dB.</p>
<figure class="fig xbox font-sm" id="Fig8"><h5 class="obj_head">Fig. 8.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375764_41598_2025_16753_Fig8_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b56f/12375764/659b2928c150/41598_2025_16753_Fig8_HTML.jpg" loading="lazy" id="MO9" height="595" width="717" alt="Fig. 8"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig8/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>(<strong>a</strong>)-(<strong>b</strong>) PSNR performance curves versus the CBR over AWGN channel. (<strong>c</strong>)-(<strong>d</strong>) SSIM performance curves versus the CBR over AWGN channel. Where the SNR = 1dB, 4dB and 10dB for Kodak and CLIC2020 dataset.</p></figcaption></figure><p id="Par48">In summary, compared to the low-resolution dataset evaluations, the proposed scheme demonstrates even more substantial improvements in high-resolution testing scenarios. This underscores the superior capability of STARJSCC in high-resolution image semantic transmission tasks relative to other models. This phenomenon arises because STARJSCC’s hybrid attention architecture effectively integrates both local and global information, enhancing the model’s capacity to capture fine-grained semantic features. This architectural strength enables exceptional performance on high-resolution images where abundant structural details exist. In contrast, the inherent loss of finer object boundaries and texture variations in low-resolution images fundamentally limits the full exploitation of STARJSCC’s advantages.</p></section></section><section id="Sec15"><h3 class="pmc_sec_title">Ablation study</h3>
<section id="Sec16"><h4 class="pmc_sec_title">Study on block design</h4>
<p id="Par49">In order to investigate the impact of different Star Block designs on the performance of STARJSCC system, an ablation study is conducted to analyze their architectural variations. Subsequently, we also compare Star Block with standard MobileNet block and EfficientNet-style bottleneck under the same training configurations to justify its use. The four distinct Star Block variants (Block I, Block II, Block III, Block IV) are designed, as illustrated in Fig. <a href="#Fig9" class="usa-link">9</a>, and tested within the STARJSCC framework. Table <a href="#Tab1" class="usa-link">1</a> presents the performance metrics of these variants under CBR = 1/12 and SNR = 9 dB, where the Storage metric indicates the storage overhead of models trained with each respective module.</p>
<figure class="fig xbox font-sm" id="Fig9"><h5 class="obj_head">Fig. 9.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375764_41598_2025_16753_Fig9_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b56f/12375764/19e87bdf0098/41598_2025_16753_Fig9_HTML.jpg" loading="lazy" id="MO10" height="280" width="790" alt="Fig. 9"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig9/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Four distinct Star Block variants are designed, with being Block I adopted as the standard configuration in the proposed STARJSCC framework.</p></figcaption></figure><section class="tw xbox font-sm" id="Tab1"><h5 class="obj_head">Table 1.</h5>
<div class="caption p"><p>Performance comparison of different block variants under CBR = 1/12 and SNR = 9 dB, tested on the Kodak dataset.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Design</th>
<th align="left" colspan="1" rowspan="1">PSNR</th>
<th align="left" colspan="1" rowspan="1">SSIM</th>
<th align="left" colspan="1" rowspan="1">Storage</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Block I</td>
<td align="left" colspan="1" rowspan="1">30.97dB</td>
<td align="left" colspan="1" rowspan="1">0.93680</td>
<td align="left" colspan="1" rowspan="1">22.7MB</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Block II</td>
<td align="left" colspan="1" rowspan="1">30.87dB</td>
<td align="left" colspan="1" rowspan="1">0.93519</td>
<td align="left" colspan="1" rowspan="1">30.3MB</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Block III</td>
<td align="left" colspan="1" rowspan="1">30.78dB</td>
<td align="left" colspan="1" rowspan="1">0.93590</td>
<td align="left" colspan="1" rowspan="1">29.2MB</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Block IV</td>
<td align="left" colspan="1" rowspan="1">30.83dB</td>
<td align="left" colspan="1" rowspan="1">0.93654</td>
<td align="left" colspan="1" rowspan="1">29.2MB</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">MobileNetV2 Block</td>
<td align="left" colspan="1" rowspan="1">30.51dB</td>
<td align="left" colspan="1" rowspan="1">0.93381</td>
<td align="left" colspan="1" rowspan="1">33.9MB</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">EfficientNet Block</td>
<td align="left" colspan="1" rowspan="1">30.23dB</td>
<td align="left" colspan="1" rowspan="1">0.93065</td>
<td align="left" colspan="1" rowspan="1">23.0MB</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab1/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section><p id="Par50">The experimental results demonstrate that models based on Star Block and its variants outperform those using standard MobileNet block and EfficientNet-style bottleneck, justifying the selection of Star Block as the fundamental module for STARJSCC. Among these, Block I achieves the best performance in terms of both PSNR and SSIM, followed by Block II and Block IV, while Block III shows slightly inferior results. Notably, the model trained with Block I exhibits significantly lower storage overhead compared to the other three variants. This substantial reduction in storage requirements, combined with its superior performance, further validates Block I as the optimal design choice for our system.</p></section><section id="Sec17"><h4 class="pmc_sec_title">Study on attention mechanism</h4>
<p id="Par51">Generally, the principle of the attention mechanism lies in minimizing the loss by adjusting the model’s focus on different image regions. In STARJSCC, we introduce the CSA mechanism to adapt to varying channel conditions, thereby improving the model’s semantic preservation and transmission capabilities. To understand the impact mechanism of the CSA Mod on semantic features during transmission, we focus on the scaling coefficients it generates. Specifically, we conduct 10 transmissions for images from the Kodak dataset at 5 different SNR values and compute the average of the scaling coefficients produced by the CSA Mod. The detailed distributions are illustrated in Fig. <a href="#Fig10" class="usa-link">10</a>. We extract the scaling coefficients from the first 48 channels of the first and second CSA Nod in the encoder and visualize their distributions using heatmaps. The results show that after processing by the first CSA Mod, the scaling coefficients exhibit a distinct “stratification” phenomenon, indicating that they still retain noticeable variations at different SNR values. However, after refinement by the second CSA Mod, the differences in scaling coefficients at different SNRs diminish and become nearly identical. This trend aligns with the analysis in Ref<sup><a href="#CR19" class="usa-link" aria-describedby="CR19">19</a></sup>., suggesting that channel noise has a more pronounced impact on low-level features than on high-level features.</p>
<figure class="fig xbox font-sm" id="Fig10"><h5 class="obj_head">Fig. 10.</h5>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375764_41598_2025_16753_Fig10_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b56f/12375764/feb2d6427d0c/41598_2025_16753_Fig10_HTML.jpg" loading="lazy" id="MO11" height="203" width="668" alt="Fig. 10"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig10/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>The scaling coefficients of the first 48 channels in the encoder of STARJSCC on AWGN channel (CBR = 1/12). (<strong>a</strong>) the scaling coefficients of the first CSA Mod. (<strong>b</strong>) the scaling coefficients of the second CSA Mod. The scaling coefficients of each channel are evaluated on the Kodak dataset.</p></figcaption></figure><p id="Par52">Furthermore, to validate the effectiveness of the proposed CSA mechanism, we conduct comparative experiments with standard attention mechanisms including SE and Convolutional Block Attention Module (CBAM), and investigate the impact of SNR input on the attention module’s performance. Specifically, under the same training configurations, we evaluate different attention mechanisms within the STARJSCC framework for wireless image transmission, with the corresponding performance results summarized in Table <a href="#Tab2" class="usa-link">2</a>. For ease of understanding, we refer to the attention modules without SNR input as CSA_wo_SNR, SE_wo_SNR, and CBAM_wo_SNR, while those with SNR input are denoted as CSA+SNR, SE+SNR and CBAM+SNR. The results of Table <a href="#Tab2" class="usa-link">2</a> demonstrate that our proposed CSA attention mechanism achieves the highest PSNR and SSIM values regardless of SNR input incorporation. Moreover, by embedding SNR into the CSA module, our approach achieves performance improvements of 0.26 dB and 0.00213 in PSNR and SSIM, respectively.</p>
<section class="tw xbox font-sm" id="Tab2"><h5 class="obj_head">Table 2.</h5>
<div class="caption p"><p>The PSNR and SSIM comparison of different attention mechanism under CBR = 1/6 and SNR = 13 dB, tested on the Kodak dataset.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead><tr>
<th align="left" colspan="1" rowspan="1">Attention</th>
<th align="left" colspan="1" rowspan="1">PSNR</th>
<th align="left" colspan="1" rowspan="1">SSIM</th>
</tr></thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">CSA+SNR</td>
<td align="left" colspan="1" rowspan="1">35.00dB</td>
<td align="left" colspan="1" rowspan="1">0.97173</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">SE+SNR</td>
<td align="left" colspan="1" rowspan="1">33.91dB</td>
<td align="left" colspan="1" rowspan="1">0.96579</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">CBAM+SNR</td>
<td align="left" colspan="1" rowspan="1">34.39dB</td>
<td align="left" colspan="1" rowspan="1">0.96847</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">CSA_wo_SNR</td>
<td align="left" colspan="1" rowspan="1">34.74dB</td>
<td align="left" colspan="1" rowspan="1">0.96960</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">SE_wo_SNR</td>
<td align="left" colspan="1" rowspan="1">34.15dB</td>
<td align="left" colspan="1" rowspan="1">0.96766</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">CBAM_wo_SNR</td>
<td align="left" colspan="1" rowspan="1">34.26dB</td>
<td align="left" colspan="1" rowspan="1">0.96397</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab2/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section></section><section id="Sec18"><h3 class="pmc_sec_title">Analysis of model parameters, computational complexity, storage requirements, and inference time</h3>
<p id="Par53">Under the conditions of CBR=1/6, we further evaluate the model parameters, storage requirements, FLOPs, and inference time of conventional BPG + LDPC, ADJSCC, DEEPJSCC-V, SwinJSCC_Base, MambaJSCC and STARJSCC on the Kodak dataset. Notably, metrics such as parameters and storage overhead are independent of input image dimensions, as they solely depend on the model architecture. During testing, kodim02 image is preprocessed by resizing to 256<span xmlns:mml="http://www.w3.org/1998/Math/MathML" id="IEq130"><math id="d33e4039"><mo>×</mo></math></span>256 pixels before being fed into the model. We transmit it 10 times and take the average as the final inference time result.</p>
<p id="Par54">As shown in Table <a href="#Tab3" class="usa-link">3</a>, the proposed STARJSCC scheme demonstrates significant advantages in FLOPs, parameters, and storage overhead. Specifically, STARJSCC demonstrates significantly faster inference time compared to the BPG+LDPC scheme. In terms of both FLOPs and parameters, STARJSCC achieves reductions of 30.83% and 52.78% compared to MambaJSCC and ADJSCC respectively. Furthermore, the storage cost of STARJSCC is only 59.90% of ADJSCC and 49.03% of DEEPJSCC-V. These improvements stem from its lightweight backbone network design, which replaces standard convolutions with DW-Convs and employs the star operation to fuse features from dual-branch structures, thereby improving the efficiency of semantic feature modeling. Although our model does not hold an advantage over other JSCC schemes, its outstanding advantages in computational efficiency, parameter reduction and storage economy make it particularly suitable for resource-constrained deployment scenarios, demonstrating significant practical value.</p>
<section class="tw xbox font-sm" id="Tab3"><h4 class="obj_head">Table 3.</h4>
<div class="caption p"><p>Comparison of inference time, FLOPs, parameters, and storage requirements across different codec schemes.</p></div>
<div class="tbl-box p" tabindex="0"><table class="content" frame="hsides" rules="groups">
<thead>
<tr>
<th align="left" rowspan="2" colspan="1">Scheme</th>
<th align="left" colspan="2" rowspan="1">Inference</th>
<th align="left" rowspan="2" colspan="1">FLOPs</th>
<th align="left" rowspan="2" colspan="1">Parameters</th>
<th align="left" rowspan="2" colspan="1">Storage</th>
</tr>
<tr>
<th align="left" colspan="1" rowspan="1">Encoder</th>
<th align="left" colspan="1" rowspan="1">Decoder</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">BPG + LDPC</td>
<td align="left" colspan="1" rowspan="1">&gt; 670ms</td>
<td align="left" colspan="1" rowspan="1">&gt; 7.3s</td>
<td align="left" colspan="1" rowspan="1">-</td>
<td align="left" colspan="1" rowspan="1">-</td>
<td align="left" colspan="1" rowspan="1">-</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">ADJSCC</td>
<td align="left" colspan="1" rowspan="1">7.69ms</td>
<td align="left" colspan="1" rowspan="1">6.57ms</td>
<td align="left" colspan="1" rowspan="1">66.3481G</td>
<td align="left" colspan="1" rowspan="1">10.63M</td>
<td align="left" colspan="1" rowspan="1">44.6MB</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">DEEPJSCC-V</td>
<td align="left" colspan="1" rowspan="1">8.63ms</td>
<td align="left" colspan="1" rowspan="1">7.19ms</td>
<td align="left" colspan="1" rowspan="1">68.0260G</td>
<td align="left" colspan="1" rowspan="1">11.05M</td>
<td align="left" colspan="1" rowspan="1">46.3MB</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">SwinJSCC_Base</td>
<td align="left" colspan="1" rowspan="1">25.68ms</td>
<td align="left" colspan="1" rowspan="1">4.35ms</td>
<td align="left" colspan="1" rowspan="1">34.0235G</td>
<td align="left" colspan="1" rowspan="1">33.03M</td>
<td align="left" colspan="1" rowspan="1">145.5MB</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">MambaJSCC</td>
<td align="left" colspan="1" rowspan="1">5.68ms</td>
<td align="left" colspan="1" rowspan="1">6.47ms</td>
<td align="left" colspan="1" rowspan="1">22.6785G</td>
<td align="left" colspan="1" rowspan="1">12.72M</td>
<td align="left" colspan="1" rowspan="1">58.6MB</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">STARJSCC</td>
<td align="left" colspan="1" rowspan="1">34.66ms</td>
<td align="left" colspan="1" rowspan="1">5.92ms</td>
<td align="left" colspan="1" rowspan="1">16.6865G</td>
<td align="left" colspan="1" rowspan="1">5.02M</td>
<td align="left" colspan="1" rowspan="1">22.7MB</td>
</tr>
</tbody>
</table></div>
<div class="p text-right font-secondary"><a href="table/Tab3/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div></section></section><section id="Sec19"><h3 class="pmc_sec_title">Visualization analysis</h3>
<p id="Par56">To further validate the effectiveness of the proposed model, a set of visual comparisons is provided using the kodim21 image from the Kodak dataset. As illustrated in Fig. <a href="#Fig11" class="usa-link">11</a>, the image reconstruction quality of STARJSCC, ADJSCC, and DEEPJSCC-V under AWGN channel conditions is visually compared, demonstrating the robustness and adaptability of the proposed framework. It is important to note that even when the SNR is constant during testing, inherent randomness in channel noise may introduce subtle variations in reconstruction outcomes. From these results, the STARJSCC scheme exhibits significant advantages across all SNR levels. Compared to DEEPJSCC-V, which supports SNR and CBR adaptation, STARJSCC achieves PSNR and SSIM improvements of 4.25 dB and 0.0276, respectively, under SNR = 21 dB. Furthermore, the proposed method effectively mitigates granular artifacts and shadowing distortions, producing reconstructed images with rich details and high fidelity. Consequently, STARJSCC better satisfies human visual perception requirements in semantic communication systems, bring more natural and authentic visual experiences.</p>
<figure class="fig xbox font-sm" id="Fig11"><h4 class="obj_head">Fig. 11.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375764_41598_2025_16753_Fig11_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b56f/12375764/1e790cbdcbe5/41598_2025_16753_Fig11_HTML.jpg" loading="lazy" id="MO12" height="1167" width="714" alt="Fig. 11"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig11/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Visual comparison of STARJSCC, ADJSCC and DEEPJSCC-V under AWGN channel at SNR=1dB, 5dB, 9dB, 15dB and 21dB.</p></figcaption></figure><p id="Par57">In practical semantic communication scenarios, images received after wireless transmission are typically utilized for downstream tasks. To validate the usability of transmitted images in subsequent semantic processing, we conduct object detection task using these images. The evaluation is performed with a Yolov8 network initialized with officially released pre-trained weights.Specifically, we utilize images kodim06, kodim11, kodim20, and kodim23 from the Kodak dataset, along with their semantically transmitted versions (processed through ADJSCC, DEEPJSCC-V, and STARJSCC), as input to YOLOv8 to obtain detection results. The transmission parameters are configured with SNR = 6 dB and CBR = 1/12. The comparative results and performance metrics output by Yolov8 are presented in Fig. <a href="#Fig12" class="usa-link">12</a>. From these results, we observe that the transmitted images of all three models consistently meet the performance standards for object detection. Notably, the transmitted images perform better than the originals in terms of detection success rate in many cases. Furthermore, under conditions with strong background interference (e.g., kodim11), the detection performance of ADJSCC- and STARJSCC-transmitted images is significantly superior to that of both the original images and DEEPJSCC-V-transmitted images. This demonstrates that STARJSCC-transmitted images can be effectively utilized for downstream semantic tasks without compromising accuracy.</p>
<figure class="fig xbox font-sm" id="Fig12"><h4 class="obj_head">Fig. 12.</h4>
<p class="img-box line-height-none margin-x-neg-2 tablet:margin-x-0 text-center"><a class="tileshop" target="_blank" href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=12375764_41598_2025_16753_Fig12_HTML.jpg"><img class="graphic zoom-in" src="https://cdn.ncbi.nlm.nih.gov/pmc/blobs/b56f/12375764/b3803fb0a243/41598_2025_16753_Fig12_HTML.jpg" loading="lazy" id="MO13" height="535" width="669" alt="Fig. 12"></a></p>
<div class="p text-right font-secondary"><a href="figure/Fig12/" class="usa-link" target="_blank" rel="noopener noreferrer">Open in a new tab</a></div>
<figcaption><p>Performance comparison of original and transmitted images in object detection task, where SNR = 6dB and CBR = 1/12 during the transmission. (<strong>a</strong>)-(<strong>d</strong>) show the detection results of original images. (<strong>e</strong>)-(<strong>h</strong>) show the detection results of the images transmitted using ADJSCC. (<strong>i</strong>)-(<strong>l</strong>) show the detection results of the images transmitted using DEEPJSCC-V. (<strong>m</strong>)-(<strong>p</strong>) show the detection results of the images transmitted using STARJSCC.</p></figcaption></figure></section></section><section id="Sec20"><h2 class="pmc_sec_title">Conclusion</h2>
<p id="Par58">This paper proposes STARJSCC, a novel and highly flexible JSCC architecture that demonstrates exceptional adaptability within a single model, dynamically address diverse channel states and CBR conditions. Specifically, we design a star operation-based modulation network for wireless image transmission codec framework, incorporating a plug-in CSA Mod that enables dynamic channel sensing and parameter adjustment while maintaining transmission quality. Extensive experimental results demonstrate that, compared to conventional CNN-based JSCC frameworks, STARJSCC not only significantly reduces model parameters, computational complexity, and storage overhead but also achieves superior image transmission quality. These advancements position STARJSCC as a promising solution for semantic communication systems in resource-constrained wireless scenarios.</p>
<p id="Par59">In future work, we will explore the deep integration of the proposed framework with SOTA architectures such as Transformer and Mamba, with a focus on developing more efficient rate-adaptive compression algorithms and optimizing the model’s transmission efficiency and generalization capabilities. Furthermore, we have verified the model’s compatibility with mainstream deployment tools such as TensorFlow Lite and ONNX Runtime. We will explore STARJSCC’s generalizability in broader semantic communication scenarios (such as IoT device communication and satellite communication) and conduct cross-modal research to extend it to other data transmission types (such as video streams, voice signals and text information). Through the synergistic integration and refinement of these advanced techniques, we aim to lay the groundwork for novel methodologies and solutions in the design and optimization of next-generation wireless communication systems.</p></section><section id="ack1" class="ack"><h2 class="pmc_sec_title">Acknowledgements</h2>
<p>This work was supported in part by National Natural Science Foundation of China under Grant 62361003 and 62261003, the Key Research and Development Program of Guangxi under Grants AD25069071, the Natural Science Foundation of Guangxi under Grant 2025GXNSFAA069672, and in part by the Innovation Project of Guangxi Graduate Education under Grant YCSW2025124.</p></section><section id="notes1"><h2 class="pmc_sec_title">Author contributions</h2>
<p>This paper was co-authored by Xiangcheng Li and Dongri Ban. Xiangcheng Li was mainly responsible for the construction of the research framework and the formulation of research methods, and Dongri Ban took on the tasks of experimental design and data analysis. Zhaokai Ruan and Xiuyu Yue were involved in the research discussions and the verification of results. During the writing stage, Haiqiang Chen and Youming Sun jointly completed the compilation and proofreading of the manuscript. All authors have contributed to the subsequent revisions of the paper.</p></section><section id="notes2"><h2 class="pmc_sec_title">Data availability</h2>
<p>The datasets used and/or analysed during the current study available from the corresponding author on reasonable request.</p></section><section id="notes3"><h2 class="pmc_sec_title">Declarations</h2>
<section id="FPar1"><h3 class="pmc_sec_title">Competing interests</h3>
<p id="Par60">The authors declare no competing interests.</p></section></section><section id="fn-group1" class="fn-group"><h2 class="pmc_sec_title">Footnotes</h2>
<div class="fn-group p font-secondary-light font-sm">
<div class="fn p" id="fn1">
<p><strong>Publisher’s note</strong></p>
<p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
</div>
<div class="fn p" id="fn2"><p>These authors contributed equally to this work: Xiangcheng Li, Dongri Ban and Youming Sun.</p></div>
</div></section><section id="Bib1" class="ref-list"><h2 class="pmc_sec_title">References</h2>
<section id="Bib1_sec2"><ul class="ref-list font-sm" style="list-style-type:none">
<li id="CR1">
<span class="label">1.</span><cite>Qin, Z. et al. Ai empowered wireless communications: From bits to semantics. <em>Proc. IEEE</em><strong>112</strong>, 621–652 (2024).</cite> [<a href="https://scholar.google.com/scholar_lookup?Qin,%20Z.%20et%20al.%20Ai%20empowered%20wireless%20communications:%20From%20bits%20to%20semantics.%20Proc.%20IEEE112,%20621%E2%80%93652%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR2">
<span class="label">2.</span><cite>An, Z., Zhang, T., Xu, Y., Pedersen, G. F. &amp; Shen, M. Multimodality-aided multicarrier waveform recognition in low snr regimes based on denoised cyclic autocorrelation transformation. <em>IEEE Transactions on Aerosp. Electron. Syst.</em><strong>59</strong>, 5859–5875 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?An,%20Z.,%20Zhang,%20T.,%20Xu,%20Y.,%20Pedersen,%20G.%20F.%20&amp;%20Shen,%20M.%20Multimodality-aided%20multicarrier%20waveform%20recognition%20in%20low%20snr%20regimes%20based%20on%20denoised%20cyclic%20autocorrelation%20transformation.%20IEEE%20Transactions%20on%20Aerosp.%20Electron.%20Syst.59,%205859%E2%80%935875%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR3">
<span class="label">3.</span><cite>An, Z. et al. Physics-informed scattering transform network for modulation recognition in 5g industrial cognitive communications considering nonlinear impairments in active phased arrays. <em>IEEE Transactions on Ind. Informatics </em>(2024).</cite>
</li>
<li id="CR4">
<span class="label">4.</span><cite>An, Z. et al. Collaborative learning-based modulation recognition for 6g multibeam satellite communication systems via blind and semi-blind channel equalization. <em>IEEE Transactions on Aerosp. Electron. Syst.</em> (2024).</cite>
</li>
<li id="CR5">
<span class="label">5.</span><cite>Cover, T. M. <em>Elements of information theory</em> (John Wiley &amp; Sons, 1999).</cite>
</li>
<li id="CR6">
<span class="label">6.</span><cite>Weaver, W. Recent contributions to the mathematical theory of communication. <em>ETC: a review of general semantics</em> 261–281 (1953).</cite>
</li>
<li id="CR7">
<span class="label">7.</span><cite>Lu, Z. et al. Semantics-empowered communications: A tutorial-cum-survey. <em>IEEE Commun. Surv. &amp; Tutorials</em><strong>26</strong>, 41–79 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Lu,%20Z.%20et%20al.%20Semantics-empowered%20communications:%20A%20tutorial-cum-survey.%20IEEE%20Commun.%20Surv.%20&amp;%20Tutorials26,%2041%E2%80%9379%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR8">
<span class="label">8.</span><cite>Xu, Y., Xu, G., Liu, Y., Liu, Y. &amp; Shen, M. A survey of the fusion of traditional data security technology and blockchain. <em>Expert. Syst. with Appl.</em> 124151 (2024).</cite>
</li>
<li id="CR9">
<span class="label">9.</span><cite>Marcellin, M. W., Gormish, M. J., Bilgin, A. &amp; Boliek, M. P. An overview of jpeg-2000. In <em>Proceedings DCC 2000. Data compression conference</em>, 523–541 (IEEE, 2000).</cite>
</li>
<li id="CR10">
<span class="label">10.</span><cite>Rabbani, M. &amp; Joshi, R. An overview of the jpeg 2000 still image compression standard. <em>Signal processing: Image communication</em><strong>17</strong>, 3–48 (2002).</cite> [<a href="https://scholar.google.com/scholar_lookup?Rabbani,%20M.%20&amp;%20Joshi,%20R.%20An%20overview%20of%20the%20jpeg%202000%20still%20image%20compression%20standard.%20Signal%20processing:%20Image%20communication17,%203%E2%80%9348%20(2002)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR11">
<span class="label">11.</span><cite>Bellard, F. The bpg image format. <a href="http://bellard.org/bpg/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://bellard.org/bpg/</a> (2014).</cite>
</li>
<li id="CR12">
<span class="label">12.</span><cite>Richardson, T. &amp; Kudekar, S. Design of low-density parity check codes for 5g new radio. <em>IEEE Commun. Mag.</em><strong>56</strong>, 28–34 (2018).</cite> [<a href="https://scholar.google.com/scholar_lookup?Richardson,%20T.%20&amp;%20Kudekar,%20S.%20Design%20of%20low-density%20parity%20check%20codes%20for%205g%20new%20radio.%20IEEE%20Commun.%20Mag.56,%2028%E2%80%9334%20(2018)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR13">
<span class="label">13.</span><cite>Weithoffer, S., Nour, C. A., Wehn, N., Douillard, C. &amp; Berrou, C. 25 years of turbo codes: From mb/s to beyond 100 gb/s. In <em>2018 IEEE 10th international symposium on turbo codes &amp; iterative information processing (ISTC)</em>, 1–6 (IEEE, 2018).</cite>
</li>
<li id="CR14">
<span class="label">14.</span><cite>Li, H. &amp; Yuan, J. A practical construction method for polar codes in awgn channels. In <em>IEEE 2013 Tencon-Spring</em>, 223–226 (IEEE, 2013).</cite>
</li>
<li id="CR15">
<span class="label">15.</span><cite>Farsad, N., Rao, M. &amp; Goldsmith, A. Deep learning for joint source-channel coding of text. In <em>2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)</em>, 2326–2330 (IEEE, 2018).</cite>
</li>
<li id="CR16">
<span class="label">16.</span><cite>Weng, Z. &amp; Qin, Z. Semantic communication systems for speech transmission. <em>IEEE J. on Sel. Areas Commun.</em><strong>39</strong>, 2434–2444 (2021).</cite> [<a href="https://scholar.google.com/scholar_lookup?Weng,%20Z.%20&amp;%20Qin,%20Z.%20Semantic%20communication%20systems%20for%20speech%20transmission.%20IEEE%20J.%20on%20Sel.%20Areas%20Commun.39,%202434%E2%80%932444%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR17">
<span class="label">17.</span><cite>Bourtsoulatze, E., Kurka, D. B. &amp; Gündüz, D. Deep joint source-channel coding for wireless image transmission. <em>IEEE Transactions on Cogn. Commun. Netw.</em><strong>5</strong>, 567–579 (2019).</cite> [<a href="https://scholar.google.com/scholar_lookup?Bourtsoulatze,%20E.,%20Kurka,%20D.%20B.%20&amp;%20G%C3%BCnd%C3%BCz,%20D.%20Deep%20joint%20source-channel%20coding%20for%20wireless%20image%20transmission.%20IEEE%20Transactions%20on%20Cogn.%20Commun.%20Netw.5,%20567%E2%80%93579%20(2019)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR18">
<span class="label">18.</span><cite>Kurka, D. B. &amp; Gündüz, D. Deepjscc-f: Deep joint source-channel coding of images with feedback. <em>IEEE journal on selected areas in information theory</em><strong>1</strong>, 178–193 (2020).</cite> [<a href="https://scholar.google.com/scholar_lookup?Kurka,%20D.%20B.%20&amp;%20G%C3%BCnd%C3%BCz,%20D.%20Deepjscc-f:%20Deep%20joint%20source-channel%20coding%20of%20images%20with%20feedback.%20IEEE%20journal%20on%20selected%20areas%20in%20information%20theory1,%20178%E2%80%93193%20(2020)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR19">
<span class="label">19.</span><cite>Xu, J. et al. Wireless image transmission using deep source channel coding with attention modules. <em>IEEE Transactions on Circuits Syst. for Video Technol.</em><strong>32</strong>, 2315–2328 (2021).</cite> [<a href="https://scholar.google.com/scholar_lookup?Xu,%20J.%20et%20al.%20Wireless%20image%20transmission%20using%20deep%20source%20channel%20coding%20with%20attention%20modules.%20IEEE%20Transactions%20on%20Circuits%20Syst.%20for%20Video%20Technol.32,%202315%E2%80%932328%20(2021)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR20">
<span class="label">20.</span><cite>Yuan, H., Xu, W., Wang, Y. &amp; Wang, X. Channel adaptive dl based joint source-channel coding without a prior knowledge. arXiv preprint <a href="http://arxiv.org/abs/2306.15183" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">arXiv:2306.15183</a> (2023).</cite>
</li>
<li id="CR21">
<span class="label">21.</span><cite>Yang, M. &amp; Kim, H.-S. Deep joint source-channel coding for wireless image transmission with adaptive rate control. In <em>ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 5193–5197 (IEEE, 2022).</cite>
</li>
<li id="CR22">
<span class="label">22.</span><cite>Zhang, W. et al. Predictive and adaptive deep coding for wireless image transmission in semantic communication. <em>IEEE Transactions on Wirel. Commun.</em><strong>22</strong>, 5486–5501 (2023).</cite> [<a href="https://scholar.google.com/scholar_lookup?Zhang,%20W.%20et%20al.%20Predictive%20and%20adaptive%20deep%20coding%20for%20wireless%20image%20transmission%20in%20semantic%20communication.%20IEEE%20Transactions%20on%20Wirel.%20Commun.22,%205486%E2%80%935501%20(2023)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR23">
<span class="label">23.</span><cite>Yang, K. et al. Witt: A wireless image transmission transformer for semantic communications. In <em>ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 1–5 (IEEE, 2023).</cite>
</li>
<li id="CR24">
<span class="label">24.</span><cite>Yang, K. et al. Swinjscc: Taming swin transformer for deep joint source-channel coding. <em>IEEE Transactions on Cogn. Commun. Netw. </em>(2024).</cite>
</li>
<li id="CR25">
<span class="label">25.</span><cite>Peng, X., Qin, Z., Tao, X., Lu, J. &amp; Letaief, K. B. A robust image semantic communication system with multi-scale vision transformer. <em>IEEE J. on Sel. Areas Commun.</em> (2025).</cite>
</li>
<li id="CR26">
<span class="label">26.</span><cite>Wu, T. et al. Mambajscc: Deep joint source-channel coding with visual state space model. In <em>GLOBECOM 2024 - 2024 IEEE Global Communications Conference</em>, 1677–1682 (2024).</cite>
</li>
<li id="CR27">
<span class="label">27.</span><cite>Hu, J., Shen, L. &amp; Sun, G. Squeeze-and-excitation networks. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em>, 7132–7141 (2018).</cite>
</li>
<li id="CR28">
<span class="label">28.</span><cite>Ma, X., Dai, X., Bai, Y., Wang, Y. &amp; Fu, Y. Rewrite the stars. In <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 5694–5703 (2024).</cite>
</li>
<li id="CR29">
<span class="label">29.</span><cite>Ballé, J., Laparra, V. &amp; Simoncelli, E. P. Density modeling of images using a generalized normalization transformation. In <em>4th International Conference on Learning Representations, ICLR 2016</em> (2016).</cite>
</li>
<li id="CR30">
<span class="label">30.</span><cite>He, K., Zhang, X., Ren, S. &amp; Sun, J. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In <em>Proceedings of the IEEE international conference on computer vision</em>, 1026–1034 (2015).</cite>
</li>
<li id="CR31">
<span class="label">31.</span><cite>Sun, H. et al. Unsupervised bidirectional contrastive reconstruction and adaptive fine-grained channel attention networks for image dehazing. <em>Neural Networks</em><strong>176</strong>, 106314 (2024).
</cite> [<a href="https://doi.org/10.1016/j.neunet.2024.106314" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/38669785/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Sun,%20H.%20et%20al.%20Unsupervised%20bidirectional%20contrastive%20reconstruction%20and%20adaptive%20fine-grained%20channel%20attention%20networks%20for%20image%20dehazing.%20Neural%20Networks176,%20106314%20(2024)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR32">
<span class="label">32.</span><cite>Krizhevsky, A., Hinton, G. et al. Learning multiple layers of features from tiny images (2009).</cite>
</li>
<li id="CR33">
<span class="label">33.</span><cite>Agustsson, E. &amp; Timofte, R. Ntire 2017 challenge on single image super-resolution: Dataset and study. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition workshops</em>, 126–135 (2017).</cite>
</li>
<li id="CR34">
<span class="label">34.</span><cite>Kodak photocd dataset. <a href="http://r0k.us/graphics/kodak/" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://r0k.us/graphics/kodak/</a> (2014).</cite>
</li>
<li id="CR35">
<span class="label">35.</span><cite>CLIC 2020: Challenge on learned image compression. <a href="http://compression.cc" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">http://compression.cc</a> (2020).</cite>
</li>
<li id="CR36">
<span class="label">36.</span><cite>Wang, Z., Bovik, A. C., Sheikh, H. R. &amp; Simoncelli, E. P. Image quality assessment: from error visibility to structural similarity. <em>IEEE transactions on image processing</em><strong>13</strong>, 600–612 (2004).
</cite> [<a href="https://doi.org/10.1109/tip.2003.819861" class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">DOI</a>] [<a href="https://pubmed.ncbi.nlm.nih.gov/15376593/" class="usa-link">PubMed</a>] [<a href="https://scholar.google.com/scholar_lookup?Wang,%20Z.,%20Bovik,%20A.%20C.,%20Sheikh,%20H.%20R.%20&amp;%20Simoncelli,%20E.%20P.%20Image%20quality%20assessment:%20from%20error%20visibility%20to%20structural%20similarity.%20IEEE%20transactions%20on%20image%20processing13,%20600%E2%80%93612%20(2004)." class="usa-link usa-link--external" data-ga-action="click_feat_suppl" target="_blank" rel="noopener noreferrer">Google Scholar</a>]</li>
<li id="CR37">
<span class="label">37.</span><cite>Diederik, K. Adam: A method for stochastic optimization (2014).</cite>
</li>
</ul></section></section><section id="_ad93_" lang="en" class="associated-data"><h2 class="pmc_sec_title">Associated Data</h2>
<p class="font-secondary"><em>This section collects any data citations, data availability statements, or supplementary materials included in this article.</em></p>
<section id="_adda93_" lang="en" class="data-availability-statement"><h3 class="pmc_sec_title">Data Availability Statement</h3>
<p>The datasets used and/or analysed during the current study available from the corresponding author on reasonable request.</p></section></section></section><footer class="p courtesy-note font-secondary font-sm text-center"><hr class="headless">
<p>Articles from Scientific Reports are provided here courtesy of <strong>Nature Publishing Group</strong></p></footer></section></article>

                      

                    </main>
                </div>
            </div>
        </div>

        



<!-- Secondary navigation placeholder -->
<div class="pmc-sidenav desktop:grid-col-4 display-flex">
    <section class="pmc-sidenav__container" aria-label="Article resources and navigation">
        <button type="button" class="usa-button pmc-sidenav__container__close usa-button--unstyled">
            <img src="/static/img/usa-icons/close.svg" role="img" alt="Close" />
        </button>
    <div class="display-none desktop:display-block">
       <section class="margin-top-4 desktop:margin-top-0">
              <h2 class="margin-top-0">ACTIONS</h2>
           <ul class="usa-list usa-list--unstyled usa-list--actions">
               
               <li>
                     <a
                             href="https://doi.org/10.1038/s41598-025-16753-4"
                             class="usa-button usa-button--outline width-24 font-xs display-inline-flex flex-align-center flex-justify-start padding-left-1"
                             target="_blank"
                             rel="noreferrer noopener"
                             data-ga-category="actions"
                             data-ga-action="click"
                             data-ga-label="publisher_link_desktop"
                     >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#launch"></use>
                         </svg>
                         <span class="display-inline-flex flex-justify-center flex-1 padding-right-2">View on publisher site</span>
                     </a>
               </li>
               
               
               <li>
                    <a
                            href="pdf/41598_2025_Article_16753.pdf"
                            class="usa-button usa-button--outline width-24 display-inline-flex flex-align-center flex-justify-start padding-left-1"
                            data-ga-category="actions"
                            data-ga-action="click"
                            data-ga-label="pdf_download_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#file_download"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1">PDF (5.2 MB)</span>
                    </a>
               </li>
               
                
               <li>
                   <button role="button" class="usa-button width-24 citation-dialog-trigger display-inline-flex flex-align-center flex-justify-start padding-left-1"
                        aria-label="Open dialog with citation text in different styles"
                        data-ga-category="actions"
                        data-ga-action="open"
                        data-ga-label="cite_desktop"
                        data-all-citations-url="/resources/citations/12375764/"
                        data-citation-style="nlm"
                        data-download-format-link="/resources/citations/12375764/export/"
                    >
                        <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#format_quote"></use>
                        </svg>
                       <span class="display-inline-flex flex-justify-center flex-1 button-label">Cite</span>
                    </button>
               </li>
                
               <li>

                        <button class="usa-button width-24 collections-dialog-trigger collections-button display-inline-flex flex-align-center flex-justify-start padding-left-1 collections-button-empty"
                              aria-label="Save article in MyNCBI collections."
                              data-ga-category="actions"
                              data-ga-action="click"
                              data-ga-label="collections_button_desktop"
                              data-collections-open-dialog-enabled="false"
                              data-collections-open-dialog-url="https://account.ncbi.nlm.nih.gov/?back_url=https%3A%2F%2Fpmc.ncbi.nlm.nih.gov%2Farticles%2FPMC12375764%2F%3Freport%3Dclassic%23open-collections-dialog"
                              data-in-collections="false">
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-full" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-full.svg#icon"></use>
                            </svg>
                            <svg class="usa-icon width-3 height-3 usa-icon--bookmark-empty" aria-hidden="true" focusable="false" role="img" hidden>
                                <use xlink:href="/static/img/action-bookmark-empty.svg#icon"></use>
                            </svg>
                            <span class="display-inline-flex flex-justify-center flex-1">Collections</span>
                       </button>
               </li>
               <li class="pmc-permalink">
                    <button
                            type="button"
                            class="usa-button width-24 display-inline-flex flex-align-center flex-justify padding-left-1 shadow-none"
                            aria-label="Show article permalink"
                            aria-expanded="false"
                            aria-haspopup="true"
                            data-ga-category="actions"
                            data-ga-action="open"
                            data-ga-label="permalink_desktop"
                    >
                         <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img" hidden>
                            <use xlink:href="/static/img/sprite.svg#share"></use>
                        </svg>
                        <span class="display-inline-flex flex-justify-center flex-1 button-label">Permalink</span>
                    </button>
                   

<div class="pmc-permalink__dropdown" hidden>
    <div class="pmc-permalink__dropdown__container">
          <h2 class="usa-modal__heading margin-top-0 margin-bottom-2 text-uppercase font-sans-xs">PERMALINK</h2>
          <div class="pmc-permalink__dropdown__content">
              <input type="text" class="usa-input" value="https://pmc.ncbi.nlm.nih.gov/articles/PMC12375764/" aria-label="Article permalink">
              <button class="usa-button display-inline-flex pmc-permalink__dropdown__copy__btn margin-right-0" title="Copy article permalink" data-ga-category="save_share" data-ga-action="link" data-ga-label="copy_link">
                  <svg class="usa-icon" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#content_copy"></use>
                  </svg>
                  <span class="margin-left-1">Copy</span>
              </button>
          </div>
    </div>
</div>
               </li>
           </ul>
       </section>
     </div>

        <section class="pmc-resources margin-top-6 desktop:margin-top-4" data-page-path="/articles/PMC12375764/">
            <h2 class="margin-top-0">RESOURCES</h2>
            
                <div class="usa-accordion usa-accordion--multiselectable" data-allow-multiple>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-similar-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_similar_articles"
                        data-ga-label="/articles/PMC12375764/"
                        data-action-open="open_similar_articles"
                        data-action-close="close_similar_articles"
                        >
                            Similar articles
                        </button>
                    </h3>
                    <div
                            id="resources-similar-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/similar-article-links/40850988/"
                            
                    >
                        
                    </div>
                    <h3 class="usa-accordion__heading">
                        <button
                        type="button"
                        class="usa-accordion__button"
                        aria-expanded="false"
                        aria-controls="resources-cited-by-other-articles"
                        data-ga-category="resources_accordion"
                        data-ga-action="open_cited_by"
                        data-ga-label="/articles/PMC12375764/"
                        data-action-open="open_cited_by"
                        data-action-close="close_cited_by"
                        >
                             Cited by other articles
                        </button>
                    </h3>
                    <div
                            id="resources-cited-by-other-articles"
                            class="usa-accordion__content usa-prose"
                            
                                data-source-url="/resources/cited-by-links/40850988/"
                            
                    >
                          
                    </div>
                    
                        <h3 class="usa-accordion__heading">
                            <button
                            type="button"
                            class="usa-accordion__button"
                            aria-expanded="false"
                            aria-controls="resources-links-to-ncbi-databases"
                            data-ga-category="resources_accordion"
                            data-ga-action="open_NCBI_links"
                            data-ga-label="/articles/PMC12375764/"
                            data-action-open="open_NCBI_links"
                            data-action-close="close_NCBI_link"
                            >
                                 Links to NCBI Databases
                            </button>
                        </h3>
                        <div
                                id="resources-links-to-ncbi-databases"
                                class="usa-accordion__content usa-prose"
                                data-source-url="/resources/db-links/12375764/"
                        >
                        </div>
                    
                    
                </div>
            
        </section>


        <section
        class="usa-in-page-nav usa-in-page-nav--wide margin-top-6 desktop:margin-top-4"
        data-title-text="On this page"
        data-title-heading-level="h2"
        data-scroll-offset="0"
        data-root-margin="-10% 0px -80% 0px"
        data-main-content-selector="main"
        data-threshold="1"
        hidden
        ></section>
    </section>
</div>


        

<div class="overlay" role="dialog" aria-label="Citation Dialog" hidden>
    <div class="dialog citation-dialog" aria-hidden="true">
        <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
            <h2 class="usa-modal__heading margin-0">Cite</h2>
             <button type="button" class="usa-button usa-button--unstyled close-overlay text-black width-auto"  tabindex="1">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#close"></use>
                </svg>
             </button>
        </div>

        

<div class="citation-text-block">
  <div class="citation-text margin-bottom-2"></div>
  <ul class="usa-list usa-list--unstyled display-inline-flex flex-justify width-full flex-align-center">
      <li>
        <button
          class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center copy-button dialog-focus"
          data-ga-category="save_share"
          data-ga-action="cite"
          data-ga-label="copy"
          tabindex="2">
            <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                <use xlink:href="/static/img/sprite.svg#content_copy"></use>
            </svg>
            <span>Copy</span>
        </button>
      </li>
      <li>
          <a
              href="#"
              role="button"
              class="usa-button usa-button--unstyled text-no-underline display-flex flex-align-center export-button"
              data-ga-category="save_share"
              data-ga-action="cite"
              data-ga-label="download"
              title="Download a file for external citation management software"
              tabindex="3">
                <svg class="usa-icon width-3 height-3" aria-hidden="true" focusable="false" role="img">
                    <use xlink:href="/static/img/sprite.svg#file_download"></use>
                </svg>
                <span class="display-none mobile-lg:display-inline">Download .nbib</span>
                <span class="display-inline mobile-lg:display-none">.nbib</span>
            </a>
      </li>
      <li>
          

<div class="display-inline-flex flex-align-center">
  <label class="usa-label margin-top-0">Format:</label>
  <select aria-label="Format" class="usa-select citation-style-selector padding-1 margin-top-0 border-0 padding-right-4" tabindex="4" >
    
      <option data-style-url-name="ama"
              value="AMA"
              >
        AMA
      </option>
    
      <option data-style-url-name="apa"
              value="APA"
              >
        APA
      </option>
    
      <option data-style-url-name="mla"
              value="MLA"
              >
        MLA
      </option>
    
      <option data-style-url-name="nlm"
              value="NLM"
              selected="selected">
        NLM
      </option>
    
  </select>
</div>
      </li>
  </ul>
</div>
    </div>
</div>

        <div class="overlay" role="dialog" hidden>
  <div id="collections-action-dialog" class="dialog collections-dialog" aria-hidden="true">
   <div class="display-inline-flex flex-align-center flex-justify width-full margin-bottom-2">
        <h2 class="usa-modal__heading margin-0">Add to Collections</h2>
    </div>
    <div class="collections-action-panel action-panel">
      


<form id="collections-action-dialog-form"
      class="usa-form maxw-full collections-action-panel-form action-panel-content action-form action-panel-smaller-selectors"
      data-existing-collections-url="/list-existing-collections/"
      data-add-to-existing-collection-url="/add-to-existing-collection/"
      data-create-and-add-to-new-collection-url="/create-and-add-to-new-collection/"
      data-myncbi-max-collection-name-length="100"
      data-collections-root-url="https://www.ncbi.nlm.nih.gov/myncbi/collections/">

    <input type="hidden" name="csrfmiddlewaretoken" value="jhWwNrS93hVB7qzy2kcD8uVRx2VHIo3dwPuG1g1pO6Bov1w2A5AlojeNByLteQiN">

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-new"
            class="usa-radio__input usa-radio__input--tile collections-new  margin-top-0"
            name="collections"
            value="new"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_new" />
            <label class="usa-radio__label" for="collections-action-dialog-new">Create a new collection</label>
        </div>
        <div class="usa-radio">
            <input type="radio"
            id="collections-action-dialog-existing"
            class="usa-radio__input usa-radio__input--tile collections-existing"
            name="collections"
            value="existing"
            checked="true"
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="collections_radio_existing" />
            <label class="usa-radio__label" for="collections-action-dialog-existing">Add to an existing collection</label>
        </div>
    </fieldset>

    <fieldset class="usa-fieldset margin-bottom-2">
        <div class="action-panel-control-wrap new-collections-controls">
           <label for="collections-action-dialog-add-to-new" class="usa-label margin-top-0">
                Name your collection
               <abbr title="required" class="usa-hint usa-hint--required text-no-underline">*</abbr>
          </label>
          <input
            type="text"
            name="add-to-new-collection"
            id="collections-action-dialog-add-to-new"
            class="usa-input collections-action-add-to-new"
            pattern="[^&quot;&amp;=&lt;&gt;/]*" title="The following characters are not allowed in the Name field: &quot;&amp;=&lt;&gt;/"
            maxlength=""
            data-ga-category="collections_button"
            data-ga-action="create_collection"
            data-ga-label="non_favorties_collection"
            required
          />
        </div>
        <div class="action-panel-control-wrap existing-collections-controls">
             <label for="collections-action-dialog-add-to-existing" class="usa-label margin-top-0">
                Choose a collection
              </label>
              <select id="collections-action-dialog-add-to-existing"
                      class="usa-select collections-action-add-to-existing"
                      data-ga-category="collections_button"
                      data-ga-action="select_collection"
                      data-ga-label="($('.collections-action-add-to-existing').val() === 'Favorites') ? 'Favorites' : 'non_favorites_collection'">
              </select>
              <div class="collections-retry-load-on-error usa-input-error-message selection-validation-message">
                Unable to load your collection due to an error<br>
                <a href="#">Please try again</a>
              </div>
        </div>
    </fieldset>

    <div class="display-inline-flex">
        <button class="usa-button margin-top-0 action-panel-submit"
            type="submit"
            data-loading-label="Adding..."
            data-pinger-ignore
            data-ga-category="collections_button"
            data-ga-action="click"
            data-ga-label="add">
          Add
        </button>
        <button class="usa-button usa-button--outline margin-top-0 action-panel-cancel"
                aria-label="Close 'Add to Collections' panel"
                ref="linksrc=close_collections_panel"
                data-ga-category="collections_button"
                data-ga-action="click"
                data-ga-label="cancel">
          Cancel
        </button>
    </div>
</form>
    </div>
  </div>
</div>

        

      </div>
    </div>
  </div>



        
    
    

<footer class="ncbi-footer ncbi-dark-background " >
    
        <div class="ncbi-footer__icon-section">
            <div class="ncbi-footer__social-header">
                Follow NCBI
            </div>

            <div class="grid-container ncbi-footer__ncbi-social-icons-container">
                
                    <a href="https://twitter.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="40"
                             height="40"
                             viewBox="0 0 40 40"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on X (formerly known as Twitter)</span>
                    </a>
                

                
                    <a href="https://www.facebook.com/ncbi.nlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="16"
                             height="29"
                             focusable="false"
                             aria-hidden="true"
                             viewBox="0 0 16 29"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg">
                            <path d="M3.8809 21.4002C3.8809 19.0932 3.8809 16.7876 3.8809 14.478C3.8809 14.2117 3.80103 14.1452 3.54278 14.1492C2.53372 14.1638 1.52334 14.1492 0.514288 14.1598C0.302626 14.1598 0.248047 14.0972 0.248047 13.8936C0.256034 12.4585 0.256034 11.0239 0.248047 9.58978C0.248047 9.37013 0.302626 9.30224 0.528931 9.3049C1.53798 9.31688 2.54837 9.3049 3.55742 9.31555C3.80103 9.31555 3.8809 9.26097 3.87957 9.00272C3.87158 8.00565 3.85428 7.00592 3.90753 6.00884C3.97142 4.83339 4.31487 3.73115 5.04437 2.78467C5.93095 1.63318 7.15699 1.09005 8.56141 0.967577C10.5582 0.79319 12.555 0.982221 14.5518 0.927641C14.7102 0.927641 14.7462 0.99287 14.7449 1.13664C14.7449 2.581 14.7449 4.02668 14.7449 5.47104C14.7449 5.67604 14.6517 5.68669 14.4946 5.68669C13.4523 5.68669 12.4113 5.68669 11.3703 5.68669C10.3506 5.68669 9.92057 6.10868 9.90593 7.13904C9.89661 7.7647 9.91525 8.39303 9.89794 9.01869C9.88995 9.26364 9.96583 9.31822 10.2015 9.31688C11.7204 9.30623 13.2393 9.31688 14.7595 9.3049C15.0257 9.3049 15.0723 9.3728 15.0444 9.62439C14.89 10.9849 14.7515 12.3467 14.6144 13.7085C14.5691 14.1571 14.5785 14.1585 14.1458 14.1585C12.8386 14.1585 11.5313 14.1665 10.2254 14.1518C9.95119 14.1518 9.89794 14.2317 9.89794 14.4899C9.90593 19.0799 9.89794 23.6752 9.91125 28.2612C9.91125 28.5674 9.8407 28.646 9.53186 28.6433C7.77866 28.6273 6.02414 28.6366 4.27094 28.634C3.82499 28.634 3.87158 28.6992 3.87158 28.22C3.87602 25.9472 3.87913 23.6739 3.8809 21.4002Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on Facebook</span>
                    </a>
                

                
                    <a href="https://www.linkedin.com/company/ncbinlm"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="25"
                             height="23"
                             viewBox="0 0 26 24"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M14.6983 9.98423C15.6302 9.24808 16.5926 8.74754 17.6762 8.51991C19.673 8.09126 21.554 8.30824 23.1262 9.7526C24.2351 10.7723 24.7529 12.1115 25.0165 13.5612C25.1486 14.3363 25.2105 15.1218 25.2015 15.9081C25.2015 18.3043 25.2015 20.6898 25.2082 23.0806C25.2082 23.3468 25.1549 23.444 24.8621 23.4414C23.1297 23.4272 21.3992 23.4272 19.6704 23.4414C19.4041 23.4414 19.3429 23.3588 19.3442 23.1019C19.3535 20.5194 19.3442 17.9368 19.3442 15.3543C19.3442 14.0005 18.3258 12.9448 17.0266 12.9488C15.7273 12.9528 14.6983 14.0071 14.6983 15.361C14.6983 17.9328 14.6917 20.5047 14.6983 23.0753C14.6983 23.3708 14.6198 23.444 14.3296 23.4427C12.6185 23.4294 10.9079 23.4294 9.19779 23.4427C8.93155 23.4427 8.86099 23.3735 8.86232 23.1086C8.8783 19.7619 8.88628 16.4144 8.88628 13.066C8.88628 11.5688 8.87874 10.0708 8.86365 8.57182C8.86365 8.3575 8.90758 8.27896 9.14054 8.28029C10.9048 8.29094 12.6687 8.29094 14.4321 8.28029C14.6464 8.28029 14.6983 8.34818 14.6983 8.54653C14.6903 9.00047 14.6983 9.45441 14.6983 9.98423Z">
                            </path>
                            <path d="M6.55316 15.8443C6.55316 18.2564 6.55316 20.6699 6.55316 23.082C6.55316 23.3629 6.48127 23.4388 6.19906 23.4374C4.47737 23.4241 2.75568 23.4241 1.03399 23.4374C0.767751 23.4374 0.69986 23.3629 0.701191 23.1006C0.709178 18.2648 0.709178 13.4281 0.701191 8.59053C0.701191 8.34026 0.765089 8.27237 1.01669 8.2737C2.74991 8.28435 4.48048 8.28435 6.20838 8.2737C6.47462 8.2737 6.5465 8.33627 6.54517 8.6065C6.54783 11.0186 6.55316 13.4308 6.55316 15.8443Z">
                            </path>
                            <path d="M3.65878 0.243898C5.36804 0.243898 6.58743 1.45529 6.58743 3.1406C6.58743 4.75801 5.32145 5.95742 3.60819 5.96807C3.22177 5.97614 2.83768 5.90639 2.47877 5.76299C2.11985 5.61959 1.79344 5.40546 1.51897 5.13334C1.24449 4.86123 1.02755 4.53668 0.881058 4.17902C0.734563 3.82136 0.661505 3.43788 0.666231 3.05141C0.67555 1.42601 1.9362 0.242566 3.65878 0.243898Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on LinkedIn</span>
                    </a>
                

                
                    <a href="https://github.com/ncbi"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="28"
                             height="27"
                             viewBox="0 0 28 28"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M16.7228 20.6334C17.5057 20.5527 18.2786 20.3944 19.0301 20.1608C21.3108 19.4193 22.5822 17.8259 22.963 15.4909C23.1228 14.5112 23.1814 13.5287 22.9883 12.5437C22.8106 11.6423 22.4013 10.8028 21.8007 10.1076C21.7526 10.0605 21.7197 10 21.7064 9.934C21.6931 9.86799 21.7 9.79952 21.7262 9.73748C22.0856 8.6206 21.9711 7.51969 21.601 6.42677C21.582 6.3497 21.5345 6.2827 21.468 6.23923C21.4016 6.19577 21.3211 6.17906 21.2429 6.19248C20.7329 6.21649 20.2313 6.33051 19.7611 6.52928C19.1103 6.7908 18.4899 7.12198 17.9104 7.51703C17.84 7.56996 17.7581 7.60551 17.6713 7.62078C17.5846 7.63605 17.4954 7.6306 17.4112 7.60489C15.2596 7.05882 13.0054 7.06203 10.8554 7.61421C10.7806 7.63586 10.7018 7.63967 10.6253 7.62534C10.5487 7.611 10.4766 7.57892 10.4148 7.53167C9.64788 7.03247 8.85171 6.58918 7.96368 6.33359C7.65781 6.24338 7.34123 6.19458 7.02239 6.18849C6.94879 6.17986 6.87462 6.19893 6.81432 6.242C6.75402 6.28507 6.71191 6.34904 6.69621 6.42145C6.32342 7.51437 6.2209 8.61527 6.56307 9.73348C6.59635 9.84264 6.64694 9.93316 6.54177 10.0516C5.47666 11.2604 5.09988 12.6834 5.19574 14.2676C5.2663 15.4244 5.46201 16.5466 6.01454 17.5769C6.84399 19.1171 8.21664 19.9119 9.85158 20.3352C10.3938 20.4706 10.9444 20.5698 11.4998 20.632C11.5384 20.7492 11.4506 20.7798 11.408 20.8291C11.1734 21.1179 10.9894 21.4441 10.8634 21.7942C10.7622 22.0458 10.8315 22.4039 10.6065 22.5516C10.263 22.7766 9.83827 22.8485 9.42421 22.8871C8.17936 23.0056 7.26471 22.4877 6.6283 21.4348C6.25552 20.8184 5.76956 20.3325 5.08523 20.0663C4.76981 19.9325 4.42139 19.8967 4.08537 19.9638C3.7898 20.029 3.73788 20.1901 3.93891 20.4111C4.03639 20.5234 4.14989 20.6207 4.27575 20.6999C4.9796 21.1318 5.51717 21.7884 5.80152 22.5636C6.37002 23.9973 7.48039 24.5697 8.93825 24.6323C9.43741 24.6575 9.93768 24.615 10.4254 24.5058C10.5892 24.4672 10.6531 24.4872 10.6517 24.6762C10.6451 25.4936 10.6637 26.3123 10.6517 27.131C10.6517 27.6635 10.1684 27.9297 9.58663 27.7393C8.17396 27.2671 6.84977 26.5631 5.66838 25.656C2.59555 23.2891 0.720966 20.1861 0.217704 16.3376C-0.357453 11.9127 0.911353 8.00824 3.98551 4.73881C6.11909 2.42656 8.99932 0.939975 12.1203 0.540191C16.5351 -0.0601815 20.4347 1.14323 23.7232 4.16373C26.2449 6.47869 27.724 9.37672 28.1048 12.7726C28.5828 17.0325 27.3686 20.7945 24.4768 23.9827C22.9762 25.6323 21.0956 26.8908 18.9982 27.6488C18.8783 27.6927 18.7585 27.738 18.636 27.7726C18.0356 27.9404 17.6189 27.6395 17.6189 27.0098C17.6189 25.7452 17.6308 24.4806 17.6295 23.2159C17.6329 22.9506 17.6128 22.6856 17.5696 22.4238C17.4325 21.6664 17.3419 21.484 16.7228 20.6334Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI on GitHub</span>
                    </a>
                

                
                    <a href="https://ncbiinsights.ncbi.nlm.nih.gov/"
                       class="ncbi-footer__social-icon ncbi-footer__social-icon--gray"
                       target="_blank"
                       rel="noreferrer noopener">
                        <svg width="26"
                             height="26"
                             viewBox="0 0 27 27"
                             fill="none"
                             xmlns="http://www.w3.org/2000/svg"
                             focusable="false"
                             aria-hidden="true">
                            <path d="M23.7778 26.4574C23.1354 26.3913 22.0856 26.8024 21.636 26.3087C21.212 25.8444 21.4359 24.8111 21.324 24.0347C19.9933 14.8323 14.8727 8.80132 6.09057 5.85008C4.37689 5.28406 2.58381 4.99533 0.779072 4.99481C0.202773 4.99481 -0.0229751 4.83146 0.00455514 4.21479C0.0660406 3.08627 0.0660406 1.95525 0.00455514 0.826734C-0.0413285 0.0815827 0.259669 -0.0193618 0.896534 0.00266238C6.96236 0.222904 12.3693 2.24179 16.9889 6.16209C22.9794 11.2478 26.1271 17.7688 26.4372 25.648C26.4629 26.294 26.3179 26.5271 25.6609 26.4684C25.0827 26.417 24.4991 26.4574 23.7778 26.4574Z">
                            </path>
                            <path d="M14.8265 26.441C14.0924 26.441 13.2371 26.6795 12.6626 26.3786C12.0092 26.0372 12.3781 25.0644 12.246 24.378C11.1154 18.5324 6.6849 14.5497 0.74755 14.1001C0.217135 14.0615 -0.0104482 13.9422 0.0134113 13.3659C0.0519536 12.1454 0.0482829 10.9213 0.0134113 9.69524C-0.00127145 9.14464 0.196946 9.03268 0.703502 9.04736C9.21217 9.27128 16.5994 16.2511 17.2804 24.7231C17.418 26.4446 17.418 26.4446 15.6579 26.4446H14.832L14.8265 26.441Z">
                            </path>
                            <path d="M3.58928 26.4555C2.64447 26.4618 1.73584 26.0925 1.06329 25.4289C0.39073 24.7653 0.00933763 23.8617 0.0030097 22.9169C-0.00331824 21.9721 0.365937 21.0635 1.02954 20.3909C1.69315 19.7184 2.59675 19.337 3.54156 19.3306C4.48637 19.3243 5.39499 19.6936 6.06755 20.3572C6.7401 21.0208 7.1215 21.9244 7.12782 22.8692C7.13415 23.814 6.7649 24.7226 6.10129 25.3952C5.43768 26.0677 4.53409 26.4491 3.58928 26.4555Z">
                            </path>
                        </svg>
                        <span class="usa-sr-only">NCBI RSS feed</span>
                    </a>
                
            </div>
        </div>
    

    <div data-testid="gridContainer"
         class="grid-container ncbi-footer__container">
        <div class="grid-row ncbi-footer__main-content-container"
             data-testid="grid">
            
                <div class="ncbi-footer__column">
                    
                        <p class="ncbi-footer__circled-icons-heading">
                            Connect with NLM
                        </p>
                    

                    <div class="ncbi-footer__circled-icons-list">
                        
                            <a href=https://twitter.com/nlm_nih class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="32"
                                     height="32"
                                     viewBox="0 0 40 40"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="m6.067 8 10.81 13.9L6 33.2h4.2l8.4-9.1 7.068 9.1H34L22.8 18.5 31.9 8h-3.5l-7.7 8.4L14.401 8H6.067Zm3.6 1.734h3.266l16.8 21.732H26.57L9.668 9.734Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on X (formerly known as Twitter)</span>
                            </a>
                        

                        
                            <a href=https://www.facebook.com/nationallibraryofmedicine class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="13"
                                     height="24"
                                     viewBox="0 0 13 24"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M4.11371 23.1369C4.11371 23.082 4.11371 23.0294 4.11371 22.9745V12.9411H0.817305C0.6709 12.9411 0.670898 12.9411 0.670898 12.8016C0.670898 11.564 0.670898 10.3287 0.670898 9.09341C0.670898 8.97903 0.705213 8.95158 0.815017 8.95158C1.8673 8.95158 2.91959 8.95158 3.97417 8.95158H4.12057V8.83263C4.12057 7.8055 4.12057 6.7738 4.12057 5.74897C4.1264 4.92595 4.31387 4.11437 4.66959 3.37217C5.12916 2.38246 5.94651 1.60353 6.95717 1.1921C7.64827 0.905008 8.3913 0.764035 9.13953 0.778051C10.0019 0.791777 10.8644 0.830666 11.7268 0.860404C11.8869 0.860404 12.047 0.894717 12.2072 0.90158C12.2964 0.90158 12.3261 0.940469 12.3261 1.02968C12.3261 1.5421 12.3261 2.05452 12.3261 2.56465C12.3261 3.16857 12.3261 3.7725 12.3261 4.37642C12.3261 4.48165 12.2964 4.51367 12.1912 4.51138C11.5369 4.51138 10.8804 4.51138 10.2261 4.51138C9.92772 4.51814 9.63058 4.5526 9.33855 4.61433C9.08125 4.6617 8.84537 4.78881 8.66431 4.97766C8.48326 5.16652 8.3662 5.40755 8.32972 5.66661C8.28476 5.89271 8.26027 6.1224 8.25652 6.35289C8.25652 7.19014 8.25652 8.02969 8.25652 8.86923C8.25652 8.89439 8.25652 8.91955 8.25652 8.95615H12.0219C12.1797 8.95615 12.182 8.95616 12.1614 9.10714C12.0768 9.76596 11.9876 10.4248 11.9029 11.0813C11.8312 11.6319 11.7626 12.1824 11.697 12.733C11.6719 12.9434 11.6787 12.9434 11.4683 12.9434H8.26338V22.899C8.26338 22.979 8.26338 23.0591 8.26338 23.1392L4.11371 23.1369Z">
                                    </path>
                                </svg>
                                <span class="usa-sr-only">NLM on Facebook</span>
                            </a>
                        

                        
                            <a href=https://www.youtube.com/user/NLMNIH class="ncbi-footer__social-icon ncbi-footer__social-icon--circled" target="_blank" rel="noreferrer noopener">
                                <svg width="21"
                                     height="15"
                                     viewBox="0 0 21 15"
                                     fill="none"
                                     xmlns="http://www.w3.org/2000/svg"
                                     focusable="false"
                                     aria-hidden="true">
                                    <path d="M19.2561 1.47914C18.9016 1.15888 18.5699 0.957569 17.2271 0.834039C15.5503 0.678484 13.2787 0.655608 11.563 0.65332H9.43556C7.71987 0.65332 5.4483 0.678484 3.77151 0.834039C2.43098 0.957569 2.097 1.15888 1.74242 1.47914C0.813665 2.32097 0.619221 4.62685 0.598633 6.89384C0.598633 7.31781 0.598633 7.74101 0.598633 8.16345C0.626084 10.4121 0.827391 12.686 1.74242 13.521C2.097 13.8412 2.4287 14.0425 3.77151 14.1661C5.4483 14.3216 7.71987 14.3445 9.43556 14.3468H11.563C13.2787 14.3468 15.5503 14.3216 17.2271 14.1661C18.5676 14.0425 18.9016 13.8412 19.2561 13.521C20.1712 12.6929 20.3725 10.451 20.3999 8.22064C20.3999 7.74025 20.3999 7.25986 20.3999 6.77946C20.3725 4.54907 20.1689 2.30724 19.2561 1.47914ZM8.55942 10.5311V4.65201L13.5601 7.50005L8.55942 10.5311Z"
                                          fill="white" />
                                </svg>
                                <span class="usa-sr-only">NLM on YouTube</span>
                            </a>
                        
                    </div>
                </div>
            

            
                <address class="ncbi-footer__address ncbi-footer__column">
                    
        <p>
            <a class="usa-link usa-link--external"
            href="https://www.google.com/maps/place/8600+Rockville+Pike,+Bethesda,+MD+20894/%4038.9959508,
            -77.101021,17z/data%3D!3m1!4b1!4m5!3m4!1s0x89b7c95e25765ddb%3A0x19156f88b27635b8!8m2!3d38.9959508!
            4d-77.0988323"
            rel="noopener noreferrer" target="_blank">National Library of Medicine
            <br/> 8600 Rockville Pike<br/> Bethesda, MD 20894</a>
        </p>
    
                </address>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/web_policies.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Web Policies
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nih.gov/institutes-nih/nih-office-director/office-communications-public-liaison/freedom-information-act-office" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            FOIA
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.hhs.gov/vulnerability-disclosure-policy/index.html" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS Vulnerability Disclosure
        

        
    </a>


                        </li>
                    
                </ul>
            

            
                <ul class="usa-list usa-list--unstyled ncbi-footer__vertical-list ncbi-footer__column">
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://support.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Help
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/accessibility.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Accessibility
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__vertical-list-item">
                            









    <a href="https://www.nlm.nih.gov/careers/careers.html" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            Careers
        

        
    </a>


                        </li>
                    
                </ul>
            
        </div>

        
            <div class="grid-row grid-col-12" data-testid="grid">
                <ul class="ncbi-footer__bottom-links-list">
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nlm.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NLM
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.nih.gov/" class="usa-link  usa-link--alt ncbi-footer__link"  >
        

        
            NIH
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.hhs.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            HHS
        

        
    </a>


                        </li>
                    
                        <li class="ncbi-footer__bottom-list-item">
                            









    <a href="https://www.usa.gov/" class="usa-link usa-link--external usa-link--alt ncbi-footer__link" rel="noreferrer noopener" target='_blank' >
        

        
            USA.gov
        

        
    </a>


                        </li>
                    
                </ul>
            </div>
        
    </div>
</footer>

    


        
        
    
  <script  type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/pinger/pinger.js"> </script>


    
        

<button class="back-to-top" data-ga-category="pagination" data-ga-action="back_to_top">
    <label>Back to Top</label>
    <svg class="usa-icon order-0" aria-hidden="true" focusable="false" role="img">
        <use xlink:href="/static/img/sprite.svg#arrow_upward"></use>
    </svg>
</button>
    


        
    
    
    
        
    <script type="application/javascript">
    window.ncbi = window.ncbi || {};
    window.ncbi.pmc = window.ncbi.pmc || {};
    window.ncbi.pmc.options = {
        logLevel: 'INFO',
        
        staticEndpoint: '/static/',
        
        citeCookieName: 'pmc-cf',
    };
</script>
    <script type="module" crossorigin="" src="/static/assets/base-133c6271.js"></script>
    
    <script type="text/javascript" src="https://cdn.ncbi.nlm.nih.gov/core/jquery/jquery-3.6.0.min.js">&#xA0;</script>
    <script type="text/javascript">
        jQuery.getScript("https://cdn.ncbi.nlm.nih.gov/core/alerts/alerts.js", function () {
            galert(['div.nav_and_browser', 'div.header', '#universal_header', '.usa-banner', 'body > *:nth-child(1)'])
        });
    </script>


    <script type="text/javascript">var exports = {};</script>
     <script src="/static/CACHE/js/output.13b077bc3ffd.js"></script>

    <script type="module" crossorigin="" src="/static/assets/article-44d04358.js"></script>
    
        <script type="module" crossorigin="" src="/static/assets/math-574fdcc6.js"></script>
    
    

    </body>
</html>
