There is evidence that clinicians' practice regarding the delivery of dementia diagnoses varies in style and fluctuates in quality, even among highly experienced staff working in a specialist dementia clinic.
This variation in quality may be minimised through better adherence to available guidelines.
We designed and evaluated a workshop to improve clinicians' self‐efficacy in delivering a diagnosis of dementia during feedback sessions.
The 3‐h workshop content was based on published guidelines for clinicians and included didactic material and opportunities to reflect on current practice and to critique the practices of clinician actors depicted in videos.
Thirty clinicians from two dementia clinics participated in the workshops.
Clinicians' self‐efficacy improved from pre‐ to postintervention and again from postintervention to a follow‐up 4 months later.
Improvements in self‐efficacy were especially notable in non‐medical personnel.
Clinicians identified finding ways to provide hope as the area in which their practice changed most.
Clinicians should be provided with guidelines on best practice in delivering a dementia diagnosis and be given more opportunities to reflect on their practice in doing so.
Workshops may be an effective way of improving clinicians' communication self‐efficacy.
At a minimum, clinicians should be provided with guidelines on best practice in delivering a dementia diagnosis and be given more opportunities to reflect on their practice in doing so.
As the global population ages and the number of people diagnosed with dementia increases, the effective disclosure of diagnoses is critical.
However, clinicians can find communicating a dementia diagnosis challenging.1,2,3Clinicians acknowledge that giving bad news is daunting and are personally motivated to avoid upsetting people.1,4Dementia is a difficult diagnosis to deliver to clients and their carers because the condition is progressive, involves a myriad of symptoms and is associated with diagnostic uncertainty; treatment options are of limited efficacy.
Recently, a structured framework for the delivery of a dementia diagnosis has been proposed,11that adapted the SPIKES protocol for breaking bad news12for the delivery of a dementia diagnosis.
The protocol was revised to include the recommendations that a patient be accompanied by a trusted caregiver—for support and to aid in comprehension of the diagnosis—and that the diagnosis be delivered by a multidisciplinary team.
In relation to providing hope, the revised protocol, named SPIKES‐D, also highlighted the importance of including positive aspects of dementia when communicating a diagnosis, including ‘the slow progressive course, pharmacological and non‐pharmacological treatments, trials on Alzheimer's Disease and the encouragement to maintain the patient's autonomy’.11,p.335Interventions based on the original SPIKES protocol have been proven effective at ameliorating clinical communication skills in a range of settings, such as oncology, paediatrics, palliative care and intensive care.13However, we were unable to identify any interventions that aimed to improve professional practice in the delivery of a dementia diagnosis.
In Australia, a diagnosis of dementia is often delivered by clinicians at multidisciplinary memory clinics in a feedback session that follows extensive assessment of the client's cognitive functioning.
In Victoria, Australia, these clinics have been established across health regions and are known as Cognitive, Dementia and Memory Services (CDAMS).
These memory clinics are staffed by doctors, allied health professionals and neuropsychologists.
The role of these clinics is to provide a specialist diagnostic service for people experiencing memory loss or changes to their thinking.
No study has yet examined clinician self‐efficacy in their ability to communicate a dementia diagnosis in line with suggested guidelines, such as the SPIKES‐D protocol, nor attempted to improve diagnostic communication didactically through exposure to these guidelines.
This pilot study explored the outcomes of an educational intervention designed to improve clinicians' awareness of the SPIKES‐D protocol and facilitate reflective discussions amongst clinicians working in two CDAMS clinics in Victoria, Australia.
The aim of the study was to enhance the quality of dementia diagnosis communication in multidisciplinary memory clinics by increasing clinicians' awareness of the guidelines and improving clinician self‐efficacy in delivering diagnoses according to these guidelines.
The aim of the analyses reported here was to assess whether the workshop had been effective in improving clinicians' self‐efficacy in delivering diagnoses and to explore whether any improvements varied by key participant characteristics.
The main study hypothesis was that clinician self‐efficacy would improve from preworkshop to postworkshop and would be maintained at follow‐up.
A quasi‐experimental (i.e. non‐randomised) non‐equivalent groups design trial was used in this study.
This design was chosen as the simplest and most cost‐effective option in the real‐world setting of CDAMS clinics in Australia.
The project involved co‐design with clients and clinicians at all stages.
This study received ethics approval from Eastern Health (S22‐091‐84666), Monash Health (RES‐22‐0000‐338A) and the La Trobe University Human Research Ethics Committee (HEC84666).
The entire study comprised four phases.
The first phase involved establishing a steering committee to co‐design the intervention.
The second phase entailed conducting a survey and phone interviews with clients and carers attending CDAMS clinics to collate accounts of their experiences of the diagnostic disclosure meeting.
These accounts were used to inform the design of the intervention (i.e., the workshop).
The third phase involved delivery and quantitative evaluation of the intervention.
This paper briefly outlines the activities of the steering committee (phase one) and presents the findings of phase three of the study.
In phase one of this study, a steering committee was established to help co‐design the intervention that would be delivered to CDAMS clinicians.
Co‐design refers to the meaningful involvement of research users and experts during the study planning phase,14where experts can be either specialists or experts in the lived experiences being explored.15Recruitment for this steering committee involved contacting specialists at two CDAMS clinics in Victoria, Australia, as well as individuals living with dementia and those with experience caring for someone living with dementia.
The established committee comprised 12 people and included a person living with dementia (n= 1), carers of people living with dementia (n= 3), clinicians (n= 4) and the research team (n= 4).
The steering committee was asked to familiarise themselves with the SPIKES‐D guidelines before agreeing upon the most essential elements of a good diagnostic disclosure meeting.
After confirming these procedural elements, various intervention formats were discussed.
It was agreed that the most effective approach to improve clinicians' awareness of current guidelines for communicating a dementia diagnosis would be through an interactive workshop.
For phase three of this study, clinicians were approached at each of the two participating clinics.
Clinicians were informed about the study via a talk given to each team at their respective CDAMS clinic.
An information sheet about the study was also provided by email.
Written online consent was sought from each clinician before being recruited into the study.
Clinicians were also informed that they could withdraw from the study at any time; whereupon their feedback would not be utilised as part of the study.
A total of 32 clinicians from two CDAMS clinics were recruited into the study (Table1).
Face‐to‐face workshops were conducted at each clinic, supplemented by an online workshop for four clinicians who were unable to attend in person.
A two‐and‐a‐half‐hour, three‐part, face‐to‐face workshop was delivered (see DataS1for the workshop program).
The first part outlined the goals of the workshop, which were threefold: (1) to understand the elements and techniques that constitute good quality communication of dementia diagnoses; (2) to learn the skills required to apply at least one new technique in dementia diagnosis communication; and (3) to develop the skills to reflect on and evaluate the quality of various approaches to communicating a dementia diagnosis.
This first part also focused on facilitating discussions among clinicians on the challenges faced when delivering diagnostic feedback.
The second part presented a literature overview on breaking bad news and delivering dementia diagnoses, didactic information on best practice guidelines (predominantly the SPIKES‐D protocol, with a focus on its dementia‐specific additions, along with commonalities in other guidelines for breaking bad news12,16,17,18) and feedback regarding clients' experiences of receiving a dementia diagnosis (obtained in phase two of the study).
Key skills and practices derived from the SPIKES‐D protocol were introduced, including assessing client needs, managing time effectively, addressing family dynamics, raising difficult topics (e.g., driving) and providing hope within realistic parameters.
In the final part of the training workshops, three separate videos depicting mock diagnostic feedback meetings were presented.
The scenarios portrayed in the feedback sessions included a client, family carer, geriatrician, psychologist and social worker.
The sessions began with introductions before conveying the diagnosis and ended with implications for the client's life.
The three scenarios depicted feedback sessions of differing quality and included examples of poor practice and good practice, based on the SPIKES‐D guidelines.
We designed one scenario demonstrating particularly poor practice, one demonstrating intermediate practice and one demonstrating good (though not perfect) practice in communicating a dementia diagnosis.
Participants rated the quality of these scenarios and engaged in group discussions, which highlighted essential elements of effective feedback sessions.
Finally, workshop participants were given an opportunity to list additional issues that could be covered in more depth or in a different way in future workshops.
Basic details about each clinician (e.g. profession, clinic, years of professional experience and years of experience working with people living with dementia) were collected.
Clinicians' professions were recoded into two categories: medical and nursing (n= 17, including doctors, registrars, geriatricians and nurses) versus allied health and psychology (n= 15, including neuropsychologists, occupational therapists, social workers and a speech pathologist).
In addition to attending the education workshop, clinicians were required to complete several online questionnaires.
Upon recruitment into the study, clinicians filled out a 12‐item questionnaire designed to assess clinicians' self‐efficacy (SE‐12) in their clinical communication skills within a health‐care setting.19An additional eight questions were included alongside this self‐efficacy assessment, in response to the core elements of good diagnostic disclosure outlined in the SPIKES‐D protocol.
These additions were agreed upon by the steering committee and covered self‐efficacy in speaking directly with the client, providing hope, involving family members in planning, coping with clients' and family members' emotions, and dealing with family dynamics (see DataS2).
The response options were the same as for the SE‐12.
The 20‐item self‐efficacy questionnaire (Figure1) was administered at three intervals: upon entry into the study (T1), 1 week postintervention (T2) and 4 months postintervention (T3).
Flow diagram of participant completion of 20‐item self‐efficacy measures.
When there is a risk of ceiling effects in the main outcome measure, the potential to detect improvements is reduced, and perceived change may be a preferable option.
At T3, clinicians who participated in the workshop completed a questionnaire detailing any changes in their practice that they observed since they attended.
The perceptions of change questionnaire comprised 11 questions (see Table2and Figure2) and covered practices related to best practice in the delivery of dementia diagnoses.
Clinicians were asked to rate any perceived changes on a six‐point Likert scale from 0 =Some deteriorationto 5 =A huge amount of improvement.
Any score over 2 (very little improvement) was considered positive.
A free‐text box was also provided, seeking additional information or suggestions from participating clinicians.
The software package IBM SPSS 30.0 was used for all statistical analyses.
For means and standard deviations of each of the 20 self‐efficacy items at T1, T2 and T3, see DataS3.
Given the small number of participants, the construct validity of the 20‐item clinician self‐efficacy scale was not tested using factor analysis.
However, the internal reliability of the measure was high (Cronbach's alpha over .92 at all three time points), so total scores were calculated at each time point by summing item scores for each participant.
To compensate for missing data at T2 and T3 and to permit subgroup analyses, missing scores on the 20‐item self‐efficacy measure were replaced with a conservative value—the score for that person at the previous time point.
Changes in self‐efficacy scores over time were analysed using the non‐parametric equivalent of a repeated measures ANOVA—the Friedman test.
If the results using all three time points were significant, post hoc analyses were planned to examine change from T1 to T2 and T2 to T3 using the Wilcoxon signed ranks test.
The repeated measures analyses were repeated to explore the impacts of profession on change in clinician self‐efficacy by analysing the data for each subgroup separately.
Whether change was related to years of experience or years working with dementia was explored using non‐parametric correlation (Spearman's rho).
The 11 perceived change items were analysed individually using descriptive statistics only.
In total, 30 clinicians attended the workshops (Table1).
Lists of challenges in communicating diagnoses and changes in feedback sessions over time were identified.
At the close of the workshops, clinicians listed some suggestions for how to improve the workshops.
Additional topics included issues that were not covered in current guidelines (e.g. dealing with family conflicts) or were particularly relevant to local conditions (e.g. securing powers of attorney, raising capacity to drive, dealing with cultural sensitivities and using interpreters in feedback sessions).
Analysis of the 20‐item self‐efficacy measure revealed that clinicians' self‐efficacy in their clinical communication skills differed significantly across the three times of measurement (χ2= 17.7,p< 0.001).
Scores improved significantly from preintervention (T1 Mean 7.1, SD = 1.0) to postintervention (T2 Mean 8.0, SD = 0.
7, T1 to T2Wilcoxon z = 3.1, p= 0.002) and increased again from T2 to follow up 3 months later (T3 Mean 8.2, SD = 0.7, T2 to T3Wilcoxon z= 2.7,p= 0.007).
Similar results were obtained for change in scores with no substitution for missing values (respectively T1 to T2Wilcoxon z= 3.1,p= 0.002) and (T2 to T3Wilcoxon z= 2.4,p= 0.02).
Change in self‐efficacy was explored separately for each of the two main clinician professions.
This analysis showed no change overall for the 17 participants from the medical and nursing professions (χ2= 2.1,p= 0.36) but a significant change overall for the 15 participants who were in the allied health and psychology group (χ2= 19.0,p< 0.001).
Years of experience in the profession and years working with people with dementia were not related to change in self‐efficacy (all Spearman's rho coefficients between change scores and duration measures were non‐significant).
However, experience working with people with dementia was positively related to self‐efficacy at T1; rho = .44,p= 0.01.
No clinicians reported a deterioration in any of the 11 domains of change in practice.
The most positive changes were reported in the degree to which clinicians found ways of providing hope, setting aside time for questions, and acknowledging patients' and carers' feelings (see Table2and Figure2).
Minor improvements were reported in the amounts and types of information provided and in the degree to which participants managed conflict.
This study aimed to evaluate the impact of an educational intervention workshop to enhance the quality of dementia diagnosis communication in multidisciplinary memory clinics.
The workshop focused on increasing clinicians' awareness of the SPIKES‐D guidelines for delivering dementia diagnoses and improving their self‐efficacy in adhering to these guidelines.
The main measure used in the study was a modified self‐efficacy scale (SE‐12) related to clinicians' clinical communication skills.
The study found that clinicians' self‐efficacy in clinical communication increased from before to after the workshop and continued to increase for 4 months following the workshop.
Findings support previous research that has found interventions can improve clinicians' communication skills.13While the interventions included in the systematic review by Johnson and Panagioti13involved observer‐rated communication skills and self‐assessments of self‐efficacy, rather than self‐rated efficacy, other research has made this connection between self‐efficacy and improved communication skills of health‐care professionals.20,21Because self‐efficacy relates to a belief in one's ability to achieve outcomes by performing certain tasks or behaviours, self‐efficacy serves as an effective measure for interventions aimed at behavioural change.22,23The modified SE‐12 used in this study sought to capture whether clinicians' self‐efficacy in applying guidelines to their practice could be increased.
The measured improvement identified in this study is a particularly positive outcome, given that many of the participants were highly experienced specialists.
In a systematic review conducted by Mata et al.23looking at training in communication skills and the self‐efficacy of health professionals, the authors reported that training in communication skills can improve the performance and self‐efficacy of health professionals and concluded that improvements in self‐efficacy may ‘increase the likelihood of professionals using appropriate communication behaviors’.23While Mata et al.23identified the importance of experiential activities within such training—activities that were not conducted as part of this study—they also noted the importance of reserving time for discussion when designing training programs, particularly discussions related to the basic concepts of communication within relevant contexts of practice.
While time allocated during the intervention allows participants to engage deeply with the material, discuss concepts and begin the process of internalising new knowledge, another important consideration is the time required for participants to integrate and practice what they have learned.
The continued improvement in clinicians' self‐efficacy from T2 to T3 that we identified in this study may represent the time needed to enable clinicians to reflect, trial and implement new approaches in their practice postintervention, based on the education received during the intervention and their improved self‐efficacy.
In terms of evaluations of change in their own practice, clinicians reported the largest improvements in their practice related to the degree to which they provided hope, set aside time for questions, and acknowledged patients' and carers' feelings.
There was relatively modest improvement in the ways in which clinicians managed conflict, perhaps reflecting the difficulty they continued to feel in doing so.
There was also relatively minor change in the types and amounts of information provided, although a substantial minority reported change in both the type and amount of visual and written information provided.
The present study was not without limitations.
Being a pilot study, one of the limitations was the small number of participants, which limited the complexity of the statistical analyses we were able to undertake.
Additionally, not all participants completed the self‐efficacy measure (SE‐12) at all three intervals (T1, T2 and T3).
This poses a challenge to the internal validity of the findings, potentially leading to skewed estimates of changes in self‐efficacy over time.
Furthermore, the reduced sample size for longitudinal analysis limited the statistical power to detect significant effects and increased the risk of type two error.
Ceiling effects are present in the SE‐12 measurement; this effect reduced our capacity to demonstrate changes in these scores.
Moreover, the validity and reliability of the eight additional questions in the modified SE‐12 were not tested.
Given that this was a pilot study, intended to explore feasibility and identify potential issues before a full‐scale study, the inclusion of untested questions can be considered acceptable.
However, the results should be interpreted with caution.
Further studies could also investigate the impacts of focusing on aspects of diagnostic feedback sessions that were not included in our intervention but were listed by clinicians as skills for which they lacked a sense of self‐efficacy, for example in communicating with people from culturally and linguistically diverse backgrounds and with families where there is conflict.
Clinicians' self‐efficacy in delivering dementia diagnoses can be improved via a didactic intervention aimed at informing clinicians about best practice guidelines for the delivery of dementia diagnoses and by providing an opportunity to reflect on their practice.
Given participants were all highly experienced clinicians, the improved self‐efficacy scores, backed up by stated changes to practice, are an encouraging result.
This work was funded by a grant from Dementia Australia.
One of the authors (BR) was employed at a participating Cognitive, Dementia and Memory Service during the initial phase of the project.
Professor Yvonne Wells is an Associate Editor of Australasian Journal on Ageing.