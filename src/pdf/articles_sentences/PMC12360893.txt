Multidisciplinary tumour boards (MTBs) play a critical role in prostate cancer management, but their time‐intensive nature limits accessibility.
This study evaluates machine learning (ML) algorithms for automating MTB recommendations in prostate cancer patients, focusing on multi‐label classification for diagnostic and therapeutic decisions.
A retrospective dataset of 1929 MTB recommendations from 2020 to 2024 was used for model development and validation at a single academic centre.
Three ML algorithms—Decision Tree, Random Forest and K‐Nearest Neighbours (KNN)—were trained to predict recommendations for PSMA‐PET, conventional imaging, active surveillance and local therapy (radical prostatectomy or radiotherapy).
Model performance was assessed using accuracy, precision, recall and F1‐score.
The Random Forest model achieved the highest overall accuracy (66.3%, 95% CI 61.7–71%) and showed stable performance across most outcome categories.
Predictions for local therapy were highly accurate (F1‐score: 0.99), but model performance was lower for less frequent recommendations such as PSMA‐PET and active surveillance, reflecting class imbalance and recent guideline changes.
Limitations include moderate overall accuracy, retrospective single‐centre design and the need for extensive manual data preprocessing.
In addition, a high proportion of patients were eligible for multiple treatment options, which may limit the discriminatory value of certain outcomes.
This study demonstrates the potential of ML to replicate MTB decision patterns in prostate cancer with reasonable accuracy.
However, the current model requires further optimization before it can be considered for clinical application.
It should be regarded as a proof‐of‐concept that highlights both the opportunities and the challenges of algorithm‐based decision support in oncology.
Future work should focus on improving model performance through multi‐institutional data, prospective validation and continuous adaptation to evolving clinical guidelines.
Prostate cancer is the most common malignancy among men and the second leading cause of cancer‐related mortality worldwide.1While early detection through prostate‐specific antigen (PSA) screening has reduced mortality rates,2it has also led to challenges such as overdiagnosis and overtreatment.
Prostate cancer exhibits a highly heterogeneous disease course, ranging from indolent tumours requiring active surveillance to aggressive malignancies demanding immediate intervention.
Consequently, accurate risk stratification and personalized treatment recommendations are critical to optimizing oncological outcomes while minimizing unnecessary treatment‐related morbidity.
Artificial intelligence (AI) demonstrated the potential to streamline oncological workflows by leveraging machine learning (ML) algorithms for automated decision‐making.
Classical ML models displayed strong performance in structured clinical datasets while requiring fewer computational resources compared to deep learning (DL) approaches.
Given the need for an efficient and interpretable AI solution, we developed a ML‐based algorithm for the automatic generation of MTB recommendations in newly diagnosed prostate cancer patients.
This study aimed to develop, train and validate an ML model using real‐world tumour board data from a single institution in a retropective dataset.
We employed a multi‐label classification approach to predict key clinical recommendations, including imaging strategies (PSMA‐PET, conventional staging) and treatment options (radical prostatectomy, radiotherapy and active surveillance).
These represent different clinical decision points – diagnostic recommendations versus treatment decisions.
After assessing multiple classification algorithms, the best‐performing model was implemented into a web‐based application for demonstration and experimental testing.
By integrating AI‐driven automation into tumour board workflows, we aim to improve efficiency and facilitate broader access to high‐quality oncological decision‐making.
Patients were diagnosed with prostate cancer through our biopsy clinic or referrals with biopsy reports.
All patients presented were being considered for initial management discussion at the tumour board.
They were registered for the MTB by our staff or treating physician.
Certified MTB staff entered relevant data into our in‐house software, TDS (Tumour Documentation System).
All tumour board reports and recommendations were extracted as Word documents and saved on a hospital network drive.
As this workflow is part of standard operations, Institutional Review Board (IRB) approval was waived.
The patient history and recommendations from November 2007 until July 2024 were subsequently extracted.
Clinical variables, including patient age, prostate‐specific antigen (PSA) levels, prostate volume, digital rectal examination (DRE) results, International Society of Urological Pathology (ISUP) category, the number of positive biopsy cores, the overall number of biopsy cores and various comorbidities such as hypertensive disease, diabetes mellitus, chronic heart disease, hyperlipoproteinemia, additional malignancies and prior surgeries, were extracted from the text body.
The computational expertise for developing, testing and deploying these AI programs was provided by our co‐authors with expertise in machine learning and data science.
Data extraction process was executed through the utilization of regular expressions.6The feasibility of this approach is attributable to the standardized and categorical nature of the patient history and recommendations.
To ensure data integrity during the development, a manual proofreading process was conducted on all documents.
The outcome was defined as a multilabel classification problem, given the potential for multiple tumour board recommendations to be in effect simultaneously.
These recommendations encompassed staging examinations, such as PSMA‐PET scans, CT scans and bone scintigraphy, as well as therapy strategies, including radical prostatectomy, radiation therapy and active surveillance.
Local treatment with curative intent was handled in the model as a single outcome combining both radiation therapy and surgery, as patients qualifying for one typically qualify for both options.
The models were trained on this outcome.
All variables were stored in a database as continuous (e.g., age, PSA, prostate volume, number of positive and overall biopsy cores) or categorical (e.g., DRE, Gleason score and all comorbidities) variables.
As decision‐tree‐based models demonstrate robust performance in the absence of standardization, this step was excluded in the data preparation phase.
In the initial development stage, multiple test experiments were conducted to ascertain that standardization yielded analogous results, even for the K‐Nearest‐Neighbour (KNN) model.
Consequently, continuous variables were employed directly, while categorical variables were converted to numerical variables using ordinal encoding.
A comparison of deep learning‐based approaches and classical ML models reveals that the former do not offer advantages for tabular data.
However, the latter requires significantlyfewercomputational resources.
Consequently, we opted to train and assess a range of ML models that were particularly well‐suited for multilabel classification tasks.
The Decision Tree Classifier (DT),7Random Forest (RF)8,9and KNN models10,11,12,13were selected based on a OneVsRest approach.
The dataset was partitioned into a training cohort and validation cohort, with a ratio of 80:20.
Active surveillance (AS) and PSMA‐PET imaging have recently been incorporated into German prostate cancer guidelines.14Preliminary experiments indicated that precision and recall for these two outcomes were low due to the limited number of recommendations in comparison to the overall size of the dataset.
Consequently, we opted to incorporate exclusively tumour board sessions from 01/01/2020 onwards.
Furthermore, the dataset was stratified based on the presence or absence of AS and PSMA‐PET imaging to ensure an adequate sample size for each group.
The dataset procurement and split are summarized in Figure1.
Flowchart of data extraction and model.
Development pipeline overview of cohort selection, data preprocessing, outcome stratification, model training and deployment.
The model that demonstrated the highest accuracy was stored in pickle format for shipping and deployment.
A rudimentary frontend web application was developed to load and serve the model, employing the streamlit framework.15The application loads the model, and users can enter patient data.
Upon selection of the prediction functionality, the prediction calculation is initiated, employing all the values entered into the system.
The output vector variable is then converted to the German tumour board recommendation text using a simple heuristic text converter.
The application outputs the outcome vector variable, the converted text recommendation and the prediction time.
Python including the packages NumPy, Pandas and Scikit‐Learn were utilized for data preprocessing, training and validation.16,17,18The complete source code is accessible on our institutional GitHub page (Link:https://github.com/ukd-uro/pretb_rf_dev).
The pickle file of the model that demonstrated the highest level of performance is also available in a GitHub repository (Link:https://github.com/ukd-uro/pretb_rf_app).
The web application can be accessed and used for demonstration purposes (Link:https://pretb-rf.streamlit.app).
Following the training phase, each model was evaluated on the validation cohort.
The primary performance metrics, including overall accuracy, recall and precision, were calculated.
Overall accuracy was defined as the number of correct predictions divided by the total number of predictions made.
Precision was defined per outcome class as the number of true positives divided by the sum of the number of true positives and false positives.
Recall was defined per outcome class as the number of true positives divided by the sum of true positives and false negatives.
The F1‐score was defined as the harmonic mean of precision and recall.
To calculate 95% confidence intervals, 1000 bootstrap samples were utilized.
In total, 6979 tumour board recommendations were recorded between December 2007 and July 2024.
A detailed overview of patient and clinical characteristics for the complete dataset is provided in TableS1.
To ensure compatibility with contemporary German guideline recommendations, only cases from January 2020 onward were included in model development.
This resulted in a final dataset of 1929 recommendations used for training and validation.
To enhance model robustness, an 80:20 hold‐out validation approach was applied.
Given the underrepresentation of “Active surveillance” and “PSMA‐PET” recommendations, stratified sampling ensured adequate representation of these categories in both training and validation cohorts.
The clinical characteristics of this model cohort are summarized in Table1.
TableS2presents the distribution of tumour board recommendations across the entire dataset (n= 6979) and is provided for reference.
Clinical and demographic characteristics of the final model cohort (n= 1929): Distribution of baseline variables used for training and evaluation of machine learning models.
Note:The superscript defines the size of the cohorts, to be compared as objective as different sizes in cohorts are relevant to understand the baselines.
The overall predictive accuracies for the three models were as follows: DT (62.2%, 95% CI: 57.5%–66.8%), RF (66.3%, 95% CI: 61.7%–71%) and K‐Nearest Neighbours (66.6%, 95% CI: 61.7%–71.5%).
The classification performances for each model across all outcome classes are presented in Table2.
Classification performance of machine learning models across all outcome categories: Precision, recall and F1‐score for Decision Tree, Random Forest and K‐Nearest Neighbour classifiers on the test set.
Notably, the prediction of local therapy (radical prostatectomy or radiotherapy) yielded the highest precision, recall and F1‐scores across all models.
This likely reflects the high prevalence of patients with localized prostate cancer and the fact that both treatment options are frequently guideline‐concordant for patients with localized disease.
As a result, a large proportion of patients qualified for both modalities, which limits the discriminatory power of this outcome in model training.
The low prevalence of PSMA‐PET and active surveillance recommendations, on the other hand, contributed to reduced performance metrics in these categories.
Although the KNN model demonstrated slightly higher overall accuracy, the Random Forest model showed greater stability, particularly in underrepresented outcomes such as PSMA‐PET and conventional imaging.
It was therefore selected for deployment.
FigureS1illustrates an example of a single decision tree trained during the model development process.
It serves as a representative visualization of how clinical variables (e.g., PSA, ISUP, age) are hierarchically applied in the classification logic of the ensemble model.
The Precision‐Recall (PR) curves for the DT, RF and KNN models are illustrated in Figure2A–C.
The RF model maintained stable precision at higher recall values, while the DT and KNN models exhibited a steady decline in performance.
This supports the selection of the RF model as the most reliable for tumour board recommendation prediction.
Performance metrics and feature relevance of machine learning models.
(A–C) Precision‐recall curves for each classifier; (D–F) Feature importance visualizations for diagnostic and therapeutic outcomes based on Random Forest model.
Considering precision and recall metrics, the RF model was selected for further evaluation and deployment.
The model demonstrated robust performance across different recommendation categories, ensuring consistency in predictions.
The impact of guideline updates and the significance of feature selection were key considerations for future model refinements.
The feature importance analysis, calculated using Gini importance for the RF model, is presented in Table3and Figure2D–F.
Age, PSA levels and ISUP category were identified as the most influential predictors across all recommendation categories.
While oncological factors significantly influenced model predictions, comorbidities had a comparatively minor impact.
Feature importance of input variables in the Random Forest model: Relative contribution of clinical variables to model predictions across outcome categories, based on Gini importance.
Oncological parameters such as PSA, ISUP grade and age had the highest influence, while comorbidities played a minor role.
We developed and validated a ML‐algorithm for automatically generating MTB recommendations for prostate cancer patients.
The model was trained on a large dataset of historical tumour board decisions and was designed as a multi‐label classification task.
We evaluated three different ML models—DT, RF and K‐Nearest Neighbour (KNN)—to determine the most effective approach.
The RF model demonstrated the highest stability across multiple recommendation categories and was therefore selected for further development, including deployment in a simple front‐end web application.
The Random Forest model achieved the highest overall classification accuracy (66.3%), outperforming DT and KNN, particularly for underrepresented outcomes such as active surveillance and PSMA‐PET imaging.
However, the overall accuracy remains limited and must be interpreted with caution.
The modest performance highlights the inherent challenges of representing complex, nuanced clinical decisions as structured input variables.
Moreover, expert recommendations vary over time and between physicians, particularly in the context of evolving clinical guidelines.
A notable limitation is the outcome category “local therapy,” which comprised radical prostatectomy or radiotherapy.
This was predicted with near‐perfect precision and recall (F1‐score: 0.99) across all models, which reflects that a large proportion of patients were eligible for both treatment options.
While this consistency aligns with guideline‐conform recommendations, it reduces the discriminative value of this prediction in a modelling context and may lead to overestimation of overall model performance.
The RF model maintained stable precision across higher recall thresholds, as shown by the precision‐recall curves, supporting its selection for further exploration.
Nevertheless, we emphasize that the current accuracy level is not sufficient for clinical deployment and that further improvements in data quality and model structure are required.
Analysis of feature importance revealed that age, PSA and ISUP grade were the most influential variables across all recommendation categories.
This aligns with clinical practice and confirms that the model captures key oncological factors in prostate cancer management.
For diagnostic recommendations, PSA levels played a central role in PSMA‐PET selection, while ISUP grading and age were dominant in predicting conventional imaging.
Active surveillance was most strongly associated with low ISUP grade, as expected.
In contrast, comorbidities had limited influence on predictions, suggesting that their impact in real‐world decision‐making is not sufficiently captured in our structured dataset.
These findings demonstrate that the model reflects guideline‐based patterns but remains limited in its ability to account for more subtle or individualized clinical judgements.
The application of AI‐based decision‐support tools in oncology has the potential to enhance efficiency, standardization and scalability of tumour board workflows.
Our study illustrates that ML can replicate MTB decisions to a certain extent, especially for high‐frequency, guideline‐driven recommendations.
The web‐based prototype demonstrates the feasibility of deploying such a system with minimal computational resources, which could make AI‐assisted recommendations more broadly accessible in the future.
Nonetheless, the current model should be understood as an initial proof‐of‐concept.
It is not intended to replace clinical judgement, nor is it ready for clinical use.
The accuracy achieved—while encouraging in parts—is insufficient for direct application in patient care.
Clinicians must continue to validate all recommendations in the appropriate clinical context, particularly in borderline or complex cases where individual factors and shared decision‐making are critical.
Second, the model relies exclusively on structured data extracted from standardized documentation.
While this approach allows for efficient feature selection, it does not reflect the richness of narrative clinical information.
Advanced natural language processing (NLP) methods, such as transformer‐based models, could potentially enhance the interpretability and precision of predictions by incorporating unstructured textual data.
Third, clinical guidelines and treatment strategies evolve over time.
This dynamic environment necessitates regular model updates and retraining to remain in line with current standards.
Prospective studies, ideally embedded in real‐world clinical workflows, will be essential to evaluate the practical utility and acceptance of ML‐based recommendation systems in oncology.
In summary, we developed and validated a machine learning model for the automated generation of multidisciplinary tumour board (MTB) recommendations in prostate cancer.
Among the tested algorithms, the Random Forest model demonstrated the most robust performance and consistency across outcome categories.
Feature importance analysis confirmed that classical oncological parameters—such as age, PSA level and ISUP grade—were the key drivers of prediction, reflecting established clinical decision‐making patterns.
The integration of this model into a web‐based application illustrates the technical feasibility of providing scalable, AI‐supported tools in oncological care.
However, while the results are encouraging, the current model must be regarded as an early‐stage prototype.
Its predictive performance—although reasonable—is not yet sufficient for clinical implementation.
Further development is needed to enhance accuracy, address data imbalance and ensure adaptability to evolving guidelines.
Prospective validation in diverse clinical settings, combined with continuous model refinement and expansion of the underlying dataset, will be essential steps toward realizing the full potential of ML‐assisted decision support in prostate cancer care.